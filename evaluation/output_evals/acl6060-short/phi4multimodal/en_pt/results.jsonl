{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "pt", "output": "\"Hi everyone, today I'm going to present our research work, learning to reason deductively, math problem solving as complex region extraction.\"", "metrics": {"bleu_score": 1.962672844874697, "chrf_score": 30.307629684463073, "xcomet_score": 0.6742108464241028, "xcomet_qe_score": 0.8320356011390686, "metricx_score": 15.583565711975098, "metricx_qe_score": 13.153488159179688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "pt", "output": "I'm Alan from Bytedance AI Lab, and this is a joint work with Chery from the University of Texas at Austin and Wei Lu from Sun Tech.", "metrics": {"bleu_score": 3.7744981031838685, "chrf_score": 27.16991401699283, "xcomet_score": 0.614809513092041, "xcomet_qe_score": 0.6778502464294434, "metricx_score": 13.661632537841797, "metricx_qe_score": 9.192389488220215, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, gostaria de falar sobre nossa motivação para o raciocínio.", "metrics": {"bleu_score": 76.7733168433653, "chrf_score": 94.1467473244312, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2394769191741943, "metricx_qe_score": 2.7096683979034424, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, mostramos exemplos em que o raciocínio de múltiplos passos é útil.", "metrics": {"bleu_score": 44.534504264163466, "chrf_score": 72.30929030363313, "xcomet_score": 0.9994699954986572, "xcomet_qe_score": 1.0, "metricx_score": 0.20715543627738953, "metricx_qe_score": 0.3968292474746704, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "pt", "output": "Esta figura é tirada do artigo de Poon, onde realizam um prompting para resolver o problema de matemática em um cenário de aprendizado de curto prazo.", "metrics": {"bleu_score": 13.348189438082965, "chrf_score": 52.640869591812134, "xcomet_score": 0.5271360874176025, "xcomet_qe_score": 0.6004683971405029, "metricx_score": 9.474550247192383, "metricx_qe_score": 8.958809852600098, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "pt", "output": "Então, no lado netpade, podemos ver se, com alguns exemplos com apenas perguntas e respostas, não podemos obter as respostas corretas.", "metrics": {"bleu_score": 39.257190612723385, "chrf_score": 69.34764797233129, "xcomet_score": 0.7784178256988525, "xcomet_qe_score": 0.7909085750579834, "metricx_score": 14.779422760009766, "metricx_qe_score": 13.313460350036621, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "pt", "output": "Mas se darmos mais uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.", "metrics": {"bleu_score": 87.01761846085435, "chrf_score": 94.79440982602854, "xcomet_score": 0.9664279222488403, "xcomet_qe_score": 0.9900141954421997, "metricx_score": 1.6126751899719238, "metricx_qe_score": 3.840898036956787, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "pt", "output": "É bom ter raciocínio interpretável em múltiplos passos como saída.", "metrics": {"bleu_score": 46.92470064105599, "chrf_score": 76.484955972057, "xcomet_score": 0.9998137950897217, "xcomet_qe_score": 0.9987894296646118, "metricx_score": 1.6094605922698975, "metricx_qe_score": 3.1143970489501953, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "pt", "output": "E também pensamos que o problema de método é uma aplicação direta para avaliar essas habilidades de raciocínio.", "metrics": {"bleu_score": 35.27295712700594, "chrf_score": 67.6654115686099, "xcomet_score": 0.7832835912704468, "xcomet_qe_score": 0.7279528379440308, "metricx_score": 8.275745391845703, "metricx_qe_score": 6.791689395904541, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "pt", "output": "Então, aqui em nossa configuração de problema, dadas as perguntas, precisamos resolver essa questão e obter as respostas numéricas.", "metrics": {"bleu_score": 41.261520349079454, "chrf_score": 73.45219878319456, "xcomet_score": 0.9763007164001465, "xcomet_qe_score": 0.9717340469360352, "metricx_score": 1.033854603767395, "metricx_qe_score": 1.1593544483184814, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "pt", "output": "Então, em nossos conjuntos de dados, também nos é dado o expressão matemática, que leva a esta resposta particular.", "metrics": {"bleu_score": 32.236339479370045, "chrf_score": 69.48170114303092, "xcomet_score": 0.9048620462417603, "xcomet_qe_score": 0.8399805426597595, "metricx_score": 6.572474479675293, "metricx_qe_score": 7.044366836547852, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "pt", "output": "Assim, certas suposições também se aplicam, como em trabalhos anteriores.", "metrics": {"bleu_score": 50.08718428920986, "chrf_score": 80.91587664187756, "xcomet_score": 0.9975671768188477, "xcomet_qe_score": 0.9753861427307129, "metricx_score": 1.3570537567138672, "metricx_qe_score": 2.9195656776428223, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "pt", "output": "We assume the precision of quantities are known.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 27.042455634297152, "xcomet_score": 0.9659053087234497, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 23.222091674804688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "pt", "output": "E só consideramos operadores básicos como adição, subtração, multiplicação, divisão e exponencial.", "metrics": {"bleu_score": 82.05322216823978, "chrf_score": 91.36357658891524, "xcomet_score": 0.9957140684127808, "xcomet_qe_score": 0.9823132753372192, "metricx_score": 0.4500422477722168, "metricx_qe_score": 0.6373823881149292, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, operadores complicados podem ser realmente decompostos em esses operadores básicos.", "metrics": {"bleu_score": 53.33505353503043, "chrf_score": 88.5929957040936, "xcomet_score": 0.9899190068244934, "xcomet_qe_score": 0.9868741631507874, "metricx_score": 1.022294044494629, "metricx_qe_score": 1.3133829832077026, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, o trabalho anterior em resolução de problemas de métodos pode ser categorizado em modelo sequencia a sequencia e sequencia a árvore.", "metrics": {"bleu_score": 31.391131000259666, "chrf_score": 59.73387054615915, "xcomet_score": 0.5913852453231812, "xcomet_qe_score": 0.5917149186134338, "metricx_score": 10.824762344360352, "metricx_qe_score": 9.721325874328613, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "pt", "output": "Assim, o modelo de sequência tradicional converte a expressão em uma sequência específica para geração.", "metrics": {"bleu_score": 25.4561245937473, "chrf_score": 70.8691739313596, "xcomet_score": 0.9344044923782349, "xcomet_qe_score": 0.9149702787399292, "metricx_score": 5.137056350708008, "metricx_qe_score": 6.375702857971191, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "pt", "output": "E é bastante fácil de implementar, e pode ser generalizado para muitos problemas diferentes e complicados.", "metrics": {"bleu_score": 18.05263010472254, "chrf_score": 73.73487457787658, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5603755116462708, "metricx_qe_score": 0.6260263919830322, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "pt", "output": "Mas as desvantagens da performance são, em geral, não melhores do que o modelo estruturado. E é a falta de interpretabilidade para a previsão.", "metrics": {"bleu_score": 28.495577603220298, "chrf_score": 68.44682160548615, "xcomet_score": 0.8263097405433655, "xcomet_qe_score": 0.8242760896682739, "metricx_score": 9.781013488769531, "metricx_qe_score": 11.958487510681152, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "pt", "output": "Mas na verdade, esta direção ainda é bastante popular devido ao modelo transformador.", "metrics": {"bleu_score": 57.81682559080759, "chrf_score": 81.72026189983818, "xcomet_score": 0.9874167442321777, "xcomet_qe_score": 0.9529279470443726, "metricx_score": 2.908163070678711, "metricx_qe_score": 3.865170478820801, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "pt", "output": "Então, em modelos baseados em árvores, estruturamos essas expressões na forma de árvore e seguimos uma geração de árvores de travessia de ordem prévia.", "metrics": {"bleu_score": 47.14045207910318, "chrf_score": 72.90036967454579, "xcomet_score": 0.8094044923782349, "xcomet_qe_score": 0.7924171686172485, "metricx_score": 8.585700988769531, "metricx_qe_score": 8.585692405700684, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "pt", "output": "Então, aqui, continuamos gerando os operadores até chegarmos às folhas, que são as quantidades.", "metrics": {"bleu_score": 72.76817202342096, "chrf_score": 87.36202421983272, "xcomet_score": 0.975716233253479, "xcomet_qe_score": 0.947925329208374, "metricx_score": 2.983722448348999, "metricx_qe_score": 4.346708297729492, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "pt", "output": "Então, aqui, a coisa boa é que, na verdade, nos dá essa estrutura de árvore binária, e é, mas, mas, na verdade, é bastante contorna, porque primeiro geramos o operador, e, no final, geramos as quantidades.", "metrics": {"bleu_score": 36.99101120348658, "chrf_score": 66.73339069735633, "xcomet_score": 0.3085964024066925, "xcomet_qe_score": 0.3316586911678314, "metricx_score": 12.828756332397461, "metricx_qe_score": 14.553266525268555, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "pt", "output": "E a segunda coisa é que também contém algumas computações repetitivas.", "metrics": {"bleu_score": 63.15552371794033, "chrf_score": 74.054190222708, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2160042524337769, "metricx_qe_score": 0.9993234872817993, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "pt", "output": "Então, aqui, se olharmos essa expressão, 8 vezes 3 mais 3, é realmente gerada duas vezes. Mas, de fato, devemos reutilizar os resultados.", "metrics": {"bleu_score": 20.064835797942465, "chrf_score": 63.03257867056896, "xcomet_score": 0.9763424396514893, "xcomet_qe_score": 0.979658842086792, "metricx_score": 2.4531331062316895, "metricx_qe_score": 2.6391680240631104, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "pt", "output": "Então, em nosso método proposto, queremos resolver esses problemas de maneira passo a passo e interpretável.", "metrics": {"bleu_score": 21.951524426618455, "chrf_score": 61.233959367410016, "xcomet_score": 0.9988149404525757, "xcomet_qe_score": 1.0, "metricx_score": 1.1693063974380493, "metricx_qe_score": 2.0207457542419434, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "pt", "output": "Então, por exemplo, aqui no segundo passo, podemos obter este divisor, que é 27.", "metrics": {"bleu_score": 51.51630664996672, "chrf_score": 73.42992248823737, "xcomet_score": 0.9758400917053223, "xcomet_qe_score": 0.957056999206543, "metricx_score": 1.3269387483596802, "metricx_qe_score": 4.3979811668396, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "pt", "output": "Também podemos voltar às perguntas originais para encontrar os conteúdos relevantes.", "metrics": {"bleu_score": 49.185571326816614, "chrf_score": 79.34292290641459, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7231961488723755, "metricx_qe_score": 0.7088354825973511, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "pt", "output": "E em esses passos, obtemos os divisores.", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 75.23797114031095, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.826926350593567, "metricx_qe_score": 2.9055376052856445, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "pt", "output": "Então, e então, em este terceiro passo, realmente obtemos a razão.", "metrics": {"bleu_score": 6.250381527944883, "chrf_score": 42.82429825674404, "xcomet_score": 0.44472771883010864, "xcomet_qe_score": 0.7221245765686035, "metricx_score": 8.497234344482422, "metricx_qe_score": 12.562919616699219, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "pt", "output": "De acordo com o modelo de análise de dividendos de dividendos de dois anos, o modelo de análise de dividendos de dois anos é um modelo de análise de dividendos de dois anos que é baseado no modelo de análise de dividendos de dois anos.", "metrics": {"bleu_score": 1.022951633574269, "chrf_score": 19.7490248827412, "xcomet_score": 0.11667818576097488, "xcomet_qe_score": 0.12764883041381836, "metricx_score": 25.0, "metricx_qe_score": 24.29640769958496, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "pt", "output": "Então, aqui, geramos a expressão inteira diretamente, em vez de gerar um único operador ou quantidade.", "metrics": {"bleu_score": 46.84580982108429, "chrf_score": 79.74669617797345, "xcomet_score": 0.9990893602371216, "xcomet_qe_score": 0.9875572323799133, "metricx_score": 0.7796462774276733, "metricx_qe_score": 1.3038898706436157, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "pt", "output": "Então, isso torna o processo mais preciso.", "metrics": {"bleu_score": 58.73949094699213, "chrf_score": 86.3840484351613, "xcomet_score": 0.9882960319519043, "xcomet_qe_score": 0.9929900169372559, "metricx_score": 0.590175449848175, "metricx_qe_score": 0.5680171251296997, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "pt", "output": "Então, em nosso sistema dedutivo, começamos primeiro com um monte de quantidades apresentadas nas perguntas, e também incluímos algumas constantes como nossas iniciais.", "metrics": {"bleu_score": 23.837605956339917, "chrf_score": 74.2335817593814, "xcomet_score": 0.8502504825592041, "xcomet_qe_score": 0.8607805371284485, "metricx_score": 3.786184072494507, "metricx_qe_score": 3.218198776245117, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "pt", "output": "Então a expressão é representada por eiijop.", "metrics": {"bleu_score": 28.96204682801084, "chrf_score": 78.591780534505, "xcomet_score": 0.9644736051559448, "xcomet_qe_score": 0.9597381353378296, "metricx_score": 1.9784787893295288, "metricx_qe_score": 2.7923219203948975, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "pt", "output": "Onde realizamos o operador de qi a qj, e tal expressão é realmente direcionada.", "metrics": {"bleu_score": 53.46518078557699, "chrf_score": 90.51150355264684, "xcomet_score": 0.939848780632019, "xcomet_qe_score": 0.8907785415649414, "metricx_score": 4.299918174743652, "metricx_qe_score": 6.911802291870117, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "pt", "output": "Então, também temos subtração com palavras aqui para representar a direção oposta.", "metrics": {"bleu_score": 80.52253761904356, "chrf_score": 95.17440579501488, "xcomet_score": 0.9860293865203857, "xcomet_qe_score": 0.9631810188293457, "metricx_score": 0.677643358707428, "metricx_qe_score": 0.8231287002563477, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "pt", "output": "This is quite similar to relation extraction.", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 47.830487776191774, "xcomet_score": 0.9936637878417969, "xcomet_qe_score": 1.0, "metricx_score": 22.762929916381836, "metricx_qe_score": 19.445497512817383, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "pt", "output": "Então, em um sistema dedutivo formal, em um passo de tempo T, aplicamos o operador entre o par QI e QJ, e então obtemos essa nova expressão.", "metrics": {"bleu_score": 38.47661008080004, "chrf_score": 76.70987555378993, "xcomet_score": 0.9863594770431519, "xcomet_qe_score": 0.9891693592071533, "metricx_score": 1.5705488920211792, "metricx_qe_score": 2.0603744983673096, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "pt", "output": "Adicionamos ao estado seguinte para se tornar uma nova quantidade.", "metrics": {"bleu_score": 60.767958081376904, "chrf_score": 72.08034185872108, "xcomet_score": 0.9599635601043701, "xcomet_qe_score": 0.9656459093093872, "metricx_score": 2.1500492095947266, "metricx_qe_score": 3.8071796894073486, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "pt", "output": "Então, essas diapasadas realmente visualizam a evolução dos estados, onde continuamos adicionando expressões aos estados atuais.", "metrics": {"bleu_score": 4.814971807094068, "chrf_score": 51.35291886194573, "xcomet_score": 0.8428118824958801, "xcomet_qe_score": 0.8035240173339844, "metricx_score": 6.883808135986328, "metricx_qe_score": 6.816357135772705, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "pt", "output": "Então, em nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinado, que pode ser pássaros ou robôs, e depois codificamos uma frase, e depois obtemos essas representações de quantidade.", "metrics": {"bleu_score": 37.599623542143966, "chrf_score": 78.04907482260295, "xcomet_score": 0.6635259389877319, "xcomet_qe_score": 0.6774855852127075, "metricx_score": 8.954105377197266, "metricx_qe_score": 9.034008026123047, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "pt", "output": "Então, uma vez que temos as representações quantitativas, podemos começar a fazer inferências.", "metrics": {"bleu_score": 28.039501199940027, "chrf_score": 71.27755357052756, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5036510825157166, "metricx_qe_score": 0.4223857522010803, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, mostramos um exemplo de Q1 para obter a representação de Q1 dividido por Q2 e, em seguida, multiplicado por Q3.", "metrics": {"bleu_score": 18.510358976254352, "chrf_score": 57.542187881165084, "xcomet_score": 0.9046138525009155, "xcomet_qe_score": 0.9449076652526855, "metricx_score": 7.507149696350098, "metricx_qe_score": 7.143726825714111, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, obtemos a representação de pares, que é basicamente apenas a concatenação entre Q1 e Q2. E então aplicamos uma rede de pré-reforço, que é parametrizada pelo operador.", "metrics": {"bleu_score": 47.547123832819516, "chrf_score": 75.9384171958289, "xcomet_score": 0.8367481231689453, "xcomet_qe_score": 0.7896918058395386, "metricx_score": 5.025550842285156, "metricx_qe_score": 5.365521430969238, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "pt", "output": "E, finalmente, obtemos a representação do expressão Q1 dividido por Q2.", "metrics": {"bleu_score": 27.814503415066437, "chrf_score": 70.46977468773676, "xcomet_score": 0.8923783302307129, "xcomet_qe_score": 0.8833414912223816, "metricx_score": 4.331310272216797, "metricx_qe_score": 5.1388959884643555, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "pt", "output": "Mas em prática, na fase de inferência, podemos conseguir a expressão incorreta também.", "metrics": {"bleu_score": 36.39444945421111, "chrf_score": 63.28562743961067, "xcomet_score": 0.991024374961853, "xcomet_qe_score": 0.9788703918457031, "metricx_score": 2.5764825344085693, "metricx_qe_score": 3.109027862548828, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "pt", "output": "Então, aqui, todas as expressões possíveis são iguais a três vezes o número de operadores.", "metrics": {"bleu_score": 40.052744847255724, "chrf_score": 70.96589757373988, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.1995216608047485, "metricx_qe_score": 2.8229587078094482, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "pt", "output": "A coisa legal aqui é que podemos adicionar facilmente restrições para controlar a busca.", "metrics": {"bleu_score": 21.297466564773156, "chrf_score": 60.456025281250604, "xcomet_score": 0.9779516458511353, "xcomet_qe_score": 0.9763821363449097, "metricx_score": 1.337360143661499, "metricx_qe_score": 1.9244996309280396, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, se essa expressão não for permitida, podemos simplesmente remover essa expressão no nosso espaço de pesquisa.", "metrics": {"bleu_score": 72.42447986095323, "chrf_score": 93.11328569612097, "xcomet_score": 0.986616849899292, "xcomet_qe_score": 0.980976402759552, "metricx_score": 0.3765207529067993, "metricx_qe_score": 0.41664084792137146, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "pt", "output": "Então, no segundo passo, fazemos a mesma coisa, mas a única diferença é que, a única diferença é uma quantidade adicional.", "metrics": {"bleu_score": 76.42443661108386, "chrf_score": 88.79191919059555, "xcomet_score": 0.8532336950302124, "xcomet_qe_score": 0.5839369297027588, "metricx_score": 4.06707239151001, "metricx_qe_score": 6.884372234344482, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "pt", "output": "Esta quantidade vem da expressão calculada anteriormente.", "metrics": {"bleu_score": 42.13952948452608, "chrf_score": 81.79261054485458, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3632240891456604, "metricx_qe_score": 0.4377831816673279, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "pt", "output": "Finalmente, podemos obter esta expressão final, Q.", "metrics": {"bleu_score": 17.632778423526837, "chrf_score": 60.74117659544685, "xcomet_score": 0.7815165519714355, "xcomet_qe_score": 0.7828242778778076, "metricx_score": 10.3380765914917, "metricx_qe_score": 11.981094360351562, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "pt", "output": "Times q4. E também podemos ver que o número de todas as possíveis expressões é diferente do passo anterior.", "metrics": {"bleu_score": 67.73709971213142, "chrf_score": 91.63930481578237, "xcomet_score": 0.4365723431110382, "xcomet_qe_score": 0.3434738218784332, "metricx_score": 8.278495788574219, "metricx_qe_score": 11.88591194152832, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "pt", "output": "Assim, essa diferença torna difícil aplicar a busca de raios, porque a distribuição de probabilidade entre esses dois passos é desequilibrada.", "metrics": {"bleu_score": 44.903323241491265, "chrf_score": 79.27788060945396, "xcomet_score": 0.8289178609848022, "xcomet_qe_score": 0.8273473381996155, "metricx_score": 4.67650032043457, "metricx_qe_score": 5.084153652191162, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, o procedimento de treinamento é semelhante ao treinamento de um modelo sequencial a sequencial, onde otimizamos a perda em cada passo de tempo.", "metrics": {"bleu_score": 75.98033311259508, "chrf_score": 82.77607326428722, "xcomet_score": 0.7852444648742676, "xcomet_qe_score": 0.783219039440155, "metricx_score": 3.975586414337158, "metricx_qe_score": 4.683913707733154, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "pt", "output": "E aqui também usamos esta tau para representar quando devemos terminar este processo de geração.", "metrics": {"bleu_score": 61.28081331864041, "chrf_score": 86.0359313999412, "xcomet_score": 0.971021294593811, "xcomet_qe_score": 0.9812541007995605, "metricx_score": 3.555854082107544, "metricx_qe_score": 5.703188896179199, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "pt", "output": "E aqui o espaço é diferente de sequência para sequência, porque o espaço é diferente a cada passo, enquanto no modelo tradicional de sequência para sequência, é o número de vocabulário.", "metrics": {"bleu_score": 53.15165594498275, "chrf_score": 80.99682393962533, "xcomet_score": 0.5331077575683594, "xcomet_qe_score": 0.566870927810669, "metricx_score": 6.16536808013916, "metricx_qe_score": 8.599503517150879, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "pt", "output": "E também nos permite impor certas restrições a partir de conhecimento privo.", "metrics": {"bleu_score": 50.08718428920986, "chrf_score": 78.48359080120554, "xcomet_score": 0.911668062210083, "xcomet_qe_score": 0.9224790930747986, "metricx_score": 7.292863845825195, "metricx_qe_score": 6.16115665435791, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, conduzemos experimentos nos conjuntos de dados de problemas de método comumente usados, MAWPS, MAT23K, MATQA e SWEM.", "metrics": {"bleu_score": 23.278028502053264, "chrf_score": 50.69626109925331, "xcomet_score": 0.6970443725585938, "xcomet_qe_score": 0.7169890403747559, "metricx_score": 8.872941970825195, "metricx_qe_score": 8.64880657196045, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "pt", "output": "E aqui, brevemente, mostra os resultados comparados com os melhores métodos anteriores.", "metrics": {"bleu_score": 23.505204106959603, "chrf_score": 69.01643594608352, "xcomet_score": 0.8720139265060425, "xcomet_qe_score": 0.8613831996917725, "metricx_score": 5.161065578460693, "metricx_qe_score": 4.884740352630615, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "pt", "output": "Então, nossa variante de melhor desempenho é o Roberta Deductive Reasoner.", "metrics": {"bleu_score": 15.727800941615351, "chrf_score": 70.19984526910896, "xcomet_score": 0.9902234077453613, "xcomet_qe_score": 0.978940486907959, "metricx_score": 1.4937214851379395, "metricx_qe_score": 1.3822717666625977, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "pt", "output": "E, de fato, não usamos beam search em contraste com os métodos obvios que usam beam search.", "metrics": {"bleu_score": 24.536910395600046, "chrf_score": 45.82265130668221, "xcomet_score": 0.847213625907898, "xcomet_qe_score": 0.7204498052597046, "metricx_score": 6.528442859649658, "metricx_qe_score": 8.842671394348145, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "pt", "output": "Tudo bem, os melhores métodos são frequentemente modelos baseados em árvores.", "metrics": {"bleu_score": 3.554139148114267, "chrf_score": 38.25930171750652, "xcomet_score": 0.929956316947937, "xcomet_qe_score": 1.0, "metricx_score": 1.8647810220718384, "metricx_qe_score": 1.2884265184402466, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "pt", "output": "Então, no geral, nosso reasoner é capaz de superar significativamente este modelo baseado em árvores.", "metrics": {"bleu_score": 63.971593021393176, "chrf_score": 82.37098849940796, "xcomet_score": 0.8708544969558716, "xcomet_qe_score": 0.8466020822525024, "metricx_score": 5.433304786682129, "metricx_qe_score": 6.653103351593018, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "pt", "output": "Mas podemos ver que o número absoluto em MathQ or SWEM não é realmente alto.", "metrics": {"bleu_score": 16.94357181593088, "chrf_score": 47.39644168977095, "xcomet_score": 0.7788904309272766, "xcomet_qe_score": 0.7496991157531738, "metricx_score": 6.197251319885254, "metricx_qe_score": 6.802939414978027, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, investigue mais os resultados sobre.", "metrics": {"bleu_score": 18.190371142855746, "chrf_score": 51.54603091107133, "xcomet_score": 0.41334712505340576, "xcomet_qe_score": 0.48975467681884766, "metricx_score": 10.727540016174316, "metricx_qe_score": 5.681902885437012, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "pt", "output": "Swamp, and this dataset is challenging because the author tried to manually add something to confuse the NLP model, like adding irrelevant information and extra quantities.", "metrics": {"bleu_score": 1.8196871111910016, "chrf_score": 30.200288105814465, "xcomet_score": 0.7144616842269897, "xcomet_qe_score": 0.7816418409347534, "metricx_score": 17.769699096679688, "metricx_qe_score": 12.261800765991211, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "pt", "output": "Então, em nossa previsão, encontramos que alguns dos valores intermediários são, na verdade, negativos.", "metrics": {"bleu_score": 38.76199053423406, "chrf_score": 73.49928254605885, "xcomet_score": 0.9998573064804077, "xcomet_qe_score": 0.9990720748901367, "metricx_score": 0.7299519777297974, "metricx_qe_score": 0.7418978810310364, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, em esta pergunta, estamos perguntando, quantas maçãs Jake tem?", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 63.80259014715256, "xcomet_score": 0.9793205261230469, "xcomet_qe_score": 0.9770915508270264, "metricx_score": 3.3083677291870117, "metricx_qe_score": 1.7991926670074463, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "pt", "output": "Mas temos algumas informações adicionais, como 17 fewer pitches, e Steven tem 8 pitches, o que é totalmente relevante.", "metrics": {"bleu_score": 24.476045367213985, "chrf_score": 50.727237293892, "xcomet_score": 0.4304623305797577, "xcomet_qe_score": 0.5189857482910156, "metricx_score": 20.11351203918457, "metricx_qe_score": 17.94215965270996, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "pt", "output": "Então nosso modelo faz algumas previsões como esta, que está produzindo valores negativos.", "metrics": {"bleu_score": 20.68720601025941, "chrf_score": 72.73795915054984, "xcomet_score": 0.9606219530105591, "xcomet_qe_score": 0.9484703540802002, "metricx_score": 3.4321911334991455, "metricx_qe_score": 2.65610408782959, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "pt", "output": "E observamos essas duas expressões.", "metrics": {"bleu_score": 10.54969271144651, "chrf_score": 38.91694858388946, "xcomet_score": 0.6825231313705444, "xcomet_qe_score": 0.7838631272315979, "metricx_score": 21.325658798217773, "metricx_qe_score": 20.655824661254883, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "pt", "output": "Assim, podemos realmente limitar este espaço de busca removendo, por exemplo, aqueles resultados negativos, de modo que podemos fazer a resposta correta.", "metrics": {"bleu_score": 29.108736587772473, "chrf_score": 68.5831666541942, "xcomet_score": 0.8457573652267456, "xcomet_qe_score": 0.7960105538368225, "metricx_score": 3.6554770469665527, "metricx_qe_score": 5.0908660888671875, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "pt", "output": "Então, descobrimos que tal restrição realmente melhora bastante para alguns modelos.", "metrics": {"bleu_score": 30.57690288450511, "chrf_score": 65.61084879775869, "xcomet_score": 0.9829614162445068, "xcomet_qe_score": 0.9598069190979004, "metricx_score": 1.155534029006958, "metricx_qe_score": 1.8082225322723389, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, para pássaros, melhoramos 7 pontos. E então, para o modelo baseado em robô, realmente melhoramos 2 pontos.", "metrics": {"bleu_score": 23.71332024655201, "chrf_score": 52.652286598345576, "xcomet_score": 0.5453875660896301, "xcomet_qe_score": 0.5807509422302246, "metricx_score": 13.053383827209473, "metricx_qe_score": 13.454927444458008, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "pt", "output": "Um modelo de linguagem melhor tem uma melhor capacidade de compreensão de linguagem, de modo que o número aqui é maior para Roberta e menor para Bert.", "metrics": {"bleu_score": 23.089018317918462, "chrf_score": 59.73222750970415, "xcomet_score": 0.9862169027328491, "xcomet_qe_score": 0.9993590116500854, "metricx_score": 2.969398021697998, "metricx_qe_score": 3.066877603530884, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "pt", "output": "E também tentamos analisar a dificuldade por trás disso.", "metrics": {"bleu_score": 17.81815298791261, "chrf_score": 51.68029593717684, "xcomet_score": 0.7809211015701294, "xcomet_qe_score": 0.731676459312439, "metricx_score": 5.483124256134033, "metricx_qe_score": 8.861995697021484, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "pt", "output": "Assumimos que o número de quantidade não utilizada pode ser considerado como informação irrelevante aqui.", "metrics": {"bleu_score": 46.85909905380382, "chrf_score": 89.45201257998094, "xcomet_score": 0.9842791557312012, "xcomet_qe_score": 0.9826468229293823, "metricx_score": 2.9103333950042725, "metricx_qe_score": 4.226507186889648, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "pt", "output": "Então, aqui podemos ver que temos a porcentagem de amostras com quantidades não utilizadas, e o conjunto de dados swam tem a maior proporção.", "metrics": {"bleu_score": 72.16597075217096, "chrf_score": 88.46107200744613, "xcomet_score": 0.9268698692321777, "xcomet_qe_score": 0.9310526251792908, "metricx_score": 4.943591117858887, "metricx_qe_score": 5.559645175933838, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "pt", "output": "E aqui também mostramos o desempenho geral.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.41635861992836, "metricx_qe_score": 0.6433327794075012, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "pt", "output": "Para aqueles amostras sem quantidades não utilizadas. Portanto, o desempenho geral é, na verdade, mais alto do que o desempenho geral.", "metrics": {"bleu_score": 37.42657246981032, "chrf_score": 76.19445393519379, "xcomet_score": 0.6977682709693909, "xcomet_qe_score": 0.5342281460762024, "metricx_score": 7.114021301269531, "metricx_qe_score": 9.632875442504883, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "pt", "output": "Mas com essas amostras que com uma quantidade não usada, é realmente muito pior do que a.", "metrics": {"bleu_score": 40.4727200247809, "chrf_score": 61.17283045515814, "xcomet_score": 0.5213594436645508, "xcomet_qe_score": 0.43876922130584717, "metricx_score": 13.780667304992676, "metricx_qe_score": 16.437896728515625, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "pt", "output": "For M and WPS, we don't really have too many desk cases, so I just ignore this part.", "metrics": {"bleu_score": 2.3901021968803136, "chrf_score": 19.238976920558716, "xcomet_score": 0.6459341049194336, "xcomet_qe_score": 0.6832603216171265, "metricx_score": 16.415157318115234, "metricx_qe_score": 9.670188903808594, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "pt", "output": "Finalmente, queremos mostrar a interpretabilidade através de um exemplo de questionamento e participação.", "metrics": {"bleu_score": 71.66258375282708, "chrf_score": 77.67062368913635, "xcomet_score": 0.7819839715957642, "xcomet_qe_score": 0.7923377156257629, "metricx_score": 6.081202030181885, "metricx_qe_score": 6.566792011260986, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "pt", "output": "Então, aqui, nosso modelo faz uma previsão errada no primeiro passo.", "metrics": {"bleu_score": 47.492353188182214, "chrf_score": 73.84566871994727, "xcomet_score": 0.9909211993217468, "xcomet_qe_score": 0.9981876611709595, "metricx_score": 1.2797068357467651, "metricx_qe_score": 1.1068130731582642, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "pt", "output": "Então, podemos realmente correlacionar essa expressão com a frase aqui, certo?", "metrics": {"bleu_score": 30.576902884505124, "chrf_score": 81.92561254500306, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6281278133392334, "metricx_qe_score": 1.1106648445129395, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, pensamos que esta frase pode estar levando o modelo a uma previsão incorreta.", "metrics": {"bleu_score": 28.78787818101128, "chrf_score": 58.343176008178055, "xcomet_score": 0.9913800954818726, "xcomet_qe_score": 0.9789817333221436, "metricx_score": 1.1861481666564941, "metricx_qe_score": 1.637783169746399, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "pt", "output": "Então, aqui, plantando outro trinta e cinco faz com que o modelo pense que deveria ser um operador de adição.", "metrics": {"bleu_score": 43.937095446369234, "chrf_score": 76.48797396435441, "xcomet_score": 0.7436992526054382, "xcomet_qe_score": 0.6007601022720337, "metricx_score": 6.096229076385498, "metricx_qe_score": 7.1983160972595215, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "pt", "output": "Então tentamos revisar a frase para ser algo assim: o número de perales é 55 a menos do que o número de árvores de maçã.", "metrics": {"bleu_score": 23.386786214190362, "chrf_score": 56.44450547603845, "xcomet_score": 0.6961192488670349, "xcomet_qe_score": 0.8284440040588379, "metricx_score": 7.756455898284912, "metricx_qe_score": 6.6709394454956055, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "pt", "output": "Então, fazemos para transmitir uma semântica mais precisa, de modo que o modelo seja capaz de fazer a previsão correta.", "metrics": {"bleu_score": 76.06811142113595, "chrf_score": 87.55044961606664, "xcomet_score": 0.9043006896972656, "xcomet_qe_score": 0.8865375518798828, "metricx_score": 4.905638217926025, "metricx_qe_score": 3.736459255218506, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "pt", "output": "Então, este estudo mostra como as previsões interpretáveis nos ajudam a entender o comportamento do modelo.", "metrics": {"bleu_score": 77.7811122305422, "chrf_score": 84.80778424501784, "xcomet_score": 0.9894275665283203, "xcomet_qe_score": 1.0, "metricx_score": 0.7478823065757751, "metricx_qe_score": 0.8257451057434082, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "pt", "output": "Para concluir nosso trabalho, primeiro, nosso modelo é bastante eficiente.", "metrics": {"bleu_score": 29.629854440319527, "chrf_score": 63.995470490221805, "xcomet_score": 0.9880928993225098, "xcomet_qe_score": 0.9749346971511841, "metricx_score": 1.3787922859191895, "metricx_qe_score": 1.9802215099334717, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "pt", "output": "E somos capazes de fornecer um procedimento de resolução interpretável.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8213241100311279, "metricx_qe_score": 1.3524597883224487, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "pt", "output": "E podemos facilmente incorporar alguma conhecimento anterior como restrição, o que pode ajudar a melhorar o desempenho.", "metrics": {"bleu_score": 54.017258985951415, "chrf_score": 86.41874503140643, "xcomet_score": 0.909875750541687, "xcomet_qe_score": 0.9167779684066772, "metricx_score": 5.089694499969482, "metricx_qe_score": 5.9116692543029785, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "pt", "output": "E a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de mapas, mas também a outras tarefas que envolvem raciocínio multistage.", "metrics": {"bleu_score": 80.5169062877125, "chrf_score": 86.87578337769385, "xcomet_score": 0.7059643268585205, "xcomet_qe_score": 0.709134578704834, "metricx_score": 8.859771728515625, "metricx_qe_score": 8.991910934448242, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "pt", "output": "Mas também temos certas limitações.", "metrics": {"bleu_score": 50.81327481546149, "chrf_score": 93.8440976719106, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.04917246103286743, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "pt", "output": "Se tivermos um número maior de operadores ou constantes, o consumo de memória pode ser bastante alto.", "metrics": {"bleu_score": 80.26499775511908, "chrf_score": 87.33373298703955, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.4878699779510498, "metricx_qe_score": 1.3025422096252441, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "pt", "output": "E a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre, em diferentes estágios de tempo, então também é bastante desafiador aplicar a busca de raios.", "metrics": {"bleu_score": 66.23922210263933, "chrf_score": 81.90423342739834, "xcomet_score": 0.7133729457855225, "xcomet_qe_score": 0.7446533441543579, "metricx_score": 8.073575019836426, "metricx_qe_score": 9.847126007080078, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "pt", "output": "Então este é o fim da palestra e as perguntas são bem-vindas. Obrigado.", "metrics": {"bleu_score": 58.282339541526554, "chrf_score": 87.5323239869636, "xcomet_score": 0.9889541864395142, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3190849721431732, "metricx_qe_score": 0.3113645911216736, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "pt", "output": "\"Hello, my name is Antoine and I am from Maastricht University.\"", "metrics": {"bleu_score": 3.716499092256817, "chrf_score": 40.50179974358982, "xcomet_score": 0.9045096635818481, "xcomet_qe_score": 0.9979509115219116, "metricx_score": 13.730253219604492, "metricx_qe_score": 15.477405548095703, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "pt", "output": "Eu apresentarei meu trabalho conjunto com Jerry, que trata de um novo conjunto de dados para a recuperação de artigos estatutários.", "metrics": {"bleu_score": 39.02273664485568, "chrf_score": 79.93258385257016, "xcomet_score": 0.9650884866714478, "xcomet_qe_score": 0.8233826160430908, "metricx_score": 2.4057135581970215, "metricx_qe_score": 1.690787434577942, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "pt", "output": "Problemas legais são uma parte integrante da vida de muitas pessoas.", "metrics": {"bleu_score": 67.0422683816333, "chrf_score": 80.78641029434735, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.274706244468689, "metricx_qe_score": 1.7093849182128906, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "pt", "output": "Mas a maioria dos cidadãos tem pouco ou nenhum conhecimento sobre seus direitos e processos legais fundamentais.", "metrics": {"bleu_score": 69.12804407652906, "chrf_score": 91.83235261309986, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.581822395324707, "metricx_qe_score": 0.5356807708740234, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "pt", "output": "Como resultado, muitos cidadãos vulneráveis que não podem se dar conta do custo da assistência de um especialista jurídico são deixados indefesos ou, pior, abusados.", "metrics": {"bleu_score": 52.61352166307949, "chrf_score": 74.46393893869727, "xcomet_score": 0.9988657236099243, "xcomet_qe_score": 1.0, "metricx_score": 1.6129063367843628, "metricx_qe_score": 0.8999902009963989, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "pt", "output": "Our work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "metrics": {"bleu_score": 1.4400778827658958, "chrf_score": 18.036187605438784, "xcomet_score": 0.9462630748748779, "xcomet_qe_score": 0.9888740181922913, "metricx_score": 25.0, "metricx_qe_score": 24.902555465698242, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "pt", "output": "Um sistema assim poderia fornecer um serviço gratuito de assistência jurídica profissional para humanos sem habilidades.", "metrics": {"bleu_score": 21.409092659758045, "chrf_score": 65.52941776836317, "xcomet_score": 0.9867861270904541, "xcomet_qe_score": 0.985854983329773, "metricx_score": 2.314394474029541, "metricx_qe_score": 2.503840923309326, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "pt", "output": "Antes de mergulhar no principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos de fato.", "metrics": {"bleu_score": 72.00391346486707, "chrf_score": 87.5555249447315, "xcomet_score": 0.749108612537384, "xcomet_qe_score": 0.7522075176239014, "metricx_score": 8.139511108398438, "metricx_qe_score": 8.735837936401367, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "pt", "output": "Dada uma simples pergunta sobre uma questão legal, como, o que risco se violar a confidencialidade profissional?", "metrics": {"bleu_score": 68.8836505346656, "chrf_score": 82.54471276038483, "xcomet_score": 0.9372310638427734, "xcomet_qe_score": 0.923923134803772, "metricx_score": 5.903292655944824, "metricx_qe_score": 8.397216796875, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "pt", "output": "Um modelo é necessário para recuperar todos os artigos relevantes do corpo legislativo.", "metrics": {"bleu_score": 48.09884672898114, "chrf_score": 68.91615472687484, "xcomet_score": 0.9213098287582397, "xcomet_qe_score": 0.919784426689148, "metricx_score": 5.16763973236084, "metricx_qe_score": 4.405301094055176, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "pt", "output": "This information retrieval task comes with its own set of challenges.", "metrics": {"bleu_score": 2.6374077368969155, "chrf_score": 18.00564246171691, "xcomet_score": 0.9759777784347534, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, trata de dois tipos de linguagem.", "metrics": {"bleu_score": 51.33450480401705, "chrf_score": 73.05081341846048, "xcomet_score": 0.9732328653335571, "xcomet_qe_score": 0.96952223777771, "metricx_score": 2.362800121307373, "metricx_qe_score": 4.144604682922363, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "pt", "output": "Common natural language for the questions and complex legal language for the statutes.", "metrics": {"bleu_score": 3.377156414337854, "chrf_score": 32.81467962947142, "xcomet_score": 0.9471502304077148, "xcomet_qe_score": 0.9883500337600708, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "pt", "output": "Esta diferença nas distribuições linguísticas torna mais difícil para um sistema recuperar os candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia das normas.", "metrics": {"bleu_score": 79.86879970944234, "chrf_score": 90.61371009551367, "xcomet_score": 0.9594302177429199, "xcomet_qe_score": 0.8541291952133179, "metricx_score": 4.176257610321045, "metricx_qe_score": 4.412862300872803, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informação sozinha, como notícias ou receitas, por exemplo.", "metrics": {"bleu_score": 73.5122547996473, "chrf_score": 82.43805278774701, "xcomet_score": 0.9010223150253296, "xcomet_qe_score": 0.9610862731933594, "metricx_score": 3.347116470336914, "metricx_qe_score": 4.535945892333984, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "pt", "output": "Em vez disso, é uma coleção estruturada de disposições legais que têm um significado completo apenas quando consideradas no contexto geral, que é junto com as informações suplementares dos artigos adjacentes, os campos e subcampos a que pertencem e seu lugar na estrutura da lei.", "metrics": {"bleu_score": 67.33127821688049, "chrf_score": 83.32265313398197, "xcomet_score": 0.9906585216522217, "xcomet_qe_score": 0.9744534492492676, "metricx_score": 1.1964155435562134, "metricx_qe_score": 1.4534759521484375, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "pt", "output": "Por fim, os artigos de lei são em um pequeno parágrafo, que geralmente é a unidade de recuperação típica em a maioria dos trabalhos de recuperação.", "metrics": {"bleu_score": 36.75234456178971, "chrf_score": 70.35867433865332, "xcomet_score": 0.4365423321723938, "xcomet_qe_score": 0.514252781867981, "metricx_score": 15.574715614318848, "metricx_qe_score": 16.012889862060547, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, há documentos longos que podem ser até seis.", "metrics": {"bleu_score": 50.66546237581824, "chrf_score": 63.563687603521856, "xcomet_score": 0.7361000180244446, "xcomet_qe_score": 0.7324994206428528, "metricx_score": 18.334260940551758, "metricx_qe_score": 17.73529624938965, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "pt", "output": "Os avanços recentes em NLP despertaram um grande interesse em muitas tarefas legais, como previsão de julgamento jurídico ou revisão automática de contratos.", "metrics": {"bleu_score": 55.726418290435326, "chrf_score": 77.53489767701709, "xcomet_score": 0.9619443416595459, "xcomet_qe_score": 0.9597142934799194, "metricx_score": 1.5992783308029175, "metricx_qe_score": 2.2932724952697754, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "pt", "output": "Mas a recuperação de artigos estatutários permaneceu principalmente intocada devido à falta de grandes e de alta qualidade conjuntos de dados rotulados.", "metrics": {"bleu_score": 58.12331394080078, "chrf_score": 88.87625796655797, "xcomet_score": 0.8741812705993652, "xcomet_qe_score": 0.6833078265190125, "metricx_score": 6.7729363441467285, "metricx_qe_score": 7.616933822631836, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "pt", "output": "Em este trabalho, apresentamos um novo conjunto de dados nativo francês, centrado no cidadão, para estudar se um modelo de recuperação pode aproximar a eficiência e a confiabilidade de um especialista jurídico para a tarefa de recuperação de artigos legais.", "metrics": {"bleu_score": 48.14384742148604, "chrf_score": 81.84333784777141, "xcomet_score": 0.8181774616241455, "xcomet_qe_score": 0.7302328944206238, "metricx_score": 4.8205671310424805, "metricx_qe_score": 5.229121208190918, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "pt", "output": "Our Belgian statutory article retrieval data set, psad, consists of more than one thousand one hundred articles.", "metrics": {"bleu_score": 1.4183728388959305, "chrf_score": 20.842450537889302, "xcomet_score": 0.2867651581764221, "xcomet_qe_score": 0.6981141567230225, "metricx_score": 20.57439613342285, "metricx_qe_score": 15.594711303710938, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "pt", "output": "Essas perguntas cobrem uma ampla gama de tópicos, desde família, moradia, dinheiro até trabalho e segurança social.", "metrics": {"bleu_score": 59.231361574877134, "chrf_score": 75.17522576544322, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.41875869035720825, "metricx_qe_score": 0.37427741289138794, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "pt", "output": "Cada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus de mais de vinte e dois mil.", "metrics": {"bleu_score": 58.926000789698605, "chrf_score": 66.06731648722958, "xcomet_score": 0.6055519580841064, "xcomet_qe_score": 0.6754902005195618, "metricx_score": 11.816015243530273, "metricx_qe_score": 13.171513557434082, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "pt", "output": "Belgians codes of law. Vamos agora falar sobre como coletamos esses conjuntos de dados.", "metrics": {"bleu_score": 30.62049088236489, "chrf_score": 66.228475290778, "xcomet_score": 0.18629272282123566, "xcomet_qe_score": 0.1781584471464157, "metricx_score": 14.251297950744629, "metricx_qe_score": 20.503490447998047, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, começamos compilando um grande corpus de artigos legais.", "metrics": {"bleu_score": 17.676084425360003, "chrf_score": 53.97694690841599, "xcomet_score": 0.9785085916519165, "xcomet_qe_score": 0.9779907464981079, "metricx_score": 2.3899662494659424, "metricx_qe_score": 1.4362233877182007, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "pt", "output": "Consideramos trinta e dois códigos belgas disponíveis publicamente e extraiu todos os seus artigos, bem como os títulos das seções correspondentes.", "metrics": {"bleu_score": 47.63696334812462, "chrf_score": 82.32179714472441, "xcomet_score": 0.8652658462524414, "xcomet_qe_score": 0.9042865633964539, "metricx_score": 4.770867347717285, "metricx_qe_score": 4.726150035858154, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "pt", "output": "Então reunimos questões legais com referências a estatutos relevantes.", "metrics": {"bleu_score": 54.088044192555245, "chrf_score": 71.89249262212621, "xcomet_score": 0.9999922513961792, "xcomet_qe_score": 0.9999490976333618, "metricx_score": 0.8636595010757446, "metricx_qe_score": 1.5796284675598145, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "pt", "output": "Para fazer isso, nos associamos a uma firma de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos sobre um problema legal pessoal.", "metrics": {"bleu_score": 56.33744897929836, "chrf_score": 68.71899463397236, "xcomet_score": 0.9952175617218018, "xcomet_qe_score": 1.0, "metricx_score": 1.5427879095077515, "metricx_qe_score": 1.2643921375274658, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "pt", "output": "Fomos sorteados o suficiente para ter acesso aos seus sites, onde seu time de juristas experientes aborda os problemas legais mais comuns da Bélgica.", "metrics": {"bleu_score": 34.185025753461275, "chrf_score": 59.40057199781602, "xcomet_score": 0.8625988960266113, "xcomet_qe_score": 0.7723038196563721, "metricx_score": 6.988302707672119, "metricx_qe_score": 7.300485610961914, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "pt", "output": "Recopilamos milhares de perguntas, anotadas com categorias, subcategorias e referências legais a estatutos relevantes.", "metrics": {"bleu_score": 76.24658586234858, "chrf_score": 91.94577835030266, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.124951720237732, "metricx_qe_score": 1.6935982704162598, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "pt", "output": "Por fim, passamos pelas referências legais e filtramos as perguntas cujas referências não eram artigos em um dos códigos de lei que consideramos.", "metrics": {"bleu_score": 57.15586618084643, "chrf_score": 82.61372685762889, "xcomet_score": 0.9771906137466431, "xcomet_qe_score": 0.9715983867645264, "metricx_score": 2.2524831295013428, "metricx_qe_score": 3.1136951446533203, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "pt", "output": "The remaining references were matched and converted to the corresponding article IDs from all corpus.", "metrics": {"bleu_score": 2.5665813713132626, "chrf_score": 27.35234948957979, "xcomet_score": 0.7141739130020142, "xcomet_qe_score": 0.922261118888855, "metricx_score": 24.01488494873047, "metricx_qe_score": 11.065885543823242, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "pt", "output": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from the", "metrics": {"bleu_score": 0.9320049380462183, "chrf_score": 17.325725101731802, "xcomet_score": 0.5093488097190857, "xcomet_qe_score": 0.6939552426338196, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, cada pergunta vem com uma categoria principal e uma concatenação de subcategorias.", "metrics": {"bleu_score": 81.53551038173119, "chrf_score": 97.26877318350053, "xcomet_score": 0.997773289680481, "xcomet_qe_score": 0.9875147342681885, "metricx_score": 1.2583645582199097, "metricx_qe_score": 1.7294353246688843, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "pt", "output": "E cada artigo vem com a concatenação de sua subsequência, cabeçear na estrutura do lob.", "metrics": {"bleu_score": 28.175950490399515, "chrf_score": 70.59450066644263, "xcomet_score": 0.5391174554824829, "xcomet_qe_score": 0.6164566278457642, "metricx_score": 15.188798904418945, "metricx_qe_score": 15.769732475280762, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "pt", "output": "Esta informação extra não é usada no trabalho atual, mas pode ser de interesse para pesquisas futuras sobre recuperação de informações legais ou classificação de textos legais.", "metrics": {"bleu_score": 50.42864848737683, "chrf_score": 79.29951783568828, "xcomet_score": 0.9891844987869263, "xcomet_qe_score": 0.9762880802154541, "metricx_score": 0.9720110893249512, "metricx_qe_score": 1.0243628025054932, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos ver algumas características de nossos dados.", "metrics": {"bleu_score": 14.575161396875705, "chrf_score": 59.716900176500445, "xcomet_score": 0.9988954067230225, "xcomet_qe_score": 1.0, "metricx_score": 0.21895992755889893, "metricx_qe_score": 0.13472780585289001, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "pt", "output": "The questions are between five and forty four words long, with a median of forty words.", "metrics": {"bleu_score": 2.031628835361819, "chrf_score": 15.668259343364666, "xcomet_score": 0.704032301902771, "xcomet_qe_score": 0.8519039154052734, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "pt", "output": "The articles are much longer, with a median length of seventy-seven words, with one hundred and forty.", "metrics": {"bleu_score": 1.6066694932016616, "chrf_score": 15.013832699650042, "xcomet_score": 0.6755885481834412, "xcomet_qe_score": 0.771511435508728, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "pt", "output": "Two of them exceeding one.", "metrics": {"bleu_score": 2.9859662827819125, "chrf_score": 8.245825888807898, "xcomet_score": 0.14086245000362396, "xcomet_qe_score": 0.14847300946712494, "metricx_score": 25.0, "metricx_qe_score": 21.605627059936523, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "pt", "output": "Como mencionado anteriormente, a questão cobre uma ampla gama de tópicos, com cerca de 85% deles sendo sobre família, moradia, dinheiro ou justiça.", "metrics": {"bleu_score": 53.77631568462311, "chrf_score": 66.76832868999543, "xcomet_score": 0.9386926889419556, "xcomet_qe_score": 0.8865526914596558, "metricx_score": 4.187580585479736, "metricx_qe_score": 3.5254788398742676, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "pt", "output": "While the remaining fifteen percent concern either social security, foreigners, or work.", "metrics": {"bleu_score": 3.235537081118379, "chrf_score": 18.973989319136923, "xcomet_score": 0.9953683614730835, "xcomet_qe_score": 0.9810539484024048, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "pt", "output": "Os artigos também são muito diversos, pois vêm de trinta e dois códigos belgas diferentes que cobrem uma grande quantidade de tópicos legais.", "metrics": {"bleu_score": 56.942991472909284, "chrf_score": 76.19933213213366, "xcomet_score": 0.9792604446411133, "xcomet_qe_score": 0.9947538375854492, "metricx_score": 0.9762474298477173, "metricx_qe_score": 0.7021613121032715, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui está o número total de artigos coletados de cada um desses códigos belgas.", "metrics": {"bleu_score": 57.73502691896262, "chrf_score": 81.94928467911937, "xcomet_score": 0.9947435855865479, "xcomet_qe_score": 1.0, "metricx_score": 3.12457275390625, "metricx_qe_score": 4.193922996520996, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "pt", "output": "Out of the 22,633 articles, only 1,612 are referred to as relevant to at least one of the following three categories.", "metrics": {"bleu_score": 1.382940844142473, "chrf_score": 17.32114458615684, "xcomet_score": 0.23346064984798431, "xcomet_qe_score": 0.6432902812957764, "metricx_score": 15.092880249023438, "metricx_qe_score": 4.459962368011475, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "pt", "output": "\"One question in the data sets. And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes, or penal codes.\"", "metrics": {"bleu_score": 1.5790460212418518, "chrf_score": 32.58811145275185, "xcomet_score": 0.20181860029697418, "xcomet_qe_score": 0.47507548332214355, "metricx_score": 21.827106475830078, "metricx_qe_score": 18.52299690246582, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "pt", "output": "Enquanto isso, 18 dos 32 códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.", "metrics": {"bleu_score": 70.20458686590516, "chrf_score": 81.66302018826508, "xcomet_score": 0.9474256038665771, "xcomet_qe_score": 0.9042794704437256, "metricx_score": 1.3500549793243408, "metricx_qe_score": 1.8413476943969727, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "pt", "output": "O que não pode ser explicado pelo fato de esses códigos se concentram menos em indivíduos e suas preocupações.", "metrics": {"bleu_score": 35.45395860354175, "chrf_score": 81.50295825540302, "xcomet_score": 0.6186538934707642, "xcomet_qe_score": 0.6430771946907043, "metricx_score": 18.39736557006836, "metricx_qe_score": 17.20789337158203, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "pt", "output": "Em geral, o número médio de citações para esses artigos citados é 2, e menos de 25% deles são", "metrics": {"bleu_score": 21.02134513910948, "chrf_score": 48.466265486899154, "xcomet_score": 0.6841435432434082, "xcomet_qe_score": 0.7350085973739624, "metricx_score": 13.218677520751953, "metricx_qe_score": 9.605931282043457, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "pt", "output": "Usando nossos conjuntos de dados, avaliamos várias abordagens de recuperação, incluindo a arquitetura lexical e densa.", "metrics": {"bleu_score": 57.77966168512882, "chrf_score": 83.15453945084104, "xcomet_score": 0.8754749298095703, "xcomet_qe_score": 0.8676881790161133, "metricx_score": 1.4926402568817139, "metricx_qe_score": 2.7467215061187744, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "pt", "output": "Dada uma consulta em um artigo, um modelo léxico atribui uma pontuação ao par consulta-artigo calculando a soma, sobre os termos da consulta, das pesos de cada um desses termos em esse artigo.", "metrics": {"bleu_score": 42.34426103854124, "chrf_score": 77.57730821210286, "xcomet_score": 0.7807706594467163, "xcomet_qe_score": 0.6764029860496521, "metricx_score": 4.41613245010376, "metricx_qe_score": 4.428443908691406, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "pt", "output": "Experimentamos com as funções padrão de classificação tfidf e bm25.", "metrics": {"bleu_score": 12.605968092174914, "chrf_score": 64.2238283247737, "xcomet_score": 0.9189896583557129, "xcomet_qe_score": 0.9190987348556519, "metricx_score": 2.795799970626831, "metricx_qe_score": 4.730412483215332, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "pt", "output": "O principal problema com esses abordagens é que eles podem recuperar apenas artigos que contenham palavras-chave presentes na consulta.", "metrics": {"bleu_score": 56.600498033020344, "chrf_score": 89.33727115519244, "xcomet_score": 0.9286127090454102, "xcomet_qe_score": 0.9285792708396912, "metricx_score": 2.781106948852539, "metricx_qe_score": 2.9048895835876465, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "pt", "output": "Para superar essa limitação, experimentamos com uma arquitetura baseada em neurais que pode capturar a relação semântica entre consultas e artigos.", "metrics": {"bleu_score": 16.76784955078518, "chrf_score": 73.03150671972139, "xcomet_score": 0.8560665845870972, "xcomet_qe_score": 0.8844177722930908, "metricx_score": 0.7846412658691406, "metricx_qe_score": 0.9946703910827637, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "pt", "output": "Usamos um modelo de b-encoder que mapeia consultas e artigos em representações de vetor denso e calcula uma pontuação relevante entre um par de consulta-artigo com base na semelhança de suas inserções.", "metrics": {"bleu_score": 44.016336953294186, "chrf_score": 67.0355345900076, "xcomet_score": 0.754452109336853, "xcomet_qe_score": 0.7847148180007935, "metricx_score": 6.959375381469727, "metricx_qe_score": 5.942663192749023, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "pt", "output": "Essas inbeding geralmente resultam de uma operação de pooling no output de um modelo de inbeding de palavras.", "metrics": {"bleu_score": 38.021155610492436, "chrf_score": 54.61120813735846, "xcomet_score": 0.4750401973724365, "xcomet_qe_score": 0.6159123182296753, "metricx_score": 15.18682861328125, "metricx_qe_score": 14.723040580749512, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, estudamos a eficácia dos b-encoders siameses em uma configuração de avaliação de zero shots, o que significa que os modelos de embebimento de palavras pré-treinados são aplicados \"out of the box\" sem qualquer ajuste fino adicional.", "metrics": {"bleu_score": 34.17708221260824, "chrf_score": 70.37602785030899, "xcomet_score": 0.6111879348754883, "xcomet_qe_score": 0.6215368509292603, "metricx_score": 9.203608512878418, "metricx_qe_score": 8.410590171813965, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "pt", "output": "Experimentamos com um codificador de texto independente do contexto, nomeadamente word2vec e fastText, e com modelos de embebimento dependentes do contexto, nomeadamente Roberta e, mais especificamente, Camembert, que é um modelo de Roberta francês.", "metrics": {"bleu_score": 29.30295974039088, "chrf_score": 69.0381888887426, "xcomet_score": 0.8323274850845337, "xcomet_qe_score": 0.9059075117111206, "metricx_score": 3.2875277996063232, "metricx_qe_score": 3.631744384765625, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, treinamos nosso próprio modelo baseado em camundogos além de codor.", "metrics": {"bleu_score": 27.091430531233918, "chrf_score": 45.21276533406387, "xcomet_score": 0.34527498483657837, "xcomet_qe_score": 0.49425914883613586, "metricx_score": 16.034847259521484, "metricx_qe_score": 15.488052368164062, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "pt", "output": "Em todos os conjuntos de dados. Observe que, para o treinamento, experimentamos com os dois sabores da arquitetura Biancardi.", "metrics": {"bleu_score": 24.192619393259797, "chrf_score": 70.50124207580795, "xcomet_score": 0.4560932517051697, "xcomet_qe_score": 0.27420660853385925, "metricx_score": 17.756555557250977, "metricx_qe_score": 20.012781143188477, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "pt", "output": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and Tutoar, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "metrics": {"bleu_score": 1.041809200915957, "chrf_score": 26.305669669316924, "xcomet_score": 0.611770749092102, "xcomet_qe_score": 0.6648546457290649, "metricx_score": 25.0, "metricx_qe_score": 23.134864807128906, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "pt", "output": "Experimentamos com mean, max e pooling de classe média, bem como produto ponto e coseno para o cálculo de semelhanças.", "metrics": {"bleu_score": 13.566979610140004, "chrf_score": 55.137637713900425, "xcomet_score": 0.5265212059020996, "xcomet_qe_score": 0.5073664784431458, "metricx_score": 11.500748634338379, "metricx_qe_score": 10.141119003295898, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui estão os resultados de uma linha de base no conjunto de testes.", "metrics": {"bleu_score": 12.571192676522521, "chrf_score": 64.52647279413836, "xcomet_score": 0.7966459393501282, "xcomet_qe_score": 0.7548183798789978, "metricx_score": 5.584351062774658, "metricx_qe_score": 6.847614765167236, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "pt", "output": "Com os métodos lexicais acima, os encoders de voz siameses avaliados em uma configuração de zero struts no meio, e os encoders de voz finamente ajustados abaixo.", "metrics": {"bleu_score": 27.8556652304797, "chrf_score": 59.687052791833494, "xcomet_score": 0.6387406587600708, "xcomet_qe_score": 0.5294767022132874, "metricx_score": 12.545738220214844, "metricx_qe_score": 11.234786987304688, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "pt", "output": "No geral, o encodificador de vídeo finamente ajustado superou significativamente todas as outras linhas de base.", "metrics": {"bleu_score": 42.08598069524091, "chrf_score": 73.61246874225694, "xcomet_score": 0.8326661586761475, "xcomet_qe_score": 0.8197699785232544, "metricx_score": 6.1884074211120605, "metricx_qe_score": 6.032430648803711, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "pt", "output": "O modelo de duas torres melhora em relação à sua variante sijs em recall a cem, mas se comporta de forma semelhante em outras métricas.", "metrics": {"bleu_score": 35.955975361320206, "chrf_score": 61.05547350074839, "xcomet_score": 0.6830139756202698, "xcomet_qe_score": 0.6582247018814087, "metricx_score": 10.886809349060059, "metricx_qe_score": 11.55758285522461, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "pt", "output": "Embora bm twenty five tenha superado significativamente o treinamento além do código, seu desempenho indica que ainda é uma base sólida para a recuperação específica do domínio.", "metrics": {"bleu_score": 12.402443039753676, "chrf_score": 53.42056731048348, "xcomet_score": 0.48476099967956543, "xcomet_qe_score": 0.4233700633049011, "metricx_score": 14.098654747009277, "metricx_qe_score": 13.900395393371582, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "pt", "output": "Referindo-se à avaliação zero-shot do b-encoder siamês, descobrimos que o uso direto das inbedingas de um modelo camembert pré-treinado, sem otimizar para a tarefa de recuperação de informações, dá resultados ruins, o que é consistente com os achados anteriores.", "metrics": {"bleu_score": 35.557332599118304, "chrf_score": 64.55660019256196, "xcomet_score": 0.5262286067008972, "xcomet_qe_score": 0.41225844621658325, "metricx_score": 7.260002613067627, "metricx_qe_score": 5.711427688598633, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, observamos que o b-encoder baseado em word2vec superou significativamente o modelo FastText e baseado em bird, sugerindo que talvez as embeddings pré-treinadas a nível de palavra sejam mais apropriadas para a tarefa do que as embeddings a nível de caractere ou sub-para-para a tarefa, quando usadas \"out of the box\".", "metrics": {"bleu_score": 32.02461934437287, "chrf_score": 65.19924937744445, "xcomet_score": 0.28717926144599915, "xcomet_qe_score": 0.34778180718421936, "metricx_score": 14.717181205749512, "metricx_qe_score": 12.729652404785156, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "pt", "output": "Embora promissor, esses resultados sugerem uma ampla oportunidade para melhoria, em comparação com um especialista em direito que eventualmente pode recuperar todos os artigos relevantes para qualquer pergunta e, portanto, obter pontuações perfeitas.", "metrics": {"bleu_score": 52.94735130008154, "chrf_score": 80.2739646328747, "xcomet_score": 0.9552197456359863, "xcomet_qe_score": 0.9397810101509094, "metricx_score": 2.80031156539917, "metricx_qe_score": 3.961549758911133, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos concluir discutindo duas limitações de todos os conjuntos de dados.", "metrics": {"bleu_score": 42.40125351805035, "chrf_score": 82.62222853052793, "xcomet_score": 0.9203286170959473, "xcomet_qe_score": 0.9104638695716858, "metricx_score": 3.1502742767333984, "metricx_qe_score": 2.1483187675476074, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, o corpus do artigo é limitado a aqueles coletados dos trinta e dois códigos belgas considerados, o que não cobre a lei belga inteira, pois artigos de decretos, diretrizes e ordenanças estão ausentes.", "metrics": {"bleu_score": 35.9552710499818, "chrf_score": 55.264490732120066, "xcomet_score": 0.8318943977355957, "xcomet_qe_score": 0.8517859578132629, "metricx_score": 4.802610397338867, "metricx_qe_score": 4.214374542236328, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "pt", "output": "Durante a construção do set de dados, todas as referências a esses artigos não coletados são ignoradas, o que leva a algumas perguntas para terminar com apenas uma fração do número inicial de artigos relevantes.", "metrics": {"bleu_score": 59.422055984211894, "chrf_score": 77.86875452890834, "xcomet_score": 0.8386173248291016, "xcomet_qe_score": 0.9007619619369507, "metricx_score": 5.129966735839844, "metricx_qe_score": 4.934425354003906, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "pt", "output": "Esta perda de informação implica que a resposta contenha em seus artigos relevantes restantes pode ser incompleta, embora ainda seja completamente apropriada.", "metrics": {"bleu_score": 35.226537869293814, "chrf_score": 77.9508136487543, "xcomet_score": 0.9556927680969238, "xcomet_qe_score": 0.9250259399414062, "metricx_score": 8.364707946777344, "metricx_qe_score": 7.960832595825195, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "pt", "output": "Em segundo lugar, devemos notar que não todas as questões legais podem ser respondidas apenas com estatutos.", "metrics": {"bleu_score": 51.247766029654905, "chrf_score": 73.70421934394386, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.9781943559646606, "metricx_qe_score": 1.3900325298309326, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, a questão, posso expulso meus inquilinos se eles fazem muito barulho?", "metrics": {"bleu_score": 30.62049088236489, "chrf_score": 59.72807735831994, "xcomet_score": 0.8956910371780396, "xcomet_qe_score": 0.9036426544189453, "metricx_score": 4.221639156341553, "metricx_qe_score": 3.7554311752319336, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "pt", "output": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "metrics": {"bleu_score": 1.702120131325744, "chrf_score": 21.467340380191498, "xcomet_score": 0.8600516319274902, "xcomet_qe_score": 0.9681105613708496, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "pt", "output": "Em vez disso, o devedor deve provavelmente confiar mais no caso law e encontrar precedentes semelhantes à situação atual.", "metrics": {"bleu_score": 43.694931249512024, "chrf_score": 68.00216344330642, "xcomet_score": 0.6902186870574951, "xcomet_qe_score": 0.6881977319717407, "metricx_score": 9.241290092468262, "metricx_qe_score": 10.137624740600586, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "pt", "output": "For example, the tenant makes two parties a week until two August.", "metrics": {"bleu_score": 2.9275822595890535, "chrf_score": 14.839140720319211, "xcomet_score": 0.5542020797729492, "xcomet_qe_score": 0.7953659296035767, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos legais, e o domínio das menos adequadas ainda precisa ser determinado.", "metrics": {"bleu_score": 70.53391703706568, "chrf_score": 76.08286655932338, "xcomet_score": 0.9748128652572632, "xcomet_qe_score": 0.8724913597106934, "metricx_score": 2.4585094451904297, "metricx_qe_score": 3.467350721359253, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "pt", "output": "Esperamos que o trabalho desperte interesse em desenvolver modelos práticos e confiáveis de recuperação de artigos de lei.", "metrics": {"bleu_score": 25.42751695147591, "chrf_score": 69.85164883030843, "xcomet_score": 0.962709903717041, "xcomet_qe_score": 0.8178479671478271, "metricx_score": 2.180373430252075, "metricx_qe_score": 1.8575798273086548, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "pt", "output": "That can help improve access to justice for all.", "metrics": {"bleu_score": 3.435488317233919, "chrf_score": 19.002346177448768, "xcomet_score": 0.9743789434432983, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "pt", "output": "Você pode conferir nosso artigo, que está disponível em código, nos seguintes links. Obrigado.", "metrics": {"bleu_score": 14.879641171245488, "chrf_score": 47.658666422535575, "xcomet_score": 0.8175972700119019, "xcomet_qe_score": 0.8523275256156921, "metricx_score": 6.547908782958984, "metricx_qe_score": 6.965899467468262, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "pt", "output": "Olá, estamos felizes em apresentar nosso trabalho sobre Vowels, um benchmark independente de tarefa projetado para testar modelos de visão e linguagem com fenômenos linguísticos específicos.", "metrics": {"bleu_score": 33.43908532746717, "chrf_score": 73.4334800535467, "xcomet_score": 0.6537129878997803, "xcomet_qe_score": 0.6480115056037903, "metricx_score": 6.550067901611328, "metricx_qe_score": 6.487380027770996, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "pt", "output": "Por que fizemos o esforço de configurar este benchmark?", "metrics": {"bleu_score": 4.85851417160653, "chrf_score": 28.50671859494936, "xcomet_score": 0.9193571209907532, "xcomet_qe_score": 1.0, "metricx_score": 5.687128067016602, "metricx_qe_score": 5.170471668243408, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "pt", "output": "Bem, durante os últimos anos, vimos uma explosão de modelos de visão e linguagem baseados em transformadores, pré-treinados em grandes quantidades de pares de imagens e textos.", "metrics": {"bleu_score": 54.029057714801915, "chrf_score": 84.21286683595505, "xcomet_score": 0.9840350151062012, "xcomet_qe_score": 0.9817894697189331, "metricx_score": 2.8282079696655273, "metricx_qe_score": 3.274233818054199, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "pt", "output": "Cada um desses modelos empurra o estado do arte em tarefas de visão e linguagem, como resposta a perguntas visuais, raciocínio de sentido comum visual, recuperação de imagens, fundamentação de frases.", "metrics": {"bleu_score": 22.685225961067914, "chrf_score": 57.72440759928665, "xcomet_score": 0.7356072664260864, "xcomet_qe_score": 0.7443976998329163, "metricx_score": 5.390932559967041, "metricx_qe_score": 5.334833145141602, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "pt", "output": "Então, recebemos um aviso de que as precisões nesses benchmarks específicos de tarefas estão aumentando de forma constante.", "metrics": {"bleu_score": 19.164533861636915, "chrf_score": 62.572875249569535, "xcomet_score": 0.9343318939208984, "xcomet_qe_score": 0.9281896352767944, "metricx_score": 5.540835380554199, "metricx_qe_score": 5.3181586265563965, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "pt", "output": "Mas sabemos o que os modelos realmente aprenderam.", "metrics": {"bleu_score": 86.33400213704509, "chrf_score": 97.52646005366397, "xcomet_score": 0.9095565676689148, "xcomet_qe_score": 0.8517215251922607, "metricx_score": 1.5594980716705322, "metricx_qe_score": 3.1600325107574463, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "pt", "output": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "metrics": {"bleu_score": 1.5090865200235957, "chrf_score": 21.126633190211127, "xcomet_score": 0.964440107345581, "xcomet_qe_score": 0.9653360843658447, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "pt", "output": "and the low score for this one.", "metrics": {"bleu_score": 0.0, "chrf_score": 7.361111111111112, "xcomet_score": 0.9248173236846924, "xcomet_qe_score": 0.9770287871360779, "metricx_score": 17.440662384033203, "metricx_qe_score": 11.804882049560547, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "pt", "output": "Do vision and language models focus on the right thing?", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 25.16674224650684, "xcomet_score": 0.9123049974441528, "xcomet_qe_score": 0.9926931858062744, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "pt", "output": "Ou se concentram em viés, como demonstrado pelo trabalho anterior?", "metrics": {"bleu_score": 24.384183193426086, "chrf_score": 63.460677279217, "xcomet_score": 0.8130321502685547, "xcomet_qe_score": 0.8424959778785706, "metricx_score": 3.009781837463379, "metricx_qe_score": 1.8982703685760498, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "pt", "output": "Para lançar mais luz sobre este aspecto, proponemos uma direção mais agnóstica para a tarefa e introduzimos vales que testam a sensibilidade de modelos de visão e linguagem a fenômenos linguísticos específicos que afetam tanto as modalidades linguísticas quanto visuais.", "metrics": {"bleu_score": 44.03210067807771, "chrf_score": 83.61543148591886, "xcomet_score": 0.6828067302703857, "xcomet_qe_score": 0.5797809362411499, "metricx_score": 6.359543800354004, "metricx_qe_score": 7.608895301818848, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "pt", "output": "Nós nos dirigimos à existência, à pluralidade, à contagem, às relações espaciais, às ações e à referência de entidades.", "metrics": {"bleu_score": 11.120412274507306, "chrf_score": 65.92888269181934, "xcomet_score": 0.815313458442688, "xcomet_qe_score": 0.8264727592468262, "metricx_score": 5.100229740142822, "metricx_qe_score": 6.722804069519043, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "pt", "output": "Mas como podemos testar se os modelos de visão e linguagem capturaram esses fenômenos?", "metrics": {"bleu_score": 22.765893232556483, "chrf_score": 64.9432714313898, "xcomet_score": 0.9967528581619263, "xcomet_qe_score": 0.9953340291976929, "metricx_score": 1.4540213346481323, "metricx_qe_score": 2.355668306350708, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "pt", "output": "By foiling, a method previously applied for vision and language models only for noun phrases by Ravi Shankar and collaborators, and on counting by us in previous work.", "metrics": {"bleu_score": 1.5283262635570904, "chrf_score": 24.415714145483758, "xcomet_score": 0.8219163417816162, "xcomet_qe_score": 0.7975770235061646, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "pt", "output": "Foiling básicamente significa que tomamos a legenda de uma imagem e produzemos um foil alterando a legenda de tal forma que não descreva mais a imagem.", "metrics": {"bleu_score": 23.301482433033083, "chrf_score": 58.22444272912462, "xcomet_score": 0.652195930480957, "xcomet_qe_score": 0.9321150779724121, "metricx_score": 8.903393745422363, "metricx_qe_score": 6.680741310119629, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "pt", "output": "E fazemos essas alterações de frases focando em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e referência de entidades, onde cada peça pode consistir em um ou mais instrumentos, em caso de encontrarmos mais de uma maneira interessante de criar instâncias de folha.", "metrics": {"bleu_score": 61.13086731144164, "chrf_score": 80.88001315489286, "xcomet_score": 0.4894973039627075, "xcomet_qe_score": 0.5801962614059448, "metricx_score": 7.032422065734863, "metricx_qe_score": 8.474320411682129, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, no caso da peça de ação, temos dois instrumentos, um em que o verbo de ação é mudado com uma ação diferente, e um em que os tempos verbais são trocados.", "metrics": {"bleu_score": 68.16777387008752, "chrf_score": 80.96384089543416, "xcomet_score": 0.6188042163848877, "xcomet_qe_score": 0.6007469892501831, "metricx_score": 8.791666030883789, "metricx_qe_score": 11.263701438903809, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "pt", "output": "Contagem e correferência também são peças que têm mais de um instrumento.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 87.63593286062218, "xcomet_score": 0.796010434627533, "xcomet_qe_score": 0.7172844409942627, "metricx_score": 3.9774932861328125, "metricx_qe_score": 5.924042224884033, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "pt", "output": "E criamos esses foils garantindo que falhem a descrever a imagem, que sejam frases gramaticais e válidas.", "metrics": {"bleu_score": 7.425156669330895, "chrf_score": 36.48475515791718, "xcomet_score": 0.6835309267044067, "xcomet_qe_score": 0.8404170870780945, "metricx_score": 11.062435150146484, "metricx_qe_score": 8.051119804382324, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "pt", "output": "Isso não é fácil de fazer, porque uma legenda defeituosa pode ser menos provável do que a legenda original.", "metrics": {"bleu_score": 67.12403123245673, "chrf_score": 82.3150138281158, "xcomet_score": 0.9078909754753113, "xcomet_qe_score": 0.874247133731842, "metricx_score": 1.856614589691162, "metricx_qe_score": 1.9885210990905762, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, embora não seja impossível, é estatisticamente menos provável que plantas cortem um homem do que um homem cortar plantas. E grandes modelos de visão e linguagem poderiam pegar isso.", "metrics": {"bleu_score": 56.9220994632926, "chrf_score": 81.62472423928608, "xcomet_score": 0.8672528862953186, "xcomet_qe_score": 0.8125972151756287, "metricx_score": 6.215223789215088, "metricx_qe_score": 5.509164810180664, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, para obter FOs válidos, devemos tomar medidas.", "metrics": {"bleu_score": 18.36028134946796, "chrf_score": 45.45149435463276, "xcomet_score": 0.8677281141281128, "xcomet_qe_score": 0.9300616383552551, "metricx_score": 7.136728763580322, "metricx_qe_score": 3.843573570251465, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, fazemos uso de modelos de linguagem fortes para propor erros.", "metrics": {"bleu_score": 84.23626743789745, "chrf_score": 84.4497147156113, "xcomet_score": 0.8428727388381958, "xcomet_qe_score": 0.7884083986282349, "metricx_score": 5.1218132972717285, "metricx_qe_score": 6.06643009185791, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "pt", "output": "Em segundo lugar, usamos inferência de linguagem natural, ou NLP, para filtrar foils que ainda poderiam estar descrevendo a imagem, pois, ao construir foils, precisamos garantir que eles não descrevam a imagem.", "metrics": {"bleu_score": 23.561839549684937, "chrf_score": 62.28125729780507, "xcomet_score": 0.6871514320373535, "xcomet_qe_score": 0.7967592477798462, "metricx_score": 11.88520622253418, "metricx_qe_score": 11.314284324645996, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "pt", "output": "Para testar isso automaticamente, aplicamos inferência de linguagem natural com a seguinte justificativa.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 61.32478229888106, "xcomet_score": 0.875444769859314, "xcomet_qe_score": 0.8965397477149963, "metricx_score": 2.9561431407928467, "metricx_qe_score": 2.967357635498047, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "pt", "output": "We consider an image to be the premise and its caption its entailed hypothesis.", "metrics": {"bleu_score": 2.458476536482737, "chrf_score": 25.874777350793067, "xcomet_score": 0.9742389917373657, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, consideramos a legenda como a premissa e o foil como sua hipótese.", "metrics": {"bleu_score": 54.254864072519524, "chrf_score": 75.83024227846896, "xcomet_score": 0.7600444555282593, "xcomet_qe_score": 0.8565833568572998, "metricx_score": 7.921868801116943, "metricx_qe_score": 6.613996505737305, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "pt", "output": "Se um modelo nli prevê que o foil contradiz ou é neutro em relação à legenda, tomamos isso como um indicador de um foil válido.", "metrics": {"bleu_score": 33.39087646492814, "chrf_score": 58.961788272776325, "xcomet_score": 0.5437579154968262, "xcomet_qe_score": 0.7636833190917969, "metricx_score": 10.082988739013672, "metricx_qe_score": 8.885558128356934, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "pt", "output": "Se um nli prevê que o foil será incluído na legenda, não pode ser um bom foil, pois, por transitividade, dará uma descrição verdadeira da imagem e filtramos esses foils.", "metrics": {"bleu_score": 36.856095316963895, "chrf_score": 56.53139945122426, "xcomet_score": 0.36543989181518555, "xcomet_qe_score": 0.42864271998405457, "metricx_score": 18.16582489013672, "metricx_qe_score": 13.323110580444336, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "pt", "output": "Mas esse procedimento não é perfeito, é apenas um indicador para fôis válidos.", "metrics": {"bleu_score": 65.54913610595183, "chrf_score": 76.77433484489019, "xcomet_score": 0.7884912490844727, "xcomet_qe_score": 0.802057683467865, "metricx_score": 7.711135387420654, "metricx_qe_score": 5.260281562805176, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, como uma terceira medida para gerar fauxls válidos, empregamos anotadores humanos para validar os dados usados em Vals.", "metrics": {"bleu_score": 63.50869045864349, "chrf_score": 77.00341623821816, "xcomet_score": 0.5825127363204956, "xcomet_qe_score": 0.6704552173614502, "metricx_score": 7.418499946594238, "metricx_qe_score": 6.569869041442871, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "pt", "output": "O, após a filtragem e avaliação humana, temos tantas instâncias de teste quanto descrito nesta tabela.", "metrics": {"bleu_score": 79.12619863720215, "chrf_score": 88.22546772621548, "xcomet_score": 0.8848171234130859, "xcomet_qe_score": 0.8989269733428955, "metricx_score": 6.342111587524414, "metricx_qe_score": 6.317358016967773, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "pt", "output": "Note que Valls não entrega nenhum dado de treinamento, mas apenas dados de teste.", "metrics": {"bleu_score": 12.874330508144842, "chrf_score": 43.55993273254969, "xcomet_score": 0.7516872882843018, "xcomet_qe_score": 0.764946699142456, "metricx_score": 5.923191547393799, "metricx_qe_score": 5.375088691711426, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "pt", "output": "Como é um zero-shot testing benchmark apenas, é projetado para aproveitar as capacidades existentes de modelos de visão e linguagem após o pré-treinamento.", "metrics": {"bleu_score": 26.8222817742636, "chrf_score": 60.38009050135735, "xcomet_score": 0.7946474552154541, "xcomet_qe_score": 0.7892928719520569, "metricx_score": 8.326044082641602, "metricx_qe_score": 8.279778480529785, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "pt", "output": "A refinamento apenas permitiria aos modelos explorar artefatos ou vieses estatísticos nos dados.", "metrics": {"bleu_score": 49.5043021737605, "chrf_score": 72.53574854840477, "xcomet_score": 0.7478244304656982, "xcomet_qe_score": 0.7929279208183289, "metricx_score": 6.4914398193359375, "metricx_qe_score": 6.341281890869141, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "pt", "output": "E todos sabemos que esses modelos gostam de enganar e tomar atalhos.", "metrics": {"bleu_score": 16.751015697653383, "chrf_score": 62.858150874029675, "xcomet_score": 0.9919370412826538, "xcomet_qe_score": 1.0, "metricx_score": 1.7981009483337402, "metricx_qe_score": 2.100069522857666, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "pt", "output": "E, como dizemos, estamos interessados em avaliar quais capacidades os modelos de visão e linguagem têm após o pré-treinamento.", "metrics": {"bleu_score": 46.20838147988013, "chrf_score": 82.64155798563537, "xcomet_score": 0.9688783288002014, "xcomet_qe_score": 0.9901964068412781, "metricx_score": 2.337930679321289, "metricx_qe_score": 2.5882341861724854, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "pt", "output": "We experiment with five vision and language models on VOWELS, namely with CLIP, ALXLmert, Vilbert, Vilbert12in1, and Visualbert.", "metrics": {"bleu_score": 3.8100339513031853, "chrf_score": 30.073907959607116, "xcomet_score": 0.6058338284492493, "xcomet_qe_score": 0.6469598412513733, "metricx_score": 16.133590698242188, "metricx_qe_score": 9.313994407653809, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "pt", "output": "Dois de nossos indicadores de avaliação mais importantes são a precisão dos modelos na classificação de pares de frases de imagem em captions e foils.", "metrics": {"bleu_score": 20.120150406405223, "chrf_score": 57.678519408992145, "xcomet_score": 0.6425178050994873, "xcomet_qe_score": 0.7191958427429199, "metricx_score": 7.831501483917236, "metricx_qe_score": 7.140730857849121, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "pt", "output": "\"Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\"", "metrics": {"bleu_score": 1.1775510232018285, "chrf_score": 26.03919250098481, "xcomet_score": 0.806726336479187, "xcomet_qe_score": 0.9262852668762207, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "pt", "output": "For more metrics and results on them, do check out our paper.", "metrics": {"bleu_score": 3.377156414337854, "chrf_score": 19.420060577102262, "xcomet_score": 0.957487940788269, "xcomet_qe_score": 0.9875798225402832, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "pt", "output": "Os resultados com precisão parciais são mostrados aqui, e são consistentes com os resultados que obtemos das outras métricas. É que o melhor desempenho zero shot é alcançado por vilbert twelve in one, seguido por vilbert alex bert clip e, finalmente, visual bert.", "metrics": {"bleu_score": 32.44638087577641, "chrf_score": 65.51633087386288, "xcomet_score": 0.44878992438316345, "xcomet_qe_score": 0.41797763109207153, "metricx_score": 13.104270935058594, "metricx_qe_score": 12.53643798828125, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "pt", "output": "É notável como instrumentos centrados em objetos individuais, como existência e frases nominales, são quase resolvidos por Wilbert Dweghin 1, destacando que os modelos são capazes de identificar objetos nomeados e sua presença em imagens.", "metrics": {"bleu_score": 55.80351516794008, "chrf_score": 79.3970502263943, "xcomet_score": 0.6905779838562012, "xcomet_qe_score": 0.6301689743995667, "metricx_score": 6.895976543426514, "metricx_qe_score": 7.299911975860596, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "pt", "output": "No entanto, nenhum dos peças restantes pode ser resolvido de forma confiável em nossos ambientes de foiling adversarial.", "metrics": {"bleu_score": 20.313747122261766, "chrf_score": 58.16705779507726, "xcomet_score": 0.6422710418701172, "xcomet_qe_score": 0.7322858572006226, "metricx_score": 7.29742431640625, "metricx_qe_score": 8.286794662475586, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "pt", "output": "We see from the lularity and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects or counting them in an image.", "metrics": {"bleu_score": 1.1209313974917106, "chrf_score": 29.930673592997763, "xcomet_score": 0.9223732948303223, "xcomet_qe_score": 0.9335811734199524, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "pt", "output": "O pedaço de relação mostra que eles têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos em uma imagem.", "metrics": {"bleu_score": 60.52665103345166, "chrf_score": 89.40871669386851, "xcomet_score": 0.8702960014343262, "xcomet_qe_score": 0.8280608057975769, "metricx_score": 4.009130477905273, "metricx_qe_score": 4.852448463439941, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "pt", "output": "Eles também têm dificuldade em distinguir ações e identificar seus participantes, mesmo que apoiados por biais de plausibilidade, como vemos no trecho de ações.", "metrics": {"bleu_score": 51.473464105383584, "chrf_score": 80.48648913896226, "xcomet_score": 0.7977889776229858, "xcomet_qe_score": 0.840979814529419, "metricx_score": 4.625430583953857, "metricx_qe_score": 5.038567066192627, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "pt", "output": "A partir do trecho de correferência, descobrimos que rastrear múltiplas referências para o mesmo objeto em uma imagem usando pronoms é também difícil para modelos de visão e linguagem.", "metrics": {"bleu_score": 25.71098651154103, "chrf_score": 73.62466481924133, "xcomet_score": 0.7836275100708008, "xcomet_qe_score": 0.8270277976989746, "metricx_score": 3.599224805831909, "metricx_qe_score": 4.871869087219238, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "pt", "output": "Como uma verificação de sanidade, e porque é um experimento interessante, também avaliamos dois modelos textuais, GPT1 e GPT2, para avaliar se Voss é resolvível por esses modelos unimodais calculando a perplexidade da legenda correta e a falha e preditando a entrada com a perplexidade mais baixa.", "metrics": {"bleu_score": 38.324114266513064, "chrf_score": 66.87457745001274, "xcomet_score": 0.5462907552719116, "xcomet_qe_score": 0.49591943621635437, "metricx_score": 8.202202796936035, "metricx_qe_score": 9.291025161743164, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "pt", "output": "Se a perplejidade for maior para o foil, tomamos isso como uma indicação de que a legenda foiled pode sofrer de viés de plausibilidade ou outros vieses linguísticos.", "metrics": {"bleu_score": 30.591118675057672, "chrf_score": 65.14351350892083, "xcomet_score": 0.5212863683700562, "xcomet_qe_score": 0.5366881489753723, "metricx_score": 9.433177947998047, "metricx_qe_score": 8.843791961669922, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "pt", "output": "E é interessante ver que, em alguns casos, os modelos de GPT apenas de texto capturaram a plausibilidade do mundo melhor do que os modelos de visão e linguagem.", "metrics": {"bleu_score": 73.24536822795659, "chrf_score": 89.67132664041954, "xcomet_score": 0.9480510950088501, "xcomet_qe_score": 0.886644721031189, "metricx_score": 3.5864381790161133, "metricx_qe_score": 4.222753524780273, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "pt", "output": "Então, para resumir, Valsa é um benchmark que usa a lente das construções linguísticas para ajudar a comunidade a melhorar modelos de visão e linguagem testando suas capacidades de fundamentação visual.", "metrics": {"bleu_score": 45.784102982039435, "chrf_score": 71.05879437491089, "xcomet_score": 0.617141604423523, "xcomet_qe_score": 0.6997805833816528, "metricx_score": 6.596488952636719, "metricx_qe_score": 7.36057186126709, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "pt", "output": "Nossos experimentos mostram que modelos de visão e linguagem identificam bem objetos nomeados em suas presenças em imagens, como mostrado pelo peça de existência, mas lutam para fundamentar sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.", "metrics": {"bleu_score": 49.638365409693925, "chrf_score": 82.70743405342206, "xcomet_score": 0.7177979946136475, "xcomet_qe_score": 0.6993348598480225, "metricx_score": 5.779703617095947, "metricx_qe_score": 5.943943500518799, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "pt", "output": "\"we would really like to encourage the community to use valsa for measuring progress towards language grounding with vision and language models.\"", "metrics": {"bleu_score": 1.3903879849009706, "chrf_score": 24.781575578746178, "xcomet_score": 0.7752780914306641, "xcomet_qe_score": 0.805696964263916, "metricx_score": 25.0, "metricx_qe_score": 24.80820083618164, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "pt", "output": "E ainda mais, os valores poderiam ser usados como uma avaliação indireta de conjuntos de dados, pois os modelos poderiam ser avaliados antes e depois do treinamento ou refinamento para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados por valores.", "metrics": {"bleu_score": 65.13700604596107, "chrf_score": 80.62659956739319, "xcomet_score": 0.6884990930557251, "xcomet_qe_score": 0.7058136463165283, "metricx_score": 7.440250873565674, "metricx_qe_score": 7.527061939239502, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "pt", "output": "Se você estiver interessado, verifique os dados Vaults no GitHub e, se tiver alguma dúvida, não hesite em entrar em contato com nós.", "metrics": {"bleu_score": 18.25741858350554, "chrf_score": 44.50569202753462, "xcomet_score": 0.8244802951812744, "xcomet_qe_score": 0.8513695001602173, "metricx_score": 3.809711456298828, "metricx_qe_score": 4.621479511260986, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "pt", "output": "\"Hello, my name is Kamezawa from the University of Tokyo.\"", "metrics": {"bleu_score": 3.737437943747671, "chrf_score": 32.29242307186041, "xcomet_score": 0.9028453826904297, "xcomet_qe_score": 0.9928067922592163, "metricx_score": 23.855051040649414, "metricx_qe_score": 22.66782569885254, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "pt", "output": "I will be presenting a paper entitled R and S, a large scale dataset for automatic list not curations via commit log summarization.", "metrics": {"bleu_score": 1.2834898766816611, "chrf_score": 23.40087975719467, "xcomet_score": 0.28621289134025574, "xcomet_qe_score": 0.6263321042060852, "metricx_score": 14.216727256774902, "metricx_qe_score": 10.997713088989258, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "pt", "output": "I will explain in this order.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 20.81986069076357, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 6.638169288635254, "metricx_qe_score": 2.650315523147583, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, vou apresentar a geração automática de frases que estamos trabalhando nesta pesquisa.", "metrics": {"bleu_score": 23.725104025593723, "chrf_score": 64.33292881692223, "xcomet_score": 0.7713098526000977, "xcomet_qe_score": 0.7603877186775208, "metricx_score": 9.151577949523926, "metricx_qe_score": 9.734522819519043, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "pt", "output": "Release note é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.", "metrics": {"bleu_score": 80.66357446243076, "chrf_score": 85.13726904078133, "xcomet_score": 0.9355751276016235, "xcomet_qe_score": 0.9355983734130859, "metricx_score": 4.8406829833984375, "metricx_qe_score": 5.389471054077148, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "pt", "output": "A imagem mostra a razão para o barulho de dois pontos.", "metrics": {"bleu_score": 12.133798522701927, "chrf_score": 29.469124753254437, "xcomet_score": 0.14047452807426453, "xcomet_qe_score": 0.13824445009231567, "metricx_score": 23.199005126953125, "metricx_qe_score": 25.0, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "pt", "output": "These nodes play an important role in open source development, but they are time consuming to prepare manually.", "metrics": {"bleu_score": 2.060187754521775, "chrf_score": 27.9756147445849, "xcomet_score": 0.8293927907943726, "xcomet_qe_score": 0.8896005153656006, "metricx_score": 25.0, "metricx_qe_score": 22.965087890625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, seria muito útil poder gerar automaticamente notas de lançamento de alta qualidade.", "metrics": {"bleu_score": 45.980029022599005, "chrf_score": 72.83484556808749, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5498978495597839, "metricx_qe_score": 0.6360129714012146, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "pt", "output": "Referir-se a duas pesquisas anteriores sobre geração automática de notas de risco.", "metrics": {"bleu_score": 50.78431769269645, "chrf_score": 74.05560961866526, "xcomet_score": 0.5979031324386597, "xcomet_qe_score": 0.6252655982971191, "metricx_score": 13.04389762878418, "metricx_qe_score": 10.352914810180664, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "pt", "output": "O primeiro é um sistema chamado Arlen, lançado em 2014.", "metrics": {"bleu_score": 63.40466277046863, "chrf_score": 84.12356342018738, "xcomet_score": 0.7761461734771729, "xcomet_qe_score": 0.5776955485343933, "metricx_score": 7.464832305908203, "metricx_qe_score": 13.19893741607666, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "pt", "output": "Tomar um enfoque baseado em regras, por exemplo, usando o extractor de mudanças para extrair diferenças de código, mudanças de bibliotecas e mudanças de documentos das diferenças entre as versões, e, finalmente, combiná-las.", "metrics": {"bleu_score": 35.70318366964023, "chrf_score": 63.191759294297334, "xcomet_score": 0.7691198587417603, "xcomet_qe_score": 0.767974317073822, "metricx_score": 7.698745250701904, "metricx_qe_score": 7.346836566925049, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "pt", "output": "A característica mais notável deste sistema é o extractor de problemas na esquina superior direita.", "metrics": {"bleu_score": 50.67309892897293, "chrf_score": 83.72961985265034, "xcomet_score": 0.9009066224098206, "xcomet_qe_score": 0.8297722935676575, "metricx_score": 5.547697067260742, "metricx_qe_score": 5.97513484954834, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "pt", "output": "Which must be linked to Jira, the issue tracking system, and can only be applied to projects that use Jira.", "metrics": {"bleu_score": 4.322454646369599, "chrf_score": 21.01985396186114, "xcomet_score": 0.8969646692276001, "xcomet_qe_score": 0.9961528778076172, "metricx_score": 17.16649627685547, "metricx_qe_score": 5.230062961578369, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "pt", "output": "Em outras palavras, não pode ser usado para muitos projetos no Github.", "metrics": {"bleu_score": 77.4403141014203, "chrf_score": 89.81344521733699, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5996657013893127, "metricx_qe_score": 1.038176417350769, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "pt", "output": "O segundo é grief, recentemente anunciado em 2021.", "metrics": {"bleu_score": 19.96019880774733, "chrf_score": 61.90022115041519, "xcomet_score": 0.45873090624809265, "xcomet_qe_score": 0.5604473352432251, "metricx_score": 8.486614227294922, "metricx_qe_score": 9.519294738769531, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "pt", "output": "2020. Está disponível na internet e pode ser instalado via pip.", "metrics": {"bleu_score": 61.153805769010226, "chrf_score": 78.79832243153417, "xcomet_score": 0.6231073141098022, "xcomet_qe_score": 0.4391966164112091, "metricx_score": 9.202847480773926, "metricx_qe_score": 13.578630447387695, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "pt", "output": "Este sistema possui um modelo de classificação de texto baseado em aprendizado simples e produz uma das cinco probabilidades, como recursos ou correções de bugs, para cada mensagem de commit de entrada.", "metrics": {"bleu_score": 26.871428370610335, "chrf_score": 59.50270169600993, "xcomet_score": 0.6841887831687927, "xcomet_qe_score": 0.7677030563354492, "metricx_score": 5.523945331573486, "metricx_qe_score": 4.962771415710449, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "pt", "output": "A imagem é um exemplo de uso que retorna um rótulo de correção de erro ou correção de bugs.", "metrics": {"bleu_score": 11.728147369287814, "chrf_score": 45.574301337236115, "xcomet_score": 0.9155354499816895, "xcomet_qe_score": 0.9068012833595276, "metricx_score": 2.801725387573242, "metricx_qe_score": 3.066634178161621, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "pt", "output": "Os dados de treinamento do Coalesce são bastante pequenos, cerca de cinco mil, e serão apresentados nos experimentos descritos abaixo.", "metrics": {"bleu_score": 62.48651455191908, "chrf_score": 73.3308425940507, "xcomet_score": 0.7024556398391724, "xcomet_qe_score": 0.7321410179138184, "metricx_score": 6.383190631866455, "metricx_qe_score": 7.433502674102783, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "pt", "output": "A performance do modelo de classificação de texto não é alta.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 55.018379946181994, "xcomet_score": 0.9865025281906128, "xcomet_qe_score": 1.0, "metricx_score": 3.3952879905700684, "metricx_qe_score": 4.001788139343262, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "pt", "output": "Presento a vocês duas pesquisas relacionadas, mas com problemas de aplicabilidade limitada e escassez de recursos de dados.", "metrics": {"bleu_score": 42.849450901003145, "chrf_score": 78.24817745200512, "xcomet_score": 0.9922140836715698, "xcomet_qe_score": 0.9830752611160278, "metricx_score": 0.8793745040893555, "metricx_qe_score": 0.8907998204231262, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "pt", "output": "Our paper solves these two problems and automatically generates high quality release notes.", "metrics": {"bleu_score": 2.292084231617577, "chrf_score": 32.75558847007268, "xcomet_score": 0.9768402576446533, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "pt", "output": "Para o problema da aplicabilidade limitada, propomos um método de resumo de classificação de alta qualidade, usando apenas mensagens de commit como entrada.", "metrics": {"bleu_score": 28.437757352138362, "chrf_score": 68.68074536075912, "xcomet_score": 0.9161258935928345, "xcomet_qe_score": 0.9587681889533997, "metricx_score": 6.782398700714111, "metricx_qe_score": 6.5655293464660645, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "pt", "output": "Este método proposto pode ser usado para todos os repositórios de inglês.", "metrics": {"bleu_score": 79.10665071754353, "chrf_score": 92.61704861814371, "xcomet_score": 0.9762592315673828, "xcomet_qe_score": 0.9807526469230652, "metricx_score": 2.346045732498169, "metricx_qe_score": 2.2622735500335693, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "pt", "output": "Para o segundo problema de recursos de dados escassos, construí um conjunto de dados de R e R, composto por cerca de oitenta e dois mil peças de dados, coletando dados de repositórios públicos do GitHub usando a API do GitHub.", "metrics": {"bleu_score": 50.496352077047916, "chrf_score": 77.24562654121682, "xcomet_score": 0.6794834136962891, "xcomet_qe_score": 0.6935784816741943, "metricx_score": 6.6821675300598145, "metricx_qe_score": 6.840908527374268, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "pt", "output": "Em seguida, descrevo nosso dataset.", "metrics": {"bleu_score": 15.685718045401451, "chrf_score": 42.99741946392906, "xcomet_score": 0.978018045425415, "xcomet_qe_score": 0.967595100402832, "metricx_score": 4.449550628662109, "metricx_qe_score": 3.9283714294433594, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui está um exemplo de dados.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9989265203475952, "xcomet_qe_score": 0.9954147338867188, "metricx_score": 0.192732572555542, "metricx_qe_score": 0.2367323637008667, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "pt", "output": "A esquerda é um commit message, e a direita é o node de origem.", "metrics": {"bleu_score": 3.2273052162907674, "chrf_score": 24.731901135501197, "xcomet_score": 0.4501073658466339, "xcomet_qe_score": 0.49138107895851135, "metricx_score": 18.099010467529297, "metricx_qe_score": 18.173227310180664, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "pt", "output": "The reason notes are labeled as improvements of faces etc.", "metrics": {"bleu_score": 6.249439580998987, "chrf_score": 19.52515161417893, "xcomet_score": 0.37045109272003174, "xcomet_qe_score": 0.7658257484436035, "metricx_score": 20.718111038208008, "metricx_qe_score": 16.686616897583008, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "pt", "output": "Temos configurado uma tarefa que recebe os mensagens de commit como entrada e produz os nós de lista rotulados.", "metrics": {"bleu_score": 14.400124446705304, "chrf_score": 50.61720018212349, "xcomet_score": 0.7277932167053223, "xcomet_qe_score": 0.6949030160903931, "metricx_score": 9.099319458007812, "metricx_qe_score": 8.468210220336914, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "pt", "output": "This can be regarded as a summarization task.", "metrics": {"bleu_score": 4.266331692956901, "chrf_score": 19.95775807744309, "xcomet_score": 0.9754339456558228, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 21.963693618774414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "pt", "output": "Temos prédefinidas quatro níveis: recursos, melhorias, correções de bugs, duplicações, removidos e mudanças de quebra.", "metrics": {"bleu_score": 21.16066310018769, "chrf_score": 41.57659068543446, "xcomet_score": 0.5506097674369812, "xcomet_qe_score": 0.5285588502883911, "metricx_score": 14.74337100982666, "metricx_qe_score": 11.403764724731445, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "pt", "output": "Esses valores são estabelecidos com base em pesquisas anteriores e outras práticas.", "metrics": {"bleu_score": 39.553325358771794, "chrf_score": 63.678617963969906, "xcomet_score": 0.8875701427459717, "xcomet_qe_score": 0.8887584209442139, "metricx_score": 2.7722203731536865, "metricx_qe_score": 2.095029354095459, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "pt", "output": "The lease note on the bottom right and extracted from the lease note shown on the bottom left.", "metrics": {"bleu_score": 2.0244462660665508, "chrf_score": 16.49770335543702, "xcomet_score": 0.4871646761894226, "xcomet_qe_score": 0.7402589321136475, "metricx_score": 14.505176544189453, "metricx_qe_score": 9.480218887329102, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "pt", "output": "At this time, it is necessary to detect the four labels that have been set up in advance.", "metrics": {"bleu_score": 2.276859592073037, "chrf_score": 19.993051875568586, "xcomet_score": 0.9898034334182739, "xcomet_qe_score": 0.9740556478500366, "metricx_score": 25.0, "metricx_qe_score": 23.323139190673828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "pt", "output": "Mas as etiquetas não são sempre consistentes com cada lipase.", "metrics": {"bleu_score": 17.242221289766626, "chrf_score": 47.615235071777015, "xcomet_score": 0.7928991317749023, "xcomet_qe_score": 0.7389051914215088, "metricx_score": 9.526856422424316, "metricx_qe_score": 9.836008071899414, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, o nível de melhoria inclui melhorias, aprimoramentos, otimizações, etc.", "metrics": {"bleu_score": 22.8985946814998, "chrf_score": 61.06383872295943, "xcomet_score": 0.9081628322601318, "xcomet_qe_score": 0.9112043380737305, "metricx_score": 3.2577617168426514, "metricx_qe_score": 2.5283408164978027, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "pt", "output": "Preparamos uma lista de vocabulário de termos de estudo para cada uma dessas variações rotacionais.", "metrics": {"bleu_score": 51.98157258729877, "chrf_score": 74.4890039125709, "xcomet_score": 0.6154776811599731, "xcomet_qe_score": 0.6474834680557251, "metricx_score": 13.98772144317627, "metricx_qe_score": 13.117504119873047, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "pt", "output": "Use it to detect the release note class and collect the text of the list that follows as the release note sentence for the class.", "metrics": {"bleu_score": 1.2385894093817358, "chrf_score": 22.687030149155344, "xcomet_score": 0.6991575956344604, "xcomet_qe_score": 0.8445093035697937, "metricx_score": 11.253761291503906, "metricx_qe_score": 7.614343166351318, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "pt", "output": "\"Next is a commit message.\"", "metrics": {"bleu_score": 4.8734989388136185, "chrf_score": 11.997316383509613, "xcomet_score": 0.466613233089447, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 16.295001983642578, "metricx_qe_score": 12.503323554992676, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "pt", "output": "Mensagens de commit não estão associadas a cada versão.", "metrics": {"bleu_score": 11.884631831419354, "chrf_score": 45.15956239473789, "xcomet_score": 0.9073030948638916, "xcomet_qe_score": 0.9788070321083069, "metricx_score": 6.735125541687012, "metricx_qe_score": 4.9076337814331055, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "pt", "output": "Como mostrado na imagem abaixo, se a versão atual for 2.5.19, precisamos atualizar.", "metrics": {"bleu_score": 24.230028661194897, "chrf_score": 44.898081315113075, "xcomet_score": 0.5566281080245972, "xcomet_qe_score": 0.6138285994529724, "metricx_score": 13.85783863067627, "metricx_qe_score": 14.235260009765625, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "pt", "output": "The previous release version 2.5 to 18 and get it deep. This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "metrics": {"bleu_score": 0.9964194812460634, "chrf_score": 18.524706728412074, "xcomet_score": 0.41011232137680054, "xcomet_qe_score": 0.6094492673873901, "metricx_score": 25.0, "metricx_qe_score": 24.185365676879883, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "pt", "output": "Criamos uma regra de correspondência heurística para obter as versões anterior e seguinte.", "metrics": {"bleu_score": 91.93227152249175, "chrf_score": 95.99249781766002, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.800369918346405, "metricx_qe_score": 0.7086400985717773, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "pt", "output": "Day set analysis.", "metrics": {"bleu_score": 9.688464563433238, "chrf_score": 8.794617293376596, "xcomet_score": 0.40188831090927124, "xcomet_qe_score": 0.81794673204422, "metricx_score": 17.286771774291992, "metricx_qe_score": 11.013893127441406, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "pt", "output": "No final, 7200 repositórios.", "metrics": {"bleu_score": 3.932742381668659, "chrf_score": 23.17864789900191, "xcomet_score": 0.1507388949394226, "xcomet_qe_score": 0.14464934170246124, "metricx_score": 22.998754501342773, "metricx_qe_score": 23.851783752441406, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, o número médio de tokens de nota de lançamento é de sessenta e três, o que é bastante alto para a tarefa de resumo.", "metrics": {"bleu_score": 65.35593760488659, "chrf_score": 81.69631644267099, "xcomet_score": 0.6952264308929443, "xcomet_qe_score": 0.7001775503158569, "metricx_score": 2.2192935943603516, "metricx_qe_score": 2.7049753665924072, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, o número de tokens únicos é bastante grande, em 8.830.000.", "metrics": {"bleu_score": 60.638269883199015, "chrf_score": 64.88858530115169, "xcomet_score": 0.8832370042800903, "xcomet_qe_score": 0.8062369227409363, "metricx_score": 3.7565317153930664, "metricx_qe_score": 4.324711322784424, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "pt", "output": "Devido ao grande número de classes e nomes de método encontrados na biblioteca.", "metrics": {"bleu_score": 21.446539598866316, "chrf_score": 57.68966218606153, "xcomet_score": 0.7852285504341125, "xcomet_qe_score": 0.9213666915893555, "metricx_score": 8.353475570678711, "metricx_qe_score": 7.55682373046875, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "pt", "output": "Em seguida, vou explicar o método proposto.", "metrics": {"bleu_score": 43.167001068522545, "chrf_score": 78.0639938247243, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08695930987596512, "metricx_qe_score": 0.1412639021873474, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "pt", "output": "O modelo de resumo extrativo e abstrativo de classe consiste em dois módulos neurais.", "metrics": {"bleu_score": 32.078739729528806, "chrf_score": 59.53351061383781, "xcomet_score": 0.8763003945350647, "xcomet_qe_score": 0.8590943217277527, "metricx_score": 2.802046537399292, "metricx_qe_score": 2.629333972930908, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "pt", "output": "A classificador usando bart ou cod bart e o gerador usando bart.", "metrics": {"bleu_score": 4.277213401227561, "chrf_score": 34.54958971239054, "xcomet_score": 0.6964730024337769, "xcomet_qe_score": 0.7870432138442993, "metricx_score": 12.481600761413574, "metricx_qe_score": 11.500444412231445, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, ceas usa um classificador para classificar cada mensagem de commit em cinco classes de motivo: features, improvements, bug fixes, deprecation, and other.", "metrics": {"bleu_score": 31.371616450821193, "chrf_score": 52.33506612473957, "xcomet_score": 0.6054419279098511, "xcomet_qe_score": 0.5910103917121887, "metricx_score": 10.754019737243652, "metricx_qe_score": 8.03150463104248, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "pt", "output": "The commit messages classified as other are discarded.", "metrics": {"bleu_score": 4.266331692956901, "chrf_score": 26.511135419509618, "xcomet_score": 0.9638099670410156, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 24.198156356811523, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "pt", "output": "Então, ceas aplica o transformador a todos os documentos de amor de forma independente e gera uma lista de notas para cada classe.", "metrics": {"bleu_score": 27.748702735605818, "chrf_score": 55.112034676212716, "xcomet_score": 0.42254412174224854, "xcomet_qe_score": 0.3967047929763794, "metricx_score": 16.260692596435547, "metricx_qe_score": 17.649682998657227, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "pt", "output": "Em esta tarefa, as correspondências diretas entre mensagens de commit e nós de razão não são conhecidas.", "metrics": {"bleu_score": 51.84341074271373, "chrf_score": 72.88421343549565, "xcomet_score": 0.6801855564117432, "xcomet_qe_score": 0.7172282934188843, "metricx_score": 9.035706520080566, "metricx_qe_score": 8.965714454650879, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, para treinar o classificador, classificador, atribuimos níveis de grau a cada mensagem de commit de entrada usando os primeiros dez caracteres de cada mensagem de commit.", "metrics": {"bleu_score": 39.62645069468097, "chrf_score": 63.32642119694213, "xcomet_score": 0.6439838409423828, "xcomet_qe_score": 0.6989619135856628, "metricx_score": 11.087719917297363, "metricx_qe_score": 11.047833442687988, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "pt", "output": "Modelamos o classificador abstrativo usando dois métodos diferentes.", "metrics": {"bleu_score": 21.386638885976566, "chrf_score": 47.85644595136354, "xcomet_score": 0.8850141167640686, "xcomet_qe_score": 0.8830226063728333, "metricx_score": 6.012138843536377, "metricx_qe_score": 6.239747524261475, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "pt", "output": "O primeiro modelo, que chamamos de ga single, consiste em uma única rede de set-to-set e gera uma única linha de texto de entrada de mensagem de commit.", "metrics": {"bleu_score": 14.632843990736758, "chrf_score": 52.943851493129, "xcomet_score": 0.41985803842544556, "xcomet_qe_score": 0.48485690355300903, "metricx_score": 14.852607727050781, "metricx_qe_score": 16.017498016357422, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "pt", "output": "O texto de saída pode ser dividido em segmentos classificados com base em amostras de ponto final especiais e específicas da classe.", "metrics": {"bleu_score": 10.64727618653598, "chrf_score": 57.38783848595108, "xcomet_score": 0.7187544703483582, "xcomet_qe_score": 0.8332887887954712, "metricx_score": 6.461925506591797, "metricx_qe_score": 5.540864944458008, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "pt", "output": "O segundo método, que chamamos de csmatch, consiste em quatro redes sec-to-sec diferentes, cada uma das quais corresponde a uma das classes de nós de lista.", "metrics": {"bleu_score": 55.10570511975452, "chrf_score": 69.71650564992251, "xcomet_score": 0.4900188446044922, "xcomet_qe_score": 0.41627755761146545, "metricx_score": 12.897701263427734, "metricx_qe_score": 11.137664794921875, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "pt", "output": "Ok, me deixe explicar o experimento.", "metrics": {"bleu_score": 7.267884212102741, "chrf_score": 42.665603715131866, "xcomet_score": 0.983146071434021, "xcomet_qe_score": 0.9865994453430176, "metricx_score": 1.6231719255447388, "metricx_qe_score": 1.9558587074279785, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "pt", "output": "Cinco métodos foram comparados, CAS, CAS single, CAS multi, clustering e o estudo anterior Griffith.", "metrics": {"bleu_score": 15.435109972796829, "chrf_score": 66.7561335699948, "xcomet_score": 0.8487871885299683, "xcomet_qe_score": 0.7557478547096252, "metricx_score": 8.67082405090332, "metricx_qe_score": 9.873454093933105, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "pt", "output": "Em relação à avaliação, em alguns casos, esses nós são saídos em sentenças múltiplas.", "metrics": {"bleu_score": 45.823642987102374, "chrf_score": 53.70654449099759, "xcomet_score": 0.6651758551597595, "xcomet_qe_score": 0.6489660739898682, "metricx_score": 18.865877151489258, "metricx_qe_score": 19.186038970947266, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "pt", "output": "Como é difícil calcular o número de frases que existem, elas são combinadas com espaços e tratadas como uma única frase longa.", "metrics": {"bleu_score": 65.31420255892324, "chrf_score": 85.75522658612645, "xcomet_score": 0.9984126091003418, "xcomet_qe_score": 1.0, "metricx_score": 1.330360770225525, "metricx_qe_score": 1.644091248512268, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "pt", "output": "The view is panoramic when the system outputs a short sentence.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 15.526671908992432, "xcomet_score": 0.2263500690460205, "xcomet_qe_score": 0.7390257716178894, "metricx_score": 22.49361801147461, "metricx_qe_score": 18.72212028503418, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "pt", "output": "Esta penalidade resulta em um valor de cor azul mais baixo nos resultados do experimento descritos a seguir.", "metrics": {"bleu_score": 23.987717557009486, "chrf_score": 71.83839488379493, "xcomet_score": 0.9831533432006836, "xcomet_qe_score": 0.9873402118682861, "metricx_score": 3.1361002922058105, "metricx_qe_score": 2.9067208766937256, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "pt", "output": "Finalmente, também calculamos a especificidade, porque ruge e azul não podem ser calculados se as notas de release estiverem vazias.", "metrics": {"bleu_score": 57.60910462758842, "chrf_score": 76.96729240378114, "xcomet_score": 0.8245847225189209, "xcomet_qe_score": 0.8457293510437012, "metricx_score": 7.634701728820801, "metricx_qe_score": 7.40769624710083, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "pt", "output": "Uma alta especificidade significa que o modelo produz corretamente um texto vazio em casos em que o texto de entrada não é vazio.", "metrics": {"bleu_score": 32.59889346257789, "chrf_score": 62.48542165446603, "xcomet_score": 0.8740251064300537, "xcomet_qe_score": 0.910237193107605, "metricx_score": 3.3932199478149414, "metricx_qe_score": 4.428775787353516, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "pt", "output": "Here are the results.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 22.785756919296478, "xcomet_score": 0.9614166021347046, "xcomet_qe_score": 1.0, "metricx_score": 7.168374061584473, "metricx_qe_score": 4.641719818115234, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "pt", "output": "Como o dataset contém endereços de e-mail, valores hash, etc., também avaliamos o dataset limpo, que os exclui.", "metrics": {"bleu_score": 49.130926679270786, "chrf_score": 65.4460699289283, "xcomet_score": 0.9804574251174927, "xcomet_qe_score": 0.9972367286682129, "metricx_score": 6.350475311279297, "metricx_qe_score": 6.49260139465332, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "pt", "output": "CAS and CAS achieved LUE scores more than ten points higher than the baselines.", "metrics": {"bleu_score": 2.923637789252517, "chrf_score": 16.344601985942393, "xcomet_score": 0.5037850141525269, "xcomet_qe_score": 0.7749834060668945, "metricx_score": 20.75550651550293, "metricx_qe_score": 14.971397399902344, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "pt", "output": "Em particular, no conjunto de teste limpo, a lacuna de pontuação entre o método proposto e o banco de dados base aumentou para mais de 20 pontos.", "metrics": {"bleu_score": 45.055528169659475, "chrf_score": 66.17334516925084, "xcomet_score": 0.7054341435432434, "xcomet_qe_score": 0.5296574234962463, "metricx_score": 8.076888084411621, "metricx_qe_score": 6.432950973510742, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "pt", "output": "These results indicate that GHS and GHS have significant effects.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 33.30068183581079, "xcomet_score": 0.19740337133407593, "xcomet_qe_score": 0.6320497393608093, "metricx_score": 20.032123565673828, "metricx_qe_score": 18.217180252075195, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "pt", "output": "CAS obteve uma pontuação de pontuação de pontuação melhor do que CAS, sugerindo que combinar um classificador e um gerador é eficaz na treinamento do classificador usando amostras.", "metrics": {"bleu_score": 45.309372174398234, "chrf_score": 72.56918120849144, "xcomet_score": 0.13202254474163055, "xcomet_qe_score": 0.0865156278014183, "metricx_score": 18.12626838684082, "metricx_qe_score": 19.414039611816406, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "pt", "output": "A alta cobertura de CAS pode ser alcançada com sucesso, porque o classificador pode se concentrar na seleção de mensagens de commit relevantes para cada classe.", "metrics": {"bleu_score": 41.79882049216856, "chrf_score": 74.22492412853566, "xcomet_score": 0.7756770849227905, "xcomet_qe_score": 0.8126908540725708, "metricx_score": 7.792116165161133, "metricx_qe_score": 7.916630744934082, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "pt", "output": "As CSOs tendem a ter um valor de utilidade maior do que as CS.", "metrics": {"bleu_score": 5.816635421147513, "chrf_score": 16.843217432774996, "xcomet_score": 0.14078839123249054, "xcomet_qe_score": 0.16751977801322937, "metricx_score": 20.535627365112305, "metricx_qe_score": 15.299392700195312, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "pt", "output": "Sugere que também é eficaz desenvolver de forma independente modelos de resumo observacionais diferentes para cada classe de nós de E.", "metrics": {"bleu_score": 49.32870682433747, "chrf_score": 64.20518732989568, "xcomet_score": 0.5804280638694763, "xcomet_qe_score": 0.5702646970748901, "metricx_score": 8.16508674621582, "metricx_qe_score": 7.059381008148193, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, uma análise de erro.", "metrics": {"bleu_score": 64.34588841607616, "chrf_score": 73.13974125480468, "xcomet_score": 0.964150071144104, "xcomet_qe_score": 0.9484947919845581, "metricx_score": 0.556283712387085, "metricx_qe_score": 0.847040593624115, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "pt", "output": "Os métodos de CS tendem a produzir frases mais curtas do que frases de referência humanas.", "metrics": {"bleu_score": 65.15835084211272, "chrf_score": 78.88240883408629, "xcomet_score": 0.8182075023651123, "xcomet_qe_score": 0.7722689509391785, "metricx_score": 5.240474224090576, "metricx_qe_score": 4.506657600402832, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "pt", "output": "Na figura à direita, a frase de referência tem três ou quatro frases, enquanto cs tem apenas uma.", "metrics": {"bleu_score": 78.69685946580964, "chrf_score": 89.52204936248232, "xcomet_score": 0.8625098466873169, "xcomet_qe_score": 0.7474074363708496, "metricx_score": 5.7848615646362305, "metricx_qe_score": 7.0465826988220215, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "pt", "output": "A razão para essa relutância do modelo é que, em dados de treinamento, apenas 33% das frases estão presentes no nível de recursos e 40% no nível de melhorias.", "metrics": {"bleu_score": 32.64915101392729, "chrf_score": 54.94679929747696, "xcomet_score": 0.7691720724105835, "xcomet_qe_score": 0.8076300621032715, "metricx_score": 3.4424540996551514, "metricx_qe_score": 2.63100266456604, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, os métodos de CAS não podem gerar notas de dificuldade com precisão sem informações adicionais.", "metrics": {"bleu_score": 56.85488870277223, "chrf_score": 76.10029391286353, "xcomet_score": 0.8379070162773132, "xcomet_qe_score": 0.8537766933441162, "metricx_score": 7.418360233306885, "metricx_qe_score": 8.032906532287598, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "pt", "output": "O exemplo superior à direita é um exemplo de um commit message muito bagunçado. E a frase completa não pode ser gerada sem referência à solicitação ou problema correspondente.", "metrics": {"bleu_score": 57.031782981026986, "chrf_score": 73.5733786288583, "xcomet_score": 0.863731861114502, "xcomet_qe_score": 0.9001616835594177, "metricx_score": 6.707510471343994, "metricx_qe_score": 6.380983829498291, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "pt", "output": "O exemplo abaixo mostra que os dois mensagens de commit na entrada estão relacionadas e devem ser combinadas em uma única frase, mas falha em fazer isso.", "metrics": {"bleu_score": 42.51298835731235, "chrf_score": 73.96760350828183, "xcomet_score": 0.8733408451080322, "xcomet_qe_score": 0.8709300756454468, "metricx_score": 6.606198310852051, "metricx_qe_score": 5.807186603546143, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "pt", "output": "Finally, a conclusion.", "metrics": {"bleu_score": 10.400597689005304, "chrf_score": 34.097867217062266, "xcomet_score": 0.9389060735702515, "xcomet_qe_score": 1.0, "metricx_score": 22.316770553588867, "metricx_qe_score": 16.856294631958008, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "pt", "output": "We've built a new dataset for automatic phrase node generation.", "metrics": {"bleu_score": 2.853183878886449, "chrf_score": 18.868078231250372, "xcomet_score": 0.7075932025909424, "xcomet_qe_score": 0.7909296751022339, "metricx_score": 20.877246856689453, "metricx_qe_score": 9.63465404510498, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "pt", "output": "Também formulamos a tarefa de inserir mensagens de commit e resumir-as, de modo que seja aplicável a todos os projetos escritos em inglês.", "metrics": {"bleu_score": 48.15092081725061, "chrf_score": 72.13978246016548, "xcomet_score": 0.885425329208374, "xcomet_qe_score": 0.8483242988586426, "metricx_score": 4.897946357727051, "metricx_qe_score": 5.242717742919922, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "pt", "output": "O nosso experimento mostra que o método proposto gera leituras menos ruído a maior cobertura do que as linhas de base.", "metrics": {"bleu_score": 40.38821027524454, "chrf_score": 58.039814534056134, "xcomet_score": 0.7374916076660156, "xcomet_qe_score": 0.713428258895874, "metricx_score": 10.210164070129395, "metricx_qe_score": 10.315313339233398, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "pt", "output": "Please check out our desert oasis on the top.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 12.566590107076465, "xcomet_score": 0.17835983633995056, "xcomet_qe_score": 0.4937800467014313, "metricx_score": 23.093727111816406, "metricx_qe_score": 16.828712463378906, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "pt", "output": "Obrigado.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14589540660381317, "metricx_qe_score": 0.24346594512462616, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "pt", "output": "\"Hello, my name is Safarali.\"", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 15.926874868603322, "xcomet_score": 0.1214287057518959, "xcomet_qe_score": 0.1386294811964035, "metricx_score": 18.115819931030273, "metricx_qe_score": 10.326632499694824, "linguapy_score": [1, "ALBANIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "pt", "output": "E apresentarei nosso artigo, few-shot tabular data enrichment using fine-tuning transformers architectures.", "metrics": {"bleu_score": 6.609782562064607, "chrf_score": 35.571103147120056, "xcomet_score": 0.9079705476760864, "xcomet_qe_score": 0.9294652938842773, "metricx_score": 10.95925521850586, "metricx_qe_score": 6.4458327293396, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "pt", "output": "Data scientists analyze data and mainly focus on manipulating the data's existing features.", "metrics": {"bleu_score": 2.292084231617577, "chrf_score": 26.038044837924897, "xcomet_score": 0.9917434453964233, "xcomet_qe_score": 0.9829064607620239, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "pt", "output": "Mas algumas vezes essas características são limitadas.", "metrics": {"bleu_score": 29.797147054518835, "chrf_score": 71.41005469997995, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.27376794815063477, "metricx_qe_score": 0.5134426355361938, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "pt", "output": "A geração de recursos usando outra fonte de dados pode adicionar informações substanciais.", "metrics": {"bleu_score": 42.57110866884422, "chrf_score": 67.70381803954969, "xcomet_score": 0.8882614374160767, "xcomet_qe_score": 0.8995776176452637, "metricx_score": 3.6022250652313232, "metricx_qe_score": 3.5784807205200195, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "pt", "output": "O nosso objetivo de pesquisa é a enriquecimento automático de dados tabulares usando fontes externas de texto livre.", "metrics": {"bleu_score": 29.153692299445236, "chrf_score": 79.87150481363426, "xcomet_score": 0.9225360751152039, "xcomet_qe_score": 0.9198399782180786, "metricx_score": 3.7292206287384033, "metricx_qe_score": 3.894050121307373, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "pt", "output": "Suponha que temos um conjunto de dados tabulares e uma base de conhecimento.", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 88.92637257314419, "xcomet_score": 0.8967338800430298, "xcomet_qe_score": 0.9431560039520264, "metricx_score": 3.915160894393921, "metricx_qe_score": 2.22221302986145, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "pt", "output": "We need an automatic process which involve entity linking and text analysis to extract new features from the knowledge base free text.", "metrics": {"bleu_score": 3.5902757996620975, "chrf_score": 31.91395626073634, "xcomet_score": 0.9133780002593994, "xcomet_qe_score": 0.9380192756652832, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "pt", "output": "O nosso quadro, primeiro, é exatamente esse processo automático.", "metrics": {"bleu_score": 41.72261448611505, "chrf_score": 65.3050861881456, "xcomet_score": 0.717121958732605, "xcomet_qe_score": 0.6648948788642883, "metricx_score": 13.095663070678711, "metricx_qe_score": 16.27012062072754, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "pt", "output": "Então vamos ver um exemplo em um conjunto de dados alimentado em Fast.", "metrics": {"bleu_score": 26.58483576665878, "chrf_score": 75.49931885811425, "xcomet_score": 0.8138558864593506, "xcomet_qe_score": 0.7771508097648621, "metricx_score": 6.152589321136475, "metricx_qe_score": 6.547565460205078, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "pt", "output": "In this example, the dataset is university dataset.", "metrics": {"bleu_score": 3.3449303459224256, "chrf_score": 22.555354663495915, "xcomet_score": 0.9341437816619873, "xcomet_qe_score": 0.9715653657913208, "metricx_score": 25.0, "metricx_qe_score": 18.12618064880371, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "pt", "output": "When its goal is to classify universities into low-ranked universities and high-ranked universities.", "metrics": {"bleu_score": 1.9869571647551538, "chrf_score": 28.673929614741777, "xcomet_score": 0.9923228025436401, "xcomet_qe_score": 0.9253767132759094, "metricx_score": 24.899524688720703, "metricx_qe_score": 24.74163818359375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "pt", "output": "As knowledge base, we use Wikipedia.", "metrics": {"bleu_score": 6.413885305524152, "chrf_score": 21.0155667438126, "xcomet_score": 0.977408766746521, "xcomet_qe_score": 1.0, "metricx_score": 22.810075759887695, "metricx_qe_score": 19.516036987304688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "pt", "output": "The first phase of fist is entity linking.", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 42.4190664780086, "xcomet_score": 0.6981576681137085, "xcomet_qe_score": 0.8122814297676086, "metricx_score": 24.48747444152832, "metricx_qe_score": 17.974058151245117, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "pt", "output": "Quando cada entidade, neste exemplo, o nome da universidade, é vinculada a uma entidade dentro da base de conhecimento.", "metrics": {"bleu_score": 83.18180062062373, "chrf_score": 90.62385306773947, "xcomet_score": 0.9975329637527466, "xcomet_qe_score": 1.0, "metricx_score": 0.8458046913146973, "metricx_qe_score": 1.5514565706253052, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "pt", "output": "E o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9991304874420166, "xcomet_qe_score": 0.9943479299545288, "metricx_score": 1.0971180200576782, "metricx_qe_score": 1.6895017623901367, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "pt", "output": "Em este exemplo, o texto é o resumo da página da Wikipedia.", "metrics": {"bleu_score": 69.30977286178778, "chrf_score": 89.71868372270119, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4258562922477722, "metricx_qe_score": 0.4227108657360077, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "pt", "output": "Agora precisamos gerar ou extrair características do texto de recuperação.", "metrics": {"bleu_score": 47.90437745835814, "chrf_score": 79.70603546117493, "xcomet_score": 0.9220987558364868, "xcomet_qe_score": 0.91970294713974, "metricx_score": 4.391572952270508, "metricx_qe_score": 5.279175758361816, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "pt", "output": "Então, precisamos, nós precisamos de uma fase de extração de recursos, que inclui análise de texto.", "metrics": {"bleu_score": 42.0628882417221, "chrf_score": 71.78025869900088, "xcomet_score": 0.658117413520813, "xcomet_qe_score": 0.6872214078903198, "metricx_score": 8.275517463684082, "metricx_qe_score": 8.857158660888672, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "pt", "output": "E essa é a novidade principal deste artigo, e eu mergulhará profundamente nela nas próximas slides.", "metrics": {"bleu_score": 23.168097675687946, "chrf_score": 52.46504532648958, "xcomet_score": 0.7531716823577881, "xcomet_qe_score": 0.7350375652313232, "metricx_score": 5.645185470581055, "metricx_qe_score": 6.188587665557861, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "pt", "output": "Após a fase de extração de características, há uma fase de geração de características, quando usamos as características extratas para gerar um pequeno número de novas características.", "metrics": {"bleu_score": 72.02343877500252, "chrf_score": 93.16638864857869, "xcomet_score": 0.9566623568534851, "xcomet_qe_score": 0.9761689901351929, "metricx_score": 1.4430848360061646, "metricx_qe_score": 1.5136679410934448, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, gerar características em número de classes do conjunto de dados original.", "metrics": {"bleu_score": 62.628449627654696, "chrf_score": 84.74425586343294, "xcomet_score": 0.8969072103500366, "xcomet_qe_score": 0.8331257104873657, "metricx_score": 5.977558612823486, "metricx_qe_score": 9.06883716583252, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "pt", "output": "In this example, the original dataset has two classes.", "metrics": {"bleu_score": 8.139165682360764, "chrf_score": 32.13294995544994, "xcomet_score": 0.9810378551483154, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 23.675682067871094, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "pt", "output": "O primeiro gera duas novas características.", "metrics": {"bleu_score": 46.19993369945709, "chrf_score": 70.68478861320135, "xcomet_score": 0.7893723249435425, "xcomet_qe_score": 0.8181789517402649, "metricx_score": 8.302699089050293, "metricx_qe_score": 12.863316535949707, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "pt", "output": "But if the dataset has five classes, first generate five new features.", "metrics": {"bleu_score": 5.073216355122755, "chrf_score": 19.784907311094514, "xcomet_score": 0.5735441446304321, "xcomet_qe_score": 0.8261669278144836, "metricx_score": 25.0, "metricx_qe_score": 21.322607040405273, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "pt", "output": "Cada característica representa a probabilidade para cada classe.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9717273712158203, "xcomet_qe_score": 0.9597997665405273, "metricx_score": 0.9552944898605347, "metricx_qe_score": 1.6667594909667969, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "pt", "output": "Para analisar o texto, utilizamos a Corrente, o estado do arte da análise de texto, que são modelos de linguagem transformadores, como BERT, GPT, XLNET, etc.", "metrics": {"bleu_score": 41.44650159239492, "chrf_score": 70.35933674175894, "xcomet_score": 0.7509927749633789, "xcomet_qe_score": 0.7640377283096313, "metricx_score": 7.474427700042725, "metricx_qe_score": 7.497260570526123, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "pt", "output": "But it is not likely that we can train language model using the input datasets.", "metrics": {"bleu_score": 1.9046304733974748, "chrf_score": 19.204243360969606, "xcomet_score": 0.9517288208007812, "xcomet_qe_score": 0.9791598916053772, "metricx_score": 23.333328247070312, "metricx_qe_score": 16.250688552856445, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "pt", "output": "O AOE Arouche será uma tarefa alvo de refinamento.", "metrics": {"bleu_score": 4.206027236923763, "chrf_score": 22.588147413534987, "xcomet_score": 0.14355607330799103, "xcomet_qe_score": 0.16559463739395142, "metricx_score": 19.30768585205078, "metricx_qe_score": 19.51862907409668, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "pt", "output": "Então, na fase de extração de características, podemos baixar o modelo de linguagem treinado, ajustar o modelo de linguagem sobre o conjunto de dados-alvo.", "metrics": {"bleu_score": 60.75235870951837, "chrf_score": 73.36355889399957, "xcomet_score": 0.9260321855545044, "xcomet_qe_score": 0.9427114129066467, "metricx_score": 2.003185272216797, "metricx_qe_score": 2.2492430210113525, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "pt", "output": "Em este exemplo, para refinar o modelo de linguagem, para classificar texto em classes, abstrair em classes, baixo ou alto.", "metrics": {"bleu_score": 64.86932415130525, "chrf_score": 80.75213997571704, "xcomet_score": 0.6435387134552002, "xcomet_qe_score": 0.7421383261680603, "metricx_score": 6.770884990692139, "metricx_qe_score": 7.572078704833984, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "pt", "output": "Receba a saída do modelo de linguagem, que é a probabilidade para cada classe, e use como novas características.", "metrics": {"bleu_score": 87.25129388059685, "chrf_score": 96.98662149052207, "xcomet_score": 0.9643133282661438, "xcomet_qe_score": 0.8307157754898071, "metricx_score": 1.3659850358963013, "metricx_qe_score": 2.596106767654419, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "pt", "output": "O problema com este método é que o conjunto de dados pode ter poucas tags de entidades distintas.", "metrics": {"bleu_score": 24.515235346013313, "chrf_score": 62.04454739997372, "xcomet_score": 0.8722412586212158, "xcomet_qe_score": 0.8542349338531494, "metricx_score": 6.06424617767334, "metricx_qe_score": 6.105513572692871, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "pt", "output": "Em nosso experimento, quase metade dos conjuntos de dados contêm menos de quatrocentos amostras, e o conjunto de dados mais pequeno contém trinta e cinco amostras em seu conjunto de treinamento inicial.", "metrics": {"bleu_score": 36.79746482208511, "chrf_score": 76.41792320955841, "xcomet_score": 0.9684289693832397, "xcomet_qe_score": 0.9662657976150513, "metricx_score": 1.4958468675613403, "metricx_qe_score": 1.0421805381774902, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "pt", "output": "O ajuste fino de um modelo de linguagem sobre este conjunto de dados será ineficaz.", "metrics": {"bleu_score": 72.21600387198372, "chrf_score": 84.61716257431775, "xcomet_score": 0.996809720993042, "xcomet_qe_score": 0.9909964799880981, "metricx_score": 1.6983213424682617, "metricx_qe_score": 1.38753080368042, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "pt", "output": "Mas podemos usar conhecimento anterior sobre conjuntos de dados préanalizados.", "metrics": {"bleu_score": 48.326978309062206, "chrf_score": 76.86554201710443, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3914523124694824, "metricx_qe_score": 1.2653145790100098, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "pt", "output": "Because fast is we apply fast over a multiple data set, we can use the n minus one data sets to gather information about the n minus one data sets and use this information when we analyze the nth data set.", "metrics": {"bleu_score": 1.205256842736819, "chrf_score": 20.82955231469873, "xcomet_score": 0.5597710609436035, "xcomet_qe_score": 0.697043776512146, "metricx_score": 18.330520629882812, "metricx_qe_score": 11.449352264404297, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "pt", "output": "O que sugerimos é adicionar outra fase de ajuste fino.", "metrics": {"bleu_score": 77.72460244048297, "chrf_score": 89.31917135706651, "xcomet_score": 0.9141839742660522, "xcomet_qe_score": 0.841532826423645, "metricx_score": 0.7814561128616333, "metricx_qe_score": 0.962009847164154, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "pt", "output": "Eh, preliminary multitask fine-tuning phase.", "metrics": {"bleu_score": 5.693025330278465, "chrf_score": 38.022684550192025, "xcomet_score": 0.6793830394744873, "xcomet_qe_score": 0.9676158428192139, "metricx_score": 22.869029998779297, "metricx_qe_score": 11.607912063598633, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "pt", "output": "When you fine-tune the language model over n minus one datasets.", "metrics": {"bleu_score": 3.1364240458810366, "chrf_score": 26.79367148474132, "xcomet_score": 0.9857890605926514, "xcomet_qe_score": 1.0, "metricx_score": 20.036701202392578, "metricx_qe_score": 22.625808715820312, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "pt", "output": "E então executamos outra fase de refinamento fino, que é o refinamento de tarefas de alvo, quando refinamos o modelo de linguagem sobre o conjunto de dados de alvo nth.", "metrics": {"bleu_score": 24.348815628068586, "chrf_score": 54.57757393943877, "xcomet_score": 0.7268037796020508, "xcomet_qe_score": 0.7490497827529907, "metricx_score": 5.60096549987793, "metricx_qe_score": 6.314395904541016, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "pt", "output": "The state of the art in multitask multitask fine-tuning called mTDDNN.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 23.76130209175605, "xcomet_score": 0.6427782773971558, "xcomet_qe_score": 0.8520338535308838, "metricx_score": 16.586605072021484, "metricx_qe_score": 12.677755355834961, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "pt", "output": "In MT-DNN, MT-DNN maintains a heads in the number of tasks in the training set.", "metrics": {"bleu_score": 2.2869567780619007, "chrf_score": 18.30126394483682, "xcomet_score": 0.4548899829387665, "xcomet_qe_score": 0.8551366329193115, "metricx_score": 24.00334358215332, "metricx_qe_score": 20.923683166503906, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "pt", "output": "O em este exemplo, existem quatro tarefas no conjunto de treinamento, então mtcnn e manter quatro cabeças, como você pode ver na imagem.", "metrics": {"bleu_score": 41.7946399829907, "chrf_score": 71.48033805567214, "xcomet_score": 0.612354040145874, "xcomet_qe_score": 0.555341362953186, "metricx_score": 13.442876815795898, "metricx_qe_score": 13.84389591217041, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "pt", "output": "E é uma amostra aleatória de um lote do conjunto de treinamento.", "metrics": {"bleu_score": 35.416987661440594, "chrf_score": 76.47972399276992, "xcomet_score": 0.9385298490524292, "xcomet_qe_score": 0.8578618764877319, "metricx_score": 3.072854995727539, "metricx_qe_score": 3.6627583503723145, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "pt", "output": "E se o lote de execução pertence a, por exemplo, tarefas de classificação de sentenças singulares, é executar a regressão e a regressão para trás através da primeira cabeça.", "metrics": {"bleu_score": 25.988594137136722, "chrf_score": 53.919954864206034, "xcomet_score": 0.4510166645050049, "xcomet_qe_score": 0.5308574438095093, "metricx_score": 13.006845474243164, "metricx_qe_score": 12.05514144897461, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "pt", "output": "E se a lotação aleatória pertence à classificação parciais, a tarefa é executada em frente e em direção ao retrocesso através da última cabeça.", "metrics": {"bleu_score": 8.373989924102395, "chrf_score": 50.804385980528075, "xcomet_score": 0.4347342848777771, "xcomet_qe_score": 0.4691983163356781, "metricx_score": 12.123278617858887, "metricx_qe_score": 12.619728088378906, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "pt", "output": "Em nosso cenário, um conjunto de dados de tabela varia em número de classes.", "metrics": {"bleu_score": 24.677894099899667, "chrf_score": 62.35374557777115, "xcomet_score": 0.980689287185669, "xcomet_qe_score": 0.9254922866821289, "metricx_score": 4.7295122146606445, "metricx_qe_score": 4.453691482543945, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "pt", "output": "There are many tasks.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 17.8887650401633, "xcomet_score": 0.9789221286773682, "xcomet_qe_score": 1.0, "metricx_score": 9.85861873626709, "metricx_qe_score": 7.4903154373168945, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "pt", "output": "Mtdnn maintains the number of classes, heads, output layers.", "metrics": {"bleu_score": 7.410494411527525, "chrf_score": 21.58732782898818, "xcomet_score": 0.8738672733306885, "xcomet_qe_score": 0.9264624118804932, "metricx_score": 20.393810272216797, "metricx_qe_score": 13.584919929504395, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "pt", "output": "E, adicionalmente, o mttdnn precisa inicializar novos cabeços para um novo conjunto de dados com uma nova tarefa.", "metrics": {"bleu_score": 55.69799760599948, "chrf_score": 81.37852288167497, "xcomet_score": 0.912152886390686, "xcomet_qe_score": 0.9044010639190674, "metricx_score": 6.21122932434082, "metricx_qe_score": 5.672110557556152, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "pt", "output": "O nosso método, chamado de task reformation fine tuning, é que, em nosso método, task reformation fine tuning, em vez de manter vários cabeçalhos, reformulamos cada conjunto de dados em um problema de classificação de sentença por sentença, que é de duas classes, tarefas.", "metrics": {"bleu_score": 22.566387211500547, "chrf_score": 59.82693355579075, "xcomet_score": 0.3331226110458374, "xcomet_qe_score": 0.4284542202949524, "metricx_score": 19.811243057250977, "metricx_qe_score": 18.339872360229492, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "pt", "output": "Então vamos ver um exemplo.", "metrics": {"bleu_score": 50.81327481546149, "chrf_score": 87.75875830279179, "xcomet_score": 0.9956358671188354, "xcomet_qe_score": 1.0, "metricx_score": 0.02680397778749466, "metricx_qe_score": 0.0, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui está o nosso conjunto de dados de entrada, que consiste em entidades, características, texto e classes.", "metrics": {"bleu_score": 86.56030552541704, "chrf_score": 96.91780786384557, "xcomet_score": 0.9991762638092041, "xcomet_qe_score": 0.9946451187133789, "metricx_score": 1.7182714939117432, "metricx_qe_score": 3.896151542663574, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "pt", "output": "E reformular a tarefa de classificar o texto em baixo e alto para classificar o texto, o resumo e a classe em verdadeiro ou falso.", "metrics": {"bleu_score": 43.217006636770996, "chrf_score": 72.48872779741076, "xcomet_score": 0.7399364709854126, "xcomet_qe_score": 0.6291412115097046, "metricx_score": 6.392199993133545, "metricx_qe_score": 5.725299835205078, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "pt", "output": "Em outras palavras, treinamos o modelo de linguagem para classificar uma classe abstrata em uma classe abstrata, se a abstração pertence à classe ou não.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 73.03637161460446, "xcomet_score": 0.5232927799224854, "xcomet_qe_score": 0.4181816577911377, "metricx_score": 9.149572372436523, "metricx_qe_score": 9.312726974487305, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "pt", "output": "Então, o vetor de rótulo em seis casos, permanece sempre, que consiste sempre em duas classes.", "metrics": {"bleu_score": 41.54794556635242, "chrf_score": 70.4341298908974, "xcomet_score": 0.6570233106613159, "xcomet_qe_score": 0.6520050764083862, "metricx_score": 15.046028137207031, "metricx_qe_score": 17.732946395874023, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "pt", "output": "E este é o algoritmo para o nosso refinamento refinado, refinamento refinado.", "metrics": {"bleu_score": 36.362270465000705, "chrf_score": 47.33549969085287, "xcomet_score": 0.508865237236023, "xcomet_qe_score": 0.4715854823589325, "metricx_score": 16.35264778137207, "metricx_qe_score": 18.913732528686523, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "pt", "output": "O vamos ver o quadro completo.", "metrics": {"bleu_score": 12.600736402830258, "chrf_score": 36.67664177007603, "xcomet_score": 0.8813384175300598, "xcomet_qe_score": 0.8970126509666443, "metricx_score": 6.742892265319824, "metricx_qe_score": 5.9235734939575195, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "pt", "output": "A dataset foi adicionado muito rápido.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 15.310361681329423, "xcomet_score": 0.20992308855056763, "xcomet_qe_score": 0.47263190150260925, "metricx_score": 15.95783519744873, "metricx_qe_score": 17.195247650146484, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "pt", "output": "E então uma fase rápida de execução e vinculação de entidades.", "metrics": {"bleu_score": 8.516593018819643, "chrf_score": 32.94302693904281, "xcomet_score": 0.790056049823761, "xcomet_qe_score": 0.829919695854187, "metricx_score": 13.546407699584961, "metricx_qe_score": 15.298686027526855, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "pt", "output": "Extrair o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipedia.", "metrics": {"bleu_score": 84.04350178700108, "chrf_score": 91.70958492371057, "xcomet_score": 0.9267157316207886, "xcomet_qe_score": 0.8576064109802246, "metricx_score": 4.415221691131592, "metricx_qe_score": 5.82192325592041, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "pt", "output": "Então, reformula a tarefa em uma tarefa de classificação de sentença por sentença.", "metrics": {"bleu_score": 8.225964699966553, "chrf_score": 53.54593189238022, "xcomet_score": 0.7770504951477051, "xcomet_qe_score": 0.7457367181777954, "metricx_score": 3.6418676376342773, "metricx_qe_score": 2.888376235961914, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "pt", "output": "Apply the language model to the new task and output likelihood for each class.", "metrics": {"bleu_score": 2.299921972415939, "chrf_score": 23.926058357037377, "xcomet_score": 0.7888506650924683, "xcomet_qe_score": 0.9645982980728149, "metricx_score": 22.533832550048828, "metricx_qe_score": 15.389891624450684, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "pt", "output": "Note that the language model is already fine-tuned over n minus one dataset using a preliminary multitask fine-tuning.", "metrics": {"bleu_score": 1.8504430829513174, "chrf_score": 30.49972980110821, "xcomet_score": 0.8748942613601685, "xcomet_qe_score": 0.9719771146774292, "metricx_score": 22.140565872192383, "metricx_qe_score": 9.107836723327637, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "pt", "output": "Então usamos o vetor de saída do modelo de linguagem como uma nova característica gerada no número de classes.", "metrics": {"bleu_score": 57.75794695208399, "chrf_score": 69.81725870274393, "xcomet_score": 0.956791877746582, "xcomet_qe_score": 0.9495581388473511, "metricx_score": 4.941411018371582, "metricx_qe_score": 7.128499984741211, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "pt", "output": "Para avaliar o nosso framework, usamos um conjunto de dados de classificação de 17 tabelas, que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.", "metrics": {"bleu_score": 54.480536098587315, "chrf_score": 74.65358807173811, "xcomet_score": 0.8144924640655518, "xcomet_qe_score": 0.9234490990638733, "metricx_score": 6.069663047790527, "metricx_qe_score": 5.648368835449219, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "pt", "output": "E como base de conhecimento, usamos Wikipedia.", "metrics": {"bleu_score": 67.16877364745231, "chrf_score": 82.27653295322767, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6995202898979187, "metricx_qe_score": 0.6540882587432861, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "pt", "output": "Designamos o nosso experimento como a avaliação leave one out, quando treinamos rapidamente em 16 conjuntos de dados e apliquemos ao 17º conjunto de dados.", "metrics": {"bleu_score": 16.28175249604241, "chrf_score": 44.378389051516905, "xcomet_score": 0.46956899762153625, "xcomet_qe_score": 0.45020291209220886, "metricx_score": 10.311117172241211, "metricx_qe_score": 9.62061595916748, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "pt", "output": "Também dividimos cada conjunto de dados em uma falha e aplicamos uma validação cruzada de falhas.", "metrics": {"bleu_score": 44.39719086407068, "chrf_score": 68.92873908040075, "xcomet_score": 0.6136541366577148, "xcomet_qe_score": 0.6433744430541992, "metricx_score": 16.414003372192383, "metricx_qe_score": 18.364662170410156, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "pt", "output": "Então, geramos a nova característica e avaliamos usando cinco classificadores de avaliação.", "metrics": {"bleu_score": 35.13098711506864, "chrf_score": 71.38654539851095, "xcomet_score": 0.9836387634277344, "xcomet_qe_score": 0.963677167892456, "metricx_score": 2.5694823265075684, "metricx_qe_score": 4.618771553039551, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "pt", "output": "We use in our experiment based bird based architecture.", "metrics": {"bleu_score": 3.435488317233919, "chrf_score": 21.902560823235383, "xcomet_score": 0.3485078513622284, "xcomet_qe_score": 0.781181275844574, "metricx_score": 22.08793830871582, "metricx_qe_score": 15.360763549804688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui estão os resultados de nosso experimento.", "metrics": {"bleu_score": 32.260135189272866, "chrf_score": 56.31909204442126, "xcomet_score": 0.9903225898742676, "xcomet_qe_score": 0.9908181428909302, "metricx_score": 0.37161940336227417, "metricx_qe_score": 0.08214030414819717, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "pt", "output": "Você pode ver que comparamos nosso framework com a tarefa de ajuste fino de um conjunto de dados de destino, ajuste fino de uma tarefa de destino e ajuste fino preliminar de MTDNN.", "metrics": {"bleu_score": 33.119611051319666, "chrf_score": 69.11786412662518, "xcomet_score": 0.599018931388855, "xcomet_qe_score": 0.7271432876586914, "metricx_score": 6.0105695724487305, "metricx_qe_score": 5.297331809997559, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "pt", "output": "E a nossa reformulação e refinamento alcançam o melhor resultado, a melhor performance.", "metrics": {"bleu_score": 18.92240568795936, "chrf_score": 51.86806512615295, "xcomet_score": 0.9802292585372925, "xcomet_qe_score": 1.0, "metricx_score": 4.465185642242432, "metricx_qe_score": 4.292768955230713, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "pt", "output": "While mtdnn achieved two percent improvement over the target dataset fine-tuning.", "metrics": {"bleu_score": 1.5996686545912897, "chrf_score": 12.415840833379638, "xcomet_score": 0.8905283212661743, "xcomet_qe_score": 0.9351884722709656, "metricx_score": 25.0, "metricx_qe_score": 24.826032638549805, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "pt", "output": "Our poach achieved six percent improvement.", "metrics": {"bleu_score": 3.708659055657029, "chrf_score": 14.429288289380176, "xcomet_score": 0.6143491268157959, "xcomet_qe_score": 0.8074094653129578, "metricx_score": 25.0, "metricx_qe_score": 23.202058792114258, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "pt", "output": "Quando olhamos no pequeno conjunto de dados, podemos ver que o desempenho de mtcnn diminui e a melhoria da fase de multi-task fine-tuning preliminar diminui para 1.5 por cento.", "metrics": {"bleu_score": 52.192851128807135, "chrf_score": 73.68836165260345, "xcomet_score": 0.7294816970825195, "xcomet_qe_score": 0.7065491676330566, "metricx_score": 8.978926658630371, "metricx_qe_score": 9.997986793518066, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "pt", "output": "\"but our performance increased to eleven percent compared to the target task fine-tuning alone.\"", "metrics": {"bleu_score": 1.9169807603100912, "chrf_score": 20.119169679464846, "xcomet_score": 0.9278779029846191, "xcomet_qe_score": 0.935457706451416, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "pt", "output": "Para somar, fast permite a enriquecimento de fewshot a partir de trinta e cinco amostras em nosso experimento.", "metrics": {"bleu_score": 32.004580793050366, "chrf_score": 55.81289914073078, "xcomet_score": 0.37263718247413635, "xcomet_qe_score": 0.39184561371803284, "metricx_score": 14.753878593444824, "metricx_qe_score": 13.13216495513916, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "pt", "output": "Usa uma arquitetura para todos os conjuntos de dados de tarefas.", "metrics": {"bleu_score": 32.649710286280516, "chrf_score": 79.22919672885513, "xcomet_score": 0.9688006639480591, "xcomet_qe_score": 0.9576547145843506, "metricx_score": 4.0187811851501465, "metricx_qe_score": 4.233893394470215, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "pt", "output": "E ele mantém a cabeça do modelo.", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 57.435995164256035, "xcomet_score": 0.8014741539955139, "xcomet_qe_score": 0.828023374080658, "metricx_score": 6.213772773742676, "metricx_qe_score": 7.367697238922119, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "pt", "output": "But it adds a reformulation phase.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 29.00397525686319, "xcomet_score": 0.8718012571334839, "xcomet_qe_score": 0.9968031644821167, "metricx_score": 23.459108352661133, "metricx_qe_score": 17.69023323059082, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "pt", "output": "É um conjunto de treinamento aumentado e precisa de um valor alvo com significado semântico para que possamos alimentá-lo no modelo de linguagem e utilizá-lo no problema de classificação de frases por pares.", "metrics": {"bleu_score": 52.64600205808348, "chrf_score": 80.26248782615394, "xcomet_score": 0.759675145149231, "xcomet_qe_score": 0.7058112621307373, "metricx_score": 5.603975296020508, "metricx_qe_score": 5.444166660308838, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "pt", "output": "Obrigado.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14589540660381317, "metricx_qe_score": 0.24346594512462616, "linguapy_score": [0, "PORTUGUESE"]}}
