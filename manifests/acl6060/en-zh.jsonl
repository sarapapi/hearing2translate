{"dataset_id": "acl_6060", "sample_id": 0, "src_audio": "/acl6060/audio/dev/0.wav", "src_ref": "Hi, this is Elena and I'm going to be presenting our work, Detecting Unassimilated Borrowings in Spanish: An Annotated Corpus and Approaches to Modeling.", "tgt_ref": "大家好，我是Elena，我将向大家介绍我们的工作——检测西班牙语中的未同化借词：注释语料库和建模方法。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_audio": "/acl6060/audio/dev/1.wav", "src_ref": "So we're going to be covering what lexical borrowing is, the task that we proposed, the dataset that we have released and some models that we explored.", "tgt_ref": "我们将讨论什么是词汇借用、我们提出的任务、我们已经发布的数据集，以及我们探索的一些模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_audio": "/acl6060/audio/dev/2.wav", "src_ref": "But to begin with, what is lexical borrowing and why it matters as an NLP task?", "tgt_ref": "首先，什么是词汇借用，为什么它作为一个自然语言处理任务很重要？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_audio": "/acl6060/audio/dev/3.wav", "src_ref": "Well, lexical borrowing is basically the incorporation of words from one language into another language.", "tgt_ref": "总的来说，词汇借用是将一种语言的单词并入另一种语言中。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_audio": "/acl6060/audio/dev/4.wav", "src_ref": "For instance, in Spanish we use words that come from English.", "tgt_ref": "例如，在西班牙语中，我们会使用来自英语的单词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_audio": "/acl6060/audio/dev/5.wav", "src_ref": "And here you have a few examples, words such as podcast, app, and online crowdfunding, all these are English words that we sometimes use in Spanish.", "tgt_ref": "这里有几个例子，比如podcast、app和online crowdfunding等单词，所有这些都是我们有时会在西班牙语中使用的英语单词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_audio": "/acl6060/audio/dev/6.wav", "src_ref": "Lexical borrowing is a type of linguistic borrowing um which is basically reproducing in one language patterns of other languages.", "tgt_ref": "词汇借用是一种语言学借用，本质上是在一种语言中再现其他语言的模式。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_audio": "/acl6060/audio/dev/7.wav", "src_ref": "And borrowing and code switching have sometimes been compared and described as a continuum, code switching being ah the thing that bilinguals do where they mix two languages at the same time.", "tgt_ref": "借用和语码转换有时会被比较并被描述为一个连续体，语码转换就是双语者同时混合两种语言时所做的事情。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_audio": "/acl6060/audio/dev/8.wav", "src_ref": "There are however some differences between lexical borrowing and code-switching.", "tgt_ref": "然而，词汇借用和语码转换之间存在一些差异。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_audio": "/acl6060/audio/dev/9.wav", "src_ref": "We're going to be focusing on lexical borrowing.", "tgt_ref": "我们将重点讨论词汇借用。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_audio": "/acl6060/audio/dev/10.wav", "src_ref": "Code switching is something that is done by bilinguals and by definition the code switches are not integrated into any of the languages in use, whereas lexical borrowing is something that is also done by monolinguals.", "tgt_ref": "语码转换是由双语者完成的，根据定义，语码转换并没有融入到任何一种正在使用的语言中，而词汇借用也可以由单语者完成。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_audio": "/acl6060/audio/dev/11.wav", "src_ref": "The borrowings will comply with the grammar of the recipient language.", "tgt_ref": "借词要符合接受者语言的语法。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_audio": "/acl6060/audio/dev/12.wav", "src_ref": "And borrowings can eventually be integrated into the recipient language.", "tgt_ref": "借词最终可以融入到接受者的语言中。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_audio": "/acl6060/audio/dev/13.wav", "src_ref": "So why is borrowing an interesting phenomenon?", "tgt_ref": "那么，为什么说借词是一种有趣的现象呢？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_audio": "/acl6060/audio/dev/14.wav", "src_ref": "Well, from the point of view of linguistics, borrowing is a manifestation of of how languages change and how they interact.", "tgt_ref": "从语言学的角度来看，借词是语言如何变化以及它们如何相互作用的一种表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_audio": "/acl6060/audio/dev/15.wav", "src_ref": "And also lexical borrowings are a source of new words.", "tgt_ref": "而且词汇借用也是新词的来源之一。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_audio": "/acl6060/audio/dev/16.wav", "src_ref": "Here you have some examples of lexical borrowings that have been incorporated into the Spanish language as new words.", "tgt_ref": "这里有一些词汇借用的例子，这些借词已经作为新词融入到西班牙语语言中。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_audio": "/acl6060/audio/dev/17.wav", "src_ref": "In terms of NLP ah borrowings are a common source of out-of-vocabulary words.", "tgt_ref": "就自然语言处理而言，借词是词汇单词之外的一个常见来源。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_audio": "/acl6060/audio/dev/18.wav", "src_ref": "And in fact, automatically detecting lexical borrowings ah has proven to be useful for NLP downstream tasks such as parsing, text-to-speech synthesis or machine translation.", "tgt_ref": "而事实上，自动地检测词汇借用已被证明对自然语言处理下游任务有用，例如解析、文本-语音合成或机器翻译。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_audio": "/acl6060/audio/dev/19.wav", "src_ref": "There has been a growing interest in the influence of English on other languages ah particularly ah related to English lexical borrowings, borrowings which sometimes have been called Anglicisms.", "tgt_ref": "人们越来越关注英语对其他语言的影响，尤其是与英语词汇借用有关的影响，这些借词有时被称为英语的借词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_audio": "/acl6060/audio/dev/20.wav", "src_ref": "And here, you have some examples of ah work on automatic detection of borrowings in ah some of these languages.", "tgt_ref": "在这里，我们举了一些关于这些语言中借词的自动检测工作的例子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_audio": "/acl6060/audio/dev/21.wav", "src_ref": "So the task that we propose is to detect unassimilated lexical borrowings in Spanish newswire.", "tgt_ref": "因此，我们提出的任务是检测西班牙语新闻专线中未同化的词汇借用。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_audio": "/acl6060/audio/dev/22.wav", "src_ref": "Which means that we are interested in extracting ah words borrowed from other languages that are being used in Spanish newspapers but that have not been integrated or assimilated into the recipient language.", "tgt_ref": "也就是说，我们感兴趣的是提取从其他语言中借用的单词，这些单词正在西班牙语报纸中使用，但尚未融入或同化到接收者的语言中。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_audio": "/acl6060/audio/dev/23.wav", "src_ref": "So not yet integrated into Spanish.", "tgt_ref": "所以还没有融入西班牙语。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_audio": "/acl6060/audio/dev/24.wav", "src_ref": "Here you have an example.", "tgt_ref": "让我来举个例子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_audio": "/acl6060/audio/dev/25.wav", "src_ref": "This is a sentence in Spanish: Las prendas bestsellers se estampan con motivos florales, animal print o retales tipo patchwork.", "tgt_ref": "这是一个西班牙语的句子：Las Prendas Bestsellers Se estampan con motivos florales，Animal print o retales tipo patchwork.", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_audio": "/acl6060/audio/dev/26.wav", "src_ref": "Um, and as you can see, there are three spans of texts which are actually English words like bestseller, animal print and patchwork.", "tgt_ref": "嗯，正如大家所看到的，有三个跨度的文本实际上是英语单词，比如bestseller、animal print和patchwork。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_audio": "/acl6060/audio/dev/27.wav", "src_ref": "These are the type of spans that we are interested in extracting and detecting.", "tgt_ref": "这些是我们所感兴趣的提取和检测的跨度类型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_audio": "/acl6060/audio/dev/28.wav", "src_ref": "There has been previous word on Anglicism detection ah which consists consisted of a CRF model for Anglicism detection on Spanish Newswire.", "tgt_ref": "之前已经有关于英语检测的单词，由西班牙语新闻专线上用于英语检测的CRF模型组成。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_audio": "/acl6060/audio/dev/29.wav", "src_ref": "This model achieved an F1 score of eighty six.", "tgt_ref": "这个模型取得了86分的F1分数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_audio": "/acl6060/audio/dev/30.wav", "src_ref": "But there were some limitations both um in the dataset and the modeling approach.", "tgt_ref": "但是在数据集和建模方法方面都有一些局限性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_audio": "/acl6060/audio/dev/31.wav", "src_ref": "So the dataset focused exclusively on one source of news, consisted only of headlines.", "tgt_ref": "该数据集只关注新闻的一个来源，并且仅包含头条新闻。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_audio": "/acl6060/audio/dev/32.wav", "src_ref": "And also there was an overlap in the borrowings that appear in the training set and the test set.", "tgt_ref": "此外，在训练集和测试集中出现的借词也有重叠。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_audio": "/acl6060/audio/dev/33.wav", "src_ref": "This prevented the assessment of whether the modeling approach could actually generalize to previously unseen borrowings.", "tgt_ref": "这使我们无法评估建模方法是否可以实际概括到以前未见过的借词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_audio": "/acl6060/audio/dev/34.wav", "src_ref": "So what we aim is to tackle some of these limitations in the task.", "tgt_ref": "因此，我们的目标是解决任务中的一些局限性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_audio": "/acl6060/audio/dev/35.wav", "src_ref": "So to begin we, to begin with, we created a new dataset.", "tgt_ref": "为此，首先我们创建了一个新的数据集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_audio": "/acl6060/audio/dev/36.wav", "src_ref": "Ah the aim at a new dataset that was annotated with lexical borrowings and the aim was to create a test set that was as difficult as possible.", "tgt_ref": "我们的目标是创建一个新的数据集，该数据集使用词汇借词进行注释，目的是创建一个尽可能困难的测试集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_audio": "/acl6060/audio/dev/37.wav", "src_ref": "So there would be minimal overlap in words and topics between the training set and test set.", "tgt_ref": "因此，训练集和测试集之间的单词和主题的重叠程度会很小。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_audio": "/acl6060/audio/dev/38.wav", "src_ref": "And as a result, well, the test set comes from sources and dates that we're not seeing in the training set.", "tgt_ref": "因此，测试集来自我们在训练集中看不到的来源和日期。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_audio": "/acl6060/audio/dev/39.wav", "src_ref": "Here you can see that there's no overlap in the in the time.", "tgt_ref": "在这里大家可以看到，在时间上没有重叠。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_audio": "/acl6060/audio/dev/40.wav", "src_ref": "It's also, the test set is also very borrowing-dense.", "tgt_ref": "而且，测试集的借词密度也很高。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_audio": "/acl6060/audio/dev/41.wav", "src_ref": "Just to give you some numbers, if the training set contains six borrowings per each thousand tokens, the test set contained twenty borrowings per each thousand tokens.", "tgt_ref": "给大家看一些数字：如果训练集每1000个令牌包含6六个借词，那么测试集每1000个令牌包含20个借词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_audio": "/acl6060/audio/dev/42.wav", "src_ref": "The test set contained as many out of vocabulary words as possible.", "tgt_ref": "测试集包含了尽可能多的词汇表外的单词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_audio": "/acl6060/audio/dev/43.wav", "src_ref": "In fact, ninety two percent of the borrowings in the test set are OOV.", "tgt_ref": "事实上，测试集中92%的借词都是OOV。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_audio": "/acl6060/audio/dev/44.wav", "src_ref": "So, they were not seen during training.", "tgt_ref": "因此，在训练期间看不到它们。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_audio": "/acl6060/audio/dev/45.wav", "src_ref": "And the corpus consisted basically of a collection of texts that came from different sources of Spanish newspapers.", "tgt_ref": "而语料库总的来说是由来自不同来源的西班牙报纸的文本集合而成的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_audio": "/acl6060/audio/dev/46.wav", "src_ref": "And ah it was annotated by hand ah using two tags.", "tgt_ref": "而且它是用两个标签手工注释的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_audio": "/acl6060/audio/dev/47.wav", "src_ref": "One for English lexical borrowings which is the majority of lexical borrowings in Spanish, and then the label other for borrowings from other languages.", "tgt_ref": "一个标签用于注释英语词汇借词，这是西班牙语中的大多数词汇借词，然后另一个标签用于注释来自其他语言的借词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_audio": "/acl6060/audio/dev/48.wav", "src_ref": "We use CONLL formats and we used BIO encoding so that we could encode ah single token borrowings such as app or multi token borrowings such as machine learning.", "tgt_ref": "我们使用CONLL格式和BIO编码，这样我们就可以编码单个令牌借词，比如app，或多个令牌借词，比如machine learning。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_audio": "/acl6060/audio/dev/49.wav", "src_ref": "These are the numbers of the corpus.", "tgt_ref": "这些是语料库的数字。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_audio": "/acl6060/audio/dev/50.wav", "src_ref": "As you can see, it amounts to roughly three hundred seventy thousand tokens.", "tgt_ref": "如大家所见，这相当于大约有37万个令牌。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_audio": "/acl6060/audio/dev/51.wav", "src_ref": "And here you have the number of spans that were labeled as English and the spans that were labeled as other borrowings and how many of them were unique.", "tgt_ref": "这包含了被标记为英语的跨度数量和标记为其他借词的跨度数量，以及它们中有多少是独一无二的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_audio": "/acl6060/audio/dev/52.wav", "src_ref": "And here you have a couple of examples of the of the set of the dataset.", "tgt_ref": "这里有几个关于数据集集合的例子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_audio": "/acl6060/audio/dev/53.wav", "src_ref": "As you can see for instance here, we have ah in the first example, we have the borrowing batch cooking which is a multi word borrowing.", "tgt_ref": "正如大家所看到的，例如，在第一个例子中，我们有一个借词的批处理，这是一个多单词借词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_audio": "/acl6060/audio/dev/54.wav", "src_ref": "And we have annotated it using the BIO um encode.", "tgt_ref": "而且我们已经使用BIO编码对其进行了注释。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_audio": "/acl6060/audio/dev/55.wav", "src_ref": "So the BIO was used for words in Spanish so not for words that were not borrowed.", "tgt_ref": "因此，BIO用于西班牙语中的单词，而不是用于未借用的单词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_audio": "/acl6060/audio/dev/56.wav", "src_ref": "And here in this second example, you have benching and crash which are also labeled as borrowings from English.", "tgt_ref": "在这个第二个例子中，大家可以看到benching和crash这两个词也被标记为是从英语借来的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_audio": "/acl6060/audio/dev/57.wav", "src_ref": "So, once we had the dataset, we explored several models for the task of extracting and detecting these lexical borrowings.", "tgt_ref": "因此，一旦我们拥有了数据集，我们就为提取和检测这些词汇借词的任务探索了几个模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_audio": "/acl6060/audio/dev/58.wav", "src_ref": "The first one that we tried was the conditional random field model.", "tgt_ref": "我们首先尝试的是条件随机场模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_audio": "/acl6060/audio/dev/59.wav", "src_ref": "Ah, this was the model that had been used on previous work.", "tgt_ref": "这是在之前工作中使用过的模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_audio": "/acl6060/audio/dev/60.wav", "src_ref": "And we used the same handcrafted features from that from those from that work.", "tgt_ref": "我们使用了与那次工作中相同的手工制作的特征。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_audio": "/acl6060/audio/dev/61.wav", "src_ref": "As you can see, these are the features.", "tgt_ref": "如大家所见，这些都是特征。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_audio": "/acl6060/audio/dev/62.wav", "src_ref": "These are binary features such as the word or the token in upper case?", "tgt_ref": "这些都是二进制特征，例如大写的单词或令牌？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_audio": "/acl6060/audio/dev/63.wav", "src_ref": "Is it title titlecase?", "tgt_ref": "是标题标签吗？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_audio": "/acl6060/audio/dev/64.wav", "src_ref": "Is it a quotation mark?", "tgt_ref": "是引号吗？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_audio": "/acl6060/audio/dev/65.wav", "src_ref": "Things like that, which are the type of features that one would expect in a named entity recognition task.", "tgt_ref": "诸如此类的东西，这是人们在命名实体识别任务中所期望的特征类型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_audio": "/acl6060/audio/dev/66.wav", "src_ref": "These are the results that we got.", "tgt_ref": "这就是我们得到的结果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_audio": "/acl6060/audio/dev/67.wav", "src_ref": "We obtain fifty five F1 score using the the CRF model with handcrafted features.", "tgt_ref": "我们使用具有手工制作特征的CRF模型获得55分的F1分数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_audio": "/acl6060/audio/dev/68.wav", "src_ref": "Which is a huge different difference um compared to the reported F1 score of eighty six, which was the result obtained with the same CRF model, same features but on a different dataset also for Spanish lexical borrowing detection.", "tgt_ref": "与报告的86分F1分数相比，这是一个巨大的差异，F1分数是用相同的CRF模型，相同的特征，但是在不同的数据集上获得的结果，也用于西班牙语词汇借用检测。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_audio": "/acl6060/audio/dev/69.wav", "src_ref": "So, this proves that the dataset that we created is more difficult and that we needed to explore more sophisticated models for these tasks.", "tgt_ref": "因此，这证明了我们创建的数据集更加困难，我们需要探索更复杂的模型用于这些任务。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_audio": "/acl6060/audio/dev/70.wav", "src_ref": "So, we tested two transformer based models.", "tgt_ref": "因此，我们测试了两个基于转换器的模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_audio": "/acl6060/audio/dev/71.wav", "src_ref": "We used BETO which is a monolingual BERT model trained for Spanish and also multilingual BERT.", "tgt_ref": "我们使用了BETO，这是一个单语BERT模型，针对西班牙语和多语言BERT训练的模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_audio": "/acl6060/audio/dev/72.wav", "src_ref": "Both models we use them through the transformers library by HuggingFace.", "tgt_ref": "我们通过HuggingFace的转换器库使用这两个模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_audio": "/acl6060/audio/dev/73.wav", "src_ref": "These are the results that we got.", "tgt_ref": "这就是我们得到的结果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_audio": "/acl6060/audio/dev/74.wav", "src_ref": "As you can see, multilingual BERT performs better than BETO both on the development set and on the test set and across all metrics.", "tgt_ref": "正如大家所看到的，多语言BERT在开发集和测试集以及所有指标上的表现都优于BETO。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_audio": "/acl6060/audio/dev/75.wav", "src_ref": "Just so we have ah an idea to compare, the CRF model obtained an eighty two.", "tgt_ref": "正因为如此，我们有了一个比较的想法，CRF模型获得了82分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_audio": "/acl6060/audio/dev/76.wav", "src_ref": "The CRF model obtained a fifty five obtained a fifty five F1 score, whereas the multilingual BERT obtained eighty two, which is a big difference.", "tgt_ref": "CRF模型获得了55分，获得了55分的F1分数，而多语言BERT获得了82分，这是一个很大的差异。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_audio": "/acl6060/audio/dev/77.wav", "src_ref": "So, once that we had those results, we asked ourselves another question which is, could we find a BiLSTM-CRF model, feed it with different types of embeddings, embeddings that encode different types of linguistic information and perform outperform the results obtained by transformer based models?", "tgt_ref": "所以，一旦我们得到了这些结果，我们就会问自己另一个问题，那就是，我们能否找到一个BiLSTM-CRF模型，为它提供不同类型的嵌入，嵌入对不同类型的语言信息进行编码，并执行优于基于转换器的模型获得的结果？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_audio": "/acl6060/audio/dev/78.wav", "src_ref": "So in order to do so, we ran some preliminary experiments, we we run this by BiLSTM-CRF model using flare library.", "tgt_ref": "因此，为了做到这一点，我们进行了一些初步实验，我们使用flare库通过BiLSTM-CRF模型运行这些实验。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_audio": "/acl6060/audio/dev/79.wav", "src_ref": "And we tried experimented with different type of embeddings like transformer-based but also fast-text, character embeddings, and so on.", "tgt_ref": "我们尝试了不同类型的嵌入，比如基于转换器但也是快速的文本、字符嵌入等等。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_audio": "/acl6060/audio/dev/80.wav", "src_ref": "What we found out was that transformer-based embeddings performed better than non contextualized embeddings, that the combination of English BERT and Spanish BETO embeddings outperform multilingual BERT embeddings.", "tgt_ref": "我们发现，基于转换器的嵌入比非情境化的嵌入表现得更好，英语BERT和西班牙语BETO嵌入的组合比多语言BERT嵌入表现得更好。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_audio": "/acl6060/audio/dev/81.wav", "src_ref": "And that BPE embeddings produced better F1 and character embeddings produce better recall.", "tgt_ref": "BPE嵌入产生了更好的F1，字符嵌入产生了更好的调用。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_audio": "/acl6060/audio/dev/82.wav", "src_ref": "With that in mind, these were the best performing results that we got.", "tgt_ref": "考虑到这一点，这些是我们获得的表现最好的结果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_audio": "/acl6060/audio/dev/83.wav", "src_ref": "Both models were BiLSTM-CRF models using flare.", "tgt_ref": "两个模型均为使用flare的BiLSTM-CRF模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_audio": "/acl6060/audio/dev/84.wav", "src_ref": "One was fed with BETO and BERT embeddings and BPE, and the other one BETO and BERT embeddings and BPE and also character embeddings.", "tgt_ref": "一个是BETO和BERT 嵌入和BPE，另一个是BETO和BERT嵌入和BPE，还有字符嵌入。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_audio": "/acl6060/audio/dev/85.wav", "src_ref": "This last one was the one that produced the highest F1 score on the test set, although the highest score on the development set was obtained by the one without character embeddings.", "tgt_ref": "最后一个是在测试集上产生最高F1分数的那个，尽管在开发集上的最高分数是由没有字符嵌入的那个获得的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_audio": "/acl6060/audio/dev/86.wav", "src_ref": "Just ah to bear in mind that the best result that we got with multilingual BERT obtained an F1 of seventy six on the development set and eighty two on the test set.", "tgt_ref": "请记住，我们使用多语言BERT获得的最佳结果是在开发集中获得了76分的F1分数，在测试集中获得了82分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_audio": "/acl6060/audio/dev/87.wav", "src_ref": "So this is an improvement compared to those results.", "tgt_ref": "因此，与那些结果相比，这是一种进步。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_audio": "/acl6060/audio/dev/88.wav", "src_ref": "Finally, we asked ourselves another question which was can lexical borrowing detection be framed as transfer learning from language identification in code switching?", "tgt_ref": "最后，我们问了自己另一个问题，那就是在语码转换中，词汇借用检测能否被框定为语言识别的迁移学习？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_audio": "/acl6060/audio/dev/89.wav", "src_ref": "So, we run the same BiLSTM-CRF model that we had run using flare, but instead of using these unadapted transformer-based BETO and BERT embeddings, we used code switch embeddings.", "tgt_ref": "因此，我们运行了使用flare运行的相同的BiLSTM-CRF模型，但我们使用了语码转换嵌入，而不是使用这些未调整的基于转换器的BETO和BERT嵌入。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_audio": "/acl6060/audio/dev/90.wav", "src_ref": "What are code switch embeddings?", "tgt_ref": "什么是语码转换嵌入？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_audio": "/acl6060/audio/dev/91.wav", "src_ref": "Well these are um embeddings that are have been fine tuned transformer-based embeddings that have been pretrained for language identification on the Spanish English section of the LinCE code switching dataset.", "tgt_ref": "这些是经过微调的基于转换器的嵌入，这些嵌入已经在LinCE语码转换数据集的西班牙语英语部分经过预训练 用于 语言识别。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_audio": "/acl6060/audio/dev/92.wav", "src_ref": "LinCE is a dataset on code switching that has a section on Spanish English, Spanish English code switching.", "tgt_ref": "LinCE是一个关于语码转换的数据集，其中有一个关于西班牙语英语，西班牙语英语语码转换的部分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_audio": "/acl6060/audio/dev/93.wav", "src_ref": "So we fed our BiLSTM-CRF with code switch embeddings and optionally character embeddings, BPE embeddings and so on.", "tgt_ref": "因此，我们给我们的BiLSTM-CRF提供了语码转换嵌入和可选的字符嵌入、BPE嵌入等等。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_audio": "/acl6060/audio/dev/94.wav", "src_ref": "The best result that we got was eighty four point twenty two, which is the highest across all the models that we tried on the test set.", "tgt_ref": "我们得到的最好结果是84.22分，这是我们在测试集上尝试的所有模型中最高的分数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_audio": "/acl6060/audio/dev/95.wav", "src_ref": "Although the best result F1 score that we got on the development set, which was seventy nine, was lower than the best result obtained by the BiLSTM-CRF fed with unadapted embeddings.", "tgt_ref": "尽管我们在开发集上获得的最好结果F1评分为79分，低于使用未调整嵌入的BiLSTM-CRF获得的最好结果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_audio": "/acl6060/audio/dev/96.wav", "src_ref": "So, some conclusions from our work.", "tgt_ref": "因此，从我们的工作中得出了一些结论。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_audio": "/acl6060/audio/dev/97.wav", "src_ref": "We have ah we have produced a new dataset of Spanish newswire that is annotated with unassimilated lexical borrowings.", "tgt_ref": "我们已经创建了一个新的西班牙语新闻专线数据集，使用未同化的词汇借词进行了注释。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_audio": "/acl6060/audio/dev/98.wav", "src_ref": "This dataset is more borrowing dense and OOV-rich than previous resources.", "tgt_ref": "与之前的资源相比，这个数据集的借词密度更高，并且OOV也更丰富。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_audio": "/acl6060/audio/dev/99.wav", "src_ref": "We have explored four types of models for lexical borrowing detection.", "tgt_ref": "我们已经探索了四种类型的模型 用于 词汇借用检测。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_audio": "/acl6060/audio/dev/100.wav", "src_ref": "Um. In terms of error analysis, well, recall was a weak point for all models.", "tgt_ref": "呃。在错误分析方面，调用对于所有模型来说都是一个薄弱环节。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_audio": "/acl6060/audio/dev/101.wav", "src_ref": "Ah, as you can see here, some frequent false negatives include uppercase borrowings, words that exist in both English and Spanish, for instance.", "tgt_ref": "正如大家在这里看到的，一些常见的假阴性包括大写的借词，例如在英语和西班牙语中都存在的单词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_audio": "/acl6060/audio/dev/102.wav", "src_ref": "Also interestingly, BPE embeddings seem to improve F1 score.", "tgt_ref": "同样有趣的是，BPE嵌入似乎提高了F1分数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_audio": "/acl6060/audio/dev/103.wav", "src_ref": "And character embedding seem to improve recall.", "tgt_ref": "而字符嵌入似乎可以改善调用。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_audio": "/acl6060/audio/dev/104.wav", "src_ref": "Which ah it's an interesting finding that perhaps we can explore on future work.", "tgt_ref": "这是一个有趣的发现，也许我们可以在未来的工作中探索。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_audio": "/acl6060/audio/dev/105.wav", "src_ref": "Um. Well, this is everything that I have.", "tgt_ref": "呃。嗯，以上就是我要介绍的所有内容。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_audio": "/acl6060/audio/dev/106.wav", "src_ref": "Thank you so much for listening.", "tgt_ref": "非常感谢大家的聆听。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_audio": "/acl6060/audio/dev/107.wav", "src_ref": "My name is Antoine.", "tgt_ref": "我叫Antoine。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_audio": "/acl6060/audio/dev/108.wav", "src_ref": "I'm a PhD student at the University of Massachusetts Amherst.", "tgt_ref": "我是马萨诸塞大学阿默斯特分校的一名博士生。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_audio": "/acl6060/audio/dev/109.wav", "src_ref": "I am presenting our paper KinyaBERT: a Morphology-aware Kinyarwanda Language Model.", "tgt_ref": "我将介绍我们的论文《KinyaBERT：一种形态学意识的基尼亚卢旺达语语言模型》。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_audio": "/acl6060/audio/dev/110.wav", "src_ref": "Today, I'll talk about the motivation for this research.", "tgt_ref": "今天，我将谈一谈这项研究的动机。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_audio": "/acl6060/audio/dev/111.wav", "src_ref": "Then I'll present KinyaBERT model architecture in detail.", "tgt_ref": "然后，我将详细介绍KinyaBERT模型的架构。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_audio": "/acl6060/audio/dev/112.wav", "src_ref": "I'll then talk about our experimental results, then finish with some conclusions.", "tgt_ref": "然后我会谈谈我们的实验结果，最后得出一些结论。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_audio": "/acl6060/audio/dev/113.wav", "src_ref": "We all know that recent natural language processing advances have been made possible by the use of pretrained language models such as BERT.", "tgt_ref": "我们都知道，最近的自然语言处理进步是通过使用预训练语言模型（如BERT ）实现的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_audio": "/acl6060/audio/dev/114.wav", "src_ref": "However, there are still a number of limitations.", "tgt_ref": "然而，仍然存在许多限制。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_audio": "/acl6060/audio/dev/115.wav", "src_ref": "Due to the complex morphology that is expressed by most morphologically rich languages, the ubiquitous byte pair encoding tokenization algorithm that I used cannot extract the exact subword lexical units, meaning the morphemes, which are needed for effective representation.", "tgt_ref": "由于大多数形态学上丰富的语言所表达的形态学很复杂，我使用的普遍存在的字节对编码标记化算法无法提取有效表达所需的确切子词词汇单位，即意义语素。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_audio": "/acl6060/audio/dev/116.wav", "src_ref": "For example, here we have three Kinyarwanda words that have several morphemes in them, but the BPE algorithms cannot extract them.", "tgt_ref": "例如，这里我们有三个基尼亚卢旺达语单词，其中有几个语素，但BPE算法无法提取它们。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_audio": "/acl6060/audio/dev/117.wav", "src_ref": "This is because some morphological rules produce different surface forms that hide the exact lexical information, and BPE, which is solely based on the surface forms, does not have access to this lexical model.", "tgt_ref": "这是因为某些形态化规则产生不同的表面形式，隐藏了确切的词汇信息，而完全基于表面形式的BPE无法访问此词汇模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_audio": "/acl6060/audio/dev/118.wav", "src_ref": "The second challenge is that even if one had access to an oracle morphological analyzer, replacing BPE tokens with morphemes is not enough to express the morphological compositionality.", "tgt_ref": "第二个挑战是，即使人们能够使用甲骨文形态化分析器，用语素替换BPE令牌也不足以表达形态学组合性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_audio": "/acl6060/audio/dev/119.wav", "src_ref": "A third gap in the research is that new pretrained language models are most often evaluated on high resource languages.", "tgt_ref": "这次研究涉及的第三个空白是，新的预训练语言模型通常是在高资源语言上进行评估的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_audio": "/acl6060/audio/dev/120.wav", "src_ref": "And we need to assess their applicability on low resources and diverse languages as well.", "tgt_ref": "我们还需要评估它们在低资源和多样化语言上的适用性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_audio": "/acl6060/audio/dev/121.wav", "src_ref": "Therefore, we present KinyaBERT, which is a simple but effective adaptation of the BERT architecture that is meant to more effectively handle morphologically rich languages.", "tgt_ref": "所以，我们提出KinyaBERT，它是BERT架构的一个简单但有效的改编，旨在更有效地处理形态上丰富的语言。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_audio": "/acl6060/audio/dev/122.wav", "src_ref": "We evaluate KinyaBERT on Kinyarwanda, a low resource morphologically rich language, which is spoken by more than twelve million people across Eastern and Central Africa.", "tgt_ref": "我们评估了基尼亚卢旺达语的KinyaBERT，这是一种低资源形态上丰富的语言，在东非和中非有超过1200万人使用。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_audio": "/acl6060/audio/dev/123.wav", "src_ref": "The input to the model is either a sentence or a document.", "tgt_ref": "模型的输入是句子或文档。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_audio": "/acl6060/audio/dev/124.wav", "src_ref": "For example here, we have John twarahamubonye biradutangaza, which means we were surprised to find John there.", "tgt_ref": "例如这句，John twarahamubonye biradutangaza，意思是，我们惊讶地发现John在那里。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_audio": "/acl6060/audio/dev/125.wav", "src_ref": "As you can see, Kinyarwanda words contains several morphemes that contain different information in them.", "tgt_ref": "正如大家所看到的，基尼亚卢旺达语单词包含几个语素，每个语素包含不同的信息。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_audio": "/acl6060/audio/dev/126.wav", "src_ref": "Therefore, in our model, we pass this sentence or a document to a morphological analyzer.", "tgt_ref": "所以，在我们的模型中，我们将这个句子或文档传递给形态分析器。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_audio": "/acl6060/audio/dev/127.wav", "src_ref": "Which then generates morphemes contained in each of the words.", "tgt_ref": "然后生成包含在每个单词中的词素。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_audio": "/acl6060/audio/dev/128.wav", "src_ref": "The morphemes usually are made of the stem and zero or more affixes.", "tgt_ref": "语素通常由词干和零个或多个词缀组成。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_audio": "/acl6060/audio/dev/129.wav", "src_ref": "The affixes may indicate tense, aspect, subject or object in verbs, and more often relates to the Bantu noun class for subjects and objects.", "tgt_ref": "词缀可以表示动词中的时态、方面、主语或宾语，更多时候与班图语的名词类主语和宾语有关。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_audio": "/acl6060/audio/dev/130.wav", "src_ref": "The morphological analyzer also produces a part of speech tag for each of the words.", "tgt_ref": "形态分析器还为每个单词生成语音标签的一部分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_audio": "/acl6060/audio/dev/131.wav", "src_ref": "After this step, we make embeddings for the spee- for the part of speech tags.", "tgt_ref": "在这一步之后，我们为语音标签的部分进行嵌入。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_audio": "/acl6060/audio/dev/132.wav", "src_ref": "Embeddings for the affixes.", "tgt_ref": "词缀的嵌入。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_audio": "/acl6060/audio/dev/133.wav", "src_ref": "And embeddings for the stem.", "tgt_ref": "以及词干的嵌入。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_audio": "/acl6060/audio/dev/134.wav", "src_ref": "These are the morphology level, these are the morphology level embeddings.", "tgt_ref": "这些是形态学层面的，这些是形态学层面的嵌入。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_audio": "/acl6060/audio/dev/135.wav", "src_ref": "We then pass these embeddings through a morphology encoder, which is a small transformer encoder that is applied to each word independently.", "tgt_ref": "然后，我们将这些嵌入通过形态学编码器传递，这是一个独立应用于每个单词的小型转换器编码器。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_audio": "/acl6060/audio/dev/136.wav", "src_ref": "The output of the are the vectors that are contextualized with the morphological information at each word.", "tgt_ref": "它们的输出是情境化的向量，每个单词都有形态化的信息。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_audio": "/acl6060/audio/dev/137.wav", "src_ref": "Now, we perform composition where the morphological embeddings corresponding to part of speech and stem are concatenated together.", "tgt_ref": "现在，我们进行组合，其中与语音部分相对应的形态化嵌入与词干连接在一起。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_audio": "/acl6060/audio/dev/138.wav", "src_ref": "We further concat we further concatenate them with another stem embedding at the sentence level.", "tgt_ref": "我们进一步将它们与句子级别的另一个词干嵌入连接起来。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_audio": "/acl6060/audio/dev/139.wav", "src_ref": "Then we form an input to the main sentence or document encoder.", "tgt_ref": "然后，我们对主句子或文档编码器形成一个输入。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_audio": "/acl6060/audio/dev/140.wav", "src_ref": "The final output are contextualized embeddings that can be used for downstream NLP tasks.", "tgt_ref": "最终输出是情境化嵌入，可用于下游自然语言处理任务。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_audio": "/acl6060/audio/dev/141.wav", "src_ref": "For a morphological analyzer, we use finite state two level morphology principles with custom implementation that is tailored to the Kinyarwanda language.", "tgt_ref": "对于形态分析器，我们使用有限状态二级形态学原则，并根据基尼亚卢旺达语语言定制实现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_audio": "/acl6060/audio/dev/142.wav", "src_ref": "We effectively model the morphology of all Kinyarwanda words, including verbals, nouns, demonstrative and possessive pronouns, numerals, and others.", "tgt_ref": "我们有效地对所有基尼亚卢旺达语单词的形态进行建模，包括动词、名词、指示和所有格代词、数字等等。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_audio": "/acl6060/audio/dev/143.wav", "src_ref": "We use an unsupervised part of speech tagging algorithm.", "tgt_ref": "我们使用语音标记算法的无监督部分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_audio": "/acl6060/audio/dev/144.wav", "src_ref": "A first order factored model is used to account for morphology probability, basically the probability that is assigned by the morphological analyzer.", "tgt_ref": "一阶因子模型用于说明形态学概率，基本上是由形态分析器分配的概率。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_audio": "/acl6060/audio/dev/145.wav", "src_ref": "We also take into consideration the part of speech tag precedence as well as the syntactic agreements that are present in the in the input words.", "tgt_ref": "我们还考虑了部分语音标签的优先顺序，以及输入单词中存在的句法协议。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_audio": "/acl6060/audio/dev/146.wav", "src_ref": "The part of speech tagger uses a bidi bidirectional inference which improves upon the more often used Viterbi algorithm for decoding.", "tgt_ref": "部分语音标记器使用bidi双向推理，这种方法改进了更经常用于解码的Viterbi算法。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_audio": "/acl6060/audio/dev/147.wav", "src_ref": "A few remarks here for positional encoding.", "tgt_ref": "这里有一些注释对于位置编码。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_audio": "/acl6060/audio/dev/148.wav", "src_ref": "One, the morphology encoder does not use any positional encoding.", "tgt_ref": "第一，形态学编码器不使用任何位置编码。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_audio": "/acl6060/audio/dev/149.wav", "src_ref": "This is because each of the morphemes occupies a known slot in the morphological model.", "tgt_ref": "这是因为每个语素在形态化模型中占据了一个已知的位置。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_audio": "/acl6060/audio/dev/150.wav", "src_ref": "Therefore, positional information is inherent when the morphemes are given.", "tgt_ref": "因此，当给出语素时，位置信息是固有的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_audio": "/acl6060/audio/dev/151.wav", "src_ref": "Second, the sentence encoder uses the so-called untied relative positional embeddings, which have been recently published at ICLR conference.", "tgt_ref": "第二，句子编码器使用所谓的不受约束的相对位置嵌入，这是最近在ICLR会议上发表的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_audio": "/acl6060/audio/dev/152.wav", "src_ref": "This positional embeddings essentially disentangles positional correlations from token to token attention computation.", "tgt_ref": "这种位置嵌入本质上将位置相关性从令牌分离到令牌注意力计算。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_audio": "/acl6060/audio/dev/153.wav", "src_ref": "Similar to BERT, we use a masked language model pre-training objective.", "tgt_ref": "与BERT类似，我们使用掩码语言模型预训练目标。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_audio": "/acl6060/audio/dev/154.wav", "src_ref": "Essentially we have to predict both the stem and the affixes that are associated with the words.", "tgt_ref": "从本质上讲，我们必须预测与单词相关的词干和词缀。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_audio": "/acl6060/audio/dev/155.wav", "src_ref": "During pre-training, fifteen percent of all words are considered for prediction, of which eighty percent are masked, ten percent are swapped with random words, and ten percent are left unchanged.", "tgt_ref": "在预训练期间，所有单词的15%被认为用于预测，其中80%被屏蔽，10%与随机单词交换，10%保持不变。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_audio": "/acl6060/audio/dev/156.wav", "src_ref": "For affix prediction, we face some multi label classification problem.", "tgt_ref": "对于词缀预测，我们面临一些多标签分类问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_audio": "/acl6060/audio/dev/157.wav", "src_ref": "For this, we either group together affixes into a fixed number of sets and predict the set as a class label.", "tgt_ref": "为此，我们要么将词缀组合成固定数量的集合，并将该集合预测为一个类标签。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_audio": "/acl6060/audio/dev/158.wav", "src_ref": "The other option is to predict the affix probability vector.", "tgt_ref": "另一种选择是预测词缀概率向量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_audio": "/acl6060/audio/dev/159.wav", "src_ref": "We evaluate both of these approaches in our experiments.", "tgt_ref": "我们在实验中对这两种方法进行了评估。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_audio": "/acl6060/audio/dev/160.wav", "src_ref": "We pre-train KinyaBERT on about two and half gigabytes of Kinyarwanda text, and compare it to three baseline models.", "tgt_ref": "我们用大约2.5千兆字节的基尼亚卢旺达语文本对KinyaBERT进行预训练，并将其与三个基线模型进行比较。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_audio": "/acl6060/audio/dev/161.wav", "src_ref": "One is a multilingual model called XLM-R, that is trained on a large text corpora that is made of multiple languages.", "tgt_ref": "一个是称为XLM-R的多语言模型，它是在由多种语言组成的大型文本语料库上训练的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_audio": "/acl6060/audio/dev/162.wav", "src_ref": "The other two baselines are pretrained on the same Kinyarwanda text using either the byte pair encoding algorithm or using morphological analysis without using the two tier transformer encoder architecture.", "tgt_ref": "另外两个基线是使用字节对编码算法或使用形态分析而不使用两层转换器编码器架构对同一基尼亚卢旺达语文本进行预训练的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_audio": "/acl6060/audio/dev/163.wav", "src_ref": "All models are configured in the base architecture, which is about between a hundred and a hundred and ten million parameters, with Kinyarwanda with KinyaBERT using the least number of parameters.", "tgt_ref": "所有模型都是在基础架构中配置的，基础架构的参数大约在100到1000万之间，基尼亚卢旺达语和KinyaBERT使用的参数数量最少。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_audio": "/acl6060/audio/dev/164.wav", "src_ref": "All models except the multilingual are pretrained for thirty two thousand gradient updates with a batch size of two thousand five hundred and sixty sequences in each batch.", "tgt_ref": "除多语言外，所有模型都经过预训练用于32000梯度更新，每批次的批量大小为2560序列。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_audio": "/acl6060/audio/dev/165.wav", "src_ref": "We evaluate the pretrained models on three sets of tasks.", "tgt_ref": "我们在三组任务上评估预训练模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_audio": "/acl6060/audio/dev/166.wav", "src_ref": "One is the GLUE benchmark which has often been used for evaluating the effectiveness of pretrained language models.", "tgt_ref": "其中一个是GLUE基准，它经常用于评估预训练语言模型的有效性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_audio": "/acl6060/audio/dev/167.wav", "src_ref": "We obtain our GLUE benchmark data by translating the original benchmark data into Kinyarwanda using Google Translate.", "tgt_ref": "我们通过使用Google翻译将原始基准数据翻译成基尼亚卢旺达语来获得GLUE基准数据。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_audio": "/acl6060/audio/dev/168.wav", "src_ref": "The second task is Kinyarwanda named entity recognition benchmark, which is a high quality dataset that was annotated by trained native speakers.", "tgt_ref": "第二个任务是基尼亚卢旺达语命名实体识别基准，这是一个由训练有素的母语使用者注释的高质量数据集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_audio": "/acl6060/audio/dev/169.wav", "src_ref": "The third one is a news categorization task where we pull news articles from several websites and collecting their categorization tags that were assigned by the authors and then essentially trying to predict the same, the the same categories.", "tgt_ref": "第三个是新闻分类任务，我们从几个网站中提取新闻文章，并收集作者分配的分类标签，然后基本上尝试预测相同的类别。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_audio": "/acl6060/audio/dev/170.wav", "src_ref": "And now we go to the results.", "tgt_ref": "现在我们来看看结果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_audio": "/acl6060/audio/dev/171.wav", "src_ref": "For the GLUE benchmark, we find that KinyaBERT consistently outperforms baseline models.", "tgt_ref": "对于GLUE基准，我们发现KinyaBERT始终优于基线模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_audio": "/acl6060/audio/dev/172.wav", "src_ref": "Here we show the average performance for ten finetuning runs.", "tgt_ref": "在这里，我们展示了十次微调运行的平均表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_audio": "/acl6060/audio/dev/173.wav", "src_ref": "We also run a user evaluation of the translations that are produced by Google Translate.", "tgt_ref": "我们还对Google翻译生成的翻译进行了用户评估。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_audio": "/acl6060/audio/dev/174.wav", "src_ref": "Essentially, user users rated about six thousand examples, assigning scores on a scale from one to four, assessing the quality of the translations.", "tgt_ref": "基本上，用户用户对大约6000个例子进行了评分，按照从1到4的等级进行评分，评估翻译的质量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_audio": "/acl6060/audio/dev/175.wav", "src_ref": "The result is that many translations were noisy.", "tgt_ref": "其结果是，许多翻译是杂乱无章的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_audio": "/acl6060/audio/dev/176.wav", "src_ref": "But, all models had to cope with the same translation noise, and the relative performance between the models is still important to notice.", "tgt_ref": "但是，所有模型都必须应对相同的翻译噪声，并且模型之间的相对性能仍然是值得注意的重要因素。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_audio": "/acl6060/audio/dev/177.wav", "src_ref": "For the named entity recognition task, we also find that KinyaBERT gives the best performance with the affix distribution regression variant performing best.", "tgt_ref": "对于命名实体识别任务，我们还发现KinyaBERT给出的表现最好，并且词缀分布回归变体表现最佳。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_audio": "/acl6060/audio/dev/178.wav", "src_ref": "These results are also averages of ten finetuning runs.", "tgt_ref": "这些结果也是十微调运行的平均值。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_audio": "/acl6060/audio/dev/179.wav", "src_ref": "For the news categorization task, we find mixed results.", "tgt_ref": "对于新闻分类任务，我们发现结果好坏参半。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_audio": "/acl6060/audio/dev/180.wav", "src_ref": "Previous work on text classification for Kinyarwanda had found that simple keyword detection is mostly enough for solving this specific task.", "tgt_ref": "之前关于基尼亚卢旺达语文本分类的工作发现，简单的关键词检测就足以解决这个特定的任务。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_audio": "/acl6060/audio/dev/181.wav", "src_ref": "Therefore, there is less gain from using pretrained language models.", "tgt_ref": "因此，使用预训练语言模型的收益较少。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_audio": "/acl6060/audio/dev/182.wav", "src_ref": "On this particular task of news categorization.", "tgt_ref": "关于新闻分类这个特殊任务。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_audio": "/acl6060/audio/dev/183.wav", "src_ref": "We also conducted an ablation study to see if there are alternative structures that improve performance.", "tgt_ref": "我们还进行了一项消融研究，看看是否有其他结构可以提高表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_audio": "/acl6060/audio/dev/184.wav", "src_ref": "For the GLUE benchmark, we find that using affix sets consistently performs better, while affix probability regression objective yields the best performance on named entity recognition.", "tgt_ref": "对于GLUE基准，我们发现使用词缀集始终表现更好，而词缀概率回归目标在命名实体识别上产生最佳表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_audio": "/acl6060/audio/dev/185.wav", "src_ref": "Also by looking at the low scores for finetuning, we find that KinyaBERT has better convergence in most cases.", "tgt_ref": "此外，通过查看微调的低分数，我们发现KinyaBERT在大多数情况下具有更好的收敛性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_audio": "/acl6060/audio/dev/186.wav", "src_ref": "So to conclude, this work has demonstrated the effectiveness of explicitly using morphological information in pretrained language models.", "tgt_ref": "总之，这项工作已经证明了在预训练语言模型中明确使用形态学信息的有效性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_audio": "/acl6060/audio/dev/187.wav", "src_ref": "The proposed two tier transformer encoder architecture enables capturing morphological complexity morphological compositionality, which is an important aspect of morphologically rich languages.", "tgt_ref": "所提出的两层转换器编码器架构能够捕获形态学复杂性形态学组合性，这是形态学丰富语言的一个重要方面。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_audio": "/acl6060/audio/dev/188.wav", "src_ref": "These findings should motivate further research into morphology aware language pretrained language models.", "tgt_ref": "这些发现应该能激发对形态学感知语言预训练语言模型的进一步研究。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_audio": "/acl6060/audio/dev/189.wav", "src_ref": "Hello, my name is Michał Pietruszka and it is my pleasure to present to you the paper titled Sparsifying Transformer Models with Trainable Representation Pooling.", "tgt_ref": "大家好，我叫Michał Pietruszka，我很高兴向大家介绍这篇题为《用可训练的表示池来对转换器模型进行稀疏化》的论文。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_audio": "/acl6060/audio/dev/190.wav", "src_ref": "A work done at Applica AI in cooperation with Lukasz Borchmann and Lukasz Garncarek.", "tgt_ref": "这是ApplicaAI与Lukasz Borchmann和Lukasz Garncarek合作完成的一项工作。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_audio": "/acl6060/audio/dev/191.wav", "src_ref": "Let me start with the problems our work targets.", "tgt_ref": "让我先谈谈我们的工作目标。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_audio": "/acl6060/audio/dev/192.wav", "src_ref": "Our method works well for the cases where long inputs are considered.", "tgt_ref": "我们的方法在考虑长输入的情况下效果不错。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_audio": "/acl6060/audio/dev/193.wav", "src_ref": "Roughly speaking, it is meant for the task orders and input of over two thousand tokens and the targets are shorter than the provided inputs.", "tgt_ref": "粗略地说，这意味着超过2000个令牌的任务订单和输入，并且目标比提供的输入要短。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_audio": "/acl6060/audio/dev/194.wav", "src_ref": "This has some specific applications in NLP.", "tgt_ref": "这在自然语言处理中有一些具体的应用。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_audio": "/acl6060/audio/dev/195.wav", "src_ref": "For example, one can imagine that given a long document, there's a need to summarize it, classify, answer the question about it, extract information or some key phrases.", "tgt_ref": "例如，可以想象，给定一份很长的文档，需要对其进行总结、分类，回答有关它的问题，提取信息或一些关键短语。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_audio": "/acl6060/audio/dev/196.wav", "src_ref": "Let me recall the vanilla transformer and our and its issue of its attention complexity that depends on the square of the input line.", "tgt_ref": "让我回顾一下普通的转换器，以及我们和它的注意力复杂性问题，这取决于输入行的平方。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_audio": "/acl6060/audio/dev/197.wav", "src_ref": "In the vanilla transformer, with full attention connectivity, relations of each token to every other token have to be calculated.", "tgt_ref": "在普通的转换器中，在完全注意力连通的情况下，必须计算每个令牌与其他令牌之间的关系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_audio": "/acl6060/audio/dev/198.wav", "src_ref": "The computational complexity of attention, this depends on the number of layers l, sequence length n, another sequence length, and the dimensionality of representations.", "tgt_ref": "注意力的计算复杂性，这取决于层l的数量，序列长度n，另一个序列长度以及表示的维度。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_audio": "/acl6060/audio/dev/199.wav", "src_ref": "Similarly, in the decoder's cross attention, to this picture on the right side, the only difference here is that the target tokens are attending to the input tokens in this case.", "tgt_ref": "类似地，在解码器的交叉注意力中，对于右侧的这张图片，这里唯一的区别是，在这种情况下，目标令牌正在关注输入令牌。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_audio": "/acl6060/audio/dev/200.wav", "src_ref": "Which can be seen also in this formula.", "tgt_ref": "这也可以从这个公式中看出来。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_audio": "/acl6060/audio/dev/201.wav", "src_ref": "The BLEU score represents relations that have to be calculated.", "tgt_ref": "BLEU分数表示必须计算的关系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_audio": "/acl6060/audio/dev/202.wav", "src_ref": "In case of the full attention, we need to calculate every relations within the input sequence.", "tgt_ref": "在完全注意力的情况下，我们需要计算输入 序列中的每个关系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_audio": "/acl6060/audio/dev/203.wav", "src_ref": "Now, we see what happens when we have a blockwise encoder that works by limiting the tokens connectivity so that they can only see other nearby tokens.", "tgt_ref": "现在，我们看看当我们有一个分块编码器时会发生什么，该编码器通过限制令牌连接来工作，这样它们只能看到附近的其他令牌。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_audio": "/acl6060/audio/dev/204.wav", "src_ref": "The text is read in chunks which can drastically reduce the number of computations on the encoder side, but does not improve the decoder's cross attention as every input token is passed to the decoder anyway.", "tgt_ref": "文本是以块的形式读取的，这可以大大减少编码器端的计算数量，但并不能提高解码器的交叉注意力，因为无论如何，每个输入令牌都会传递给解码器。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_audio": "/acl6060/audio/dev/205.wav", "src_ref": "This method is often referred to as fusion in decoder.", "tgt_ref": "这种方法通常被称为解码器中的融合。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_audio": "/acl6060/audio/dev/206.wav", "src_ref": "The improvement here can be interpreted as changing one of the dependencies of n to another constant m representing the block size.", "tgt_ref": "这里的改进可以解释为将n的一个依赖关系更改为另一个表示块大小的常数m。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_audio": "/acl6060/audio/dev/207.wav", "src_ref": "Our key observation is that most tokens are irrelevant for a wide variety of tasks and can be almost completely disregarded. This is exemplified on the slide.", "tgt_ref": "我们的主要观察结果是，大多数令牌与各种任务都是不相关的，几乎可以完全忽略。这一点在幻灯片上得到了例证。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_audio": "/acl6060/audio/dev/208.wav", "src_ref": "The only parts of the inputs are relevant to the desired output.", "tgt_ref": "输入的唯一部分与期望的输出相关。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_audio": "/acl6060/audio/dev/209.wav", "src_ref": "For example.", "tgt_ref": "例如，", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_audio": "/acl6060/audio/dev/210.wav", "src_ref": "One can read an article once marking the most important parts with a highlighter, and then produce a summary based on this part from the middle stage only.", "tgt_ref": "阅读一篇文章时，可以先用荧光笔标出最重要的部分，然后只从中间阶段开始根据这一部分写出摘要。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_audio": "/acl6060/audio/dev/211.wav", "src_ref": "The cost of highlighting and deciding if the current token is essential to produce the summary is thus cheap and depends only on the token's representation.", "tgt_ref": "因此，突出显示和决定当前令牌是否对生成摘要至关重要的成本而言是便宜的，并且仅取决于令牌的表示。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_audio": "/acl6060/audio/dev/212.wav", "src_ref": "The pooling of the highlighted tokens is possible.", "tgt_ref": "突出显示的令牌可以进行池化。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_audio": "/acl6060/audio/dev/213.wav", "src_ref": "Thanks to our top k operator and its cost is negligible.", "tgt_ref": "多亏了我们的top k运算符，其成本可以忽略不计。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_audio": "/acl6060/audio/dev/214.wav", "src_ref": "The cost of producing a summary from a shortened input is also much lower than in the vanilla model when the whole input is considered.", "tgt_ref": "当考虑整个输入时，从缩短的输入生成摘要的成本也比普通模型低得多。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_audio": "/acl6060/audio/dev/215.wav", "src_ref": "But here's a question.", "tgt_ref": "但这里有一个问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_audio": "/acl6060/audio/dev/216.wav", "src_ref": "How to select important tokens and backpropagate gradients to that selection?", "tgt_ref": "如何选择重要的令牌并将梯度反向传播到该选择？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_audio": "/acl6060/audio/dev/217.wav", "src_ref": "The essential underlying problem that we solve is to propose the trainable selection mechanism.", "tgt_ref": "我们解决的根本问题是提出可训练的选择机制。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_audio": "/acl6060/audio/dev/218.wav", "src_ref": "One that can allow for gradient to be back propagated during the training so that the network can learn to select the most important tokens.", "tgt_ref": "一种可以允许在训练期间反向传播梯度的方法，以便网络能够学习选择最重要的令牌。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_audio": "/acl6060/audio/dev/219.wav", "src_ref": "More precisely", "tgt_ref": "更确切地说，", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_audio": "/acl6060/audio/dev/220.wav", "src_ref": "Given some embeddings underscore obtained from a simple linear layer, the task is to return the highest scoring embeddings. First, the sequence is permuted and pairs are prepared so that the higher scoring vector is taken with the lower scoring one.", "tgt_ref": "给定从简单线性层获得的一些嵌入下划线，任务是返回得分最高的嵌入。首先，对序列进行排列，并准备成对，以便将得分较高的向量与得分较低的向量一起使用。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_audio": "/acl6060/audio/dev/221.wav", "src_ref": "Next, weights are calculated using boosted softmax over scores.", "tgt_ref": "接下来，使用分数上的提升softmax计算权重。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_audio": "/acl6060/audio/dev/222.wav", "src_ref": "After each tournament round, new vectors and scores are composed as a linear combination of those pairs with the obtained weights.", "tgt_ref": "在每一轮锦标赛之后，新的向量和分数被组成为这些对与所获得的权重的线性组合。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_audio": "/acl6060/audio/dev/223.wav", "src_ref": "So in short, we combine them linearly by performing a softmax over their scores.", "tgt_ref": "因此，简而言之，我们通过对它们的分数执行softmax来线性地组合它们。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_audio": "/acl6060/audio/dev/224.wav", "src_ref": "And while combining two tokens, some noise can be produces produced.", "tgt_ref": "并且当组合两个令牌时，可以产生一些噪声。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_audio": "/acl6060/audio/dev/225.wav", "src_ref": "But it also allows the gradients to be propagated to all input embeddings.", "tgt_ref": "但它也允许梯度传播到所有输入嵌入。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_audio": "/acl6060/audio/dev/226.wav", "src_ref": "In short, a trainable top k we propose is based on performing a tournament like soft selection at each step.", "tgt_ref": "简而言之，我们提出的可训练的top k是基于在每个步骤中执行软选择这样的锦标赛。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_audio": "/acl6060/audio/dev/227.wav", "src_ref": "And from a different perspective, the representation pooling follows the encoder layer.", "tgt_ref": "而从另一个角度来看，表示池化是在编码器层之后。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_audio": "/acl6060/audio/dev/228.wav", "src_ref": "First, each representation is scored and then only those with the highest scores are passed to the next layer.", "tgt_ref": "首先，对每个表示进行评分，然后只有得分最高的那些表示才会被传递到下一层。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_audio": "/acl6060/audio/dev/229.wav", "src_ref": "Encoding can be performed as in standard transformer architecture on the full length input.", "tgt_ref": "编码可以像标准转换器架构一样在全长输入上执行。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_audio": "/acl6060/audio/dev/230.wav", "src_ref": "It is however possible to process text in blocks of fixed length of fixed length and globally select the best representation.", "tgt_ref": "然而，它还可以在固定长度的块中处理固定长度的文本，并在全局范围内选择最佳的表示。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_audio": "/acl6060/audio/dev/231.wav", "src_ref": "Here is an example of the representation pooling introduced after the encoder.", "tgt_ref": "下面是一个在编码器之后引入的表示池的例子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_audio": "/acl6060/audio/dev/232.wav", "src_ref": "This directly influenced the cause of cross attention, which depends not on the input length N, but the constant K, representing the pooled length.", "tgt_ref": "这直接影响了交叉注意力的原因，它不取决于输入长度N，而是常数K，代表池化长度。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_audio": "/acl6060/audio/dev/233.wav", "src_ref": "This constant informs how many representations are selected and passed to the decoder.", "tgt_ref": "这个常数通知我们有多少个表示被选择并传递给解码器。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_audio": "/acl6060/audio/dev/234.wav", "src_ref": "Producing a summary from a shorter text is significantly cheaper than previous solution.", "tgt_ref": "从较短的文本生成摘要比之前的解决方案要便宜得多。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_audio": "/acl6060/audio/dev/235.wav", "src_ref": "As the sequence length can be shortened by a large factor.", "tgt_ref": "由于序列长度可以缩短大的因子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_audio": "/acl6060/audio/dev/236.wav", "src_ref": "For example, we successfully used k of sixteen or even sixty times four or even sixty four times smaller than the value of n in our experiments.", "tgt_ref": "例如，我们在实验中成功地使用了比n值小16倍甚至64倍的k值。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_audio": "/acl6060/audio/dev/237.wav", "src_ref": "Please note that the beneficial impact of blockwise encoding and self attention is sustained.", "tgt_ref": "请注意，分块编码和自我注意力的有益影响是持续的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_audio": "/acl6060/audio/dev/238.wav", "src_ref": "Remember that the computational cost of attention depend on the square of the input length.", "tgt_ref": "请记住，注意力的计算成本取决于输入长度的平方。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_audio": "/acl6060/audio/dev/239.wav", "src_ref": "Reducing it the input earlier during the encoding process can significantly lower the costs.", "tgt_ref": "在编码过程中尽早减少输入可以显著降低成本。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_audio": "/acl6060/audio/dev/240.wav", "src_ref": "For the pyramidion model, we narrowed down the size of the representation on the output of each of each chosen layer, leading to the exponential reduction of computational cost as the encoding proceeds.", "tgt_ref": "对于金字塔模型，我们缩小了每个选定层输出上表示的大小，导致随着编码的进行，计算成本呈指数级降低。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_audio": "/acl6060/audio/dev/241.wav", "src_ref": "As you can see, the total computational cost of a full encoder here is less than two times the cost of the full-sized first layer.", "tgt_ref": "正如大家所看到的，这里完整的编码器的总计算成本不到全尺寸第一层成本的两倍。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_audio": "/acl6060/audio/dev/242.wav", "src_ref": "When pooling is introduced earlier, the sum of all purple squares is thus bounded to a constant, not dependent on the number of layers l.", "tgt_ref": "当较早引入池化时，所有紫色方块的总和都受限于一个常数，而不取决于层l的数量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_audio": "/acl6060/audio/dev/243.wav", "src_ref": "But on the constant c, which can be influenced by the placing of the pooling layers within the network.", "tgt_ref": "而是取决于常数c，常数c可能受到网络内池化层的放置的影响。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_audio": "/acl6060/audio/dev/244.wav", "src_ref": "Our improvements were benchmarked on eight thousand tokens long inputs.", "tgt_ref": "我们的改进以8000个令牌长的输入为基准。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_audio": "/acl6060/audio/dev/245.wav", "src_ref": "And the figure shows that when pooling is engaged, the best scalability for the network's depth is achieved.", "tgt_ref": "该图显示，当使用池化时，网络深度的最佳可扩展性得到了实现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_audio": "/acl6060/audio/dev/246.wav", "src_ref": "Here one can note that training the pyramidion of twenty four layers can be cheaper than training a two layer vanilla transformer on such long inputs.", "tgt_ref": "这里我们可以注意到，在如此长的输入上，训练24层的金字塔可能比训练两层的普通转换器更便宜。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_audio": "/acl6060/audio/dev/247.wav", "src_ref": "Not to mention how easily vanilla transformer can go out of memory for such a long input.", "tgt_ref": "更不用说，对于这么长的输入，普通转换器是多么容易耗尽内存。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_audio": "/acl6060/audio/dev/248.wav", "src_ref": "The qual quality qual qualitative comparison of our trend pyramidion to other baseline is performed on the long document summarization task, or given the body of an article from arXiv or PubMed, the task is to generate its abstract.", "tgt_ref": "我们的趋势金字塔与其他基线的qual质量qual定性比较是在长文档总结任务上执行的，或者给定来自arXiv或PubMed的文章主体，而任务是生成其摘要。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_audio": "/acl6060/audio/dev/249.wav", "src_ref": "Thus, one can see blockwise, which is our baseline, performs on the level of the re, recent state-of-the-art models, while the pyramidion retains or improves the performance of this competitive baseline.", "tgt_ref": "因此，人们可以看到分块（我们的基线）的表现与最近最先进模型的水平相当，而金字塔则保留或提高这一竞争基线的表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_audio": "/acl6060/audio/dev/250.wav", "src_ref": "At the same time, our model is eighty percent faster to train and over four hundred fifty percent faster at inference when compared to the blockwise baseline.", "tgt_ref": "与此同时，与分块基线相比，我们的模型训练速度提高了80%，推理速度提高了450%以上。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_audio": "/acl6060/audio/dev/251.wav", "src_ref": "Both models have much lower parameter counts and were trained from scratch on the chosen tasks.", "tgt_ref": "这两个模型的参数计数要低得多，并且都是根据所选的任务从头开始训练的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_audio": "/acl6060/audio/dev/252.wav", "src_ref": "Previous approaches to to achieve a similar performance had to use more parameters and leverage pretrained foundation foundational models and additional language pretraining objective to achieve similar performance.", "tgt_ref": "之前实现类似表现的方法必须使用更多的参数，并利用预训练基础模型和额外的语言预训练目标来实现类似的表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_audio": "/acl6060/audio/dev/253.wav", "src_ref": "We invite you to read our full paper and use our GitHub code.", "tgt_ref": "我们邀请大家阅读我们的完整论文并使用我们的GitHub代码。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_audio": "/acl6060/audio/dev/254.wav", "src_ref": "Thank you for watching.", "tgt_ref": "感谢大家的观看。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_audio": "/acl6060/audio/dev/255.wav", "src_ref": "Hello, this is Jiawei Zhou from Harvard University.", "tgt_ref": "大家好，我是来自哈佛大学的Jiawei Zhou。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_audio": "/acl6060/audio/dev/256.wav", "src_ref": "I am very glad to present our work on Online Semantic Parsing for Latency Reduction in Task-Oriented Dialogue.", "tgt_ref": "我很高兴向大家介绍我们在在线语义解析用于减少面向任务的对话中的延迟方面的工作。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_audio": "/acl6060/audio/dev/257.wav", "src_ref": "This is joint work with Jason, Michael, Anthony and Sam from Microsoft Semantic Machines.", "tgt_ref": "这项工作是与来自微软语义机器公司的Jason、Michael、Anthony和Sam共同完成的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_audio": "/acl6060/audio/dev/258.wav", "src_ref": "In task-oriented dialogue, a user interacts with the system that handles requests from user utterances usually in speaking.", "tgt_ref": "在面向任务的对话中，用户通常在说话时与处理来自用户话语请求的系统进行交互。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_audio": "/acl6060/audio/dev/259.wav", "src_ref": "From the finish of the user utterance to the system response there is often a noticeable delay.", "tgt_ref": "从用户话语结束到系统响应，通常存在明显的延迟。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_audio": "/acl6060/audio/dev/260.wav", "src_ref": "Under the hood, the user utterance is translated into an executable program.", "tgt_ref": "在表面之下，用户话语被翻译成一个可执行程序。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_audio": "/acl6060/audio/dev/261.wav", "src_ref": "Which is then executed so that the system can respond properly.", "tgt_ref": "然后执行该程序，以便系统能够正确响应。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_audio": "/acl6060/audio/dev/262.wav", "src_ref": "Because the program is represented as a semantic graph that outlines the computation, where node represents a function invocation and its children are the arguments.", "tgt_ref": "因为该程序被表示为概述计算的语义图形，其中节点表示一个函数调用，而其子节点是参数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_audio": "/acl6060/audio/dev/263.wav", "src_ref": "The great nodes mark instantaneous operations, but the others are slow to execute.", "tgt_ref": "大的节点标记瞬时操作，但其他节点执行起来很慢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_audio": "/acl6060/audio/dev/264.wav", "src_ref": "The simple example here we show, these programs can often be more complicated graphs beyond the tree structures.", "tgt_ref": "在我们这里展示的简单例子中，这些程序通常可以是比树结构更复杂的图形。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_audio": "/acl6060/audio/dev/265.wav", "src_ref": "In this talk, we ask the question, can we start generating the program and executing it before the user even finishes the utterance so that the faster response can be achieved by the system?", "tgt_ref": "在这次演讲中，我们提出了这样一个问题：我们是否可以在用户完成话语之前就开始生成程序并执行它，以便系统能够实现更快的响应？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_audio": "/acl6060/audio/dev/266.wav", "src_ref": "This is the online prediction and decision problem.", "tgt_ref": "这就是在线预测和决策问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_audio": "/acl6060/audio/dev/267.wav", "src_ref": "There are a lot of others in this realm.", "tgt_ref": "在这个领域还有许多其他例子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_audio": "/acl6060/audio/dev/268.wav", "src_ref": "Examples include simultaneous translation where a live interpreter translates one language to another in real time, smart text auto completion to guess the user intent, and Uber pool where the drivers are sent to where they might be needed based on the predicted demand.", "tgt_ref": "例如，同步翻译，其中现场翻译人员实时将一种语言翻译成另一种语言，智能文本自动补全功能用于猜测用户意图；再比如优步拼车，根据预测的需求将司机送到可能需要的地方。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_audio": "/acl6060/audio/dev/269.wav", "src_ref": "All of these scenarios have one thing in common.", "tgt_ref": "所有这些场景都有一个共同点。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_audio": "/acl6060/audio/dev/270.wav", "src_ref": "That is, it is beneficial to make decisions before seeing all the input.", "tgt_ref": "也就是说，在看到所有输入之前做出决策是有益的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_audio": "/acl6060/audio/dev/271.wav", "src_ref": "In our case, we are going to deal with online semantic parsing, which could be expected to be challenging as we have to guess what the user might say.", "tgt_ref": "在我们的案例中，我们将处理在线语义解析，这可能具有挑战性，因为我们必须猜测用户可能会说什么。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_audio": "/acl6060/audio/dev/272.wav", "src_ref": "And it is also underexplored with no formal evaluation metric.", "tgt_ref": "而且它也没有得到充分的探索，没有正式的评估指标。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_audio": "/acl6060/audio/dev/273.wav", "src_ref": "First, let's look at how an ordinary system works.", "tgt_ref": "首先，让我们来看看一个普通的系统是如何工作的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_audio": "/acl6060/audio/dev/274.wav", "src_ref": "It is operating offline by parsing to the program only at the end of the user utterance.", "tgt_ref": "它只在用户话语结束时通过解析对程序进行离线操作。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_audio": "/acl6060/audio/dev/275.wav", "src_ref": "Here, the character graph is predicted after seeing all the information.", "tgt_ref": "在这里，字符图形是在看到所有信息之后预测的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_audio": "/acl6060/audio/dev/276.wav", "src_ref": "In contrast, we are proposing an online system that compares at every utterance prefix.", "tgt_ref": "相反，我们提出了一个在线系统，可以对每个话语前缀进行比较。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_audio": "/acl6060/audio/dev/277.wav", "src_ref": "For example, each time we see a new token, we predict a new graph.", "tgt_ref": "例如，每当我们看到一个新的令牌，我们就会预测一个新的图形。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_audio": "/acl6060/audio/dev/278.wav", "src_ref": "Notice that there could be errors.", "tgt_ref": "请注意，可能存在错误。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_audio": "/acl6060/audio/dev/279.wav", "src_ref": "At the position of at the pool party with Barack Obama, we got a graph with the right nodes on the person and the event subject, but guess the wrong timing information.", "tgt_ref": "在与Barack Obama的泳池派对上，我们得到了一张关于人物和事件主题正确节点的图表，但猜错了时间信息。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_audio": "/acl6060/audio/dev/280.wav", "src_ref": "This process goes on until we receive the full user utterance.", "tgt_ref": "这个过程一直持续到我们接收到完整的用户话语。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_audio": "/acl6060/audio/dev/281.wav", "src_ref": "How would this affect the execution timeline in the offline system?", "tgt_ref": "这将如何影响离线系统中的执行时间线？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_audio": "/acl6060/audio/dev/282.wav", "src_ref": "We'll get the program graph at the end so that the system can start execution at this point.", "tgt_ref": "我们将在最后得到程序图形，以便系统可以在这一点上开始执行。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_audio": "/acl6060/audio/dev/283.wav", "src_ref": "Remember that the great nodes are fast operations, so we only consider the execution timeline of the colored slow functions.", "tgt_ref": "请记住，大的节点是快速操作，因此我们只考虑彩色慢速函数的执行时间线。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_audio": "/acl6060/audio/dev/284.wav", "src_ref": "First, these two find person functions can be executed in parallel, highlighted in white from the pink box as they have no dependency on other functions.", "tgt_ref": "首先，这两个“查找人员”函数可以并行执行，由于它们与其他功能没有依赖关系，因此在粉色框中以白色突出显示。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_audio": "/acl6060/audio/dev/285.wav", "src_ref": "Next, the node create event can then get executed after obtaining results from lower level nodes and then the top function yield so the whole program is finished.", "tgt_ref": "接下来，在获得下层节点的结果后，节点创建事件可以得到执行，然后顶层函数产生，从而完成整个程序。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_audio": "/acl6060/audio/dev/286.wav", "src_ref": "The execution process is strict, restricted to the program dependency structure where some operations cannot be parallelized which induces a noticeable delay.", "tgt_ref": "执行过程是严格的，仅限于程序依赖关系结构，其中一些操作无法并行化，从而导致明显的延迟。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_audio": "/acl6060/audio/dev/287.wav", "src_ref": "In our online system, where we predict as we go, the program execution can start earlier.", "tgt_ref": "在我们的在线系统中，我们可以随时预测，因此程序可以更早地开始执行。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_audio": "/acl6060/audio/dev/288.wav", "src_ref": "Here, at the prefix after Obama we predict confidently that the find person function should be in the program, but the rest may contain errors as they are grayed out.", "tgt_ref": "在这里，在Obama后面的前缀处，我们自信地预测“查找人员”函数应该在程序中，但其余部分可能包含错误，因为它们显示为灰色。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_audio": "/acl6060/audio/dev/289.wav", "src_ref": "The execution of the node can be immediately started as a step.", "tgt_ref": "节点的执行可以作为一个步骤立即开始。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_audio": "/acl6060/audio/dev/290.wav", "src_ref": "Then, with more tokens, we predict a totally new graph, but part of it has already being executed.", "tgt_ref": "然后，使用更多的令牌，我们预测一个全新的图形，但其中一部分已经被执行。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_audio": "/acl6060/audio/dev/291.wav", "src_ref": "So, we only need to consider the rest of the nodes that we are confident about as well.", "tgt_ref": "因此，我们只需要考虑我们也有信心的其余节点。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_audio": "/acl6060/audio/dev/292.wav", "src_ref": "Here, another find person can be executed in parallel.", "tgt_ref": "在这里，可以并行执行另一个“查找人员”函数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_audio": "/acl6060/audio/dev/293.wav", "src_ref": "Again, we may have wrong predictions.", "tgt_ref": "同样，我们可能会做出错误的预测。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_audio": "/acl6060/audio/dev/294.wav", "src_ref": "With more text, we have more ability to make it right.", "tgt_ref": "有了更多的文本，我们就有更多的能力来纠正错误。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_audio": "/acl6060/audio/dev/295.wav", "src_ref": "Such as the event time here where AM is also anticipated correctly.", "tgt_ref": "比如这里的事件时间，对上午的预测也是正确的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_audio": "/acl6060/audio/dev/296.wav", "src_ref": "Then, we can start executing the rest following the program dependency structure.", "tgt_ref": "然后，我们可以按照程序依赖关系结构开始执行其余部分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_audio": "/acl6060/audio/dev/297.wav", "src_ref": "By overlapping the execution timeline with the utterance timeline, we save a big amount of time.", "tgt_ref": "通过将执行时间线与话语时间线重叠，我们节省了大量时间。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_audio": "/acl6060/audio/dev/298.wav", "src_ref": "So we proposed the task of online semantic parsing.", "tgt_ref": "于是我们提出了在线语义解析的任务。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_audio": "/acl6060/audio/dev/299.wav", "src_ref": "One underlying assumption is that the execution time dominates the model prediction time.", "tgt_ref": "一个基本假设是，执行时间主导模型预测时间。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_audio": "/acl6060/audio/dev/300.wav", "src_ref": "So we could only gain time by predicting earlier.", "tgt_ref": "因此，我们只能通过提前预测来争取时间。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_audio": "/acl6060/audio/dev/301.wav", "src_ref": "Another assumption is that as the prediction and execution happen in the background, that it is not visible to users.", "tgt_ref": "另一个假设是，由于预测和执行是在后台进行的，所以对用户来说是不可见的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_audio": "/acl6060/audio/dev/302.wav", "src_ref": "It is not necessary to maintain a consistent parsing history.", "tgt_ref": "没有必要保持一致的解析历史记录。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_audio": "/acl6060/audio/dev/303.wav", "src_ref": "So, we reparse from scratch after each token.", "tgt_ref": "因此，我们在每个令牌之后从头开始解析。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_audio": "/acl6060/audio/dev/304.wav", "src_ref": "In particular, we propose a two step approach.", "tgt_ref": "具体而言，我们提出一个两步骤方法。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_audio": "/acl6060/audio/dev/305.wav", "src_ref": "A proposed step that predicts a graph with complete structure and a select step that selects the nodes that are worth executing at this time.", "tgt_ref": "一个提议的步骤，用于预测具有完整结构的图形，以及一个选择步骤，用于选择此时值得执行的节点。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_audio": "/acl6060/audio/dev/306.wav", "src_ref": "We had two variants of the proposed method.", "tgt_ref": "我们提出的方法有两种变体。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_audio": "/acl6060/audio/dev/307.wav", "src_ref": "First approach combines a language model completion with full utterance to graph parsing.", "tgt_ref": "第一种方法将语言模型的完成与完整的话语到图形的解析相结合。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_audio": "/acl6060/audio/dev/308.wav", "src_ref": "In particular, the prefix after Obama is first completed through a finetuned BART language model and then translated into a program with full offline parser.", "tgt_ref": "具体来说，Obama之后的前缀首先是通过一个微调过的BART语言模型完成的，然后转换为具有完全离线解析器的程序。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_audio": "/acl6060/audio/dev/309.wav", "src_ref": "The second approach directly predicts the program from user utterance prefixes.", "tgt_ref": "第二种方法直接从用户话语前缀预测程序。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_audio": "/acl6060/audio/dev/310.wav", "src_ref": "This is achieved by training a single online parser to translate to the goal graph from each prefix.", "tgt_ref": "这是通过训练单个在线解析器将每个前缀转换为目标图形来实现的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_audio": "/acl6060/audio/dev/311.wav", "src_ref": "This facilitates the model to learn the right anticipation.", "tgt_ref": "这有助于模型学习正确的预期。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_audio": "/acl6060/audio/dev/312.wav", "src_ref": "In a bit more detail, how do we generate these graphs?", "tgt_ref": "更详细地说，我们如何生成这些图形？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_audio": "/acl6060/audio/dev/313.wav", "src_ref": "We formulate the problem by generating a serial version of the graph.", "tgt_ref": "我们通过生成图形的序列版本来表述问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_audio": "/acl6060/audio/dev/314.wav", "src_ref": "Each node or edge is represented by an action.", "tgt_ref": "每个节点或边都由一个动作表示。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_audio": "/acl6060/audio/dev/315.wav", "src_ref": "Here, we start from the first node.", "tgt_ref": "在这里，我们从第一个节点开始。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_audio": "/acl6060/audio/dev/316.wav", "src_ref": "The number below records the absolute index in action history.", "tgt_ref": "下面的数字记录了动作历史记录中的绝对索引。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_audio": "/acl6060/audio/dev/317.wav", "src_ref": "Then, we got the second node.", "tgt_ref": "然后，我们得到了第二个节点。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_audio": "/acl6060/audio/dev/318.wav", "src_ref": "Next, is the edge between them.", "tgt_ref": "接下来，是它们之间的边。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_audio": "/acl6060/audio/dev/319.wav", "src_ref": "It contains the pointer to the index of the previous node and the edge label.", "tgt_ref": "它包含指向前一个节点索引和边标签的指针。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_audio": "/acl6060/audio/dev/320.wav", "src_ref": "Zero here means connecting the most recent node with the node generated by the zeroth action and next node next edge.", "tgt_ref": "这里的0表示将最近的节点与第0个动作和下一个节点的下一个边生成的节点连接起来。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_audio": "/acl6060/audio/dev/321.wav", "src_ref": "This process goes on until we generate the full graph.", "tgt_ref": "这个过程一直持续到生成完整的图形为止。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_audio": "/acl6060/audio/dev/322.wav", "src_ref": "The underlying model is based on transformer with self pointing mechanism similar to a previous transition based parser.", "tgt_ref": "底层模型基于转换器，具有类似于基于解析器的之前转换的自指向机制。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_audio": "/acl6060/audio/dev/323.wav", "src_ref": "After generating a complete graph, we obtained the action level probabilities that correspond to different parts of the graph.", "tgt_ref": "在生成完整的图形之后，我们获得了与图形不同部分相对应的动作水平概率。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_audio": "/acl6060/audio/dev/324.wav", "src_ref": "We select confidence subgraphs based on the thresholding heuristic to be executed.", "tgt_ref": "我们根据要执行的阈值启发式选择置信度子图。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_audio": "/acl6060/audio/dev/325.wav", "src_ref": "Later on, we're going to vary the threshold to achieve different tradeoffs between the latency reduction and the execution cost.", "tgt_ref": "稍后，我们将改变阈值，以在延迟减少和执行成本之间实现不同的权衡。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_audio": "/acl6060/audio/dev/326.wav", "src_ref": "For formal evaluation of the online methods, we propose final latency reduction or FLR metric.", "tgt_ref": "对于在线方法的正式评估，我们提出最终延迟减少或FLR指标。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_audio": "/acl6060/audio/dev/327.wav", "src_ref": "Here's a recap of how an offline system finishes the execution timeline.", "tgt_ref": "以下是离线系统如何完成执行时间线的概述。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_audio": "/acl6060/audio/dev/328.wav", "src_ref": "In online systems, execution overlaps with the utterance timeline, so it ends earlier.", "tgt_ref": "在在线系统中，执行与话语时间线重叠，因此会提前结束。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_audio": "/acl6060/audio/dev/329.wav", "src_ref": "FLR is defined as the reduction time compared to the offline system, marked by the end of the execution.", "tgt_ref": "FLR被定义为与离线系统相比的减少时间，以执行结束为标志。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_audio": "/acl6060/audio/dev/330.wav", "src_ref": "We conduct experiments on two large conversational semantic parsing datasets, SMCalFlow and TreeDST.", "tgt_ref": "我们在两个大的会话式语义解析数据集上进行了实验，即SMCalFlow和TreeDST。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_audio": "/acl6060/audio/dev/331.wav", "src_ref": "Our graph based parser when operating offline, achieves state-of-the-art performance on parsing on both datasets.", "tgt_ref": "当离线操作时，我们基于图形的解析器在两个数据集上的解析都达到了最先进的性能。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_audio": "/acl6060/audio/dev/332.wav", "src_ref": "The LM complete model also achieves nontrivial BLEU gain compared with the simple baseline of node completion.", "tgt_ref": "与节点完成的简单基线相比，LM完成模型也达到了非平凡的BLEU增益。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_audio": "/acl6060/audio/dev/333.wav", "src_ref": "Now, let's look at the prediction accuracy of our prefix to graph parser.", "tgt_ref": "现在，让我们来看看我们对图形解析器前缀的预测准确性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_audio": "/acl6060/audio/dev/334.wav", "src_ref": "We test the match F1 score of graph tuples between the generation and the go graph in validation data in y axis for each prefix length in x axis represented by percentages.", "tgt_ref": "我们测试y轴上验证数据中生成和go图形之间的图形元组的匹配F1分数，以百分比表示x轴上的每个前缀长度。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_audio": "/acl6060/audio/dev/335.wav", "src_ref": "Each of these curves represents a different model with the only difference in training data.", "tgt_ref": "这些曲线中的每一条都代表不同的模型，唯一的区别在于训练数据。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_audio": "/acl6060/audio/dev/336.wav", "src_ref": "The bottom curve is the offline parser, and we mix in prefix data in different lengths to transition the model to an online parser.", "tgt_ref": "最下面的曲线是离线解析器，我们混合不同长度的前缀数据，以将模型转换为在线解析器。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_audio": "/acl6060/audio/dev/337.wav", "src_ref": "For example, the legend prefix eighty percent plus means the model is trained with prefix data with prefix length larger than eighty percent of the full utterance length.", "tgt_ref": "例如，图例前缀80%+表示使用前缀长度大于整个话语长度的80%的前缀数据来训练模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_audio": "/acl6060/audio/dev/338.wav", "src_ref": "The upper left corner is the desired area.", "tgt_ref": "左上角是所需的区域。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_audio": "/acl6060/audio/dev/339.wav", "src_ref": "As we can see, the offline parser in black curve is not doing well on the prefix data.", "tgt_ref": "正如我们所看到的，黑色曲线中的离线解析器在前缀数据上表现不佳。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_audio": "/acl6060/audio/dev/340.wav", "src_ref": "As we're mixing more prefixes in training, the curve is lifting upper and left, performing better on all the prefix lengths.", "tgt_ref": "当我们在训练中混合更多的前缀，曲线向上和向左提升，在所有前缀长度上表现得更好。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_audio": "/acl6060/audio/dev/341.wav", "src_ref": "However, the full utterance parsing performance is not affected in the upper right dot.", "tgt_ref": "然而，在右上角的点中，完整的话语解析表现不受影响。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_audio": "/acl6060/audio/dev/342.wav", "src_ref": "Based on these strong results, how much latency do we reduce?", "tgt_ref": "基于这些强有力的结果，我们可以减少多少延迟？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_audio": "/acl6060/audio/dev/343.wav", "src_ref": "We measure the time by the number of source tokens and simulate different function execution times.", "tgt_ref": "我们通过来源令牌的数量来衡量时间，并模拟不同的函数执行时间。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_audio": "/acl6060/audio/dev/344.wav", "src_ref": "The curves show the tradeoff between the FLR metric and the execution cost, measured by the number of excessive function costs that are not correct.", "tgt_ref": "这些曲线显示了FLR指标和执行成本之间的权衡，通过不正确的超额函数成本的数量来衡量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_audio": "/acl6060/audio/dev/345.wav", "src_ref": "This is achieved by varying the subgraph selection threshold.", "tgt_ref": "这是通过改变子图选择阈值来实现的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_audio": "/acl6060/audio/dev/346.wav", "src_ref": "A higher threshold selects fewer functions of mistake, but obtains a smaller FLR, whereas the lower threshold more aggressively selects and executes programs.", "tgt_ref": "较高的阈值选择较少的错误函数，但获得较小的FLR，而较低的阈值更积极地选择和执行程序。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_audio": "/acl6060/audio/dev/347.wav", "src_ref": "We compare the two approaches we propose and a baseline that does nothing but directly applying the offline parser for online use.", "tgt_ref": "我们比较了我们提出的两种方法和一个基线，这个基线除了直接应用离线解析器用于在线使用外，什么都不做。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_audio": "/acl6060/audio/dev/348.wav", "src_ref": "The upper left region is has the best FLR and cost tradeoff.", "tgt_ref": "左上区域具有最佳FLR和成本权衡。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_audio": "/acl6060/audio/dev/349.wav", "src_ref": "We see both of our methods beat the baseline by a large margin, and they perform more similarly on TreeDST.", "tgt_ref": "我们看到我们的两种方法都以很大的幅度击败了基线，并且它们在TreeDST上的表现更加相似。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_audio": "/acl6060/audio/dev/350.wav", "src_ref": "While individual function execution is faster, there tends to be more run executions and lower latency reduction room.", "tgt_ref": "虽然单个函数的执行速度更快，但往往有更多的运行执行和更低的延迟减少空间。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_audio": "/acl6060/audio/dev/351.wav", "src_ref": "When individual function execution is slower, there is more room for FLR improvement.", "tgt_ref": "当单个函数的执行速度较慢时，FLR的改进空间较大。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_audio": "/acl6060/audio/dev/352.wav", "src_ref": "Our two approaches achieve better performance in different cost cost regions.", "tgt_ref": "我们的两种方法在不同的成本区域实现了更好的表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_audio": "/acl6060/audio/dev/353.wav", "src_ref": "Overall, we achieve thirty to sixty three percent relative latency reduction depending on execution time and allowed cost.", "tgt_ref": "总体而言，我们实现了30%到63%的相对延迟减少，具体取决于执行时间和允许的成本。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_audio": "/acl6060/audio/dev/354.wav", "src_ref": "Finally, we have a breakdown of average latency reduction in tokens for each type of the function node when the allowed cost is three run executions.", "tgt_ref": "最后，当允许的成本是三次运行执行时，我们对每种类型函数节点的令牌中平均延迟减少进行了细分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_audio": "/acl6060/audio/dev/355.wav", "src_ref": "As we can see, there are gains all over the board.", "tgt_ref": "正如我们所看到的，各方面都有收获。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_audio": "/acl6060/audio/dev/356.wav", "src_ref": "There are also some functions on which we gain impressive latency reduction where the red bar is much longer, such as find manager and recipient.", "tgt_ref": "还有一些函数，在红色条较长的情况下，我们获得了令人印象深刻的延迟减少，例如查找管理员和收件人。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_audio": "/acl6060/audio/dev/357.wav", "src_ref": "These are low level functions that do not have much dependency on others.", "tgt_ref": "这些都是较低级别的函数，与其他函数没有太多依赖关系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_audio": "/acl6060/audio/dev/358.wav", "src_ref": "In conclusion, we proposed online semantic parsing as new task to explore with the rigorous latency reduction metric.", "tgt_ref": "总之，我们提出了在线语义解析作为新的任务，以探索严格的延迟减少指标。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_audio": "/acl6060/audio/dev/359.wav", "src_ref": "With a strong graph based semantic parser, we achieve relatively good latency reduction either through our pipeline approach with LM completion and a full parser or directly through a learned parser on the prefixes.", "tgt_ref": "通过强大的基于图形的语义解析器，我们可以通过具有LM补全和完整解析器的管道方法，或者直接通过基于前缀的学习解析器，来实现相对较好的延迟减少。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_audio": "/acl6060/audio/dev/360.wav", "src_ref": "Moreover, our approach can be a general framework and can be applied to other executable semantic representations in different domains.", "tgt_ref": "而且，我们的方法可以是一个通用框架，并且可以应用于不同域中的其他可执行语义表示。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_audio": "/acl6060/audio/dev/361.wav", "src_ref": "Future works could explore smarter prediction and execution integration method.", "tgt_ref": "未来的工作可以探索更智能的预测和执行集成方法。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_audio": "/acl6060/audio/dev/362.wav", "src_ref": "Thanks for your listening.", "tgt_ref": "谢谢聆听！", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_audio": "/acl6060/audio/dev/363.wav", "src_ref": "Hi.", "tgt_ref": "大家好！", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_audio": "/acl6060/audio/dev/364.wav", "src_ref": "I'm going to discuss our work on generating retrieval augmented counterfactuals for question answering tasks.", "tgt_ref": "我将讨论我们在为问题回答任务生成检索增强型反事实方面的工作。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_audio": "/acl6060/audio/dev/365.wav", "src_ref": "This is work done during my internship at Google Research, where I was mentored by Matthew Lamm and Ian Tenney.", "tgt_ref": "这是我在Google Research实习期间完成的工作，在那里我得到了Matthew Lamm和Ian Tenney的指导。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_audio": "/acl6060/audio/dev/366.wav", "src_ref": "To motivate the task, let me begin by defining a counterfactual.", "tgt_ref": "为了激发这项任务的动机，让我从定义一个反事实开始。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_audio": "/acl6060/audio/dev/367.wav", "src_ref": "In this work, we define a counterfactual as a perturbation of the input text that differs in some meaningful controlled way from the original text.", "tgt_ref": "在这项工作中，我们将反事实定义为输入 文本的扰动，其在某种有意义的受控方式上与原始文本不同。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_audio": "/acl6060/audio/dev/368.wav", "src_ref": "And allows us to reason about the changes in the outcome or the task label.", "tgt_ref": "并允许我们对结果或任务标签的变化进行推理。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_audio": "/acl6060/audio/dev/369.wav", "src_ref": "For instance, changing the words fascinating to captivating or expected to mind-numbing changes the sentiment for this movie review.", "tgt_ref": "例如，将单词“引人入胜”改为“令人着迷”，或将“意料之中”改为“单调无聊”，就会改变这篇电影评论的情绪。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_audio": "/acl6060/audio/dev/370.wav", "src_ref": "Similarly, adding the qualifier women's to the question changes the answer to the question in the example below.", "tgt_ref": "同样，在下面的示例中，在问题中添加限定词“women's”，就会改变问题的回答。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_audio": "/acl6060/audio/dev/371.wav", "src_ref": "Humans are typically robust to such perturbations compared to NLP models trained on the task.", "tgt_ref": "与在任务上训练的自然语言处理模型相比，人类通常对这种扰动具有很强的适应性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_audio": "/acl6060/audio/dev/372.wav", "src_ref": "Why is that?", "tgt_ref": "为什么会这样？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_audio": "/acl6060/audio/dev/373.wav", "src_ref": "The dataset may be sampled with systematic biases that lead to a simple decision boundary that is violated by the counterfactual.", "tgt_ref": "数据集可以通过系统性偏见进行采样，从而导致一个简单的决策边界被反事实所违反。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_audio": "/acl6060/audio/dev/374.wav", "src_ref": "As shown in this 2D classification problem.", "tgt_ref": "正如这个2D分类问题中所示。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_audio": "/acl6060/audio/dev/375.wav", "src_ref": "My work has found that adding counterfactual examples to the training data can make the model robust to such perturbations.", "tgt_ref": "我的工作发现，在训练数据中添加反事实示例可以使模型对这种扰动具有鲁棒性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_audio": "/acl6060/audio/dev/376.wav", "src_ref": "So, if counterfactuals are valuable, how can we generate them?", "tgt_ref": "那么，如果反事实是有价值的，我们如何才能产生它们呢？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_audio": "/acl6060/audio/dev/377.wav", "src_ref": "This task is especially hard for NLP because here are three examples from three different NLP tasks.", "tgt_ref": "这个任务对于自然语言处理来说尤其困难，因为这里有三个来自三个不同自然语言处理任务的例子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_audio": "/acl6060/audio/dev/378.wav", "src_ref": "As you can see, examples that violate the decision boundary between outcomes need to be very carefully crafted by perturbing some attributes of the text that are underlined here.", "tgt_ref": "正如大家所看到的，违反结果之间的决策边界的例子需要通过扰乱此处下划线的文本的某些属性来精心制作。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_audio": "/acl6060/audio/dev/379.wav", "src_ref": "This could be done by human annotation, but this is expensive and biased.", "tgt_ref": "这可以通过人类注释来完成，但这样做不仅昂贵，而且还带有偏见。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_audio": "/acl6060/audio/dev/380.wav", "src_ref": "Some prior work has focused on using syntax trees or semantic role labeling.", "tgt_ref": "之前的一些工作侧重于使用句法树或语义角色标签。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_audio": "/acl6060/audio/dev/381.wav", "src_ref": "But the set of perturbations generated by these techniques are limited by the semantic framework.", "tgt_ref": "但是，由这些技术生成的扰动集受到语义框架的限制。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_audio": "/acl6060/audio/dev/382.wav", "src_ref": "More recent work has used masked language models to fill in masked portions of the text to change labels.", "tgt_ref": "最近的工作使用掩码语言模型来填充文本的掩码部分以更改标签。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_audio": "/acl6060/audio/dev/383.wav", "src_ref": "But finding what parts of the text to perturb can be challenging.", "tgt_ref": "但是，找出文本的哪些部分会造成扰动是一项具有挑战性的工作。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_audio": "/acl6060/audio/dev/384.wav", "src_ref": "There are more challenges to generating counterfactuals for question answering specifically.", "tgt_ref": "具体而言，在为问题回答生成反事实产生方面存在更多的挑战。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_audio": "/acl6060/audio/dev/385.wav", "src_ref": "This task requires background knowledge.", "tgt_ref": "这项任务需要背景知识。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_audio": "/acl6060/audio/dev/386.wav", "src_ref": "For instance, to perturb the original question is Indiana Jones Temple of Doom a prequel?", "tgt_ref": "例如，为了扰乱原来的问题，《夺宝奇兵之末日神庙》是一部前传吗？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_audio": "/acl6060/audio/dev/387.wav", "src_ref": "We need to be aware of the other movies in the franchise to get to a question like is Indiana Jones Raiders of the Lost Ark a prequel?", "tgt_ref": "我们需要了解《夺宝奇兵》系列的其他电影，才能回答这样的问题：《夺宝奇兵之法柜奇兵》是一部前传吗？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_audio": "/acl6060/audio/dev/388.wav", "src_ref": "Furthermore, random perturbations can lead to questions that are not answerable with the available evidence or have false premises.", "tgt_ref": "此外，随机扰动可能导致无法用现有证据回答或具有错误前提的问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_audio": "/acl6060/audio/dev/389.wav", "src_ref": "Moreover, some question perturbations can lead to significant semantic drift from the original input.", "tgt_ref": "而且，一些问题扰动可能导致与原始输入的显著语义偏差。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_audio": "/acl6060/audio/dev/390.wav", "src_ref": "For instance, this question is Indiana Jones practicing child slavery in Temple of Doom?", "tgt_ref": "例如，这个问题是印第安纳·琼斯是否在《末日神庙》中奴役儿童？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_audio": "/acl6060/audio/dev/391.wav", "src_ref": "We propose a very simple yet effective technique called retrieve generate filter or RGF, to tackle counterfactual perturbations of questions, and also aims to tackle all the other aforementioned challenges.", "tgt_ref": "我们提出一种非常简单但有效的技术，称为检索生成过滤器或RGF，以解决问题的反事实扰动，并旨在解决上述所有其他挑战。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_audio": "/acl6060/audio/dev/392.wav", "src_ref": "The core intuition behind RGF is that the necessary background information that is needed to generate perturbations may be present in the near misses made by a question answering model.", "tgt_ref": "RGF背后的核心直觉是，产生扰动所需的必要背景信息可能存在于问题回答模型造成的未遂事件中。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_audio": "/acl6060/audio/dev/393.wav", "src_ref": "For instance, the state-of-the-art model REALM produces the following top k answers to the question who is the captain of the Richmond Football Club?", "tgt_ref": "例如，最先进的模型REALM为“谁是里士满足球俱乐部的队长”这个问题提供以下前k个回答？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_audio": "/acl6060/audio/dev/394.wav", "src_ref": "While it does recover the original reference passage and answer Trent Cotchin as the top most choice.", "tgt_ref": "虽然它确实提取了原始参考段落并回答“Trent Cotchin”作为首选。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_audio": "/acl6060/audio/dev/395.wav", "src_ref": "It also retrieves additional passages and answers which can be used to guide question perturbation.", "tgt_ref": "它还检索了其他段落和回答，可用于指导问题扰动。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_audio": "/acl6060/audio/dev/396.wav", "src_ref": "For instance, it recovers two more answers corresponding to the captains of the reserve team and the women's team of the same club, and this can lead to interesting edits.", "tgt_ref": "例如，它还提取了另外两个回答，分别对应于同一俱乐部预备队和女队的队长，这可能会带来有趣的编辑。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_audio": "/acl6060/audio/dev/397.wav", "src_ref": "To summarize, RGF first retrieves top k most relevant answers and contexts which don't match the reference answer in context.", "tgt_ref": "总而言之，RGF首先检索前k个最相关的回答和上下文中与参考回答不匹配的上下文。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_audio": "/acl6060/audio/dev/398.wav", "src_ref": "Following this step, the question generation model conditions on these alternate answers to generate a question that corresponds to them.", "tgt_ref": "在这一步骤之后，问题生成模型以这些备选回答为条件，生成一个与它们相对应的问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_audio": "/acl6060/audio/dev/399.wav", "src_ref": "And finally, we can filter the generated questions based on minimality or based on the type of semantic perturbation we are interested in introducing.", "tgt_ref": "最后，我们可以基于最小化或基于我们有兴趣引入的语义扰动的类型来过滤生成的问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_audio": "/acl6060/audio/dev/400.wav", "src_ref": "Going over each step in greater detail for retrieval, we use a retrieve then read model like REALM that takes as input the original question, and a large corpus like Wikipedia.", "tgt_ref": "更详细地检查检索的每个步骤，我们使用检索然后读取模型，如REALM，将原始问题作为输入，并使用像维基百科这样的大型语料库。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_audio": "/acl6060/audio/dev/401.wav", "src_ref": "It consists of two modules.", "tgt_ref": "它由两个模块组成。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_audio": "/acl6060/audio/dev/402.wav", "src_ref": "The retriever module performs similarity search over a dense index of passages to retrieve the top k most relevant passages to the question.", "tgt_ref": "检索器模块对密集的段落索引执行相似性搜索，以检索与问题最相关的前k个段落。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_audio": "/acl6060/audio/dev/403.wav", "src_ref": "And a reader module then extracts a span from each passage as a potential answer.", "tgt_ref": "然后，阅读器模块从每个段落中提取一个跨度作为潜在的回答。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_audio": "/acl6060/audio/dev/404.wav", "src_ref": "REALM retrieves the gold passage and answer in most cases.", "tgt_ref": "在大多数情况下，REALM会检索黄金段落和回答。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_audio": "/acl6060/audio/dev/405.wav", "src_ref": "However, in this work, we are more interested in the answers and context that it retrieves further down the line.", "tgt_ref": "然而，在这项工作中，我们更感兴趣的是它进一步检索的回答案和上下文。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_audio": "/acl6060/audio/dev/406.wav", "src_ref": "In the next step, question generation, we use these alternate answers and contexts to regenerate new questions that correspond to these alternatives.", "tgt_ref": "在下一步问题生成中，我们使用这些备选回答和上下文来重新生成与这些备选回答相对应的新问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_audio": "/acl6060/audio/dev/407.wav", "src_ref": "Question generation model is a pre trained text-to-text transformer that is fine-tuned on the NQ data to generate a question for an answer that's marked in context.", "tgt_ref": "问题生成模型是一个预先训练好的文本到文本的转换器，它在NQ数据上进行了微调，以针对已在上下文中标记的回答生成一个问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_audio": "/acl6060/audio/dev/408.wav", "src_ref": "During inference we supply the question generation model, the alternative answer and context that we retrieved in the previous step.", "tgt_ref": "在推理过程中，我们提供问题生成模型、备选回答以及我们在前一步中检索到的上下文。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_audio": "/acl6060/audio/dev/409.wav", "src_ref": "For example, for the query who is the captain of the Richmond Football Club? REALM retrieves passages about the club's women's team, captained by Jess Kennedy, and the question generation model generates the query who captained Richmond Football Club's first ever women's team?", "tgt_ref": "例如，对于“谁是里士满足球俱乐部的队长？”这个询问，REALM检索由Jess Kennedy担任队长的俱乐部女队的段落，而问题生成模型生成询问“谁是里士满足球俱乐部有史以来第一支女子足球队的队长？”", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_audio": "/acl6060/audio/dev/410.wav", "src_ref": "Which has a specific semantic perturbation.", "tgt_ref": "它有一个特定的语义扰动。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_audio": "/acl6060/audio/dev/411.wav", "src_ref": "In a similar fashion, we also get queries like who captained Richmond's VFL Reserve team?", "tgt_ref": "通过类似的方式，我们也会得到一些这样的询问，比如“谁是里士满VFL预备队的队长？”", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_audio": "/acl6060/audio/dev/412.wav", "src_ref": "Or who did graham negate in the grand final last year?", "tgt_ref": "或者“格雷厄姆在去年的总决赛中打败了谁？”", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_audio": "/acl6060/audio/dev/413.wav", "src_ref": "Finally, we filter out a subset of the generated queries based on some desired characteristics.", "tgt_ref": "最后，我们根据一些期望的特征过滤掉生成的询问的一个子集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_audio": "/acl6060/audio/dev/414.wav", "src_ref": "As motivated earlier, we would like to ensure that the new question is still semantically close to the original.", "tgt_ref": "如前所述，我们希望确保新的问题仍然在语义上接近原始问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_audio": "/acl6060/audio/dev/415.wav", "src_ref": "For filtering techniques that doesn't require additional supervision, we simply retain new questions that have a small token label edit distance from the original question.", "tgt_ref": "对于不需要额外监督的过滤技术，我们只需保留与原始问题有较小令牌标签编辑距离的新问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 416, "src_audio": "/acl6060/audio/dev/416.wav", "src_ref": "For example, we remove the question who did graham negate in the grand final last year?", "tgt_ref": "例如，我们删除了“格雷厄姆在去年的总决赛中打败了谁？”的问题 。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 417, "src_audio": "/acl6060/audio/dev/417.wav", "src_ref": "Because it has a longer edit distance from the original question.", "tgt_ref": "因为它与原始问题有一个较长的编辑距离。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 418, "src_audio": "/acl6060/audio/dev/418.wav", "src_ref": "In our experiments, we demonstrate that this simple heuristic can be used to augment and queue training data.", "tgt_ref": "在我们的实验中，我们证明了这个简单的启发式可以用来增强训练数据并将其排入队列。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 419, "src_audio": "/acl6060/audio/dev/419.wav", "src_ref": "We also experiment with a filtering strategy that is based on the type of semantic perturbation.", "tgt_ref": "我们还试验了一种基于语义扰动类型的过滤策略。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 420, "src_audio": "/acl6060/audio/dev/420.wav", "src_ref": "To this end, we use a general purpose query decomposition framework called QED.", "tgt_ref": "为此，我们使用了一个名为QED的通用询问分解框架。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 421, "src_audio": "/acl6060/audio/dev/421.wav", "src_ref": "QED identifies two parts to the question, a predicate and a reference.", "tgt_ref": "QED确定问题的两个部分，一个是谓词，一个是引用。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 422, "src_audio": "/acl6060/audio/dev/422.wav", "src_ref": "References are noun phrases in the question that correspond to entities in the context.", "tgt_ref": "引用是问题中与上下文中的实体相对应的名词短语。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 423, "src_audio": "/acl6060/audio/dev/423.wav", "src_ref": "A predicate is basically the remaining portion of the question.", "tgt_ref": "谓词基本上是问题的剩余部分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 424, "src_audio": "/acl6060/audio/dev/424.wav", "src_ref": "For example, we are able to decompose the query who captained Richmond's first ever women's team into two references: Richmond Football Club women's team and the predicate who captained X.", "tgt_ref": "例如，我们能够将“谁是里士满足球俱乐部有史以来第一支女子足球队的队长”的询问分解为两个参考：里士满足球俱乐部女子足球队和谁担任队长X的谓词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 425, "src_audio": "/acl6060/audio/dev/425.wav", "src_ref": "A model trained on reference predicate annotations for NQ gives us this question decomposition.", "tgt_ref": "在NQ的引用谓词注释上训练的模型为我们提供了这个问题的分解。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 426, "src_audio": "/acl6060/audio/dev/426.wav", "src_ref": "Decomposing both the original and generated question based on QED allows us to categorize our generated counterfactuals for evaluation.", "tgt_ref": "根据QED分解原始问题和生成的问题，使我们能够对生成的反事实进行分类评估。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 427, "src_audio": "/acl6060/audio/dev/427.wav", "src_ref": "Specifically, we obtain two groups of questions.", "tgt_ref": "具体而言，我们得到两组问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 428, "src_audio": "/acl6060/audio/dev/428.wav", "src_ref": "Those that undergo a reference change while retaining predicates, and those that undergo a predicate change and optionally add references.", "tgt_ref": "在保留谓词的同时进行引用更改的问题，以及进行谓词更改并可选地添加引用的问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 429, "src_audio": "/acl6060/audio/dev/429.wav", "src_ref": "For instance, who captained Richmond's VFL reserve team is a reference change?", "tgt_ref": "例如，“谁是里士满VFL预备队的队长？”是进行引用更改。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 430, "src_audio": "/acl6060/audio/dev/430.wav", "src_ref": "While, who wears number nine for the club is a predicate change.", "tgt_ref": "而“谁在俱乐部穿9号球衣”是进行谓词更改。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 431, "src_audio": "/acl6060/audio/dev/431.wav", "src_ref": "We now evaluate the effectiveness of RGF perturbations when augmented to training data.", "tgt_ref": "我们现在评估当增强到训练数据时RGF扰动的有效性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 432, "src_audio": "/acl6060/audio/dev/432.wav", "src_ref": "So, to effectively evaluate the effectiveness of counterfactual augmentation in particular, we experiment with two strong data augmentation baselines.", "tgt_ref": "因此，为了有效地评估反事实增强的有效性，我们特别对两个强大的数据增强基线进行实验。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 433, "src_audio": "/acl6060/audio/dev/433.wav", "src_ref": "The first baseline, called random answer and question generation, adds data that has no relation with the original question.", "tgt_ref": "第一个基线称为随机回答和问题生成，添加了与原始问题没有关系的数据。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 434, "src_audio": "/acl6060/audio/dev/434.wav", "src_ref": "That is, passages and answers are simply randomly sampled from Wikipedia.", "tgt_ref": "也就是说，段落和回答都是从维基百科中随机抽取的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 435, "src_audio": "/acl6060/audio/dev/435.wav", "src_ref": "This baseline basically adds more data that looks like NQ.", "tgt_ref": "这个基线基本上增加了更多看起来像NQ的数据。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 436, "src_audio": "/acl6060/audio/dev/436.wav", "src_ref": "With the second baseline gold answer and question generation, we specifically update the retrieval portion of our method.", "tgt_ref": "通过第二个基线黄金回答和问题生成，我们特别更新了我们方法的检索部分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 437, "src_audio": "/acl6060/audio/dev/437.wav", "src_ref": "Here, alternate answers are just chosen from the same passage that contained the gold answer.", "tgt_ref": "在这里，备选回答是从包含黄金回答的相同段落中选择的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 438, "src_audio": "/acl6060/audio/dev/438.wav", "src_ref": "How base how do the baselines and RGF ah augmentation perform on reading comprehension where the model has access to question and context?", "tgt_ref": "在模型能够访问问题和上下文的情况下，基线和RGF增强在阅读理解方面的表现如何？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 439, "src_audio": "/acl6060/audio/dev/439.wav", "src_ref": "We experiment with six out of domain datasets and present results here, where data is the training data is doubled in augmentation.", "tgt_ref": "我们对域数据集中的六个数据集进行了实验，并在这里展示了结果，其中数据是训练数据，在增强中增加了一倍。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 440, "src_audio": "/acl6060/audio/dev/440.wav", "src_ref": "We find that both data augmentation baselines are not able to improve our domain generalization.", "tgt_ref": "我们发现两个数据增强基线都无法改善我们的域泛化。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 441, "src_audio": "/acl6060/audio/dev/441.wav", "src_ref": "In fact, an ensemble of six models trained on the original data seems to be the most competitive baseline.", "tgt_ref": "事实上，在原始数据上训练的六个模型的集合似乎是最具竞争力的基线。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 442, "src_audio": "/acl6060/audio/dev/442.wav", "src_ref": "Comparing against that baseline, we find that RGF counterfactuals are able to improve out of domain performance while maintaining in domain performance.", "tgt_ref": "与基线相比，我们发现RGF反事实能够提高域外表现，同时保持域内表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 443, "src_audio": "/acl6060/audio/dev/443.wav", "src_ref": "This suggests that filling in the reasoning gaps of the model via counterfactual augmentation is more effective than adding more data from the training distribution.", "tgt_ref": "这表明通过反事实增强填补模型的推理空白，比从训练分布中添加更多的数据更有效。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 444, "src_audio": "/acl6060/audio/dev/444.wav", "src_ref": "Furthermore, we find that using retrieval to sample alternative outcomes or answers is important for effective CDA.", "tgt_ref": "此外，我们发现，使用检索对备选结果或回答进行抽样，对于有效的CDA非常重要。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 445, "src_audio": "/acl6060/audio/dev/445.wav", "src_ref": "We also experiment with open domain QA setting where the model only sees the question and once again we evaluate on four out of domain datasets.", "tgt_ref": "我们还尝试了开放域 问答设置，其中模型只看到问题，然后我们再次对域数据集中的四个数据集进行评估。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 446, "src_audio": "/acl6060/audio/dev/446.wav", "src_ref": "We find that baseline models are not as effective for out of domain generalization.", "tgt_ref": "我们发现基线模型对域外泛化并不那么有效。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 447, "src_audio": "/acl6060/audio/dev/447.wav", "src_ref": "However, data augmentation with RGF shows more significant improvements.", "tgt_ref": "然而，使用RGF的数据增强显示出更显著的改进。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 448, "src_audio": "/acl6060/audio/dev/448.wav", "src_ref": "We even improve in the in domain NQ dataset.", "tgt_ref": "我们甚至在域NQ数据集中进行了改进。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 449, "src_audio": "/acl6060/audio/dev/449.wav", "src_ref": "We hypothesized that the counterfactual data augmentation aids the model in learning better query encodings for very similar queries.", "tgt_ref": "我们假设反事实数据增强有助于模型学习更好的询问编码，用于非常相似的询问。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 450, "src_audio": "/acl6060/audio/dev/450.wav", "src_ref": "Finally, we also evaluate on the model's ability to improve consistency in the local neighborhood of the original question.", "tgt_ref": "最后，我们还评估了模型在原始问题的局部邻域中提高一致性的能力。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 451, "src_audio": "/acl6060/audio/dev/451.wav", "src_ref": "Consistency measures the proportion of questions correctly answered by the model where both the original and the counterfactual query are correctly answered.", "tgt_ref": "一致性衡量的是模型正确回答问题的比例，其中原始问题和反事实询问都得到了正确回答。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 452, "src_audio": "/acl6060/audio/dev/452.wav", "src_ref": "This explicitly helps us to measure the model's robustness to small perturbations in the neighborhood of the original input.", "tgt_ref": "这显然有助于我们衡量模型对原始输入邻域中的小扰动的鲁棒性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 453, "src_audio": "/acl6060/audio/dev/453.wav", "src_ref": "We experiment with five datasets which contain pairs of questions that are semantically close to each other.", "tgt_ref": "我们对五个数据集进行了实验，这些数据集包含语义上彼此接近的问题对。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 454, "src_audio": "/acl6060/audio/dev/454.wav", "src_ref": "Apart from the three datasets AQA, AmbigQA and QUOREF-Contrast set that are already available, we also evaluate on RGF counterfactuals that are paired with original NQ questions based on whether they underwent a predicate change or reference change.", "tgt_ref": "除了已经可用的三个数据集AQA、AmbigQA和QUOREF-对比集之外，我们还根据RGF反事实与原始NQ问题配对，评估它们是否经历了谓词变化或引用变化。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 455, "src_audio": "/acl6060/audio/dev/455.wav", "src_ref": "These subsets were annotated in-house to eliminate noise and are provided as a resource.", "tgt_ref": "这些子集在内部进行了注释，以消除噪声，并作为资源提供。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 456, "src_audio": "/acl6060/audio/dev/456.wav", "src_ref": "All baselines are unable to significantly improve consistency with the ensemble model improving consistency by a small margin.", "tgt_ref": "所有基线都无法显著提高与整体模型的一致性，只能小幅提高一致性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 457, "src_audio": "/acl6060/audio/dev/457.wav", "src_ref": "However, RGF counterfactual augmentation has impressive gains in consistency both on prior datasets and the two subsets we curated for reference and predicate perturbations.", "tgt_ref": "然而，RGF反事实增强在先前的数据集和我们为引用和谓词扰动策划的两个子集上的一致性方面都取得了令人印象深刻的提高。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 458, "src_audio": "/acl6060/audio/dev/458.wav", "src_ref": "Note that the augmented RGF data is not biased by perturbation type, only the evaluation sets are.", "tgt_ref": "请注意，增强RGF数据不会因扰动类型而产生偏差，只有评估集才会产生偏差。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 459, "src_audio": "/acl6060/audio/dev/459.wav", "src_ref": "In fact, a qualitative inspection of the kinds of counterfactuals generated show that the generated questions contain several diverse perturbations.", "tgt_ref": "事实上，对生成的各种反事实的定性检查表明，生成的问题包含几种不同的扰动。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 460, "src_audio": "/acl6060/audio/dev/460.wav", "src_ref": "For instance, this original question on the population of Walnut Grove, Minnesota is perturbed along different dimensions like town, state, country, and along different predicates like location, poverty, number of schools.", "tgt_ref": "例如，这个关于明尼苏达州沃尔纳特格罗夫人口的原始问题在不同维度上受到扰动，如城镇、州、国家，以及不同的谓词，如位置、贫困、学校数量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 461, "src_audio": "/acl6060/audio/dev/461.wav", "src_ref": "Audio of perturbations are context specific.", "tgt_ref": "扰动的音频是上下文特定的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 462, "src_audio": "/acl6060/audio/dev/462.wav", "src_ref": "For example, for this other question about the Wimbledon ah singles tournament, the perturbation is along type of game, type of tournament, or the game outcome.", "tgt_ref": "例如，这另一个问题与温布尔登网球公开赛单打锦标赛有关，扰动取决于比赛类型、锦标赛类型或比赛结果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 463, "src_audio": "/acl6060/audio/dev/463.wav", "src_ref": "Final takeaways; we tackle the task of counterfactual data augmentation and perturbations for information seeking queries and tackle its unique challenges via a reversal of the generation approach, over generate using near misses of the model and filter based on perturbation type or minimality.", "tgt_ref": "最后的总结：我们解决了反事实数据增强和信息扰动寻求询问的任务，并通过逆转生成方法来解决其独特的挑战，通过使用模型的未遂事件来过度生成，并根据扰动类型或最小化进行过滤。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 464, "src_audio": "/acl6060/audio/dev/464.wav", "src_ref": "We find that this technique requires no additional supervision and the examples are labeled for augmentation.", "tgt_ref": "我们发现这种技术不需要额外的监督，并且这些示例被标记用于增强。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 465, "src_audio": "/acl6060/audio/dev/465.wav", "src_ref": "Augmentation improves out of domain generalization and neighborhood consistency.", "tgt_ref": "增强改善了域外泛化和邻域一致性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 31, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 466, "src_audio": "/acl6060/audio/dev/466.wav", "src_ref": "And we find that RGF counterfactuals are semantically diverse without introducing bias during augmentation.", "tgt_ref": "我们发现，RGF反事实在语义上是多样化的，不会在增强过程中引入偏差。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 31, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 467, "src_audio": "/acl6060/audio/dev/467.wav", "src_ref": "Thank you.", "tgt_ref": "谢谢！", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 31, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 468, "src_audio": "/acl6060/audio/eval/468.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 469, "src_audio": "/acl6060/audio/eval/469.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "tgt_ref": "我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 470, "src_audio": "/acl6060/audio/eval/470.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "tgt_ref": "首先，我想谈谈我们对于推理的动机。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 471, "src_audio": "/acl6060/audio/eval/471.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "tgt_ref": "在这里，我们展示了一个多步骤推理有帮助的例子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 472, "src_audio": "/acl6060/audio/eval/472.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "tgt_ref": "这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 473, "src_audio": "/acl6060/audio/eval/473.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "tgt_ref": "在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 474, "src_audio": "/acl6060/audio/eval/474.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "tgt_ref": "但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 475, "src_audio": "/acl6060/audio/eval/475.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "tgt_ref": "所以，最好将可解释的多步骤推理作为输出。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 476, "src_audio": "/acl6060/audio/eval/476.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "tgt_ref": "我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 477, "src_audio": "/acl6060/audio/eval/477.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "tgt_ref": "在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 478, "src_audio": "/acl6060/audio/eval/478.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "tgt_ref": "在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 479, "src_audio": "/acl6060/audio/eval/479.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "tgt_ref": "某些假设也适用于之前的工作。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 480, "src_audio": "/acl6060/audio/eval/480.wav", "src_ref": "We assume the precision of quantities are known.", "tgt_ref": "我们假设数量的精确度是已知的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 481, "src_audio": "/acl6060/audio/eval/481.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "tgt_ref": "并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 482, "src_audio": "/acl6060/audio/eval/482.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "tgt_ref": "此外，复杂的运算符实际上可以分解成这些基本运算符。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 483, "src_audio": "/acl6060/audio/eval/483.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "tgt_ref": "之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 484, "src_audio": "/acl6060/audio/eval/484.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "tgt_ref": "传统的序列到序列模型将表达式转换为特定的序列以进行生成。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 485, "src_audio": "/acl6060/audio/eval/485.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "tgt_ref": "这很容易实现，可以概括成许多不同的复杂问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 486, "src_audio": "/acl6060/audio/eval/486.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "tgt_ref": "但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 487, "src_audio": "/acl6060/audio/eval/487.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "tgt_ref": "但因为转换器模型的原因，实际上这个方向仍然很受欢迎。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 488, "src_audio": "/acl6060/audio/eval/488.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "tgt_ref": "因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 489, "src_audio": "/acl6060/audio/eval/489.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "tgt_ref": "所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 490, "src_audio": "/acl6060/audio/eval/490.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "tgt_ref": "这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 491, "src_audio": "/acl6060/audio/eval/491.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "tgt_ref": "其次，其中还包含一些重复的计算。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 492, "src_audio": "/acl6060/audio/eval/492.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "tgt_ref": "如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 493, "src_audio": "/acl6060/audio/eval/493.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "tgt_ref": "在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 494, "src_audio": "/acl6060/audio/eval/494.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "tgt_ref": "例如，在第二步中，我们可以得到这些除数，即27。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 495, "src_audio": "/acl6060/audio/eval/495.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "tgt_ref": "我们也可以回头参考原始问题来查找相关内容。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 496, "src_audio": "/acl6060/audio/eval/496.wav", "src_ref": "And in these steps we obtain the divisors.", "tgt_ref": "在这些步骤中，我们得到了除数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 497, "src_audio": "/acl6060/audio/eval/497.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "tgt_ref": "然后在第三步，我们实际上得到了商。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 498, "src_audio": "/acl6060/audio/eval/498.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "tgt_ref": "好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 499, "src_audio": "/acl6060/audio/eval/499.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "tgt_ref": "在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 500, "src_audio": "/acl6060/audio/eval/500.wav", "src_ref": "So this makes the process more accurate.", "tgt_ref": "这使得这个过程更加准确。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 501, "src_audio": "/acl6060/audio/eval/501.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "tgt_ref": "在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 502, "src_audio": "/acl6060/audio/eval/502.wav", "src_ref": "So, the expression is represented by e i j o p.", "tgt_ref": "表达式由e i j o p表示。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 503, "src_audio": "/acl6060/audio/eval/503.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "tgt_ref": "我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 504, "src_audio": "/acl6060/audio/eval/504.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "tgt_ref": "我们在这里也有减法与单词代表相反的方向。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 505, "src_audio": "/acl6060/audio/eval/505.wav", "src_ref": "This is quite similar to relation extraction.", "tgt_ref": "这与关系提取 非常相似。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 506, "src_audio": "/acl6060/audio/eval/506.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "tgt_ref": "在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 507, "src_audio": "/acl6060/audio/eval/507.wav", "src_ref": "We add it to the next state to become a new quantity.", "tgt_ref": "我们把它添加到下一个状态，成为一个新的数量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 508, "src_audio": "/acl6060/audio/eval/508.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "tgt_ref": "这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 509, "src_audio": "/acl6060/audio/eval/509.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "tgt_ref": "在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 510, "src_audio": "/acl6060/audio/eval/510.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "tgt_ref": "一旦我们得到数量陈述，我们就可以开始做推理。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 511, "src_audio": "/acl6060/audio/eval/511.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "tgt_ref": "这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 512, "src_audio": "/acl6060/audio/eval/512.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "tgt_ref": "首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 513, "src_audio": "/acl6060/audio/eval/513.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "tgt_ref": "最后，我们得到表达式表达q_1除以q_2。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 514, "src_audio": "/acl6060/audio/eval/514.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "tgt_ref": "但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 515, "src_audio": "/acl6060/audio/eval/515.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "tgt_ref": "这里所有可能的表达式等于运算符数量的三倍。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 516, "src_audio": "/acl6060/audio/eval/516.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "tgt_ref": "这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 517, "src_audio": "/acl6060/audio/eval/517.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "tgt_ref": "例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 518, "src_audio": "/acl6060/audio/eval/518.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "tgt_ref": "所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 519, "src_audio": "/acl6060/audio/eval/519.wav", "src_ref": "So this quantity come from the previous calculated expression.", "tgt_ref": "所以，这个数量来自之前计算的表达式。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 520, "src_audio": "/acl6060/audio/eval/520.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "tgt_ref": "我们最终可以得到最后这个表达式q_3乘以q_4。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 521, "src_audio": "/acl6060/audio/eval/521.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "tgt_ref": "我们还可以看到，所有可能的表达式的数字与之前的步骤不同。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 522, "src_audio": "/acl6060/audio/eval/522.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "tgt_ref": "这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 523, "src_audio": "/acl6060/audio/eval/523.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "tgt_ref": "训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 524, "src_audio": "/acl6060/audio/eval/524.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "tgt_ref": "在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 525, "src_audio": "/acl6060/audio/eval/525.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "tgt_ref": "这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 526, "src_audio": "/acl6060/audio/eval/526.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "tgt_ref": "它还允许我们根据先前的知识施加某些约束。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 527, "src_audio": "/acl6060/audio/eval/527.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "tgt_ref": "我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 528, "src_audio": "/acl6060/audio/eval/528.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "tgt_ref": "在这里，我们简要地展示了与之前最佳方法相比的结果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 529, "src_audio": "/acl6060/audio/eval/529.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "tgt_ref": "我们表现最好的变体是Roberta-DeductiveReasoner。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 530, "src_audio": "/acl6060/audio/eval/530.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "tgt_ref": "事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 531, "src_audio": "/acl6060/audio/eval/531.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "tgt_ref": "没错。最好的方法通常是基于树的模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 532, "src_audio": "/acl6060/audio/eval/532.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "tgt_ref": "总的来说，我们的推理能够显著优于这个基于树的模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 533, "src_audio": "/acl6060/audio/eval/533.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "tgt_ref": "但我们可以看到，MathQA或SVAMP上的绝对数字并不高。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 534, "src_audio": "/acl6060/audio/eval/534.wav", "src_ref": "So we further investigate the results on SVAMP.", "tgt_ref": "我们进一步研究SVAMP的结果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 535, "src_audio": "/acl6060/audio/eval/535.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "tgt_ref": "这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 536, "src_audio": "/acl6060/audio/eval/536.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "tgt_ref": "在我们的预测中，我们发现一些中间值实际上是负数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 537, "src_audio": "/acl6060/audio/eval/537.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "tgt_ref": "例如，在这些问题中，我们问Jake有多少个苹果？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 538, "src_audio": "/acl6060/audio/eval/538.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "tgt_ref": "但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 539, "src_audio": "/acl6060/audio/eval/539.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "tgt_ref": "我们的模型做出了一些这样的预测，产生了负值。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 540, "src_audio": "/acl6060/audio/eval/540.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "tgt_ref": "我们观察到这两个表达式实际上有相似的分数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 541, "src_audio": "/acl6060/audio/eval/541.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "tgt_ref": "我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 542, "src_audio": "/acl6060/audio/eval/542.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "tgt_ref": "我们进一步发现，针对某些模型，这种约束实际上改善了很多。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 543, "src_audio": "/acl6060/audio/eval/543.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "tgt_ref": "例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 544, "src_audio": "/acl6060/audio/eval/544.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "tgt_ref": "因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 545, "src_audio": "/acl6060/audio/eval/545.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "tgt_ref": "我们还试图分析所有这些数据集背后的困难。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 546, "src_audio": "/acl6060/audio/eval/546.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "tgt_ref": "我们假设这里的未使用数量的数量可以被视为不相关的信息。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 547, "src_audio": "/acl6060/audio/eval/547.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "tgt_ref": "在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 548, "src_audio": "/acl6060/audio/eval/548.wav", "src_ref": "And here we also show the overall performance.", "tgt_ref": "在这里，我们还展示了整体表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 549, "src_audio": "/acl6060/audio/eval/549.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "tgt_ref": "对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 550, "src_audio": "/acl6060/audio/eval/550.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "tgt_ref": "但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 551, "src_audio": "/acl6060/audio/eval/551.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "tgt_ref": "对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 552, "src_audio": "/acl6060/audio/eval/552.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "tgt_ref": "最后，我们想通过一个问题扰动的例子来展示可解释性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 553, "src_audio": "/acl6060/audio/eval/553.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "tgt_ref": "在这里，我们的模型实际上在第一步就做出了错误的预测。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 554, "src_audio": "/acl6060/audio/eval/554.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "tgt_ref": "我们实际上可以将这个表达式与这里的句子相关联。好。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 555, "src_audio": "/acl6060/audio/eval/555.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "tgt_ref": "我们认为这个句子可能会误导模型做出错误的预测。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 556, "src_audio": "/acl6060/audio/eval/556.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "tgt_ref": "在这里再植入一个35，会使得模型以为它是一个加法运算符。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 557, "src_audio": "/acl6060/audio/eval/557.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "tgt_ref": "我们尝试将句子修改为类似梨树的数量比苹果树少35棵。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 558, "src_audio": "/acl6060/audio/eval/558.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "tgt_ref": "我们使其传达更准确的语义，以便模型能够使预测正确。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 559, "src_audio": "/acl6060/audio/eval/559.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "tgt_ref": "这项研究展示了可解释预测如何帮助我们理解模型行为。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 560, "src_audio": "/acl6060/audio/eval/560.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "tgt_ref": "对我们的工作做个总结，首先我们的模型实际上是非常有效的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 561, "src_audio": "/acl6060/audio/eval/561.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "tgt_ref": "我们能够提供可解释的解决程序。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 562, "src_audio": "/acl6060/audio/eval/562.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "tgt_ref": "我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 563, "src_audio": "/acl6060/audio/eval/563.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "tgt_ref": "最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 564, "src_audio": "/acl6060/audio/eval/564.wav", "src_ref": "We also have certain limitations.", "tgt_ref": "我们也有一定的局限性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 565, "src_audio": "/acl6060/audio/eval/565.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "tgt_ref": "如果我们有大量 数量的运算符或常量，内存消耗可能相当高。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 566, "src_audio": "/acl6060/audio/eval/566.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "tgt_ref": "第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 567, "src_audio": "/acl6060/audio/eval/567.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "我的演讲到此结束，欢迎各位提出问题。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 568, "src_audio": "/acl6060/audio/eval/568.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 569, "src_audio": "/acl6060/audio/eval/569.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "tgt_ref": "我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 570, "src_audio": "/acl6060/audio/eval/570.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "tgt_ref": "法律问题是许多人生活中不可或缺的一部分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 571, "src_audio": "/acl6060/audio/eval/571.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "tgt_ref": "但大多数公民对他们的权利和基本法律程序知之甚少。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 572, "src_audio": "/acl6060/audio/eval/572.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "tgt_ref": "结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 573, "src_audio": "/acl6060/audio/eval/573.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "tgt_ref": "所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 574, "src_audio": "/acl6060/audio/eval/574.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "tgt_ref": "这样一个系统可以为非技术人员提供免费的专业法律援助服务。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 575, "src_audio": "/acl6060/audio/eval/575.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "tgt_ref": "在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 576, "src_audio": "/acl6060/audio/eval/576.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "tgt_ref": "给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 577, "src_audio": "/acl6060/audio/eval/577.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "tgt_ref": "需要一个模型来从大量立法中检索所有相关的法定条款。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 578, "src_audio": "/acl6060/audio/eval/578.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "tgt_ref": "这种信息检索 任务有其自身的一系列挑战。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 579, "src_audio": "/acl6060/audio/eval/579.wav", "src_ref": "First, it deals with two types of language.", "tgt_ref": "首先，它涉及两种类型的语言。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 580, "src_audio": "/acl6060/audio/eval/580.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "tgt_ref": "针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 581, "src_audio": "/acl6060/audio/eval/581.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "tgt_ref": "这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 582, "src_audio": "/acl6060/audio/eval/582.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "tgt_ref": "此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 583, "src_audio": "/acl6060/audio/eval/583.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "tgt_ref": "相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 584, "src_audio": "/acl6060/audio/eval/584.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "tgt_ref": "最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 585, "src_audio": "/acl6060/audio/eval/585.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "tgt_ref": "在这里，有一些有可能是长达六千字的长文档。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 586, "src_audio": "/acl6060/audio/eval/586.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "tgt_ref": "自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 587, "src_audio": "/acl6060/audio/eval/587.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "tgt_ref": "但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 588, "src_audio": "/acl6060/audio/eval/588.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "tgt_ref": "在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 589, "src_audio": "/acl6060/audio/eval/589.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "tgt_ref": "我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 590, "src_audio": "/acl6060/audio/eval/590.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "tgt_ref": "这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 591, "src_audio": "/acl6060/audio/eval/591.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "tgt_ref": "每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 592, "src_audio": "/acl6060/audio/eval/592.wav", "src_ref": "Let's now talk about how we collected this dataset.", "tgt_ref": "现在，让我们来谈谈我们是如何收集这个数据集的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 593, "src_audio": "/acl6060/audio/eval/593.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "tgt_ref": "首先，我们从汇编大量语料库的法律条款开始。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 594, "src_audio": "/acl6060/audio/eval/594.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "tgt_ref": "我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 595, "src_audio": "/acl6060/audio/eval/595.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "tgt_ref": "然后，我们参考相关法规收集了法律问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 596, "src_audio": "/acl6060/audio/eval/596.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "tgt_ref": "为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 597, "src_audio": "/acl6060/audio/eval/597.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "tgt_ref": "我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 598, "src_audio": "/acl6060/audio/eval/598.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "tgt_ref": "我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 599, "src_audio": "/acl6060/audio/eval/599.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "tgt_ref": "最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 600, "src_audio": "/acl6060/audio/eval/600.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "tgt_ref": "其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 601, "src_audio": "/acl6060/audio/eval/601.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "tgt_ref": "我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 602, "src_audio": "/acl6060/audio/eval/602.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "tgt_ref": "此外，每个问题都具有主类别和一系列子类别。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 603, "src_audio": "/acl6060/audio/eval/603.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "tgt_ref": "每个条款都带有法律结构中子序列标题的联结。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 604, "src_audio": "/acl6060/audio/eval/604.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "tgt_ref": "这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 605, "src_audio": "/acl6060/audio/eval/605.wav", "src_ref": "Let's look at some characteristic of our dataset.", "tgt_ref": "让我们来看看我们的数据集的一些特征。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 606, "src_audio": "/acl6060/audio/eval/606.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "tgt_ref": "这些问题的长度在5到44个单词之间，中位数为14个单词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 607, "src_audio": "/acl6060/audio/eval/607.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "tgt_ref": "条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 608, "src_audio": "/acl6060/audio/eval/608.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "tgt_ref": "最长的一条有5790个单词。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 609, "src_audio": "/acl6060/audio/eval/609.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "tgt_ref": "如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 610, "src_audio": "/acl6060/audio/eval/610.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "tgt_ref": "则其余的15%则涉及社会保障、外国人或工作。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 611, "src_audio": "/acl6060/audio/eval/611.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "tgt_ref": "这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 612, "src_audio": "/acl6060/audio/eval/612.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "tgt_ref": "以下是从这些比利时法典中收集的条款总数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 613, "src_audio": "/acl6060/audio/eval/613.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "tgt_ref": "在22633个条款中，只有1612个与数据集中的至少一个问题相关。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 614, "src_audio": "/acl6060/audio/eval/614.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "tgt_ref": "这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 615, "src_audio": "/acl6060/audio/eval/615.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "tgt_ref": "与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 616, "src_audio": "/acl6060/audio/eval/616.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "tgt_ref": "这可以解释为，这些法典较少关注个人及个人关心的问题。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 617, "src_audio": "/acl6060/audio/eval/617.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "tgt_ref": "总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 618, "src_audio": "/acl6060/audio/eval/618.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "tgt_ref": "使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 619, "src_audio": "/acl6060/audio/eval/619.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "tgt_ref": "给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 620, "src_audio": "/acl6060/audio/eval/620.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "tgt_ref": "我们使用标准的 TF-IDF和BM25排序函数进行实验。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 621, "src_audio": "/acl6060/audio/eval/621.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "tgt_ref": "这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 622, "src_audio": "/acl6060/audio/eval/622.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "tgt_ref": "为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 623, "src_audio": "/acl6060/audio/eval/623.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "tgt_ref": "我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 624, "src_audio": "/acl6060/audio/eval/624.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "tgt_ref": "这些嵌入通常来自于对单词嵌入模型输出的池化操作。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 625, "src_audio": "/acl6060/audio/eval/625.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "tgt_ref": "首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 626, "src_audio": "/acl6060/audio/eval/626.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "tgt_ref": "我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 627, "src_audio": "/acl6060/audio/eval/627.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "tgt_ref": "此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 628, "src_audio": "/acl6060/audio/eval/628.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "tgt_ref": "请注意，针对训练，我们尝试使用了双编码器架构的两种风格。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 629, "src_audio": "/acl6060/audio/eval/629.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "tgt_ref": "第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 630, "src_audio": "/acl6060/audio/eval/630.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "tgt_ref": "我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 631, "src_audio": "/acl6060/audio/eval/631.wav", "src_ref": "Here are the result of our baseline on the test sets.", "tgt_ref": "以下是我们在测试集上的基线结果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 632, "src_audio": "/acl6060/audio/eval/632.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "tgt_ref": "上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 633, "src_audio": "/acl6060/audio/eval/633.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "tgt_ref": "总体而言，微调的双编码器明显优于所有其他基线。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 634, "src_audio": "/acl6060/audio/eval/634.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "tgt_ref": "双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 635, "src_audio": "/acl6060/audio/eval/635.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "tgt_ref": "虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 636, "src_audio": "/acl6060/audio/eval/636.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "tgt_ref": "关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 637, "src_audio": "/acl6060/audio/eval/637.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "tgt_ref": "此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 638, "src_audio": "/acl6060/audio/eval/638.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "tgt_ref": "虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 639, "src_audio": "/acl6060/audio/eval/639.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "tgt_ref": "最后，让我们讨论一下数据集的两个局限性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 640, "src_audio": "/acl6060/audio/eval/640.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "tgt_ref": "首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 641, "src_audio": "/acl6060/audio/eval/641.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "tgt_ref": "在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 642, "src_audio": "/acl6060/audio/eval/642.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "tgt_ref": "因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 643, "src_audio": "/acl6060/audio/eval/643.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "tgt_ref": "其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 644, "src_audio": "/acl6060/audio/eval/644.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "tgt_ref": "例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 645, "src_audio": "/acl6060/audio/eval/645.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "tgt_ref": "在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 646, "src_audio": "/acl6060/audio/eval/646.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "tgt_ref": "相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 647, "src_audio": "/acl6060/audio/eval/647.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "tgt_ref": "例如，租户每周举行两次派对，直到凌晨2点。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 648, "src_audio": "/acl6060/audio/eval/648.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "tgt_ref": "因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 649, "src_audio": "/acl6060/audio/eval/649.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "tgt_ref": "我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 650, "src_audio": "/acl6060/audio/eval/650.wav", "src_ref": "That can help improve access to justice for all.", "tgt_ref": "这可以帮助改善所有人对司法的利用。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 651, "src_audio": "/acl6060/audio/eval/651.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 652, "src_audio": "/acl6060/audio/eval/652.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 653, "src_audio": "/acl6060/audio/eval/653.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "tgt_ref": "我们为什么要费尽心思设立这个基准呢？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 654, "src_audio": "/acl6060/audio/eval/654.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "tgt_ref": "那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 655, "src_audio": "/acl6060/audio/eval/655.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "tgt_ref": "这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 656, "src_audio": "/acl6060/audio/eval/656.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "tgt_ref": "因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 657, "src_audio": "/acl6060/audio/eval/657.wav", "src_ref": "But do we know what the models have actually learned?", "tgt_ref": "但我们是否知道模型实际上学到了什么？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 658, "src_audio": "/acl6060/audio/eval/658.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "tgt_ref": "视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 659, "src_audio": "/acl6060/audio/eval/659.wav", "src_ref": "And the low score for this one?", "tgt_ref": "而这一个的低分呢？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 660, "src_audio": "/acl6060/audio/eval/660.wav", "src_ref": "Do vision and language models focus on the right thing?", "tgt_ref": "视觉和语言模型关注的是正确的事情吗？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 661, "src_audio": "/acl6060/audio/eval/661.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "tgt_ref": "还是像之前的工作所显示的那样，他们专注于偏差？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 662, "src_audio": "/acl6060/audio/eval/662.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "tgt_ref": "为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 663, "src_audio": "/acl6060/audio/eval/663.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "tgt_ref": "我们的目标是存在性、复数、计数、空间关系、动作和实体共指。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 664, "src_audio": "/acl6060/audio/eval/664.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "tgt_ref": "但是，我们如何测试视觉和语言模型是否捕获了这种现象？", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 665, "src_audio": "/acl6060/audio/eval/665.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "tgt_ref": "通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 666, "src_audio": "/acl6060/audio/eval/666.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "tgt_ref": "干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 667, "src_audio": "/acl6060/audio/eval/667.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "tgt_ref": "当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 668, "src_audio": "/acl6060/audio/eval/668.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "tgt_ref": "例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 669, "src_audio": "/acl6060/audio/eval/669.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "tgt_ref": "计数和共指也是具有多种工具的方面。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 670, "src_audio": "/acl6060/audio/eval/670.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "tgt_ref": "当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 671, "src_audio": "/acl6060/audio/eval/671.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "tgt_ref": "这并不容易，因为被干扰的标题可能比原始标题更不可能。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 672, "src_audio": "/acl6060/audio/eval/672.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "tgt_ref": "例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 673, "src_audio": "/acl6060/audio/eval/673.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "tgt_ref": "所以，要制造有效的干扰，我们必须想方设法。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 674, "src_audio": "/acl6060/audio/eval/674.wav", "src_ref": "First, we make use of strong language models to propose foils.", "tgt_ref": "首先，我们利用强大的语言模型来提出干扰。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 675, "src_audio": "/acl6060/audio/eval/675.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "tgt_ref": "其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 676, "src_audio": "/acl6060/audio/eval/676.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "tgt_ref": "为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 677, "src_audio": "/acl6060/audio/eval/677.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "tgt_ref": "我们认为图像是前提，其标题是其附带的假设。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 678, "src_audio": "/acl6060/audio/eval/678.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "tgt_ref": "此外，我们认为标题是前提，而干扰词是其假设。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 679, "src_audio": "/acl6060/audio/eval/679.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "tgt_ref": "如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 680, "src_audio": "/acl6060/audio/eval/680.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "tgt_ref": "如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 681, "src_audio": "/acl6060/audio/eval/681.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "tgt_ref": "但这个过程并不完美，它只是一个有效干扰词的指标。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 682, "src_audio": "/acl6060/audio/eval/682.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "tgt_ref": "所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 683, "src_audio": "/acl6060/audio/eval/683.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "tgt_ref": "因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 684, "src_audio": "/acl6060/audio/eval/684.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "tgt_ref": "请注意，VALSE不提供任何训练数据，而仅提供测试数据。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 685, "src_audio": "/acl6060/audio/eval/685.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "tgt_ref": "由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 686, "src_audio": "/acl6060/audio/eval/686.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "tgt_ref": "微调只会使模型能够利用数据中的工件或统计 偏差。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 687, "src_audio": "/acl6060/audio/eval/687.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "tgt_ref": "我们都知道，这些模型喜欢作弊和走捷径。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 688, "src_audio": "/acl6060/audio/eval/688.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "tgt_ref": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 689, "src_audio": "/acl6060/audio/eval/689.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "tgt_ref": "我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 690, "src_audio": "/acl6060/audio/eval/690.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "tgt_ref": "我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 691, "src_audio": "/acl6060/audio/eval/691.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "tgt_ref": "也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 692, "src_audio": "/acl6060/audio/eval/692.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "tgt_ref": "有关更多指标及其结果，请查看我们的论文。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 693, "src_audio": "/acl6060/audio/eval/693.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "tgt_ref": "这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 694, "src_audio": "/acl6060/audio/eval/694.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "tgt_ref": "值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 695, "src_audio": "/acl6060/audio/eval/695.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "tgt_ref": "但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 696, "src_audio": "/acl6060/audio/eval/696.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "tgt_ref": "我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 697, "src_audio": "/acl6060/audio/eval/697.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "tgt_ref": "关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 698, "src_audio": "/acl6060/audio/eval/698.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "tgt_ref": "他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 699, "src_audio": "/acl6060/audio/eval/699.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "tgt_ref": "从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 700, "src_audio": "/acl6060/audio/eval/700.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "tgt_ref": "作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 701, "src_audio": "/acl6060/audio/eval/701.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "tgt_ref": "如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 702, "src_audio": "/acl6060/audio/eval/702.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "tgt_ref": "有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 703, "src_audio": "/acl6060/audio/eval/703.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "tgt_ref": "因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 704, "src_audio": "/acl6060/audio/eval/704.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "tgt_ref": "我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 705, "src_audio": "/acl6060/audio/eval/705.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "tgt_ref": "我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 706, "src_audio": "/acl6060/audio/eval/706.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "tgt_ref": "更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 707, "src_audio": "/acl6060/audio/eval/707.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 708, "src_audio": "/acl6060/audio/eval/708.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "tgt_ref": "大家好，我是东京大学的Kamezawa。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 709, "src_audio": "/acl6060/audio/eval/709.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "tgt_ref": "我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 710, "src_audio": "/acl6060/audio/eval/710.wav", "src_ref": "I'll be explaining in this order.", "tgt_ref": "我将按照这个顺序解释。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 711, "src_audio": "/acl6060/audio/eval/711.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "tgt_ref": "首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 712, "src_audio": "/acl6060/audio/eval/712.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "tgt_ref": "发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 713, "src_audio": "/acl6060/audio/eval/713.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "tgt_ref": "这个图像显示的是vuejs库的2.6.4版本的发行说明。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 714, "src_audio": "/acl6060/audio/eval/714.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "tgt_ref": "发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 715, "src_audio": "/acl6060/audio/eval/715.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "tgt_ref": "因此，如果能够自动生成高质量的发行说明，那将是非常有用的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 716, "src_audio": "/acl6060/audio/eval/716.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "tgt_ref": "我将遵从之前的两项关于自动生成发行说明的研究。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 717, "src_audio": "/acl6060/audio/eval/717.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "tgt_ref": "第一个是被称为ARENA的系统 ，发布于2014年。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 718, "src_audio": "/acl6060/audio/eval/718.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "tgt_ref": "它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 719, "src_audio": "/acl6060/audio/eval/719.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "tgt_ref": "这个系统最显著的特征是右上角的问题提取器。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 720, "src_audio": "/acl6060/audio/eval/720.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "tgt_ref": "这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 721, "src_audio": "/acl6060/audio/eval/721.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "tgt_ref": "换句话说，它不能用于GitHub上的许多项目。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 722, "src_audio": "/acl6060/audio/eval/722.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "tgt_ref": "第二个是Glyph ，最近在2020年宣布。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 723, "src_audio": "/acl6060/audio/eval/723.wav", "src_ref": "It is available on the internet and can be installed via pip.", "tgt_ref": "它可以在互联网上下载，并可以通过pip安装。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 724, "src_audio": "/acl6060/audio/eval/724.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "tgt_ref": "这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 725, "src_audio": "/acl6060/audio/eval/725.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "tgt_ref": "此图像是一个返回纠正或错误修复标签的示例用法。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 726, "src_audio": "/acl6060/audio/eval/726.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "tgt_ref": "Glyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 727, "src_audio": "/acl6060/audio/eval/727.wav", "src_ref": "The performance of the text classification model is not high.", "tgt_ref": "文本分类模型的表现不佳。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 728, "src_audio": "/acl6060/audio/eval/728.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "tgt_ref": "我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 729, "src_audio": "/acl6060/audio/eval/729.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "tgt_ref": "我们的论文解决了这两个问题，并自动生成了高质量的发行说明。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 730, "src_audio": "/acl6060/audio/eval/730.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "tgt_ref": "面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 731, "src_audio": "/acl6060/audio/eval/731.wav", "src_ref": "This proposed method can be used for all English repositories.", "tgt_ref": "这个提议的方法可以用于所有英语存储库。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 732, "src_audio": "/acl6060/audio/eval/732.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "tgt_ref": "对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 733, "src_audio": "/acl6060/audio/eval/733.wav", "src_ref": "Next, I'll describe our dataset.", "tgt_ref": "接下来，我将介绍我们的数据集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 734, "src_audio": "/acl6060/audio/eval/734.wav", "src_ref": "Here is an example of data.", "tgt_ref": "以下是数据的示例。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 735, "src_audio": "/acl6060/audio/eval/735.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "tgt_ref": "左侧是提交消息，右侧是发行说明。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 736, "src_audio": "/acl6060/audio/eval/736.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "tgt_ref": "发行说明被标记为优化或修复等。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 737, "src_audio": "/acl6060/audio/eval/737.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "tgt_ref": "我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 738, "src_audio": "/acl6060/audio/eval/738.wav", "src_ref": "This can be regarded as a summarization task.", "tgt_ref": "这可以看作是一项总结 任务。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 739, "src_audio": "/acl6060/audio/eval/739.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "tgt_ref": "我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 740, "src_audio": "/acl6060/audio/eval/740.wav", "src_ref": "These were set based on previous research and other factors.", "tgt_ref": "这些都是基于之前的研究和其他因素设定的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 741, "src_audio": "/acl6060/audio/eval/741.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "tgt_ref": "右下角的发行说明是从左下角的发行说明中提取的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 742, "src_audio": "/acl6060/audio/eval/742.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "tgt_ref": "现在，有必要检测事先设置好的四个标签。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 743, "src_audio": "/acl6060/audio/eval/743.wav", "src_ref": "But the labels are not always consistent with each repository.", "tgt_ref": "但是，标签并不总是与每个存储库一致。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 744, "src_audio": "/acl6060/audio/eval/744.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "tgt_ref": "例如，改进标签包括改进、增强、优化等。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 745, "src_audio": "/acl6060/audio/eval/745.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "tgt_ref": "我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 746, "src_audio": "/acl6060/audio/eval/746.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "tgt_ref": "这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 747, "src_audio": "/acl6060/audio/eval/747.wav", "src_ref": "Next is a commit message.", "tgt_ref": "接下来是提交消息。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 748, "src_audio": "/acl6060/audio/eval/748.wav", "src_ref": "Commit messages are not tied to each release.", "tgt_ref": "提交信息并不与每个版本相联系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 749, "src_audio": "/acl6060/audio/eval/749.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "tgt_ref": "如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 750, "src_audio": "/acl6060/audio/eval/750.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "tgt_ref": "这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 751, "src_audio": "/acl6060/audio/eval/751.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "tgt_ref": "我们创建了一个启发式匹配规则来获取上一个和下一个版本。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 752, "src_audio": "/acl6060/audio/eval/752.wav", "src_ref": "Dataset analysis.", "tgt_ref": "数据集分析。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 753, "src_audio": "/acl6060/audio/eval/753.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "tgt_ref": "最后，收集到了7200个存储库和82000份数据。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 754, "src_audio": "/acl6060/audio/eval/754.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "tgt_ref": "此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 755, "src_audio": "/acl6060/audio/eval/755.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "tgt_ref": "此外，独特的令牌数量也相当是大的，有883万个。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 756, "src_audio": "/acl6060/audio/eval/756.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "tgt_ref": "这是由于在资源库中发现了大量独特的类或方法名称。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 757, "src_audio": "/acl6060/audio/eval/757.wav", "src_ref": "Next, I will explain the proposed method.", "tgt_ref": "接下来，我将解释所提议的方法。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 758, "src_audio": "/acl6060/audio/eval/758.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "tgt_ref": "这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 759, "src_audio": "/acl6060/audio/eval/759.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "tgt_ref": "一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 760, "src_audio": "/acl6060/audio/eval/760.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "tgt_ref": "首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 761, "src_audio": "/acl6060/audio/eval/761.wav", "src_ref": "The commit messages classified as other are discarded.", "tgt_ref": "被归类为“其他”的提交消息将被丢弃。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 762, "src_audio": "/acl6060/audio/eval/762.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "tgt_ref": "然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 763, "src_audio": "/acl6060/audio/eval/763.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "tgt_ref": "在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 764, "src_audio": "/acl6060/audio/eval/764.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "tgt_ref": "所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 765, "src_audio": "/acl6060/audio/eval/765.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "tgt_ref": "我们通过两种不同的方法对分类抽象总结方法进行建模。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 766, "src_audio": "/acl6060/audio/eval/766.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "tgt_ref": "第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 767, "src_audio": "/acl6060/audio/eval/767.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "tgt_ref": "输出的文本可以根据特殊的类特定端点符号分为分类段落。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 768, "src_audio": "/acl6060/audio/eval/768.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "tgt_ref": "第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 769, "src_audio": "/acl6060/audio/eval/769.wav", "src_ref": "Okay, let me explain the experiments.", "tgt_ref": "好，让我解释一下实验。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 770, "src_audio": "/acl6060/audio/eval/770.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "tgt_ref": "我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 771, "src_audio": "/acl6060/audio/eval/771.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "tgt_ref": "关于评估，在某些情况下，发行说明是以多个句子形式输出的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 772, "src_audio": "/acl6060/audio/eval/772.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "tgt_ref": "由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 773, "src_audio": "/acl6060/audio/eval/773.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "tgt_ref": "当系统输出一个短句时，BLEU会受到惩罚。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 774, "src_audio": "/acl6060/audio/eval/774.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "tgt_ref": "在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 775, "src_audio": "/acl6060/audio/eval/775.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "tgt_ref": "最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 776, "src_audio": "/acl6060/audio/eval/776.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "tgt_ref": "更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 777, "src_audio": "/acl6060/audio/eval/777.wav", "src_ref": "Here are the results.", "tgt_ref": "结果如下。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 778, "src_audio": "/acl6060/audio/eval/778.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "tgt_ref": "由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 779, "src_audio": "/acl6060/audio/eval/779.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "tgt_ref": "CEAS和CAS的ROUGE-L得分比基线高10分以上。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 780, "src_audio": "/acl6060/audio/eval/780.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "tgt_ref": "特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 781, "src_audio": "/acl6060/audio/eval/781.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "tgt_ref": "这些结果表明CEAS和CAS受到严重影响。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 782, "src_audio": "/acl6060/audio/eval/782.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "tgt_ref": "CEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 783, "src_audio": "/acl6060/audio/eval/783.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "tgt_ref": "CEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 784, "src_audio": "/acl6060/audio/eval/784.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "tgt_ref": "CAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 785, "src_audio": "/acl6060/audio/eval/785.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "tgt_ref": "这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 786, "src_audio": "/acl6060/audio/eval/786.wav", "src_ref": "Here are an error analysis.", "tgt_ref": "这里有一个错误分析。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 787, "src_audio": "/acl6060/audio/eval/787.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "tgt_ref": "CAS方法倾向于输出比人类参考句子更短的句子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 788, "src_audio": "/acl6060/audio/eval/788.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "tgt_ref": "在右图中，引用句子有3或4个句子 ，而CAS只有1个。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 789, "src_audio": "/acl6060/audio/eval/789.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "tgt_ref": "这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 790, "src_audio": "/acl6060/audio/eval/790.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "tgt_ref": "此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 791, "src_audio": "/acl6060/audio/eval/791.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "tgt_ref": "右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 792, "src_audio": "/acl6060/audio/eval/792.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "tgt_ref": "下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 793, "src_audio": "/acl6060/audio/eval/793.wav", "src_ref": "Finally, a conclusion.", "tgt_ref": "最后，一个结论。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 794, "src_audio": "/acl6060/audio/eval/794.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "tgt_ref": "我们已经建立了一个新的数据集，用于自动生成发行说明。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 795, "src_audio": "/acl6060/audio/eval/795.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "tgt_ref": "我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 796, "src_audio": "/acl6060/audio/eval/796.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "tgt_ref": "我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 797, "src_audio": "/acl6060/audio/eval/797.wav", "src_ref": "Please check out our dataset on GitHub.", "tgt_ref": "请查看我们在GitHub上的数据集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 798, "src_audio": "/acl6060/audio/eval/798.wav", "src_ref": "Thank you.", "tgt_ref": "谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 799, "src_audio": "/acl6060/audio/eval/799.wav", "src_ref": "Hello. My name is Asaf Harari.", "tgt_ref": "大家好。我的名字是Asaf Harari。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 800, "src_audio": "/acl6060/audio/eval/800.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "tgt_ref": "我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 801, "src_audio": "/acl6060/audio/eval/801.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "tgt_ref": "数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 802, "src_audio": "/acl6060/audio/eval/802.wav", "src_ref": "But sometimes, these features are limited.", "tgt_ref": "但有时，这些特征是有限的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 803, "src_audio": "/acl6060/audio/eval/803.wav", "src_ref": "Feature generation using another data source may add substantial information.", "tgt_ref": "使用另一个数据来源生成特征可能会增加大量的信息。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 804, "src_audio": "/acl6060/audio/eval/804.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "tgt_ref": "我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 805, "src_audio": "/acl6060/audio/eval/805.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "tgt_ref": "假设我们有一个表格数据集和一个知识库。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 806, "src_audio": "/acl6060/audio/eval/806.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "tgt_ref": "我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 807, "src_audio": "/acl6060/audio/eval/807.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "tgt_ref": "我们的框架FeSTE正是这个自动过程。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 808, "src_audio": "/acl6060/audio/eval/808.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "tgt_ref": "我们来看看在一个数据集中输入FeSTE的例子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 809, "src_audio": "/acl6060/audio/eval/809.wav", "src_ref": "In this example, the dataset is university dataset.", "tgt_ref": "在这个例子中，数据集是大学数据集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 810, "src_audio": "/acl6060/audio/eval/810.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "tgt_ref": "当它的目标是将大学分为低排名的大学和高排名的大学时。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 811, "src_audio": "/acl6060/audio/eval/811.wav", "src_ref": "As knowledge base, we use Wikipedia.", "tgt_ref": "我们使用维基百科作为知识库。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 812, "src_audio": "/acl6060/audio/eval/812.wav", "src_ref": "The first phase of FeSTE is entity linking.", "tgt_ref": "FeSTE的第一阶段是实体链接。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 813, "src_audio": "/acl6060/audio/eval/813.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "tgt_ref": "当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 814, "src_audio": "/acl6060/audio/eval/814.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "tgt_ref": "并且知识库的实体文本被提取出来，并添加到数据集中。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 815, "src_audio": "/acl6060/audio/eval/815.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "tgt_ref": "在这个例子中，文本是维基百科页面的摘要。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 816, "src_audio": "/acl6060/audio/eval/816.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "tgt_ref": "现在，我们需要从检索 文本中生成或提取特征。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 817, "src_audio": "/acl6060/audio/eval/817.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "tgt_ref": "因此，我们需要进行特征提取阶段，其中包括文本分析。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 818, "src_audio": "/acl6060/audio/eval/818.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "tgt_ref": "这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 819, "src_audio": "/acl6060/audio/eval/819.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "tgt_ref": "在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 820, "src_audio": "/acl6060/audio/eval/820.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "tgt_ref": "首先，在原始数据集的类别数量中生成特征。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 821, "src_audio": "/acl6060/audio/eval/821.wav", "src_ref": "In this example, the original dataset has two classes.", "tgt_ref": "在这个例子中，原始数据集有两个类别。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 822, "src_audio": "/acl6060/audio/eval/822.wav", "src_ref": "So, FeSTE generates two new features.", "tgt_ref": "所以，FeSTE生成两个特征。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 823, "src_audio": "/acl6060/audio/eval/823.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "tgt_ref": "但如果数据集有五个类，FeSTE就会生成五个新的特征。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 824, "src_audio": "/acl6060/audio/eval/824.wav", "src_ref": "Each feature represents the likelihood for each class.", "tgt_ref": "每个特征表示每个类的可能性。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 825, "src_audio": "/acl6060/audio/eval/825.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "tgt_ref": "为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 826, "src_audio": "/acl6060/audio/eval/826.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "tgt_ref": "但是，我们不可能用输入数据集来训练语言模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 827, "src_audio": "/acl6060/audio/eval/827.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "tgt_ref": "因此，有一个朴素的方法是：目标任务微调。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 828, "src_audio": "/acl6060/audio/eval/828.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "tgt_ref": "因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 829, "src_audio": "/acl6060/audio/eval/829.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "tgt_ref": "在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 830, "src_audio": "/acl6060/audio/eval/830.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "tgt_ref": "接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 831, "src_audio": "/acl6060/audio/eval/831.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "tgt_ref": "这种方法的问题是，数据集可能只有几个不同的实体/文本。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 832, "src_audio": "/acl6060/audio/eval/832.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "tgt_ref": "在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 833, "src_audio": "/acl6060/audio/eval/833.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "tgt_ref": "因此，在这个数据集上微调语言模型将是无效的。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 834, "src_audio": "/acl6060/audio/eval/834.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "tgt_ref": "但我们可以使用关于预先分析的数据集的先验知识。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 835, "src_audio": "/acl6060/audio/eval/835.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "tgt_ref": "因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 836, "src_audio": "/acl6060/audio/eval/836.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "tgt_ref": "我们的建议是，添加另一个微调阶段。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 837, "src_audio": "/acl6060/audio/eval/837.wav", "src_ref": "A preliminary multitask finetuning phase.", "tgt_ref": "一个初步的多任务微调阶段。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 838, "src_audio": "/acl6060/audio/eval/838.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "tgt_ref": "当你在n减1数据集上微调语言模型时。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 839, "src_audio": "/acl6060/audio/eval/839.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "tgt_ref": "然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 840, "src_audio": "/acl6060/audio/eval/840.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "tgt_ref": "最先进的多任务多任务微调技术称为MTDNN。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 841, "src_audio": "/acl6060/audio/eval/841.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "tgt_ref": "在MTDNN中，MTDNN在训练集的任务数量上保持着头部。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 842, "src_audio": "/acl6060/audio/eval/842.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "tgt_ref": "因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 843, "src_audio": "/acl6060/audio/eval/843.wav", "src_ref": "And it samples a random batch from ah from the training set.", "tgt_ref": "它从训练集中随机抽取一批。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 844, "src_audio": "/acl6060/audio/eval/844.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "tgt_ref": "而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 845, "src_audio": "/acl6060/audio/eval/845.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "tgt_ref": "而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 846, "src_audio": "/acl6060/audio/eval/846.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "tgt_ref": "在我们的场景中，表格数据集在类的数量上有所不同。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 847, "src_audio": "/acl6060/audio/eval/847.wav", "src_ref": "So there are many tasks.", "tgt_ref": "存在很多的任务。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 848, "src_audio": "/acl6060/audio/eval/848.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "tgt_ref": "MTDNN保持了类、头、输出层的数量。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 849, "src_audio": "/acl6060/audio/eval/849.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "tgt_ref": "另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 850, "src_audio": "/acl6060/audio/eval/850.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "tgt_ref": "我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 851, "src_audio": "/acl6060/audio/eval/851.wav", "src_ref": "So let's see an example.", "tgt_ref": "让我们来看一个例子。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 852, "src_audio": "/acl6060/audio/eval/852.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "tgt_ref": "这里是我们的输入数据集，由实体、特征、文本和类组成。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 853, "src_audio": "/acl6060/audio/eval/853.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "tgt_ref": "而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 854, "src_audio": "/acl6060/audio/eval/854.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "tgt_ref": "或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 855, "src_audio": "/acl6060/audio/eval/855.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "tgt_ref": "因此，标签向量在这种情况下始终保持……它总是由两个类组成。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 856, "src_audio": "/acl6060/audio/eval/856.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "tgt_ref": "而这就是我们精细的、重新制定的微调方法的算法。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 857, "src_audio": "/acl6060/audio/eval/857.wav", "src_ref": "So let's see the full framework.", "tgt_ref": "让我们来看看完整的框架。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 858, "src_audio": "/acl6060/audio/eval/858.wav", "src_ref": "Dataset fed into FeSTE.", "tgt_ref": "数据集送入FeSTE。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 859, "src_audio": "/acl6060/audio/eval/859.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "tgt_ref": "然后，FeSTE执行实体链接阶段。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 860, "src_audio": "/acl6060/audio/eval/860.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "tgt_ref": "它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 861, "src_audio": "/acl6060/audio/eval/861.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "tgt_ref": "然后，它将任务重新表述为一个成对的句子分类任务。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 862, "src_audio": "/acl6060/audio/eval/862.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "tgt_ref": "将语言模型应用于新的任务，并对每一类的输出可能性进行分析。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 863, "src_audio": "/acl6060/audio/eval/863.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "tgt_ref": "现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 864, "src_audio": "/acl6060/audio/eval/864.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "tgt_ref": "然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 865, "src_audio": "/acl6060/audio/eval/865.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "tgt_ref": "为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 866, "src_audio": "/acl6060/audio/eval/866.wav", "src_ref": "And as knowledge base we use Wikipedia.", "tgt_ref": "我们还是使用维基百科来作为知识库。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 867, "src_audio": "/acl6060/audio/eval/867.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "tgt_ref": "我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 868, "src_audio": "/acl6060/audio/eval/868.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "tgt_ref": "我们还将每个数据集分成四折，并应用四折交叉验证。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 869, "src_audio": "/acl6060/audio/eval/869.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "tgt_ref": "然后，我们生成新的特征，并使用五个评估分类器对其进行评估。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 870, "src_audio": "/acl6060/audio/eval/870.wav", "src_ref": "We use in our experiments base BERT base architecture.", "tgt_ref": "在我们的实验中，我们使用基础BERT基础架构。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 871, "src_audio": "/acl6060/audio/eval/871.wav", "src_ref": "Here are the results for our experiments.", "tgt_ref": "以下是我们实验的结果。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 872, "src_audio": "/acl6060/audio/eval/872.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "tgt_ref": "你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 873, "src_audio": "/acl6060/audio/eval/873.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "tgt_ref": "而我们重新制定的微调实现了最好的结果，最好的表现。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 874, "src_audio": "/acl6060/audio/eval/874.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "tgt_ref": "而MTDNN比目标 数据集 微调提高了2%。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 875, "src_audio": "/acl6060/audio/eval/875.wav", "src_ref": "Our approach achieved six percent improvement.", "tgt_ref": "我们的方法实现了6%的改进。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 876, "src_audio": "/acl6060/audio/eval/876.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "tgt_ref": "当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 877, "src_audio": "/acl6060/audio/eval/877.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "tgt_ref": "但与单独的目标任务微调相比，我们的表现提高到了11%。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 878, "src_audio": "/acl6060/audio/eval/878.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "tgt_ref": "总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 879, "src_audio": "/acl6060/audio/eval/879.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "tgt_ref": "它使用一个架构用于所有任务和数据集。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 880, "src_audio": "/acl6060/audio/eval/880.wav", "src_ref": "And it keeps the head of ah of the model.", "tgt_ref": "而且它保留了模型的头部。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 881, "src_audio": "/acl6060/audio/eval/881.wav", "src_ref": "But it adds reformulation phase.", "tgt_ref": "但它增加了重新制定阶段。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 882, "src_audio": "/acl6060/audio/eval/882.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "tgt_ref": "它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 883, "src_audio": "/acl6060/audio/eval/883.wav", "src_ref": "Thank you.", "tgt_ref": "谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
