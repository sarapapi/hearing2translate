{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle! Heute werde ich unser Forschungswerk präsentieren, das das Lernen, deduktiv zu reden, Materialproblemlösung und komplexe Reason Extraktion beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Allen von Biden's Air Lab und das ist ein Gemeinschaftswerk mit Chiri von der Universität von Texas in Austin und Weidow von S.U.D."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Wir zeigen Ihnen Beispiele, wie viele Steppzüge gesund sind."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Figur ist aus dem Papier entnommen, wo sie vornehmen, um das Problem in einem zukünftigen Lernszenario zu lösen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der NAP-Seite sehen wir, dass wir, wenn wir einige Beispiele mit korrekt und in der Antworten geben, vielleicht nicht in der Lage sind, die richtigen Antworten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir einige vernünftigere Beschreibungen geben, ist das Modell in der Lage, die vernünftige Beschreibung zu vorhersagen und auch eine korrekte Vorhersage hier zu machen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "So ist es gut, dass man eine multi-stap-Reasoning-Ausgabe haben kann."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir denken auch, dass das Methodoproblem eine strenge Anwendung ist, um solche Argumentationsfähigkeiten zu bewerten."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Also hier in unserer Problemstellung, angesichts der Fragen, müssen wir diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen haben wir auch den mathematischen Ausdruck, der zu dieser Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "So gelten bestimmte Annahmen auch, wie in vorherigen Werken."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen die Präzision von Quantizationen an, die bekannt sind."}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren zersetzt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Also vorherige Arbeiten in der Mathematik der Problemlösung können tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baum-Modelle eingeteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "So konvertiert das traditionelle Sequenz-zu-Sequenz-Modell den Ausdruck zu einer spezifischen Sequenz für eine Generation."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist ziemlich einfach zu implementieren und es kann zu vielen verschiedenen, komplizierten Problemen verallgemeinern."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil der Performance ist eigentlich generell nicht besser als das Strukturmodell, und es ist der Mangel an Interpretabilität für Prognosen."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber diese Richtung ist aufgrund des Transformator-Modells immer noch sehr beliebt."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumbasierten Modellen strukturieren wir diese Ausdrücke in der Baumform und folgen einem Preorder-Traversal in drei Generationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir die Operatoren, bis wir die Lifte erreichen, die die Quantitäten sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute ist, dass es uns diese binäre Baumstruktur gibt, aber es ist ziemlich kontingentiv, weil wir zuerst die Operatoren generieren und dann am Ende die Quantitäten."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und das zweite ist, dass es auch einige wiederholte Berechnungen enthält."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Also hier, wenn wir uns diesen Ausdruck ansehen, dann ist Atoms 3+3 tatsächlich zweimal generiert, aber in der Tat sollten wir die Ergebnisse verwenden."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz wollen wir diese Probleme Schritt für Schritt und in interpretierbarer Weise lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "So können wir in der zweiten Stufe diese Teilung, die 27 ist,"}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten werden wir die Teiler erreichen."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann, in diesem dritten Schritt, bekommen wir den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Nach diesen drei Schritten können wir die Ergebnisse des zweiten Schrittes nutzen und dann die Ergebnisse des vierten Schrittes erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Quantitäten zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Das macht den Prozess noch genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Diktativsystem beginnen wir mit einem Bündel von Größen, die in den Fragen präsentiert werden, und auch mit einigen Konstanten als Initialis."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Also der Ausdruck ist repräsentiert von EIJOP."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir performieren Operatoren von QI zu QJ, und solcher Ausdruck ist tatsächlich gerichtet."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Also wir haben auch Subtraktion mit Wörtern hier, um die entgegengesetzte Richtung zu repräsentieren."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie bei der Rhodesian Extraktion."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formalen deduktiven System, in einem Time-Step-T, wenden wir den Operator zwischen QI und QJP hier an und dann erhalten wir diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es zu den nächsten Staaten hinzu, um eine neue Quantität zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Lichter visualisieren die Evolution der Zustände, wo wir den aktuellen Zuständen immer wieder Ausdruck geben."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zuerst ein vorgetragenes Sprachmodell, das Vögel oder Roboter sein kann, und dann kodieren wir den Satz und dann erhalten wir diese Quantitativrepräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir die Quantitätsrepräsentationen bekommen, können wir anfangen, Inferenzen zu machen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel von Q1 um die Reputation für Q1 zu erhalten, geteilt durch Q2 und dann"}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst bekommen wir die Paarepresentation, die im Grunde nur die Konkatenation zwischen Q1 und Q2, und dann wenden wir ein Feed-Forward-Netzwerk an, das vom Operator parametrisiert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und dann haben wir endlich die Repräsentations-Ausdrücke Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis, im Infantstage, könnten wir auch den falschen Ausdruck bekommen."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind alle möglichen Ausdrücke gleich drei Mal so viele Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne ist, dass wir leicht Einschränkungen hinzufügen können, um diese Such-Sprechen zu kontrollieren."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck in unserem Suchraum einfach entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir nur noch eine Menge mehr machen."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Quantität kommt von der vorherigen berechneten Expression."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "So können wir endlich diesen letzten Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke sich von der vorherigen unterscheidet."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "So, solche Unterschiede machen es schwer, Beamschutz anzuwenden, weil die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanced ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Das Trainingsverfahren ist ähnlich wie das Trainingsmodell Sequenz zu Sequenz, bei dem wir die Verluste bei jedem Schritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier benutzen wir auch diese Taube, um zu zeigen, wann wir diesen Generationsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist der Raum von Sequenz zu Sequenz unterschiedlich, weil der Raum in jedem Termin unterschiedlich ist, während in traditionellen Sequenz-zu-Sequenz-Modellen es die Anzahl des Vokabulars ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es erlaubt uns auch, bestimmte Einschränkungen aus Vorwissen aufzuerlegen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente mit den üblicherweise verwendeten Methoden, wie dem Mathematical Problem Dataset, M.A.W.P.S., Mathematical 23K, Mathematical QA und Swamp."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen Best-Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Leistung ist Robert Haidt, der Detective Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und in der Tat verwenden wir BeamSearch nicht, im Gegensatz zu offensichtlichen Ansätzen, die BeamSearch verwenden."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Also die besten Ansätze sind oft ein baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "So ist unser Reasoner insgesamt in der Lage, dieses dreibasisige Modell deutlich zu übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MathQua oder Swamp nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Also wir untersuchen die Ergebnisse weiter."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist herausfordernd, weil der Autor versucht, etwas manuell hinzuzufügen, um das NLB-Modell zu verwirren, wie z.B. die Hinzufügung von Umweltinformationen und zusätzlichen Mengen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Prognose finden wir, dass einige der Zwischenwerte negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn Feldpinschen und Steven hat acht Pinschen, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Also unser Modell macht so eine Vorhersage, die negative Werte erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum begrenzen, indem wir die Ergebnisse negativ entfernen, damit wir die Antwort korrekt machen."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben weiter festgestellt, dass solche Einschränkungen für einige Modelle tatsächlich&nbsp; viel verbessern."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel für die Bär, wir verbessern sieben Punkte und dann für das Roboter-Base-Modell, wir verbessern zwei Punkte."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "So hat ein besseres Sprachmodell eine bessere Sprachverständnisschone, so dass die Zahl hier höher für Roboter und niedriger für Operatoren ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch, die Schwierigkeiten hinter dieser #BB zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass die Anzahl der ungenutzten Mengen hier als irrelevante Informationen betrachtet werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und der Sumpfdatensatz den größten Anteil hat."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Samples ohne Quantifierung ist die Gesamtleistung also eigentlich höher als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber mit diesen Proben, die mit ungenutzte Qualität eigentlich viel schlimmer sind als die,"}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für M.W.P.S. haben wir nicht wirklich so viele Fälle, also kann ich das einfach nicht."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich wollen wir die Interpretabilität durch ein Crush and Participate-Beispiel zeigen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Hier macht unser Modell tatsächlich eine falsche Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck mit dem Satz hier korrelieren, oder?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken, diese Anzeichen könnten das Modell zu einer falschen Vorhersage führen."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein weiteres 35er, das das Modell dazu bringt, zu denken, dass es eine Addition ist."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Also versuchten wir, den Satz zu überarbeiten, so dass es etwas wie die Anzahl der Birnenbäume ist, die fünf weniger sind als die Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben es also gemacht, dass es eine genauere Semantik gibt, so dass das Modell die Vorhersage korrekt machen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Zum Abschluss unserer Arbeit: Unser Modell ist eigentlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "und wir sind in der Lage, interpretierbare Einsparverfahren zu bieten."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einiger Vorwissen als Einschränkungen einbeziehen, die helfen können, die Leistung zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerk-Problemlösungsthemen zutrifft, sondern auch auf andere Aufgaben, die Multi-Stage-Reasoning beinhalten."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und die zweite Sache ist, wie erwähnt, dass die Verteilungswahrscheinlichkeit unbalanced ist, also ist es auch ziemlich schwierig, Beams zu verwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist das Ende des Gesprächs. Fragen sind willkommen."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich bin von der Universität Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine eigene Arbeit mit Jerry präsentieren, die sich um einen neuen Datensatz für die Statutierung von Artikeln handelt."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat wenig oder gar keine Kenntnisse über ihre Rechte und grundlegende rechtliche Prozesse."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "als ergebnis viele verletzliche bürger, die sich nicht die kostspielige assistance eines juristischen experten leisten können, werden ungeschützt oder am schlimmsten ausgebeutet"}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Kluft zwischen Menschen und dem Gesetz zu überbrücken, indem wir ein wirksames Rückgewinnungssystem für gesetzliche Artikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtshilfedienst für unqualifizierte Menschen bieten."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zuerst das Problem der gesetzlichen Artikelrückgewinnung."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "gegeben eine einfache frage auf eine reale materie so wie was tue ich riskieren wenn ich verletze professionelle konfidenzialität"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetzgebungsbereich zu gewinnen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationserfassungsthase hat ihre eigenen Herausforderungen."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Erstens handelt es sich um zwei Arten von Sprachen."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Gemeinsame natürliche Sprache für die Fragen und komplexe rechtliche Sprache für die Statuten."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "diese unterschied in sprachverteilungen macht es schwieriger für ein system, relevante kandidaten zu retrieben, da es indirekt ein inhärentes interpretationssystem erfordert, das eine natürliche frage zu einer rechtlichen frage übersetzen kann, die der terminologie von statuten entspricht"}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "besides statutary law is not a stack of independent article that can be treated as a complete source of information on the own unlike news or recipes for example"}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "statt es ist eine struktur kollektion von legal provision die haben eine ganze bedeutung nur wenn betrachtet in der überwältigenden kontext das ist zusammen mit der supplementären information von den benachbarten artikeln die felder und subfelder sie gehören zu und ihre platz in der struktur des gesetzes"}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich sind gesetzliche Artikel in einem kleinen Absatz, der in den meisten Rückholungswerken normalerweise die typische Rückholungseinheit ist."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Jahre lang"}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben ein großes Interesse an vielen rechtlichen Aufgaben wie der Vorhersage von Rechtsurteilen oder der automatisierten Kontraktprüfung geweckt."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Strafverfolgung der Artikel ist hauptsächlich unberührt geblieben, weil es keine großen, qualitativ hochwertigen Datensätze gibt."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "in dieser arbeit präsentieren wir ein neues französisch natives bürgerzentrisches datensatz, um zu studieren, ob ein retrieval model die effizienz und zuverlässigkeit eines legal experts für die aufgabe des statutarischen artikel retrieval annähern kann"}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "oder belgische Statutary Article Retrieval Dataset, z. B. besteht aus mehr als 1.100"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen decken eine breite Palette von Themen ab, von Familie, Wohnung, Geld, Arbeit und Sozialsicherheit."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen mit Bezug auf relevante Artikel aus einem Korpus von mehr als 22.600"}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Das sind belgische Gesetze. Jetzt reden wir darüber, wie wir diese Datensätze gesammelt haben."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst begannen wir mit der Zusammenstellung eines großen Korpus legaler Artikel."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachteten 32 öffentlich verfügbare belgische Codes und entnahmen alle Artikel sowie die entsprechenden Abschnitte."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann haben wir rechtliche Fragen mit Bezug auf relevante Statuten zusammengestellt."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "um das zu tun wir partner mit einer belgischen juristischen firma die erhält jedes jahr rund viertausend e mails von belgischen bürgern die fragen nach rat über eine persönliche oder rechtliche issue"}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich genug, Zugang zu ihren Webseiten zu bekommen, wo ihr Team von erfahrenen Juristen die häufigsten Rechtsfragen in Belgien adressiert."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir sammelten Tausende von Fragen, die mit Kategorien, Unterkategorien und rechtlichen Referenzen zu relevanten Statuten annotiert waren."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "letztlich wir passten die legal referenzen und filterten aus die fragen deren referenzen waren nicht artikeln in einem der codes of law wir betrachteten"}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Referenzen wurden abgestimmt und in die entsprechenden Artikel-Ides von O Corpus umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.100 Fragen, jede sorgfältig mit den Ideen der relevanten Artikel aus"}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus kommt jede Frage mit einer Hauptkategorie und einer Konkatenation von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel hat eine Konkatenation der nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzliche Information wird nicht in der gegenwärtigen Arbeit verwendet, aber könnte für zukünftige Forschungen über die Erlangung von rechtlichen Informationen oder die Klassifizierung von Rechtstexten von Interesse sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Lass uns einige Merkmale aller Datensätze untersuchen."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen sind zwischen fünf und vierundvierzig Wörtern lang, mit einem Median von vierundvierzig Wörtern."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer Medianlänge von 77 Wörtern, mit 140 Wörtern."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei davon, die einen Thunderstorm überschreiten."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "wie zuvor erwähnt die frage deckt ein weites range von topics mit rund achtzig fünf prozent von ihnen seiend entweder über familie housing geld oder justiz"}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden 15 % beziehen sich auf Sozialversicherung, Ausländer oder Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr vielfältig, da sie aus 32 verschiedenen belgischen Codes stammen, die eine große Anzahl von Rechtsthemen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Codes gesammelt wurden."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Aus den zweiundzwanzigtausendsechshundertdreiunddreißig Artikeln werden nur eintausendsechshunderdundzwanzig als relevant bezeichnet."}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "Einer der Fragen in der Datensammlung, und etwa 80 Prozent dieser zitierten Artikel stammen von der Zivilgerichtshof, der Justizbehörde, der Kriminalverfolgungsbehörde oder der Strafverfolgungsbehörde."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen haben achtzehn von zweiunddreißig Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Was durch die Tatsache erklärt werden kann, dass die Kodexen weniger auf Individuen und ihre Bedenken konzentrieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ist die mediane Anzahl der Zitate für diese zitierten Artikel zwei, und weniger als 25 % davon"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen benutzen wir mehrere Retrieval-Ansätze, darunter lexikalische und dichte Architektur."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "gegeben ein query in einem artikel ein lexikales modell zählt eine score zu dem query article paar durch berechnen der summe über die query-terme von den gewichten von jedem dieser termen in diesem artikel"}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-Ranking-Funktionen TfIdF und BM25"}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem mit diesen Ansätzen ist, dass sie nur Artikel retrieven können, die Schlüsselwörter enthalten, die in der Abfrage vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuralen Architektur, die die semantische Beziehung zwischen Anfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Encoder-Modell, das Queries und Artikel in dichte Vektorrepräsentationen mappt und eine relevante Punktzahl zwischen einem Query-Article-Paar berechnet, nach der Ähnlichkeit ihrer Embeddings."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen resultieren typischerweise aus einer Pooling-Operation auf der Ausgabe eines Wort-Embedding-Modells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst untersuchen wir die Effektivität von siamesischen Biancodern in einer Zero-Shot-Evaluierung, was bedeutet, dass prätrainweite Embeding-Modelle ohne zusätzliche Feintuning aus der Box angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Textencoder, namentlich WordtoVec und Fasttext, und kontextabhängigen Embedding Modellen, namentlich Roberta und mehr spezifisch Camembert, was ein französisches Roberta Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes auf CommonBert basierendes Modell,"}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den zwei Geschmacksrichtungen der Biancoro-Architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Wort-Embedding-Modell verwendet, das das Query n'Article zusammen in einem gemeinsamen Densivektorraum mappt, und ToTower, das zwei unabhängige Wort-Embedding-Modelle verwendet, die das Query n'Article separat in verschiedene Embedding-Räume encodiert."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mean, Max und CLS-Pooling sowie mit Punktprodukt und Kosinus, um Ähnlichkeiten zu berechnen."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Basislinie auf dem Testset."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "mit den lexikalischen Methoden oben die siamesischen beyankoder evaluiert in einem zero shot setup in der mitte und die fein tunten beyankoder unten"}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die Fine Tune Biancoder alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zwei-Tower-Modell verbessert sich über seine siamesische Variante auf Recall at One Hundred, aber führt ähnlich an den anderen Metriken aus."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl B.M. 25 die Train-Unterführung deutlich überflüssiger macht, zeigt seine Leistung, dass es eine starke Basis für Domain-Spezifische Rückkehr ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Bezüglich der Zero-Shot-Evaluation von Siamese Bianchoder finden wir, dass direktes Verwenden der Embeddings eines vorgeführten Kamambertmodells ohne Optimierung für die Information retrieval task schlechte Ergebnisse gibt, was mit vorherigen Funden übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "ferner beobachten wir, daß der wort-to-vec-wort-basierte biancoder signifikant den fasttext und wortbasierten modell übertraf, was darauf hindeutet, daß vielleicht prätrainierte wort-level-embeddings für die aufgabe geeigneter sind als charakter-level oder subword-level-embeddings, wenn sie aus der box verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "obwohl promising diese resultate suggerieren ample opportunität für verbesserung verglichen mit einem geschicklichen expert der kann schließlich retrieve all relevant article zu jeder frage und somit bekommen perfekte scores"}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns schließen, indem wir zwei Einschränkungen aller Datensätze diskutieren."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "zuerst der corpus von artikel ist begrenzt auf diejenigen gesammelt aus den dreißig zwei betrachteten belgischen codes die nicht decken das gesamte belgische gesetz als artikel aus dekreten direktiven und ordinanzen sind fehlend"}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "während der datensatzkonstruktion alle referenzen zu diesen ungesammelten artikeln sind ignoriert was verursacht einige fragen zu enden mit nur einer fraktion der ursprünglichen zahl von relevanten artikeln"}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsausfall impliziert, dass die Antwort in den verbleibenden relevanten Artikeln unvollständig sein könnte, obwohl sie immer noch völlig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir bemerken, dass nicht alle rechtlichen Fragen mit Statuten allein beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Kann ich meine Mieter evakuieren, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "könnte nicht eine detaillierte antwort innerhalb statutarischer gesetzlichkeit haben, die eine spezifische noise-schwelle quantifiziert, an der evakuierung erlaubt ist"}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollten die Landleute sich wahrscheinlich mehr auf Rechtsprechung verlassen und Präzedenzfälle finden, die der aktuellen Situation ähneln."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Mieter zwei Partys pro Woche bis zu"}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "hence einige fragen sind besser geeignet als andere zu der statutarischen artikel retrieval task und die domäne der weniger geeigneten einmal bleibt zu werden bestimmt"}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass alle Arbeiten Interesse an der Entwicklung praktischer und zuverlässiger gesetzlicher Artikelrückgewinnungsmodelle wecken."}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann helfen, den Zugang zu Justice Fold zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Papiere, die in den folgenden Links angeführt sind, auschecken."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir sind glücklich, unsere Arbeit auf Vowels, einem task-independenten Benchmark, zu präsentieren, der für das Testen von Visionen und Sprachmodellen mit spezifischen linguistischen Phänomenen gedacht ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark aufzustellen?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformator-basierten Vision- und Sprachmodellen gesehen, die auf großen Mengen von Bild- und Textpaaren vorgeübt wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle schiebt den Stand der Kunst auf Vision und Language Tasks wie Visual Question Answering, Visual Common Sense Reasoning, Image Retrieval, Phrase Grounding."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "So haben wir eine Nachricht bekommen: Die Genauigkeiten dieser Aufgaben-spezifischen Benchmarks steigen stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was ist es, dass ein Vision and Language Transformer verstand, wenn er ein Highscore für dieses Bild und diesen Satz zu matchen zeigte?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "und die Low Score für dieses eine."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Fokussieren Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Voreingenommenheiten, wie es vorherige Arbeiten gezeigt haben?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf diesen Aspekt zu werfen, schlagen wir eine mehr task-agnostic Richtung vor und führen Vowels ein, die die Sensitivität von Vision und Language Models zu spezifischen linguistischen Phänomenen, die sowohl die linguistische als auch die visuelle Modalitäten beeinflussen, testen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir target Existenz, Pluralität, Zählung,&nbsp; Spatial Relations, Aktionen und Entitätskoreferenz."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle diese Phänomene erfasst haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Eine Methode, die zuvor nur für Nomenphrasen von Ravi Shekhar und Mitarbeitern und auf Zählung durch uns in früheren Arbeiten angewendet wurde."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet, dass wir die Beschriftung eines Bildes nehmen und ein Folien produzieren, indem wir die Beschriftung so verändern, dass sie das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir machen diese Phrasenalterationen, indem wir auf sechs spezifische Stücke fokussieren, wie Existenz, Pluralität, Zählung, Spatialrelationen, Aktionen und Entitätskoreferenz, wo jedes Stück aus einem oder mehreren Instrumenten bestehen kann, in Fall dass wir mehr als einen interessanten Weg gefunden haben, um Folieninstanzen zu kreieren."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "In der Fall des Aktionsspieces haben wir zwei Instrumente, ein Instrument, in dem das Aktionsverb mit einer anderen Aktion geändert wird, und ein Instrument, in dem die Aktanten ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählung und Korreferenz sind auch Stücke, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir kreieren diese Folien, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und ansonsten gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht leicht zu tun, weil eine falsche Beschriftung weniger wahrscheinlich ist als die Originalbeschriftung."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es statistisch gesehen nicht unmöglich, dass Pflanzen einen Mann schneiden, als dass ein Mann Pflanzen schneiden könnte, und große Visionen und Sprachmodelle könnten dies aufspüren."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um also gültige Folien zu erhalten, müssen wir Maßnahmen ergreifen."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst machen wir Verwendung von starken Sprachmodellen, um Folien vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir Natursprachen-Inferenz oder Short NLI, um Folien zu filtern, die das Bild noch beschreiben können, da wir bei der Konstruktion von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir die Natursprachen-Inferenz mit dem folgenden Rational an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als Prämisse und seine Beschreibung als Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus betrachten wir die Überschrift als Prämisse und das Folien als Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass ein Folien widerspricht oder neutral ist, nehmen wir das als Indikator für ein gültiges Folien."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass das Folien durch Dekaption enthaelt wird, kann es nicht ein gutes Folien sein, da es durch Transitivität eine wahrhaftige Beschreibung des Bildes gibt."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Verfahren ist nicht perfekt, es ist nur ein Indikator für gültige Folien."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Als dritte Maßnahme für die Erzeugung von gültigen Folien verwenden wir daher Human-Annotatoren, um die Daten zu validieren, die in Valven verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach Filterung und Human Evaluation haben wir so viele Testinstanzen wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass Valve keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um ein Zero-Shot-Test-Benchmark handelt, ist es so konzipiert, dass es die vorhandenen Fähigkeiten von Vision- und Sprachmodellen nach dem Vortraining nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Durch die Feintuning könnten Modelle nur Artefakte oder statistische Voreingenommenheiten in den Daten ausnutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Models gerne schwindeln und Abkürzungen machen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind interessiert in die Beurteilung der Fähigkeiten, die Vision- und Sprachmodelle nach dem Vortraining haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Visionen und Sprachmodellen auf Vowels, nämlich mit Clip, Alex Mert, Wilbert, Wilbert Twenty One und Visual Bird."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Evaluierungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bildsatzpaaren in Captions und Folien."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "vielleicht mehr relevant für dieses video wir werden showcase unsere mehr primitive metrik die paarbweise genauigkeit die misst ob die image sentence alignment score ist größer für das korrekte image textpaar als für sein foiled paar"}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Metriken und Ergebnisse,&nbsp; schaut euch unser Papier an."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit paartlicher Genauigkeit sind hier gezeigt und sie sind konsistent mit den Ergebnissen, die wir aus den anderen Metriken bekommen haben. Die beste Nullschussperformance wurde von Wilbert 12 in 1 erreicht, gefolgt von Wilbert, Alex, Merck, Klip und schließlich Visual Bird."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf die einzelnen Objekte wie Existenz und Nomenklatur konzentrieren, fast von Wilbert 12 in 1 gelöst werden, was darauf hindeutet, dass Modelle in der Lage sind, benannte Objekte und ihre Präsenz in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann keiner der verbleibenden Stücke in unseren feindseligsten Einstellungen zuverlässig gelöst werden."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen aus den Pluralität und Zählinstrumenten, dass Vision und Language Models Schwierigkeiten haben, Referenzen zu Single versus Multiple Objects zu unterscheiden oder sie in einem Image zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Relation P zeigt, dass sie Schwierigkeiten haben, eine namentliche räumliche Beziehung zwischen Objekten in einem Bild zu klassifizieren."}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Aktionen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie von Plausibilitätsbiases unterstützt werden, wie wir in der Aktionsstücke sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "aus der Correspondence Piece finden wir heraus, dass das Traceing multiple references to the same object in an image by using pronouns is also difficult for vision and language models."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Sanitätstest und weil es ein interessantes Experiment ist, benutzen wir auch zwei Text-Only-Modelle, GPT-I und GPT-II, um zu beurteilen, ob Valse durch diese Unimodell-Modelle lösbar ist, indem wir die Perplexität der korrekten und der falschen Caption berechnen und die Eingabe mit der niedrigsten Perplexität vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Perplexität für das Folien höher ist, nehmen wir das als Indikation, dass das gefolierte Caption an Plausibilitätsbias oder anderen linguistischen Bias leiden kann."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Es ist interessant zu sehen, dass in einigen Fällen die Text-GTP-Modelle die Plausibilität der Welt besser erfassen als die Vision- und Sprachmodelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "So, zum Zusammenfassungsbericht, ist Wals ein Benchmark, der die Länge von linguistischen Konstrukten verwendet, um der Gemeinschaft zu helfen, Vision und Sprachmodelle zu verbessern, indem sie ihre visuellen Grundungskapazitäten hart testen."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die Sprachmodelle die Objekte in der Präsenz identifizieren, die von der Existenz gezeigt werden, aber sie kämpfen um ihre Interdependenz und ihre Beziehungen zu den visuellen Szenen zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir würden die Community dazu ermutigen, VALs zu verwenden, um den Fortschritt in Bezug auf die Sprache zu messen, mit Visionen und Sprachmodellen."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr Valves könnten als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach Training oder Feintuning evaluiert werden könnten, um zu sehen, ob ein Datensatz Modellen hilft, irgendwelche von den von Valves getesteten Aspekten zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, überprüfen Sie die falschen Daten auf GitHub und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizawa von der Universität von Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde eine Arbeit mit dem Titel \"L und Sum: ein groß angelegter Dadset für automatische Wiederholung der Drogenkonsumation\" präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde es in dieser Reihenfolge erklären."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst werde ich die automatische Wissensgenerierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNote ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Veröffentlichung eines Softwareprodukts verteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Die E-Mail zeigt eine Release-Notiz für Bogen 2,6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Diese Notizen spielen eine wichtige Rolle bei der Open-Source-Entwicklung, aber es nimmt Zeit, sie manuell vorzubereiten."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, automatisch hochwertige Lease-Notes generieren zu können."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich habe mich auf zwei frühere Untersuchungen zur automatischen RISC-Generation bezogen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens Array, das 2014 veröffentlicht wurde."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es nimmt einen regelbasierten Ansatz an, beispielsweise die verwendeten Änderungen zu verwenden, um Kernunterschiede, Bibliotheksänderungen und Dokumentänderungen aus den Unterschieden zwischen den Veröffentlichungen zu extrahieren und sie schließlich zu kombinieren."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das bemerkenswerteste Merkmal dieses Systems ist die Extraktionsfläche in der oberen rechten Ecke."}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Die muss mit Zero verbunden sein, dem Ausgabensystem, und kann nur auf Produkte angewendet werden, die Zero verwenden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, es kann nicht für viele Projekte auf Gitarre verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist Grief, der kürzlich in den letzten 20 Jahren angekündigt wurde."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Es ist im Internet verfügbar und kann über Pip gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System hat ein einfaches, läufig basierendes Klassifizierungsmodell und ergibt eine von fünf Rubriken, wie Features oder Bugfixes, für jede Eingabe-Commit-Nachricht."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist eine einfache Verwendung, die ein korrigierendes oder Fehlerbehebungs-Label zurückgibt."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingsdaten sind ziemlich klein, etwa fünftausend, und werden in den unten beschriebenen Experimenten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Text-Klassifikationsmodells ist nicht hoch."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Untersuchungen, aber es gab Probleme mit begrenzter Anwendbarkeit und knappem Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Artikel löst diese beiden Probleme und generiert automatisch hochwertige Zuhörer."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das begrenzte Anwendbarkeitsproblem schlägt er eine hochwertige Klassifizierungsmethode vor, die nur die Kommissionsbotschaft als Eingang verwendet."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Versionen verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der knappsten Ressourcen bauten wir eine Ansatzgruppe auf, die aus etwa 82,000 Datenstücken bestand, indem wir Daten aus öffentlichen GitHub-Repositorien mit der GitHub API sammelten."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unsere Wüste."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Kommits-Nachricht und die rechte Seite ist die Leiste."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Lezner werden als Instrumente für Physiker usw. bewertet."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die übertragenen Nachrichten als Eingabe und Ausgabe nimmt, die nicht erlaubt ist."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Das kann als eine Zusammenfassungsarbeit angesehen werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier vordefinierte Ebenen: Funktionen, Verbesserungen, Fehlerbehebungen, Verfall, Entfernung und Bremsänderungen."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese Gesetze basieren auf früheren Forschungen und anderen Faktoren."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Der Blatt ist unten rechts nicht zu sehen und wird ausgelöst, wenn der Blatt unten links nicht zu sehen ist."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zeitpunkt ist es notwendig, die vier Trümmer zu erkennen, die im Voraus aufgestellt wurden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Werte sind nicht immer mit jedem Lipetzi übereinstimmen."}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel umfasst das Verbesserungsniveau Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabularliste von dreißig Wörtern für jede dieser Rotationsvariationen vorbereitet."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die verhältnismäßigen Klassen zu erkennen und den Text der Klassen zu korrigieren, der als verhältnismäßiger Satz für die Klassen folgt."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Kommitte-Nachricht."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Kommando-Nachrichten sind nicht an jedes Stück gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie im Bild unten zu sehen ist, wenn die aktuelle Freigabe 2,5 bis 19 ist, müssen wir"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "die vorherige Version, 2.518 und get it done. Das ist ein bisschen tedious und es ist nicht genug, um nur eine Liste von Releases zu bekommen und zu sehen, wie es vor und nach geht."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er schuf ein heuristisches Matching-Tool, um die vorherigen und nächsten Versionen zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein Narzis."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende: 7.200 Lagerstätten."}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist die durchschnittliche Anzahl der veröffentlichten Tokens dreiundsechzig, was für einige Vermittlungsarbeiten ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Anzahl der einzigartigen Token ist ziemlich hoch, bei 80.000-80.000."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "Aufgrund der großen Anzahl von einzigartigen Klassen- und Methodennamen, die im Labor gefunden wurden."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes werde ich die vorgeschlagene Methode erklären."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Kreuzweise extraktive und abstrakte Zusammenfassungsmodul besteht aus zwei neutralen Modulen."}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "ein Klassifizierer mit Bart oder Code Bart und ein Generator mit Bart"}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst verwendet CAS einen Klassifikator, um jede Kommando-Nachricht in fünf G-Snot-Klassen zu klassifizieren: Features, Improvements, Bugfixes, Applications, Pluses und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die Kommitt-Nachrichten, die als andere eingestuft werden, werden verworfen."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Anschließend wendet GAS den Generator unabhängig voneinander auf die vier Rader-Dokumente an und generiert für jede Klasse eine Notenliste."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Korrespondenzen zwischen Kommissionsbotschaften und Reasonalen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifikator zu trainieren, weisen wir den ersten zehn Zeichen jeder Kommando-Nachricht zwei Ebenen zu."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die klassifizierte obstruktive Summary-Analyse mit zwei verschiedenen Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GISingle nennen, besteht aus einem einzigen Sex-to-Sex-Netzwerk und generiert eine einzige, lange, ohne Text, gegebenenfalls eine Konzentrierung von Eingabekommitterten-Nachrichten."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Die Ausgangsmarkierungen können auf der Grundlage spezieller, cross-spezifischer Endpunkt-Symbole in Querschnittsegmente unterteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GS-Mach nennen, besteht aus vier verschiedenen Sec-to-Sec-Netzwerken, von denen jede einer der drei Notenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, lass mich das Experiment erklären."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden berechnet: Cheers, Cheers Single, Cheers March, Rustling und vorherige Studie Grief."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Was die Abweichung betrifft, so werden in einigen Fällen diese Notizen in mehreren Sätzen ausgedrückt."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze auf Null zu korrigieren, werden sie mit Räumen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro wird bestraft, wenn das System einen kurzen Satz aussagt."}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem niedrigeren Wirkwert, wie in den nachstehend beschriebenen Experimentsergebnissen dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich korrigieren wir auch die Spezifität, weil blau und blau nicht korrigert werden können, wenn die Leisten nicht leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass die Modell-Genauigkeit-Ausgabe leeren Text ist, in Fällen, in denen die Leitnoten als leer angenommen werden."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist der zweite Teil."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da das Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, betreiben wir auch ein Print-Datensatz, das sie ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "CEA und CEA erreichten bei Rouge's Scores mehr als zehn Punkte höher als die Baseline."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Clearing-Test-Set stieg die Punktzahl zwischen der vorgeschlagenen Methode und der Baseline auf mehr als 20 Punkte."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse deuten darauf hin, dass sie und sie erheblich wirksam sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS hat eine bessere Root-Face-Score als GAS, was darauf hindeutet, dass die Kombination eines Klassifikators und eines Generators effektiv ist und die Klassifikator mit Subroutinen ausbildet."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe CAL-Abdeckung kann ordnungsgemäß erreicht werden, da sich der Klassifizierer auf die Auswahl relevanter Kommitt-Nachrichten für jede Klasse konzentrieren kann."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie ist sehr geneigt, höhere Leistungen zu erzielen als eine Single."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "was darauf hindeutet, dass es auch effektiv ist, unabhängig voneinander unterschiedliche abstrakte Zusammenfassungsmodelle für jede Piece-Note-Klasse zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hier und da ist das."}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Shears Methoden neigen dazu, kürzere Sätze als menschliche Referenzsätze auszugeben."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der rechten Abbildung hat der Bezugssatz drei oder vier Sätze, während der andere nur einen hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese kleinere Zurückhaltung ist, dass in der Ausbildung nur 33 % der Sätze auf der Features-Ebene und 40 % auf der Implementationsebene vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können Cie's Methoden ohne zusätzliche Informationen keine genauen Rückmeldungen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das oberste Beispiel rechts ist ein Beispiel für eine sehr unordentliche Kommit-Botschaft, und der vollständige Satz kann nicht ohne Bezug auf das entsprechende Privileg oder Problem generiert werden."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden committed-Mitteilungen im Eingang miteinander verbunden sind und in einen Satz kombiniert werden sollten, aber dies nicht der Fall ist."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Endlich ein Abschluss."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben ein neues Desktop für automatische Generations-Personen gebaut."}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben mir auch die Aufgabe übertragen, Kommitt-Nachrichten einzugeben und sie zusammenzufassen, so dass sie auf alle Projekte anwendbar sind, die in Englisch geschrieben sind."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode weniger Lärm und eine höhere Abdeckung als die Ausgangsgrenze erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte prüfen Sie, ob das auf GitHub ist!"}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wie nennt man den Fahrer?"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "And I will present our paper, Future tabular data enrichment using fine tuned transformers architectures."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Analysiert ein Wissenschaftler Daten und konzentriert sich hauptsächlich auf die Manipulation der vorhandenen Datenmerkmale?"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Eigenschaften begrenzt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Eine zukünftige Generation, die eine andere Datenquelle verwendet, kann substantielle Informationen hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsschwerpunkt ist die automatische Tabellendatenvermehrung mit freiem Text aus externen Quellen."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, wir haben einen Tabellendatensatz und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen einen automatischen Prozess, der Entity-Linking und Textanalyse beinhaltet, um neue Funktionen aus dem Knowledge-Base-Free-Text zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework, first, is exactly this automatic process."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "So, lassen Sie uns ein Beispiel nennen. In einer Datensatz, die in zwei Festungen gefüttert wird,"}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Datensatz ein Universitätsdatensatz."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es das Ziel hat, Universitäten in Low-Ranked-Universitäten und High-Ranked-Universitäten zu klassifizieren."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Fest ist Entity-Linking."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "wenn jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität innerhalb der Wissensbasis verbunden ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Knowledge Base wird extrahiert und zum Datensatz hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text der Wikipedia Page Abstract."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Now we need to generate or extract features from the retrieved text."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen eine Feature-Extraktionsphase, die Textanalysen beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers und ich werde in die nächste Folge tief dive."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Feature-Extraction-Phase gibt es eine Feature-Generation-Phase, in der wir die extrahierten Features nutzen, um eine kleine Anzahl neuer Features zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Erst erzeugen wir Features in der Anzahl der Klassen des Original-Datasets."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also erzeugen Sie zwei neue Features."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn der Datensatz fünf Klassen hat, generieren Sie zuerst fünf neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jedes Feature repräsentiert die Wahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen State of the Art der Textanalyse, die transform-basierte Sprachmodelle sind, S B G P T, Excel et cetera."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Aber es ist nicht wahrscheinlich, dass wir das Language Model trainieren können, indem wir die Input-Daten verwenden."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "So ein naiver Ansatz wird ein Target-Task-Fine-Tuning sein."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Extraktionsphase können wir das per Trend-Sprachmodell herunterladen, das Sprachmodell über den Zieldatensatz einstellen"}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, um das Sprachmodell zu fintuchern, um Text in Klassen zu klassifizieren, abstrakt in Klassen, Low oder High."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Receive the language model output, which is the likelihood for each class, and use as new features."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem mit diesem Ansatz ist, dass Datensätze nur wenige verschiedene Entitätenstaggs haben können."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthalten fast die Hälfte der Datensätze weniger als 400 Proben, und der kleinste Datensatz enthält 35 Proben in seinem Trainingsset."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein sehr fein gestaltetes Sprachmodell, das ineffektiv sein wird."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können auch vorherige Kenntnisse über präanalysierte Daten verwenden."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "weil wir schnell über mehrere Datensätze anwenden können, können wir die N-Wert-Daten aufnehmen und diese Daten verwenden, wenn wir die N-Wert-Daten aufschreiben."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist eine weitere Feintuningphase."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "und vorläufige Multitasking-Fine-Tuning-Phase."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über Nm1 Datensätze finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Finierung durch, die als Ziel-Finierung bezeichnet wird, wenn wir das Sprachmodell über den End-Targetset ausfinden."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der State of the Art in Multitask Fine Tuning, genannt MTDN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDN halten wir die Heads in the number of tasks in the training set."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es vier Aufgaben im Trainingsset, also entleeren Sie den DNA und bewahren Sie vier Köpfe auf."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "und es samples a random badge from the training set."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Runner Badge gehört zu zum Beispiel Sing and Seltons Klassifikationstasks, ist es die Exekution vorwärts und rückwärts durch den ersten Head."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die Random-Batch zu einem Ranking-Prozess gehört, ist es möglich, dass sie durch den letzten Kopf vorwärts und rückwärts geht."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario, Tabelle, Datensatz und Reihenfolge der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Also gibt es viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN hält die Anzahl der Klassen-Höhen, Ausgangs-Layer,"}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss MTN neue Heads für neue Datensätze mit einer neuen Aufgabe anstellen."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Ansatz, der Task Reformulation Fine Tuning, reformieren wir jedes Datensatz in einen Satz pro Klassifikationsproblem,"}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Also lassen Sie uns ein Beispiel sehen."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Input-Datensatz, der sich aus Entitäten, Features, Texten und Klassen zusammensetzt."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe von der Klassifizierung des Textes in Low-and-High, um den Text, die Abstrakt- und die Klasse in True-or-False zu klassifizieren."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, wir trainieren das Sprachmodell, um Abstrakt und Klasse zu klassifizieren, ob das Abstrakt der Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Labelvektor in diesem Fall besteht aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unsere neu formulierte Feinabstimmungsanpassung."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "So lassen wir das vollen Framework sehen."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein sehr fester Datensatz."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erst in der Linking-Phase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "es extrahiert den Text aus der Knowledge Base, der in diesem Beispiel der Abstracts der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird die Aufgabe in Satz-per-Klassifikations-Aufgaben umformuliert."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Das Sprachmodell auf die neue Aufgabe und die Ausgangswahrscheinlichkeit für jede Klasse anwenden."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Das Sprachmodell ist bereits über einen N-Wert-Satz mit einer vorläufigen Multitasking-Fine-Tuning-Ausrichtung ausgerichtet."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Outputvektor des Language Model als neu generierte Funktion in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Framework zu bewerten, verwenden wir einen 17 Tabularen Klassifikationsdatensatz, der in Größe, Funktionen, Balance, Domain und Initial Performance variiert."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Knowledge Base verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir entwerfen unser Experiment als live one out evaluation, wenn wir schnell über 16 Datensätze trainieren und es auf das 17. Datensatz anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch diese Daten in vier Fälle gespalten und haben die Cross-Verifizierung durchgeführt."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Features und bewerten sie mit fünf Evaluation Classifiers."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserer experimentellen, geburtsbasierten Architektur"}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse für unser Experiment."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Wir vergleichen unser Framework mit Target-Dataset-Fine-Tuning und MT-DNN-Preliminary-Fine-Tuning."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere Reformulierte Feintuning erzielte das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN ein Improvement von 2% erzielte,"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Pouch hat sich um 6 % verbessert."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir auf den kleinen Datensatz schauen, sehen wir, dass die Leistung von MTDN und die Verbesserung der Preliminary Multitasking Phase sinken auf 1,5 Prozent."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung ist um 11% gestiegen, verglichen mit der Ziel-Task-Fine-Tuning-Alone."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für das Summen ermöglicht FastFourShot-Enrichment aus 35 Samples in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Tasks-Datasets."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er hält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es hat seine Reformulation."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es wird die Transition so angepasst, dass es ein Zielwert mit semantischer Bedeutung braucht, also können wir es in das Sprachmodell einführen und es in der Klassenklassifikationsproblematik verwenden."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke fürs Gespräch."}
