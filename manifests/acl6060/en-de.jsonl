{"dataset_id": "acl_6060", "sample_id": 0, "src_audio": "/acl6060/audio/dev/0.wav", "src_ref": "Hi, this is Elena and I'm going to be presenting our work, Detecting Unassimilated Borrowings in Spanish: An Annotated Corpus and Approaches to Modeling.", "tgt_ref": "Hallo, hier ist Elena und ich stelle nun unsere Arbeit vor: Die Erkennung nicht-assimilierter Entlehnungen im Spanischen: Ein annotierter Korpus und Ansätze zur Modellierung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_audio": "/acl6060/audio/dev/1.wav", "src_ref": "So we're going to be covering what lexical borrowing is, the task that we proposed, the dataset that we have released and some models that we explored.", "tgt_ref": "Wir werden uns also damit beschäftigen, was die lexikalische Entlehnung ist, die von uns vorgeschlagene Aufgabe, den veröffentlichten Datensatz und einige untersuchte Modelle.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_audio": "/acl6060/audio/dev/2.wav", "src_ref": "But to begin with, what is lexical borrowing and why it matters as an NLP task?", "tgt_ref": "Doch zunächst einmal: Was ist die lexikalische Entlehnung und warum ist sie als NLP-Aufgabe so wichtig?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_audio": "/acl6060/audio/dev/3.wav", "src_ref": "Well, lexical borrowing is basically the incorporation of words from one language into another language.", "tgt_ref": "Die lexikalische Entlehnung ist im Grunde die Übernahme von Wörtern aus einer Sprache in eine andere Sprache.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_audio": "/acl6060/audio/dev/4.wav", "src_ref": "For instance, in Spanish we use words that come from English.", "tgt_ref": "Zum Beispiel verwenden wir im Spanischen Wörter, die aus dem Englischen stammen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_audio": "/acl6060/audio/dev/5.wav", "src_ref": "And here you have a few examples, words such as podcast, app, and online crowdfunding, all these are English words that we sometimes use in Spanish.", "tgt_ref": "Und hier ein paar Beispiele: Wörter wie Podcast, App und Online-Crowdfunding sind englische Wörter, die wir manchmal im Spanischen verwenden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_audio": "/acl6060/audio/dev/6.wav", "src_ref": "Lexical borrowing is a type of linguistic borrowing um which is basically reproducing in one language patterns of other languages.", "tgt_ref": "Die lexikalische Entlehnung ist eine Art der sprachlichen Entlehnung, die im Grunde genommen die Reproduktion von Mustern einer Sprache in einer anderen Sprache bedeutet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_audio": "/acl6060/audio/dev/7.wav", "src_ref": "And borrowing and code switching have sometimes been compared and described as a continuum, code switching being ah the thing that bilinguals do where they mix two languages at the same time.", "tgt_ref": "Manchmal wurde die Entlehnung mit dem Code-Switching verglichen und als ein Kontinuum beschrieben. Code-Switching wird von Zweisprachigen praktiziert, wenn sie zwei Sprachen gleichzeitig verwenden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_audio": "/acl6060/audio/dev/8.wav", "src_ref": "There are however some differences between lexical borrowing and code-switching.", "tgt_ref": "Es gibt jedoch einige Unterschiede zwischen lexikalischer Entlehnung und Code-Switching.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_audio": "/acl6060/audio/dev/9.wav", "src_ref": "We're going to be focusing on lexical borrowing.", "tgt_ref": "Wir werden uns auf die lexikalische Entlehnung konzentrieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_audio": "/acl6060/audio/dev/10.wav", "src_ref": "Code switching is something that is done by bilinguals and by definition the code switches are not integrated into any of the languages in use, whereas lexical borrowing is something that is also done by monolinguals.", "tgt_ref": "Zweisprachige Personen praktizieren das sogenannte Code-Switching. Per Definition sind die Code-Switches nicht Teil der verwendeten Sprachen, während die lexikalische Entlehnung auch von einsprachigen Personen verwendet wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_audio": "/acl6060/audio/dev/11.wav", "src_ref": "The borrowings will comply with the grammar of the recipient language.", "tgt_ref": "Die Entlehnungen werden der Grammatik der Empfängersprache angepasst.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_audio": "/acl6060/audio/dev/12.wav", "src_ref": "And borrowings can eventually be integrated into the recipient language.", "tgt_ref": "Entlehnungen können Schritt für Schritt in die Empfängersprache integriert werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_audio": "/acl6060/audio/dev/13.wav", "src_ref": "So why is borrowing an interesting phenomenon?", "tgt_ref": "Warum ist Entlehnen so ein interessantes Phänomen?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_audio": "/acl6060/audio/dev/14.wav", "src_ref": "Well, from the point of view of linguistics, borrowing is a manifestation of of how languages change and how they interact.", "tgt_ref": "Aus Sicht der Linguistik ist die Entlehnung eine Manifestation dessen, wie sich Sprachen verändern und wie sie interagieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_audio": "/acl6060/audio/dev/15.wav", "src_ref": "And also lexical borrowings are a source of new words.", "tgt_ref": "Auch lexikalische Entlehnungen sind eine Quelle für neue Wörter.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_audio": "/acl6060/audio/dev/16.wav", "src_ref": "Here you have some examples of lexical borrowings that have been incorporated into the Spanish language as new words.", "tgt_ref": "Hier finden Sie einige Beispiele für lexikalische Entlehnungen, die als neue Wörter in die spanische Sprache aufgenommen wurden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_audio": "/acl6060/audio/dev/17.wav", "src_ref": "In terms of NLP ah borrowings are a common source of out-of-vocabulary words.", "tgt_ref": "Beim NLP sind Entlehnungen eine häufige Quelle von Wörtern, die nicht im Wortschatz enthalten sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_audio": "/acl6060/audio/dev/18.wav", "src_ref": "And in fact, automatically detecting lexical borrowings ah has proven to be useful for NLP downstream tasks such as parsing, text-to-speech synthesis or machine translation.", "tgt_ref": "Die automatische Erkennung lexikalischer Entlehnungen erwies sich als nützlich für NLP und nachgelagerte Aufgaben wie Parsing, Text-zu-Sprache-Synthesen oder die maschinelle Übersetzung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_audio": "/acl6060/audio/dev/19.wav", "src_ref": "There has been a growing interest in the influence of English on other languages ah particularly ah related to English lexical borrowings, borrowings which sometimes have been called Anglicisms.", "tgt_ref": "Der Einfluss des Englischen auf andere Sprachen erfährt immer stärkeres Interesse, insbesondere bei englischen lexikalischen Entlehnungen. Diese werden manchmal auch als Anglizismen bezeichnet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_audio": "/acl6060/audio/dev/20.wav", "src_ref": "And here, you have some examples of ah work on automatic detection of borrowings in ah some of these languages.", "tgt_ref": "Hier sind einige Beispiele von Arbeiten zur automatischen Erkennung von Entlehnungen in einigen dieser Sprachen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_audio": "/acl6060/audio/dev/21.wav", "src_ref": "So the task that we propose is to detect unassimilated lexical borrowings in Spanish newswire.", "tgt_ref": "Die Aufgabe, die wir vorschlagen, besteht also darin, nicht-assimilierte lexikalische Entlehnungen in spanischen Nachrichten zu erkennen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_audio": "/acl6060/audio/dev/22.wav", "src_ref": "Which means that we are interested in extracting ah words borrowed from other languages that are being used in Spanish newspapers but that have not been integrated or assimilated into the recipient language.", "tgt_ref": "Wir sind daran interessiert, aus anderen Sprachen entlehnte Wörter zu extrahieren, die in spanischen Zeitungen verwendet werden, aber nicht in die Empfängersprache integriert oder assimiliert wurden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_audio": "/acl6060/audio/dev/23.wav", "src_ref": "So not yet integrated into Spanish.", "tgt_ref": "Sie wurden also noch nicht ins Spanische integriert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_audio": "/acl6060/audio/dev/24.wav", "src_ref": "Here you have an example.", "tgt_ref": "Hier ist ein Beispiel.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_audio": "/acl6060/audio/dev/25.wav", "src_ref": "This is a sentence in Spanish: Las prendas bestsellers se estampan con motivos florales, animal print o retales tipo patchwork.", "tgt_ref": "Dies ist ein Satz auf Spanisch: Las prendas bestsellers se estampan con motivos florales, animal print o retales tipo patchwork.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_audio": "/acl6060/audio/dev/26.wav", "src_ref": "Um, and as you can see, there are three spans of texts which are actually English words like bestseller, animal print and patchwork.", "tgt_ref": "Wie Sie sehen können, sind hier drei Textpassagen, die eigentlich englische Wörter sind: Bestseller, Animal Print und Patchwork.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_audio": "/acl6060/audio/dev/27.wav", "src_ref": "These are the type of spans that we are interested in extracting and detecting.", "tgt_ref": "Bei diesen Passagen wollen wir extrahieren und erkennen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_audio": "/acl6060/audio/dev/28.wav", "src_ref": "There has been previous word on Anglicism detection ah which consists consisted of a CRF model for Anglicism detection on Spanish Newswire.", "tgt_ref": "Es gab früher schon Arbeiten über die Erkennung von Anglizismen. Diese beschäftigten sich mit einem CRF-Modell für die Erkennung von Anglizismen in spanischen Nachrichten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_audio": "/acl6060/audio/dev/29.wav", "src_ref": "This model achieved an F1 score of eighty six.", "tgt_ref": "Dieses Modell erreichte einen F1-Score von 86.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_audio": "/acl6060/audio/dev/30.wav", "src_ref": "But there were some limitations both um in the dataset and the modeling approach.", "tgt_ref": "Es gab jedoch einige Einschränkungen sowohl beim Datensatz als auch beim Modellierungsansatz.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_audio": "/acl6060/audio/dev/31.wav", "src_ref": "So the dataset focused exclusively on one source of news, consisted only of headlines.", "tgt_ref": "Der Datensatz konzentrierte sich also ausschließlich auf eine Quelle von den Nachrichten und bestand nur aus Schlagzeilen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_audio": "/acl6060/audio/dev/32.wav", "src_ref": "And also there was an overlap in the borrowings that appear in the training set and the test set.", "tgt_ref": "Außerdem gab es Überschneidungen bei den Entlehnungen, die im Trainingssatz und im Testsatz vorkommen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_audio": "/acl6060/audio/dev/33.wav", "src_ref": "This prevented the assessment of whether the modeling approach could actually generalize to previously unseen borrowings.", "tgt_ref": "Dadurch konnte nicht beurteilt werden, ob der Modellierungsansatz tatsächlich auf zuvor unbekannte Entlehnungen verallgemeinert werden kann.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_audio": "/acl6060/audio/dev/34.wav", "src_ref": "So what we aim is to tackle some of these limitations in the task.", "tgt_ref": "Unser Ziel ist es also, einige dieser Einschränkungen in der Aufgabe zu überwinden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_audio": "/acl6060/audio/dev/35.wav", "src_ref": "So to begin we, to begin with, we created a new dataset.", "tgt_ref": "Zu Beginn haben wir also einen neuen Datensatz erstellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_audio": "/acl6060/audio/dev/36.wav", "src_ref": "Ah the aim at a new dataset that was annotated with lexical borrowings and the aim was to create a test set that was as difficult as possible.", "tgt_ref": "Das Ziel war ein neuer Datensatz, der mit lexikalischen Entlehnungen annotiert wurde, und einen möglichst schwierigen Testsatz zu erstellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_audio": "/acl6060/audio/dev/37.wav", "src_ref": "So there would be minimal overlap in words and topics between the training set and test set.", "tgt_ref": "Es gäbe also minimale Überschneidungen bei Wörtern und Themen zwischen dem Trainingssatz und dem Testsatz.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_audio": "/acl6060/audio/dev/38.wav", "src_ref": "And as a result, well, the test set comes from sources and dates that we're not seeing in the training set.", "tgt_ref": "Das Ergebnis ist, dass der Testsatz aus Quellen und Daten stammt, die wir nicht im Trainingssatz sehen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_audio": "/acl6060/audio/dev/39.wav", "src_ref": "Here you can see that there's no overlap in the in the time.", "tgt_ref": "Hier können Sie sehen, dass es keine Überschneidungen in der Zeit gibt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_audio": "/acl6060/audio/dev/40.wav", "src_ref": "It's also, the test set is also very borrowing-dense.", "tgt_ref": "Außerdem enthält der Testsatz auch sehr viele Entlehnungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_audio": "/acl6060/audio/dev/41.wav", "src_ref": "Just to give you some numbers, if the training set contains six borrowings per each thousand tokens, the test set contained twenty borrowings per each thousand tokens.", "tgt_ref": "Um Ihnen ein paar Zahlen zu nennen: Wenn der Trainingssatz sechs Entlehnungen pro 1000 Token enthält, enthält der Testsatz 20 Entlehnungen pro 1000 Token.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_audio": "/acl6060/audio/dev/42.wav", "src_ref": "The test set contained as many out of vocabulary words as possible.", "tgt_ref": "Der Testsatz enthielt so viele Vokabelwörter wie möglich.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_audio": "/acl6060/audio/dev/43.wav", "src_ref": "In fact, ninety two percent of the borrowings in the test set are OOV.", "tgt_ref": "Tatsächlich sind 92 Prozent der Entlehnungen im Testsatz OOV.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_audio": "/acl6060/audio/dev/44.wav", "src_ref": "So, they were not seen during training.", "tgt_ref": "Sie waren also während des Trainings nicht bekannt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_audio": "/acl6060/audio/dev/45.wav", "src_ref": "And the corpus consisted basically of a collection of texts that came from different sources of Spanish newspapers.", "tgt_ref": "Der Korpus bestand im Wesentlichen aus einer Sammlung von Texten, die aus verschiedenen Quellen spanischer Zeitungen stammten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_audio": "/acl6060/audio/dev/46.wav", "src_ref": "And ah it was annotated by hand ah using two tags.", "tgt_ref": "Er wurde manuell mit zwei Tags annotiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_audio": "/acl6060/audio/dev/47.wav", "src_ref": "One for English lexical borrowings which is the majority of lexical borrowings in Spanish, and then the label other for borrowings from other languages.", "tgt_ref": "Einer für englische lexikalische Entlehnungen, die den Großteil der lexikalischen Entlehnungen im Spanischen ausmachen, und dann das andere Label für Entlehnungen aus anderen Sprachen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_audio": "/acl6060/audio/dev/48.wav", "src_ref": "We use CONLL formats and we used BIO encoding so that we could encode ah single token borrowings such as app or multi token borrowings such as machine learning.", "tgt_ref": "Wir verwenden CONLL-Formate und die BIO-Kodierung, sodass wir einfache Token-Entlehnungen wie „App“ oder mehrteilige Token-Entlehnungen wie „maschinelles Lernen“ kodieren können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_audio": "/acl6060/audio/dev/49.wav", "src_ref": "These are the numbers of the corpus.", "tgt_ref": "Das sind die Nummern des Korpus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_audio": "/acl6060/audio/dev/50.wav", "src_ref": "As you can see, it amounts to roughly three hundred seventy thousand tokens.", "tgt_ref": "Wie Sie sehen können, handelt es sich um etwa 370 000 Token.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_audio": "/acl6060/audio/dev/51.wav", "src_ref": "And here you have the number of spans that were labeled as English and the spans that were labeled as other borrowings and how many of them were unique.", "tgt_ref": "Hier sehen Sie die Reihe an Passagen, die als Englisch markiert wurden, und die Passagen, die als andere Entlehnungen markiert waren, und wie viele davon einzigartig waren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_audio": "/acl6060/audio/dev/52.wav", "src_ref": "And here you have a couple of examples of the of the set of the dataset.", "tgt_ref": "Hier sehen Sie einige Beispiele für den Datensatz.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_audio": "/acl6060/audio/dev/53.wav", "src_ref": "As you can see for instance here, we have ah in the first example, we have the borrowing batch cooking which is a multi word borrowing.", "tgt_ref": "Wie Sie zum Beispiel hier sehen können, haben wir im ersten Beispiel die Entlehnung „batch cooking“, die eine mehrteilige Wort-Entlehnung ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_audio": "/acl6060/audio/dev/54.wav", "src_ref": "And we have annotated it using the BIO um encode.", "tgt_ref": "Wir haben dieses Wort mit der BIO-Kodierung annotiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_audio": "/acl6060/audio/dev/55.wav", "src_ref": "So the BIO was used for words in Spanish so not for words that were not borrowed.", "tgt_ref": "BIO wurde also für Wörter im Spanischen verwendet, also nicht für Wörter, die nicht entlehnt wurden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_audio": "/acl6060/audio/dev/56.wav", "src_ref": "And here in this second example, you have benching and crash which are also labeled as borrowings from English.", "tgt_ref": "Hier in diesem zweiten Beispiel sehen Sie „benching“ und „crash“, die ebenfalls als Entlehnungen aus dem Englischen markiert sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_audio": "/acl6060/audio/dev/57.wav", "src_ref": "So, once we had the dataset, we explored several models for the task of extracting and detecting these lexical borrowings.", "tgt_ref": "Nachdem wir also den Datensatz hatten, untersuchten wir verschiedene Modelle für die Aufgabe, bei der wir lexikalische Entlehnungen extrahieren und erkennen wollten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_audio": "/acl6060/audio/dev/58.wav", "src_ref": "The first one that we tried was the conditional random field model.", "tgt_ref": "Zuerst haben wir das bedingte Zufallsfeld Modell getestet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_audio": "/acl6060/audio/dev/59.wav", "src_ref": "Ah, this was the model that had been used on previous work.", "tgt_ref": "Das war das Modell, das bei früheren Arbeiten verwendet worden war.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_audio": "/acl6060/audio/dev/60.wav", "src_ref": "And we used the same handcrafted features from that from those from that work.", "tgt_ref": "Wir haben die gleichen manuell erstellten Funktionen wie bei dieser Arbeit verwendet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_audio": "/acl6060/audio/dev/61.wav", "src_ref": "As you can see, these are the features.", "tgt_ref": "Wie Sie sehen können, sind dies die Funktionen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_audio": "/acl6060/audio/dev/62.wav", "src_ref": "These are binary features such as the word or the token in upper case?", "tgt_ref": "Dies sind binäre Funktionen, wie das Wort oder das Token in Großbuchstaben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_audio": "/acl6060/audio/dev/63.wav", "src_ref": "Is it title titlecase?", "tgt_ref": "Handelt es sich um einen Titel?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_audio": "/acl6060/audio/dev/64.wav", "src_ref": "Is it a quotation mark?", "tgt_ref": "Ist es ein Anführungszeichen?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_audio": "/acl6060/audio/dev/65.wav", "src_ref": "Things like that, which are the type of features that one would expect in a named entity recognition task.", "tgt_ref": "Solche Dinge sind die Art von Funktionen, die man bei einer Named Entity Recognition-Aufgabe erwarten würde.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_audio": "/acl6060/audio/dev/66.wav", "src_ref": "These are the results that we got.", "tgt_ref": "Das sind die Ergebnisse, die wir erhalten haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_audio": "/acl6060/audio/dev/67.wav", "src_ref": "We obtain fifty five F1 score using the the CRF model with handcrafted features.", "tgt_ref": "Wir erhalten 55 F1-Scores, wenn wir das CRF-Modell mit manuell erstellten Funktionen verwenden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_audio": "/acl6060/audio/dev/68.wav", "src_ref": "Which is a huge different difference um compared to the reported F1 score of eighty six, which was the result obtained with the same CRF model, same features but on a different dataset also for Spanish lexical borrowing detection.", "tgt_ref": "Das ist ein großer Unterschied im Vergleich zum bereits berichteten F1-Score von 86, der ein Ergebnis desselben CRF-Modells mit derselben Funktionen war, aber auf einen anderen Datensatz angewendet wurde, auch für die Erkennung von spanischen lexikalischen Entlehnungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_audio": "/acl6060/audio/dev/69.wav", "src_ref": "So, this proves that the dataset that we created is more difficult and that we needed to explore more sophisticated models for these tasks.", "tgt_ref": "Das beweist also, dass der Datensatz, den wir erstellt haben, schwieriger ist und dass wir anspruchsvollere Modelle für diese Aufgaben entwickeln müssen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_audio": "/acl6060/audio/dev/70.wav", "src_ref": "So, we tested two transformer based models.", "tgt_ref": "Wir haben also zwei Transformer-basierte Modelle getestet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_audio": "/acl6060/audio/dev/71.wav", "src_ref": "We used BETO which is a monolingual BERT model trained for Spanish and also multilingual BERT.", "tgt_ref": "Wir haben BETO verwendet, ein einsprachiges BERT-Modell, das auf Spanisch trainiert ist, und auch ein mehrsprachiges BERT-Modell.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_audio": "/acl6060/audio/dev/72.wav", "src_ref": "Both models we use them through the transformers library by HuggingFace.", "tgt_ref": "Beide Modelle verwenden wir über die Transformer-Bibliothek von HuggingFace.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_audio": "/acl6060/audio/dev/73.wav", "src_ref": "These are the results that we got.", "tgt_ref": "Das sind die Ergebnisse, die wir erhalten haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_audio": "/acl6060/audio/dev/74.wav", "src_ref": "As you can see, multilingual BERT performs better than BETO both on the development set and on the test set and across all metrics.", "tgt_ref": "Wie Sie sehen können, schneidet das mehrsprachige BERT sowohl im Entwicklungssatz als auch im Testsatz und bei allen Metriken besser ab als BETO.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_audio": "/acl6060/audio/dev/75.wav", "src_ref": "Just so we have ah an idea to compare, the CRF model obtained an eighty two.", "tgt_ref": "Das CRF-Modell hat 82 erreicht, nur damit wir einen Vergleich ziehen können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_audio": "/acl6060/audio/dev/76.wav", "src_ref": "The CRF model obtained a fifty five obtained a fifty five F1 score, whereas the multilingual BERT obtained eighty two, which is a big difference.", "tgt_ref": "Das CRF-Modell erreichte einen F1-Score von 55, während das mehrsprachige BERT 82 erreichte, was ein großer Unterschied ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_audio": "/acl6060/audio/dev/77.wav", "src_ref": "So, once that we had those results, we asked ourselves another question which is, could we find a BiLSTM-CRF model, feed it with different types of embeddings, embeddings that encode different types of linguistic information and perform outperform the results obtained by transformer based models?", "tgt_ref": "Nachdem wir also diese Ergebnisse hatten, stellten wir uns eine weitere Frage, nämlich: Können wir ein BiLSTM-CRF-Modell finden, verschiedene Arten von Einbettungen darin einspeisen, Einbettungen, die verschiedene Arten von sprachlichen Informationen kodieren, und die Ergebnisse von Transformer-basierten Modellen übertreffen?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_audio": "/acl6060/audio/dev/78.wav", "src_ref": "So in order to do so, we ran some preliminary experiments, we we run this by BiLSTM-CRF model using flare library.", "tgt_ref": "Dafür haben wir einige präliminäre Experimente durchgeführt, und zwar mit dem BiLSTM-CRF-Modell unter Verwendung von Flare Library.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_audio": "/acl6060/audio/dev/79.wav", "src_ref": "And we tried experimented with different type of embeddings like transformer-based but also fast-text, character embeddings, and so on.", "tgt_ref": "Wir haben mit verschiedenen Arten von Einbettungen experimentiert, z. B. mit Transformer-basierten, aber auch mit Schnell-Text-Einbettungen und Zeichen-Einbettungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_audio": "/acl6060/audio/dev/80.wav", "src_ref": "What we found out was that transformer-based embeddings performed better than non contextualized embeddings, that the combination of English BERT and Spanish BETO embeddings outperform multilingual BERT embeddings.", "tgt_ref": "Wir haben herausgefunden, dass Transformer-basierte Einbettungen besser abschneiden als nicht kontextualisierte Einbettungen, dass die Kombination aus englischer BERT- und spanischer BETO-Einbettung besser ist als mehrsprachige BERT-Einbettungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_audio": "/acl6060/audio/dev/81.wav", "src_ref": "And that BPE embeddings produced better F1 and character embeddings produce better recall.", "tgt_ref": "Auch ergeben die BPE-Einbettungen ein besseres F1 und die Zeicheneinbettungen ein besseres Recall.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_audio": "/acl6060/audio/dev/82.wav", "src_ref": "With that in mind, these were the best performing results that we got.", "tgt_ref": "Vor diesem Hintergrund waren dies die besten Ergebnisse, die wir erzielen konnten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_audio": "/acl6060/audio/dev/83.wav", "src_ref": "Both models were BiLSTM-CRF models using flare.", "tgt_ref": "Beide Modelle waren BiLSTM-CRF-Modelle unter Verwendung von Flare.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_audio": "/acl6060/audio/dev/84.wav", "src_ref": "One was fed with BETO and BERT embeddings and BPE, and the other one BETO and BERT embeddings and BPE and also character embeddings.", "tgt_ref": "Bei einem wurden BETO- und BERT-Einbettungen und BPE eingespeist, beim anderen BETO- und BERT-Einbettungen und BPE sowie Zeichen-Einbettungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_audio": "/acl6060/audio/dev/85.wav", "src_ref": "This last one was the one that produced the highest F1 score on the test set, although the highest score on the development set was obtained by the one without character embeddings.", "tgt_ref": "Letzteres war dasjenige, das den höchste F1-Score beim Testsatz erzielte, obwohl der höchste Score beim Entwicklungssatz durch das Modell ohne Zeichen-Einbettungen erreicht wurde.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_audio": "/acl6060/audio/dev/86.wav", "src_ref": "Just ah to bear in mind that the best result that we got with multilingual BERT obtained an F1 of seventy six on the development set and eighty two on the test set.", "tgt_ref": "Vergessen Sie nicht, dass das beste Ergebnis, das wir mit mehrsprachigem BERT erzielt haben, einen F1-Wert von 76 im Entwicklungssatz und 82 im Testsatz erreichte.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_audio": "/acl6060/audio/dev/87.wav", "src_ref": "So this is an improvement compared to those results.", "tgt_ref": "Dies ist also eine Verbesserung im Vergleich zu diesen Ergebnissen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_audio": "/acl6060/audio/dev/88.wav", "src_ref": "Finally, we asked ourselves another question which was can lexical borrowing detection be framed as transfer learning from language identification in code switching?", "tgt_ref": "Schließlich stellten wir uns noch eine weitere Frage: Kann die Erkennung von lexikalischen Entlehnungen als Transferlernen von Sprachidentifikation beim Code-Switching formuliert werden?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_audio": "/acl6060/audio/dev/89.wav", "src_ref": "So, we run the same BiLSTM-CRF model that we had run using flare, but instead of using these unadapted transformer-based BETO and BERT embeddings, we used code switch embeddings.", "tgt_ref": "Wir haben also dasselbe BiLSTM-CRF-Modell wie mit Flare verwendet, aber anstelle dieser nicht angepassten Transformer-basierten BETO- und BERT-Einbettungen haben wir Code-Switch-Einbettungen verwendet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_audio": "/acl6060/audio/dev/90.wav", "src_ref": "What are code switch embeddings?", "tgt_ref": "Was sind Code-Switch-Einbettungen?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_audio": "/acl6060/audio/dev/91.wav", "src_ref": "Well these are um embeddings that are have been fine tuned transformer-based embeddings that have been pretrained for language identification on the Spanish English section of the LinCE code switching dataset.", "tgt_ref": "Dies sind Einbettungen, die auf Transformer-basierte Einbettungen abgestimmt wurden. Diese wurden für die Sprachidentifikation im Spanisch-Englisch-Abschnitt des LinCE-Code-Switching-Datensatzes vortrainiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_audio": "/acl6060/audio/dev/92.wav", "src_ref": "LinCE is a dataset on code switching that has a section on Spanish English, Spanish English code switching.", "tgt_ref": "LinCE ist ein Datensatz vom Code-Switching, der einen Abschnitt mit Code-Switching von Spanisch und Englisch enthält.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_audio": "/acl6060/audio/dev/93.wav", "src_ref": "So we fed our BiLSTM-CRF with code switch embeddings and optionally character embeddings, BPE embeddings and so on.", "tgt_ref": "Wir speisten also Code-Switch-Einbettungen in unser BiLSTM-CRF ein. Optional können Zeicheneinbettungen, BPE-Einbettungen und so weiter eingefügt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_audio": "/acl6060/audio/dev/94.wav", "src_ref": "The best result that we got was eighty four point twenty two, which is the highest across all the models that we tried on the test set.", "tgt_ref": "Das beste Ergebnis, das wir erzielt haben, war 84,22. Das ist das beste Ergebnis aller Modelle, die wir mit dem Testsatz ausprobiert haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_audio": "/acl6060/audio/dev/95.wav", "src_ref": "Although the best result F1 score that we got on the development set, which was seventy nine, was lower than the best result obtained by the BiLSTM-CRF fed with unadapted embeddings.", "tgt_ref": "Obwohl der beste F1-Score, den wir beim Entwicklungssatz erzielt haben, 97 war, war dieser niedriger als das beste Ergebnis vom BiLSTM-CRF, das mit unangepassten Einbettungen eingespeist war.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_audio": "/acl6060/audio/dev/96.wav", "src_ref": "So, some conclusions from our work.", "tgt_ref": "Hier sind einige Schlussfolgerungen aus unserer Arbeit.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_audio": "/acl6060/audio/dev/97.wav", "src_ref": "We have ah we have produced a new dataset of Spanish newswire that is annotated with unassimilated lexical borrowings.", "tgt_ref": "Wir haben einen neuen Datensatz mit spanischen Nachrichten erstellt, der mit nicht assimilierten lexikalischen Entlehnungen annotiert ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_audio": "/acl6060/audio/dev/98.wav", "src_ref": "This dataset is more borrowing dense and OOV-rich than previous resources.", "tgt_ref": "Dieser Datensatz ist dichter an Entlehnungen und OOV-reicher als frühere Ressourcen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_audio": "/acl6060/audio/dev/99.wav", "src_ref": "We have explored four types of models for lexical borrowing detection.", "tgt_ref": "Wir haben vier Arten von Modellen für die Erkennung lexikalischer Entlehnungen erforscht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_audio": "/acl6060/audio/dev/100.wav", "src_ref": "Um. In terms of error analysis, well, recall was a weak point for all models.", "tgt_ref": "Also. Was die Fehleranalyse betrifft, war der Recall ein Schwachpunkt bei allen Modellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_audio": "/acl6060/audio/dev/101.wav", "src_ref": "Ah, as you can see here, some frequent false negatives include uppercase borrowings, words that exist in both English and Spanish, for instance.", "tgt_ref": "Wie Sie hier sehen können, gehören zu den häufigen falsch-negativen Ergebnissen beispielsweise auch Entlehnungen in Großbuchstaben und Wörter, die es sowohl im Englischen als auch im Spanischen gibt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_audio": "/acl6060/audio/dev/102.wav", "src_ref": "Also interestingly, BPE embeddings seem to improve F1 score.", "tgt_ref": "Interessant ist auch, dass BPE-Einbettungen den F1-Core zu verbessern scheinen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_audio": "/acl6060/audio/dev/103.wav", "src_ref": "And character embedding seem to improve recall.", "tgt_ref": "Und die Einbettung von Zeichen scheint den Recall zu verbessern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_audio": "/acl6060/audio/dev/104.wav", "src_ref": "Which ah it's an interesting finding that perhaps we can explore on future work.", "tgt_ref": "Das ist eine interessante Erkenntnis, die wir vielleicht in künftigen Arbeiten untersuchen können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_audio": "/acl6060/audio/dev/105.wav", "src_ref": "Um. Well, this is everything that I have.", "tgt_ref": "Also. Das wäre alles, was ich zu sagen habe.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_audio": "/acl6060/audio/dev/106.wav", "src_ref": "Thank you so much for listening.", "tgt_ref": "Vielen Dank fürs Zuhören.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_audio": "/acl6060/audio/dev/107.wav", "src_ref": "My name is Antoine.", "tgt_ref": "Mein Name ist Antoine.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_audio": "/acl6060/audio/dev/108.wav", "src_ref": "I'm a PhD student at the University of Massachusetts Amherst.", "tgt_ref": "Ich bin Doktorand an der University of Massachusetts Amherst.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_audio": "/acl6060/audio/dev/109.wav", "src_ref": "I am presenting our paper KinyaBERT: a Morphology-aware Kinyarwanda Language Model.", "tgt_ref": "Ich stelle unser Paper KinyaBERT vor: ein Morphologie-bewusstes Kinyarwanda-Sprachmodell.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_audio": "/acl6060/audio/dev/110.wav", "src_ref": "Today, I'll talk about the motivation for this research.", "tgt_ref": "Heute werde ich über den Grund für diese Forschung sprechen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_audio": "/acl6060/audio/dev/111.wav", "src_ref": "Then I'll present KinyaBERT model architecture in detail.", "tgt_ref": "Dann werde ich die KinyaBERT-Modell-Architektur im Detail vorstellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_audio": "/acl6060/audio/dev/112.wav", "src_ref": "I'll then talk about our experimental results, then finish with some conclusions.", "tgt_ref": "Ich werde dann über unsere experimentellen Ergebnisse sprechen und zum Schluss einige Schlussfolgerungen darstellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_audio": "/acl6060/audio/dev/113.wav", "src_ref": "We all know that recent natural language processing advances have been made possible by the use of pretrained language models such as BERT.", "tgt_ref": "Wir alle wissen, dass die jüngsten Fortschritte bei der NLP durch die Verwendung von vortrainierten Sprachmodellen wie BERT ermöglicht wurden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_audio": "/acl6060/audio/dev/114.wav", "src_ref": "However, there are still a number of limitations.", "tgt_ref": "Allerdings gibt es immer noch eine Reihe von Einschränkungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_audio": "/acl6060/audio/dev/115.wav", "src_ref": "Due to the complex morphology that is expressed by most morphologically rich languages, the ubiquitous byte pair encoding tokenization algorithm that I used cannot extract the exact subword lexical units, meaning the morphemes, which are needed for effective representation.", "tgt_ref": "Aufgrund der komplexen Morphologie, die von den meisten morphologisch reichen Sprachen ausgedrückt wird, kann der allgegenwärtige byte pair encoding-Tokenisierungsalgorithmus, den ich verwendet habe, nicht die genauen lexikalischen Unterwort-Einheiten extrahieren, d. h. die Morpheme, die für eine effektive Repräsentation benötigt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_audio": "/acl6060/audio/dev/116.wav", "src_ref": "For example, here we have three Kinyarwanda words that have several morphemes in them, but the BPE algorithms cannot extract them.", "tgt_ref": "Hier haben wir zum Beispiel drei Kinyarwanda-Wörter, die mehrere Morpheme enthalten, aber die BPE-Algorithmen können sie nicht extrahieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_audio": "/acl6060/audio/dev/117.wav", "src_ref": "This is because some morphological rules produce different surface forms that hide the exact lexical information, and BPE, which is solely based on the surface forms, does not have access to this lexical model.", "tgt_ref": "Das liegt daran, dass einige morphologische Regeln verschiedene Oberflächenformen erzeugen, die die genauen lexikalischen Informationen verbergen. BPE stützt sich aber nur auf die Oberflächenformen und hat so keinen Zugang zu diesem lexikalischen Modell.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_audio": "/acl6060/audio/dev/118.wav", "src_ref": "The second challenge is that even if one had access to an oracle morphological analyzer, replacing BPE tokens with morphemes is not enough to express the morphological compositionality.", "tgt_ref": "Die zweite Herausforderung besteht darin, dass, selbst wenn man Zugang zu einem morphologischen Analysator von Oracle hätte, würde es nicht ausreichen, das BPE-Token durch Morpheme zu ersetzen, um die morphologische Kompositionalität auszudrücken.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_audio": "/acl6060/audio/dev/119.wav", "src_ref": "A third gap in the research is that new pretrained language models are most often evaluated on high resource languages.", "tgt_ref": "Eine dritte Lücke in der Forschung besteht darin, dass neue vortrainierte Sprachmodelle meist bei ressourcenintensiven Sprachen evaluiert werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_audio": "/acl6060/audio/dev/120.wav", "src_ref": "And we need to assess their applicability on low resources and diverse languages as well.", "tgt_ref": "Wir müssen ihre Anwendbarkeit auch bei geringen Ressourcen und in verschiedenen Sprachen bewerten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_audio": "/acl6060/audio/dev/121.wav", "src_ref": "Therefore, we present KinyaBERT, which is a simple but effective adaptation of the BERT architecture that is meant to more effectively handle morphologically rich languages.", "tgt_ref": "Daher präsentieren wir KinyaBERT. Das ist eine einfache, aber effektive Anpassung der BERT-Architektur, die für den effektiveren Umgang mit morphologisch reichen Sprachen gedacht ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_audio": "/acl6060/audio/dev/122.wav", "src_ref": "We evaluate KinyaBERT on Kinyarwanda, a low resource morphologically rich language, which is spoken by more than twelve million people across Eastern and Central Africa.", "tgt_ref": "Wir evaluieren KinyaBERT mit Kinyarwanda, einer ressourcenarmen und morphologisch reichen Sprache, die von mehr als zwölf Millionen Menschen in Ost- und Zentralafrika gesprochen wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_audio": "/acl6060/audio/dev/123.wav", "src_ref": "The input to the model is either a sentence or a document.", "tgt_ref": "Die Eingabe für das Modell ist entweder ein Satz oder ein Dokument.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_audio": "/acl6060/audio/dev/124.wav", "src_ref": "For example here, we have John twarahamubonye biradutangaza, which means we were surprised to find John there.", "tgt_ref": "Zum Beispiel haben wir hier den Satz: „John twarahamubonye biradutangaza“. Das bedeutet: „Wir waren überrascht, John dort anzutreffen.“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_audio": "/acl6060/audio/dev/125.wav", "src_ref": "As you can see, Kinyarwanda words contains several morphemes that contain different information in them.", "tgt_ref": "Wie Sie sehen können, enthaltenWörter im Kinyarwanda mehrere Morpheme, die unterschiedliche Informationen enthalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_audio": "/acl6060/audio/dev/126.wav", "src_ref": "Therefore, in our model, we pass this sentence or a document to a morphological analyzer.", "tgt_ref": "Daher übergeben wir in unserem Modell diesen Satz oder ein Dokument an einen morphologischen Analysator.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_audio": "/acl6060/audio/dev/127.wav", "src_ref": "Which then generates morphemes contained in each of the words.", "tgt_ref": "Dieser erzeugt dann Morpheme, die in allen Wörtern enthalten sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_audio": "/acl6060/audio/dev/128.wav", "src_ref": "The morphemes usually are made of the stem and zero or more affixes.", "tgt_ref": "Die Morpheme setzen sich in der Regel aus dem Stamm und null oder mehr Affixen zusammen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_audio": "/acl6060/audio/dev/129.wav", "src_ref": "The affixes may indicate tense, aspect, subject or object in verbs, and more often relates to the Bantu noun class for subjects and objects.", "tgt_ref": "Die Affixe können Zeitform, Aspekt, Subjekt oder Objekt in den Verben anzeigen und beziehen sich häufiger auf die Substantivklasse der Bantu für Subjekte und Objekte.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_audio": "/acl6060/audio/dev/130.wav", "src_ref": "The morphological analyzer also produces a part of speech tag for each of the words.", "tgt_ref": "Der morphologische Analysator erzeugt auch einen Teil eines Sprach-Tags für jedes der Wörter.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_audio": "/acl6060/audio/dev/131.wav", "src_ref": "After this step, we make embeddings for the spee- for the part of speech tags.", "tgt_ref": "Nach diesem Schritt erstellen wir Einbettungen für den Teil der Sprach-Tags.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_audio": "/acl6060/audio/dev/132.wav", "src_ref": "Embeddings for the affixes.", "tgt_ref": "Einbettungen für die Affixe.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_audio": "/acl6060/audio/dev/133.wav", "src_ref": "And embeddings for the stem.", "tgt_ref": "Einbettungen für den Stamm.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_audio": "/acl6060/audio/dev/134.wav", "src_ref": "These are the morphology level, these are the morphology level embeddings.", "tgt_ref": "Dies sind die Einbettungen auf Morphologie-Ebene.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_audio": "/acl6060/audio/dev/135.wav", "src_ref": "We then pass these embeddings through a morphology encoder, which is a small transformer encoder that is applied to each word independently.", "tgt_ref": "Anschließend durchlaufen diese Einbettungen einen Morphologie-Encoder, der ein kleiner Transformer-Encoder ist, der auf jedes Wort unabhängig angewendet wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_audio": "/acl6060/audio/dev/136.wav", "src_ref": "The output of the are the vectors that are contextualized with the morphological information at each word.", "tgt_ref": "Ausgegeben werden die Vektoren, die mit den morphologischen Informationen bei jedem Wort kontextualisiert werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_audio": "/acl6060/audio/dev/137.wav", "src_ref": "Now, we perform composition where the morphological embeddings corresponding to part of speech and stem are concatenated together.", "tgt_ref": "Nun führen wir eine Komposition durch, bei der die morphologischen Einbettungen, die der Sprache und dem Wortstamm entsprechen, miteinander verkettet werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_audio": "/acl6060/audio/dev/138.wav", "src_ref": "We further concat we further concatenate them with another stem embedding at the sentence level.", "tgt_ref": "Wir verketten sie mit einer weiteren Einbettung des Stammes auf der Ebene des Satzes.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_audio": "/acl6060/audio/dev/139.wav", "src_ref": "Then we form an input to the main sentence or document encoder.", "tgt_ref": "Dann erstellen wir eine Eingabe für den Hauptsatz oder den Dokument-Encoder.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_audio": "/acl6060/audio/dev/140.wav", "src_ref": "The final output are contextualized embeddings that can be used for downstream NLP tasks.", "tgt_ref": "Die Endausgabe sind kontextualisierte Einbettungen, die für nachgelagerte NLP-Aufgaben verwendet werden können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_audio": "/acl6060/audio/dev/141.wav", "src_ref": "For a morphological analyzer, we use finite state two level morphology principles with custom implementation that is tailored to the Kinyarwanda language.", "tgt_ref": "Für einen morphologischen Analysator verwenden wir Morphologie-Prinzipien mit endlichen Automaten auf zwei Ebenen und mit einer maßgeschneiderten Implementierung, die auf die Sprache Kinyarwanda zugeschnitten ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_audio": "/acl6060/audio/dev/142.wav", "src_ref": "We effectively model the morphology of all Kinyarwanda words, including verbals, nouns, demonstrative and possessive pronouns, numerals, and others.", "tgt_ref": "Wir modellieren die Morphologie aller Wörter auf Kinyarwanda, einschließlich der Verben, Substantive, Demonstrativ- und Possessivpronomen, Numerale und andere.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_audio": "/acl6060/audio/dev/143.wav", "src_ref": "We use an unsupervised part of speech tagging algorithm.", "tgt_ref": "Wir verwenden einen nicht überwachten Teil eines Sprach-Tagging-Algorithmus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_audio": "/acl6060/audio/dev/144.wav", "src_ref": "A first order factored model is used to account for morphology probability, basically the probability that is assigned by the morphological analyzer.", "tgt_ref": "Ein faktorisiertes Modell erster Ordnung wird verwendet, um die Morphologie-Wahrscheinlichkeit zu berücksichtigen, d. h. die Wahrscheinlichkeit, die vom morphologischen Analysator zugewiesen wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_audio": "/acl6060/audio/dev/145.wav", "src_ref": "We also take into consideration the part of speech tag precedence as well as the syntactic agreements that are present in the in the input words.", "tgt_ref": "Wir berücksichtigen auch den Vorrang der Sprach-Tags sowie die syntaktischen Vereinbarungen, die in den eingegebenen Wörtern vorhanden sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_audio": "/acl6060/audio/dev/146.wav", "src_ref": "The part of speech tagger uses a bidi bidirectional inference which improves upon the more often used Viterbi algorithm for decoding.", "tgt_ref": "Der Teil des Sprach-Taggers verwendet eine bidirektionale Inferenz, die den häufiger verwendeten Viterbi-Algorithmus für die Dekodierung verbessert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_audio": "/acl6060/audio/dev/147.wav", "src_ref": "A few remarks here for positional encoding.", "tgt_ref": "Hier noch ein paar Anmerkungen zur Positionskodierung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_audio": "/acl6060/audio/dev/148.wav", "src_ref": "One, the morphology encoder does not use any positional encoding.", "tgt_ref": "Erstens verwendet der Morphologie-Encoder keine Positionskodierung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_audio": "/acl6060/audio/dev/149.wav", "src_ref": "This is because each of the morphemes occupies a known slot in the morphological model.", "tgt_ref": "Das liegt daran, dass jedes der Morpheme einen bekannten Platz im morphologischen Modell einnimmt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_audio": "/acl6060/audio/dev/150.wav", "src_ref": "Therefore, positional information is inherent when the morphemes are given.", "tgt_ref": "Daher ist die positionelle Information inhärent, wenn die Morpheme gegeben sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_audio": "/acl6060/audio/dev/151.wav", "src_ref": "Second, the sentence encoder uses the so-called untied relative positional embeddings, which have been recently published at ICLR conference.", "tgt_ref": "Zweitens verwendet der Satz-Encoder die so genannten ungebundenen, relativ positionellen Einbettungen, die kürzlich auf der ICLR-Konferenz veröffentlicht wurden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_audio": "/acl6060/audio/dev/152.wav", "src_ref": "This positional embeddings essentially disentangles positional correlations from token to token attention computation.", "tgt_ref": "Diese positionellen Einbettungen entkoppeln im Wesentlichen positionelle Korrelationen von Token hin zu einer Token-Aufmerksamkeitsberechnung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_audio": "/acl6060/audio/dev/153.wav", "src_ref": "Similar to BERT, we use a masked language model pre-training objective.", "tgt_ref": "Ähnlich wie BERT verwenden wir ein maskiertes Sprachmodell als Vortrainingsziel.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_audio": "/acl6060/audio/dev/154.wav", "src_ref": "Essentially we have to predict both the stem and the affixes that are associated with the words.", "tgt_ref": "Im Wesentlichen müssen wir sowohl den Stamm als auch die Affixe, aus denen die Wörter bestehen, vorhersagen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_audio": "/acl6060/audio/dev/155.wav", "src_ref": "During pre-training, fifteen percent of all words are considered for prediction, of which eighty percent are masked, ten percent are swapped with random words, and ten percent are left unchanged.", "tgt_ref": "Während des Vortrainings werden fünfzehn Prozent aller Wörter für die Vorhersage berücksichtigt, von denen achtzig Prozent maskiert, zehn Prozent mit zufälligen Wörtern ausgetauscht und zehn Prozent unverändert gelassen werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_audio": "/acl6060/audio/dev/156.wav", "src_ref": "For affix prediction, we face some multi label classification problem.", "tgt_ref": "Für die Vorhersage der Affixe stehen wir vor einem Multi-Label-Klassifikationsproblem.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_audio": "/acl6060/audio/dev/157.wav", "src_ref": "For this, we either group together affixes into a fixed number of sets and predict the set as a class label.", "tgt_ref": "Daher fassen wir entweder die Affixe zu einer festen Reihe von Gruppen zusammen und sagen die Gruppe als Klassenlabel voraus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_audio": "/acl6060/audio/dev/158.wav", "src_ref": "The other option is to predict the affix probability vector.", "tgt_ref": "Die andere Möglichkeit ist die Vorhersage der Affixe durch einen Wahrscheinlichkeitsvektor.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_audio": "/acl6060/audio/dev/159.wav", "src_ref": "We evaluate both of these approaches in our experiments.", "tgt_ref": "Wir bewerten beide Ansätze in unseren Experimenten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_audio": "/acl6060/audio/dev/160.wav", "src_ref": "We pre-train KinyaBERT on about two and half gigabytes of Kinyarwanda text, and compare it to three baseline models.", "tgt_ref": "Wir trainieren KinyaBERT mit etwa zweieinhalb Gigabyte an Text in Kinyarwanda vor und vergleichen es mit drei Modellen der Baseline.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_audio": "/acl6060/audio/dev/161.wav", "src_ref": "One is a multilingual model called XLM-R, that is trained on a large text corpora that is made of multiple languages.", "tgt_ref": "Eines davon ist ein mehrsprachiges Modell namens XLM-R, das mit großen Textkorpora trainiert wird, die aus mehreren Sprachen bestehen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_audio": "/acl6060/audio/dev/162.wav", "src_ref": "The other two baselines are pretrained on the same Kinyarwanda text using either the byte pair encoding algorithm or using morphological analysis without using the two tier transformer encoder architecture.", "tgt_ref": "Die beiden anderen Baselines werden mit demselben Text auf Kinyarwanda vortrainiert, wobei entweder der byte pair encoding-Algorithmus oder die morphologische Analyse ohne die zweistufige Transformer-Encoder-Architektur verwendet wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_audio": "/acl6060/audio/dev/163.wav", "src_ref": "All models are configured in the base architecture, which is about between a hundred and a hundred and ten million parameters, with Kinyarwanda with KinyaBERT using the least number of parameters.", "tgt_ref": "Alle Modelle sind in der Basisarchitektur konfiguriert, die etwa hundert bis hundertzehn Millionen Parameter umfasst, wobei Kinyarwanda mit KinyaBERT die geringste Anzahl von Parametern verwendet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_audio": "/acl6060/audio/dev/164.wav", "src_ref": "All models except the multilingual are pretrained for thirty two thousand gradient updates with a batch size of two thousand five hundred and sixty sequences in each batch.", "tgt_ref": "Alle außer dem mehrsprachigen Modell werden für zweiunddreißigtausend Gradient-Updates vortrainiert, mit einer Batchgröße von zweitausendfünfhundertsechzig Sequenzen in jedem Batch.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_audio": "/acl6060/audio/dev/165.wav", "src_ref": "We evaluate the pretrained models on three sets of tasks.", "tgt_ref": "Wir bewerten die vortrainierten Modelle anhand von drei Gruppen von Aufgaben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_audio": "/acl6060/audio/dev/166.wav", "src_ref": "One is the GLUE benchmark which has often been used for evaluating the effectiveness of pretrained language models.", "tgt_ref": "Eine davon ist die GLUE-Benchmark, die häufig zur Bewertung der Effektivität von vortrainierten Sprachmodellen verwendet wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_audio": "/acl6060/audio/dev/167.wav", "src_ref": "We obtain our GLUE benchmark data by translating the original benchmark data into Kinyarwanda using Google Translate.", "tgt_ref": "Wir erhalten unsere GLUE-Benchmark-Daten, indem wir die originalen Benchmark-Daten mit Google Translate ins Kinyarwanda übersetzen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_audio": "/acl6060/audio/dev/168.wav", "src_ref": "The second task is Kinyarwanda named entity recognition benchmark, which is a high quality dataset that was annotated by trained native speakers.", "tgt_ref": "Die zweite Aufgabe ist die named entity recognition-Benchmark von Kinyarwanda, ein qualitativ hochwertiger Datensatz, der von trainierten Muttersprachlern annotiert wurde.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_audio": "/acl6060/audio/dev/169.wav", "src_ref": "The third one is a news categorization task where we pull news articles from several websites and collecting their categorization tags that were assigned by the authors and then essentially trying to predict the same, the the same categories.", "tgt_ref": "Bei der dritten Aufgabe handelt es sich um eine Kategorisierung von Nachrichten. Hier rufen wir Nachrichtenartikel von verschiedenen Websites ab und sammeln ihre Kategorisierungstags, die von den Autoren zugewiesen wurden. Im Wesentlichen versuchen wir, die gleichen Kategorien vorherzusagen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_audio": "/acl6060/audio/dev/170.wav", "src_ref": "And now we go to the results.", "tgt_ref": "Sehen wir uns jetzt die Ergebnisse an.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_audio": "/acl6060/audio/dev/171.wav", "src_ref": "For the GLUE benchmark, we find that KinyaBERT consistently outperforms baseline models.", "tgt_ref": "Bei der GLUE-Benchmark haben wir festgestellt, dass KinyaBERT durchweg besser abschneidet als die Baseline-Modelle.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_audio": "/acl6060/audio/dev/172.wav", "src_ref": "Here we show the average performance for ten finetuning runs.", "tgt_ref": "Hier zeigen wir die durchschnittliche Leistung von zehn Durchläufen zur Feinabstimmung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_audio": "/acl6060/audio/dev/173.wav", "src_ref": "We also run a user evaluation of the translations that are produced by Google Translate.", "tgt_ref": "Wir führen auch eine Benutzerevaluation der Übersetzungen durch, die von Google Translate erstellt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_audio": "/acl6060/audio/dev/174.wav", "src_ref": "Essentially, user users rated about six thousand examples, assigning scores on a scale from one to four, assessing the quality of the translations.", "tgt_ref": "Im Wesentlichen bewerteten die Benutzer etwa sechstausend Beispiele und vergaben Noten auf einer Skala von eins bis vier, um die Qualität der Übersetzungen zu bewerten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_audio": "/acl6060/audio/dev/175.wav", "src_ref": "The result is that many translations were noisy.", "tgt_ref": "Das Ergebnis war, dass viele Übersetzungen qualitativ schlecht waren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_audio": "/acl6060/audio/dev/176.wav", "src_ref": "But, all models had to cope with the same translation noise, and the relative performance between the models is still important to notice.", "tgt_ref": "Aber alle Modelle mussten mit der gleichen schlechten Qualität der Übersetzung umgehen, und die relative Leistung zwischen den Modellen kann immer noch bedeutend festgestellt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_audio": "/acl6060/audio/dev/177.wav", "src_ref": "For the named entity recognition task, we also find that KinyaBERT gives the best performance with the affix distribution regression variant performing best.", "tgt_ref": "Bei der Aufgabe Named Entity Recognition stellten wir außerdem fest, dass KinyaBERT die beste Leistung erbringt, wobei die Variante mit der Verteilungsregression der Affixe am besten abschneidet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_audio": "/acl6060/audio/dev/178.wav", "src_ref": "These results are also averages of ten finetuning runs.", "tgt_ref": "Diese Ergebnisse sind auch Mittelwerte von zehn Durchläufen zur Feinabstimmung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_audio": "/acl6060/audio/dev/179.wav", "src_ref": "For the news categorization task, we find mixed results.", "tgt_ref": "Bei der Aufgabe zur Kategorisierung der Nachrichten bekamen wir gemischte Ergebnisse.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_audio": "/acl6060/audio/dev/180.wav", "src_ref": "Previous work on text classification for Kinyarwanda had found that simple keyword detection is mostly enough for solving this specific task.", "tgt_ref": "Frühere Arbeiten zur Textklassifizierung für Kinyarwanda hatten herausgefunden, dass eine einfache Schlüsselworterkennung meistens ausreicht, um diese spezifische Aufgabe zu lösen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_audio": "/acl6060/audio/dev/181.wav", "src_ref": "Therefore, there is less gain from using pretrained language models.", "tgt_ref": "Daher ist die Verwendung von vortrainierten Sprachmodellen weniger erfolgsversprechend.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_audio": "/acl6060/audio/dev/182.wav", "src_ref": "On this particular task of news categorization.", "tgt_ref": "Jetzt zu dieser besonderen Aufgabe der Kategorisierung von Nachrichten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_audio": "/acl6060/audio/dev/183.wav", "src_ref": "We also conducted an ablation study to see if there are alternative structures that improve performance.", "tgt_ref": "Wir haben auch eine Ablationsstudie durchgeführt, um zu sehen, ob es alternative Strukturen gibt, die die Leistung verbessern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_audio": "/acl6060/audio/dev/184.wav", "src_ref": "For the GLUE benchmark, we find that using affix sets consistently performs better, while affix probability regression objective yields the best performance on named entity recognition.", "tgt_ref": "Bei der GLUE-Benchmark haben wir festgestellt, dass die Verwendung von Affix-Sätzen durchweg besser abschneidet, während das Ziel der Affix-Wahrscheinlichkeitsregression die beste Leistung bei der Named Entity Recognition erbringt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_audio": "/acl6060/audio/dev/185.wav", "src_ref": "Also by looking at the low scores for finetuning, we find that KinyaBERT has better convergence in most cases.", "tgt_ref": "Auch wenn man die niedrigen Werte bei der Feinabstimmung betrachtet, stellt man fest, dass KinyaBERT in den meisten Fällen eine bessere Konvergenz aufweist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_audio": "/acl6060/audio/dev/186.wav", "src_ref": "So to conclude, this work has demonstrated the effectiveness of explicitly using morphological information in pretrained language models.", "tgt_ref": "Abschließend lässt sich sagen, dass diese Arbeit die Effektivität der expliziten Verwendung von morphologischen Informationen in vortrainierten Sprachmodellen bewiesen hat.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_audio": "/acl6060/audio/dev/187.wav", "src_ref": "The proposed two tier transformer encoder architecture enables capturing morphological complexity morphological compositionality, which is an important aspect of morphologically rich languages.", "tgt_ref": "Die vorgeschlagene zweistufige Transformer-Encoder-Architektur ermöglicht die Erfassung von morphologischer Komplexität und morphologischer Kompositionalität, die ein wichtiger Aspekt von morphologisch reichen Sprachen ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_audio": "/acl6060/audio/dev/188.wav", "src_ref": "These findings should motivate further research into morphology aware language pretrained language models.", "tgt_ref": "Diese Ergebnisse sollten zu weiteren Forschungen über morphologie-bewusste, vortrainierte Sprachmodelle motivieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_audio": "/acl6060/audio/dev/189.wav", "src_ref": "Hello, my name is Michał Pietruszka and it is my pleasure to present to you the paper titled Sparsifying Transformer Models with Trainable Representation Pooling.", "tgt_ref": "Hallo, mein Name ist Michał Pietruszka und es ist mir eine Freude, Ihnen das Paper mit dem Titel Sparsifying Transformer Models with Trainable Representation Pooling vorzustellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_audio": "/acl6060/audio/dev/190.wav", "src_ref": "A work done at Applica AI in cooperation with Lukasz Borchmann and Lukasz Garncarek.", "tgt_ref": "Die Arbeit wurde bei Applica KI in Zusammenarbeit mit Lukasz Borchmann und Lukasz Garncarek durchgeführt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_audio": "/acl6060/audio/dev/191.wav", "src_ref": "Let me start with the problems our work targets.", "tgt_ref": "Lassen Sie mich mit den Problemen beginnen, die in unserer Arbeit abgehandelt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_audio": "/acl6060/audio/dev/192.wav", "src_ref": "Our method works well for the cases where long inputs are considered.", "tgt_ref": "Unsere Methode funktioniert gut für die Fälle, in denen lange Eingaben berücksichtigt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_audio": "/acl6060/audio/dev/193.wav", "src_ref": "Roughly speaking, it is meant for the task orders and input of over two thousand tokens and the targets are shorter than the provided inputs.", "tgt_ref": "Grob gesagt ist sie für Aufgaben und Eingaben von über zweitausend Token gedacht, wo die Zieltexte kürzer als die vorgegebenen Eingaben sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_audio": "/acl6060/audio/dev/194.wav", "src_ref": "This has some specific applications in NLP.", "tgt_ref": "Dies führt zu einigen spezifischen Anwendungen in der NLP.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_audio": "/acl6060/audio/dev/195.wav", "src_ref": "For example, one can imagine that given a long document, there's a need to summarize it, classify, answer the question about it, extract information or some key phrases.", "tgt_ref": "Man kann sich zum Beispiel vorstellen, dass ein langes Dokument zusammengefasst, klassifiziert und eine Frage darüber beantwortet werden muss und Informationen oder einige Schlüsselsätze extrahiert werden müssen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_audio": "/acl6060/audio/dev/196.wav", "src_ref": "Let me recall the vanilla transformer and our and its issue of its attention complexity that depends on the square of the input line.", "tgt_ref": "Erinnern wir uns an den Vanilla-Transformer und sein Problem mit der Aufmerksamkeitskomplexität, die vom Quadrat der Eingabezeile abhängt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_audio": "/acl6060/audio/dev/197.wav", "src_ref": "In the vanilla transformer, with full attention connectivity, relations of each token to every other token have to be calculated.", "tgt_ref": "Im Vanilla-Transformer müssen bei voller Aufmerksamkeitskonnektivität die Relationen jedes Token zu jedem anderen Token berechnet werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_audio": "/acl6060/audio/dev/198.wav", "src_ref": "The computational complexity of attention, this depends on the number of layers l, sequence length n, another sequence length, and the dimensionality of representations.", "tgt_ref": "Die rechnerische Komplexität der Aufmerksamkeit hängt von der Reihe der Schichten l, der Sequenzlänge n, einer weiteren Sequenzlänge und der Dimensionalität der Repräsentationen ab.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_audio": "/acl6060/audio/dev/199.wav", "src_ref": "Similarly, in the decoder's cross attention, to this picture on the right side, the only difference here is that the target tokens are attending to the input tokens in this case.", "tgt_ref": "Ähnlich verhält es sich mit der Cross-Attention des Decoders zu diesem Bild auf der rechten Seite, wobei der einzige Unterschied darin besteht, dass die Ziel-Token in diesem Fall auf die Eingabe-Token gerichtet sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_audio": "/acl6060/audio/dev/200.wav", "src_ref": "Which can be seen also in this formula.", "tgt_ref": "Das sieht man in dieser Formel.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_audio": "/acl6060/audio/dev/201.wav", "src_ref": "The BLEU score represents relations that have to be calculated.", "tgt_ref": "Der BLEU-Score stellt Relationen dar, die berechnet werden müssen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_audio": "/acl6060/audio/dev/202.wav", "src_ref": "In case of the full attention, we need to calculate every relations within the input sequence.", "tgt_ref": "Im Falle der vollständigen Aufmerksamkeit müssen wir jede Relation innerhalb der Eingabe-Sequenz berechnen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_audio": "/acl6060/audio/dev/203.wav", "src_ref": "Now, we see what happens when we have a blockwise encoder that works by limiting the tokens connectivity so that they can only see other nearby tokens.", "tgt_ref": "Jetzt sehen wir, was passiert, wenn wir einen blockweisen Encoder haben, der die Konnektivität der Token so einschränkt, dass sie nur andere Token in der Nähe sehen können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_audio": "/acl6060/audio/dev/204.wav", "src_ref": "The text is read in chunks which can drastically reduce the number of computations on the encoder side, but does not improve the decoder's cross attention as every input token is passed to the decoder anyway.", "tgt_ref": "Der Text wird in Blöcken gelesen, was die Reihe der Berechnungen auf der Encoder-Seite drastisch reduzieren kann. Aber die Cross-Attention des Decoders wird so nicht verbessert, da jedes Eingabe-Token ohnehin an den Decoder weitergegeben wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_audio": "/acl6060/audio/dev/205.wav", "src_ref": "This method is often referred to as fusion in decoder.", "tgt_ref": "Diese Methode wird oft als Fusion im Decoder bezeichnet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_audio": "/acl6060/audio/dev/206.wav", "src_ref": "The improvement here can be interpreted as changing one of the dependencies of n to another constant m representing the block size.", "tgt_ref": "Die Verbesserung hier kann so interpretiert werden, dass eine der Abhängigkeiten von n durch eine andere Konstante m ersetzt wird, die die Blockgröße darstellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_audio": "/acl6060/audio/dev/207.wav", "src_ref": "Our key observation is that most tokens are irrelevant for a wide variety of tasks and can be almost completely disregarded. This is exemplified on the slide.", "tgt_ref": "Unsere wichtigste Beobachtung ist, dass die meisten Token für eine Vielzahl von Aufgaben irrelevant sind und fast vollständig vernachlässigt werden können. Dies ist beispielhaft auf der Folie dargestellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_audio": "/acl6060/audio/dev/208.wav", "src_ref": "The only parts of the inputs are relevant to the desired output.", "tgt_ref": "Nur ein Teil der Eingaben ist für die gewünschte Ausgabe relevant.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_audio": "/acl6060/audio/dev/209.wav", "src_ref": "For example.", "tgt_ref": "Zum Beispiel.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_audio": "/acl6060/audio/dev/210.wav", "src_ref": "One can read an article once marking the most important parts with a highlighter, and then produce a summary based on this part from the middle stage only.", "tgt_ref": "Man kann einen Artikel einmal lesen, die wichtigsten Teile mit einem Textmarker markieren und dann eine Zusammenfassung erstellen, die nur auf diesem Teil aus der mittleren Phase basiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_audio": "/acl6060/audio/dev/211.wav", "src_ref": "The cost of highlighting and deciding if the current token is essential to produce the summary is thus cheap and depends only on the token's representation.", "tgt_ref": "Die Kosten für die Hervorhebung und die Entscheidung, ob das aktuelle Token für die Erstellung der Zusammenfassung wesentlich ist, sind somit gering und hängen nur von der Repräsentation des Token ab.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_audio": "/acl6060/audio/dev/212.wav", "src_ref": "The pooling of the highlighted tokens is possible.", "tgt_ref": "Das Pooling der hervorgehobenen Token ist möglich.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_audio": "/acl6060/audio/dev/213.wav", "src_ref": "Thanks to our top k operator and its cost is negligible.", "tgt_ref": "Das ist unserem Top-k-Operator zu verdanken und die Kosten sind vernachlässigbar.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_audio": "/acl6060/audio/dev/214.wav", "src_ref": "The cost of producing a summary from a shortened input is also much lower than in the vanilla model when the whole input is considered.", "tgt_ref": "Die Kosten für die Erstellung einer Zusammenfassung aus einer gekürzten Eingabe sind ebenfalls viel niedriger als beim Vanilla-Modell, wenn die gesamte Eingabe berücksichtigt wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_audio": "/acl6060/audio/dev/215.wav", "src_ref": "But here's a question.", "tgt_ref": "Aber hier stellt sich eine Frage.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_audio": "/acl6060/audio/dev/216.wav", "src_ref": "How to select important tokens and backpropagate gradients to that selection?", "tgt_ref": "Wie kann man wichtige Token auswählen und Gradienten zu dieser Auswahl zurückverfolgen?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_audio": "/acl6060/audio/dev/217.wav", "src_ref": "The essential underlying problem that we solve is to propose the trainable selection mechanism.", "tgt_ref": "Das zugrundeliegende wesentliche Problem, das wir lösen, besteht darin, einen trainierbaren Auswahlmechanismus vorzuschlagen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_audio": "/acl6060/audio/dev/218.wav", "src_ref": "One that can allow for gradient to be back propagated during the training so that the network can learn to select the most important tokens.", "tgt_ref": "Dieser ermöglicht es, dass der Gradient während des Trainings rückverfolgt werden kann, sodass das Netzwerk lernen kann, die wichtigsten Token auszuwählen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_audio": "/acl6060/audio/dev/219.wav", "src_ref": "More precisely", "tgt_ref": "Präziser ausgedrückt:", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_audio": "/acl6060/audio/dev/220.wav", "src_ref": "Given some embeddings underscore obtained from a simple linear layer, the task is to return the highest scoring embeddings. First, the sequence is permuted and pairs are prepared so that the higher scoring vector is taken with the lower scoring one.", "tgt_ref": "Angesichts einiger Unterwert-Einbettungen, die aus einer einfachen linearen Schicht stammen, besteht die Aufgabe darin, die Einbettungen mit dem höchsten Score zu ermitteln. Zunächst wird die Sequenz permutiert, und es werden Paare gebildet, sodass der höher bewertete Vektor mit dem niedriger bewerteten zusammengebracht wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_audio": "/acl6060/audio/dev/221.wav", "src_ref": "Next, weights are calculated using boosted softmax over scores.", "tgt_ref": "Anschließend werden die Gewichtungen mithilfe von einer verstärkten Softmax über die Scores berechnet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_audio": "/acl6060/audio/dev/222.wav", "src_ref": "After each tournament round, new vectors and scores are composed as a linear combination of those pairs with the obtained weights.", "tgt_ref": "Nach jeder Turnierrunde werden neue Vektoren und Scores als lineare Kombination dieser Paare mit den erhaltenen Gewichtungen zusammengestellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_audio": "/acl6060/audio/dev/223.wav", "src_ref": "So in short, we combine them linearly by performing a softmax over their scores.", "tgt_ref": "Kurz gesagt kombinieren wir sie linear, indem wir eine Softmax über ihre Scores durchführen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_audio": "/acl6060/audio/dev/224.wav", "src_ref": "And while combining two tokens, some noise can be produces produced.", "tgt_ref": "Während man zwei Token kombiniert, kann auch schlechte Qualität erzeugt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_audio": "/acl6060/audio/dev/225.wav", "src_ref": "But it also allows the gradients to be propagated to all input embeddings.", "tgt_ref": "Aber auch die Übertragung der Gradienten auf alle eingegebenen Einbettungen wird ermöglicht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_audio": "/acl6060/audio/dev/226.wav", "src_ref": "In short, a trainable top k we propose is based on performing a tournament like soft selection at each step.", "tgt_ref": "Kurz gesagt wollen wir ein trainierbares Top-k vorschlagen, das eine turnierähnliche Soft-Selection bei jedem Schritt ausführt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_audio": "/acl6060/audio/dev/227.wav", "src_ref": "And from a different perspective, the representation pooling follows the encoder layer.", "tgt_ref": "Aus einem anderen Blickwinkel betrachtet, folgt das Repräsentationspooling auf die Encoder-Schicht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_audio": "/acl6060/audio/dev/228.wav", "src_ref": "First, each representation is scored and then only those with the highest scores are passed to the next layer.", "tgt_ref": "Zunächst wird jede Repräsentation bewertet. Dann werden nur jene mit den höchsten Scores an die nächste Ebene weitergegeben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_audio": "/acl6060/audio/dev/229.wav", "src_ref": "Encoding can be performed as in standard transformer architecture on the full length input.", "tgt_ref": "Die Kodierung kann wie in der Standard-Transformer-Architektur auf die volle Länge der Eingabe durchgeführt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_audio": "/acl6060/audio/dev/230.wav", "src_ref": "It is however possible to process text in blocks of fixed length of fixed length and globally select the best representation.", "tgt_ref": "Es ist jedoch möglich, Text in Blöcken mit fester Länge zu verarbeiten und global die beste Repräsentation zu wählen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_audio": "/acl6060/audio/dev/231.wav", "src_ref": "Here is an example of the representation pooling introduced after the encoder.", "tgt_ref": "Hier ist ein Beispiel für das nach dem Encoder eingeführte Repräsentationspooling.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_audio": "/acl6060/audio/dev/232.wav", "src_ref": "This directly influenced the cause of cross attention, which depends not on the input length N, but the constant K, representing the pooled length.", "tgt_ref": "Dies hatte einen direkten Einfluss auf die Ursache der Cross-Attention. Diese hängt nicht von der Länge der Eingabe N ab, sondern von der Konstante K, welche die gepoolte Länge darstellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_audio": "/acl6060/audio/dev/233.wav", "src_ref": "This constant informs how many representations are selected and passed to the decoder.", "tgt_ref": "Diese Konstante gibt an, wie viele Repräsentationen ausgewählt und an den Decoder übergeben werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_audio": "/acl6060/audio/dev/234.wav", "src_ref": "Producing a summary from a shorter text is significantly cheaper than previous solution.", "tgt_ref": "Die Erstellung einer Zusammenfassung aus einem kürzeren Text ist wesentlich billiger als die frühere Lösung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_audio": "/acl6060/audio/dev/235.wav", "src_ref": "As the sequence length can be shortened by a large factor.", "tgt_ref": "Die Sequenzlänge kann um einen großen Faktor verkürzt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_audio": "/acl6060/audio/dev/236.wav", "src_ref": "For example, we successfully used k of sixteen or even sixty times four or even sixty four times smaller than the value of n in our experiments.", "tgt_ref": "Wir haben beispielsweise in unseren Experimenten k erfolgreich sechzehnmal oder sogar vierundsechzigmal kleiner als den Wert von n verwendet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_audio": "/acl6060/audio/dev/237.wav", "src_ref": "Please note that the beneficial impact of blockwise encoding and self attention is sustained.", "tgt_ref": "Bitte beachten Sie, dass die positive Wirkung von blockweiser Kodierung und selbständiger Aufmerksamkeit anhaltend ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_audio": "/acl6060/audio/dev/238.wav", "src_ref": "Remember that the computational cost of attention depend on the square of the input length.", "tgt_ref": "Vergessen Sie nicht, dass die Rechenkosten der Aufmerksamkeit vom Quadrat der eingegebenen Länge abhängen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_audio": "/acl6060/audio/dev/239.wav", "src_ref": "Reducing it the input earlier during the encoding process can significantly lower the costs.", "tgt_ref": "Die Reduzierung der Eingabe zu einem früheren Zeitpunkt während des Kodierungsprozesses kann die Kosten erheblich senken.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_audio": "/acl6060/audio/dev/240.wav", "src_ref": "For the pyramidion model, we narrowed down the size of the representation on the output of each of each chosen layer, leading to the exponential reduction of computational cost as the encoding proceeds.", "tgt_ref": "Für das Pyramidion-Modell haben wir die Größe der Repräsentation bei der Ausgabe jeder ausgewählten Schicht eingegrenzt, was zu einer exponentiellen Verringerung der Rechenkosten führt, wenn die Kodierung fortschreitet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_audio": "/acl6060/audio/dev/241.wav", "src_ref": "As you can see, the total computational cost of a full encoder here is less than two times the cost of the full-sized first layer.", "tgt_ref": "Wie Sie sehen können, sind die gesamten Rechenkosten eines vollständigen Encoders hier weniger als doppelt so hoch als die Kosten der ersten Schicht in voller Größe.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_audio": "/acl6060/audio/dev/242.wav", "src_ref": "When pooling is introduced earlier, the sum of all purple squares is thus bounded to a constant, not dependent on the number of layers l.", "tgt_ref": "Wenn das Pooling früher eingeführt wird, wird die Summe aller lila Quadrate auf eine Konstante begrenzt, die nicht von der Anzahl der Schichten abhängt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_audio": "/acl6060/audio/dev/243.wav", "src_ref": "But on the constant c, which can be influenced by the placing of the pooling layers within the network.", "tgt_ref": "Die Konstante c kann durch die Anordnung der Pooling-Schichten innerhalb des Netzwerks beeinflusst werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_audio": "/acl6060/audio/dev/244.wav", "src_ref": "Our improvements were benchmarked on eight thousand tokens long inputs.", "tgt_ref": "Unsere Verbesserungen wurden mit Eingaben in der Länge von achttausend Token verglichen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_audio": "/acl6060/audio/dev/245.wav", "src_ref": "And the figure shows that when pooling is engaged, the best scalability for the network's depth is achieved.", "tgt_ref": "Die Abbildung zeigt, dass die beste Skalierbarkeit für die Tiefe des Netzwerks erreicht wird, wenn das Pooling aktiviert ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_audio": "/acl6060/audio/dev/246.wav", "src_ref": "Here one can note that training the pyramidion of twenty four layers can be cheaper than training a two layer vanilla transformer on such long inputs.", "tgt_ref": "Hier kann man feststellen, dass bei solchen langen Eingaben das Training des Pyramidions mit 24 Schichten billiger sein kann als das Training eines zweischichtigen Vanilla-Transformers.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_audio": "/acl6060/audio/dev/247.wav", "src_ref": "Not to mention how easily vanilla transformer can go out of memory for such a long input.", "tgt_ref": "Ganz zu schweigen davon, wie schnell ein Vanilla-Transformer bei einer so langen Eingabe ungenügend Speicher haben kann.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_audio": "/acl6060/audio/dev/248.wav", "src_ref": "The qual quality qual qualitative comparison of our trend pyramidion to other baseline is performed on the long document summarization task, or given the body of an article from arXiv or PubMed, the task is to generate its abstract.", "tgt_ref": "Der qualitative Vergleich unseres Trend-Pyramidions mit anderen Baselines wird anhand der langen Aufgabe mit der Zusammenfassung des Dokuments durchgeführt. Alternativ kann der Hauptteil eines Artikels von arXiv oder PubMed herangezogen werden, wo die Aufgabe darin besteht, eine Zusammenfassung zu erstellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_audio": "/acl6060/audio/dev/249.wav", "src_ref": "Thus, one can see blockwise, which is our baseline, performs on the level of the re, recent state-of-the-art models, while the pyramidion retains or improves the performance of this competitive baseline.", "tgt_ref": "Man kann also sehen, dass der blockweise Ansatz, der unsere Baseline darstellt, auf modernsten Modellen basiert, während das Pyramidion die Leistung dieser konkurrenzfähigen Baseline beibehält oder verbessert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_audio": "/acl6060/audio/dev/250.wav", "src_ref": "At the same time, our model is eighty percent faster to train and over four hundred fifty percent faster at inference when compared to the blockwise baseline.", "tgt_ref": "Gleichzeitig ist unser Modell zu achtzig Prozent schneller zu trainieren und zu über vierhundertfünfzig Prozent schneller bei der Inferenz im Vergleich zur blockweisen Baseline.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_audio": "/acl6060/audio/dev/251.wav", "src_ref": "Both models have much lower parameter counts and were trained from scratch on the chosen tasks.", "tgt_ref": "Beide Modelle haben viel weniger Parameter und wurden von Grund auf für die ausgewählten Aufgaben trainiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_audio": "/acl6060/audio/dev/252.wav", "src_ref": "Previous approaches to to achieve a similar performance had to use more parameters and leverage pretrained foundation foundational models and additional language pretraining objective to achieve similar performance.", "tgt_ref": "Frühere Ansätze zur Erzielung einer ähnlichen Leistung mussten mehr Parameter verwenden sowie vortrainierte grundlegende Modelle und zusätzliche Vortrainingsziele bei der Sprache nutzen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_audio": "/acl6060/audio/dev/253.wav", "src_ref": "We invite you to read our full paper and use our GitHub code.", "tgt_ref": "Wir laden Sie ein, unser vollständiges Paper zu lesen und unseren GitHub-Code zu verwenden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_audio": "/acl6060/audio/dev/254.wav", "src_ref": "Thank you for watching.", "tgt_ref": "Vielen Dank fürs Zuschauen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_audio": "/acl6060/audio/dev/255.wav", "src_ref": "Hello, this is Jiawei Zhou from Harvard University.", "tgt_ref": "Hallo, ich bin Jiawei Zhou von der Harvard University.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_audio": "/acl6060/audio/dev/256.wav", "src_ref": "I am very glad to present our work on Online Semantic Parsing for Latency Reduction in Task-Oriented Dialogue.", "tgt_ref": "Ich freue mich sehr, unsere Arbeit zum semantischenOnline-Parsing für die Latenzreduktion bei einem aufgabenorientierten Dialog vorstellen zu können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_audio": "/acl6060/audio/dev/257.wav", "src_ref": "This is joint work with Jason, Michael, Anthony and Sam from Microsoft Semantic Machines.", "tgt_ref": "Dies ist eine gemeinsame Arbeit mit Jason, Michael, Anthony und Sam von Microsoft Semantic Machines.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_audio": "/acl6060/audio/dev/258.wav", "src_ref": "In task-oriented dialogue, a user interacts with the system that handles requests from user utterances usually in speaking.", "tgt_ref": "Beim aufgabenorientierten Dialog interagiert ein Benutzer mit dem System, das Anfragen von Benutzeräußerungen, in der Regel in gesprochener Form, bearbeitet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_audio": "/acl6060/audio/dev/259.wav", "src_ref": "From the finish of the user utterance to the system response there is often a noticeable delay.", "tgt_ref": "Vom Ende der Benutzeräußerung bis zur Antwort des Systems gibt es oft eine spürbare Verzögerung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_audio": "/acl6060/audio/dev/260.wav", "src_ref": "Under the hood, the user utterance is translated into an executable program.", "tgt_ref": "Im Detail wird die Benutzeräußerung in ein ausführbares Programm übersetzt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_audio": "/acl6060/audio/dev/261.wav", "src_ref": "Which is then executed so that the system can respond properly.", "tgt_ref": "Dieses wird dann ausgeführt, damit das System richtig reagieren kann.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_audio": "/acl6060/audio/dev/262.wav", "src_ref": "Because the program is represented as a semantic graph that outlines the computation, where node represents a function invocation and its children are the arguments.", "tgt_ref": "Denn das Programm wird als semantischer Graph dargestellt, der die Berechnung skizziert, wobei ein Knoten einen Funktionsaufruf darstellt und seine Kindknoten die Argumente sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_audio": "/acl6060/audio/dev/263.wav", "src_ref": "The great nodes mark instantaneous operations, but the others are slow to execute.", "tgt_ref": "Die großen Knoten markieren sofortige Operationen, aber die anderen sind langsam in der Ausführung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_audio": "/acl6060/audio/dev/264.wav", "src_ref": "The simple example here we show, these programs can often be more complicated graphs beyond the tree structures.", "tgt_ref": "Das einfache Beispiel hier zeigt, dass diese Programme oft kompliziertere Graphen sein können als die Baumstrukturen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_audio": "/acl6060/audio/dev/265.wav", "src_ref": "In this talk, we ask the question, can we start generating the program and executing it before the user even finishes the utterance so that the faster response can be achieved by the system?", "tgt_ref": "In diesem Vortrag stellen wir die Frage, ob wir mit der Generierung des Programms und seiner Ausführung beginnen können, bevor der Benutzer überhaupt die Äußerung beendet hat, sodass das System schneller reagieren kann.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_audio": "/acl6060/audio/dev/266.wav", "src_ref": "This is the online prediction and decision problem.", "tgt_ref": "Dies ist das Problem der Online-Vorhersage und Entscheidung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_audio": "/acl6060/audio/dev/267.wav", "src_ref": "There are a lot of others in this realm.", "tgt_ref": "Es gibt viele andere in diesem REALM.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_audio": "/acl6060/audio/dev/268.wav", "src_ref": "Examples include simultaneous translation where a live interpreter translates one language to another in real time, smart text auto completion to guess the user intent, and Uber pool where the drivers are sent to where they might be needed based on the predicted demand.", "tgt_ref": "Beispiele sind Simultanübersetzungen, bei denen ein Dolmetscher live eine Sprache in eine andere in Echtzeit übersetzt; die intelligente automatische Vervollständigung von Text, um die Absicht des Benutzers zu erraten; und der Uber Pool, wo Fahrer dorthin geschickt werden, wo sie basierend auf der prognostizierten Nachfrage möglicherweise benötigt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_audio": "/acl6060/audio/dev/269.wav", "src_ref": "All of these scenarios have one thing in common.", "tgt_ref": "All diese Szenarien haben eines gemeinsam.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_audio": "/acl6060/audio/dev/270.wav", "src_ref": "That is, it is beneficial to make decisions before seeing all the input.", "tgt_ref": "Es ist vorteilhaft, Entscheidungen zu treffen, bevor man alle Eingaben sieht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_audio": "/acl6060/audio/dev/271.wav", "src_ref": "In our case, we are going to deal with online semantic parsing, which could be expected to be challenging as we have to guess what the user might say.", "tgt_ref": "In unserem Fall werden wir uns mit dem semantischen Online-Parsing befassen, was eine Herausforderung sein könnte, da wir erraten müssen, was der Benutzer sagen könnte.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_audio": "/acl6060/audio/dev/272.wav", "src_ref": "And it is also underexplored with no formal evaluation metric.", "tgt_ref": "Dieses Gebiet ist auch wenig erforscht und hat keine formale Evaluationsmetrik.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_audio": "/acl6060/audio/dev/273.wav", "src_ref": "First, let's look at how an ordinary system works.", "tgt_ref": "Schauen wir uns zunächst an, wie ein gewöhnliches System funktioniert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_audio": "/acl6060/audio/dev/274.wav", "src_ref": "It is operating offline by parsing to the program only at the end of the user utterance.", "tgt_ref": "Dieses funktioniert offline durch Parsing zum Programm erst am Ende der Benutzeräußerung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_audio": "/acl6060/audio/dev/275.wav", "src_ref": "Here, the character graph is predicted after seeing all the information.", "tgt_ref": "Hier wird das Zeichen Graph vorhergesagt, nachdem alle Information gesehen wurden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_audio": "/acl6060/audio/dev/276.wav", "src_ref": "In contrast, we are proposing an online system that compares at every utterance prefix.", "tgt_ref": "Im Gegensatz dazu schlagen wir ein Online-System vor, das bei jedem Äußerung das Präfix vergleicht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_audio": "/acl6060/audio/dev/277.wav", "src_ref": "For example, each time we see a new token, we predict a new graph.", "tgt_ref": "Jedes Mal, wenn wir beispielsweise ein neues Token sehen, prognostizieren wir einen neuen Graphen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_audio": "/acl6060/audio/dev/278.wav", "src_ref": "Notice that there could be errors.", "tgt_ref": "Beachten Sie, dass Fehler auftreten können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_audio": "/acl6060/audio/dev/279.wav", "src_ref": "At the position of at the pool party with Barack Obama, we got a graph with the right nodes on the person and the event subject, but guess the wrong timing information.", "tgt_ref": "Bei der Position von der Poolparty mit Barack Obama haben wir einen Graphen mit den richtigen Knoten über die Person und das Thema des Ereignisses, aber wahrscheinlich die falschen Informationen zu den Zeiten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_audio": "/acl6060/audio/dev/280.wav", "src_ref": "This process goes on until we receive the full user utterance.", "tgt_ref": "Dieser Prozess geht weiter, bis wir die vollständige Benutzeräußerung erhalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_audio": "/acl6060/audio/dev/281.wav", "src_ref": "How would this affect the execution timeline in the offline system?", "tgt_ref": "Wie würde sich dies auf die Ausführungszeiten im Offline-System auswirken?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_audio": "/acl6060/audio/dev/282.wav", "src_ref": "We'll get the program graph at the end so that the system can start execution at this point.", "tgt_ref": "Am Ende erhalten wir den Programm-Graphen, damit das System an dieser Stelle mit der Ausführung beginnen kann.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_audio": "/acl6060/audio/dev/283.wav", "src_ref": "Remember that the great nodes are fast operations, so we only consider the execution timeline of the colored slow functions.", "tgt_ref": "Vergessen Sie nicht, dass die großen Knoten schnelle Operationen sind. Daher betrachten wir nur die Ausführungszeiten der farbigen langsamen Funktionen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_audio": "/acl6060/audio/dev/284.wav", "src_ref": "First, these two find person functions can be executed in parallel, highlighted in white from the pink box as they have no dependency on other functions.", "tgt_ref": "Erstens können diese beiden Personensuchfunktionen parallel ausgeführt werden, da sie keine Abhängigkeit von anderen Funktionen haben. Sie sind weiß hinterlegt im rosa Kästchen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_audio": "/acl6060/audio/dev/285.wav", "src_ref": "Next, the node create event can then get executed after obtaining results from lower level nodes and then the top function yield so the whole program is finished.", "tgt_ref": "Als Nächstes kann der Knoten „Ereignis erstellen“ ausgeführt werden, nachdem er Ergebnisse von Knoten bekommen hat. Mit der Top-Ertragsfunktion wird das gesamte Programm beendet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_audio": "/acl6060/audio/dev/286.wav", "src_ref": "The execution process is strict, restricted to the program dependency structure where some operations cannot be parallelized which induces a noticeable delay.", "tgt_ref": "Der Ausführungsprozess ist streng und beschränkt sich auf die Abhängigkeitsstruktur des Programms, bei der einige Operationen nicht parallelisiert werden können. Das führt zu einer spürbaren Verzögerung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_audio": "/acl6060/audio/dev/287.wav", "src_ref": "In our online system, where we predict as we go, the program execution can start earlier.", "tgt_ref": "In unserem Online-System, wo wir im Laufe der Zeit vorhersagen, kann die Programmausführung früher beginnen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_audio": "/acl6060/audio/dev/288.wav", "src_ref": "Here, at the prefix after Obama we predict confidently that the find person function should be in the program, but the rest may contain errors as they are grayed out.", "tgt_ref": "Hier, beim Präfix nach Obama, sagen wir zuversichtlich voraus, dass die Funktion „Person finden“ im Programm sein muss, aber dass der Rest Fehler enthalten kann, da sie ausgegraut sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_audio": "/acl6060/audio/dev/289.wav", "src_ref": "The execution of the node can be immediately started as a step.", "tgt_ref": "Die Ausführung des Knotens kann sofort als Schritt gestartet werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_audio": "/acl6060/audio/dev/290.wav", "src_ref": "Then, with more tokens, we predict a totally new graph, but part of it has already being executed.", "tgt_ref": "Dann, mit mehr Token, prognostizieren wir einen völlig neuen Graphen, aber ein Teil davon wird bereits ausgeführt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_audio": "/acl6060/audio/dev/291.wav", "src_ref": "So, we only need to consider the rest of the nodes that we are confident about as well.", "tgt_ref": "Wir müssen also nur den Rest der Knoten betrachten, bei denen wir uns auch sicher sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_audio": "/acl6060/audio/dev/292.wav", "src_ref": "Here, another find person can be executed in parallel.", "tgt_ref": "Hier kann wieder „Finde Person“ parallel ausgeführt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_audio": "/acl6060/audio/dev/293.wav", "src_ref": "Again, we may have wrong predictions.", "tgt_ref": "Auch hier könnten wir falsche Vorhersagen haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_audio": "/acl6060/audio/dev/294.wav", "src_ref": "With more text, we have more ability to make it right.", "tgt_ref": "Mit mehr Text steigt die Chance, dass wir richtig liegen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_audio": "/acl6060/audio/dev/295.wav", "src_ref": "Such as the event time here where AM is also anticipated correctly.", "tgt_ref": "Zum Beispiel bei der Zeit des Ereignisses, bei der AM auch richtig vorhergesehen wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_audio": "/acl6060/audio/dev/296.wav", "src_ref": "Then, we can start executing the rest following the program dependency structure.", "tgt_ref": "Dann können wir mit der Ausführung des Rests beginnen, indem wir der Abhängigkeitsstruktur des Programms folgen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_audio": "/acl6060/audio/dev/297.wav", "src_ref": "By overlapping the execution timeline with the utterance timeline, we save a big amount of time.", "tgt_ref": "Indem wir die Ausführungszeiten mit den Zeiten der Äußerungen überlappen, sparen wir viel Zeit ein.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_audio": "/acl6060/audio/dev/298.wav", "src_ref": "So we proposed the task of online semantic parsing.", "tgt_ref": "Also haben wir die Aufgabe mit dem semantischen Online-Parsing vorgeschlagen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_audio": "/acl6060/audio/dev/299.wav", "src_ref": "One underlying assumption is that the execution time dominates the model prediction time.", "tgt_ref": "Eine zugrunde liegende Annahme ist, dass die Ausführungszeit die Vorhersagezeit des Modells dominiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_audio": "/acl6060/audio/dev/300.wav", "src_ref": "So we could only gain time by predicting earlier.", "tgt_ref": "Also konnten wir nur Zeit gewinnen, indem wir früher voraussagten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_audio": "/acl6060/audio/dev/301.wav", "src_ref": "Another assumption is that as the prediction and execution happen in the background, that it is not visible to users.", "tgt_ref": "Eine weitere Annahme ist, dass, wenn die Vorhersage und die Ausführung im Hintergrund stattfinden, sie für Benutzer nicht sichtbar sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_audio": "/acl6060/audio/dev/302.wav", "src_ref": "It is not necessary to maintain a consistent parsing history.", "tgt_ref": "Es ist nicht notwendig, eine konsistente Parsing-Historie aufzubewahren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_audio": "/acl6060/audio/dev/303.wav", "src_ref": "So, we reparse from scratch after each token.", "tgt_ref": "Also parsen wir nach jedem Token von Grund auf neu.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_audio": "/acl6060/audio/dev/304.wav", "src_ref": "In particular, we propose a two step approach.", "tgt_ref": "Insbesondere wollen wir einen zweistufigen Ansatz vorschlagen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_audio": "/acl6060/audio/dev/305.wav", "src_ref": "A proposed step that predicts a graph with complete structure and a select step that selects the nodes that are worth executing at this time.", "tgt_ref": "Wir schlagen einen Schritt vor, bei dem ein Graph mit vollständiger Struktur vorhergesagt wird und einen Schritt, bei dem die Knoten ausgewählt werden, die es zu diesem Zeitpunkt wert sind, ausgeführt zu werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_audio": "/acl6060/audio/dev/306.wav", "src_ref": "We had two variants of the proposed method.", "tgt_ref": "Wir hatten zwei Varianten der vorgeschlagenen Methode.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_audio": "/acl6060/audio/dev/307.wav", "src_ref": "First approach combines a language model completion with full utterance to graph parsing.", "tgt_ref": "Der erste Ansatz kombiniert eine Sprachmodell-Vervollständigung mit einer vollständigen Äußerung zum Graph-Parsing.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_audio": "/acl6060/audio/dev/308.wav", "src_ref": "In particular, the prefix after Obama is first completed through a finetuned BART language model and then translated into a program with full offline parser.", "tgt_ref": "Insbesondere wird das Präfix nach Obama zunächst durch ein fein abgestimmtes BART-Sprachmodell vervollständigt und dann in ein Programm mit vollständigem Offline-Parser übersetzt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_audio": "/acl6060/audio/dev/309.wav", "src_ref": "The second approach directly predicts the program from user utterance prefixes.", "tgt_ref": "Der zweite Ansatz sagt das Programm direkt aus den Präfixen der Benutzeräußerung voraus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_audio": "/acl6060/audio/dev/310.wav", "src_ref": "This is achieved by training a single online parser to translate to the goal graph from each prefix.", "tgt_ref": "Dies wird durch Training von einem einzigen Online-Parser erreicht, der aus jedem Präfix in den Zielgraphen übersetzen soll.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_audio": "/acl6060/audio/dev/311.wav", "src_ref": "This facilitates the model to learn the right anticipation.", "tgt_ref": "Dies erleichtert dem Modell, die richtige Erwartung zu erlernen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_audio": "/acl6060/audio/dev/312.wav", "src_ref": "In a bit more detail, how do we generate these graphs?", "tgt_ref": "Detaillierter gesagt: Wie können wir diese Graphen generieren?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_audio": "/acl6060/audio/dev/313.wav", "src_ref": "We formulate the problem by generating a serial version of the graph.", "tgt_ref": "Wir formulieren das Problem, indem wir eine serielle Version des Graphen generieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_audio": "/acl6060/audio/dev/314.wav", "src_ref": "Each node or edge is represented by an action.", "tgt_ref": "Jeder Knoten oder jede Kante wird durch eine Aktion dargestellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_audio": "/acl6060/audio/dev/315.wav", "src_ref": "Here, we start from the first node.", "tgt_ref": "Hier beginnen wir mit dem ersten Knoten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_audio": "/acl6060/audio/dev/316.wav", "src_ref": "The number below records the absolute index in action history.", "tgt_ref": "Die Reihe unten zeichnet den absoluten Index im Aktionsverlauf auf.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_audio": "/acl6060/audio/dev/317.wav", "src_ref": "Then, we got the second node.", "tgt_ref": "Dann haben wir den zweiten Knoten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_audio": "/acl6060/audio/dev/318.wav", "src_ref": "Next, is the edge between them.", "tgt_ref": "Als Nächstes kommt die Kante zwischen ihnen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_audio": "/acl6060/audio/dev/319.wav", "src_ref": "It contains the pointer to the index of the previous node and the edge label.", "tgt_ref": "Dort ist der Zeiger auf den Index des früheren Knotens und das Kantenlabel enthalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_audio": "/acl6060/audio/dev/320.wav", "src_ref": "Zero here means connecting the most recent node with the node generated by the zeroth action and next node next edge.", "tgt_ref": "Null bedeutet hier, dass der neueste Knoten mit dem Knoten verbunden wird, der durch die Null-Aktion und die Kante des nächsten Knotens generiert wurde.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_audio": "/acl6060/audio/dev/321.wav", "src_ref": "This process goes on until we generate the full graph.", "tgt_ref": "Dieser Prozess geht weiter, bis wir den vollständigen Graph generieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_audio": "/acl6060/audio/dev/322.wav", "src_ref": "The underlying model is based on transformer with self pointing mechanism similar to a previous transition based parser.", "tgt_ref": "Das zugrunde liegende Modell basiert auf dem Transformator mit Selbstausrichtungsmechanismus, ähnlich einem früheren übergangsbasierten Parser.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_audio": "/acl6060/audio/dev/323.wav", "src_ref": "After generating a complete graph, we obtained the action level probabilities that correspond to different parts of the graph.", "tgt_ref": "Nach Generierung eines vollständigen Graphen haben wir die Wahrscheinlichkeiten der Aktionsebene erhalten, die verschiedenen Teilen des Graphen entsprechen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_audio": "/acl6060/audio/dev/324.wav", "src_ref": "We select confidence subgraphs based on the thresholding heuristic to be executed.", "tgt_ref": "Wir wählen Konfidenzteilgraphen auf der Grundlage der auszuführenden Schwellwerte heuristisch aus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_audio": "/acl6060/audio/dev/325.wav", "src_ref": "Later on, we're going to vary the threshold to achieve different tradeoffs between the latency reduction and the execution cost.", "tgt_ref": "Später werden wir den Schwellenwert variieren, um unterschiedliche Kompromisse zwischen der Latenzreduzierung und den Ausführungskosten zu erzielen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_audio": "/acl6060/audio/dev/326.wav", "src_ref": "For formal evaluation of the online methods, we propose final latency reduction or FLR metric.", "tgt_ref": "Für die formale Evaluation der Online-Methoden wollen wir eine endgültige Latenzreduzierung oder FLR-Metrik vorschlagen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_audio": "/acl6060/audio/dev/327.wav", "src_ref": "Here's a recap of how an offline system finishes the execution timeline.", "tgt_ref": "Hier ist eine Zusammenfassung, wie ein Offline-System die Ausführungszeiten beendet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_audio": "/acl6060/audio/dev/328.wav", "src_ref": "In online systems, execution overlaps with the utterance timeline, so it ends earlier.", "tgt_ref": "In Online-Systemen überschneidet sich die Ausführung mit den Zeiten der Äußerung. Sie endet also früher.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_audio": "/acl6060/audio/dev/329.wav", "src_ref": "FLR is defined as the reduction time compared to the offline system, marked by the end of the execution.", "tgt_ref": "FLR ist als die Reduktionszeit im Vergleich zum Offline-System definiert und durch das Ende der Ausführung markiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_audio": "/acl6060/audio/dev/330.wav", "src_ref": "We conduct experiments on two large conversational semantic parsing datasets, SMCalFlow and TreeDST.", "tgt_ref": "Wir führen Experimente an zwei großen Datensätzen von Konversationen mit semantischem Parsing durch: SMCalFlow und TreeDST.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_audio": "/acl6060/audio/dev/331.wav", "src_ref": "Our graph based parser when operating offline, achieves state-of-the-art performance on parsing on both datasets.", "tgt_ref": "Unser auf dem Graphen basierte Parser erreicht, wenn er offline betrieben wird, beste Leistungen beim Parsing für beide Datensätze.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_audio": "/acl6060/audio/dev/332.wav", "src_ref": "The LM complete model also achieves nontrivial BLEU gain compared with the simple baseline of node completion.", "tgt_ref": "Das LM-Complete-Modell erzielt auch eine nicht triviale BLEU -Verstärkung im Vergleich zur einfachen Basislinie der Knotenvervollständigung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_audio": "/acl6060/audio/dev/333.wav", "src_ref": "Now, let's look at the prediction accuracy of our prefix to graph parser.", "tgt_ref": "Schauen wir uns nun die Vorhersagegenauigkeit unseres Präfixes für den Graph-Parser an.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_audio": "/acl6060/audio/dev/334.wav", "src_ref": "We test the match F1 score of graph tuples between the generation and the go graph in validation data in y axis for each prefix length in x axis represented by percentages.", "tgt_ref": "Wir testen den F1-Score der Graph-Tupel zwischen der Generierung und dem Go-Graph in den Validierungsdaten auf der y-Achse für jede Präfixlänge in der x-Achse, dargestellt durch Prozentsätze.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_audio": "/acl6060/audio/dev/335.wav", "src_ref": "Each of these curves represents a different model with the only difference in training data.", "tgt_ref": "Jede dieser Kurven stellt ein anderes Modell mit dem einzigen Unterschied in den Trainingsdaten dar.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_audio": "/acl6060/audio/dev/336.wav", "src_ref": "The bottom curve is the offline parser, and we mix in prefix data in different lengths to transition the model to an online parser.", "tgt_ref": "Die untere Kurve ist der Offline-Parser. Wir mischen Präfix- Daten in verschiedenen Längen hinein, um das Modell in einen Online-Parser zu überführen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_audio": "/acl6060/audio/dev/337.wav", "src_ref": "For example, the legend prefix eighty percent plus means the model is trained with prefix data with prefix length larger than eighty percent of the full utterance length.", "tgt_ref": "Zum Beispiel bedeutet das Legendenpräfix „80 Prozent plus“, dass das Modell mit Präfix-Daten trainiert wird, wobei die Präfixlänge größer als 80 Prozent der vollen Äußerungslänge ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_audio": "/acl6060/audio/dev/338.wav", "src_ref": "The upper left corner is the desired area.", "tgt_ref": "Die obere linke Ecke ist der gewünschte Bereich.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_audio": "/acl6060/audio/dev/339.wav", "src_ref": "As we can see, the offline parser in black curve is not doing well on the prefix data.", "tgt_ref": "Wie wir sehen können, funktioniert der Offline-Parser in der schwarzen Kurve der Präfix-Daten nicht gut.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_audio": "/acl6060/audio/dev/340.wav", "src_ref": "As we're mixing more prefixes in training, the curve is lifting upper and left, performing better on all the prefix lengths.", "tgt_ref": "Da wir im Training mehr Präfixe mischen, hebt sich die Kurve nach oben und links und schneidet bei allen Präfixlängen besser ab.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_audio": "/acl6060/audio/dev/341.wav", "src_ref": "However, the full utterance parsing performance is not affected in the upper right dot.", "tgt_ref": "Die volle Leistung des Äußerung-Parsings wird jedoch im oberen rechten Punkt nicht beeinflusst.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_audio": "/acl6060/audio/dev/342.wav", "src_ref": "Based on these strong results, how much latency do we reduce?", "tgt_ref": "Basierend auf diesen starken Ergebnissen, stellt sich die Frage, wie viel Latenz reduziert wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_audio": "/acl6060/audio/dev/343.wav", "src_ref": "We measure the time by the number of source tokens and simulate different function execution times.", "tgt_ref": "Wir messen die Zeit anhand der Reihe von Quelltoken und simulieren verschiedene Funktionsausführungszeiten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_audio": "/acl6060/audio/dev/344.wav", "src_ref": "The curves show the tradeoff between the FLR metric and the execution cost, measured by the number of excessive function costs that are not correct.", "tgt_ref": "Die Kurven zeigen den Kompromiss zwischen der FLR-Metrik und den Ausführungskosten, gemessen an der Reihe übermäßiger Funktionskosten, die nicht korrekt sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_audio": "/acl6060/audio/dev/345.wav", "src_ref": "This is achieved by varying the subgraph selection threshold.", "tgt_ref": "Dies wird durch Variation der Teilgraphenauswahlschwelle erreicht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_audio": "/acl6060/audio/dev/346.wav", "src_ref": "A higher threshold selects fewer functions of mistake, but obtains a smaller FLR, whereas the lower threshold more aggressively selects and executes programs.", "tgt_ref": "Eine höhere Schwelle wählt weniger Fehlfunktionen aus, erhält aber eine kleinere FLR, während die niedrigere Schwelle aggressiver Programme auswählt und ausführt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_audio": "/acl6060/audio/dev/347.wav", "src_ref": "We compare the two approaches we propose and a baseline that does nothing but directly applying the offline parser for online use.", "tgt_ref": "Wir vergleichen die beiden Ansätze, die wir vorschlagen, mit einer Baseline, die nichts anderes tut, als den Offline-Parser für den Online-Einsatz anzuwenden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_audio": "/acl6060/audio/dev/348.wav", "src_ref": "The upper left region is has the best FLR and cost tradeoff.", "tgt_ref": "Der obere linke Bereich hat den besten FLR und Kostenvorteil.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_audio": "/acl6060/audio/dev/349.wav", "src_ref": "We see both of our methods beat the baseline by a large margin, and they perform more similarly on TreeDST.", "tgt_ref": "Wir sehen, dass beide unserer Methoden die Baseline um eine große Differenz übertreffen und sie bei TreeDST ähnlicher abschneiden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_audio": "/acl6060/audio/dev/350.wav", "src_ref": "While individual function execution is faster, there tends to be more run executions and lower latency reduction room.", "tgt_ref": "Während die Ausführung einzelner Funktionen schneller ist, gibt es tendenziell mehr Ausführungsvorgänge und weniger Raum für die Latenzreduzierung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_audio": "/acl6060/audio/dev/351.wav", "src_ref": "When individual function execution is slower, there is more room for FLR improvement.", "tgt_ref": "Wenn die Ausführung einzelner Funktionen langsamer ist, gibt es mehr Möglichkeiten für FLR-Verbesserungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_audio": "/acl6060/audio/dev/352.wav", "src_ref": "Our two approaches achieve better performance in different cost cost regions.", "tgt_ref": "Unsere beiden Ansätze erreichen eine bessere Leistung in verschiedenen Kostenbereichen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_audio": "/acl6060/audio/dev/353.wav", "src_ref": "Overall, we achieve thirty to sixty three percent relative latency reduction depending on execution time and allowed cost.", "tgt_ref": "Insgesamt erreichen wir je nach Ausführungszeit und zulässigen Kosten eine Reduzierung der relativen Latenz um 63 bis 60 Prozent.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_audio": "/acl6060/audio/dev/354.wav", "src_ref": "Finally, we have a breakdown of average latency reduction in tokens for each type of the function node when the allowed cost is three run executions.", "tgt_ref": "Schließlich haben wir eine Aufschlüsselung der durchschnittlichen Latenzreduktion in Token für jeden Typ des Funktionsknotens, wenn die zulässigen Kosten drei Ausführungsvorgänge betragen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_audio": "/acl6060/audio/dev/355.wav", "src_ref": "As we can see, there are gains all over the board.", "tgt_ref": "Wie wir sehen können, gibt es in jedem Bereich positive Ergebnisse.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_audio": "/acl6060/audio/dev/356.wav", "src_ref": "There are also some functions on which we gain impressive latency reduction where the red bar is much longer, such as find manager and recipient.", "tgt_ref": "Es gibt auch einige Funktionen, bei denen wir eine beeindruckende Latenzreduzierung erzielen und der rote Balken viel länger ist, wie z. B. Find Manager und Empfänger.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_audio": "/acl6060/audio/dev/357.wav", "src_ref": "These are low level functions that do not have much dependency on others.", "tgt_ref": "Dies sind Low-Level-Funktionen, die keine große Abhängigkeit von anderen haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_audio": "/acl6060/audio/dev/358.wav", "src_ref": "In conclusion, we proposed online semantic parsing as new task to explore with the rigorous latency reduction metric.", "tgt_ref": "Abschließend haben wir das semantische Online-Parsing als neue Aufgabe vorgeschlagen, das wir mit der strengen Latenzreduktionsmetrik untersuchen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_audio": "/acl6060/audio/dev/359.wav", "src_ref": "With a strong graph based semantic parser, we achieve relatively good latency reduction either through our pipeline approach with LM completion and a full parser or directly through a learned parser on the prefixes.", "tgt_ref": "Mit einem starken graph-basierten, semantischen Parser erreichen wir eine relativ gute Latenzreduktion, entweder durch unseren Pipeline-Ansatz mit LM-Abschluss und einem vollständigen Parser, oder direkt durch einen gelernten Parser mit Fokus auf die Präfixe.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_audio": "/acl6060/audio/dev/360.wav", "src_ref": "Moreover, our approach can be a general framework and can be applied to other executable semantic representations in different domains.", "tgt_ref": "Darüber hinaus kann unser Ansatz ein allgemeiner Rahmen sein und auf andere ausführbare semantische Darstellungen in verschiedenen Domänen angewendet werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_audio": "/acl6060/audio/dev/361.wav", "src_ref": "Future works could explore smarter prediction and execution integration method.", "tgt_ref": "Zukünftige Arbeiten könnten eine intelligentere Vorhersage und die Methode der Ausführungsintegration erforschen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_audio": "/acl6060/audio/dev/362.wav", "src_ref": "Thanks for your listening.", "tgt_ref": "Danke fürs Zuhören.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_audio": "/acl6060/audio/dev/363.wav", "src_ref": "Hi.", "tgt_ref": "Hi.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_audio": "/acl6060/audio/dev/364.wav", "src_ref": "I'm going to discuss our work on generating retrieval augmented counterfactuals for question answering tasks.", "tgt_ref": "Ich werde nun unsere Arbeit am generierenden Retrieval und den erweiterten Kontrafakten für Aufgaben der Fragenbeantwortung vorstellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_audio": "/acl6060/audio/dev/365.wav", "src_ref": "This is work done during my internship at Google Research, where I was mentored by Matthew Lamm and Ian Tenney.", "tgt_ref": "Dies ist die Arbeit, die ich während meines Praktikums bei Google Research gemacht habe, wo ich von Matthew Lamm und Ian Tenney betreut wurde.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_audio": "/acl6060/audio/dev/366.wav", "src_ref": "To motivate the task, let me begin by defining a counterfactual.", "tgt_ref": "Um die Aufgabe vorzustellen, möchte ich damit beginnen, das Wort kontrafaktisch zu definieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_audio": "/acl6060/audio/dev/367.wav", "src_ref": "In this work, we define a counterfactual as a perturbation of the input text that differs in some meaningful controlled way from the original text.", "tgt_ref": "In dieser Arbeit definieren wir kontrafaktisch als eine Störung des eingegebenen Textes, der sich in irgendeiner bedeutungsvollen kontrollierten Weise vom ursprünglichen Text unterscheidet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_audio": "/acl6060/audio/dev/368.wav", "src_ref": "And allows us to reason about the changes in the outcome or the task label.", "tgt_ref": "Damit können wir über die Änderungen des Ergebnisses oder des Labels der Aufgabe schlussfolgern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_audio": "/acl6060/audio/dev/369.wav", "src_ref": "For instance, changing the words fascinating to captivating or expected to mind-numbing changes the sentiment for this movie review.", "tgt_ref": "Wenn man beispielsweise die Wörter „faszinierend“ zu „fesselnd“ oder „erwartet“ zu „todlangweilig“ ändert, ändert das die Stimmung der Filmrezension.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_audio": "/acl6060/audio/dev/370.wav", "src_ref": "Similarly, adding the qualifier women's to the question changes the answer to the question in the example below.", "tgt_ref": "Wird die nähere Bestimmung „Damen“ zur Frage hinzugefügt, ändert sich die Antwort auf die Frage wie im Beispiel unten dargestellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_audio": "/acl6060/audio/dev/371.wav", "src_ref": "Humans are typically robust to such perturbations compared to NLP models trained on the task.", "tgt_ref": "Menschen sind in der Regel robust gegenüber solchen Störungen im Vergleich zu NLP-Modellen, die für die Aufgabe trainiert wurden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_audio": "/acl6060/audio/dev/372.wav", "src_ref": "Why is that?", "tgt_ref": "Warum?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_audio": "/acl6060/audio/dev/373.wav", "src_ref": "The dataset may be sampled with systematic biases that lead to a simple decision boundary that is violated by the counterfactual.", "tgt_ref": "Der Datensatz kann mit systematischen Bias gesampelt werden. Das führt zu einer einfachen Entscheidungsgrenze, die kontrafaktisch übertreten wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_audio": "/acl6060/audio/dev/374.wav", "src_ref": "As shown in this 2D classification problem.", "tgt_ref": "Das zeigt sich in diesem 2D-Klassifizierungsproblem.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_audio": "/acl6060/audio/dev/375.wav", "src_ref": "My work has found that adding counterfactual examples to the training data can make the model robust to such perturbations.", "tgt_ref": "Mit meiner Arbeit habe ich herausgefunden, dass das Hinzufügen von kontrafaktischen Beispielen zu den Trainingsdaten das Modell robust gegen solche Störungen machen kann.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_audio": "/acl6060/audio/dev/376.wav", "src_ref": "So, if counterfactuals are valuable, how can we generate them?", "tgt_ref": "Wenn also Kontrafakten wertvoll sind, wie können wir sie dann generieren?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_audio": "/acl6060/audio/dev/377.wav", "src_ref": "This task is especially hard for NLP because here are three examples from three different NLP tasks.", "tgt_ref": "Diese Aufgabe ist besonders schwierig für NLP, denn hier sind drei Beispiele aus drei verschiedenen NLP-Aufgaben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_audio": "/acl6060/audio/dev/378.wav", "src_ref": "As you can see, examples that violate the decision boundary between outcomes need to be very carefully crafted by perturbing some attributes of the text that are underlined here.", "tgt_ref": "Wie Sie sehen können, müssen Beispiele, die die Entscheidungsgrenze zwischen den Ergebnissen verletzen, sehr sorgfältig erstellt werden, indem einige Attribute des Textes, die hier unterstrichen werden, gestört werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_audio": "/acl6060/audio/dev/379.wav", "src_ref": "This could be done by human annotation, but this is expensive and biased.", "tgt_ref": "Dies könnte durch menschliche Annotation geschehen, aber dies ist teuer und voreingenommen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_audio": "/acl6060/audio/dev/380.wav", "src_ref": "Some prior work has focused on using syntax trees or semantic role labeling.", "tgt_ref": "Einige frühere Arbeiten konzentrierten sich auf die Verwendung von Syntax-Bäumen oder einer semantischen Rollenbezeichnung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_audio": "/acl6060/audio/dev/381.wav", "src_ref": "But the set of perturbations generated by these techniques are limited by the semantic framework.", "tgt_ref": "Aber die Reihe von Störungen, die durch diese Techniken generiert werden, sind durch den semantischen Rahmen begrenzt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_audio": "/acl6060/audio/dev/382.wav", "src_ref": "More recent work has used masked language models to fill in masked portions of the text to change labels.", "tgt_ref": "Neuere Arbeiten haben maskierte Sprachmodelle verwendet, um maskierte Teile des Textes auszufüllen, um Labels zu ändern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_audio": "/acl6060/audio/dev/383.wav", "src_ref": "But finding what parts of the text to perturb can be challenging.", "tgt_ref": "Aber herauszufinden, welche Teile des Textes zu stören sind, kann eine Herausforderung sein.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_audio": "/acl6060/audio/dev/384.wav", "src_ref": "There are more challenges to generating counterfactuals for question answering specifically.", "tgt_ref": "Es gibt mehr Herausforderungen für die Generierung von Kontrafakten als für die spezifische Beantwortung der Frage.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_audio": "/acl6060/audio/dev/385.wav", "src_ref": "This task requires background knowledge.", "tgt_ref": "Diese Aufgabe erfordert Hintergrundwissen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_audio": "/acl6060/audio/dev/386.wav", "src_ref": "For instance, to perturb the original question is Indiana Jones Temple of Doom a prequel?", "tgt_ref": "Um beispielsweise die ursprüngliche Frage zu stören: „Ist Indiana Jones und der Tempel des Todes ein Prequel?“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_audio": "/acl6060/audio/dev/387.wav", "src_ref": "We need to be aware of the other movies in the franchise to get to a question like is Indiana Jones Raiders of the Lost Ark a prequel?", "tgt_ref": "Wir müssen die anderen Filme im Franchise kennen, um die Frage stellen zu können: „Ist Indiana Jones – Jäger des verlorenen Schatzes ein Prequel?“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_audio": "/acl6060/audio/dev/388.wav", "src_ref": "Furthermore, random perturbations can lead to questions that are not answerable with the available evidence or have false premises.", "tgt_ref": "Darüber hinaus können zufällige Störungen zu Fragen führen, die mit den verfügbaren Beweisen nicht beantwortet werden können oder falsche Voraussetzungen haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_audio": "/acl6060/audio/dev/389.wav", "src_ref": "Moreover, some question perturbations can lead to significant semantic drift from the original input.", "tgt_ref": "Darüber hinaus können einige Frage-Störungen zu einer signifikanten semantischen Abweichung von der ursprünglichen Eingabe führen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_audio": "/acl6060/audio/dev/390.wav", "src_ref": "For instance, this question is Indiana Jones practicing child slavery in Temple of Doom?", "tgt_ref": "Zum Beispiel ist diese Frage hier: „Praktiziert Indiana Jones Kindersklaverei im Tempel des Todes?“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_audio": "/acl6060/audio/dev/391.wav", "src_ref": "We propose a very simple yet effective technique called retrieve generate filter or RGF, to tackle counterfactual perturbations of questions, and also aims to tackle all the other aforementioned challenges.", "tgt_ref": "Wir wollen eine sehr einfache, aber effektive Technik mit dem Namen „Retrieve Generate Filter“ oder RGF vorschlagen, um kontrafaktische Störungen von Fragen in Angriff zu nehmen. Sie zielt auch darauf ab, alle anderen oben genannten Herausforderungen zu bewältigen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_audio": "/acl6060/audio/dev/392.wav", "src_ref": "The core intuition behind RGF is that the necessary background information that is needed to generate perturbations may be present in the near misses made by a question answering model.", "tgt_ref": "Die Kernintuition hinter RGF ist, dass die notwendigen Hintergrundinformationen, die erforderlich sind, um Störungen zu genieren, in den Near-Misses vorhanden sein können, die von einem Frage-Antwort-Modell erstellt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_audio": "/acl6060/audio/dev/393.wav", "src_ref": "For instance, the state-of-the-art model REALM produces the following top k answers to the question who is the captain of the Richmond Football Club?", "tgt_ref": "Zum Beispiel liefert das hochmoderne Modell REALM die folgenden Top-k-Antworten auf die Frage, wer der Kapitän des Richmond Football Club ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_audio": "/acl6060/audio/dev/394.wav", "src_ref": "While it does recover the original reference passage and answer Trent Cotchin as the top most choice.", "tgt_ref": "Es holt die ursprüngliche Referenzpassage und die Antwort „Trent Cotchin“ als erste Wahl ein.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_audio": "/acl6060/audio/dev/395.wav", "src_ref": "It also retrieves additional passages and answers which can be used to guide question perturbation.", "tgt_ref": "Zusätzlich werden auch zusätzliche Passagen und Antworten abgerufen, die verwendet werden können, um Störungen der Frage zu steuern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_audio": "/acl6060/audio/dev/396.wav", "src_ref": "For instance, it recovers two more answers corresponding to the captains of the reserve team and the women's team of the same club, and this can lead to interesting edits.", "tgt_ref": "Zum Beispiel holt es zwei weitere Antworten ein, passend zu den Kapitänen der Reservemannschaft und der Damenmannschaft des gleichen Vereins. Dies kann zu interessanten Änderungen führen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_audio": "/acl6060/audio/dev/397.wav", "src_ref": "To summarize, RGF first retrieves top k most relevant answers and contexts which don't match the reference answer in context.", "tgt_ref": "Zusammenfassend lässt sich sagen, dass RGF zuerst die wichtigsten Top-k-Antworten und Kontexte abruft, die nicht mit der Referenz Antwort in Kontext übereinstimmen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_audio": "/acl6060/audio/dev/398.wav", "src_ref": "Following this step, the question generation model conditions on these alternate answers to generate a question that corresponds to them.", "tgt_ref": "Im Anschluss an diesen Schritt konditioniert dieses Fragengenerierungsmodell diese alternativen Antworten, um eine ihnen entsprechende Frage zu generieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_audio": "/acl6060/audio/dev/399.wav", "src_ref": "And finally, we can filter the generated questions based on minimality or based on the type of semantic perturbation we are interested in introducing.", "tgt_ref": "Schließlich können wir die generierten Fragen nach Minimalität oder nach der Art der semantischen Störung, die wir einführen möchten, filtern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_audio": "/acl6060/audio/dev/400.wav", "src_ref": "Going over each step in greater detail for retrieval, we use a retrieve then read model like REALM that takes as input the original question, and a large corpus like Wikipedia.", "tgt_ref": "Wenn wir beim Retrieval jeden Schritt genauer durchgehen, dann sehen wir, dass wir einen Abruf verwenden. Dann lesen wir ein Modell wie REALM, das als Eingabe die ursprüngliche Frage und einen großen Korpus wie etwa Wikipedia hernimmt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_audio": "/acl6060/audio/dev/401.wav", "src_ref": "It consists of two modules.", "tgt_ref": "Es besteht aus zwei Modulen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_audio": "/acl6060/audio/dev/402.wav", "src_ref": "The retriever module performs similarity search over a dense index of passages to retrieve the top k most relevant passages to the question.", "tgt_ref": "Das Retrieval-Modul führt eine Ähnlichkeitssuche über einen dichten Index von Passagen durch, um die wichtigsten Top-k-Passagen zur Frage abzurufen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_audio": "/acl6060/audio/dev/403.wav", "src_ref": "And a reader module then extracts a span from each passage as a potential answer.", "tgt_ref": "Das Lesemodul extrahiert dann aus jeder Passage einen Bereich als potenzielle Antwort.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_audio": "/acl6060/audio/dev/404.wav", "src_ref": "REALM retrieves the gold passage and answer in most cases.", "tgt_ref": "REALM ruft die Goldpassage und in den meisten Fällen die Antwort ab.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_audio": "/acl6060/audio/dev/405.wav", "src_ref": "However, in this work, we are more interested in the answers and context that it retrieves further down the line.", "tgt_ref": "In dieser Arbeit sind wir jedoch mehr an den Antworten und am Kontext interessiert, der später abgerufen wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_audio": "/acl6060/audio/dev/406.wav", "src_ref": "In the next step, question generation, we use these alternate answers and contexts to regenerate new questions that correspond to these alternatives.", "tgt_ref": "Im nächsten Schritt der Fragengenerierung verwenden wir diese alternativen Antworten und Kontexte, um neue Fragen zu generieren, die diesen Alternativen entsprechen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_audio": "/acl6060/audio/dev/407.wav", "src_ref": "Question generation model is a pre trained text-to-text transformer that is fine-tuned on the NQ data to generate a question for an answer that's marked in context.", "tgt_ref": "Das Modell der Fragengenerierung ist ein vortrainierter Text-to-Text-Transformer, der auf die NQ-Daten abgestimmt ist, um eine Frage für eine Antwort zu generieren, die für den Kontext markiert ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_audio": "/acl6060/audio/dev/408.wav", "src_ref": "During inference we supply the question generation model, the alternative answer and context that we retrieved in the previous step.", "tgt_ref": "Während der Interferenz liefern wir das Fragengenerierungsmodell, die alternative Antwort und den Kontext, die wir im früheren Schritt abgerufen haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_audio": "/acl6060/audio/dev/409.wav", "src_ref": "For example, for the query who is the captain of the Richmond Football Club? REALM retrieves passages about the club's women's team, captained by Jess Kennedy, and the question generation model generates the query who captained Richmond Football Club's first ever women's team?", "tgt_ref": "Zum Beispiel für die Anfrage: „Wer ist der Kapitän des Richmond Football Clubs?“ REALM ruft Passagen über die Damenmannschaft des Clubs ab, die von Jess Kennedy angeführt wird. Das fragengenerierende Modell generiert die Anfrage: „Wer war Kapitänin der ersten Damenmannschaft des Richmond Football Clubs?“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_audio": "/acl6060/audio/dev/410.wav", "src_ref": "Which has a specific semantic perturbation.", "tgt_ref": "Hier gibt es eine spezifische semantische Störung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_audio": "/acl6060/audio/dev/411.wav", "src_ref": "In a similar fashion, we also get queries like who captained Richmond's VFL Reserve team?", "tgt_ref": "In einer ähnlichen Art und Weise erhalten wir auch Abfragen, wie etwa: „Wer war Kapitän der Richmond's VFL-Reservemannschaft?“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_audio": "/acl6060/audio/dev/412.wav", "src_ref": "Or who did graham negate in the grand final last year?", "tgt_ref": "Oder: „Wen hat Graham letztes Jahr im großen Finale geschlagen?“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_audio": "/acl6060/audio/dev/413.wav", "src_ref": "Finally, we filter out a subset of the generated queries based on some desired characteristics.", "tgt_ref": "Schließlich filtern wir eine Teilmenge der generierten Abfragen basierend auf gewünschten Eigenschaften aus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_audio": "/acl6060/audio/dev/414.wav", "src_ref": "As motivated earlier, we would like to ensure that the new question is still semantically close to the original.", "tgt_ref": "Wie vorhin begründet, möchten wir sicherstellen, dass die neue Frage immer noch semantisch nah am Original ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_audio": "/acl6060/audio/dev/415.wav", "src_ref": "For filtering techniques that doesn't require additional supervision, we simply retain new questions that have a small token label edit distance from the original question.", "tgt_ref": "Bei den Filtertechniken, die keine zusätzliche Überwachung erfordern, speichern wir einfach neue Fragen, die einen kleinen Token-Label und einen Bearbeitungsabstand von der ursprünglichen Frage haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 416, "src_audio": "/acl6060/audio/dev/416.wav", "src_ref": "For example, we remove the question who did graham negate in the grand final last year?", "tgt_ref": "Wir entfernen zum Beispiel die Frage: „Wen hat Graham letztes Jahr im großen Finale geschlagen?“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 417, "src_audio": "/acl6060/audio/dev/417.wav", "src_ref": "Because it has a longer edit distance from the original question.", "tgt_ref": "Denn diese hat einen längeren Bearbeitungsabstand zur ursprünglichen Frage.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 418, "src_audio": "/acl6060/audio/dev/418.wav", "src_ref": "In our experiments, we demonstrate that this simple heuristic can be used to augment and queue training data.", "tgt_ref": "In unseren Experimenten zeigen wir, dass diese einfache Heuristik verwendet werden kann, um Trainingsdaten zu erweitern und in die Warteschlange zu stellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 419, "src_audio": "/acl6060/audio/dev/419.wav", "src_ref": "We also experiment with a filtering strategy that is based on the type of semantic perturbation.", "tgt_ref": "Wir experimentieren auch mit einer Filterstrategie, die auf der Art der semantischen Störung basiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 420, "src_audio": "/acl6060/audio/dev/420.wav", "src_ref": "To this end, we use a general purpose query decomposition framework called QED.", "tgt_ref": "Zu diesem Zweck verwenden wir einen allgemeinen Zerlegungsrahmen für die Anfrage mit dem Namen QED.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 421, "src_audio": "/acl6060/audio/dev/421.wav", "src_ref": "QED identifies two parts to the question, a predicate and a reference.", "tgt_ref": "QED identifiziert zwei Teile der Frage: ein Prädikat und eine Referenz.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 422, "src_audio": "/acl6060/audio/dev/422.wav", "src_ref": "References are noun phrases in the question that correspond to entities in the context.", "tgt_ref": "Referenzen sind Substantivgruppen in der Frage, die Entitäten im Kontext entsprechen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 423, "src_audio": "/acl6060/audio/dev/423.wav", "src_ref": "A predicate is basically the remaining portion of the question.", "tgt_ref": "Ein Prädikat ist im Grunde der verbleibende Teil der Frage.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 424, "src_audio": "/acl6060/audio/dev/424.wav", "src_ref": "For example, we are able to decompose the query who captained Richmond's first ever women's team into two references: Richmond Football Club women's team and the predicate who captained X.", "tgt_ref": "Zum Beispiel sind wir in der Lage, die Abfrage zu zerlegen: „Wer war Kapitänin der ersten Damenmannschaft des Richmond Football Clubs?“ Wir können die Frage in zwei Referenzen zerlegen: das Damenteam vom Richmond Football Club und das Prädikat X (wer war Kapitänin?).", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 425, "src_audio": "/acl6060/audio/dev/425.wav", "src_ref": "A model trained on reference predicate annotations for NQ gives us this question decomposition.", "tgt_ref": "Ein Modell, das auf Referenzen der Prädikatannotationen für NQ trainiert wurde, erlaubt uns diese Zerlegung der Frage.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 426, "src_audio": "/acl6060/audio/dev/426.wav", "src_ref": "Decomposing both the original and generated question based on QED allows us to categorize our generated counterfactuals for evaluation.", "tgt_ref": "Die Zerlegung sowohl des Originals als auch der generierten Frage basierend auf QED ermöglicht es uns, unsere generierten Kontrafakten für die Bewertung zu kategorisieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 427, "src_audio": "/acl6060/audio/dev/427.wav", "src_ref": "Specifically, we obtain two groups of questions.", "tgt_ref": "Konkret erhalten wir zwei Gruppen von Fragen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 428, "src_audio": "/acl6060/audio/dev/428.wav", "src_ref": "Those that undergo a reference change while retaining predicates, and those that undergo a predicate change and optionally add references.", "tgt_ref": "Es gibt Fragen, bei denen sich die Referenz ändert, aber die Prädikate gleichbleiben, und Fragen, bei denen sich die Prädikate ändern und optional Referenzen hinzugefügt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 429, "src_audio": "/acl6060/audio/dev/429.wav", "src_ref": "For instance, who captained Richmond's VFL reserve team is a reference change?", "tgt_ref": "Hier ist ein Beispiel für eine Änderung der Referenz: „Wer war Kapitän der Richmond's VFL-Reservemannschaft?“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 430, "src_audio": "/acl6060/audio/dev/430.wav", "src_ref": "While, who wears number nine for the club is a predicate change.", "tgt_ref": "Das ist eine Veränderung des Prädikats: „Wer trägt die Nummer neun beim Club?“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 431, "src_audio": "/acl6060/audio/dev/431.wav", "src_ref": "We now evaluate the effectiveness of RGF perturbations when augmented to training data.", "tgt_ref": "Wir bewerten nun die Effektivität von RGF-Störungen, wenn diese um die Trainingsdaten ergänzt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 432, "src_audio": "/acl6060/audio/dev/432.wav", "src_ref": "So, to effectively evaluate the effectiveness of counterfactual augmentation in particular, we experiment with two strong data augmentation baselines.", "tgt_ref": "Um insbesondere die Effektivität des kontrafaktischen Aufbaus effektiv bewerten zu können, experimentieren wir mit zwei starken Baselines des Datenaufbaus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 433, "src_audio": "/acl6060/audio/dev/433.wav", "src_ref": "The first baseline, called random answer and question generation, adds data that has no relation with the original question.", "tgt_ref": "Die erste Baseline, die als zufällige Antwort- und Fragengenerierung bezeichnet wird, fügt Daten hinzu, die keine Relation zur ursprünglichen Frage haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 434, "src_audio": "/acl6060/audio/dev/434.wav", "src_ref": "That is, passages and answers are simply randomly sampled from Wikipedia.", "tgt_ref": "Das heißt, dass Passagen und Antworten einfach zufällig aus Wikipedia entnommen werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 435, "src_audio": "/acl6060/audio/dev/435.wav", "src_ref": "This baseline basically adds more data that looks like NQ.", "tgt_ref": "Diese Baseline fügt im Grunde mehr Daten hinzu, die wie NQ aussehen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 436, "src_audio": "/acl6060/audio/dev/436.wav", "src_ref": "With the second baseline gold answer and question generation, we specifically update the retrieval portion of our method.", "tgt_ref": "Mit der zweiten Baseline, der Goldantwort und der Fragengeneration, aktualisieren wir speziell den Retrieval bei unserer Methode.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 437, "src_audio": "/acl6060/audio/dev/437.wav", "src_ref": "Here, alternate answers are just chosen from the same passage that contained the gold answer.", "tgt_ref": "Hier werden alternative Antworten nur aus der gleichen Passage ausgewählt, welche die Goldantwort enthält.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 438, "src_audio": "/acl6060/audio/dev/438.wav", "src_ref": "How base how do the baselines and RGF ah augmentation perform on reading comprehension where the model has access to question and context?", "tgt_ref": "Welche Leistung erbringen die Baselines, RGF und der Aufbau beim Leseverständnis, wo das Modell Zugriff auf Frage und Kontext hat?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 439, "src_audio": "/acl6060/audio/dev/439.wav", "src_ref": "We experiment with six out of domain datasets and present results here, where data is the training data is doubled in augmentation.", "tgt_ref": "Wir experimentieren mit sechs von den Datensätzen der Domäne und präsentieren hier die Ergebnisse, wobei es bei den Daten um die Trainingsdaten geht und beim Aufbau verdoppelt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 440, "src_audio": "/acl6060/audio/dev/440.wav", "src_ref": "We find that both data augmentation baselines are not able to improve our domain generalization.", "tgt_ref": "Wir stellten fest, dass beide Baselines des Datenaufbaus nicht in der Lage sind, unsere Verallgemeinerung der Domäne zu verbessern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 441, "src_audio": "/acl6060/audio/dev/441.wav", "src_ref": "In fact, an ensemble of six models trained on the original data seems to be the most competitive baseline.", "tgt_ref": "Tatsächlich scheint ein Ensemble von sechs Modellen, die mit den ursprünglichen Daten trainiert wurden, die wettbewerbsfähigste Baseline zu sein.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 442, "src_audio": "/acl6060/audio/dev/442.wav", "src_ref": "Comparing against that baseline, we find that RGF counterfactuals are able to improve out of domain performance while maintaining in domain performance.", "tgt_ref": "Im Vergleich zu dieser Baseline stellten wir fest, dass RGF-Kontrafakten in der Lage sind, die Leistung außerhalb der Domäne zu verbessern, während die Leistung innerhalb der Domäne beibehalten wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 443, "src_audio": "/acl6060/audio/dev/443.wav", "src_ref": "This suggests that filling in the reasoning gaps of the model via counterfactual augmentation is more effective than adding more data from the training distribution.", "tgt_ref": "Dies deutet darauf hin, dass das Füllen der Argumentationslücken beim Modell über einen kontrafaktischen Aufbau effektiver ist als mehr Daten aus der Training-Verteilung hinzuzufügen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 444, "src_audio": "/acl6060/audio/dev/444.wav", "src_ref": "Furthermore, we find that using retrieval to sample alternative outcomes or answers is important for effective CDA.", "tgt_ref": "Darüber hinaus fanden wir heraus, dass die Verwendung von Retrievals zur Erprobung alternativer Ergebnisse oder Antworten für effektive CDA wichtig ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 445, "src_audio": "/acl6060/audio/dev/445.wav", "src_ref": "We also experiment with open domain QA setting where the model only sees the question and once again we evaluate on four out of domain datasets.", "tgt_ref": "Wir experimentieren auch mit einer offenen Domäne-QA -Einstellung, bei der das Modell nur die Frage sieht. Wir bewerten wieder vier von den Datensätzen der Domäne.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 446, "src_audio": "/acl6060/audio/dev/446.wav", "src_ref": "We find that baseline models are not as effective for out of domain generalization.", "tgt_ref": "Wir stellten fest, dass die Baseline-Modelle nicht so effektiv für die Verallgemeinerung der Domäne sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 447, "src_audio": "/acl6060/audio/dev/447.wav", "src_ref": "However, data augmentation with RGF shows more significant improvements.", "tgt_ref": "Allerdings zeigt der Datenaufbau mit RGF signifikantere Verbesserungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 448, "src_audio": "/acl6060/audio/dev/448.wav", "src_ref": "We even improve in the in domain NQ dataset.", "tgt_ref": "Wir verbessern uns sogar in der Domäne NQ-Datensatz.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 449, "src_audio": "/acl6060/audio/dev/449.wav", "src_ref": "We hypothesized that the counterfactual data augmentation aids the model in learning better query encodings for very similar queries.", "tgt_ref": "Wir haben angenommen, dass der kontrafaktische Datenaufbau das Modell beim Lernen von besseren Abfragekodierungen für sehr ähnliche Abfragen unterstützt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 450, "src_audio": "/acl6060/audio/dev/450.wav", "src_ref": "Finally, we also evaluate on the model's ability to improve consistency in the local neighborhood of the original question.", "tgt_ref": "Schließlich bewerten wir auch die Fähigkeit des Modells, die Einheitlichkeit in der lokalen Nachbarschaft der ursprünglichen Frage zu verbessern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 451, "src_audio": "/acl6060/audio/dev/451.wav", "src_ref": "Consistency measures the proportion of questions correctly answered by the model where both the original and the counterfactual query are correctly answered.", "tgt_ref": "Die Einheitlichkeit misst den Anteil der vom Modell korrekt beantworteten Fragen, bei denen sowohl das Original als auch die kontrafaktische Abfrage korrekt beantwortet werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 452, "src_audio": "/acl6060/audio/dev/452.wav", "src_ref": "This explicitly helps us to measure the model's robustness to small perturbations in the neighborhood of the original input.", "tgt_ref": "Dies hilft uns explizit, die Robustheit des Modells bei kleinen Störungen in der Nähe der ursprünglichen Eingabe zu messen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 453, "src_audio": "/acl6060/audio/dev/453.wav", "src_ref": "We experiment with five datasets which contain pairs of questions that are semantically close to each other.", "tgt_ref": "Wir experimentieren mit fünf Datensätzen, die Paare von Fragen enthalten, die semantisch nahe beieinander liegen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 454, "src_audio": "/acl6060/audio/dev/454.wav", "src_ref": "Apart from the three datasets AQA, AmbigQA and QUOREF-Contrast set that are already available, we also evaluate on RGF counterfactuals that are paired with original NQ questions based on whether they underwent a predicate change or reference change.", "tgt_ref": "Abgesehen von den drei Datensätzen AQA, AmbigQA und den QUOREF-Kontrastsätzen, die bereits verfügbar sind, bewerten wir auch RGF-Kontrafakten. Diese sind mit ursprünglichen NQ-Fragen gepaart, basierend darauf, ob sie von einer Prädikat- oder Referenzänderung betroffen waren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 455, "src_audio": "/acl6060/audio/dev/455.wav", "src_ref": "These subsets were annotated in-house to eliminate noise and are provided as a resource.", "tgt_ref": "Diese Teilmengen wurden intern annotiert, um Qualitätsmängel zu eliminieren. Sie werden als Ressource bereitgestellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 456, "src_audio": "/acl6060/audio/dev/456.wav", "src_ref": "All baselines are unable to significantly improve consistency with the ensemble model improving consistency by a small margin.", "tgt_ref": "Alle Baselines können die Einheitlichkeit signifikant nicht verbessern. Das Ensemble der Modelle kann die Einheitlichkeit geringfügig verbessern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 457, "src_audio": "/acl6060/audio/dev/457.wav", "src_ref": "However, RGF counterfactual augmentation has impressive gains in consistency both on prior datasets and the two subsets we curated for reference and predicate perturbations.", "tgt_ref": "Der kontrafaktische Aufbau der RGF kann jedoch eine beeindruckende Steigerung der Einheitlichkeit sowohl bei früheren Datensätzen als auch bei den beiden Teilmengen, die wir für Referenz- und Prädikat-Störungen ausgewählt haben, aufweisen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 458, "src_audio": "/acl6060/audio/dev/458.wav", "src_ref": "Note that the augmented RGF data is not biased by perturbation type, only the evaluation sets are.", "tgt_ref": "Beachten Sie, dass die erweiterten RGF-Daten nicht durch den Störungstyp verfälscht werden, sondern nur durch die Evaluationssätze.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 459, "src_audio": "/acl6060/audio/dev/459.wav", "src_ref": "In fact, a qualitative inspection of the kinds of counterfactuals generated show that the generated questions contain several diverse perturbations.", "tgt_ref": "Tatsächlich zeigt eine qualitative Überprüfung der verschiedenen Arten von Kontrafaktoren, dass die generierten Fragen mehrere unterschiedliche Störungen enthalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 460, "src_audio": "/acl6060/audio/dev/460.wav", "src_ref": "For instance, this original question on the population of Walnut Grove, Minnesota is perturbed along different dimensions like town, state, country, and along different predicates like location, poverty, number of schools.", "tgt_ref": "Zum Beispiel ist diese ursprüngliche Frage über die Bevölkerung von Walnut Grove in Minnesota gestört. Diese Störung betrifft verschiedene Dimensionen wie Stadt, Bundesland, Land und verschiedene Prädikate wie Lage, Armut, Anzahl von Schulen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 461, "src_audio": "/acl6060/audio/dev/461.wav", "src_ref": "Audio of perturbations are context specific.", "tgt_ref": "Das Audio von Störungen ist kontextspezifisch.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 462, "src_audio": "/acl6060/audio/dev/462.wav", "src_ref": "For example, for this other question about the Wimbledon ah singles tournament, the perturbation is along type of game, type of tournament, or the game outcome.", "tgt_ref": "Bei dieser anderen Frage über das Einzelturnier in Wimbledon handelt die Störung von der Art des Spiels, der Art des Turniers oder des Spielergebnisses.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 463, "src_audio": "/acl6060/audio/dev/463.wav", "src_ref": "Final takeaways; we tackle the task of counterfactual data augmentation and perturbations for information seeking queries and tackle its unique challenges via a reversal of the generation approach, over generate using near misses of the model and filter based on perturbation type or minimality.", "tgt_ref": "Abschließende Erkenntnisse: Wir befassen uns mit der Aufgabe des kontrafaktischen Datenaufbaus und Störungen bei der Information. Wir suchen nach Abfragen und bewältigen deren einzigartige Herausforderungen durch eine Umkehrung des Generierungsansatzes. Wir übergenerieren mithilfe von Near-Misses des Modells und filtern basierend auf dem Störungstyp oder der Minimalität.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 464, "src_audio": "/acl6060/audio/dev/464.wav", "src_ref": "We find that this technique requires no additional supervision and the examples are labeled for augmentation.", "tgt_ref": "Wir stellten fest, dass diese Technik keiner zusätzlichen Überwachung bedarf und die Beispiele für den Aufbau markiert sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 465, "src_audio": "/acl6060/audio/dev/465.wav", "src_ref": "Augmentation improves out of domain generalization and neighborhood consistency.", "tgt_ref": "Der Aufbau verbessert sich dank der Domäneverallgemeinerung und der Konsistenz der Nachbarschaft.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 31, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 466, "src_audio": "/acl6060/audio/dev/466.wav", "src_ref": "And we find that RGF counterfactuals are semantically diverse without introducing bias during augmentation.", "tgt_ref": "Zudem stellten wir fest, dass die RGF-Kontrafakten semantisch divers sind, ohne dass Verzerrungen während des Aufbaus eingeführt wurden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 31, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 467, "src_audio": "/acl6060/audio/dev/467.wav", "src_ref": "Thank you.", "tgt_ref": "Vielen Dank!", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 31, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 468, "src_audio": "/acl6060/audio/eval/468.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "tgt_ref": "Hallo zusammen. Heute werde ich unsere Forschungsarbeit Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction vorstellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 469, "src_audio": "/acl6060/audio/eval/469.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "tgt_ref": "Ich bin Allan vom ByteDance AI Lab, und dies ist eine gemeinsame Arbeit mit Jierui Li von der University of Texas in Austin und Wei Lu von SUTD.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 470, "src_audio": "/acl6060/audio/eval/470.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "tgt_ref": "Zunächst möchte ich über unsere Motivation für das Argumentieren sprechen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 471, "src_audio": "/acl6060/audio/eval/471.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "tgt_ref": "Deshalb zeigen wir hier ein Beispiel, bei dem mehrstufiges Argumentieren hilfreich ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 472, "src_audio": "/acl6060/audio/eval/472.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "tgt_ref": "Diese Abbildung stammt aus dem PaLM-Paper, in dem sie Prompting durchführen, um das Netzwerkproblem in einem Few-Shot-Lernszenario zu lösen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 473, "src_audio": "/acl6060/audio/eval/473.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "tgt_ref": "Auf der linken Seite können wir also sehen, dass wenn einige Beispiele nur aus Frage und Antworten bestehen, dann bekommen wir nicht die richtigen Antworten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 474, "src_audio": "/acl6060/audio/eval/474.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "tgt_ref": "Wenn wir jedoch eine weitere Argumentationsbeschreibung hinzufügen, ist das Modell in der Lage, die Argumentationsbeschreibung vorherzusagen und hier auch eine korrekte Vorhersage zu treffen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 475, "src_audio": "/acl6060/audio/eval/475.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "tgt_ref": "Es ist also gut, eine interpretierbare mehrstufige Argumentation als Ergebnis zu haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 476, "src_audio": "/acl6060/audio/eval/476.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "tgt_ref": "Wir denken auch, dass mathematische Wortprobleme eine einfache Anwendung sind, um solche Argumentationsfähigkeiten zu bewerten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 477, "src_audio": "/acl6060/audio/eval/477.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "tgt_ref": "In unserem Problem-Setup müssen wir also angesichts der Fragen diese Frage lösen und die numerischen Antworten erhalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 478, "src_audio": "/acl6060/audio/eval/478.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "tgt_ref": "In unseren Datensätzen finden wir auch den mathematischen Ausdruck, der uns zu dieser bestimmten Antwort führt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 479, "src_audio": "/acl6060/audio/eval/479.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "tgt_ref": "Es gelten also auch hier bestimmte Annahmen wie in früheren Arbeiten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 480, "src_audio": "/acl6060/audio/eval/480.wav", "src_ref": "We assume the precision of quantities are known.", "tgt_ref": "Wir gehen davon aus, dass die Genauigkeit der Mengen bekannt ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 481, "src_audio": "/acl6060/audio/eval/481.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "tgt_ref": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentialrechnung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 482, "src_audio": "/acl6060/audio/eval/482.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "tgt_ref": "Darüber hinaus können komplizierte Operatoren in diese Grundoperatoren zerlegt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 483, "src_audio": "/acl6060/audio/eval/483.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "tgt_ref": "Die früheren Arbeiten zum Lösen von mathematischen Wortproblemen lassen sich also in Sequenz-zu-Sequenz- und Sequenz-zu-Baum-Modell einteilen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 484, "src_audio": "/acl6060/audio/eval/484.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "tgt_ref": "Das traditionelle Sequenz-zu-Sequenz-Modell wandelt also den Ausdruck in eine spezifische Sequenz für die Generierung um.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 485, "src_audio": "/acl6060/audio/eval/485.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "tgt_ref": "Es ist ziemlich einfach zu implementieren und kann für viele verschiedene komplizierte Probleme verallgemeinert werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 486, "src_audio": "/acl6060/audio/eval/486.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "tgt_ref": "Die Nachteile sind jedoch, dass die Leistung im Allgemeinen nicht besser ist als die des strukturierten Modells und dass es an Interpretierbarkeit für Vorhersagen mangelt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 487, "src_audio": "/acl6060/audio/eval/487.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "tgt_ref": "Aber eigentlich ist diese Richtung immer noch recht beliebt wegen des Transformermodells.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 488, "src_audio": "/acl6060/audio/eval/488.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "tgt_ref": "In baumbasierten Modellen strukturieren wir diese Ausdrücke in Baumform und folgen einem geordneten Traversal in Baumgenerationen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 489, "src_audio": "/acl6060/audio/eval/489.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "tgt_ref": "Hier fahren wir also fort, die Operatoren zu generieren, bis wir die Blätter erreichen, die die Mengen darstellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 490, "src_audio": "/acl6060/audio/eval/490.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "tgt_ref": "Das Gute daran ist, dass wir dadurch diese binäre Baumstruktur erhalten. Sie ist eigentlich ziemlich kontraintuitiv, weil wir zuerst den Operator und dann am Ende die Mengen generieren müssen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 491, "src_audio": "/acl6060/audio/eval/491.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "tgt_ref": "Zudem enthält sie auch einige sich wiederholende Berechnungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 492, "src_audio": "/acl6060/audio/eval/492.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "tgt_ref": "Wenn wir uns also diesen Ausdruck ansehen, wird 8 x 3 + 3 eigentlich zweimal generiert, aber eigentlich sollten wir die Ergebnisse wiederverwenden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 493, "src_audio": "/acl6060/audio/eval/493.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "tgt_ref": "In unserem vorgeschlagenen Ansatz wollen wir diese Probleme schrittweise und auf interpretierbare Art und Weise lösen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 494, "src_audio": "/acl6060/audio/eval/494.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "tgt_ref": "Hier im zweiten Schritt zum Beispiel können wir diese Teiler erhalten, was 27 ergibt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 495, "src_audio": "/acl6060/audio/eval/495.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "tgt_ref": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um die relevanten Inhalte zu finden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 496, "src_audio": "/acl6060/audio/eval/496.wav", "src_ref": "And in these steps we obtain the divisors.", "tgt_ref": "In diesen Schritten erhalten wir die Teiler.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 497, "src_audio": "/acl6060/audio/eval/497.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "tgt_ref": "Und in diesem dritten Schritt erhalten wir dann den Quotienten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 498, "src_audio": "/acl6060/audio/eval/498.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "tgt_ref": "Okay. Nach diesen drei Schritten können wir die Ergebnisse des zweiten Schritts wiederverwenden, dann die Ergebnisse des vierten Schritts erhalten und schließlich die Dividenden erhalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 499, "src_audio": "/acl6060/audio/eval/499.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "tgt_ref": "Hier wird also der gesamte Ausdruck direkt generiert und nicht nur ein einzelner Operator oder eine Menge.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 500, "src_audio": "/acl6060/audio/eval/500.wav", "src_ref": "So this makes the process more accurate.", "tgt_ref": "Dadurch wird der Prozess genauer.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 501, "src_audio": "/acl6060/audio/eval/501.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "tgt_ref": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Mengen, die in den Fragen vorgestellt werden, und schließen auch mit einer Konstante als Anfangszustand.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 502, "src_audio": "/acl6060/audio/eval/502.wav", "src_ref": "So, the expression is represented by e i j o p.", "tgt_ref": "Der Ausdruck wird also durch e i j o p dargestellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 503, "src_audio": "/acl6060/audio/eval/503.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "tgt_ref": "Wir führen den Operator von q_i nach q_j aus, und dieser Ausdruck ist tatsächlich geregelt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 504, "src_audio": "/acl6060/audio/eval/504.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "tgt_ref": "Wir haben hier also auch eine Subtraktion mit Wörtern, um die umgekehrte Richtung darzustellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 505, "src_audio": "/acl6060/audio/eval/505.wav", "src_ref": "This is quite similar to relation extraction.", "tgt_ref": "Dies ist der Beziehungsextraktion recht ähnlich.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 506, "src_audio": "/acl6060/audio/eval/506.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "tgt_ref": "In einem formalen deduktiven System wenden wir also in einem Zeitschritt t den Operator zwischen dem Paar q_i und q_j an und erhalten dann diesen neuen Ausdruck.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 507, "src_audio": "/acl6060/audio/eval/507.wav", "src_ref": "We add it to the next state to become a new quantity.", "tgt_ref": "Wir fügen ihn dem nächsten Zustand hinzu, um eine neue Menge zu erhalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 508, "src_audio": "/acl6060/audio/eval/508.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "tgt_ref": "Diese Folien veranschaulichen also die Entwicklung des Zustands, wobei wir dem aktuellen Zustand immer neue Ausdrücke hinzufügen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 509, "src_audio": "/acl6060/audio/eval/509.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "tgt_ref": "In unseren Modellimplementierungen verwenden wir also zunächst ein vortrainiertes Sprachmodell, bei dem es sich um BERTs oder Robertas handeln kann, und dann kodieren wir den Satz und erhalten diese Mengendarstellungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 510, "src_audio": "/acl6060/audio/eval/510.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "tgt_ref": "Sobald wir also die Mengendarstellungen haben, können wir mit der Inferenz beginnen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 511, "src_audio": "/acl6060/audio/eval/511.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "tgt_ref": "Hier zeigen wir ein Beispiel für q_1, um die Darstellung für q_2 geteilt durch q_2 und dann mal q_3 zu erhalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 512, "src_audio": "/acl6060/audio/eval/512.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "tgt_ref": "Zunächst erhalten wir die Paardarstellung, die im Grunde nur die Verkettung zwischen q_1 und q_2 ist, und dann wenden wir ein Feedforward-Netzwerk an, das durch den Operator parametrisiert ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 513, "src_audio": "/acl6060/audio/eval/513.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "tgt_ref": "Und dann erhalten wir schließlich die Ausdrucksdarstellung q_1 geteilt durch q_2.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 514, "src_audio": "/acl6060/audio/eval/514.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "tgt_ref": "Aber in der Praxis könnten wir in der Inferenzphase auch den falschen Ausdruck erhalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 515, "src_audio": "/acl6060/audio/eval/515.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "tgt_ref": "Hier sind also alle möglichen Ausdrücke gleich dem Dreifachen der Anzahl der Operatoren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 516, "src_audio": "/acl6060/audio/eval/516.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "tgt_ref": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu kontrollieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 517, "src_audio": "/acl6060/audio/eval/517.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "tgt_ref": "Wenn dieser Ausdruck zum Beispiel nicht erlaubt ist, können wir ihn einfach aus unserem Suchraum entfernen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 518, "src_audio": "/acl6060/audio/eval/518.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "tgt_ref": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir nur eine Menge mehr haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 519, "src_audio": "/acl6060/audio/eval/519.wav", "src_ref": "So this quantity come from the previous calculated expression.", "tgt_ref": "Diese Menge stammt also aus dem vorherigen berechneten Ausdruck.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 520, "src_audio": "/acl6060/audio/eval/520.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "tgt_ref": "So können wir schließlich diesen endgültigen Ausdruck q_3 mal q_4 erhalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 521, "src_audio": "/acl6060/audio/eval/521.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "tgt_ref": "Wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke anders ist als beim vorherigen Schritt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 522, "src_audio": "/acl6060/audio/eval/522.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "tgt_ref": "Ein solcher Unterschied erschwert die Anwendung von einer Beam Search, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgewogen ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 523, "src_audio": "/acl6060/audio/eval/523.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "tgt_ref": "Das Trainingsverfahren ist also ähnlich dem Training eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust bei jedem Zeitschritt optimieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 524, "src_audio": "/acl6060/audio/eval/524.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "tgt_ref": "Auch hier verwenden wir dieses Tau, um darzustellen, wann wir diesen Generierungsprozess beenden sollten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 525, "src_audio": "/acl6060/audio/eval/525.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "tgt_ref": "Hier unterscheidet sich der Raum von Sequenz zu Sequenz, weil der Raum bei jedem Zeitschritt anders ist, während im traditionellen Sequenz-zu-Sequenz-Modell dies die Anzahl des Vokabulars ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 526, "src_audio": "/acl6060/audio/eval/526.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "tgt_ref": "Es erlaubt uns auch, bestimmte Beschränkungen aus dem Vorwissen aufzuerlegen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 527, "src_audio": "/acl6060/audio/eval/527.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "tgt_ref": "Daher führen wir Experimente mit den häufig verwendeten Datensätzen der mathematischen Wortprobleme durch, MAWPS, Math23K, MathQA und SVAMP.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 528, "src_audio": "/acl6060/audio/eval/528.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "tgt_ref": "Hier zeigen wir kurz die Ergebnisse im Vergleich zu den bisherigen besten Ansätzen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 529, "src_audio": "/acl6060/audio/eval/529.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "tgt_ref": "Unsere leistungsstärkste Variante ist also Roberta-DeductiveReasoner.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 530, "src_audio": "/acl6060/audio/eval/530.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "tgt_ref": "Tatsächlich verwenden wir keine Beam Search, im Gegensatz zu allen früheren Ansätzen, die Beam Search verwendet haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 531, "src_audio": "/acl6060/audio/eval/531.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "tgt_ref": "Okay. Daher sind die besten Ansätze oft baumbasierte Modelle.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 532, "src_audio": "/acl6060/audio/eval/532.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "tgt_ref": "Insgesamt ist unser Reasoner also in der Lage, dieses baumbasierte Modell signifikant zu übertreffen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 533, "src_audio": "/acl6060/audio/eval/533.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "tgt_ref": "Aber wir können sehen, dass die absoluten Zahlen bei MathQA oder SVAMP nicht wirklich hoch sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 534, "src_audio": "/acl6060/audio/eval/534.wav", "src_ref": "So we further investigate the results on SVAMP.", "tgt_ref": "Deshalb untersuchen wir die Ergebnisse bei SVAMP weiter.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 535, "src_audio": "/acl6060/audio/eval/535.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "tgt_ref": "Dieser Datensatz ist eine Herausforderung, weil der Autor versucht hat, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. das Hinzufügen irrelevanter Informationen und zusätzlicher Mengen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 536, "src_audio": "/acl6060/audio/eval/536.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "tgt_ref": "In unserer Vorhersage stellen wir also fest, dass einige der Zwischenwerte eigentlich negativ sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 537, "src_audio": "/acl6060/audio/eval/537.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "tgt_ref": "Zum Beispiel geht es in diesen Fragen darum, wie viele Äpfel Jake hat.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 538, "src_audio": "/acl6060/audio/eval/538.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "tgt_ref": "Aber wir haben einige zusätzliche Informationen wie 17 Bilder weniger, und Steven hat acht Bilder, was völlig irrelevant ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 539, "src_audio": "/acl6060/audio/eval/539.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "tgt_ref": "Unser Modell macht also eine Vorhersage wie diese, die negative Werte ergibt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 540, "src_audio": "/acl6060/audio/eval/540.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "tgt_ref": "Wir stellen fest, dass diese beiden Ausdrücke tatsächlich ähnliche Werte haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 541, "src_audio": "/acl6060/audio/eval/541.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "tgt_ref": "Wir können also diesen Suchraum eingrenzen, indem wir die negativen Ergebnisse entfernen, damit die Antwort richtig ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 542, "src_audio": "/acl6060/audio/eval/542.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "tgt_ref": "Wir stellen also fest, dass eine solche Bedingung für einige Modelle tatsächlich eine erhebliche Verbesserung darstellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 543, "src_audio": "/acl6060/audio/eval/543.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "tgt_ref": "Bei BERT haben wir uns zum Beispiel um sieben Punkte verbessert und beim Roberta-Basismodell haben wir uns sogar um zwei Punkte verbessert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 544, "src_audio": "/acl6060/audio/eval/544.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "tgt_ref": "Ein besseres Sprachmodell hat also bessere Sprachverständnisfähigkeiten, sodass die Zahl hier höher bei Roberta und niedriger bei BERT ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 545, "src_audio": "/acl6060/audio/eval/545.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "tgt_ref": "Wir versuchen auch, die Schwierigkeiten hinter all diesen Datensätzen zu analysieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 546, "src_audio": "/acl6060/audio/eval/546.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "tgt_ref": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Informationen betrachtet werden kann.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 547, "src_audio": "/acl6060/audio/eval/547.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "tgt_ref": "Hier können wir also sehen, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben, und der SVAMP-Datensatz hat den größten Anteil.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 548, "src_audio": "/acl6060/audio/eval/548.wav", "src_ref": "And here we also show the overall performance.", "tgt_ref": "Hier zeigen wir auch die Gesamtleistung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 549, "src_audio": "/acl6060/audio/eval/549.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "tgt_ref": "Bei den Proben ohne ungenutzte Mengen ist die Leistung sogar höher als die Gesamtleistung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 550, "src_audio": "/acl6060/audio/eval/550.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "tgt_ref": "Aber bei diesen Proben mit ungenutzten Mengen ist sie eigentlich viel schlechter als die Gesamtleistung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 551, "src_audio": "/acl6060/audio/eval/551.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "tgt_ref": "Bei MAWPS haben wir nicht wirklich viele Testfälle, also ignoriere ich diesen Teil einfach.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 552, "src_audio": "/acl6060/audio/eval/552.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "tgt_ref": "Schließlich wollen wir die Interpretierbarkeit anhand eines Frage-Störungsbeispiels zeigen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 553, "src_audio": "/acl6060/audio/eval/553.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "tgt_ref": "Hier macht unser Modell also tatsächlich eine falsche Vorhersage im ersten Schritt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 554, "src_audio": "/acl6060/audio/eval/554.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "tgt_ref": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren. Okay.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 555, "src_audio": "/acl6060/audio/eval/555.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "tgt_ref": "Wir denken also, dass dieser Satz das Modell zu falschen Vorhersagen verleiten könnte.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 556, "src_audio": "/acl6060/audio/eval/556.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "tgt_ref": "Hier führt eine weitere 35 dazu, dass das Modell denkt, dass es ein Additionsoperator sein sollte.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 557, "src_audio": "/acl6060/audio/eval/557.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "tgt_ref": "Wir versuchen also den Satz so umzuformulieren, dass die Anzahl der Birnbäume um 35 weniger als die der Apfelbäume ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 558, "src_audio": "/acl6060/audio/eval/558.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "tgt_ref": "Wir sorgen also dafür, dass eine genauere Semantik vermittelt wird, sodass das Modell in der Lage ist, die Vorhersage korrekt zu treffen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 559, "src_audio": "/acl6060/audio/eval/559.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "tgt_ref": "Diese Studie zeigt also, wie uns die interpretierbaren Vorhersagen helfen, das Modellverhalten zu verstehen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 560, "src_audio": "/acl6060/audio/eval/560.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "tgt_ref": "Um unsere Arbeit abzuschließen: Zunächst ist unser Modell tatsächlich ziemlich effizient.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 561, "src_audio": "/acl6060/audio/eval/561.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "tgt_ref": "Wir sind in der Lage, ein interpretierbares Lösungsverfahren anzubieten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 562, "src_audio": "/acl6060/audio/eval/562.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "tgt_ref": "Wir können einfach einiges Vorwissen als Bedingung einbeziehen, was zur Verbesserung der Leistung beitragen kann.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 563, "src_audio": "/acl6060/audio/eval/563.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "tgt_ref": "Schließlich gilt der zugrundeliegende Mechanismus nicht nur für das Lösen von Netzwerkproblemen, sondern auch für andere Aufgaben, die mehrstufiges Argumentieren erfordern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 564, "src_audio": "/acl6060/audio/eval/564.wav", "src_ref": "We also have certain limitations.", "tgt_ref": "Auch sind uns gewisse Grenzen gesetzt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 565, "src_audio": "/acl6060/audio/eval/565.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "tgt_ref": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 566, "src_audio": "/acl6060/audio/eval/566.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "tgt_ref": "Wie bereits erwähnt ist es zudem aufgrund der unausgewogenen Wahrscheinlichkeitsverteilung zwischen den verschiedenen Zeitschritten eine ziemliche Herausforderung, die Beam Search-Strategie anzuwenden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 567, "src_audio": "/acl6060/audio/eval/567.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "Wir sind am Ende des Vortrags angekommen und freuen uns auf etwaige Fragen. Vielen Dank!", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 568, "src_audio": "/acl6060/audio/eval/568.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "tgt_ref": "Hallo, mein Name ist Antoine und ich bin von der Universität Maastricht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 569, "src_audio": "/acl6060/audio/eval/569.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "tgt_ref": "Ich werde meine gemeinsame Arbeit mit Jerry vorstellen, bei der es um einen neuen Datensatz für das Retrieval von Gesetzesartikeln geht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 570, "src_audio": "/acl6060/audio/eval/570.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "tgt_ref": "Rechtsfragen sind ein wesentlicher Bestandteil des Lebens vieler Menschen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 571, "src_audio": "/acl6060/audio/eval/571.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "tgt_ref": "Aber die Mehrheit der Bürger verfügt nur über wenig Wissen über ihre Rechte und grundlegende rechtliche Verfahren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 572, "src_audio": "/acl6060/audio/eval/572.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "tgt_ref": "Dies hat zur Folge, dass viele schutzbedürftige Bürger, die sich die kostspielige Hilfe eines Rechtsexperten nicht leisten können, schutzlos bleiben oder schlimmstenfalls ausgebeutet werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 573, "src_audio": "/acl6060/audio/eval/573.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "tgt_ref": "Unsere Arbeit zielt darauf ab, die Kluft zwischen den Menschen und dem Gesetz zu überbrücken, indem ein effektives Retrieval-System für Gesetzesartikel entwickelt wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 574, "src_audio": "/acl6060/audio/eval/574.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "tgt_ref": "Ein solches System könnte einen kostenlosen professionellen Rechtshilfedienst für unerfahrene Menschen anbieten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 575, "src_audio": "/acl6060/audio/eval/575.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "tgt_ref": "Bevor wir uns dem Hauptbeitrag dieser Arbeit widmen, wollen wir zunächst das Problem des Retrievals von Gesetzesartikeln beschreiben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 576, "src_audio": "/acl6060/audio/eval/576.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "tgt_ref": "Eine einfache Frage zu einer Rechtsangelegenheit wäre: „Was riskiere ich, wenn ich das Berufsgeheimnis verletze?“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 577, "src_audio": "/acl6060/audio/eval/577.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "tgt_ref": "Hier wird ein Modell benötigt, um alle relevanten Gesetzesartikel aus einem großen Bestand an Rechtsvorschriften abzurufen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 578, "src_audio": "/acl6060/audio/eval/578.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "tgt_ref": "Diese Informationsbeschaffungsaufgabe bringt eine Reihe von Herausforderungen mit sich.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 579, "src_audio": "/acl6060/audio/eval/579.wav", "src_ref": "First, it deals with two types of language.", "tgt_ref": "Erstens: Es geht um zwei Arten von Sprache.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 580, "src_audio": "/acl6060/audio/eval/580.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "tgt_ref": "Die gemeinsame natürliche Sprache für die Fragen und die komplexe juristische Sprache für die Gesetze.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 581, "src_audio": "/acl6060/audio/eval/581.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "tgt_ref": "Dieser Unterschied bei den Sprachverteilungen macht es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die der Terminologie der Gesetze entspricht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 582, "src_audio": "/acl6060/audio/eval/582.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "tgt_ref": "Außerdem ist das Recht keine Ansammlung unabhängiger Artikel, die für sich allein als vollständige Informationsquelle betrachtet werden können, anders als beispielsweise Nachrichten oder Rezepte.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 583, "src_audio": "/acl6060/audio/eval/583.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "tgt_ref": "Vielmehr handelt es sich um eine strukturierte Sammlung von Rechtsvorschriften, die nur im Gesamtkontext, d. h. zusammen mit den ergänzenden Informationen aus den Nachbarartikeln, den Bereichen und Teilbereichen, denen sie angehören, und ihrer Stellung im Aufbau des Gesetzes, eine vollständige Bedeutung haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 584, "src_audio": "/acl6060/audio/eval/584.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "tgt_ref": "Schließlich handelt es sich bei den Gesetzesartikeln nicht um kleine Absätze, die in den meisten Retrieval-Arbeiten die typische Retrieval-Einheit darstellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 585, "src_audio": "/acl6060/audio/eval/585.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "tgt_ref": "Hier gibt es lange Dokumente, die bis zu 6.000 Wörter umfassen können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 586, "src_audio": "/acl6060/audio/eval/586.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "tgt_ref": "Die jüngsten Fortschritte im Bereich NLP haben großes Interesse an vielen juristischen Aufgaben geweckt, z. B. an der Vorhersage juristischer Urteile oder der automatisierten Prüfung von Verträgen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 587, "src_audio": "/acl6060/audio/eval/587.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "tgt_ref": "Doch das Retrieval von Gesetzesartikeln ist aufgrund des Mangels an großen und qualitativ hochwertig markierten Datensätzen weitgehend unberührt geblieben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 588, "src_audio": "/acl6060/audio/eval/588.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "tgt_ref": "In dieser Arbeit stellen wir einen neuen Datensatz in der französischen Muttersprache vor, mit dem wir Retrievalmodelle untersuchen und analysieren, ob sie bei der Aufgabe der Suche nach Gesetzesartikeln an die Effizienz und Zuverlässigkeit eines Rechtsexperten rankommen können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 589, "src_audio": "/acl6060/audio/eval/589.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "tgt_ref": "Unser belgischer Datensatz für das Retrieval von Gesetzesartikeln, BSARD, besteht aus mehr als 1.100 juristischen Fragen, die von belgischen Bürgern gestellt wurden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 590, "src_audio": "/acl6060/audio/eval/590.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "tgt_ref": "Diese Fragen decken ein breites Spektrum an Themen ab, von Familie, Wohnen, Geld bis hin zu Arbeit und sozialer Sicherheit.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 591, "src_audio": "/acl6060/audio/eval/591.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "tgt_ref": "Jede von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als 22.600 Rechtsartikeln aus belgischen Gesetzbüchern markiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 592, "src_audio": "/acl6060/audio/eval/592.wav", "src_ref": "Let's now talk about how we collected this dataset.", "tgt_ref": "Lassen Sie uns nun darüber sprechen, wie wir diesen Datensatz gesammelt haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 593, "src_audio": "/acl6060/audio/eval/593.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "tgt_ref": "Zunächst haben wir einen großen Korpus von Rechtsartikeln zusammengestellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 594, "src_audio": "/acl6060/audio/eval/594.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "tgt_ref": "Wir haben 32 öffentlich zugängliche belgische Gesetzbücher berücksichtigt und alle Artikel sowie die entsprechenden Abschnittsüberschriften extrahiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 595, "src_audio": "/acl6060/audio/eval/595.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "tgt_ref": "Dann haben wir rechtliche Fragen mit Verweisen auf einschlägige Gesetze zusammengestellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 596, "src_audio": "/acl6060/audio/eval/596.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "tgt_ref": "Zu diesem Zweck arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa 4.000 E-Mails von belgischen Bürgern erhält, die um Rat in einer persönlichen Rechtsangelegenheit bitten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 597, "src_audio": "/acl6060/audio/eval/597.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "tgt_ref": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team aus erfahrenen Juristen die häufigsten Rechtsangelegenheiten der Belgier behandelt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 598, "src_audio": "/acl6060/audio/eval/598.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "tgt_ref": "Wir haben Tausende von Fragen gesammelt und mit Kategorien, Unterkategorien und Verweisen auf einschlägige Gesetze annotiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 599, "src_audio": "/acl6060/audio/eval/599.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "tgt_ref": "Schließlich haben wir die rechtlichen Verweise überprüft und die Fragen herausgefiltert, deren Verweise nicht in einem der von uns berücksichtigten Gesetzbücher enthalten waren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 600, "src_audio": "/acl6060/audio/eval/600.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "tgt_ref": "Die übrigen Referenzen wurden zusammengeführt und in die entsprechenden Artikel-IDs aus unserem Korpus umgewandelt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 601, "src_audio": "/acl6060/audio/eval/601.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "tgt_ref": "Am Ende hatten wir 1.108 Fragen, jede sorgfältig markiert mit den IDs der relevanten Artikel aus unserem großen Korpus von 22.630 Gesetzesartikeln.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 602, "src_audio": "/acl6060/audio/eval/602.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "tgt_ref": "Darüber hinaus enthält jede Frage eine Hauptkategorie und eine Verkettung von Unterkategorien.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 603, "src_audio": "/acl6060/audio/eval/603.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "tgt_ref": "Jeder Artikel hat eine Verkettung mit der anschließenden Überschrift im Aufbau des Gesetzes.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 604, "src_audio": "/acl6060/audio/eval/604.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "tgt_ref": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten aber für künftige Forschungen zum juristischen Informationen-Retrieval oder zur juristischen Textklassifikation von Interesse sein.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 605, "src_audio": "/acl6060/audio/eval/605.wav", "src_ref": "Let's look at some characteristic of our dataset.", "tgt_ref": "Schauen wir uns einige Merkmale unseres Datensatzes an.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 606, "src_audio": "/acl6060/audio/eval/606.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "tgt_ref": "Die Fragen sind zwischen fünf und 24 Wörter lang, mit einem Mittelwert von 14 Wörtern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 607, "src_audio": "/acl6060/audio/eval/607.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "tgt_ref": "Die Artikel sind mit einer durchschnittlichen Länge von 77 Wörtern sehr viel länger, wobei 142 von ihnen mehr als 1.000 Wörter umfassen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 608, "src_audio": "/acl6060/audio/eval/608.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "tgt_ref": "Der längste von ihnen hat bis zu 5.790 Wörter.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 609, "src_audio": "/acl6060/audio/eval/609.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "tgt_ref": "Wie bereits erwähnt decken die Fragen ein breites Spektrum an Themen ab, wobei etwa 85 Prozent der Fragen entweder die Familie, das Wohnen, Geld oder die Gerechtigkeit betreffen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 610, "src_audio": "/acl6060/audio/eval/610.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "tgt_ref": "Die restlichen 15 Prozent betreffen entweder soziale Sicherheit, Ausländer oder Arbeit.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 611, "src_audio": "/acl6060/audio/eval/611.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "tgt_ref": "Die Artikel sind auch sehr vielfältig, da sie aus 32 verschiedenen belgischen Gesetzbüchern stammen, die eine große Reihe von Rechtsthemen abdecken.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 612, "src_audio": "/acl6060/audio/eval/612.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "tgt_ref": "Hier ist die Gesamtzahl der Artikel, die aus diesen belgischen Gesetzbüchern gesammelt wurden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 613, "src_audio": "/acl6060/audio/eval/613.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "tgt_ref": "Von den 22.633 Artikeln werden nur 1.612 als relevant für mindestens eine Frage im Datensatz genannt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 614, "src_audio": "/acl6060/audio/eval/614.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "tgt_ref": "Etwa 80 Prozent dieser zitierten Artikel stammen entweder aus dem Zivilgesetzbuch, dem Gerichtsgesetzbuch, dem Gesetzbuch für strafrechtliche Ermittlungen oder dem Strafgesetzbuch.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 615, "src_audio": "/acl6060/audio/eval/615.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "tgt_ref": "Bei 18 von 32 Gesetzbüchern werden weniger als fünf Artikel als relevant für mindestens eine Frage bestimmt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 616, "src_audio": "/acl6060/audio/eval/616.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "tgt_ref": "Dies lässt sich dadurch erklären, dass diese Gesetzbücher weniger auf den Einzelnen und seine Anliegen ausgerichtet waren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 617, "src_audio": "/acl6060/audio/eval/617.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "tgt_ref": "Insgesamt liegt der Durchschnitt der Anzahl der Zitate bei zwei, und weniger als 25 Prozent der zitierten Artikel werden mehr als fünfmal zitiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 618, "src_audio": "/acl6060/audio/eval/618.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "tgt_ref": "Unter Verwendung aller Datensätze haben wir verschiedene Retrieval-Ansätze, einschließlich lexikalischer und dichter Architektur, einem Benchmarking unterzogen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 619, "src_audio": "/acl6060/audio/eval/619.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "tgt_ref": "Bei einer Abfrage und einem Artikel weist ein lexikalisches Modell dem Abfrage-Artikel-Paar eine Punktzahl zu, indem es die Summe der Gewichtungen von jedem der Begriffe in diesem Artikel über die Abfrage-Termini berechnet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 620, "src_audio": "/acl6060/audio/eval/620.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "tgt_ref": "Wir experimentieren mit den Standard-Ranking-Funktionen TF-IDF und BM25.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 621, "src_audio": "/acl6060/audio/eval/621.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "tgt_ref": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel finden können, die Schlüsselwörter enthalten, die in der Anfrage vorkommen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 622, "src_audio": "/acl6060/audio/eval/622.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "tgt_ref": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronal-basierten Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 623, "src_audio": "/acl6060/audio/eval/623.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "tgt_ref": "Wir verwenden ein Bi-Encoder-Modell, das Abfragen und Artikel in dichten Vektor-Darstellungen abbildet und einen Relevanzwert zwischen einem Abfrage-Artikel-Paar anhand der Ähnlichkeit ihrer Einbettungen berechnet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 624, "src_audio": "/acl6060/audio/eval/624.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "tgt_ref": "Diese Einbettungen resultieren in der Regel aus einer Pooling-Operation auf der Ausgabe eines Worteinbettungsmodells.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 625, "src_audio": "/acl6060/audio/eval/625.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "tgt_ref": "Zunächst untersuchen wir die Effektivität von Siamesischen Bi-Encodern in einem Zero-Shot-Evaluation-Setup, d. h. dass vortrainierte Worteinbettungsmodelle ohne zusätzliche Feinabstimmung sofort angewendet werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 626, "src_audio": "/acl6060/audio/eval/626.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "tgt_ref": "Wir experimentieren mit kontextunabhängigen Textencodern, wie word2vec und fastText, und kontextabhängigen Einbettungsmodellen, wie Roberta und insbesondere CamemBERT, einem französischen Roberta-Modell.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 627, "src_audio": "/acl6060/audio/eval/627.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "tgt_ref": "Darüber hinaus trainieren wir unser eigenes, auf CamemBERT basierendes Modell, Bi-Encoder, auf unserem Datensatz.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 628, "src_audio": "/acl6060/audio/eval/628.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "tgt_ref": "Beachten Sie, dass wir beim Training mit den beiden Varianten der Bi-Encoder-Architektur experimentieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 629, "src_audio": "/acl6060/audio/eval/629.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "tgt_ref": "Siamese, das ein einzigartiges Worteinbettungsmodell verwendet, das die Abfrage und den Artikel zusammen in einem geteilten dichten Vektorraum abbildet, und Two-Tower, das zwei unabhängige Worteinbettungsmodelle verwendet, die die Abfrage und den Artikel getrennt in verschiedenen Einbettungsräumen kodieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 630, "src_audio": "/acl6060/audio/eval/630.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "tgt_ref": "Wir experimentieren mit Mittelwert, Maximalwert und CLS-Pooling sowie mit Produkt und Kosinus für die Berechnung von Ähnlichkeiten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 631, "src_audio": "/acl6060/audio/eval/631.wav", "src_ref": "Here are the result of our baseline on the test sets.", "tgt_ref": "Hier sind die Ergebnisse unserer Baseline auf den Testsätzen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 632, "src_audio": "/acl6060/audio/eval/632.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "tgt_ref": "Die lexikalischen Methoden werden oben, die Siamesischen Bi-Encoder in einem Zero-Shot-Setup in der Mitte und die fein abgestimmten Bi-Encoder werden unten ausgewertet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 633, "src_audio": "/acl6060/audio/eval/633.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "tgt_ref": "Insgesamt übertrifft der fein abgestimmte Bi-Encoder alle anderen Baselines deutlich.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 634, "src_audio": "/acl6060/audio/eval/634.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "tgt_ref": "Das Two-Tower-Modell verbessert sich gegenüber seinen Siamesischen Varianten beim Recall um 100, schneidet aber bei den anderen Metriken ähnlich gut ab.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 635, "src_audio": "/acl6060/audio/eval/635.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "tgt_ref": "Obwohl BM25 deutlich schlechter abschnitt als der trainierte Bi-Encoder, zeigte seine Leistung, dass er immer noch eine gute Basis für ein domänenspezifisches Retrieval ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 636, "src_audio": "/acl6060/audio/eval/636.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "tgt_ref": "Bezüglich der Zero-Shot-Evaluation des Siamesischen Bi-Encoders stellen wir fest, dass die direkte Verwendung der Einbettungen eines vortrainierten CamemBERT-Modells ohne Optimierung für die Informationen-Retrieval-Aufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 637, "src_audio": "/acl6060/audio/eval/637.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "tgt_ref": "Darüber hinaus stellen wir fest, dass der word2vec-basierte Bi-Encoder die fastText- und BERT-basierten Modelle signifikant übertrifft, was darauf hindeutet, dass vortrainierte Wort-Ebenen-Einbettungen vielleicht besser für die Aufgabe geeignet sind als Zeichen- oder Unterwort-Ebenen-Einbettungen, wenn sie direkt verwendet werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 638, "src_audio": "/acl6060/audio/eval/638.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "tgt_ref": "Obwohl diese Ergebnisse vielversprechend sind, lassen sie im Vergleich zu einem erfahrenen Rechtsexperten auf ein großes Verbesserungspotenzial schließen, der früher oder später alle relevanten Artikel zu jeder Frage abrufen kann und somit perfekte Ergebnisse erzielt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 639, "src_audio": "/acl6060/audio/eval/639.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "tgt_ref": "Abschließend möchte ich auf zwei Einschränkungen unseres Datensatzes eingehen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 640, "src_audio": "/acl6060/audio/eval/640.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "tgt_ref": "Erstens ist der Artikelkorpus auf die Artikel der 32 herangezogenen belgischen Gesetzbücher beschränkt, was nicht das gesamte belgische Recht abdeckt, da Artikel aus Dekreten, Richtlinien und Verordnungen fehlen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 641, "src_audio": "/acl6060/audio/eval/641.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "tgt_ref": "Bei der Erstellung des Datensatzes werden alle Verweise auf diese nicht erfassten Artikel ignoriert, was dazu führt, dass sich einige Fragen am Ende nur auf einen Bruchteil der ursprünglichen Anzahl der relevanten Artikel beziehen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 642, "src_audio": "/acl6060/audio/eval/642.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "tgt_ref": "Diese Information impliziert also, dass die Antwort, die in den übrigen relevanten Artikeln enthalten ist, unvollständig sein könnte, obwohl sie immer noch völlig angemessen ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 643, "src_audio": "/acl6060/audio/eval/643.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "tgt_ref": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 644, "src_audio": "/acl6060/audio/eval/644.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "tgt_ref": "Zum Beispiel die Frage: „Kann ich meinen Mietern kündigen, wenn sie zu viel Lärm machen?“", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 645, "src_audio": "/acl6060/audio/eval/645.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "tgt_ref": "Möglicherweise gibt es im Gesetz keine detaillierte Antwort, die eine bestimmte Lärmschwelle festlegt, ab der eine Räumung zulässig ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 646, "src_audio": "/acl6060/audio/eval/646.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "tgt_ref": "Stattdessen sollte sich der Vermieter wahrscheinlich eher auf das Fallrecht stützen und Präzedenzfälle finden, die seiner aktuellen Situation ähnlich sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 647, "src_audio": "/acl6060/audio/eval/647.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "tgt_ref": "Zum Beispiel veranstalten die Mieter zwei Partys pro Woche bis zwei Uhr morgens.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 648, "src_audio": "/acl6060/audio/eval/648.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "tgt_ref": "Einige Fragen eignen sich daher besser als andere für die Aufgabe des Retrievals von Gesetzesartikeln. Die Domäne der weniger geeigneten Fragen muss noch bestimmt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 649, "src_audio": "/acl6060/audio/eval/649.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "tgt_ref": "Wir hoffen, dass unsere Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle für das Retrieval von Gesetzesartikeln weckt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 650, "src_audio": "/acl6060/audio/eval/650.wav", "src_ref": "That can help improve access to justice for all.", "tgt_ref": "Sie kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 651, "src_audio": "/acl6060/audio/eval/651.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "Sie können unser Paper, den Datensatz und die Gesetzbücher unter den folgenden Links einsehen. Vielen Dank!", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 652, "src_audio": "/acl6060/audio/eval/652.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "tgt_ref": "Hallo, wir freuen uns, Ihnen unsere Arbeit über VALSE vorstellen zu können. Das ist ein Aufgaben-unabhängiger Benchmark, der für das Testen von Seh- und Sprachmodellen mit spezifischen sprachlichen Phänomenen konzipiert ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 653, "src_audio": "/acl6060/audio/eval/653.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "tgt_ref": "Warum haben wir uns die Mühe gemacht, diesen Benchmark einzurichten?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 654, "src_audio": "/acl6060/audio/eval/654.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "tgt_ref": "In den letzten Jahren haben wir eine explosionsartige Zunahme von Transformer-basierten Seh- und Sprachmodellen erlebt, die mit großen Mengen an Bild-Text-Paaren vortrainiert wurden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 655, "src_audio": "/acl6060/audio/eval/655.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "tgt_ref": "Jedes dieser Modelle treibt den Fortschritt bei Seh- und Sprachaufgaben voran, wie z. B. die visuelle Fragenbeantwortung, das Argumentieren mit visuellem Menschenverstand, Bild-Retrieval, Phrasen-Erdung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 656, "src_audio": "/acl6060/audio/eval/656.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "tgt_ref": "Wir haben also die Nachricht erhalten, dass die Genauigkeiten bei diesen Aufgaben und spezifischen Benchmarks stetig steigen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 657, "src_audio": "/acl6060/audio/eval/657.wav", "src_ref": "But do we know what the models have actually learned?", "tgt_ref": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 658, "src_audio": "/acl6060/audio/eval/658.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "tgt_ref": "Was hat ein Seh- und Sprach-Transformer verstanden, wenn er für dieses Bild und diesen Satz eine hohe Punktzahl zuweist?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 659, "src_audio": "/acl6060/audio/eval/659.wav", "src_ref": "And the low score for this one?", "tgt_ref": "Und hier eine niedrige Punktzahl?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 660, "src_audio": "/acl6060/audio/eval/660.wav", "src_ref": "Do vision and language models focus on the right thing?", "tgt_ref": "Konzentrieren sich Seh- und Sprachmodelle auf die wesentlichen Punkte?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 661, "src_audio": "/acl6060/audio/eval/661.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "tgt_ref": "Oder konzentrieren sie sich auf Verzerrungen, wie in früheren Arbeiten aufgezeigt wurde?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 662, "src_audio": "/acl6060/audio/eval/662.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "tgt_ref": "Um diesen Aspekt näher zu beleuchten, schlagen wir eine eher aufgabenbezogene agnostische Richtung vor und führen VALSE ein, das die Empfindlichkeit von Seh- und Sprachmodellen für spezifische sprachliche Phänomene testet, die sowohl die sprachlichen als auch die visuellen Modalitäten betreffen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 663, "src_audio": "/acl6060/audio/eval/663.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "tgt_ref": "Wir zielen auf Existenz, Pluralität, Zählung, räumliche Beziehungen, Handlungen und Entity-Koreferenz ab.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 664, "src_audio": "/acl6060/audio/eval/664.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "tgt_ref": "Doch wie lässt sich überprüfen, ob die Seh- und Sprachmodelle dieses Phänomen erfasst haben?", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 665, "src_audio": "/acl6060/audio/eval/665.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "tgt_ref": "Das Verfälschen einer Methode wurde zuvor von Ravi Shekhar und Mitarbeitern nur für Substantivphrasen in den Seh- und Sprachmodellen und beim Zählen von uns in früheren Arbeiten angewandt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 666, "src_audio": "/acl6060/audio/eval/666.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "tgt_ref": "Verfälschen bedeutet im Grunde, dass wir die Beschriftung eines Bildes nehmen und eine Verfälschung erzeugen, indem wir die Beschriftung so verändern, dass sie das Bild nicht mehr beschreibt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 667, "src_audio": "/acl6060/audio/eval/667.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "tgt_ref": "Wir führen diese Veränderungen der Phrase durch, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Relationen, Handlungen und Entität-Koreferenz, wobei jeder Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als einen interessanten Weg gefunden haben, um Verfälschungsinstanzen zu erzeugen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 668, "src_audio": "/acl6060/audio/eval/668.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "tgt_ref": "Zum Beispiel haben wir im Fall des Handlungsteils zwei Instrumente, eines, bei dem das Handlungsverb durch eine andere Handlung ersetzt wird, und eines, bei dem die Aktanten ausgetauscht werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 669, "src_audio": "/acl6060/audio/eval/669.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "tgt_ref": "Zählung und Koreferenz sind auch Teile, die mehr als ein Instrument haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 670, "src_audio": "/acl6060/audio/eval/670.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "tgt_ref": "Wir erstellen diese Verfälschungen, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalisch richtig sind und auch korrekte Sätze bilden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 671, "src_audio": "/acl6060/audio/eval/671.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "tgt_ref": "Das ist nicht einfach zu bewerkstelligen, denn eine verfälschte Beschriftung ist weniger wahrscheinlich als die ursprüngliche Beschriftung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 672, "src_audio": "/acl6060/audio/eval/672.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "tgt_ref": "Es ist zwar zum Beispiel nicht unmöglich, aber statistisch gesehen ist es unwahrscheinlicher, dass Pflanzen einen Menschen schneiden, als dass ein Mensch Pflanzen schneidet. Große Seh- und Sprachmodelle könnten dies erkennen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 673, "src_audio": "/acl6060/audio/eval/673.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "tgt_ref": "Daher müssen wir handeln, wenn wir gültige Verfälschungen erhalten wollen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 674, "src_audio": "/acl6060/audio/eval/674.wav", "src_ref": "First, we make use of strong language models to propose foils.", "tgt_ref": "Erstens nutzen wir starke Sprachmodelle, um Verfälschungen vorzuschlagen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 675, "src_audio": "/acl6060/audio/eval/675.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "tgt_ref": "Zweitens verwenden wir die Inferenz der natürlichen Sprache oder kurz NLI, um Verfälschungen herauszufiltern, die das Bild noch beschreiben könnten. Bei der Konstruktion von Verfälschungen müssen wir sicherstellen, dass sie das Bild nicht beschreiben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 676, "src_audio": "/acl6060/audio/eval/676.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "tgt_ref": "Um dies automatisch zu testen, wenden wir die Inferenz der natürlichen Sprache mit der folgenden Logik an.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 677, "src_audio": "/acl6060/audio/eval/677.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "tgt_ref": "Wir betrachten ein Bild als die Prämisse und seine Beschriftung als die daraus abgeleitete Hypothese.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 678, "src_audio": "/acl6060/audio/eval/678.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "tgt_ref": "Darüber hinaus betrachten wir die Beschriftung als Prämisse und die Verfälschung als ihre Hypothese.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 679, "src_audio": "/acl6060/audio/eval/679.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "tgt_ref": "Wenn ein NLI-Modell vorhersagt, dass die Verfälschung der Beschriftung widerspricht oder neutral ist, ist das für uns ein Indikator für eine gültige Verfälschung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 680, "src_audio": "/acl6060/audio/eval/680.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "tgt_ref": "Wenn ein NLI vorhersagt, dass die Verfälschung die Beschriftung beinhaltet, kann es keine gute Verfälschung sein, da sie durch Transitivität eine wahrheitsgemäße Beschreibung des Bildes liefert. Wir filtern diese Verfälschungen heraus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 681, "src_audio": "/acl6060/audio/eval/681.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "tgt_ref": "Dieses Verfahren ist aber nicht perfekt, sondern nur ein Indikator für gültige Verfälschungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 682, "src_audio": "/acl6060/audio/eval/682.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "tgt_ref": "Daher setzen wir als dritte Maßnahme zur Generierung gültiger Verfälschungen menschliche Annotatoren ein, um die in VALSE verwendeten Daten zu validieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 683, "src_audio": "/acl6060/audio/eval/683.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "tgt_ref": "Nach dem Filtern und der menschlichen Evaluation haben wir also so viele Testinstanzen, wie in dieser Tabelle beschrieben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 684, "src_audio": "/acl6060/audio/eval/684.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "tgt_ref": "Beachten Sie hier, dass VALSE keine Trainingsdaten, sondern nur Testdaten liefert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 685, "src_audio": "/acl6060/audio/eval/685.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "tgt_ref": "Da es sich um einen reinen Zero-Shot-Test-Benchmark handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten der Seh- und Sprachmodelle nach dem Vortraining nutzt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 686, "src_audio": "/acl6060/audio/eval/686.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "tgt_ref": "Die Feinabstimmung würde es den Modellen nur ermöglichen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 687, "src_audio": "/acl6060/audio/eval/687.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "tgt_ref": "Wir alle wissen, dass diese Modells gerne schummeln und Abkürzungen nehmen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 688, "src_audio": "/acl6060/audio/eval/688.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "tgt_ref": "Wie wir schon erwähnten, sind wir an der Bewertung interessiert, welche Fähigkeiten die Seh- und Sprachmodelle nach dem Vortraining haben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 689, "src_audio": "/acl6060/audio/eval/689.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "tgt_ref": "Wir experimentieren mit fünf Seh- und Sprachmodellen auf VALSE, nämlich mit CLIP, LXMert, ViLBERT, ViLBERT zwölf in einem und VisualBERT.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 690, "src_audio": "/acl6060/audio/eval/690.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "tgt_ref": "Zwei unserer wichtigsten Evaluationsmetriken sind die Genauigkeit der Modelle bei der Klassifikation von Bild-Satz-Paaren in Bildbeschreibungen und Verfälschungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 691, "src_audio": "/acl6060/audio/eval/691.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "tgt_ref": "Vielleicht ist es für dieses Video relevanter, unsere tolerantere Metrik vorzustellen, die paarweise Genauigkeit. Diese misst, ob die Bild-Satz-Ausrichtung für das korrekte Bild-Text-Paar größer ist als für sein Verfälschungspaar.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 692, "src_audio": "/acl6060/audio/eval/692.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "tgt_ref": "Weitere Metriken und Ergebnisse dazu finden Sie in unserem Paper.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 693, "src_audio": "/acl6060/audio/eval/693.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "tgt_ref": "Die Ergebnisse mit paarweiser Genauigkeit werden hier gezeigt und stimmen mit den Ergebnissen überein, die wir von den anderen Metriken erhalten haben, nämlich dass die beste Zero-Shot-Leistung von ViLBERT zwölf zu eins erreicht wird, gefolgt von ViLBERT, LXMert, CLIP und schließlich VisualBERT.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 694, "src_audio": "/acl6060/audio/eval/694.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "tgt_ref": "Es ist bemerkenswert, wie Instrumente, die sich auf die einzelnen Objekte konzentrieren, wie Existenz und Substantivphrasen, von ViLBERT zwölf zu eins fast gelöst werden. Das unterstreicht, dass Modelle in der Lage sind, benannte Objekte und ihre Existenz in Bildern zu identifizieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 695, "src_audio": "/acl6060/audio/eval/695.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "tgt_ref": "Keines der verbleibenden Teile kann jedoch in unseren gegnerischen Verfälschungseinstellungen zuverlässig gelöst werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 696, "src_audio": "/acl6060/audio/eval/696.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "tgt_ref": "Wir sehen an den Instrumenten der Pluralität und der Zählung, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 697, "src_audio": "/acl6060/audio/eval/697.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "tgt_ref": "Der Relationen-Teil zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Relation zwischen Objekten in einem Bild richtig zu klassifizieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 698, "src_audio": "/acl6060/audio/eval/698.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "tgt_ref": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Teilnehmer zu identifizieren, selbst wenn sie durch Plausibilitätsbias unterstützt werden, wie wir bei dem Handlung-Teil sehen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 699, "src_audio": "/acl6060/audio/eval/699.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "tgt_ref": "Beim Koreferenz-Teil geht hervor, dass die Verfolgung mehrerer Verweise auf dasselbe Objekt in einem Bild unter Verwendung von Pronomen auch für die Seh- und Sprachmodelle schwierig ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 700, "src_audio": "/acl6060/audio/eval/700.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "tgt_ref": "Zur Überprüfung der Korrektheit und weil es ein interessantes Experiment ist, vergleichen wir auch zwei reine Textmodelle, GPT 1 und GPT 2. So wollen wir feststellen, ob VALSE durch diese unimodalen Modelle lösbar ist. Wir berechnen die Perplexität der korrekten und der verfälschten Beschriftung, ohne Bild, um den Eintrag mit der niedrigsten Perplexität vorherzusagen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 701, "src_audio": "/acl6060/audio/eval/701.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "tgt_ref": "Wenn die Perplexität bei der Verfälschung höher ist, ist das für uns ein Hinweis, dass die verfälschte Beschriftung möglicherweise unter Plausibilitätsverzerrungen oder anderen sprachlichen Verzerrungen leidet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 702, "src_audio": "/acl6060/audio/eval/702.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "tgt_ref": "Es ist interessant zu sehen, dass in einigen Fällen die GPT-Modelle mit reinem Text die Plausibilität der Welt besser erfasst haben als die Seh- und Sprachmodelle.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 703, "src_audio": "/acl6060/audio/eval/703.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "tgt_ref": "Zusammenfassend lässt sich sagen, dass VALSE ein Benchmark ist, der durch das Objektiv von linguistischen Konstrukten schaut, um die Gemeinschaft bei der Verbesserung von Seh- und Sprachmodellen zu unterstützen, indem er ihre visuelle Erdung hart testet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 704, "src_audio": "/acl6060/audio/eval/704.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "tgt_ref": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und ihre Existenz in Bildern gut erkennen, wie der Existenzteil zeigt. Sie haben aber Schwierigkeiten damit, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu begründen, wenn sie gezwungen sind, sprachliche Indikatoren zu berücksichtigen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 705, "src_audio": "/acl6060/audio/eval/705.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "tgt_ref": "Wir möchten die Community wirklich dazu ermutigen, VALSE für die Messung des Fortschritts von Sprach- Erdung mit Seh- und Sprachmodellen zu nutzen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 706, "src_audio": "/acl6060/audio/eval/706.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "tgt_ref": "Zudem könnte VALSE als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten. So kann kontrolliert werden, ob ein Datensatz dazu beiträgt, dass sich Modelle in einem der von VALSE getesteten Aspekte verbessern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 707, "src_audio": "/acl6060/audio/eval/707.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "Wenn Sie Interesse haben, schauen Sie sich die VALSE-Daten auf GitHub an. Wenn Sie irgendwelche Fragen haben, zögern Sie nicht, uns zu kontaktieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 708, "src_audio": "/acl6060/audio/eval/708.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "tgt_ref": "Hallo, mein Name ist Kamezawa von der Universität Tokio.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 709, "src_audio": "/acl6060/audio/eval/709.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "tgt_ref": "Ich werde folgendes Paper vorstellen: RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 710, "src_audio": "/acl6060/audio/eval/710.wav", "src_ref": "I'll be explaining in this order.", "tgt_ref": "Ich werde es in dieser Reihenfolge erklären.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 711, "src_audio": "/acl6060/audio/eval/711.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "tgt_ref": "Zunächst werde ich die automatische Generierung von Versionshinweisen vorstellen, an der wir in dieser Forschung arbeiten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 712, "src_audio": "/acl6060/audio/eval/712.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "tgt_ref": "Ein Versionshinweis ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Version eines Softwareprodukts vertrieben werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 713, "src_audio": "/acl6060/audio/eval/713.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "tgt_ref": "Das Bild zeigt einen Versionshinweis für Version 2.6.4 der Vuejs-Bibliothek.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 714, "src_audio": "/acl6060/audio/eval/714.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "tgt_ref": "Versionshinweise spielen bei der Open-Source-Entwicklung eine wichtige Rolle, aber ihre Erstellung ist manuell zeitaufwändig.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 715, "src_audio": "/acl6060/audio/eval/715.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "tgt_ref": "Daher wäre es sehr nützlich, wenn man automatisch qualitativ hochwertige Versionshinweise generieren könnte.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 716, "src_audio": "/acl6060/audio/eval/716.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "tgt_ref": "Ich werde zwei frühere Untersuchungen zur automatischen Generierung von Versionshinweisen erwähnen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 717, "src_audio": "/acl6060/audio/eval/717.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "tgt_ref": "Zuerst gibt es ein System mit dem Namen ARENA, das im Jahr 2014 veröffentlicht wurde.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 718, "src_audio": "/acl6060/audio/eval/718.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "tgt_ref": "Es verfolgt einen regelbasierten Ansatz, indem es zum Beispiel den Change-Extractor verwendet, um alle Unterschiede, Bibliotheksänderungen und Dokumentänderungen aus den verschiedenen Versionen zu extrahieren und sie schließlich zu kombinieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 719, "src_audio": "/acl6060/audio/eval/719.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "tgt_ref": "Die auffälligste Funktion dieses Systems ist der Ausgabe-Extraktor in der oberen rechten Ecke.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 720, "src_audio": "/acl6060/audio/eval/720.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "tgt_ref": "Dies muss Jira, dem Fehlerverwaltungssystem, überlassen werden und kann nur auf Projekte angewendet werden, die Jira verwenden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 721, "src_audio": "/acl6060/audio/eval/721.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "tgt_ref": "Mit anderen Worten: Es kann nicht für viele Projekte auf GitHub verwendet werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 722, "src_audio": "/acl6060/audio/eval/722.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "tgt_ref": "Das zweite ist Glyph, das kürzlich in 2020 angekündigt wurde.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 723, "src_audio": "/acl6060/audio/eval/723.wav", "src_ref": "It is available on the internet and can be installed via pip.", "tgt_ref": "Es ist im Internet verfügbar und kann über pip installiert werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 724, "src_audio": "/acl6060/audio/eval/724.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "tgt_ref": "Dieses System verfügt über ein einfaches, lernbasiertes Textklassifikationsmodell und gibt eine von fünf Markierung wie Funktionen oder Fehlerbehebungen für jede eingegebene Commit-Nachricht aus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 725, "src_audio": "/acl6060/audio/eval/725.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "tgt_ref": "Dieses Bild ist eine Stichprobe, das eine Markierung für eine Korrektur oder Fehlerbehebung zurückgibt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 726, "src_audio": "/acl6060/audio/eval/726.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "tgt_ref": "Die Trainingsdaten von Glyph sind ziemlich klein, etwa 5.000, und werden in den unten beschriebenen Experimenten gezeigt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 727, "src_audio": "/acl6060/audio/eval/727.wav", "src_ref": "The performance of the text classification model is not high.", "tgt_ref": "Die Leistung des Textklassifikationsmodells ist nicht hoch.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 728, "src_audio": "/acl6060/audio/eval/728.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "tgt_ref": "Ich stelle zwei verwandte Forschungsarbeiten vor, deren Probleme jedoch die begrenzte Anwendbarkeit und die knappen Datenressourcen sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 729, "src_audio": "/acl6060/audio/eval/729.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "tgt_ref": "Unser Paper löst diese zwei Probleme und erzeugt automatisch qualitativ hochwertige Versionshinweise.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 730, "src_audio": "/acl6060/audio/eval/730.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "tgt_ref": "Aufgrund des Problems der begrenzten Anwendbarkeit schlagen wir eine qualitativ hochwertige, klassenweise Zusammenfassungsmethode vor, die nur Commit-Nachrichten als Eingabe verwendet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 731, "src_audio": "/acl6060/audio/eval/731.wav", "src_ref": "This proposed method can be used for all English repositories.", "tgt_ref": "Diese vorgeschlagene Methode kann für alle englischen Repositories verwendet werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 732, "src_audio": "/acl6060/audio/eval/732.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "tgt_ref": "Für das zweite Problem der knappen Datenressourcen haben wir unseren RNSum-Datensatz erstellt, der aus etwa 82.000 Daten besteht. Diese wurden aus den Daten der öffentlichen GitHub-Repositories mithilfe der GitHub-API gesammelt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 733, "src_audio": "/acl6060/audio/eval/733.wav", "src_ref": "Next, I'll describe our dataset.", "tgt_ref": "Als Nächstes werde ich unseren Datensatz beschreiben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 734, "src_audio": "/acl6060/audio/eval/734.wav", "src_ref": "Here is an example of data.", "tgt_ref": "Hier ist ein Beispiel für die Daten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 735, "src_audio": "/acl6060/audio/eval/735.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "tgt_ref": "Auf der linken Seite ist eine Commit-Nachricht und auf der rechten Seite sind die Versionshinweise.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 736, "src_audio": "/acl6060/audio/eval/736.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "tgt_ref": "Versionshinweise sind als Verbesserungen, Korrekturen usw. markiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 737, "src_audio": "/acl6060/audio/eval/737.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "tgt_ref": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachricht als Eingabe aufnimmt und die Ausgabe ist ein markierter Versionshinweis.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 738, "src_audio": "/acl6060/audio/eval/738.wav", "src_ref": "This can be regarded as a summarization task.", "tgt_ref": "Dies kann als eine Zusammenfassungsaufgabe betrachtet werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 739, "src_audio": "/acl6060/audio/eval/739.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "tgt_ref": "Wir haben vier Markierungen vordefiniert: Funktionen, Verbesserungen, Fehlerbehebungen, Beseitigung von Verwerfungen und bahnbrechende Änderungen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 740, "src_audio": "/acl6060/audio/eval/740.wav", "src_ref": "These were set based on previous research and other factors.", "tgt_ref": "Diese wurden auf der Grundlage von früheren Forschungen und anderen Faktoren festgelegt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 741, "src_audio": "/acl6060/audio/eval/741.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "tgt_ref": "Die Versionshinweise unten rechts wurde aus den Versionshinweisen unten links extrahiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 742, "src_audio": "/acl6060/audio/eval/742.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "tgt_ref": "Zu diesem Zeitpunkt müssen die vier Markierungen, die im Voraus erstellt wurden, erkannt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 743, "src_audio": "/acl6060/audio/eval/743.wav", "src_ref": "But the labels are not always consistent with each repository.", "tgt_ref": "Die Markierungen sind jedoch nicht immer mit jedem Repository konsistent.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 744, "src_audio": "/acl6060/audio/eval/744.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "tgt_ref": "Die Markierung „Verbesserungen“ umfasst beispielsweise Verbesserungen, Erweiterungen, Optimierungen und so weiter.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 745, "src_audio": "/acl6060/audio/eval/745.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "tgt_ref": "Wir haben eine Wortschatzliste mit etwa 30 Markierungen für jede dieser Notationsvarianten erstellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 746, "src_audio": "/acl6060/audio/eval/746.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "tgt_ref": "Diese dient dazu, die Klasse des Versionshinweises zu erkennen. Sie sammelt den Text des Versionshinweises, der als Versionshinweissatz für die Klasse folgt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 747, "src_audio": "/acl6060/audio/eval/747.wav", "src_ref": "Next is a commit message.", "tgt_ref": "Als Nächstes folgt eine Commit-Nachricht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 748, "src_audio": "/acl6060/audio/eval/748.wav", "src_ref": "Commit messages are not tied to each release.", "tgt_ref": "Commit-Nachrichten sind nicht an die einzelnen Versionen gebunden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 749, "src_audio": "/acl6060/audio/eval/749.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "tgt_ref": "Wenn die aktuelle Version 2.5 bis 19 ist, müssen wir, wie im Bild unten gezeigt, die frühere Version 2.5 bis 18 identifizieren und eine Diff erhalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 750, "src_audio": "/acl6060/audio/eval/750.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "tgt_ref": "Dies ist etwas mühsam und es reicht nicht aus, nur eine Liste von Versionen zu erstellen und die Vorher-Nachher-Bilanz zu betrachten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 751, "src_audio": "/acl6060/audio/eval/751.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "tgt_ref": "Wir haben eine heuristische Abgleichsregel erstellt, um die vorherige und die nächste Version zu bekommen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 752, "src_audio": "/acl6060/audio/eval/752.wav", "src_ref": "Dataset analysis.", "tgt_ref": "Die Analyse des Datensatzes.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 753, "src_audio": "/acl6060/audio/eval/753.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "tgt_ref": "Am Ende wurden 7.200 Repositories und 82 Daten gesammelt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 754, "src_audio": "/acl6060/audio/eval/754.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "tgt_ref": "Außerdem liegt die durchschnittliche Anzahl der Versionshinweis-Token bei 63, was für eine Zusammenfassungsaufgabe recht hoch ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 755, "src_audio": "/acl6060/audio/eval/755.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "tgt_ref": "Auch die Anzahl der einzigartigen Token ist mit 830.000 recht groß.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 756, "src_audio": "/acl6060/audio/eval/756.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "tgt_ref": "Dies ist auf die große Anzahl von eindeutigen Klassen- oder Methodennamen im Repository zurückzuführen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 757, "src_audio": "/acl6060/audio/eval/757.wav", "src_ref": "Next, I will explain the proposed method.", "tgt_ref": "Als Nächstes werde ich die vorgeschlagene Methode erläutern.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 758, "src_audio": "/acl6060/audio/eval/758.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "tgt_ref": "Das klassenweise extraktive und dann abstrahierende Zusammenfassungsmodell besteht aus zwei neuronalen Modulen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 759, "src_audio": "/acl6060/audio/eval/759.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "tgt_ref": "Ein Klassifikator verwendet BERT oder CodeBERT und ein Generator verwendet BART.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 760, "src_audio": "/acl6060/audio/eval/760.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "tgt_ref": "Zuerst verwendet CEAS einen Klassifikator, um jede Commit-Nachricht in fünf Klassen von Versionshinweisen zu klassifizieren, die Verbesserungen, Fehlerbehebungen, Verwerfungen und eine weitere Klasse enthalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 761, "src_audio": "/acl6060/audio/eval/761.wav", "src_ref": "The commit messages classified as other are discarded.", "tgt_ref": "Die als „Sonstiges“ eingestuften Commit-Nachrichten werden verworfen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 762, "src_audio": "/acl6060/audio/eval/762.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "tgt_ref": "Dann wendet CEAS den Generator auf die vier markierten Dokumente unabhängig voneinander an und erstellt Versionshinweise für jede Klasse.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 763, "src_audio": "/acl6060/audio/eval/763.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "tgt_ref": "In dieser Aufgabe sind die direkten Korrespondenzen zwischen Commit-Nachrichten und Versionshinweisen nicht bekannt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 764, "src_audio": "/acl6060/audio/eval/764.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "tgt_ref": "Um den Klassifikator zu trainieren, haben wir daher jeder eingegebenen Commit-Nachricht eine Umfrage zugewiesen und dabei die ersten zehn Zeichen jeder Commit-Nachricht verwendet.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 765, "src_audio": "/acl6060/audio/eval/765.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "tgt_ref": "Wir haben den klassenweisen abstrakten Zusammenfassungsansatz durch zwei verschiedene Methoden modelliert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 766, "src_audio": "/acl6060/audio/eval/766.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "tgt_ref": "Das erste Modell, das wir CAS-Single nennen, besteht aus einem einzigen 6-zu-6-Netzwerk und generiert einen einzigen Versionshinweistext, der eine Verkettung von eingegebenen Commit-Nachrichten ergibt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 767, "src_audio": "/acl6060/audio/eval/767.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "tgt_ref": "Die ausgegebenen Texte können auf der Grundlage spezieller klassenspezifischer Endpunktsymbole in klassenweise Segmente unterteilt werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 768, "src_audio": "/acl6060/audio/eval/768.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "tgt_ref": "Die zweite Methode, die wir CAS-Multi nennen, besteht aus vier verschiedenen seq2seq-Netzwerken, von denen jedes einer der festen Versionshinweisklassen entspricht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 769, "src_audio": "/acl6060/audio/eval/769.wav", "src_ref": "Okay, let me explain the experiments.", "tgt_ref": "Ich werde nun die Experimente erklären.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 770, "src_audio": "/acl6060/audio/eval/770.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "tgt_ref": "Fünf Methoden wurden verglichen: CEAS, CAS-Single, CAS-Multi, Clustering und Glyph aus einer früheren Studie.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 771, "src_audio": "/acl6060/audio/eval/771.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "tgt_ref": "Was die Evaluation betrifft, so werden in einigen Fällen die Versionshinweise in mehreren Sätzen ausgegeben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 772, "src_audio": "/acl6060/audio/eval/772.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "tgt_ref": "Da es schwierig ist, die Anzahl von Sätzen zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 773, "src_audio": "/acl6060/audio/eval/773.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "tgt_ref": "Der BLEU wird benachteiligt, wenn das System einen kurzen Satz ausgibt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 774, "src_audio": "/acl6060/audio/eval/774.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "tgt_ref": "Dieser Abzug führt zu einem niedrigeren BLEU-Wert in den nachfolgend beschriebenen Versuchsergebnissen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 775, "src_audio": "/acl6060/audio/eval/775.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "tgt_ref": "Schließlich berechnen wir auch die Spezifität, da ROUGE und BLEU nicht berechnet werden können, wenn die Versionshinweise leer sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 776, "src_audio": "/acl6060/audio/eval/776.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "tgt_ref": "Eine höhere Spezifität bedeutet, dass das Modell in Fällen, in denen die Versionshinweise leer sind, einen leeren Text korrekt ausgibt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 777, "src_audio": "/acl6060/audio/eval/777.wav", "src_ref": "Here are the results.", "tgt_ref": "Hier sind die Resultate.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 778, "src_audio": "/acl6060/audio/eval/778.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "tgt_ref": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, haben wir auch den bereinigten Datensatz ausgewertet, der diese ausschließt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 779, "src_audio": "/acl6060/audio/eval/779.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "tgt_ref": "CEAS und CAS erreichten ROUGE-L-Werte, die mehr als zehn Punkte über den Baselines lagen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 780, "src_audio": "/acl6060/audio/eval/780.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "tgt_ref": "Insbesondere beim bereinigten Testsatz ist der Abstand zwischen der vorgeschlagenen Methode und den Baselines auf mehr als zwanzig Punkte angestiegen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 781, "src_audio": "/acl6060/audio/eval/781.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "tgt_ref": "Diese Ergebnisse zeigen, dass CEAS und CAS signifikant betroffen sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 782, "src_audio": "/acl6060/audio/eval/782.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "tgt_ref": "CEAS erzielte bessere ROUGE-L-Werte als CAS, was darauf hindeutet, dass die Kombination eines Klassifikators und eines Generators beim Training des Klassifikators mit Pseudo-Markierungen effektiv ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 783, "src_audio": "/acl6060/audio/eval/783.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "tgt_ref": "Eine hohe Abdeckung von CEAS kann wahrscheinlich erreicht werden, weil sich der Klassifikator auf die Auswahl relevanter Commit-Nachrichten für jede Klasse konzentrieren kann.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 784, "src_audio": "/acl6060/audio/eval/784.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "tgt_ref": "CAS-Multi ergab tendenziell mehr ROUGE-L-Werte als CAS-Single.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 785, "src_audio": "/acl6060/audio/eval/785.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "tgt_ref": "Wir schlagen vor, dass es auch effektiv ist, unterschiedliche abstrakte Zusammenfassungsmodelle, die unabhängig voneinander sind, für jede Klasse von den Versionshinweisen zu entwickeln.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 786, "src_audio": "/acl6060/audio/eval/786.wav", "src_ref": "Here are an error analysis.", "tgt_ref": "Hier ist eine Fehleranalyse.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 787, "src_audio": "/acl6060/audio/eval/787.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "tgt_ref": "CAS-Methoden geben tendenziell kürzere Sätze aus als menschliche Referenzsätze.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 788, "src_audio": "/acl6060/audio/eval/788.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "tgt_ref": "In der Abbildung rechts besteht der Referenzsatz aus drei oder vier Sätzen, während CAS aus nur einem besteht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 789, "src_audio": "/acl6060/audio/eval/789.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "tgt_ref": "Der Grund für die Reluktanz dieses Modells ist, dass in den Trainingsdaten nur 33 Prozent der Sätze in der Markierung Funktionen und 40 Prozent in der Markierung Verbesserung zu finden sind.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 790, "src_audio": "/acl6060/audio/eval/790.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "tgt_ref": "Darüber hinaus können CAS-Methoden ohne zusätzliche Informationen keine genauen Versionshinweise erstellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 791, "src_audio": "/acl6060/audio/eval/791.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "tgt_ref": "Oben auf der rechten Seite ist ein Beispiel für eine sehr unübersichtliche Commit-Nachricht. Der vollständige Satz kann nicht ohne Bezug auf den entsprechenden Fortschritt oder das Problem generiert werden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 792, "src_audio": "/acl6060/audio/eval/792.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "tgt_ref": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten in der Eingabe zusammenhängen und zu einem Satz zusammengefasst werden sollten, was jedoch nicht gelingt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 793, "src_audio": "/acl6060/audio/eval/793.wav", "src_ref": "Finally, a conclusion.", "tgt_ref": "Nun kommen wir zum Fazit.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 794, "src_audio": "/acl6060/audio/eval/794.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "tgt_ref": "Wir haben einen neuen Datensatz für die automatische Generierung von Versionshinweisen erstellt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 795, "src_audio": "/acl6060/audio/eval/795.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "tgt_ref": "Wir haben auch eine Aufgabe für die Eingabe von Commit-Nachrichten und deren Zusammenfassung formuliert, sodass sie für alle auf Englisch geschriebene Projekte anwendbar ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 796, "src_audio": "/acl6060/audio/eval/796.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "tgt_ref": "Unsere Experimente zeigen, dass die vorgeschlagene Methode weniger verrauschte Versionshinweise mit höherem Abdeckungsgrad als die Baselines erzeugt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 797, "src_audio": "/acl6060/audio/eval/797.wav", "src_ref": "Please check out our dataset on GitHub.", "tgt_ref": "Bitte sehen Sie sich unseren Datensatz auf GitHub an.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 798, "src_audio": "/acl6060/audio/eval/798.wav", "src_ref": "Thank you.", "tgt_ref": "Vielen Dank!", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 799, "src_audio": "/acl6060/audio/eval/799.wav", "src_ref": "Hello. My name is Asaf Harari.", "tgt_ref": "Hallo! Mein Name ist Asaf Harari.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 800, "src_audio": "/acl6060/audio/eval/800.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "tgt_ref": "Ich werde unser Paper vorstellen: Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 801, "src_audio": "/acl6060/audio/eval/801.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "tgt_ref": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Funktionen von Daten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 802, "src_audio": "/acl6060/audio/eval/802.wav", "src_ref": "But sometimes, these features are limited.", "tgt_ref": "Aber manchmal sind diese Funktionen begrenzt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 803, "src_audio": "/acl6060/audio/eval/803.wav", "src_ref": "Feature generation using another data source may add substantial information.", "tgt_ref": "Die Generierung von Funktionen unter Verwendung einer anderen Datenquelle kann wesentliche Informationen hinzufügen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 804, "src_audio": "/acl6060/audio/eval/804.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "tgt_ref": "Unser Forschungsziel ist die automatische Anreicherung tabellarischer Daten mit freiem Text aus externen Quellen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 805, "src_audio": "/acl6060/audio/eval/805.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "tgt_ref": "Angenommen, wir haben einen tabellarischen Datensatz und eine Wissensbasis.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 806, "src_audio": "/acl6060/audio/eval/806.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "tgt_ref": "Wir brauchen einen automatischen Prozess, der Entity Linking und eine Textanalyse umfasst, um neue Funktionen aus dem freien Text der Wissensbasis zu extrahieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 807, "src_audio": "/acl6060/audio/eval/807.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "tgt_ref": "Unser Rahmen FeSTE ist genau dieser automatische Prozess.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 808, "src_audio": "/acl6060/audio/eval/808.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "tgt_ref": "Sehen wir uns also ein Beispiel in einem Datensatz an, der in FeSTE eingespeist wird.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 809, "src_audio": "/acl6060/audio/eval/809.wav", "src_ref": "In this example, the dataset is university dataset.", "tgt_ref": "In diesem Beispiel ist der Datensatz der Universitätsdatensatz.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 810, "src_audio": "/acl6060/audio/eval/810.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "tgt_ref": "Das Ziel besteht darin, die Universitäten nach niedrigem und hohem Rang einzuteilen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 811, "src_audio": "/acl6060/audio/eval/811.wav", "src_ref": "As knowledge base, we use Wikipedia.", "tgt_ref": "Als Wissensbasis verwenden wir Wikipedia.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 812, "src_audio": "/acl6060/audio/eval/812.wav", "src_ref": "The first phase of FeSTE is entity linking.", "tgt_ref": "Die erste Phase von FeSTE ist Entity Linking.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 813, "src_audio": "/acl6060/audio/eval/813.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "tgt_ref": "Jede Entität, in diesem Beispiel der Name der Universität, ist mit einer Entität innerhalb der Wissensbasis verknüpft.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 814, "src_audio": "/acl6060/audio/eval/814.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "tgt_ref": "Der Text der Entitäten aus der Wissensbasis wird extrahiert und dem Datensatz hinzugefügt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 815, "src_audio": "/acl6060/audio/eval/815.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "tgt_ref": "In diesem Beispiel ist der Text das Abstract der Wikipedia-Seite.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 816, "src_audio": "/acl6060/audio/eval/816.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "tgt_ref": "Nun müssen wir Funktionen aus dem abgerufenen Text generieren oder extrahieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 817, "src_audio": "/acl6060/audio/eval/817.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "tgt_ref": "Wir müssen also eine Phase der Funktionsextraktion einleiten, zu der die Textanalyse gehört.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 818, "src_audio": "/acl6060/audio/eval/818.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "tgt_ref": "Das ist die wichtigste Neuerung dieses Papers, auf die ich auf den nächsten Folien näher eingehen werde.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 819, "src_audio": "/acl6060/audio/eval/819.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "tgt_ref": "Nach der Phase der Funktionsextraktion folgt eine Phase der Funktionsgenerierung, in der wir die extrahierten Funktionen verwenden, um eine kleine Anzahl neuer Funktionen zu erzeugen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 820, "src_audio": "/acl6060/audio/eval/820.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "tgt_ref": "Zunächst werden Funktionen in der Anzahl der Klassen des ursprünglichen Datensatzes generiert.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 821, "src_audio": "/acl6060/audio/eval/821.wav", "src_ref": "In this example, the original dataset has two classes.", "tgt_ref": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 822, "src_audio": "/acl6060/audio/eval/822.wav", "src_ref": "So, FeSTE generates two new features.", "tgt_ref": "FeSTE generiert also zwei neue Funktionen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 823, "src_audio": "/acl6060/audio/eval/823.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "tgt_ref": "Wenn der Datensatz jedoch fünf Klassen hat, generiert FeSTE fünf neue Funktionen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 824, "src_audio": "/acl6060/audio/eval/824.wav", "src_ref": "Each feature represents the likelihood for each class.", "tgt_ref": "Jede Funktion stellt die Wahrscheinlichkeit für jede Klasse dar.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 825, "src_audio": "/acl6060/audio/eval/825.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "tgt_ref": "Um den Text zu analysieren, verwenden wir die aktuellste Textanalyse, die auf Transformer-basierten Sprachmodellen wie BERT, GPT, XLNet und anderen beruht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 826, "src_audio": "/acl6060/audio/eval/826.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "tgt_ref": "Es ist aber unwahrscheinlich, dass wir Sprachmodelle mit den eingegebenen Datensätzen trainieren können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 827, "src_audio": "/acl6060/audio/eval/827.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "tgt_ref": "Ein naiver Ansatz ist also eine Feinabstimmung des Zieldatensatzes.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 828, "src_audio": "/acl6060/audio/eval/828.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "tgt_ref": "In der Phase der Funktionsextraktion können wir also vortrainierte Sprachmodelle herunterladen und das Sprachmodell über den Zieldatensatz feinabstimmen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 829, "src_audio": "/acl6060/audio/eval/829.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "tgt_ref": "In diesem Beispiel zur Feinabstimmung des Sprachmodells klassifizieren wir den Text in Klassen, d. h. wir klassifizieren das Abstract in die Klassen niedrig oder hoch.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 830, "src_audio": "/acl6060/audio/eval/830.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "tgt_ref": "Wir erhalten die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse darstellt, und verwenden sie als neue Funktionen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 831, "src_audio": "/acl6060/audio/eval/831.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "tgt_ref": "Das Problem bei diesem Ansatz ist, dass Datensätze möglicherweise nur wenige unterschiedliche Entitäten/Texte beinhalten.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 832, "src_audio": "/acl6060/audio/eval/832.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "tgt_ref": "In unserem Experiment enthält fast die Hälfte der Datensätze weniger als 400 Stichproben und der kleinste Datensatz enthält 35 Stichproben in einem Trainingssatz.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 833, "src_audio": "/acl6060/audio/eval/833.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "tgt_ref": "Die Feinabstimmung eines Sprachmodells über diesen Datensatz ist also unwirksam.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 834, "src_audio": "/acl6060/audio/eval/834.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "tgt_ref": "Aber wir können vorherige Kenntnisse über bereits analysierte Datensätze nutzen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 835, "src_audio": "/acl6060/audio/eval/835.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "tgt_ref": "Da wir FeSTE auf mehrere Datensätze anwenden, können wir die „n minus 1“-Datensätze verwenden, um Informationen über die „n minus 1“-Datensätze zu sammeln, und diese Informationen verwenden, wenn wir den n-ten Datensatz analysieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 836, "src_audio": "/acl6060/audio/eval/836.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "tgt_ref": "Wir schlagen vor, eine weitere Feinabstimmungsphase hinzuzufügen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 837, "src_audio": "/acl6060/audio/eval/837.wav", "src_ref": "A preliminary multitask finetuning phase.", "tgt_ref": "Das war eine vorläufige Multitask-Feinabstimmungsphase.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 838, "src_audio": "/acl6060/audio/eval/838.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "tgt_ref": "Die Feinabstimmung des Sprachmodells geht über die „n minus 1“-Datensätze.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 839, "src_audio": "/acl6060/audio/eval/839.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "tgt_ref": "Dann führen wir eine weitere Feinabstimmungsphase durch, die eine Feinabstimmung des Zieldatensatzes ist, wenn wir das Sprachmodell über den n-ten Zieldatensatz feinabstimmen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 840, "src_audio": "/acl6060/audio/eval/840.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "tgt_ref": "Die modernste Multitask-Feinabstimmung wird MTDNN genannt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 841, "src_audio": "/acl6060/audio/eval/841.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "tgt_ref": "Bei der MTDNN bleiben die Überschriften in der Reihe der Aufgaben im Trainingssatz.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 842, "src_audio": "/acl6060/audio/eval/842.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "tgt_ref": "In diesem Beispiel gibt es also vier Aufgaben im Trainingssatz. Das MTDNN enthält also vier Überschriften, wie Sie auf dem Bild sehen können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 843, "src_audio": "/acl6060/audio/eval/843.wav", "src_ref": "And it samples a random batch from ah from the training set.", "tgt_ref": "Es nimmt sich eine Zufallsstichprobe aus dem Trainingssatz heraus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 844, "src_audio": "/acl6060/audio/eval/844.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "tgt_ref": "Wenn die Zufallsstichprobe zum Beispiel zu einer einzelnen Satzklassifikationsaufgabe gehört, führt sie Vorwärts- und Rückwärtspfade durch die erste Überschrift aus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 845, "src_audio": "/acl6060/audio/eval/845.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "tgt_ref": "Wenn die Zufallsstichprobe zur paarweisen Ranking-Aufgabe gehört, führt sie den Vorwärts- und Rückwärtspfad über die letzte Überschrift aus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 846, "src_audio": "/acl6060/audio/eval/846.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "tgt_ref": "In unserem Szenario variieren tabellarische Datensätze in der Anzahl der Klassen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 847, "src_audio": "/acl6060/audio/eval/847.wav", "src_ref": "So there are many tasks.", "tgt_ref": "Es gibt also viele Aufgaben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 848, "src_audio": "/acl6060/audio/eval/848.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "tgt_ref": "MTDNN enthält eine Anzahl von Klassen, Überschriften und ausgegebenen Ebenen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 849, "src_audio": "/acl6060/audio/eval/849.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "tgt_ref": "Und zusätzlich muss MTDNN neue Überschriften für einen neuen Datensatz mit einer neuen Aufgabe initialisieren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 850, "src_audio": "/acl6060/audio/eval/850.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "tgt_ref": "Unser Ansatz, genannt Feinabstimmungsreformulierungsaufgabe, besteht darin, dass wir, anstatt mehrere Überschriften beizubehalten, jeden Datensatz in einen Satz pro Klassifikationssproblem umformulieren, was zwei Klassenaufgaben entspricht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 851, "src_audio": "/acl6060/audio/eval/851.wav", "src_ref": "So let's see an example.", "tgt_ref": "Schauen wir uns ein Beispiel an.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 852, "src_audio": "/acl6060/audio/eval/852.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "tgt_ref": "Hier ist unser eingegebener Datensatz, der aus Entitäten, Funktionen, Text und Klassen besteht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 853, "src_audio": "/acl6060/audio/eval/853.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "tgt_ref": "Wir formulieren die Aufgabe von einer Klassifizierung des Textes in niedrig oder hoch zu einer Klassifizierung des Textes, des Abstracts und der Klasse in wahr oder falsch um.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 854, "src_audio": "/acl6060/audio/eval/854.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "tgt_ref": "Mit anderen Worten: Wir haben das Sprachmodell so trainiert, dass es ein Abstract und die Klasse als Abstract und die Klasse klassifiziert, wenn das Abstract zur Klasse gehört oder nicht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 855, "src_audio": "/acl6060/audio/eval/855.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "tgt_ref": "So bleibt die Vektor-Markierung in diesem Fall bestehen, die immer aus zwei Klassen besteht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 856, "src_audio": "/acl6060/audio/eval/856.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "tgt_ref": "Das ist der Algorithmus für unseren neu formulierten Finabstimmungsansatz.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 857, "src_audio": "/acl6060/audio/eval/857.wav", "src_ref": "So let's see the full framework.", "tgt_ref": "Schauen wir uns also den gesamten Rahmen an.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 858, "src_audio": "/acl6060/audio/eval/858.wav", "src_ref": "Dataset fed into FeSTE.", "tgt_ref": "Der Datensatz wird in FeSTE eingespeist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 859, "src_audio": "/acl6060/audio/eval/859.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "tgt_ref": "Dann führt FeSTE die Entity-Linking-Phase aus.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 860, "src_audio": "/acl6060/audio/eval/860.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "tgt_ref": "Es extrahiert den Text aus der Wissensbasis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 861, "src_audio": "/acl6060/audio/eval/861.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "tgt_ref": "Dann formulierte es die Aufgabe in eine paarweise Satzklassifikationsaufgabe um.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 862, "src_audio": "/acl6060/audio/eval/862.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "tgt_ref": "Das Sprachmodell wird auf die neue Aufgabe und die Ausgabewahrscheinlichkeit für jede Klasse angewandt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 863, "src_audio": "/acl6060/audio/eval/863.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "tgt_ref": "Nun ist das Sprachmodell bereits über den „n minus 1“-Datensatz mithilfe einer vorläufigen Multitask-Feinabstimmung feinabgestimmt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 864, "src_audio": "/acl6060/audio/eval/864.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "tgt_ref": "Dann verwenden wir den Ausgabe-Vektor des Sprachmodells als eine neu generierte Funktion in der Anzahl der Klassen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 865, "src_audio": "/acl6060/audio/eval/865.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "tgt_ref": "Zur Evaluation unseres Rahmens verwenden wir 17 tabellarische Klassifikationsdatensätze, die sich in Größe, Funktionen, Ausgewogenheit, Domäne und anfänglicher Leistung unterscheiden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 866, "src_audio": "/acl6060/audio/eval/866.wav", "src_ref": "And as knowledge base we use Wikipedia.", "tgt_ref": "Als Wissensbasis verwenden wir Wikipedia.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 867, "src_audio": "/acl6060/audio/eval/867.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "tgt_ref": "Wir konzipieren unser Experiment als Leave-One-Out-Evaluation, bei dem wir FeSTe mit 16 Datensätzen trainieren und auf den 17. Datensatz anwenden.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 868, "src_audio": "/acl6060/audio/eval/868.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "tgt_ref": "Außerdem teilen wir jeden Datensatz in vier Brüche auf und wenden eine vierfache Kreuzvalidierung an.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 869, "src_audio": "/acl6060/audio/eval/869.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "tgt_ref": "Dann generieren wir die neuen Funktionen und bewerten sie mit fünf Evaluationssklassifikatoren.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 870, "src_audio": "/acl6060/audio/eval/870.wav", "src_ref": "We use in our experiments base BERT base architecture.", "tgt_ref": "Wir verwenden in unseren Experimenten die Basisarchitektur BERT.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 871, "src_audio": "/acl6060/audio/eval/871.wav", "src_ref": "Here are the results for our experiments.", "tgt_ref": "Hier sind die Ergebnisse unserer Experimente.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 872, "src_audio": "/acl6060/audio/eval/872.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "tgt_ref": "Sie können sehen, dass wir unseren Rahmen mit der Feinabstimmung des Zieldatensatzes, mit der Feinabstimmung der Zielaufgabe und einer vorläufigen MTDNN-Feinabstimmung vergleichen.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 873, "src_audio": "/acl6060/audio/eval/873.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "tgt_ref": "Unsere neu formulierte Feinabstimmung erreicht das beste Ergebnis und die beste Leistung.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 874, "src_audio": "/acl6060/audio/eval/874.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "tgt_ref": "MTDNN erreichte zwei Prozent Verbesserung gegenüber der Feinabstimmung des Zieldatensatzes.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 875, "src_audio": "/acl6060/audio/eval/875.wav", "src_ref": "Our approach achieved six percent improvement.", "tgt_ref": "Mit unserem Ansatz haben wir eine Verbesserung von sechs Prozent erreicht.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 876, "src_audio": "/acl6060/audio/eval/876.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "tgt_ref": "Wenn wir uns den kleinen Datensatz anschauen, sehen wir, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Multitask-Feinabstimmungsphase auf 1,5 Prozent sinkt.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 877, "src_audio": "/acl6060/audio/eval/877.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "tgt_ref": "Aber unsere Leistung stieg auf elf Prozent im Vergleich zur Feinabstimmung des Zieldatensatzes allein.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 878, "src_audio": "/acl6060/audio/eval/878.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "tgt_ref": "Für die Summierung ermöglicht FeSTE in unseren Experimenten eine Few-Shot-Anreicherung aus 35 Proben.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 879, "src_audio": "/acl6060/audio/eval/879.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "tgt_ref": "Es verwendet eine Architektur für alle Aufgaben und Datensätze.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 880, "src_audio": "/acl6060/audio/eval/880.wav", "src_ref": "And it keeps the head of ah of the model.", "tgt_ref": "Und es behält den Hauptteil des Modells.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 881, "src_audio": "/acl6060/audio/eval/881.wav", "src_ref": "But it adds reformulation phase.", "tgt_ref": "Aber es fügt eine Reformulierungsphase hinzu.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 882, "src_audio": "/acl6060/audio/eval/882.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "tgt_ref": "Es erweitert den Trainingssatz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einspeisen und für das Satzpaar-Klassifikationsproblem verwenden können.", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 883, "src_audio": "/acl6060/audio/eval/883.wav", "src_ref": "Thank you.", "tgt_ref": "Vielen Dank!", "src_lang": "en", "tgt_lang": "de", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
