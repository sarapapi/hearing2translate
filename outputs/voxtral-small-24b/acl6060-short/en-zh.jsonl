{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "zh", "output": "大家好。今天我要介绍我们的研究工作《学习演绎推理：将数学问题求解视为复杂推理的提取》。"}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "zh", "output": "我是来自拜登人工智能实验室的艾伦，这是与德克萨斯大学奥斯汀分校的切里和新加坡国立大学的韦鲁合作的成果。"}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我想谈谈我们推理的动机。"}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "zh", "output": "下面我们展示了多步推理的例子。"}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "zh", "output": "这个图片来自于一篇论文，该论文在少量学习场景中使用提示来解决数学问题。"}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "zh", "output": "在网络搜索方面，如果我们只提供一些示例，其中包含问题和答案，我们可能无法获得正确的答案。"}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "zh", "output": "但如果我们提供更多的推理描述，模型就能够预测推理描述，并在此基础上做出正确的预测。"}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "zh", "output": "因此，具有可解释的多步推理作为输出是件好事。"}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "zh", "output": "我们还认为，数学问题可以直接应用于评估这种推理能力。"}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的问题设置中，给定问题，我们需要解决这个问题并获得数值答案。"}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的数据集中，我们还被给予了导致这个特定答案的数学表达式。"}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "zh", "output": "因此，某些假设也适用于之前的工作。"}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设数量的精确度是已知的。"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "zh", "output": "我们只考虑基本运算符，例如加法、减法、乘法、除法和指数运算。"}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "zh", "output": "此外，复杂的运算符实际上可以分解为这些基本运算符。"}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "zh", "output": "因此，以前的数学问题求解工作实际上可以分为序列到序列和序列到树模型。"}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "zh", "output": "因此，传统的序列到序列模型将表达式转换为特定的序列以进行生成。"}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "zh", "output": "而且它的实现非常简单，并且可以推广到许多不同的复杂问题。"}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "zh", "output": "但其性能的缺点实际上通常不如结构模型，并且缺乏可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "zh", "output": "但由于 Transformer 模型，这个方向仍然非常受欢迎。"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "zh", "output": "在基于树的模型中，我们实际上是以树的形式构建这些表达式，并在树的生成中遵循先序遍历。"}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们不断生成运算符，直到我们到达叶子节点，即数量。"}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "zh", "output": "所以，这里的好处是它实际上给了我们这种二叉树结构，但它实际上是相当直观的，因为我们首先生成运算符，然后在最后生成数量。"}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "zh", "output": "第二，它还包含一些重复的计算。"}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "zh", "output": "因此，如果我们看看这个表达式，8×3+3实际上被生成了两次。但实际上，我们应该重用结果。"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的提议中，我们希望通过逐步和可解释的方式解决这些问题。"}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在第二步中，我们可以得到这个除数，即 27。"}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "zh", "output": "我们也可以回顾原始问题，以找到相关内容。"}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "zh", "output": "通过这些步骤，我们获得了除数。"}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "zh", "output": "然后在第三步，我们实际上获得了商。"}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "zh", "output": "好了，经过这三个步骤，我们实际上可以重用第二步的结果，然后得到第四步的结果，最后我们就可以获得股息。"}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，我们实际上是直接生成整个表达式，而不是生成单个运算符或数量。"}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "zh", "output": "这使得该过程更加准确。"}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的演绎系统中，我们首先从问题中给出的一组数量开始，并包括一些常数作为初始状态。"}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "zh", "output": "因此，表达式由 EIJOP 表示。"}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "zh", "output": "我们从 QI 到 QJ 执行操作符，这种表达式实际上是有方向的。"}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们也有减法反向，以表示相反的方向。"}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "zh", "output": "这与关系抽取非常相似。"}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在形式演绎系统中，在时间步长 t，我们在 QI 和 QJ 对之间应用运算符，然后获得这些新表达式。"}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "zh", "output": "我们将其添加到下一个状态，以形成一个新的量子。"}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这些幻灯片实际上可视化了状态的演变，我们不断地将表达式添加到当前状态中。"}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的模型实现中，我们首先使用预训练的语言模型，可以是BERT或RoBERTa，然后我们对句子进行编码，然后我们获得这些量化表示。"}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "zh", "output": "一旦我们获得了量子表示，就可以开始进行推理。"}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们展示了一个示例，用 Q1 除以 Q2，然后乘以 Q3 来获得 Q1 的表示。"}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们获得成对表示，这基本上就是 Q1 和 Q2 之间的连接，然后我们应用一个前馈网络，该网络由运算符参数化。"}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们得到表达式 Q1/Q2。"}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "zh", "output": "但实际上，在推理阶段，我们可能会得到不正确的表达。"}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这里所有可能的表达式等于运算符数量的三倍。"}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "zh", "output": "这里的好处是我们可以轻松地添加约束条件来控制这个搜索空间。"}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "zh", "output": "例如，如果不允许这个表达式，我们可以简单地从搜索空间中删除这个表达式。"}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在第二步中，我们做同样的事情，但唯一的区别是我们增加了一个数量。"}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "zh", "output": "这个数量来自之前计算的表达式。"}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们最终可以获得这个最终表达式Q3。"}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "zh", "output": "我们还可以看到，所有可能的表达式的数量与前一步不同。"}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这种差异使得应用束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。"}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "zh", "output": "因此，训练过程与训练序列到序列模型类似，我们在每个时间步优化损失。"}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "zh", "output": "我们还使用这个符号来表示何时应终止这个生成过程。"}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "zh", "output": "在这里，空间与序列到序列不同，因为每次空间都不同，而在传统的序列到序列模型中，空间是词汇量。"}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "zh", "output": "它还允许我们从先验知识中施加某些约束。"}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们在常用的数学问题数据集上进行了实验，包括MAWPS、Math23K、MathQA和SWM。"}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "zh", "output": "这里我们简要展示了与之前最佳方法相比的结果。"}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们表现最好的变体是 Roberta Det. Reasoner。"}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "zh", "output": "事实上，我们不使用束搜索，而其他方法使用束搜索。"}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "zh", "output": "好的。最好的方法通常是基于树的模型。"}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "zh", "output": "因此，总体而言，我们的推理器能够显著优于该树模型。"}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "zh", "output": "但我们可以看到，MathQA 和 SWAG 上的绝对数字并不高。"}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步调查了结果。"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "zh", "output": "SWAMP，这个数据集具有挑战性，因为作者试图手动添加一些内容来混淆NLP模型，例如添加环境信息和额外的数量。"}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在我们的预测中，我们发现一些中间值实际上是负数。"}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在这些问题中，我们问的是：德雷克有多少个苹果？"}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "zh", "output": "但我们有一些额外的信息，比如菲尔投了 17 个球，史蒂芬投了 8 个球，这完全无关紧要。"}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的模型做出了一些预测，比如这个，它产生了负值。"}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "zh", "output": "我们观察到这两个表达式"}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以通过移除那些结果为负的选项来限制搜索空间，从而使答案正确。"}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们进一步发现，这种约束实际上对某些模型的改进非常大。"}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "zh", "output": "例如，对于鸟类，我们提高了 7 分，而对于基于机器人的模型，我们实际上提高了 2 分。"}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "zh", "output": "因此，语言模型越好，语言理解能力就越强，所以这里的数字对 Roberta 来说更高，而对 BERT 来说更低。"}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "zh", "output": "我们还试图分析这个问题背后的难度。"}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "zh", "output": "我们假设未使用数量可以被视为无关信息。"}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们可以看到，我们有未使用的样本百分比，而 SWAMP 数据集的比例最大。"}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "zh", "output": "我们还展示了整体的表现。"}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "zh", "output": "对于那些没有使用数量的样本，总体表现实际上比总体表现更高。"}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "zh", "output": "但对于那些样本数量不足的情况，实际情况要比... 糟糕得多。"}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "zh", "output": "对于 MAWP，我们没有太多的死亡病例，所以我忽略了这一部分。"}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们想通过一个碰撞预测的例子来展示可解释性。"}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们的模型在第一步时做出了错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "zh", "output": "所以我们可以将这个表达与这个句子联系起来。"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们认为这句话可能会误导模型做出错误的预测。"}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这里再植入 35 会让模型认为应该是加法运算符。"}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们试图修改句子，使其成为类似于“梨树的数量比苹果树少 55 棵”的句子。"}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们使其传达更准确的语义，以便模型能够做出正确的预测。"}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "zh", "output": "因此，这项研究表明，可解释的预测有助于我们理解模型行为。"}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "zh", "output": "因此，总结我们的工作，首先，我们的模型实际上非常高效。"}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "zh", "output": "我们能够提供可解释的求解过程。"}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "zh", "output": "我们可以轻松地将一些先验知识作为约束来加以利用，这有助于提高性能。"}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "zh", "output": "最后一点是，这种潜在的机制不仅适用于数学问题解决任务，还适用于其他涉及多步推理的任务。"}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "zh", "output": "但我们也有一些限制。"}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "zh", "output": "如果我们有大量的运算符或常量，内存消耗可能会很高。"}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "zh", "output": "第二个问题是，正如所提到的，由于不同时间步长的概率分布不平衡，因此应用束搜索也相当具有挑战性。"}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "zh", "output": "这是演讲的结束，欢迎提问。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我叫安东，来自马斯特里赫特大学。"}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "zh", "output": "我将与杰瑞一起介绍我们的联合工作，主题是关于法规条文检索的新数据集。"}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "zh", "output": "法律问题在许多人的生活中占有重要地位。"}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "zh", "output": "但大多数公民对自己的权利和基本法律程序知之甚少。"}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "zh", "output": "结果，许多无力支付昂贵法律专家费用的弱势公民得不到保护，甚至更糟，被剥削。"}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "zh", "output": "我们的工作旨在通过开发有效的法规检索系统来弥合人与法律之间的差距。"}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "zh", "output": "这样的系统可以为不熟悉法律的人提供免费的专业法律援助服务。"}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "zh", "output": "在深入探讨本文的主要贡献之前，我们先来描述一下法规条文检索的问题。"}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "zh", "output": "如果我违反了职业保密义务，我会面临什么风险？"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "zh", "output": "需要一个模型来从大量的立法中检索所有相关的法规条文。"}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "zh", "output": "这项信息检索任务带来了它自己的挑战。"}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "zh", "output": "首先，它涉及两种语言。"}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "zh", "output": "问题用普通的自然语言，法律条文用复杂的法律语言。"}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "zh", "output": "语言分布的这种差异使系统难以检索相关候选者，因为它间接要求一个内在的解释系统，能够将自然问题翻译成与法律条文术语相匹配的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "zh", "output": "此外，法定法律并不是一堆可以单独作为完整信息来源的独立条款，例如新闻或食谱。"}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "zh", "output": "相反，它是一个结构化的法律条文集合，只有在整体上考虑时才有完整的意义，即与相邻条文的补充信息、它们所属的领域和子领域以及它们在法律结构中的位置一起考虑。"}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "zh", "output": "最后，法规条文不是小段落，而小段落通常是大多数检索工作中的典型检索单元。"}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "zh", "output": "这里有长达 6 页的文件。"}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "zh", "output": "自然语言处理的最新进展引发了对许多法律任务的巨大兴趣，例如法律判决预测或自动合同审查。"}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "zh", "output": "但由于缺乏大型高质量标记数据集，法规条文检索仍然主要未受影响。"}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "zh", "output": "在这项工作中，我们提出了一个新的、以法国本土公民为中心的数据集，用于研究检索模型是否能够近似法律专家在法定条款检索任务中的效率和可靠性。"}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "zh", "output": "比利时法定条文检索数据集包含超过 1100 个法律条文。"}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "zh", "output": "这些问题涵盖了广泛的主题，从家庭、住房、金钱到工作和社会保障。"}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "zh", "output": "每个案例都由经验丰富的法律专家标注，并引用了超过 22,600 篇相关文章。"}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "zh", "output": "现在让我们谈谈我们是如何收集这些数据集的。"}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们从编译大量法律文章开始。"}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "zh", "output": "我们考虑了 32 个公开可用的比利时法典，并提取了它们的所有条款以及相应的章节标题。"}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们收集了带有相关法律条文引用的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "zh", "output": "为此，我们与每年收到约 4000 封来自比利时公民的电子邮件的比利时法律事务所合作，这些公民寻求个人法律问题的建议。"}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "zh", "output": "我们很幸运能够访问他们的网站，他们的一支经验丰富的律师团队解答了比利时最常见的法律问题。"}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "zh", "output": "我们收集了成千上万个问题，并对其进行了分类、子分类和相关法律条文的标注。"}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们过滤掉了法律参考文献，并筛选出了那些参考文献不是我们考虑的法律条文的问题。"}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "zh", "output": "剩余的引用已与 OCorpus 中的相应文章 ID 匹配并转换。"}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "zh", "output": "我们最终得到了 1,108 个问题，每个问题都仔细标注了相关的《维基百科》文章的 ID。"}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "zh", "output": "此外，每个问题都有一个主要类别和一个子类别的串联。"}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "zh", "output": "每一条条文都附有其后续标题，以法律结构的形式。"}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "zh", "output": "这些额外信息在当前的工作中没有使用，但可能对未来的法律信息检索或法律文本分类研究有用。"}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "zh", "output": "让我们来看看一些数据集的特征。"}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "zh", "output": "问题的长度在 5 到 44 个单词之间，中位数为 14 个单词。"}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "zh", "output": "文章更长，中位数为 77 个单词，140 个单词。"}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "zh", "output": "其中两个超过1000米。"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "zh", "output": "正如之前提到的，问题涵盖了广泛的主题，其中约 85% 的问题涉及家庭、住房、金钱或正义。"}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "zh", "output": "而剩下的 15% 则涉及社会保障、外国人或工作。"}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "zh", "output": "这些文章也非常多样化，因为它们来自32种不同的比利时法典，涵盖了大量的法律主题。"}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "zh", "output": "以下是从这些比利时代码中收集的文章总数。"}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "zh", "output": "在 22,633 篇文章中，只有 1,612 篇被认为与至少一项研究相关。"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "zh", "output": "数据集中的一个问题。这些引用文章中有大约 80% 来自民法、司法法、刑事诉讼法或刑法。"}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "zh", "output": "与此同时，32 个代码中有 18 个代码被提及的相关文章少于 5 篇。"}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "zh", "output": "这可能是由于《德法法典》更少关注个人及其关切。"}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，这些被引用文章的中位引用数量为 2，不到 25% 的文章被引用了 10 次或更多次。"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "zh", "output": "使用我们的数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。"}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "zh", "output": "给定查询和文章，词汇模型通过计算查询词汇在该文章中的权重之和，为查询-文章对赋分。"}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试使用标准的 TF-IDF 和 BM25 排名函数。"}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "zh", "output": "这些方法的主要问题是，它们只能检索包含查询中关键字的文章。"}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "zh", "output": "为了克服这一限制，我们尝试使用一种神经网络架构，它可以捕捉查询和文章之间的语义关系。"}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用 B-Encoder 模型，将查询和文章映射到密集向量表示，并通过它们的嵌入的相似性计算查询-文章对的相关性得分。"}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "zh", "output": "这些嵌入通常是对词嵌入模型输出的池化操作的结果。"}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们在零样本评估设置中研究了孪生编码器的有效性，这意味着预训练的木材嵌入模型是直接应用的，而不需要任何额外的微调。"}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试使用上下文无关的文本编码器，即 Word2Vec 和 FastText，以及上下文相关的嵌入模型，即 RoBERTa，更具体地说是 CamemBERT，这是一个法语 RoBERTa 模型。"}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们还训练了自己的基于 Camembert 的模型，即 BeyondCoder。"}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "zh", "output": "在所有数据集上。请注意，在训练中，我们尝试了两种Bianco架构的变体。"}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "zh", "output": "Siamese，它使用一种独特的词嵌入模型，将查询和文章一起映射到共享的稠密向量空间中；以及两塔，它使用两个独立的词嵌入模型，将查询和文章分别编码到不同的嵌入空间中。"}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "zh", "output": "我们尝试使用均值、最大值和 CLS 池化，以及点积和余弦来计算相似性。"}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们在测试集上得到的基线结果。"}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "zh", "output": "在上方使用词法方法，在中间使用零样本设置评估的 Siamese B-encoders，在下方使用微调 B-encoders。"}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "zh", "output": "总的来说，精调后的解码器在所有其他基线上表现出显著优势。"}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "zh", "output": "双塔模型在召回率方面优于其“西米”变体，但在其他指标方面表现相似。"}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "zh", "output": "尽管 BM25 的表现不如训练过的 BERT 模型，但其表现仍表明它是特定领域检索的强大基线。"}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "zh", "output": "关于 Siamese BERT 编码器的零样本评估，我们发现直接使用预训练的 CamemBERT 模型的嵌入，而不优化信息检索任务，会导致结果不佳，这与之前的发现一致。"}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们观察到基于 Word2Vec 的编码器显著优于基于 FastText 和 BERT 的模型，这表明，也许预训练的词级嵌入比字符级或子词级嵌入更适合该任务，尤其是在直接使用时。"}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "zh", "output": "尽管前景看好，但这些结果表明，与能够检索出与任何问题相关的所有文章并因此获得完美分数的熟练专家相比，仍有大量改进的机会。"}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "zh", "output": "最后，让我们讨论一下我们数据集的两个局限性。"}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "zh", "output": "首先，文章的语料库仅限于从32个比利时法典中收集的文章，这并不涵盖整个比利时法律，因为缺少法令、指令和法规中的文章。"}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "zh", "output": "在数据集构建过程中，所有对这些未收集文章的引用都被忽略，这会导致一些问题，最终只剩下最初相关文章数量的一小部分。"}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "zh", "output": "这种信息丢失意味着，剩余相关文章中的答案可能不完整，但仍然完全适用。"}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们要注意到，并非所有法律问题都能仅通过法律条文来解答。"}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "zh", "output": "例如，问题“如果租户制造太多噪音，我可以驱逐他们吗？”"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "zh", "output": "在法律中可能没有详细规定噪音的具体阈值，超过该阈值就可以驱逐租户。"}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "zh", "output": "相反，地主可能更应该依靠判例法，并找到与当前情况相似的先例。"}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "zh", "output": "例如，租户每周支付两次租金，直到 2 月 8 日。"}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "zh", "output": "因此，有些问题比其他问题更适合法规条文检索任务，而不太适合的问题的领域仍有待确定。"}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "zh", "output": "我们希望这项工作能激发开发实用且可靠的法规条文检索模型的兴趣。"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "zh", "output": "这可以帮助改善所有人的司法公正。"}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "zh", "output": "您可以在以下链接中查看我们的论文、数据集和代码。谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，很高兴向大家介绍我们的 VALSE 工作，这是一个旨在测试视觉和语言模型的任务无关基准，专门针对特定的语言现象。"}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "zh", "output": "我们为什么要费力设置这个基准？"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "zh", "output": "在过去几年中，我们见证了基于 Transformer 的视觉和语言模型的爆炸式增长，这些模型是基于大量图像-文本对进行预训练的。"}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "zh", "output": "这些模型都在视觉和语言任务方面推动了最新的技术，例如视觉问答、视觉常识推理、图像检索和短语定位。"}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们收到了一条消息，这些特定任务的基准准确性正在稳步提高。"}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们真的知道这些模型学到了什么吗？"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "zh", "output": "当视觉和语言转换器为这张图片和这句话打高分时，它理解了什么？"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "zh", "output": "这个的低分。"}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "zh", "output": "视觉和语言模型是否关注正确的事物？"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "zh", "output": "他们是否专注于偏见，正如之前的研究所展示的那样？"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "zh", "output": "为了更好地阐明这一问题，我们提出了一种更加任务无关的方向，并引入了测试视觉和语言模型对影响语言和视觉两种模态的特定语言现象敏感性的测试。"}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "zh", "output": "我们的目标是存在、多样性、计数、空间关系、动作和实体共指。"}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "zh", "output": "但是，我们如何测试视觉和语言模型是否捕捉到了这种现象呢？"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "zh", "output": "通过 FOILING 方法，该方法之前仅由拉维·谢卡尔及其合作者应用于视觉和语言模型中的名词短语，以及我们在之前的工作中应用于计数。"}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "zh", "output": "“foiling” 的意思是，我们拿一张图片的标题，通过改变标题使其不再描述这张图片，从而生成一个“foil”。"}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过专注于六个特定部分来进行这些短语变化，例如存在、多样性、计数、空间关系、动作和实体共指，每个部分可以由一个或多个工具组成，如果我们发现了多种有趣的方法来创建对照实例。"}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在“动作”部分，我们有两种工具，一种是用不同的动作改变动作动词，另一种是交换动作。"}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "zh", "output": "“Counting” 和 “Coreference” 也是有多个乐器的乐曲。"}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过确保这些干扰项无法描述图像，但它们是语法正确且其他方面有效的句子来创建这些干扰项。"}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "zh", "output": "这并不容易，因为错误的标题可能比原始标题的可能性小。"}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "zh", "output": "例如，虽然并非不可能，但从统计学上看，植物割伤人类的可能性比人类割伤植物的可能性要小，而大型视觉和语言模型可以捕捉到这一点。"}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了获得有效的油漆，我们必须采取行动。"}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我们利用强大的语言模型来提出假设。"}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "zh", "output": "其次，我们使用自然语言推理（简称 NLI）来过滤掉那些仍然可能描述图像的反例，因为在构建反例时，我们需要确保它们不能描述图像。"}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "zh", "output": "为了自动测试这一点，我们应用自然语言推理，其原理如下。"}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "zh", "output": "我们认为图像是前提，而其标题是隐含的假设。"}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "zh", "output": "此外，我们认为标题是前提，而反例是其假设。"}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "zh", "output": "如果 NLI 模型预测 FOIL 与标题相矛盾或中立，我们将其视为有效 FOIL 的指标。"}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "zh", "output": "如果 NLI 预测 foil 被 caption 所蕴含，那么它就不是一个好的 foil，因为根据传递性，它会对图像给出真实的描述，我们会过滤掉这些 foil。"}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "zh", "output": "但这种方法并不完美，它只是有效的指示器。"}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "zh", "output": "因此，作为生成有效 FOIs 的第三种措施，我们雇佣人类标注者来验证 VALS 中使用的数据。"}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在过滤和人工评估后，我们有了与本表中描述的一样多的测试实例。"}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "zh", "output": "请注意，VALS 仅提供测试数据，而不提供任何培训数据。"}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "zh", "output": "由于它是一个零样本测试基准，因此它旨在利用视觉和语言模型在预训练后的现有能力。"}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "zh", "output": "微调只能使模型利用数据中的伪影或统计偏差。"}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "zh", "output": "我们都知道这些模型喜欢作弊和走捷径。"}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "zh", "output": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具备的能力。"}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "zh", "output": "我们在 VALSE 上对五种视觉和语言模型进行了实验，即 CLIP、AlexMert、ViLBERT、ViLBERT12-in-1 和 VisualBERT。"}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "zh", "output": "我们最重要的评估指标之一是模型在将图像-句子对分类为标题和非标题方面的准确性。"}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "zh", "output": "也许对这段视频更相关的是，我们将展示我们更宽松的指标，即成对准确性，它衡量的是图像-句子对齐分数是否大于正确的图像-文本对，而不是其对手。"}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "zh", "output": "有关更多指标和结果，请查看我们的论文。"}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "zh", "output": "这里显示了成对准确性的结果，这些结果与我们从其他指标获得的结果一致。最佳零次射击性能由Vilbert 12-in-1实现，其次是Vilbert、AlexMert、Clip，最后是VisualBERT。"}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "zh", "output": "值得注意的一点是，以个体对象（如存在和名词短语）为中心的工具几乎被 Wilbert 12-in-1 解决了，这突显了模型能够识别图像中命名对象及其存在的能力。"}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "zh", "output": "然而，在我们的对抗性防护设置中，剩下的任何部分都无法可靠地解决。"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "zh", "output": "从多样性和计数工具中可以看出，视觉和语言模型在区分图像中单个对象和多个对象的引用或计数时存在困难。"}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "zh", "output": "“关系”部分显示，他们在正确分类图像中物体之间的命名空间关系方面存在困难。"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "zh", "output": "即使有可信度偏见的支持，他们也很难区分动作并识别参与者，就像我们在动作部分看到的那样。"}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "zh", "output": "从共指文献中，我们了解到，通过使用代词追踪图像中对同一对象的多个引用，对视觉和语言模型来说也是困难的。"}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "zh", "output": "作为一个健全性检查，并且因为这是一个有趣的实验，我们还对两个仅文本模型 GPT-1 和 GPT-2 进行了基准测试，以评估这些单模型是否能够通过计算正确和错误标题的困惑度（这里没有图像）并预测困惑度最低的条目来解决 VALSE。"}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "zh", "output": "如果干扰项的困惑度更高，我们就认为被干扰的标题可能会受到可信度偏差或其他语言偏差的影响。"}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "zh", "output": "有趣的是，在某些情况下，仅文本的 GPT 模型比视觉和语言模型更好地捕捉到了世界的可信度。"}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "zh", "output": "总结一下，VALSE 是一个基准，它利用语言结构的视角来帮助社区通过严格测试其视觉定位能力来改进视觉和语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验表明，视觉和语言模型在图像中识别命名对象的存在方面表现良好，但当被迫遵守语言指示时，它们在将对象的相互依赖关系和视觉场景联系起来方面表现不佳。"}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "zh", "output": "我们非常希望社区能够使用 VALSE 来衡量语言与视觉语言模型的语言接地进展。"}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "zh", "output": "此外，VALS 还可以作为数据集的间接评估，因为在训练或微调前后，可以评估模型，以查看数据集是否有助于模型在 VALS 测试的任何方面取得进步。"}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "zh", "output": "如果你有兴趣，请查看 GitHub 上的 Vals 数据，如果你有任何问题，请随时联系我们。"}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "zh", "output": "大家好，我是来自东京大学的上原。"}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "zh", "output": "我将介绍一篇题为《RN-Sum：用于自动提取注释的大规模数据集》的论文。"}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "zh", "output": "我有经验吗？"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "zh", "output": "首先，我将介绍我们在本研究中正在进行的自动理财生成。"}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "zh", "output": "发行说明是一份技术文档，总结了每次软件产品发行时所分发的变更。"}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "zh", "output": "图片显示了 2.6 版本的发行说明。"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "zh", "output": "JUS 图书馆。这些节点在开源软件开发中起着重要作用，但手动准备它们需要花费大量时间。"}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "zh", "output": "因此，能够自动生成高质量的发行说明将非常有用。"}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "zh", "output": "我将引用两项关于自动听众生成的先前研究。"}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "zh", "output": "第一个是 2014 年发布的 Arena 系统。"}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "zh", "output": "它采用基于规则的方法，例如使用变更提取器从发行版之间的差异中提取核心差异、库变更和文档变更，最后将它们结合起来。"}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "zh", "output": "该系统最显著的特点是右上角的问题提取器。"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "zh", "output": "它必须与 JIRA（问题跟踪系统）链接，并且只能应用于使用 JIRA 的项目。"}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "zh", "output": "换句话说，它不能用于 GitHub 上的许多项目。"}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "zh", "output": "第二是悲伤。2013 年，这项研究公布了结果。"}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "zh", "output": "它可以在互联网上找到，并且可以被人类存储。"}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "zh", "output": "该系统具有简单的基于学习的文本分类模型，并为每个输入的提交消息输出五个标签之一，例如“功能”或“修复”。"}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "zh", "output": "该图像是一个示例用法，它返回一个包含错误修复标签的集合。"}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "zh", "output": "Quora 的训练数据量相当小，大约只有 5000 条，这将在下面描述的实验中显示出来。"}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "zh", "output": "文本交叉验证模型的性能并不高。"}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "zh", "output": "我提出了两项相关的研究，但存在适用性有限和数据资源匮乏的问题。"}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "zh", "output": "我们的论文解决了这两个问题，并自动生成高质量的发行说明。"}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "zh", "output": "针对适用性有限的问题，我们提出了一种仅使用提交消息作为输入的高质量代码摘要方法。"}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "zh", "output": "这种提议的方法可以用于所有英语设备。"}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "zh", "output": "为了解决稀缺数据资源的第二个问题，我们通过使用 GitHub API 从公共 GitHub 存储库中收集数据，构建了一个包含约 82,000 个数据点的 R 和 SUM 数据集。"}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我将描述我所做的工作。"}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "zh", "output": "以下是我们的数据示例。"}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "zh", "output": "左侧是提交信息，右侧是发行说明。"}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "zh", "output": "发行说明中标记了“改进”、“错误修复”等。"}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "zh", "output": "我们设置了一个任务，它以提交消息作为输入，并输出原始的 JSON 文件。"}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "zh", "output": "这可以被视为总结任务。"}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "zh", "output": "我们预先定义了四个标签：功能、改进、错误修复、删除和重大更改。"}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "zh", "output": "这些是基于先前的研究和其他事实而设定的。"}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "zh", "output": "右下角的叶脉是从左下角的叶脉中提取出来的。"}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "zh", "output": "此时，需要检测到事先设置的四个陷阱。"}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "zh", "output": "但每个库的标签并不总是一致的。"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "zh", "output": "例如，改进标签包括改进、增强、优化等。"}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "zh", "output": "我们为每种记谱法变体准备了一个由研究人员编制的词汇表。"}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "zh", "output": "使用它来检测发布说明类别，并将其余部分的文本作为该类别的发布说明句子进行纠正。"}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "zh", "output": "接下来是提交消息。"}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "zh", "output": "提交信息与每个分支无关。"}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "zh", "output": "如下图所示，如果当前版本是 2.5.19，我们需要标识"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "zh", "output": "确定先前的发行版本（2.5.18）并获取其深度。这有点麻烦，仅获取发行版列表并查看前后是不够的。"}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "zh", "output": "我们创建了一个启发式匹配规则来获取前一个和下一个版本。"}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "zh", "output": "你认识他吗？"}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "zh", "output": "最终，有 7200 个存储库。"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "zh", "output": "此外，平均每个释放节点的令牌数量为 63，这对于概括任务来说是相当高的。"}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "zh", "output": "此外，独特令牌的数量也相当大，达到了 880,000 个。"}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "zh", "output": "由于在库中发现了大量独特的类和方法名称。"}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "zh", "output": "接下来，我将解释所提出的方法。"}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "zh", "output": "类别抽取和抽象总结模型由两个神经模块组成。"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "zh", "output": "使用BERT或CodeBERT的分类器和使用BART的生成器。"}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "zh", "output": "首先，CAS 使用分类器将每条提交消息分类为五个类别：功能、实现、修复、文档和其他。"}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "zh", "output": "提交消息被归类为“其他”或“丢弃”。"}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "zh", "output": "然后，CAS 将生成器应用于四个标签文档，并为每个类生成一个列表节点。"}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "zh", "output": "在本任务中，提交信息与原因之间的直接对应关系是未知的。"}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "zh", "output": "因此，为了训练分类器，我们使用每条提交消息的前 10 个字符为每条输入提交消息分配伪标签。"}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "zh", "output": "我们通过两种不同的方法对类别抽象摘要进行建模。"}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "zh", "output": "第一个模型，我们称之为“单一 GCS”，由一个单一的 seq2seq 网络组成，并生成一段长文本，给出输入提交消息的连接。"}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "zh", "output": "输出文本可以根据特定的类别特定的终止符号分为类别分段。"}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "zh", "output": "第二种方法，我们称之为“CAS-Match”，由四个不同的“sec2sec”网络组成，每个网络对应一个“reach node”类别。"}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "zh", "output": "好的，让我解释一下这个实验。"}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "zh", "output": "比较了五种方法：CAS、CAS单、CAS多、PlasLink和以前的研究Griff。"}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "zh", "output": "在某些情况下，评估的输出是多个句子。"}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "zh", "output": "由于很难计算句子的数量，因此将它们与空格结合起来，并将其视为一个长句。"}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "zh", "output": "当系统输出一个短句时，蓝色会变暗。"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "zh", "output": "这种惩罚导致了实验结果中较低的蓝色值，下面将对此进行描述。"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "zh", "output": "最后，我们还计算了特异性，因为如果发布笔记为空，则无法计算 Rouge 和 Bleu。"}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "zh", "output": "高特异性意味着模型在实际节点为空的情况下输出空文本。"}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "zh", "output": "以下是结果。"}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "zh", "output": "由于数据集包含电子邮件地址、哈希值等，我们还评估了经过清理的数据集（排除了这些内容）。"}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "zh", "output": "CAS 和 CAS 的 ROUGE 得分比基线高出 10 分以上。"}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "zh", "output": "特别是在清洁测试集上，所提出的方法与基线方法之间的得分差距超过了 20 分。"}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "zh", "output": "这些结果表明，CS 和 CS 具有显著的效果。"}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "zh", "output": "CAS 的鲁棒性得分比 CAS 高，这表明将分类器与生成器结合起来是有效的，并且使用两者来训练分类器是有效的。"}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "zh", "output": "由于分类器可以专注于为每个类选择相关的提交消息，因此可以实现高CAS覆盖率。"}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "zh", "output": "CAS 多重化倾向于比 CAS 单重化具有更高的鲁棒性。"}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "zh", "output": "这表明，为每个病例笔记类别独立开发不同的吸收摘要模型也很有效。"}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "zh", "output": "这里是错误分析。"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "zh", "output": "CS方法倾向于输出比人类参考句子更短的句子。"}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "zh", "output": "右图中，参考句子有三到四个句子，而CUS 只有一个句子。"}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "zh", "output": "这种模型的犹豫不决的原因是，在训练数据中，只有 33% 的句子在“特征”标签中出现，40% 在“改进”标签中出现。"}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "zh", "output": "此外，没有额外信息，CS 方法无法生成准确的 B 结点。"}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "zh", "output": "右侧顶部的示例是一个非常混乱的提交消息示例，而不参考相应的拉取请求或问题，就无法生成完整的句子。"}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "zh", "output": "下面的示例显示了输入中的两个提交消息是相关的，并且应该合并为一个句子，但它不这样做。"}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "zh", "output": "最后，结论。"}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "zh", "output": "我们为自动驾驶汽车创建了一个新的数据集。"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "zh", "output": "我们还为您提供了输入提交信息并总结它们的任务，以便适用于所有用英语编写的项目。"}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "zh", "output": "我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下生成的叶节点更少噪声。"}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "zh", "output": "请检查代码或删除该行。"}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。"}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我叫萨法里。"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "zh", "output": "我将介绍我们的论文《使用微调 Transformer 架构的少量表格数据丰富》。"}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "zh", "output": "数据科学家分析数据，主要集中在操纵数据的现有特征。"}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "zh", "output": "但有时这些功能是有限的。"}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "zh", "output": "使用另一个数据源生成特征可能会添加大量信息。"}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "zh", "output": "我们的研究目标是利用外部来源的自由文本自动丰富表格数据。"}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "zh", "output": "假设我们有一个表格数据集和一个知识库。"}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "zh", "output": "我们需要一个自动化流程，该流程涉及实体链接和文本分析，以从知识库的自由文本中提取新特征。"}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "zh", "output": "我们的框架 F.A.S.T. 就是这个自动化过程。"}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "zh", "output": "例如，在输入到 FAST 的数据集中。"}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，数据集是大学数据集。"}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "zh", "output": "当其目标是将大学分类为低排名大学和高排名大学时。"}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用维基百科作为知识库。"}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "zh", "output": "FEST 的第一个阶段是实体链接。"}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "zh", "output": "每个实体（本例中为大学名称）都与知识库中的实体相关联。"}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "zh", "output": "知识库中的实体文本被提取并添加到数据集中。"}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，文本是维基百科页面的摘要。"}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "zh", "output": "现在我们需要从检索文本中生成或提取特征。"}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "zh", "output": "因此，我们需要一个特征提取阶段，其中包括文本分析。"}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "zh", "output": "这也是这篇论文的主要创新之处，我将在接下来的幻灯片中深入探讨。"}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "zh", "output": "在特征提取阶段之后，会有一个特征生成阶段，我们会使用提取的特征来生成少量的新特征。"}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "zh", "output": "首先，生成与原始数据集中类别数量相同的特征。"}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，原始数据集有两个类别。"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "zh", "output": "因此，FAST 生成了两个新特征。"}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "zh", "output": "但如果数据集有五个类别，首先生成五个新特征。"}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "zh", "output": "每个特征代表每个类别的可能性。"}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "zh", "output": "要分析文本，我们使用当前最先进的文本分析方法，即基于变压器的语言模型，例如 BERT、XLNet 等。"}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "zh", "output": "但我们不太可能使用输入数据集来训练语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "zh", "output": "因此，天真的方法是目标任务微调。"}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "zh", "output": "在特征提取阶段，我们可以下载预训练的语言模型，然后在目标数据集上微调语言模型。"}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "zh", "output": "在这个例子中，要微调语言模型，将文本分类为“抽象”类别，分为“低”或“高”类别。"}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "zh", "output": "接收语言模型的输出，即每个类别的可能性，并将其作为新的特征。"}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "zh", "output": "这种方法的问题是，数据集可能只有少量的实体标签。"}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，几乎一半的数据集包含少于 400 个样本，最小的数据集包含 35 个样本。"}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在该数据集上微调语言模型将是无效的。"}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "zh", "output": "但我们可以利用对预分析数据集的先验知识。"}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "zh", "output": "因为我们在多个数据集上应用了 FAST，所以我们可以使用 n-1 个数据集来收集有关 n-1 个数据集的信息，并在分析 n 个数据集时使用这些信息。"}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "zh", "output": "我们建议添加另一个微调阶段。"}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "zh", "output": "预训练多任务微调阶段。"}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "zh", "output": "当你在 N-1 数据集上微调语言模型时，"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们执行另一个微调阶段，即目标任务微调，我们在 n 个目标数据集上对语言模型进行微调。"}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "zh", "output": "多任务微调的最新技术称为“多任务提示微调”（MT-DNN）。"}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "zh", "output": "在 MT-DNN 中，MT-DNN 维护了与训练集中的任务数量相同的头。"}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在这个例子中，训练集中有四个任务，所以空的 DNN 保持四个头，如图所示。"}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "zh", "output": "它从训练集中随机抽取一个批次。"}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "zh", "output": "如果运行批次属于单个句子分类任务，则执行前向和后向传递，通过第一个头。"}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "zh", "output": "如果随机批次属于成对排名任务，则其前向和后向传递通过最后一个头。"}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的场景中，表格数据集包含类别数量。"}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "zh", "output": "因此，有许多任务。"}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "zh", "output": "空DNN保持类别数量（输出层）。"}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "zh", "output": "此外，MT-DNN 需要为新任务的新数据集初始化新的头。"}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法称为任务重新表述微调，我们的方法是任务重新表述微调，而不是保留多个头，我们将每个数据集重新表述为每个分类问题的句子，这是一个两类任务。"}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "zh", "output": "让我们看一个例子。"}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的输入数据集，其中包含实体、特征、文本和类别。"}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "zh", "output": "我们将把任务从将文本分类为“低”和“高”改为将文本、摘要和类别分类为“真”或“假”。"}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "zh", "output": "换句话说，我们训练语言模型来分类摘要和类别，以确定摘要是否属于该类别。"}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "zh", "output": "因此，在Zix的情况下，标签向量始终由两个类组成。"}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们的微调方法的算法。"}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "zh", "output": "让我们看看完整的框架。"}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "zh", "output": "数据集被输入到 FAST。"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "zh", "output": "然后是快速执行实体链接阶段。"}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "zh", "output": "它从知识库中提取文本，在这个例子中，知识库是维基百科页面的摘要。"}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "zh", "output": "然后，它将任务重新表述为句子分类任务。"}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "zh", "output": "将语言模型应用于新任务，并输出每个类别的可能性。"}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "zh", "output": "请注意，语言模型已经在 N-1 数据集上进行了微调，使用的是预备的多任务微调。"}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "zh", "output": "然后，我们将语言模型的输出向量作为新生成的特征，用于分类数量。"}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "zh", "output": "为了评估我们的框架，我们使用了 17 个表格分类数据集，这些数据集在大小、特征、平衡性、领域和初始性能方面各不相同。"}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "zh", "output": "我们使用维基百科作为知识库。"}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "zh", "output": "我们设计的实验是留一法评估，当我们在 16 个数据集上训练 FAST 并将其应用于第 17 个数据集时。"}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "zh", "output": "我们还将每个数据集分成四个子集，并应用四折交叉验证。"}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "zh", "output": "然后我们生成新的特征，并使用五种评估分类器对其进行评估。"}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "zh", "output": "我们在实验中使用基于 BERT 的架构。"}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "zh", "output": "这是我们实验的结果。"}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "zh", "output": "你可以看到，我们将我们的框架与目标数据集微调、目标任务微调和空DNN预微调进行了比较。"}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "zh", "output": "我们重新制定的微调方法取得了最佳结果，表现最好。"}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "zh", "output": "虽然空的 DNN 在目标数据集微调方面取得了 2% 的改进，"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "zh", "output": "我们的方法取得了 6% 的改进。"}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "zh", "output": "在小数据集上，我们可以看到，空DNN的性能下降，而预训练多任务微调阶段的改进降至1.5%。"}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "zh", "output": "但与目标任务微调相比，我们的性能提高了 11%。"}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "zh", "output": "在我们的实验中，FAST 从 35 个样本中实现了少样本增强。"}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "zh", "output": "它使用一种架构来处理所有任务和数据集。"}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "zh", "output": "它保留了模型的头部。"}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "zh", "output": "但它增加了重新表述阶段。"}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "zh", "output": "它会增强数据集，并为其添加具有语义意义的目标值，以便我们可以将其输入语言模型，并用于句子对分类问题。"}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "zh", "output": "谢谢。"}
