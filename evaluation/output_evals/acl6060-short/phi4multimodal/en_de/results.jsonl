{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen, heute werde ich unsere Forschungsarbeit vorstellen, das Erlernen der deduktiven Argumentation, das Lösen von Matheproblemen als komplexe Regionsextraktion.", "metrics": {"bleu_score": 12.586347848916265, "chrf_score": 52.750614822388364, "xcomet_score": 0.9265515804290771, "xcomet_qe_score": 0.9203689098358154, "metricx_score": 2.578390121459961, "metricx_qe_score": 2.1673009395599365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von bydance ai lab und dies ist eine gemeinsame Arbeit mit Cheryle von der University of Texas at Austin und Wei Lu von suudd.", "metrics": {"bleu_score": 44.82508886944377, "chrf_score": 67.85950201587457, "xcomet_score": 0.7295637130737305, "xcomet_qe_score": 0.7344987392425537, "metricx_score": 7.359961986541748, "metricx_qe_score": 7.209465980529785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst möchte ich über unsere Motivation zum Argumentieren sprechen.", "metrics": {"bleu_score": 47.53852732567741, "chrf_score": 79.0004810825208, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08230084180831909, "metricx_qe_score": 0.39760926365852356, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, in denen Mehrschritt-Argumentation hilfreich ist.", "metrics": {"bleu_score": 13.977689291213357, "chrf_score": 47.57864826110774, "xcomet_score": 0.9781262874603271, "xcomet_qe_score": 0.9853711128234863, "metricx_score": 0.4165676236152649, "metricx_qe_score": 0.2651974558830261, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung stammt aus dem Paddock-Papier, wo sie eine Aufforderung zur Lösung des mathematischen Problems in einem kurzen Lernszenario durchführen.", "metrics": {"bleu_score": 20.82198320914846, "chrf_score": 52.47382335047701, "xcomet_score": 0.6581680178642273, "xcomet_qe_score": 0.6887349486351013, "metricx_score": 8.357083320617676, "metricx_qe_score": 6.942629337310791, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der Net-Pad-Seite können wir also sehen, dass wir bei einigen Beispielen, die nur Fragen und Antworten enthalten, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten.", "metrics": {"bleu_score": 21.61600519890841, "chrf_score": 61.38547155307024, "xcomet_score": 0.892528772354126, "xcomet_qe_score": 0.8822639584541321, "metricx_score": 1.6453566551208496, "metricx_qe_score": 1.8385282754898071, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Aber wenn wir mehr Argumentationsbeschreibung geben, kann das Modell die Argumentationsbeschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen.", "metrics": {"bleu_score": 9.55223130240429, "chrf_score": 64.62935867650798, "xcomet_score": 0.9753646850585938, "xcomet_qe_score": 1.0, "metricx_score": 0.3992055058479309, "metricx_qe_score": 0.4106571674346924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, interpretierbare, mehrstufige Argumentation als Ausgabe zu haben.", "metrics": {"bleu_score": 44.71018619258421, "chrf_score": 74.98447923249664, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8188890218734741, "metricx_qe_score": 0.6644158363342285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir denken auch, dass das Metrower Problem eine einfache Anwendung ist, um solche Argumentationsfähigkeiten zu bewerten.", "metrics": {"bleu_score": 47.97543511401897, "chrf_score": 74.91700924636375, "xcomet_score": 0.9165686368942261, "xcomet_qe_score": 0.9042748808860779, "metricx_score": 4.728353977203369, "metricx_qe_score": 5.688939094543457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Problemstellung müssen wir also angesichts der gestellten Fragen diese Frage lösen und die numerischen Antworten erhalten.", "metrics": {"bleu_score": 68.59238121837059, "chrf_score": 84.11884109030632, "xcomet_score": 0.9968305826187134, "xcomet_qe_score": 0.9858447313308716, "metricx_score": 0.6437485218048096, "metricx_qe_score": 1.1925904750823975, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen erhalten wir auch die mathematische Ausdrucksweise, die zu dieser speziellen Antwort führt.", "metrics": {"bleu_score": 17.383699257236064, "chrf_score": 64.98157830326258, "xcomet_score": 0.9798698425292969, "xcomet_qe_score": 0.9720019698143005, "metricx_score": 2.2687270641326904, "metricx_qe_score": 3.6492156982421875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "So gelten auch bestimmte Annahmen, wie in früheren Arbeiten.", "metrics": {"bleu_score": 39.23542209424606, "chrf_score": 72.59727129404217, "xcomet_score": 0.9843739867210388, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.3132494688034058, "metricx_qe_score": 1.239505648612976, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "We assume the precision of quantities are known.", "metrics": {"bleu_score": 3.056960239296902, "chrf_score": 14.781163298466904, "xcomet_score": 0.9473754167556763, "xcomet_qe_score": 1.0, "metricx_score": 24.36939239501953, "metricx_qe_score": 23.222091674804688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential.", "metrics": {"bleu_score": 88.43946454355333, "chrf_score": 93.2282436226332, "xcomet_score": 0.9847314357757568, "xcomet_qe_score": 0.9869264364242554, "metricx_score": 0.6797162294387817, "metricx_qe_score": 1.0274807214736938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem können komplexe Operatoren tatsächlich in diese grundlegenden Operatoren zerlegt werden.", "metrics": {"bleu_score": 17.242221289766636, "chrf_score": 59.83418200864682, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.34410229325294495, "metricx_qe_score": 0.3624913692474365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten im Bereich der Methodenproblem-Lösung können also in Sequenz-zu-Sequenz- und Sequenz-zu-Baummodelle unterteilt werden.", "metrics": {"bleu_score": 15.934326838673726, "chrf_score": 54.44143375014732, "xcomet_score": 0.9089585542678833, "xcomet_qe_score": 0.7482323050498962, "metricx_score": 4.085643291473389, "metricx_qe_score": 4.3219170570373535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Das traditionelle Sequenz-zu-Sequenz-Modell wandelt den Ausdruck in eine bestimmte Sequenz für die Generierung um.", "metrics": {"bleu_score": 61.60362085721387, "chrf_score": 83.34086688725529, "xcomet_score": 0.9673161506652832, "xcomet_qe_score": 0.9434313774108887, "metricx_score": 0.39299091696739197, "metricx_qe_score": 0.6167879700660706, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist ziemlich einfach zu implementieren, und es kann auf viele verschiedene, komplizierte Probleme verallgemeinert werden.", "metrics": {"bleu_score": 40.1577332834242, "chrf_score": 85.87844102455242, "xcomet_score": 0.9966082572937012, "xcomet_qe_score": 0.9948526620864868, "metricx_score": 0.2091112583875656, "metricx_qe_score": 0.24340806901454926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Nachteile sind, dass die Leistung in der Regel nicht besser ist als das Strukturmodell, und es fehlt an Interpretierbarkeit für die Vorhersage.", "metrics": {"bleu_score": 24.549958769136765, "chrf_score": 60.86757323684247, "xcomet_score": 0.9624195098876953, "xcomet_qe_score": 0.9847941398620605, "metricx_score": 0.632236123085022, "metricx_qe_score": 0.6961886286735535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Richtung noch ziemlich beliebt wegen des Transformator-Modells.", "metrics": {"bleu_score": 41.24914892312111, "chrf_score": 74.42393955483658, "xcomet_score": 0.9881284236907959, "xcomet_qe_score": 0.9851628541946411, "metricx_score": 1.0835083723068237, "metricx_qe_score": 1.8340681791305542, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in einer Baumform und folgen einer Vorabtraversierung in der Baumgenerierung.", "metrics": {"bleu_score": 40.4727200247809, "chrf_score": 72.74985995906569, "xcomet_score": 0.8885906934738159, "xcomet_qe_score": 0.9252954721450806, "metricx_score": 2.646426200866699, "metricx_qe_score": 1.883292555809021, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Also hier erzeugen wir weiter die Operatoren, bis wir die Blätter erreichen, die die Mengen sind.", "metrics": {"bleu_score": 46.01055269729767, "chrf_score": 63.36521677354149, "xcomet_score": 0.9447261095046997, "xcomet_qe_score": 0.9411529302597046, "metricx_score": 1.295696496963501, "metricx_qe_score": 1.891235113143921, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist also das Gute, dass es uns tatsächlich diese binäre Baumstruktur gibt. Und das ist es, aber eigentlich ist es ziemlich kontraintuitiv, weil wir zuerst den Operator generieren und dann am Ende die Quantitäten.", "metrics": {"bleu_score": 32.50978080700331, "chrf_score": 67.31515250542512, "xcomet_score": 0.8826481103897095, "xcomet_qe_score": 0.8825259208679199, "metricx_score": 3.1462230682373047, "metricx_qe_score": 3.7440152168273926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, dass es auch einige wiederholte Berechnungen enthält.", "metrics": {"bleu_score": 7.768562846380176, "chrf_score": 57.39191234877043, "xcomet_score": 0.9634249210357666, "xcomet_qe_score": 0.9852228164672852, "metricx_score": 0.6130671501159668, "metricx_qe_score": 0.40860599279403687, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck ansehen, 8 mal 3 plus 3, wird er tatsächlich zweimal generiert. Aber eigentlich sollten wir die Ergebnisse wiederverwenden.", "metrics": {"bleu_score": 50.7783395766514, "chrf_score": 83.59280798658321, "xcomet_score": 0.9995788335800171, "xcomet_qe_score": 1.0, "metricx_score": 0.3129901885986328, "metricx_qe_score": 0.41176414489746094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz wollen wir diese Probleme also schrittweise und interpretierbar lösen.", "metrics": {"bleu_score": 48.911594341925095, "chrf_score": 79.58283464861383, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.384177029132843, "metricx_qe_score": 0.39549097418785095, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "So zum Beispiel hier im zweiten Schritt, können wir diese Teiler erhalten, die 27 sind.", "metrics": {"bleu_score": 38.17666460451127, "chrf_score": 75.37132446323342, "xcomet_score": 0.9362766742706299, "xcomet_qe_score": 0.9270287752151489, "metricx_score": 2.299431562423706, "metricx_qe_score": 3.1376051902770996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "We can also refer back to the original questions to find the relevant contents.", "metrics": {"bleu_score": 2.458476536482737, "chrf_score": 20.18187229276257, "xcomet_score": 0.9960262775421143, "xcomet_qe_score": 0.9928059577941895, "metricx_score": 19.231319427490234, "metricx_qe_score": 20.826019287109375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Divisoren.", "metrics": {"bleu_score": 46.713797772819994, "chrf_score": 76.57873724513303, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9579393267631531, "metricx_qe_score": 0.8657515645027161, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Also, und dann, in diesem dritten Schritt, erhalten wir tatsächlich den Quotienten.", "metrics": {"bleu_score": 25.33654946448646, "chrf_score": 75.28790878085121, "xcomet_score": 0.9751657247543335, "xcomet_qe_score": 0.9550884962081909, "metricx_score": 1.2987245321273804, "metricx_qe_score": 1.5515440702438354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung. Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse aus dem zweiten Schritt wiederverwenden und dann die Ergebnisse des vierten Schrittes erhalten. Und schließlich können wir die Dividenden erhalten.", "metrics": {"bleu_score": 31.812069078172414, "chrf_score": 82.50578242864121, "xcomet_score": 0.9921752214431763, "xcomet_qe_score": 0.9908163547515869, "metricx_score": 1.0053651332855225, "metricx_qe_score": 1.634798526763916, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir also tatsächlich den gesamten Ausdruck direkt, anstatt einen einzelnen Operator oder eine einzelne Größe zu erzeugen.", "metrics": {"bleu_score": 9.560408787521254, "chrf_score": 52.18980414887603, "xcomet_score": 0.9856142997741699, "xcomet_qe_score": 0.9885179400444031, "metricx_score": 1.139541506767273, "metricx_qe_score": 1.1830073595046997, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "So wird der Prozess dadurch genauer.", "metrics": {"bleu_score": 30.739407647563215, "chrf_score": 75.30003610597052, "xcomet_score": 0.9541820287704468, "xcomet_qe_score": 0.94239342212677, "metricx_score": 0.8158994913101196, "metricx_qe_score": 1.3755947351455688, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also mit einer Reihe von Quantitäten, die in den Fragen präsentiert werden, und auch mit einigen Konstanten als unseren Anfangsbedingungen.", "metrics": {"bleu_score": 45.61794096358693, "chrf_score": 65.90487668535438, "xcomet_score": 0.9627796411514282, "xcomet_qe_score": 0.9537255764007568, "metricx_score": 1.9229389429092407, "metricx_qe_score": 2.374396800994873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "The expression is represented by eiijop.", "metrics": {"bleu_score": 3.2149545730574576, "chrf_score": 12.716836932021996, "xcomet_score": 0.9568283557891846, "xcomet_qe_score": 0.9393309354782104, "metricx_score": 8.490522384643555, "metricx_qe_score": 10.075678825378418, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wo wir Operator von QI zu QJ ausführen und solche Ausdrücke tatsächlich gerichtet sind.", "metrics": {"bleu_score": 4.4301276307049475, "chrf_score": 43.31513783145112, "xcomet_score": 0.9034645557403564, "xcomet_qe_score": 0.9060162305831909, "metricx_score": 2.5577406883239746, "metricx_qe_score": 2.116755485534668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben hier auch eine Subtraktion mit einem Wort, um die entgegengesetzte Richtung darzustellen.", "metrics": {"bleu_score": 34.018746665856, "chrf_score": 69.7213303792521, "xcomet_score": 0.974071204662323, "xcomet_qe_score": 0.9550946950912476, "metricx_score": 0.7733194828033447, "metricx_qe_score": 0.9731951951980591, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "This is quite similar to relation extraction.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 20.122278142459518, "xcomet_score": 0.9559072256088257, "xcomet_qe_score": 1.0, "metricx_score": 19.787569046020508, "metricx_qe_score": 19.445497512817383, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formalen deduktiven System wenden wir an einem Zeitschritt t den Operator zwischen dem qi- und qj-Paar an, und erhalten dann diesen neuen Ausdruck.", "metrics": {"bleu_score": 53.89161727534065, "chrf_score": 85.46664315331066, "xcomet_score": 0.9591727256774902, "xcomet_qe_score": 0.9602069854736328, "metricx_score": 0.7645728588104248, "metricx_qe_score": 1.2428081035614014, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "We add it to the next state to become a new quantity.", "metrics": {"bleu_score": 2.6485681362909563, "chrf_score": 10.552127755877061, "xcomet_score": 0.9385837316513062, "xcomet_qe_score": 0.9828684329986572, "metricx_score": 23.22552490234375, "metricx_qe_score": 22.78107452392578, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folien visualisieren also tatsächlich die Entwicklung der Zustände, bei der wir dem aktuellen Zustand immer wieder Ausdrücke hinzufügen.", "metrics": {"bleu_score": 28.10335395782486, "chrf_score": 67.37076812470474, "xcomet_score": 0.9974466562271118, "xcomet_qe_score": 0.9394032955169678, "metricx_score": 0.5498351454734802, "metricx_qe_score": 0.893043041229248, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vortrainiertes Sprachmodell, das entweder Vögel oder Roboter sein kann, und dann kodieren wir den Satz. Und dann erhalten wir diese quantitativen Darstellungen.", "metrics": {"bleu_score": 43.646327508770526, "chrf_score": 71.77805136812283, "xcomet_score": 0.8635540008544922, "xcomet_qe_score": 0.8378287553787231, "metricx_score": 4.9574198722839355, "metricx_qe_score": 4.744878768920898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir die quantitativen Repräsentationen erhalten, können wir mit der Inferenz beginnen.", "metrics": {"bleu_score": 57.57575636202256, "chrf_score": 60.575181586029814, "xcomet_score": 0.9925005435943604, "xcomet_qe_score": 0.9939028024673462, "metricx_score": 0.8291870355606079, "metricx_qe_score": 1.0768532752990723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Replikation für Q1 zu erhalten, die durch Q2 geteilt und dann mit Q3 multipliziert wird.", "metrics": {"bleu_score": 23.427916020740984, "chrf_score": 56.614106793371775, "xcomet_score": 0.8702987432479858, "xcomet_qe_score": 0.8793660402297974, "metricx_score": 5.924490928649902, "metricx_qe_score": 6.474605560302734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paardarstellung, die im Grunde nur die Konkatenation zwischen Q one und Q two ist. Und dann wenden wir ein Feedforward-Netzwerk an, das vom Betreiber parametrisiert ist.", "metrics": {"bleu_score": 47.06985163084426, "chrf_score": 71.28723408751716, "xcomet_score": 0.8927381038665771, "xcomet_qe_score": 0.8466055393218994, "metricx_score": 4.313599586486816, "metricx_qe_score": 3.6415486335754395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir schließlich die Ausdrucksrepräsentation Q1 geteilt durch Q2.", "metrics": {"bleu_score": 34.62779310386341, "chrf_score": 73.35507353111136, "xcomet_score": 0.9895706176757812, "xcomet_qe_score": 0.9847257137298584, "metricx_score": 0.7339649200439453, "metricx_qe_score": 0.8704105019569397, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Tat, in der Praxis, in der Inferenzphase, könnten wir auch die falsche, falsche Ausdrucksweise erhalten.", "metrics": {"bleu_score": 15.60424226865365, "chrf_score": 70.82664929509818, "xcomet_score": 0.9459447860717773, "xcomet_qe_score": 0.9337548017501831, "metricx_score": 5.519392490386963, "metricx_qe_score": 6.54356575012207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist also die Anzahl aller möglichen Ausdrücke gleich dreimal der Anzahl der Operatoren.", "metrics": {"bleu_score": 34.79159475128446, "chrf_score": 67.62685598343126, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5341131091117859, "metricx_qe_score": 0.8438886404037476, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne hier ist, dass wir die Suche leicht einschränken können, um die Suche zu steuern.", "metrics": {"bleu_score": 21.951524426618455, "chrf_score": 47.12242925486318, "xcomet_score": 0.9868311882019043, "xcomet_qe_score": 0.9757428169250488, "metricx_score": 1.0471296310424805, "metricx_qe_score": 1.2945672273635864, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, wenn dieser Ausdruck nicht erlaubt ist, können wir diesen Ausdruck einfach aus unserem Suchraum entfernen.", "metrics": {"bleu_score": 51.086369427314914, "chrf_score": 84.03063677459915, "xcomet_score": 0.9953954219818115, "xcomet_qe_score": 0.9983659982681274, "metricx_score": 0.6272094249725342, "metricx_qe_score": 1.0537021160125732, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Also im zweiten Schritt machen wir dasselbe, aber der einzige Unterschied ist, dass wir die einzige Unterschied ist eine mehr Mengen.", "metrics": {"bleu_score": 45.66337854967315, "chrf_score": 72.56014719952448, "xcomet_score": 0.6953057646751404, "xcomet_qe_score": 0.7161200046539307, "metricx_score": 8.090434074401855, "metricx_qe_score": 8.039745330810547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe ergibt sich aus dem vorher berechneten Ausdruck.", "metrics": {"bleu_score": 20.556680845025987, "chrf_score": 57.532146001494056, "xcomet_score": 0.9999076128005981, "xcomet_qe_score": 0.9993991851806641, "metricx_score": 1.2305328845977783, "metricx_qe_score": 3.2955198287963867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Also endlich können wir diesen Endausdruck Q3 erhalten.", "metrics": {"bleu_score": 6.550847048803501, "chrf_score": 41.515057175296164, "xcomet_score": 0.8355849981307983, "xcomet_qe_score": 0.8249313831329346, "metricx_score": 7.56942081451416, "metricx_qe_score": 9.507739067077637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "times q4 and we can also see the number of all the possible expression is different from the previous step.", "metrics": {"bleu_score": 1.8160849415439309, "chrf_score": 16.77926905013692, "xcomet_score": 0.5315999984741211, "xcomet_qe_score": 0.7065843939781189, "metricx_score": 23.033157348632812, "metricx_qe_score": 19.160898208618164, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede machen es schwierig, die Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten ungleich ist.", "metrics": {"bleu_score": 36.92410708813977, "chrf_score": 63.67175152678084, "xcomet_score": 0.9055382013320923, "xcomet_qe_score": 0.8943539261817932, "metricx_score": 1.84027898311615, "metricx_qe_score": 3.103151321411133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Das Trainingsverfahren ist also ähnlich wie das Trainieren eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust in jeder Zeitschritt optimieren.", "metrics": {"bleu_score": 56.42499050012735, "chrf_score": 85.0398806355551, "xcomet_score": 0.9395591020584106, "xcomet_qe_score": 0.8761472105979919, "metricx_score": 1.4145796298980713, "metricx_qe_score": 1.065020203590393, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch dieses Tau, um darzustellen, wann wir diesen Generierungsprozess beenden sollten.", "metrics": {"bleu_score": 77.7811122305422, "chrf_score": 93.16890559489094, "xcomet_score": 0.9878531694412231, "xcomet_qe_score": 0.9760472774505615, "metricx_score": 0.8554815649986267, "metricx_qe_score": 1.2309409379959106, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum anders von Sequenz zu Sequenz, weil der Raum bei jeder Abfolge anders ist, während im traditionellen Sequenz-zu-Sequence-Modell die Anzahl der Vokabeln ist.", "metrics": {"bleu_score": 47.42238106152009, "chrf_score": 69.28132074035331, "xcomet_score": 0.8171070218086243, "xcomet_qe_score": 0.7930496335029602, "metricx_score": 5.016463279724121, "metricx_qe_score": 5.910972595214844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht uns auch, bestimmte Einschränkungen aus dem Wissen des Primärdatensatzes aufzuerlegen.", "metrics": {"bleu_score": 22.229849552064017, "chrf_score": 65.15345449529904, "xcomet_score": 0.9726800918579102, "xcomet_qe_score": 0.8495263457298279, "metricx_score": 2.1647253036499023, "metricx_qe_score": 3.1642801761627197, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente mit den häufig verwendeten Mathematikproblem-Datensätzen durch: MAWPS, MAT23K, MATQA und SWEM.", "metrics": {"bleu_score": 21.187639417686533, "chrf_score": 59.786466252678736, "xcomet_score": 0.8605607748031616, "xcomet_qe_score": 0.8683139085769653, "metricx_score": 4.6852850914001465, "metricx_qe_score": 4.328171730041504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den bisherigen besten Ansätzen.", "metrics": {"bleu_score": 85.07331335123531, "chrf_score": 97.6831168834807, "xcomet_score": 0.9915759563446045, "xcomet_qe_score": 0.9877573251724243, "metricx_score": 0.2909244894981384, "metricx_qe_score": 0.3001486659049988, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere leistungsstärkste Variante ist der Roberta-Deduktive-Reasoner.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 79.70993483029058, "xcomet_score": 0.9834648966789246, "xcomet_qe_score": 0.9779046773910522, "metricx_score": 0.8125619292259216, "metricx_qe_score": 0.9991324543952942, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir keine Beam Search im Gegensatz zu anderen Ansätzen, die Beam Search verwenden.", "metrics": {"bleu_score": 43.01138300680105, "chrf_score": 80.42811172701421, "xcomet_score": 0.8805127143859863, "xcomet_qe_score": 0.8053812980651855, "metricx_score": 2.0359134674072266, "metricx_qe_score": 3.685495138168335, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "In Ordnung, die besten Ansätze sind oft ein Baummodell.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 41.38414491049875, "xcomet_score": 0.9331722855567932, "xcomet_qe_score": 0.9738059043884277, "metricx_score": 0.6652145981788635, "metricx_qe_score": 0.4919770359992981, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt ist unser Reasoner in der Lage, dieses baumbasierte Modell deutlich zu übertreffen.", "metrics": {"bleu_score": 61.60362085721387, "chrf_score": 78.36921582929006, "xcomet_score": 0.9700793027877808, "xcomet_qe_score": 0.9305542707443237, "metricx_score": 1.3653068542480469, "metricx_qe_score": 3.4201231002807617, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absolute Zahl auf MathQ or SWEM nicht wirklich hoch ist.", "metrics": {"bleu_score": 41.180376356915765, "chrf_score": 66.76016205486567, "xcomet_score": 0.8469854593276978, "xcomet_qe_score": 0.8183534145355225, "metricx_score": 4.342925071716309, "metricx_qe_score": 3.8205089569091797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Also untersuchen wir die Ergebnisse weiter.", "metrics": {"bleu_score": 36.74145494215666, "chrf_score": 66.33182790641068, "xcomet_score": 0.9959354400634766, "xcomet_qe_score": 0.9773709774017334, "metricx_score": 0.954030454158783, "metricx_qe_score": 1.4971065521240234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "And this dataset is challenging because the author tried to manually add something to confuse the NLP model, such as adding irrelevant information and extra quantities.", "metrics": {"bleu_score": 1.236744811096618, "chrf_score": 23.891951503738383, "xcomet_score": 0.9431540966033936, "xcomet_qe_score": 0.9466882944107056, "metricx_score": 23.84316635131836, "metricx_qe_score": 20.501535415649414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Vorhersage finden wir also, dass einige der Zwischentermine tatsächlich negativ sind.", "metrics": {"bleu_score": 30.781789741768915, "chrf_score": 69.98552502965975, "xcomet_score": 0.9167065024375916, "xcomet_qe_score": 0.916205883026123, "metricx_score": 3.0777292251586914, "metricx_qe_score": 3.899798631668091, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel in diesen Fragen fragen wir, wie viele Äpfel Jake hat.", "metrics": {"bleu_score": 53.36129799268556, "chrf_score": 72.9200239299847, "xcomet_score": 0.9878679513931274, "xcomet_qe_score": 0.9864997863769531, "metricx_score": 1.0365206003189087, "metricx_qe_score": 1.3006919622421265, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Bilder, und Steven hat acht Bilder, was völlig irrelevant ist.", "metrics": {"bleu_score": 71.78970818142898, "chrf_score": 89.30277812529576, "xcomet_score": 0.9850857257843018, "xcomet_qe_score": 0.984917163848877, "metricx_score": 0.85783851146698, "metricx_qe_score": 0.9949209690093994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also einige Vorhersagen wie diese, die negative Werte ergeben.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 85.35545443816581, "xcomet_score": 0.9950497150421143, "xcomet_qe_score": 0.9865840673446655, "metricx_score": 0.4138873219490051, "metricx_qe_score": 0.5367680191993713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke.", "metrics": {"bleu_score": 11.147892272337163, "chrf_score": 33.87680096462581, "xcomet_score": 0.7297190427780151, "xcomet_qe_score": 0.8604840636253357, "metricx_score": 6.011697769165039, "metricx_qe_score": 13.461858749389648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "So können wir diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse entfernen, die negativ sind, damit wir die Antwort korrekt machen können.", "metrics": {"bleu_score": 13.292032579101747, "chrf_score": 62.589714691529984, "xcomet_score": 0.9053018689155579, "xcomet_qe_score": 0.8352469801902771, "metricx_score": 2.2048134803771973, "metricx_qe_score": 2.8449058532714844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "So finden wir weiter, dass diese Einschränkung tatsächlich für einige Modelle recht viel verbessert.", "metrics": {"bleu_score": 10.988536550999948, "chrf_score": 39.294691462614225, "xcomet_score": 0.9399726986885071, "xcomet_qe_score": 0.9339791536331177, "metricx_score": 2.7768430709838867, "metricx_qe_score": 1.9674450159072876, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert. Und dann haben wir beim robotergestützten Modell tatsächlich zwei Punkte verbessert.", "metrics": {"bleu_score": 18.975516698135845, "chrf_score": 56.254047308754316, "xcomet_score": 0.7284427881240845, "xcomet_qe_score": 0.7314250469207764, "metricx_score": 9.800237655639648, "metricx_qe_score": 9.039558410644531, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat also eine bessere Sprachverständnisfähigkeit, so dass die Zahl hier für Roberta höher und für Bert niedriger ist.", "metrics": {"bleu_score": 25.481620920647202, "chrf_score": 76.23682739804856, "xcomet_score": 0.9991295337677002, "xcomet_qe_score": 1.0, "metricx_score": 0.7824383974075317, "metricx_qe_score": 1.1367285251617432, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch, die Schwierigkeit hinter diesen Bp.", "metrics": {"bleu_score": 22.499268274284365, "chrf_score": 54.23328334487591, "xcomet_score": 0.7522206902503967, "xcomet_qe_score": 0.7389510869979858, "metricx_score": 13.774031639099121, "metricx_qe_score": 16.50943946838379, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "We assume the number of unused quantity can be regarded as irrelevant information here.", "metrics": {"bleu_score": 2.0128303461390598, "chrf_score": 28.96305126315191, "xcomet_score": 0.9742485880851746, "xcomet_qe_score": 0.9884222149848938, "metricx_score": 23.458660125732422, "metricx_qe_score": 23.43635368347168, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier können wir also sehen, dass wir die Anzahl der Proben mit ungenutzten Mengen haben. Und der SWAMP-Datensatz hat die größte Portion.", "metrics": {"bleu_score": 48.15092081725061, "chrf_score": 71.96666321573298, "xcomet_score": 0.9300757646560669, "xcomet_qe_score": 0.927985429763794, "metricx_score": 3.043574333190918, "metricx_qe_score": 3.497100353240967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung.", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 95.153554655332, "xcomet_score": 0.9975186586380005, "xcomet_qe_score": 0.9953868389129639, "metricx_score": 0.17540127038955688, "metricx_qe_score": 0.28346192836761475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen. Die Gesamtleistung ist also tatsächlich höher als die Leistung, die tatsächlich höher ist als die Gesamtleistung.", "metrics": {"bleu_score": 23.71332024655201, "chrf_score": 68.08313924267216, "xcomet_score": 0.3235083222389221, "xcomet_qe_score": 0.3440742790699005, "metricx_score": 6.845334053039551, "metricx_qe_score": 7.399449825286865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "But with those samples that with unused quantity is actually way worse than the way worse than.", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 12.579031626806259, "xcomet_score": 0.26923030614852905, "xcomet_qe_score": 0.5658111572265625, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Performance for M and WPS we don't really have too many desk cases so I just ignore this part.", "metrics": {"bleu_score": 1.9146030690102511, "chrf_score": 15.130901020915296, "xcomet_score": 0.6407688856124878, "xcomet_qe_score": 0.6948317289352417, "metricx_score": 13.562112808227539, "metricx_qe_score": 10.754423141479492, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretierbarkeit anhand eines Beispiels für eine Frage- und Antwortbeispiel zeigen.", "metrics": {"bleu_score": 29.256127307315065, "chrf_score": 71.50411849576729, "xcomet_score": 0.8420401811599731, "xcomet_qe_score": 0.8361902236938477, "metricx_score": 3.0353615283966064, "metricx_qe_score": 3.2227530479431152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Hier macht unser Modell also tatsächlich eine falsche Vorhersage im ersten Schritt.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9906495213508606, "xcomet_qe_score": 0.9788217544555664, "metricx_score": 0.3428908586502075, "metricx_qe_score": 0.46378058195114136, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "So können wir diesen Ausdruck tatsächlich mit dem Satz hier korrelieren.", "metrics": {"bleu_score": 49.5958668188253, "chrf_score": 76.87254739882869, "xcomet_score": 0.9572954177856445, "xcomet_qe_score": 0.9460722804069519, "metricx_score": 1.0830196142196655, "metricx_qe_score": 1.2796534299850464, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben, dass dieser Satz das Modell zu einer falschen Vorhersage verleiten könnte.", "metrics": {"bleu_score": 51.497322032579355, "chrf_score": 76.02843397124782, "xcomet_score": 0.999920129776001, "xcomet_qe_score": 0.9994806051254272, "metricx_score": 0.2727993428707123, "metricx_qe_score": 0.2789649963378906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Also hier, indem man weitere fünfunddreißig pflanzt, lässt das Modell denken, dass es sich um einen zusätzlichen Operator handeln sollte.", "metrics": {"bleu_score": 9.165852474742529, "chrf_score": 43.582910661857156, "xcomet_score": 0.7029961943626404, "xcomet_qe_score": 0.730574369430542, "metricx_score": 6.566373825073242, "metricx_qe_score": 6.809909820556641, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Also versuchen wir, den Satz zu überarbeiten, so dass die Anzahl der Birnbäume um fünf weniger ist als die Anzahl der Apfelbäume.", "metrics": {"bleu_score": 27.466953528819282, "chrf_score": 61.25740055083855, "xcomet_score": 0.9068740606307983, "xcomet_qe_score": 0.9364199042320251, "metricx_score": 4.725522041320801, "metricx_qe_score": 5.380335807800293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Also machen wir es, um eine genauere Semantik zu vermitteln, so dass das Modell in der Lage ist, die Vorhersage korrekt zu treffen.", "metrics": {"bleu_score": 52.46789370600703, "chrf_score": 74.38727894087235, "xcomet_score": 0.9477843046188354, "xcomet_qe_score": 0.938300609588623, "metricx_score": 3.036404609680176, "metricx_qe_score": 2.4391093254089355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie interpretierbare Vorhersagen uns helfen, das Verhalten des Modells zu verstehen.", "metrics": {"bleu_score": 22.10986613588833, "chrf_score": 72.9772157876664, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3443455398082733, "metricx_qe_score": 0.4315869212150574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell zunächst ziemlich effizient.", "metrics": {"bleu_score": 36.049080429833154, "chrf_score": 75.19860241995453, "xcomet_score": 0.9741106629371643, "xcomet_qe_score": 0.9472644329071045, "metricx_score": 0.6036584973335266, "metricx_qe_score": 0.8289480209350586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind in der Lage, interpretierbare Lösungsverfahren bereitzustellen.", "metrics": {"bleu_score": 38.16330911371339, "chrf_score": 69.48921756810411, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.18744516372680664, "metricx_qe_score": 0.22230243682861328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige vorherige Kenntnisse als Einschränkung einbeziehen, die die Leistung verbessern können.", "metrics": {"bleu_score": 6.019608768705656, "chrf_score": 43.75563803709346, "xcomet_score": 0.9928522109985352, "xcomet_qe_score": 0.9702682495117188, "metricx_score": 1.4412462711334229, "metricx_qe_score": 1.2901761531829834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das letzte ist, dass der zugrunde liegende Mechanismus nicht nur für die Lösung von Matheproblemaufgaben gilt, sondern auch für andere Aufgaben, die mehrstufiges Denken erfordern.", "metrics": {"bleu_score": 38.44223126709894, "chrf_score": 69.33743039543444, "xcomet_score": 0.9616789221763611, "xcomet_qe_score": 0.9329686760902405, "metricx_score": 4.523974418640137, "metricx_qe_score": 4.475037097930908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 18.03958201806172, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4435056149959564, "metricx_qe_score": 0.46961158514022827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und die zweite Sache ist, dass, wie bereits erwähnt, weil die Wahrscheinlichkeitsverteilung zwischen verschiedenen Zeitschritten ungleich ist, es auch ziemlich schwierig ist, Beam Search anzuwenden.", "metrics": {"bleu_score": 5.416498094653075, "chrf_score": 58.987585297028645, "xcomet_score": 0.9252216815948486, "xcomet_qe_score": 0.909183144569397, "metricx_score": 1.4505678415298462, "metricx_qe_score": 2.594715118408203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank.", "metrics": {"bleu_score": 15.917012694603715, "chrf_score": 48.32341531106971, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.35534191131591797, "metricx_qe_score": 0.2528751492500305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme aus der Maastricht University.", "metrics": {"bleu_score": 55.68544122775911, "chrf_score": 72.70098537984703, "xcomet_score": 0.9896216988563538, "xcomet_qe_score": 1.0, "metricx_score": 0.41119304299354553, "metricx_qe_score": 0.26860228180885315, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine gemeinsame Arbeit mit Jerry vorstellen, die sich um einen neuen Datensatz für die gesetzliche Artikelabfrage dreht.", "metrics": {"bleu_score": 51.15762742536574, "chrf_score": 69.67428722128074, "xcomet_score": 0.9635434150695801, "xcomet_qe_score": 0.9661415815353394, "metricx_score": 1.1295548677444458, "metricx_qe_score": 0.9151458740234375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Legal issues are an integral part of many people's lives.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 11.528552424912652, "xcomet_score": 0.993156909942627, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "But the majority of citizens have little to no knowledge about their rights and fundamental legal processes.", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 14.342905781630636, "xcomet_score": 0.9973558187484741, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worse, exploited.", "metrics": {"bleu_score": 1.8916885184068941, "chrf_score": 16.40437076262333, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Our work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "metrics": {"bleu_score": 1.4400778827658958, "chrf_score": 20.31194891935726, "xcomet_score": 0.9879719018936157, "xcomet_qe_score": 0.9888740181922913, "metricx_score": 24.417699813842773, "metricx_qe_score": 24.902555465698242, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen, professionellen Rechtsbeistand für unqualifizierte Menschen bieten.", "metrics": {"bleu_score": 39.75360176263951, "chrf_score": 72.06054161415861, "xcomet_score": 0.9823228120803833, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5495592355728149, "metricx_qe_score": 0.3338266909122467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem der gesetzlich vorgeschriebenen Artikelabfrage.", "metrics": {"bleu_score": 31.327681146619366, "chrf_score": 64.59625967008989, "xcomet_score": 0.9597511887550354, "xcomet_qe_score": 0.9846726655960083, "metricx_score": 0.7426697611808777, "metricx_qe_score": 0.3822200298309326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Gegeben eine einfache Frage zu einem Thema wie, was riskiere ich, wenn ich die berufliche Vertraulichkeit verletze?", "metrics": {"bleu_score": 26.3433347744036, "chrf_score": 55.19330739391045, "xcomet_score": 0.8819286823272705, "xcomet_qe_score": 0.940720796585083, "metricx_score": 3.867705821990967, "metricx_qe_score": 3.1271555423736572, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Bestimmungen aus einem großen Gesetzgebungsvolumen abzurufen.", "metrics": {"bleu_score": 22.35942642459069, "chrf_score": 53.34093907647116, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.394356906414032, "metricx_qe_score": 0.29849374294281006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "This information retrieval task comes with its own set of challenges.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 23.028150188997703, "xcomet_score": 0.9653302431106567, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "First, it deals with two types of language.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 12.13040771864301, "xcomet_score": 0.9511018991470337, "xcomet_qe_score": 1.0, "metricx_score": 24.90877914428711, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Common natural language for the questions and complex legal language for the statutes.", "metrics": {"bleu_score": 2.4617934274488045, "chrf_score": 16.575878897007783, "xcomet_score": 0.9527537822723389, "xcomet_qe_score": 0.9883500337600708, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschied in Sprachverteilungen macht es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzt, die der Terminologie von Statuten entspricht.", "metrics": {"bleu_score": 74.3353602848513, "chrf_score": 88.30212256049599, "xcomet_score": 0.959348738193512, "xcomet_qe_score": 0.9251875877380371, "metricx_score": 1.9059257507324219, "metricx_qe_score": 1.2190589904785156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das Gesetz nicht ein Haufen unabhängiger Artikel, die als vollständige Informationsquelle für sich allein betrachtet werden können, wie zum Beispiel Nachrichten oder Rezepte.", "metrics": {"bleu_score": 36.2710218902162, "chrf_score": 73.54838303321624, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2668423056602478, "metricx_qe_score": 0.3065592050552368, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen ist es eine strukturierte Sammlung von Rechtsvorschriften, die nur im Gesamtkontext eine Bedeutung haben, d.h. zusammen mit den ergänzenden Informationen aus den angrenzenden Artikeln, den Feldern und Unterfeldern, zu denen sie gehören, und ihrem Platz in der Struktur des Gesetzes.", "metrics": {"bleu_score": 45.927348217213925, "chrf_score": 66.58381384174584, "xcomet_score": 0.9648000001907349, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.39939969778060913, "metricx_qe_score": 0.33627477288246155, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich sind gesetzliche Artikel in einem kleinen Absatz, der normalerweise die typische Abrufeinheit in den meisten Abrufarbeiten ist.", "metrics": {"bleu_score": 9.119890156469005, "chrf_score": 42.18945215666817, "xcomet_score": 0.7967633008956909, "xcomet_qe_score": 0.7961992025375366, "metricx_score": 11.999361038208008, "metricx_qe_score": 10.509174346923828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Here they are long documents that may be up to six.", "metrics": {"bleu_score": 2.8666091494718775, "chrf_score": 12.459480150319974, "xcomet_score": 0.5397757291793823, "xcomet_qe_score": 0.7805993556976318, "metricx_score": 22.346776962280273, "metricx_qe_score": 21.57447052001953, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in NLP haben großes Interesse an vielen Rechtsaufgaben geweckt, wie z.B. rechtliche Urteilsauslegung oder automatisierte Vertragsprüfung.", "metrics": {"bleu_score": 28.277136108122956, "chrf_score": 58.345238868247186, "xcomet_score": 0.9822138547897339, "xcomet_qe_score": 0.9192442297935486, "metricx_score": 0.7721484303474426, "metricx_qe_score": 0.8734312057495117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Aber die gesetzliche Artikelabfrage ist aufgrund des Mangels an großen, qualitativ hochwertigen, beschrifteten Datensätzen weitgehend unberührt geblieben.", "metrics": {"bleu_score": 42.461633178803446, "chrf_score": 70.03754916005107, "xcomet_score": 0.9411666393280029, "xcomet_qe_score": 0.9635594487190247, "metricx_score": 1.0882506370544434, "metricx_qe_score": 1.0113295316696167, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir einen neuen, für französische Muttersprachler und Bürger konzipierten Datensatz, um zu untersuchen, ob ein Retrieval-Modell die Effizienz und Zuverlässigkeit eines Rechtsfachmanns für die Aufgabe der gesetzlichen Artikelabfrage annähern kann.", "metrics": {"bleu_score": 16.93877994297226, "chrf_score": 59.467838591702396, "xcomet_score": 0.8976914882659912, "xcomet_qe_score": 0.8774604797363281, "metricx_score": 3.0174853801727295, "metricx_qe_score": 3.8510096073150635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Our Belgian statutory article retrieval data set, psrd, consists of more than one thousand one hundred articles.", "metrics": {"bleu_score": 1.8666836339485868, "chrf_score": 17.961606489376656, "xcomet_score": 0.4158516526222229, "xcomet_qe_score": 0.7185975909233093, "metricx_score": 16.417625427246094, "metricx_qe_score": 15.430173873901367, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen decken ein breites Themenspektrum ab, von Familie, Wohnung, Geld bis hin zu Arbeit und Sozialversicherung.", "metrics": {"bleu_score": 54.33878021899394, "chrf_score": 73.50385547884447, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.23324963450431824, "metricx_qe_score": 0.1268204152584076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als zweiundzwanzigtausend markiert.", "metrics": {"bleu_score": 68.51944659744045, "chrf_score": 69.70039379505279, "xcomet_score": 0.8542599678039551, "xcomet_qe_score": 0.8696452379226685, "metricx_score": 5.575255870819092, "metricx_qe_score": 7.768857002258301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgian codes of law. Let's now talk about how we collected these data sets.", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 13.657069111492493, "xcomet_score": 0.27421867847442627, "xcomet_qe_score": 0.31997713446617126, "metricx_score": 19.98454475402832, "metricx_qe_score": 22.038185119628906, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst haben wir mit der Zusammenstellung eines großen Korpus juristischer Artikel begonnen.", "metrics": {"bleu_score": 9.238430210261097, "chrf_score": 49.23905206504865, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.30058881640434265, "metricx_qe_score": 0.45923614501953125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "We considered thirty two publicly available Belgian codes and extracted all their articles as well as the corresponding section headings.", "metrics": {"bleu_score": 1.8160849415439309, "chrf_score": 18.325035770141486, "xcomet_score": 0.8905452489852905, "xcomet_qe_score": 1.0, "metricx_score": 21.709287643432617, "metricx_qe_score": 22.80816078186035, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann haben wir rechtliche Fragen mit Verweisen auf relevante Rechtsvorschriften gesammelt.", "metrics": {"bleu_score": 63.15552371794033, "chrf_score": 64.06972393222699, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2930799722671509, "metricx_qe_score": 0.2318289577960968, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "To do so, we partner with a Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "metrics": {"bleu_score": 1.3794462224541233, "chrf_score": 17.283866500483285, "xcomet_score": 0.9987626075744629, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team von erfahrenen Juristen die häufigsten rechtlichen Fragen Belgiens behandelt.", "metrics": {"bleu_score": 71.4731571540253, "chrf_score": 78.16003330499721, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.5136814713478088, "metricx_qe_score": 0.6277109980583191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen gesammelt, die mit Kategorien, Unterkategorien und juristischen Verweisen auf relevante Statuten annotiert sind.", "metrics": {"bleu_score": 43.7241098509127, "chrf_score": 73.15343598602561, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5436281561851501, "metricx_qe_score": 0.6535390615463257, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir die juristischen Referenzen überprüft und die Fragen herausgesucht, deren Referenzen nicht Artikel in einem der von uns betrachteten Rechtskodizes waren.", "metrics": {"bleu_score": 37.56881561469425, "chrf_score": 57.00881239436504, "xcomet_score": 0.9614678621292114, "xcomet_qe_score": 0.9627445936203003, "metricx_score": 1.94282066822052, "metricx_qe_score": 1.4249438047409058, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "The remaining references were matched and converted to the corresponding article IDs from all corpus.", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 20.705945703565305, "xcomet_score": 0.9132122993469238, "xcomet_qe_score": 0.922261118888855, "metricx_score": 18.783039093017578, "metricx_qe_score": 11.065885543823242, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from the", "metrics": {"bleu_score": 1.506189323093867, "chrf_score": 19.07840617165571, "xcomet_score": 0.5605594515800476, "xcomet_qe_score": 0.6939552426338196, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus wird jede Frage mit einer Hauptkategorie und einer Kette von Unterkategorien versehen.", "metrics": {"bleu_score": 10.82597837309053, "chrf_score": 68.03220226607284, "xcomet_score": 0.9774335622787476, "xcomet_qe_score": 0.9765597581863403, "metricx_score": 1.4576456546783447, "metricx_qe_score": 1.9994410276412964, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel kommt mit einer Verkettung der nachfolgenden Überschrift in der Struktur des Lobes.", "metrics": {"bleu_score": 3.9779457777453793, "chrf_score": 49.276478595454805, "xcomet_score": 0.8383872509002686, "xcomet_qe_score": 0.8149207830429077, "metricx_score": 7.786046504974365, "metricx_qe_score": 7.146270751953125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der aktuellen Arbeit nicht verwendet, könnten aber für zukünftige Forschungen zur rechtlichen Informationsabruf oder zur rechtlichen Textklassifizierung von Interesse sein.", "metrics": {"bleu_score": 50.03557455114012, "chrf_score": 72.26846560181433, "xcomet_score": 0.9521963596343994, "xcomet_qe_score": 0.969857394695282, "metricx_score": 0.8581652641296387, "metricx_qe_score": 0.40862417221069336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns einige Merkmale unserer Datensätze betrachten.", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 58.694921872395845, "xcomet_score": 0.9891918897628784, "xcomet_qe_score": 0.9995100498199463, "metricx_score": 0.9365360140800476, "metricx_qe_score": 0.5409671068191528, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "The questions are between five and forty four words long, with a median of forty words.", "metrics": {"bleu_score": 2.5540496664715904, "chrf_score": 14.642205082345928, "xcomet_score": 0.6281434297561646, "xcomet_qe_score": 0.8519039154052734, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "The articles are much longer, with a median length of seventy-seven words, with one hundred and forty percent of them being longer than the average article length of seventy-five words.", "metrics": {"bleu_score": 1.3355980882200826, "chrf_score": 19.70178213261656, "xcomet_score": 0.90592360496521, "xcomet_qe_score": 0.9508349895477295, "metricx_score": 12.824969291687012, "metricx_qe_score": 15.945526123046875, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Two of them exceeding one.", "metrics": {"bleu_score": 4.167251645138561, "chrf_score": 7.226467431781796, "xcomet_score": 0.14760398864746094, "xcomet_qe_score": 0.14847300946712494, "metricx_score": 22.140336990356445, "metricx_qe_score": 21.605627059936523, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, deckt die Frage ein breites Themenspektrum ab, von dem etwa 85 Prozent sich entweder mit Familie, Wohnung, Geld oder Gerechtigkeit befassen.", "metrics": {"bleu_score": 13.13322974583701, "chrf_score": 58.17524260610995, "xcomet_score": 0.9576150178909302, "xcomet_qe_score": 0.9641584157943726, "metricx_score": 1.783135175704956, "metricx_qe_score": 1.6883516311645508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "While the remaining fifteen percent concern either social security, foreigners, or work.", "metrics": {"bleu_score": 3.1251907639724417, "chrf_score": 19.16230276756593, "xcomet_score": 0.9900118112564087, "xcomet_qe_score": 0.9810539484024048, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "The articles are also very diverse, as they come from thirty-two different Belgian codes that cover a large number of legal topics.", "metrics": {"bleu_score": 1.8709718017288024, "chrf_score": 15.865961622416783, "xcomet_score": 0.9817259311676025, "xcomet_qe_score": 1.0, "metricx_score": 14.580211639404297, "metricx_qe_score": 19.970117568969727, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Codes gesammelt wurden.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 74.7960335439847, "xcomet_score": 0.9758502244949341, "xcomet_qe_score": 0.94249027967453, "metricx_score": 3.0755269527435303, "metricx_qe_score": 2.747055768966675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Out of the 22,633 articles, only 1,612 are referred to as relevant to at least one of the following three categories.", "metrics": {"bleu_score": 1.958224832501124, "chrf_score": 22.16356466766619, "xcomet_score": 0.25469306111335754, "xcomet_qe_score": 0.6432902812957764, "metricx_score": 8.809370994567871, "metricx_qe_score": 4.459962368011475, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "\"One question in the data sets. And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes, or penal codes.\"", "metrics": {"bleu_score": 1.389736936231864, "chrf_score": 17.767301958917184, "xcomet_score": 0.19758234918117523, "xcomet_qe_score": 0.47507548332214355, "metricx_score": 18.405536651611328, "metricx_qe_score": 18.52299690246582, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen haben achtzehn von zweiunddreißig Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage bezeichnet werden.", "metrics": {"bleu_score": 36.30716142599353, "chrf_score": 62.37426785884036, "xcomet_score": 0.9638469219207764, "xcomet_qe_score": 0.9763738512992859, "metricx_score": 3.274705410003662, "metricx_qe_score": 3.158241033554077, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Was kann durch die Tatsache erklärt werden, dass diese Codes weniger auf Individuen und ihre Anliegen eingehen.", "metrics": {"bleu_score": 10.657284485555579, "chrf_score": 40.94339201712415, "xcomet_score": 0.9599155187606812, "xcomet_qe_score": 0.9784141182899475, "metricx_score": 4.9663262367248535, "metricx_qe_score": 3.318164110183716, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt beträgt die mittlere Anzahl der Zitate für diese zitierten Artikel 2, und weniger als 25 Prozent von ihnen sind.", "metrics": {"bleu_score": 26.788770505940324, "chrf_score": 52.22439192132442, "xcomet_score": 0.7767592668533325, "xcomet_qe_score": 0.765104353427887, "metricx_score": 11.627976417541504, "metricx_qe_score": 11.759886741638184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen haben wir mehrere Abrufverfahren, einschließlich lexikalischer und dichterischer Architektur, verifiziert.", "metrics": {"bleu_score": 17.662808265513323, "chrf_score": 50.4106006026226, "xcomet_score": 0.9344847202301025, "xcomet_qe_score": 0.9127437472343445, "metricx_score": 2.9364733695983887, "metricx_qe_score": 1.966820478439331, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Given a query and an article, a lexical model assigns a score to the query-article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "metrics": {"bleu_score": 1.3113617852675474, "chrf_score": 14.831554200501602, "xcomet_score": 0.9621316194534302, "xcomet_qe_score": 0.9075160026550293, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-Tf-idf- und bm25-Rangfunktionen.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 65.99062620009066, "xcomet_score": 0.9204143285751343, "xcomet_qe_score": 0.9177841544151306, "metricx_score": 3.3357114791870117, "metricx_qe_score": 3.9983971118927, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die Schlüsselwörter enthalten, die in der Abfrage vorhanden sind.", "metrics": {"bleu_score": 72.67072830982373, "chrf_score": 86.87286610204312, "xcomet_score": 0.9916040897369385, "xcomet_qe_score": 0.9922547340393066, "metricx_score": 0.5713827610015869, "metricx_qe_score": 0.6251809000968933, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann.", "metrics": {"bleu_score": 87.87419089273847, "chrf_score": 94.0489601912323, "xcomet_score": 0.9998520612716675, "xcomet_qe_score": 0.9999477863311768, "metricx_score": 0.4494284987449646, "metricx_qe_score": 0.3703739643096924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Encoder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen abbildet und einen Relevanzwert zwischen einem Abfragesatz und einem Artikelpaar anhand der Ähnlichkeit ihrer Einbettungen berechnet.", "metrics": {"bleu_score": 55.84477172924733, "chrf_score": 84.37386301947515, "xcomet_score": 0.8972511291503906, "xcomet_qe_score": 0.8767726421356201, "metricx_score": 2.3773741722106934, "metricx_qe_score": 3.399481773376465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen ergeben sich in der Regel aus einer Pooling-Operation auf der Ausgabe eines Wort-Einbettungsmodells.", "metrics": {"bleu_score": 63.894310424627285, "chrf_score": 84.46895318071277, "xcomet_score": 0.9081146717071533, "xcomet_qe_score": 0.8715264797210693, "metricx_score": 1.37093186378479, "metricx_qe_score": 2.6679677963256836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst untersuchten wir die Wirksamkeit von Siamese-Biencoder in einem Zero-Shot-Evaluierungssetup, was bedeutet, dass vortrainierte Wort-Embedding-Modelle ohne zusätzliche Feinabstimmung unverändert angewendet werden.", "metrics": {"bleu_score": 12.88160710316241, "chrf_score": 64.47032607241871, "xcomet_score": 0.8356350660324097, "xcomet_qe_score": 0.878581702709198, "metricx_score": 4.402181148529053, "metricx_qe_score": 4.389673233032227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Textencodern, nämlich Word2Vec und fasttext, und kontextabhängigen Embedding-Modellen, nämlich Roberta und speziell Camembert, das ein französisches Roberta-Modell ist.", "metrics": {"bleu_score": 25.983833013159888, "chrf_score": 67.95531255045087, "xcomet_score": 0.889011025428772, "xcomet_qe_score": 0.861823320388794, "metricx_score": 1.8082506656646729, "metricx_qe_score": 1.33209228515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes camembert-basiertes Modell, das Beyond Quarters heißt.", "metrics": {"bleu_score": 16.269767496284814, "chrf_score": 42.678040359779146, "xcomet_score": 0.7586871385574341, "xcomet_qe_score": 0.7533532381057739, "metricx_score": 7.046390533447266, "metricx_qe_score": 7.655600070953369, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Auf allen Datensätzen. Beachten Sie, dass wir beim Training mit den beiden Geschmacksrichtungen der Biancoduro-Architektur experimentieren.", "metrics": {"bleu_score": 52.891281824158625, "chrf_score": 76.8986607583792, "xcomet_score": 0.642024040222168, "xcomet_qe_score": 0.6191397309303284, "metricx_score": 8.402134895324707, "metricx_qe_score": 9.099709510803223, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and Tutoire, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "metrics": {"bleu_score": 2.1400286214609148, "chrf_score": 21.942682003921714, "xcomet_score": 0.6847208738327026, "xcomet_qe_score": 0.6648837327957153, "metricx_score": 25.0, "metricx_qe_score": 23.44773292541504, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mean Max und CLS-Pooling sowie dot product und cosign zur Berechnung von Ähnlichkeiten.", "metrics": {"bleu_score": 24.090574722655482, "chrf_score": 61.48122264556748, "xcomet_score": 0.6933275461196899, "xcomet_qe_score": 0.6944655179977417, "metricx_score": 9.367229461669922, "metricx_qe_score": 7.793264865875244, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Baseline auf dem Testset.", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 82.98027892110711, "xcomet_score": 0.9593713283538818, "xcomet_qe_score": 0.8772333860397339, "metricx_score": 0.9508166313171387, "metricx_qe_score": 2.606977939605713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den lexikalischen Methoden oben, den siamesischen B-Encoders, die in einer Zero-Stop-Umgebung in der Mitte bewertet werden, und den fein abgestimmten B-Encoders unten.", "metrics": {"bleu_score": 10.166724095023941, "chrf_score": 62.36329848265396, "xcomet_score": 0.7944654226303101, "xcomet_qe_score": 0.7642042636871338, "metricx_score": 4.689643859863281, "metricx_qe_score": 4.700865268707275, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertrafen die fein abgestimmten B-Encoder alle anderen Baselines deutlich.", "metrics": {"bleu_score": 38.16330911371339, "chrf_score": 81.93049802902611, "xcomet_score": 0.9556561708450317, "xcomet_qe_score": 0.8916218280792236, "metricx_score": 3.9926767349243164, "metricx_qe_score": 4.492704391479492, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zwei-Türmer-Modell übertrifft seine siamesische Variante bei der Rückrufquote um einhundert, zeigt aber bei den anderen Metriken eine ähnliche Leistung.", "metrics": {"bleu_score": 17.896429192677505, "chrf_score": 47.78183851356428, "xcomet_score": 0.9645318388938904, "xcomet_qe_score": 0.9520630240440369, "metricx_score": 3.423646926879883, "metricx_qe_score": 4.70402717590332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl bm twenty five die trainierte Bioncode deutlich unterdurchschnittlich abschneidet, deutet seine Leistung darauf hin, dass es immer noch eine starke Basis für domänenspezifische Abrufungen ist.", "metrics": {"bleu_score": 9.426052256779037, "chrf_score": 56.25223453312339, "xcomet_score": 0.8231388926506042, "xcomet_qe_score": 0.8260492086410522, "metricx_score": 9.03303337097168, "metricx_qe_score": 7.590167045593262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "In Bezug auf die Nullschussbewertung des siamesischen B-Encoders stellen wir fest, dass die direkte Verwendung der Einbettungen eines vortrainierten Camembert-Modells ohne Optimierung für die Informationsabrufaufgabe schlechte Ergebnisse liefert, was mit früheren Ergebnissen übereinstimmt.", "metrics": {"bleu_score": 55.06194514562286, "chrf_score": 76.68500381548802, "xcomet_score": 0.8034558296203613, "xcomet_qe_score": 0.8481847047805786, "metricx_score": 3.8698785305023193, "metricx_qe_score": 3.368582248687744, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir festgestellt, dass die von der Wort2vec-Basis abgeleitete B-Encoder-Version die FastText- und B-Basis-Modelle deutlich übertraf, was darauf hindeutet, dass möglicherweise vortrainierte Wortebene-Embeddings für die Aufgabe geeigneter sind als Charakterebene- oder Subwortebene-Embeddings, wenn sie unverändert verwendet werden.", "metrics": {"bleu_score": 22.21719382370813, "chrf_score": 54.537252941384814, "xcomet_score": 0.5990736484527588, "xcomet_qe_score": 0.6290071606636047, "metricx_score": 7.867995738983154, "metricx_qe_score": 8.091979026794434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl vielversprechend, deuten diese Ergebnisse auf eine große Verbesserungspotenzial hin, im Vergleich zu einem geschulten Experten, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Ergebnisse erzielen kann.", "metrics": {"bleu_score": 32.459798883158996, "chrf_score": 70.29064262956236, "xcomet_score": 0.9745294451713562, "xcomet_qe_score": 0.9782498478889465, "metricx_score": 1.03946053981781, "metricx_qe_score": 0.7921841144561768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Fassen wir zusammen, indem wir zwei Einschränkungen aller Datensätze diskutieren.", "metrics": {"bleu_score": 7.495553473355845, "chrf_score": 40.06218607322147, "xcomet_score": 0.9403342008590698, "xcomet_qe_score": 0.9160813093185425, "metricx_score": 3.2080132961273193, "metricx_qe_score": 1.9077047109603882, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Erstens ist der Artikelkorpus auf die aus den 32 untersuchten belgischen Kodices gesammelten Artikel beschränkt, was nicht das gesamte belgische Recht abdeckt, da Artikel aus Dekreten, Richtlinien und Verordnungen fehlen.", "metrics": {"bleu_score": 72.42514056275603, "chrf_score": 81.69144615076492, "xcomet_score": 0.9808201193809509, "xcomet_qe_score": 0.9538546800613403, "metricx_score": 1.3113501071929932, "metricx_qe_score": 1.201278805732727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Verweise auf diese nicht gesammelten Artikel ignoriert, was zu einigen Fragen führt, um nur einen Bruchteil der anfänglichen Anzahl relevanter Artikel zu erhalten.", "metrics": {"bleu_score": 25.068350706929095, "chrf_score": 59.06157436036602, "xcomet_score": 0.8299204707145691, "xcomet_qe_score": 0.7801821231842041, "metricx_score": 6.9290337562561035, "metricx_qe_score": 5.490543365478516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationslücke impliziert, dass die Antwort in den verbleibenden relevanten Artikeln möglicherweise unvollständig ist, obwohl sie immer noch völlig angemessen ist.", "metrics": {"bleu_score": 40.42993900849046, "chrf_score": 70.57029967495588, "xcomet_score": 0.9848461151123047, "xcomet_qe_score": 0.9666081666946411, "metricx_score": 0.9309482574462891, "metricx_qe_score": 1.176276683807373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Statuten beantwortet werden können.", "metrics": {"bleu_score": 82.82477531331043, "chrf_score": 91.23469865547756, "xcomet_score": 0.9973293542861938, "xcomet_qe_score": 1.0, "metricx_score": 0.9860327243804932, "metricx_qe_score": 0.34543314576148987, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage, kann ich meine Mieter vertreiben, wenn sie zu viel Lärm machen?", "metrics": {"bleu_score": 51.072310908001, "chrf_score": 73.77248579377883, "xcomet_score": 0.9971439838409424, "xcomet_qe_score": 0.9936083555221558, "metricx_score": 0.47089362144470215, "metricx_qe_score": 0.4245910942554474, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "metrics": {"bleu_score": 1.7316314614810704, "chrf_score": 17.219714467525872, "xcomet_score": 0.7507243156433105, "xcomet_qe_score": 0.9681105613708496, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Landlord wahrscheinlich mehr auf Präzedenzfälle zurückgreifen und Präzedenzfälle finden, die der aktuellen Situation ähnlich sind.", "metrics": {"bleu_score": 36.96839097373222, "chrf_score": 66.28708614753297, "xcomet_score": 0.9691817760467529, "xcomet_qe_score": 1.0, "metricx_score": 1.5653735399246216, "metricx_qe_score": 1.0181711912155151, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "For example, the tenant makes two parties a week until two August.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 14.087921883761457, "xcomet_score": 0.5583032369613647, "xcomet_qe_score": 0.7953659296035767, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen für die gesetzliche Artikelabrufaufgabe besser geeignet als andere, und die Domäne der weniger geeigneten bleibt zu bestimmen.", "metrics": {"bleu_score": 12.675606378131997, "chrf_score": 51.023922267699895, "xcomet_score": 0.9534984827041626, "xcomet_qe_score": 0.9127998352050781, "metricx_score": 1.7453042268753052, "metricx_qe_score": 1.9969581365585327, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "We hope that all work sparks interest in developing practical and reliable statutory article retrieval models.", "metrics": {"bleu_score": 1.7042146160049085, "chrf_score": 22.290677128925562, "xcomet_score": 0.9091956615447998, "xcomet_qe_score": 0.969595730304718, "metricx_score": 23.855117797851562, "metricx_qe_score": 23.36597442626953, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "That can help improve access to justice for all.", "metrics": {"bleu_score": 2.812739937159535, "chrf_score": 12.52648020463469, "xcomet_score": 0.8530086278915405, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "You can check out our paper at setencode at the following links. Thank you.", "metrics": {"bleu_score": 2.0274685852177114, "chrf_score": 14.444536601651144, "xcomet_score": 0.7918248772621155, "xcomet_qe_score": 0.8162817358970642, "metricx_score": 17.186256408691406, "metricx_qe_score": 14.167181015014648, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit auf Vowels, einem taskindependenten Benchmark, der für die Bewertung von Vision- und Sprachmodellen mit bestimmten sprachlichen Phänomenen entwickelt wurde, vorzustellen.", "metrics": {"bleu_score": 25.880858490185165, "chrf_score": 53.62740989619752, "xcomet_score": 0.7905498147010803, "xcomet_qe_score": 0.7760997414588928, "metricx_score": 6.758701324462891, "metricx_qe_score": 7.293168067932129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark einzurichten?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998863935470581, "xcomet_qe_score": 0.9992614984512329, "metricx_score": 0.20635683834552765, "metricx_qe_score": 0.29098349809646606, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Nun, in den letzten Jahren haben wir eine Explosion von transformatorbasierten Vision- und Sprachmodellen gesehen, die auf große Mengen von Bild-Text-Paaren vortrainiert wurden.", "metrics": {"bleu_score": 32.16397363858737, "chrf_score": 66.9566116284412, "xcomet_score": 0.9560517072677612, "xcomet_qe_score": 0.9755427837371826, "metricx_score": 2.4588520526885986, "metricx_qe_score": 2.2718708515167236, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle bringt die Spitze der Technik in den Bereichen Bild- und Sprachaufgaben mit sich, wie z.B. visuelle Fragestellung, Beantwortung, visuelle logische Schlussfolgerung, Bildwiederherstellung, Satzverankerung.", "metrics": {"bleu_score": 20.638636014941365, "chrf_score": 47.57225964968008, "xcomet_score": 0.933668851852417, "xcomet_qe_score": 0.9677330851554871, "metricx_score": 2.2145462036132812, "metricx_qe_score": 1.7963110208511353, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Also haben wir eine Nachricht erhalten, die Genauigkeiten auf diesen task-spezifischen Benchmarks nehmen stetig zu.", "metrics": {"bleu_score": 11.317025556111567, "chrf_score": 61.726458666990084, "xcomet_score": 0.9426595568656921, "xcomet_qe_score": 0.9407480359077454, "metricx_score": 3.201862335205078, "metricx_qe_score": 3.220093250274658, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5102907419204712, "metricx_qe_score": 0.9778188467025757, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "metrics": {"bleu_score": 1.5732934811145336, "chrf_score": 22.945309457796828, "xcomet_score": 0.8608940839767456, "xcomet_qe_score": 0.9653360843658447, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "And the low score for this one.", "metrics": {"bleu_score": 0.0, "chrf_score": 10.134204415758195, "xcomet_score": 0.9208128452301025, "xcomet_qe_score": 0.9944015741348267, "metricx_score": 11.347540855407715, "metricx_qe_score": 15.118833541870117, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Do vision and language models focus on the right thing?", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 14.874340397236796, "xcomet_score": 0.7883993983268738, "xcomet_qe_score": 0.9926931858062744, "metricx_score": 24.421545028686523, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie in früheren Arbeiten gezeigt?", "metrics": {"bleu_score": 54.844980922047604, "chrf_score": 70.38460547411864, "xcomet_score": 0.9823395013809204, "xcomet_qe_score": 1.0, "metricx_score": 0.40236908197402954, "metricx_qe_score": 0.2961832880973816, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt weiter zu beleuchten, schlagen wir eine agnostischere Richtung vor und führen Vals ein, die die Empfindlichkeit von visuellen und sprachlichen Modellen gegenüber bestimmten sprachlichen Phänomenen testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen.", "metrics": {"bleu_score": 45.9927792757078, "chrf_score": 71.26897274634766, "xcomet_score": 0.8632258772850037, "xcomet_qe_score": 0.8612966537475586, "metricx_score": 2.1091980934143066, "metricx_qe_score": 3.85738468170166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "We target existence, plurality, counting, spatial relations, actions, and entity coreference.", "metrics": {"bleu_score": 3.4197980307804725, "chrf_score": 25.97133449697842, "xcomet_score": 0.9625022411346436, "xcomet_qe_score": 0.9836755990982056, "metricx_score": 24.872203826904297, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "But how do we test whether the vision and language models have captured these phenomena?", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 18.525444915527704, "xcomet_score": 0.9864256381988525, "xcomet_qe_score": 0.9964276552200317, "metricx_score": 24.64211082458496, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "By foiling, a method previously applied for vision and language models only for noun phrases by Ravi Shankar and collaborators, and on counting by us in previous work.", "metrics": {"bleu_score": 1.5784309053930103, "chrf_score": 19.980665618987775, "xcomet_score": 0.6537573337554932, "xcomet_qe_score": 0.7975770235061646, "metricx_score": 23.806133270263672, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde, dass wir die Bildunterschrift nehmen und eine Folie erzeugen, indem wir die Bildunterschrift so ändern, dass sie das Bild nicht mehr beschreibt.", "metrics": {"bleu_score": 57.823527323521574, "chrf_score": 67.78562321577903, "xcomet_score": 0.7754034399986267, "xcomet_qe_score": 0.9609031677246094, "metricx_score": 4.0831756591796875, "metricx_qe_score": 1.97776460647583, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir machen diese Phrase-Änderungen, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Handlungen und Entitätskoreferrenzen, wobei jedes Stück aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, FOL-Instanzen zu erstellen.", "metrics": {"bleu_score": 55.6517094289141, "chrf_score": 75.14183381781162, "xcomet_score": 0.7761530876159668, "xcomet_qe_score": 0.7084807753562927, "metricx_score": 4.667936325073242, "metricx_qe_score": 5.129983425140381, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir im Fall des Actions PIECE zwei Instrumente, eines in dem das Handlungsvorgestell veränderte mit einer anderen Handlung und eines in dem Handlungszeitformen ausgetauscht werden.", "metrics": {"bleu_score": 31.034313423842054, "chrf_score": 64.41485745835836, "xcomet_score": 0.6707000136375427, "xcomet_qe_score": 0.7935312986373901, "metricx_score": 13.218114852905273, "metricx_qe_score": 12.190199851989746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Counting and coreference also are pieces that have more than one instrument.", "metrics": {"bleu_score": 2.8603449943861583, "chrf_score": 31.46835211239721, "xcomet_score": 0.8819562196731567, "xcomet_qe_score": 0.8568745851516724, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schaffen diese Foys, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalisch und ansonsten gültige Sätze sind.", "metrics": {"bleu_score": 56.839979799673266, "chrf_score": 65.66057190324285, "xcomet_score": 0.8814935684204102, "xcomet_qe_score": 0.9010562300682068, "metricx_score": 5.542889595031738, "metricx_qe_score": 5.496476173400879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht einfach, da eine fehlende Bildunterschrift seltener vorkommen kann als die ursprüngliche Bildunterschrift.", "metrics": {"bleu_score": 14.085916416769418, "chrf_score": 44.63620877343841, "xcomet_score": 0.9871935844421387, "xcomet_qe_score": 0.992361307144165, "metricx_score": 1.3908909559249878, "metricx_qe_score": 0.8044729232788086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, obwohl es nicht unmöglich ist, ist es statistisch wahrscheinlicher, dass Pflanzen einen Mann schneiden, als dass ein Mann Pflanzen schneidet. Und große Vision- und Sprachmodelle könnten dies erkennen.", "metrics": {"bleu_score": 36.45191045460592, "chrf_score": 72.0032154007498, "xcomet_score": 0.9014887809753418, "xcomet_qe_score": 0.9319499731063843, "metricx_score": 4.786314487457275, "metricx_qe_score": 3.8151612281799316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Therefore, to obtain valid foils, we must take action.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 11.220187249727877, "xcomet_score": 0.88438481092453, "xcomet_qe_score": 0.9856106042861938, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "First, we make use of strong language models to propose foils.", "metrics": {"bleu_score": 3.673526562988939, "chrf_score": 17.845604790280554, "xcomet_score": 0.875478208065033, "xcomet_qe_score": 0.969338059425354, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir natürliche Sprachinferenz, oder kurz NLI, um Foils zu filtern, die das Bild noch beschreiben könnten, da wir bei der Erstellung von Foils sicherstellen müssen, dass sie das Bild nicht beschreiben.", "metrics": {"bleu_score": 45.920941854034346, "chrf_score": 67.12482863291525, "xcomet_score": 0.789749264717102, "xcomet_qe_score": 0.8469128608703613, "metricx_score": 7.69180965423584, "metricx_qe_score": 6.541336536407471, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "To test this automatically, we apply natural language inference with the following rationale.", "metrics": {"bleu_score": 2.393672168921959, "chrf_score": 24.130851759700516, "xcomet_score": 0.9785058498382568, "xcomet_qe_score": 1.0, "metricx_score": 24.410688400268555, "metricx_qe_score": 24.150941848754883, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "We consider an image to be the premise and its caption its entailed hypothesis.", "metrics": {"bleu_score": 2.458476536482737, "chrf_score": 19.904571394116463, "xcomet_score": 0.9187745451927185, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich betrachten wir die Bildunterschrift als Prämisse und das Folienpapier als Hypothese.", "metrics": {"bleu_score": 19.402570578233032, "chrf_score": 52.53281188483761, "xcomet_score": 0.9357309341430664, "xcomet_qe_score": 0.9907506704330444, "metricx_score": 0.9307999610900879, "metricx_qe_score": 0.4283469319343567, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "If an nli model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "metrics": {"bleu_score": 1.633898440122165, "chrf_score": 17.949206085414346, "xcomet_score": 0.8451864719390869, "xcomet_qe_score": 0.907997190952301, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image and we filter these foils out.", "metrics": {"bleu_score": 1.3339264902154053, "chrf_score": 18.794862536490413, "xcomet_score": 0.5609045624732971, "xcomet_qe_score": 0.7312869429588318, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "But this procedure is not perfect. It is just an indicator for valid foils.", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 19.66797792169295, "xcomet_score": 0.9178910255432129, "xcomet_qe_score": 1.0, "metricx_score": 23.317367553710938, "metricx_qe_score": 21.968677520751953, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Generierung gültiger Falscheien, menschliche Annotatoren, um die Daten zu validieren, die in Vals verwendet werden.", "metrics": {"bleu_score": 36.032121811571, "chrf_score": 72.42035484672724, "xcomet_score": 0.9412506818771362, "xcomet_qe_score": 0.8935068845748901, "metricx_score": 4.762020587921143, "metricx_qe_score": 6.731775283813477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Filterung und der menschlichen Bewertung haben wir so viele Testinstanzen, wie in dieser Tabelle beschrieben.", "metrics": {"bleu_score": 56.971032152705476, "chrf_score": 75.59275791006239, "xcomet_score": 0.9985876083374023, "xcomet_qe_score": 0.9820192456245422, "metricx_score": 0.4296507239341736, "metricx_qe_score": 0.6265155076980591, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass Valls keine Trainingsdaten liefert, sondern nur Testdaten.", "metrics": {"bleu_score": 28.025542898280413, "chrf_score": 77.18139499576814, "xcomet_score": 0.8871389627456665, "xcomet_qe_score": 0.8749264478683472, "metricx_score": 1.209532618522644, "metricx_qe_score": 1.9324520826339722, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Since it is a zero-shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "metrics": {"bleu_score": 1.5886262183839546, "chrf_score": 24.490547002769375, "xcomet_score": 0.981237530708313, "xcomet_qe_score": 0.9872356653213501, "metricx_score": 23.877307891845703, "metricx_qe_score": 24.041324615478516, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Fine-tuning würde es den Modellen nur ermöglichen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen.", "metrics": {"bleu_score": 88.17122476287477, "chrf_score": 88.28551161634805, "xcomet_score": 0.9616537094116211, "xcomet_qe_score": 0.9704836010932922, "metricx_score": 2.775322914123535, "metricx_qe_score": 3.216600179672241, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nehmen.", "metrics": {"bleu_score": 45.72313446186435, "chrf_score": 75.60584325726424, "xcomet_score": 0.9927325248718262, "xcomet_qe_score": 0.9957997798919678, "metricx_score": 0.7157299518585205, "metricx_qe_score": 0.8700405955314636, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach dem Pretraining aufweisen.", "metrics": {"bleu_score": 24.192619393259797, "chrf_score": 59.74296522815726, "xcomet_score": 0.9886809587478638, "xcomet_qe_score": 1.0, "metricx_score": 1.6648707389831543, "metricx_qe_score": 0.8001390099525452, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "We experiment with five vision and language models on VOWELS, namely with CLIP, ALX-MERT, Vilbert, Vilbert12in1, and Visualbert.", "metrics": {"bleu_score": 3.97213910459993, "chrf_score": 30.086335276434305, "xcomet_score": 0.6469149589538574, "xcomet_qe_score": 0.7110049724578857, "metricx_score": 11.295455932617188, "metricx_qe_score": 8.18154525756836, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Evaluierungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satzpaaren in Beschriftungen und Folien.", "metrics": {"bleu_score": 41.2295470431275, "chrf_score": 70.76768810694072, "xcomet_score": 0.8947561383247375, "xcomet_qe_score": 0.8441872000694275, "metricx_score": 2.89668345451355, "metricx_qe_score": 1.3516007661819458, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht noch relevanter für dieses Video, werden wir unsere permissivere Metrik, die paarweise Genauigkeit, vorführen, die misst, ob der Bild-Satz-Ausrichtungspunkt für die richtige Bild-Text-Paarung größer ist als für das gefälschte Paar.", "metrics": {"bleu_score": 20.920046486776364, "chrf_score": 64.46589857366472, "xcomet_score": 0.8233669996261597, "xcomet_qe_score": 0.7113447189331055, "metricx_score": 3.598867893218994, "metricx_qe_score": 3.583005666732788, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "For more metrics and results on them, do check out our paper.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 15.719057460582512, "xcomet_score": 0.9617215394973755, "xcomet_qe_score": 0.9875798225402832, "metricx_score": 24.40216827392578, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit paarweis Genauigkeit werden hier gezeigt, und sie stimmen mit den Ergebnissen überein, die wir aus den anderen Metriken erhalten haben. Es ist, dass die beste Nullschussleistung durch Wilbert Twelve in One erreicht wird, gefolgt von Wilbert, Alex Mert, Clip und schließlich Visual Bird.", "metrics": {"bleu_score": 36.09260083442242, "chrf_score": 68.77608127982423, "xcomet_score": 0.4802323281764984, "xcomet_qe_score": 0.46250757575035095, "metricx_score": 9.127360343933105, "metricx_qe_score": 8.455857276916504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die auf einzelne Objekte wie Existenz und Nomenphrasen ausgerichtet sind, fast von Wilbert 12 in 1 gelöst werden, was betont, dass Modelle in der Lage sind, benannte Objekte und ihre Präsenz in Bildern zu identifizieren.", "metrics": {"bleu_score": 48.80758122704637, "chrf_score": 65.67208533117447, "xcomet_score": 0.8723421096801758, "xcomet_qe_score": 0.8436009883880615, "metricx_score": 3.704496383666992, "metricx_qe_score": 4.081214904785156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings können keine der verbleibenden Teile in unseren gegnerischen Foulingsituationen zuverlässig gelöst werden.", "metrics": {"bleu_score": 32.85702044797774, "chrf_score": 64.4715151943476, "xcomet_score": 0.9110389947891235, "xcomet_qe_score": 0.9749935269355774, "metricx_score": 2.883615732192993, "metricx_qe_score": 1.3722503185272217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "We see from the lularity and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects or counting them in an image.", "metrics": {"bleu_score": 1.4252258012210821, "chrf_score": 19.435715616272518, "xcomet_score": 0.9066945314407349, "xcomet_qe_score": 0.9335811734199524, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "metrics": {"bleu_score": 2.0592684545558493, "chrf_score": 22.173757515270452, "xcomet_score": 0.8867919445037842, "xcomet_qe_score": 0.9651520252227783, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie von Plausibilitätsbasierten Verzerrungen unterstützt werden, wie wir im Handlungsstück sehen.", "metrics": {"bleu_score": 62.180717171184014, "chrf_score": 79.22500596178935, "xcomet_score": 0.9296802282333374, "xcomet_qe_score": 0.9124395847320557, "metricx_score": 1.3636813163757324, "metricx_qe_score": 1.6902275085449219, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Co-reference Piece erfahren wir, dass das Verfolgen mehrerer Referenzen auf dasselbe Objekt in einem Bild durch die Verwendung von Pronomen auch für visuelle und Sprachmodelle schwierig ist.", "metrics": {"bleu_score": 40.13786550577507, "chrf_score": 66.43090900412896, "xcomet_score": 0.8411760330200195, "xcomet_qe_score": 0.8556035757064819, "metricx_score": 3.939584970474243, "metricx_qe_score": 3.9332408905029297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Sanity Check und weil es ein interessantes Experiment ist, haben wir auch zwei Textmodelle, GPT1 und GPT2, verglichen, um zu beurteilen, ob Vals durch diese unidimensionalen Modelle gelöst werden kann, indem die Verwirrung der richtigen und falschen Bildunterschrift berechnet und die Eingabe mit der geringsten Verwirrung vorhergesagt wird.", "metrics": {"bleu_score": 17.84439753088631, "chrf_score": 49.544435401306416, "xcomet_score": 0.6755833625793457, "xcomet_qe_score": 0.6843357086181641, "metricx_score": 4.316889762878418, "metricx_qe_score": 4.579948902130127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "metrics": {"bleu_score": 1.5301683686839007, "chrf_score": 19.248528487904075, "xcomet_score": 0.7326084971427917, "xcomet_qe_score": 0.9316962361335754, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die textbasierten GPT-Modelle die Plausibilität der Welt besser erfasst haben als die visuelle und sprachbasierten Modelle.", "metrics": {"bleu_score": 62.06800198581103, "chrf_score": 76.20338623174693, "xcomet_score": 0.97748863697052, "xcomet_qe_score": 0.9637571573257446, "metricx_score": 0.8149784803390503, "metricx_qe_score": 1.0075805187225342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass Valsa ein Benchmark ist, der die Linse der linguistischen Konstrukte verwendet, um der Community zu helfen, Vision- und Sprachmodelle zu verbessern, indem sie ihre visuellen Grundlagen hart testen.", "metrics": {"bleu_score": 24.58597990773975, "chrf_score": 59.91702812289904, "xcomet_score": 0.7484121322631836, "xcomet_qe_score": 0.7627222537994385, "metricx_score": 6.286229133605957, "metricx_qe_score": 5.658116817474365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass visuelle und sprachliche Modelle benannte Objekte in ihren Bildern gut identifizieren, wie durch das Existenzstück gezeigt, aber Schwierigkeiten haben, ihre Abhängigkeit und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren.", "metrics": {"bleu_score": 40.24073939940233, "chrf_score": 68.05673292527183, "xcomet_score": 0.8983889818191528, "xcomet_qe_score": 0.8846386671066284, "metricx_score": 3.4853577613830566, "metricx_qe_score": 3.5652477741241455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "We would really like to encourage the community to use VAlues for measuring progress towards language grounding with vision and language models.", "metrics": {"bleu_score": 1.5766042244954548, "chrf_score": 20.460496796834516, "xcomet_score": 0.7427940368652344, "xcomet_qe_score": 0.8556915521621704, "metricx_score": 24.662328720092773, "metricx_qe_score": 23.880985260009766, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, Valves könnten als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz dazu beiträgt, dass Modelle in einem der von Valves getesteten Aspekt verbessert werden.", "metrics": {"bleu_score": 61.73608277795635, "chrf_score": 81.39133966044965, "xcomet_score": 0.8032531142234802, "xcomet_qe_score": 0.7963581681251526, "metricx_score": 7.182212829589844, "metricx_qe_score": 7.2061004638671875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "If you are interested, please check out the Valls data on GitHub and if you have any questions, do not hesitate to contact us.", "metrics": {"bleu_score": 1.8913109322531225, "chrf_score": 19.099594322512488, "xcomet_score": 0.8320425748825073, "xcomet_qe_score": 0.8317978978157043, "metricx_score": 7.572037220001221, "metricx_qe_score": 6.6173906326293945, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamezawa from the University of Tokyo.", "metrics": {"bleu_score": 43.36189090348677, "chrf_score": 67.504209558587, "xcomet_score": 0.9667677283287048, "xcomet_qe_score": 0.9698256254196167, "metricx_score": 5.118667125701904, "metricx_qe_score": 4.385619163513184, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde ein Papier mit dem Titel \"RNSum: Large Scale Dataset for Automatic Recurrent Neural Network Curation via Commit Log Summarization\" vorstellen.", "metrics": {"bleu_score": 9.562406574442017, "chrf_score": 62.0249275995752, "xcomet_score": 0.7814120650291443, "xcomet_qe_score": 0.7759283781051636, "metricx_score": 2.4823012351989746, "metricx_qe_score": 2.055206537246704, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "I will explain in this order.", "metrics": {"bleu_score": 6.770186228657864, "chrf_score": 10.974150648347857, "xcomet_score": 0.9948517084121704, "xcomet_qe_score": 1.0, "metricx_score": 3.8239552974700928, "metricx_qe_score": 2.650315523147583, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst werde ich die automatische Knotengenerierung vorstellen, an der wir in dieser Forschung arbeiten.", "metrics": {"bleu_score": 65.72677895577044, "chrf_score": 75.09311902183319, "xcomet_score": 0.8476223945617676, "xcomet_qe_score": 0.8132790327072144, "metricx_score": 5.20695161819458, "metricx_qe_score": 4.645050525665283, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Release Note ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Version eines Softwareprodukts verteilt werden.", "metrics": {"bleu_score": 77.72256411812982, "chrf_score": 81.5010883021114, "xcomet_score": 0.9515838623046875, "xcomet_qe_score": 0.9806770086288452, "metricx_score": 1.9618010520935059, "metricx_qe_score": 1.726650357246399, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Risikonebenen für Bajan 2,6%.", "metrics": {"bleu_score": 16.058516370438436, "chrf_score": 25.174215293104734, "xcomet_score": 0.13808324933052063, "xcomet_qe_score": 0.135206937789917, "metricx_score": 14.033360481262207, "metricx_qe_score": 23.002851486206055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "These nodes play an important role in open source development, but they are time-consuming to prepare manually.", "metrics": {"bleu_score": 2.4074859035470344, "chrf_score": 17.428156914547206, "xcomet_score": 0.8331413269042969, "xcomet_qe_score": 0.8863617777824402, "metricx_score": 22.056631088256836, "metricx_qe_score": 20.892621994018555, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, hochwertige Release Notes automatisch zu generieren.", "metrics": {"bleu_score": 28.339296176052862, "chrf_score": 54.47489764094189, "xcomet_score": 0.9922420978546143, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.5777539014816284, "metricx_qe_score": 0.35235098004341125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Studien zur automatischen Risikogenerierung verweisen.", "metrics": {"bleu_score": 12.320255516768906, "chrf_score": 53.47462922082427, "xcomet_score": 0.7815729379653931, "xcomet_qe_score": 0.792583703994751, "metricx_score": 7.804001808166504, "metricx_qe_score": 4.6703267097473145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "The first is a system called Arlen, released in 2014.", "metrics": {"bleu_score": 2.9381581998927433, "chrf_score": 15.904264850601308, "xcomet_score": 0.7730062007904053, "xcomet_qe_score": 0.7576813697814941, "metricx_score": 16.049938201904297, "metricx_qe_score": 16.589990615844727, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet einen regelbasierten Ansatz, z. B. den Verwendung des Änderungsextraktors, um Kernunterschiede, Bibliotheksänderungen und Dokumentänderungen aus den Unterschieden zwischen den Versionen zu extrahieren und sie schließlich zu kombinieren.", "metrics": {"bleu_score": 45.32607978893935, "chrf_score": 74.67844199877759, "xcomet_score": 0.9539646506309509, "xcomet_qe_score": 0.9239453077316284, "metricx_score": 2.2729618549346924, "metricx_qe_score": 2.1621577739715576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist der Problemextraktor in der oberen rechten Ecke.", "metrics": {"bleu_score": 54.45178846139407, "chrf_score": 70.42630054677592, "xcomet_score": 0.9356541633605957, "xcomet_qe_score": 0.96976637840271, "metricx_score": 1.743484377861023, "metricx_qe_score": 0.8618403077125549, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Which must be linked to Jira, the issue tracking system, and can only be applied to projects that use Jira.", "metrics": {"bleu_score": 4.141141330484801, "chrf_score": 20.073022717023438, "xcomet_score": 0.8506428003311157, "xcomet_qe_score": 0.9961528778076172, "metricx_score": 12.859153747558594, "metricx_qe_score": 5.230062961578369, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, es kann nicht für viele Projekte auf Github verwendet werden.", "metrics": {"bleu_score": 44.80304273880272, "chrf_score": 83.56672980954643, "xcomet_score": 0.9911720752716064, "xcomet_qe_score": 0.9910182952880859, "metricx_score": 0.41232043504714966, "metricx_qe_score": 0.5953456163406372, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "The second is grief, recently announced in 2021.", "metrics": {"bleu_score": 4.521356896113449, "chrf_score": 15.250173679666954, "xcomet_score": 0.44779568910598755, "xcomet_qe_score": 0.7002503871917725, "metricx_score": 15.829519271850586, "metricx_qe_score": 14.480974197387695, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "It is available on the internet and can be installed via pip.", "metrics": {"bleu_score": 3.673526562988939, "chrf_score": 27.100778446249222, "xcomet_score": 0.9608222246170044, "xcomet_qe_score": 0.9818592071533203, "metricx_score": 20.55967903137207, "metricx_qe_score": 21.26077651977539, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches lernbasiertes Textklassifikationsmodell und gibt für jeden Eingabe-Commit-Text eine der fünf Kategorien aus, wie z.B. Features oder Bugfixes.", "metrics": {"bleu_score": 28.95907231555484, "chrf_score": 58.83237811909915, "xcomet_score": 0.9719189405441284, "xcomet_qe_score": 0.9830930233001709, "metricx_score": 2.3314504623413086, "metricx_qe_score": 1.4419035911560059, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Beispiel, das eine Korrektur oder eine Fehlerbehebung anzeigt.", "metrics": {"bleu_score": 18.51565595560746, "chrf_score": 52.103313185556786, "xcomet_score": 0.985404372215271, "xcomet_qe_score": 0.9781237244606018, "metricx_score": 0.9299116730690002, "metricx_qe_score": 0.9390228986740112, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Keras' Training Data ist ziemlich klein, etwa 5000, und wird in den unten beschriebenen Experimenten gezeigt.", "metrics": {"bleu_score": 44.61660210144735, "chrf_score": 69.81272018959697, "xcomet_score": 0.740369439125061, "xcomet_qe_score": 0.7251334190368652, "metricx_score": 6.032267093658447, "metricx_qe_score": 5.593111038208008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Textklassifikationsmodells ist nicht hoch.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26596003770828247, "metricx_qe_score": 0.4735175371170044, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "I present two related researches, but there are problems of limited applicability and scarce data resources.", "metrics": {"bleu_score": 2.416027466056967, "chrf_score": 19.774861973279407, "xcomet_score": 0.9632470607757568, "xcomet_qe_score": 0.9882595539093018, "metricx_score": 19.232818603515625, "metricx_qe_score": 22.751209259033203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Our paper solves these two problems and automatically generates high quality release notes.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 28.49246929370143, "xcomet_score": 0.8704829216003418, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das Problem der begrenzten Anwendbarkeit schlagen wir eine qualitativ hochwertige Klassifizierungssummarisierungsmethode vor, die nur Commit-Nachrichten als Eingabe verwendet.", "metrics": {"bleu_score": 64.53403586930145, "chrf_score": 78.78125470648362, "xcomet_score": 0.9487514495849609, "xcomet_qe_score": 0.9486701488494873, "metricx_score": 2.1649765968322754, "metricx_qe_score": 1.5913482904434204, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Wörterbücher verwendet werden.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 80.82223744788863, "xcomet_score": 0.9210816621780396, "xcomet_qe_score": 0.9402592182159424, "metricx_score": 3.044806957244873, "metricx_qe_score": 1.8927797079086304, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der knappen Datenressourcen haben wir einen rl- und some-Dataset aufgebaut, das aus etwa 82.000 Daten besteht, die wir aus öffentlichen GitHub-Repositorys mit der GitHub-API gesammelt haben.", "metrics": {"bleu_score": 40.28754317603132, "chrf_score": 67.09058147334028, "xcomet_score": 0.8387615084648132, "xcomet_qe_score": 0.8448523879051208, "metricx_score": 7.290832996368408, "metricx_qe_score": 8.053311347961426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unseren Datensatz.", "metrics": {"bleu_score": 24.0785655451027, "chrf_score": 70.3481767213826, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel für Daten.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 81.3052385800557, "xcomet_score": 0.9865502119064331, "xcomet_qe_score": 0.9950288534164429, "metricx_score": 0.11113797873258591, "metricx_qe_score": 0.3509396016597748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist eine Commit-Nachricht und die rechte Seite ist ein Release-Node.", "metrics": {"bleu_score": 25.919218840980953, "chrf_score": 53.29614244007688, "xcomet_score": 0.8037726879119873, "xcomet_qe_score": 0.7872673273086548, "metricx_score": 4.158987045288086, "metricx_qe_score": 3.2926719188690186, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "The reason notes are labeled as improvements of faces etc.", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 12.964506998093311, "xcomet_score": 0.35337018966674805, "xcomet_qe_score": 0.7658257484436035, "metricx_score": 19.109739303588867, "metricx_qe_score": 16.686616897583008, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachrichten als Eingabe nimmt und die mit Labels versehenen Listenpunkte als Ausgabe liefert.", "metrics": {"bleu_score": 38.305978177479744, "chrf_score": 67.75334586227108, "xcomet_score": 0.9271291494369507, "xcomet_qe_score": 0.8818868398666382, "metricx_score": 2.6099352836608887, "metricx_qe_score": 3.4060699939727783, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "This can be regarded as a summarization task.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 14.295159593378065, "xcomet_score": 0.9716808795928955, "xcomet_qe_score": 1.0, "metricx_score": 20.048583984375, "metricx_qe_score": 21.963693618774414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Ebenen definiert: Features, Verbesserungen, Bugfixes, Deprekationen, Removals und Breaking Changes.", "metrics": {"bleu_score": 14.400124446705304, "chrf_score": 37.345609297726924, "xcomet_score": 0.6238193511962891, "xcomet_qe_score": 0.7554442286491394, "metricx_score": 5.9920525550842285, "metricx_qe_score": 4.253737926483154, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese Werte wurden auf der Grundlage früherer Forschung und anderer Praktiken festgelegt.", "metrics": {"bleu_score": 24.71244254525359, "chrf_score": 68.17815826275529, "xcomet_score": 0.9851720333099365, "xcomet_qe_score": 1.0, "metricx_score": 0.9427165985107422, "metricx_qe_score": 0.9227614402770996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "The lease note on the bottom right and extracted from the lease note shown on the bottom left.", "metrics": {"bleu_score": 2.0244462660665508, "chrf_score": 15.369437940039491, "xcomet_score": 0.5476489067077637, "xcomet_qe_score": 0.7402589321136475, "metricx_score": 17.125009536743164, "metricx_qe_score": 9.480218887329102, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zeitpunkt ist es notwendig, die vier Labyrinthe zu erkennen, die im Voraus eingerichtet wurden.", "metrics": {"bleu_score": 21.951524426618455, "chrf_score": 54.163144070606016, "xcomet_score": 0.925808310508728, "xcomet_qe_score": 0.860767126083374, "metricx_score": 5.06805419921875, "metricx_qe_score": 3.351576566696167, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Labels sind nicht immer konsistent mit jeder Definition.", "metrics": {"bleu_score": 9.864703138979419, "chrf_score": 40.945278639650745, "xcomet_score": 0.8746168613433838, "xcomet_qe_score": 0.8831794857978821, "metricx_score": 4.916373252868652, "metricx_qe_score": 3.394439220428467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel umfasst die Verbesserungsstufe Verbesserungen, Optimierungen und so weiter.", "metrics": {"bleu_score": 39.72090153861676, "chrf_score": 60.30927967313776, "xcomet_score": 0.9626609086990356, "xcomet_qe_score": 0.9222862720489502, "metricx_score": 2.37796950340271, "metricx_qe_score": 1.4005882740020752, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabelliste mit Studienbegriffen für jede dieser Notationsvarianten erstellt.", "metrics": {"bleu_score": 46.15415465297943, "chrf_score": 66.7018687650813, "xcomet_score": 0.9121692776679993, "xcomet_qe_score": 0.9177519679069519, "metricx_score": 4.032475471496582, "metricx_qe_score": 3.1369645595550537, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Use it to detect the release note class and collect the text of the list that follows as the release note sentence for the class.", "metrics": {"bleu_score": 1.4445809981770859, "chrf_score": 14.693987267031822, "xcomet_score": 0.6306344270706177, "xcomet_qe_score": 0.8445093035697937, "metricx_score": 10.520278930664062, "metricx_qe_score": 7.614343166351318, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Next is a commit message.", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 15.13949671989257, "xcomet_score": 0.9150968790054321, "xcomet_qe_score": 0.992209792137146, "metricx_score": 10.624197959899902, "metricx_qe_score": 10.248659133911133, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Commit messages are not tied to each release.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 17.317815384752922, "xcomet_score": 0.9485031366348267, "xcomet_qe_score": 1.0, "metricx_score": 22.43446922302246, "metricx_qe_score": 24.628185272216797, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie im folgenden Bild gezeigt, wenn die aktuelle Version Version 2.5.19 ist, müssen wir die Daten aktualisieren.", "metrics": {"bleu_score": 13.08659428474303, "chrf_score": 48.32754100974132, "xcomet_score": 0.8048726916313171, "xcomet_qe_score": 0.78843754529953, "metricx_score": 7.819950103759766, "metricx_qe_score": 8.394556045532227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "The previous release version 2.5 to 18 and get it deep. This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "metrics": {"bleu_score": 0.9964194812460634, "chrf_score": 19.31522686226336, "xcomet_score": 0.514326810836792, "xcomet_qe_score": 0.6094492673873901, "metricx_score": 25.0, "metricx_qe_score": 24.185365676879883, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine heuristische Übereinstimmungsregel erstellt, um die vorherige und die nächste Version zu erhalten.", "metrics": {"bleu_score": 70.85876411943929, "chrf_score": 80.18983784798557, "xcomet_score": 0.9981439113616943, "xcomet_qe_score": 1.0, "metricx_score": 0.5447828769683838, "metricx_qe_score": 0.5286601781845093, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Day set analysis.", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 21.16962529764334, "xcomet_score": 0.40638992190361023, "xcomet_qe_score": 0.81794673204422, "metricx_score": 11.381097793579102, "metricx_qe_score": 11.013893127441406, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "In the end, seven thousand two hundred repositories.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 28.226460481833538, "xcomet_score": 0.6269258260726929, "xcomet_qe_score": 0.7626968026161194, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der im Monat veröffentlichten Token dreiundsechzig, was für eine Zusammenfassungsaufgabe recht hoch ist.", "metrics": {"bleu_score": 53.74512308135862, "chrf_score": 72.65308585505392, "xcomet_score": 0.9479361772537231, "xcomet_qe_score": 0.9496275186538696, "metricx_score": 2.384610652923584, "metricx_qe_score": 1.605698585510254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist die Anzahl der einzigartigen Token recht groß, nämlich achttausendachthundertdreißigtausend.", "metrics": {"bleu_score": 35.416987661440594, "chrf_score": 59.056972643608155, "xcomet_score": 0.9938526153564453, "xcomet_qe_score": 0.9927122592926025, "metricx_score": 0.5753577351570129, "metricx_qe_score": 0.44731494784355164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "Due to the large number of unique class and method names found in the library.", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 18.011055546672893, "xcomet_score": 0.8988968133926392, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 17.322708129882812, "metricx_qe_score": 16.18985366821289, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes werde ich die vorgeschlagene Methode erläutern.", "metrics": {"bleu_score": 75.06238537503395, "chrf_score": 93.98135035339729, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das extraktive und abstrakte Summarisierungsmodell besteht aus zwei neuronalen Modulen.", "metrics": {"bleu_score": 44.591268087021724, "chrf_score": 61.589944030709354, "xcomet_score": 0.9323861598968506, "xcomet_qe_score": 0.899320662021637, "metricx_score": 2.148331642150879, "metricx_qe_score": 2.471040964126587, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "A classifier using bart or code bart and a generator using bart.", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 23.523769868993462, "xcomet_score": 0.814393937587738, "xcomet_qe_score": 0.8733881711959839, "metricx_score": 17.861047744750977, "metricx_qe_score": 18.365371704101562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst verwendet ceas einen Klassifikator, um jede Commit-Nachricht in fünf Klassen zu klassifizieren: Features, Verbesserungen, Bugfixes, Deprekationen, plus und andere.", "metrics": {"bleu_score": 35.28229622155421, "chrf_score": 57.43982763348527, "xcomet_score": 0.8616814613342285, "xcomet_qe_score": 0.9166450500488281, "metricx_score": 5.971219539642334, "metricx_qe_score": 5.431053638458252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die Commited Messages, die als other klassifiziert sind, werden verworfen.", "metrics": {"bleu_score": 13.065113298388567, "chrf_score": 39.47463499230682, "xcomet_score": 0.8125689029693604, "xcomet_qe_score": 0.8649791479110718, "metricx_score": 5.901162147521973, "metricx_qe_score": 5.4895172119140625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet CES die generierte Methode auf die vier anderen Dokumente unabhängig voneinander an und generiert eine Liste von Notizen für jede Klasse.", "metrics": {"bleu_score": 31.52861344254502, "chrf_score": 62.59430135689964, "xcomet_score": 0.6610534191131592, "xcomet_qe_score": 0.7256056666374207, "metricx_score": 3.207364559173584, "metricx_qe_score": 3.4240975379943848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Entsprechungen zwischen Commit-Meldungen und Begründungen nicht bekannt.", "metrics": {"bleu_score": 37.59663529467017, "chrf_score": 58.588764972540865, "xcomet_score": 0.7503662109375, "xcomet_qe_score": 0.773756206035614, "metricx_score": 3.6841371059417725, "metricx_qe_score": 4.516462802886963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Daher weisen wir jedem Eingabe-Commit-Nachricht zwei Ebenen zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden.", "metrics": {"bleu_score": 20.665381837026608, "chrf_score": 52.336260120691726, "xcomet_score": 0.8207042217254639, "xcomet_qe_score": 0.8135291337966919, "metricx_score": 7.108266353607178, "metricx_qe_score": 7.186400890350342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren den klassifizierten abstrakten Summarisierungsansatz mit zwei verschiedenen Methoden.", "metrics": {"bleu_score": 5.35587222083487, "chrf_score": 58.1531009903681, "xcomet_score": 0.9611012935638428, "xcomet_qe_score": 0.9108798503875732, "metricx_score": 1.560009479522705, "metricx_qe_score": 1.4659016132354736, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir ga-single nennen, besteht aus einem einzigen sek-to-sek-Netzwerk und generiert eine einzige log-ist-no-text, die eine Zusammenfassung der Eingabe-Commit-Nachrichten darstellt.", "metrics": {"bleu_score": 32.205467825922135, "chrf_score": 61.34763255762964, "xcomet_score": 0.5353262424468994, "xcomet_qe_score": 0.5196151733398438, "metricx_score": 14.571720123291016, "metricx_qe_score": 15.290427207946777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgabe-Text kann in klassifizierte Segmente unterteilt werden, basierend auf speziellen, klassenspezifischen Endpunktbeispielen.", "metrics": {"bleu_score": 10.82597837309053, "chrf_score": 54.484215234702624, "xcomet_score": 0.9497957229614258, "xcomet_qe_score": 0.9290863275527954, "metricx_score": 4.557115077972412, "metricx_qe_score": 4.410953521728516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir csmatch nennen, besteht aus vier verschiedenen Sek-to-Sek-Netzwerken, von denen jedes einer der Listen-Klassen entspricht.", "metrics": {"bleu_score": 60.80105469061645, "chrf_score": 71.75299553621926, "xcomet_score": 0.6167259216308594, "xcomet_qe_score": 0.6354386806488037, "metricx_score": 7.6710524559021, "metricx_qe_score": 8.532295227050781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, lass mich das Experiment erklären.", "metrics": {"bleu_score": 11.044795567078939, "chrf_score": 48.837236179367665, "xcomet_score": 0.9677102565765381, "xcomet_qe_score": 0.9574393033981323, "metricx_score": 0.778838038444519, "metricx_qe_score": 0.6630911231040955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen: CAS, CAS Single, CAS Mould, Clustering und previous study grip.", "metrics": {"bleu_score": 27.447938256311044, "chrf_score": 58.823050458451256, "xcomet_score": 0.6549551486968994, "xcomet_qe_score": 0.5826056003570557, "metricx_score": 10.44830322265625, "metricx_qe_score": 10.916126251220703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "In Bezug auf die Auswertung werden diese Notizen in einigen Fällen in mehreren Sätzen ausgegeben.", "metrics": {"bleu_score": 30.415590104969052, "chrf_score": 54.27027139898415, "xcomet_score": 0.9690170288085938, "xcomet_qe_score": 0.9396991729736328, "metricx_score": 1.5917494297027588, "metricx_qe_score": 1.3744456768035889, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze zu zählen, da sie sind, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt.", "metrics": {"bleu_score": 64.42822497401406, "chrf_score": 82.38613549660745, "xcomet_score": 0.9626079797744751, "xcomet_qe_score": 0.9534733295440674, "metricx_score": 3.788745403289795, "metricx_qe_score": 4.842616558074951, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "The view is panoramic when the system outputs a short sentence.", "metrics": {"bleu_score": 3.1157290929555894, "chrf_score": 14.99842665517713, "xcomet_score": 0.23542125523090363, "xcomet_qe_score": 0.7390257716178894, "metricx_score": 20.845632553100586, "metricx_qe_score": 18.72212028503418, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem niedrigeren Blue Value in den Experimentsergebnissen, die im Folgenden beschrieben werden.", "metrics": {"bleu_score": 16.61742929957894, "chrf_score": 55.881501592211805, "xcomet_score": 0.8187854290008545, "xcomet_qe_score": 0.8612704277038574, "metricx_score": 4.129331111907959, "metricx_qe_score": 3.8907225131988525, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich berechnen wir auch die Spezifität, da Rote und Blau nicht berechnet werden können, wenn die Release-Knoten leer sind.", "metrics": {"bleu_score": 64.7084148066781, "chrf_score": 74.58993401487582, "xcomet_score": 0.8084896206855774, "xcomet_qe_score": 0.8175926804542542, "metricx_score": 6.073123455047607, "metricx_qe_score": 4.8957085609436035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell in Fällen, in denen die Eingabennadeln nicht leer sind, korrekt leere Textausgaben erzeugt.", "metrics": {"bleu_score": 54.89938756679379, "chrf_score": 64.64389330724093, "xcomet_score": 0.8632198572158813, "xcomet_qe_score": 0.8718942403793335, "metricx_score": 5.23431396484375, "metricx_qe_score": 5.192033290863037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Here are the results.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 21.383207021509556, "xcomet_score": 0.9305862188339233, "xcomet_qe_score": 1.0, "metricx_score": 4.0917158126831055, "metricx_qe_score": 4.641719818115234, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, haben wir auch den bereinigten Datensatz untersucht, der sie ausschließt.", "metrics": {"bleu_score": 77.05151516024394, "chrf_score": 85.48861107254838, "xcomet_score": 0.986684262752533, "xcomet_qe_score": 0.9844167232513428, "metricx_score": 0.39465874433517456, "metricx_qe_score": 0.45344027876853943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "CAS and CAS achieved LULU scores more than ten points higher than the baselines.", "metrics": {"bleu_score": 2.923637789252517, "chrf_score": 21.41980602688022, "xcomet_score": 0.48973357677459717, "xcomet_qe_score": 0.7172741889953613, "metricx_score": 19.476966857910156, "metricx_qe_score": 17.503047943115234, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem clean Test Set ist die Punktzahllücke zwischen der vorgeschlagenen Methode und dem Basismodell auf mehr als 20 Punkte gestiegen.", "metrics": {"bleu_score": 22.816849039973945, "chrf_score": 56.766144070245716, "xcomet_score": 0.8400729894638062, "xcomet_qe_score": 0.8960145711898804, "metricx_score": 4.472260475158691, "metricx_qe_score": 4.827676296234131, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "This result indicates that GHS and GHS have significant effects.", "metrics": {"bleu_score": 3.42209762272661, "chrf_score": 18.991301611089188, "xcomet_score": 0.23773601651191711, "xcomet_qe_score": 0.6465182304382324, "metricx_score": 17.123001098632812, "metricx_qe_score": 16.642911911010742, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "CAS got a better ROC score than CAS, suggesting that combining a classifier and a generator is effective in training the classifier using pseudo labels.", "metrics": {"bleu_score": 2.960061576193395, "chrf_score": 27.342438187022523, "xcomet_score": 0.5007797479629517, "xcomet_qe_score": 0.6104719638824463, "metricx_score": 23.038053512573242, "metricx_qe_score": 20.76419448852539, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "The high coverage of CAS can be achieved properly because the classifier can focus on selecting relevant commit messages for each class.", "metrics": {"bleu_score": 1.5095250248540109, "chrf_score": 21.231888528958923, "xcomet_score": 0.6588129997253418, "xcomet_qe_score": 0.8151559829711914, "metricx_score": 21.427509307861328, "metricx_qe_score": 17.161052703857422, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "CS Match tend to be higher in L than CS Single.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 18.921114752267336, "xcomet_score": 0.2412886917591095, "xcomet_qe_score": 0.6204848885536194, "metricx_score": 20.459308624267578, "metricx_qe_score": 16.388662338256836, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Das deutet darauf hin, dass es auch effektiv ist, unabhängig voneinander summarische Modelle mit unterschiedlicher Abstraktion für jede EIS-Klasse zu entwickeln.", "metrics": {"bleu_score": 28.67854689261496, "chrf_score": 56.892374802231394, "xcomet_score": 0.9580768346786499, "xcomet_qe_score": 0.922126054763794, "metricx_score": 4.42726993560791, "metricx_qe_score": 4.235175132751465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hier eine Fehleranalyse.", "metrics": {"bleu_score": 49.76093899250716, "chrf_score": 77.7341142949867, "xcomet_score": 0.9997150897979736, "xcomet_qe_score": 0.9981482028961182, "metricx_score": 0.09292015433311462, "metricx_qe_score": 0.15425381064414978, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "CS methods tend to output shorter sentences than human reference sentences.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 21.799146629993853, "xcomet_score": 0.8114050626754761, "xcomet_qe_score": 0.8963682651519775, "metricx_score": 24.410505294799805, "metricx_qe_score": 23.880599975585938, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung auf der rechten Seite hat der Referenzsatz drei oder vier Sätze, während cs nur einen Satz hat.", "metrics": {"bleu_score": 14.23071532720465, "chrf_score": 62.51004174164739, "xcomet_score": 0.9623786211013794, "xcomet_qe_score": 0.9595661163330078, "metricx_score": 3.446624755859375, "metricx_qe_score": 4.663092613220215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellresistenz ist, dass in den Trainingsdaten nur dreiunddreißig Prozent der Sätze auf der Featuresebene und vierzig Prozent auf der Verbesserungenebene vorhanden sind.", "metrics": {"bleu_score": 27.63215174928276, "chrf_score": 56.078165047552844, "xcomet_score": 0.9271481037139893, "xcomet_qe_score": 0.9401957988739014, "metricx_score": 1.6344560384750366, "metricx_qe_score": 1.5355443954467773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem können CAS-Methoden ohne zusätzliche Informationen keine genauen Listenpunkte generieren.", "metrics": {"bleu_score": 53.8772222047036, "chrf_score": 64.99145028944638, "xcomet_score": 0.8942617774009705, "xcomet_qe_score": 0.89063560962677, "metricx_score": 4.472059726715088, "metricx_qe_score": 3.996912956237793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das oberste Beispiel auf der rechten Seite ist ein Beispiel für eine sehr unordentliche Commit-Nachricht. Und der vollständige Satz kann ohne Bezug auf die entsprechende Pull Request oder das Problem nicht generiert werden.", "metrics": {"bleu_score": 41.645706114025764, "chrf_score": 76.36378083894402, "xcomet_score": 0.9222560524940491, "xcomet_qe_score": 0.9655373096466064, "metricx_score": 1.5752507448196411, "metricx_qe_score": 1.2643380165100098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten in der Eingabe miteinander verbunden sind und zu einem einzigen Satz zusammengefasst werden sollten. Aber es versagt, dies zu tun.", "metrics": {"bleu_score": 47.43107045832291, "chrf_score": 72.75316691795663, "xcomet_score": 0.9762904644012451, "xcomet_qe_score": 0.9755489230155945, "metricx_score": 0.8631254434585571, "metricx_qe_score": 1.08575439453125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Finally, a conclusion.", "metrics": {"bleu_score": 8.745825313180626, "chrf_score": 7.211538461538461, "xcomet_score": 0.4105106294155121, "xcomet_qe_score": 1.0, "metricx_score": 12.889494895935059, "metricx_qe_score": 16.856294631958008, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "We have built a new dataset for automatic phrase node generation.", "metrics": {"bleu_score": 3.1157290929555894, "chrf_score": 19.442440942644772, "xcomet_score": 0.7721953392028809, "xcomet_qe_score": 0.7982283234596252, "metricx_score": 19.906166076660156, "metricx_qe_score": 10.184820175170898, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe formuliert, Commit-Meldungen einzugeben und zu zusammenfassen, sodass sie für alle Projekte, die auf Englisch geschrieben sind, anwendbar ist.", "metrics": {"bleu_score": 24.601372576927545, "chrf_score": 65.61630913043098, "xcomet_score": 0.9881583452224731, "xcomet_qe_score": 0.973357081413269, "metricx_score": 0.7586297988891602, "metricx_qe_score": 1.5712168216705322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode weniger verrauschte Lesennoten bei höherer Abdeckung als die Baselines erzeugt.", "metrics": {"bleu_score": 67.49454888262711, "chrf_score": 77.98555308613348, "xcomet_score": 0.8597742319107056, "xcomet_qe_score": 0.8389925360679626, "metricx_score": 4.491847038269043, "metricx_qe_score": 3.8737921714782715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Please check out our desert oasis on the top.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 13.157355747184262, "xcomet_score": 0.19508102536201477, "xcomet_qe_score": 0.4937800467014313, "metricx_score": 19.606895446777344, "metricx_qe_score": 16.828712463378906, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 87.72426647426647, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Safar Ali.", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 45.20012371172729, "xcomet_score": 0.2309459149837494, "xcomet_qe_score": 0.27347037196159363, "metricx_score": 5.258333206176758, "metricx_qe_score": 4.16712760925293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unsere Arbeit vorstellen, kurz Tabellen-Daten-Erweiterung mit feinabgestimmten Transformer-Architekturen.", "metrics": {"bleu_score": 3.4857116957065437, "chrf_score": 40.62156678875258, "xcomet_score": 0.8728589415550232, "xcomet_qe_score": 0.8667315244674683, "metricx_score": 5.68429708480835, "metricx_qe_score": 6.521237850189209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Data scientists analyze data and mainly focus on manipulating the data's existing features.", "metrics": {"bleu_score": 2.4617934274488045, "chrf_score": 19.54821625843258, "xcomet_score": 0.9925143718719482, "xcomet_qe_score": 0.9829064607620239, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "But sometimes these features are limited.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 12.822484835393047, "xcomet_score": 0.9981358051300049, "xcomet_qe_score": 0.9976193904876709, "metricx_score": 19.864673614501953, "metricx_qe_score": 23.2288761138916, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Feature generation using another data source may add substantial information.", "metrics": {"bleu_score": 2.853183878886449, "chrf_score": 20.396028517862877, "xcomet_score": 0.9414024353027344, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Our research goal is automatic tabular data enrichment using external sources of free text.", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 25.013115300030076, "xcomet_score": 0.997702956199646, "xcomet_qe_score": 0.9935675859451294, "metricx_score": 23.85231590270996, "metricx_qe_score": 22.622896194458008, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, wir haben einen tabellarischen Datensatz und eine Wissensdatenbank.", "metrics": {"bleu_score": 80.70557274927978, "chrf_score": 90.56639279059108, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.42374300956726074, "metricx_qe_score": 0.5424605011940002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "We need an automatic process which involve entity linking and text analysis to extract new features from the knowledge base free text.", "metrics": {"bleu_score": 1.445299819229979, "chrf_score": 27.12370673291381, "xcomet_score": 0.9216192960739136, "xcomet_qe_score": 0.9380192756652832, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Struktur, zunächst einmal, ist genau dieser automatische Prozess.", "metrics": {"bleu_score": 41.72261448611505, "chrf_score": 69.97372006020822, "xcomet_score": 0.8693248629570007, "xcomet_qe_score": 0.8280066251754761, "metricx_score": 6.279628753662109, "metricx_qe_score": 7.7693562507629395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Also schauen wir uns ein Beispiel an. In den Daten, die zu schnell eingegeben werden,", "metrics": {"bleu_score": 6.986768364373987, "chrf_score": 36.234816558024455, "xcomet_score": 0.7259664535522461, "xcomet_qe_score": 0.5101906061172485, "metricx_score": 8.74495792388916, "metricx_qe_score": 7.454912185668945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Datensatz der Universitätsdatensatz.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.996767520904541, "xcomet_qe_score": 0.9648513793945312, "metricx_score": 0.24305054545402527, "metricx_qe_score": 0.6734426021575928, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "When its goal is to classify universities into low-ranked universities and high-ranked universities.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 21.959432164817663, "xcomet_score": 0.7879980802536011, "xcomet_qe_score": 0.9253767132759094, "metricx_score": 22.75249481201172, "metricx_qe_score": 24.74163818359375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "As knowledge base we use Wikipedia.", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 31.89770996811626, "xcomet_score": 0.9994814395904541, "xcomet_qe_score": 1.0, "metricx_score": 11.318742752075195, "metricx_qe_score": 13.528685569763184, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "The first phase of fist is entity linking.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 31.882033798298043, "xcomet_score": 0.7589173316955566, "xcomet_qe_score": 0.8122814297676086, "metricx_score": 20.48896026611328, "metricx_qe_score": 17.974058151245117, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Entität, in diesem Beispiel der Name der Universität, mit einer Entität innerhalb der Wissensdatenbank verknüpft ist.", "metrics": {"bleu_score": 63.371489335485336, "chrf_score": 85.2979154475863, "xcomet_score": 0.9812171459197998, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.419507771730423, "metricx_qe_score": 0.23583729565143585, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "And the text of the entities of the knowledge base is extracted and added to the dataset.", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 18.764586525072186, "xcomet_score": 0.939234733581543, "xcomet_qe_score": 0.991266131401062, "metricx_score": 23.30948829650879, "metricx_qe_score": 22.09562110900879, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text die Wikipedia-Artikelüberschrift.", "metrics": {"bleu_score": 48.88290318657944, "chrf_score": 63.37023506678303, "xcomet_score": 0.9884979724884033, "xcomet_qe_score": 1.0, "metricx_score": 2.656456708908081, "metricx_qe_score": 3.0683798789978027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Merkmale aus dem Abruftext generieren oder extrahieren.", "metrics": {"bleu_score": 28.947421495675087, "chrf_score": 59.43826373401036, "xcomet_score": 0.9886027574539185, "xcomet_qe_score": 0.9810433387756348, "metricx_score": 0.8402680158615112, "metricx_qe_score": 0.5299805998802185, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "So müssen wir eine Feature-Extraktion-Phase einführen, die Textanalyse beinhaltet.", "metrics": {"bleu_score": 6.857388492518904, "chrf_score": 41.27380551842828, "xcomet_score": 0.9131474494934082, "xcomet_qe_score": 0.9076064825057983, "metricx_score": 4.789381980895996, "metricx_qe_score": 4.925521373748779, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptnovität dieses Papiers, und ich werde in den nächsten Folien tief in sie eintauchen.", "metrics": {"bleu_score": 10.657284485555579, "chrf_score": 44.44374283226509, "xcomet_score": 0.823610782623291, "xcomet_qe_score": 0.8762560486793518, "metricx_score": 2.2567994594573975, "metricx_qe_score": 2.8887438774108887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Feature-Extraktion-Phase gibt es eine Feature-Generierungsphase, in der wir die extrahierten Features verwenden, um eine kleine Anzahl neuer Features zu generieren.", "metrics": {"bleu_score": 40.80917315547267, "chrf_score": 56.154232282430485, "xcomet_score": 0.9485706090927124, "xcomet_qe_score": 0.9681028723716736, "metricx_score": 1.154563546180725, "metricx_qe_score": 0.6262251138687134, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "First, generate features in the number of classes of the original dataset.", "metrics": {"bleu_score": 3.377156414337854, "chrf_score": 18.727301291304563, "xcomet_score": 0.7958634495735168, "xcomet_qe_score": 0.9496772289276123, "metricx_score": 8.006606101989746, "metricx_qe_score": 6.347663402557373, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08455271273851395, "metricx_qe_score": 0.3038375675678253, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also erstelle schnell zwei neue Features.", "metrics": {"bleu_score": 14.535768424205482, "chrf_score": 28.801697976843286, "xcomet_score": 0.906670331954956, "xcomet_qe_score": 0.9041004180908203, "metricx_score": 3.668605089187622, "metricx_qe_score": 3.2035059928894043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "But if the dataset has five classes, first generate five new features.", "metrics": {"bleu_score": 3.377156414337854, "chrf_score": 18.381987314013028, "xcomet_score": 0.5674978494644165, "xcomet_qe_score": 0.8261669278144836, "metricx_score": 23.177106857299805, "metricx_qe_score": 21.322607040405273, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Eigenschaft repräsentiert die Wahrscheinlichkeit für jede Klasse.", "metrics": {"bleu_score": 43.44371253135793, "chrf_score": 65.6097909447073, "xcomet_score": 0.9979524612426758, "xcomet_qe_score": 1.0, "metricx_score": 0.8377842903137207, "metricx_qe_score": 0.7834119200706482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "To analyze the text, we use the current state of the art of text analysis, which are transformer-based language models such as bert, gpt, xlnet, and et cetera.", "metrics": {"bleu_score": 1.6276888006478718, "chrf_score": 29.82377325104736, "xcomet_score": 0.8881264925003052, "xcomet_qe_score": 0.903842568397522, "metricx_score": 8.847902297973633, "metricx_qe_score": 9.422637939453125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "But it is not likely that we can train language model using the input datasets.", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 19.05042737811223, "xcomet_score": 0.962578535079956, "xcomet_qe_score": 0.9791598916053772, "metricx_score": 17.370651245117188, "metricx_qe_score": 16.250688552856445, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe sein, die feinabgestimmt wird.", "metrics": {"bleu_score": 15.133218633429316, "chrf_score": 47.082120123214175, "xcomet_score": 0.9488273859024048, "xcomet_qe_score": 0.8827534914016724, "metricx_score": 3.0214037895202637, "metricx_qe_score": 3.9778053760528564, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Feature-Extraktion-Phase können wir also ein prärandisches Sprachmodell herunterladen und das Sprachmodell über den Zieldatensatz feinabstimmen.", "metrics": {"bleu_score": 53.28191817884722, "chrf_score": 73.13808064222711, "xcomet_score": 0.9017376899719238, "xcomet_qe_score": 0.8866211175918579, "metricx_score": 3.8362343311309814, "metricx_qe_score": 3.2731544971466064, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel, um das Sprachmodell zu verfeinern, um Text in Klassen zu klassifizieren, abstrakt in Klassen zu klassifizieren, niedrig oder hoch.", "metrics": {"bleu_score": 16.76978332247088, "chrf_score": 60.950461316127615, "xcomet_score": 0.8640940189361572, "xcomet_qe_score": 0.8744521141052246, "metricx_score": 7.128355979919434, "metricx_qe_score": 4.530982494354248, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Receive the language model output, which is the likelihood for each class, and use as new features.", "metrics": {"bleu_score": 2.2799725391172525, "chrf_score": 17.04537240423965, "xcomet_score": 0.8199467658996582, "xcomet_qe_score": 0.9951825141906738, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "The problem with this approach is that the dataset may have few distinct entity types.", "metrics": {"bleu_score": 2.158229074594286, "chrf_score": 16.488193101682338, "xcomet_score": 0.954315185546875, "xcomet_qe_score": 0.9879595041275024, "metricx_score": 7.978027820587158, "metricx_qe_score": 5.883913040161133, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Studie enthalten fast die Hälfte der Datensätze weniger als 400 Proben, und der kleinste Datensatz enthält 35 Proben in seinem Anfangs-Trainingssatz.", "metrics": {"bleu_score": 48.15092081725061, "chrf_score": 70.37026123171813, "xcomet_score": 0.9206538200378418, "xcomet_qe_score": 0.9161698222160339, "metricx_score": 0.6401765942573547, "metricx_qe_score": 0.9317115545272827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "So, um ein Sprachmodell über diesen Datensatz zu verfeinern, wäre es unzureichend.", "metrics": {"bleu_score": 10.511846841633776, "chrf_score": 44.951866942364724, "xcomet_score": 0.9047889709472656, "xcomet_qe_score": 0.9190304279327393, "metricx_score": 2.427401065826416, "metricx_qe_score": 1.914047360420227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können vorherige Kenntnisse über voranalysierte Datensätze verwenden.", "metrics": {"bleu_score": 50.26587270045526, "chrf_score": 78.90236451353269, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.2518448233604431, "metricx_qe_score": 0.24771606922149658, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Because fast is we apply fast over a multiple data set, we can use the n minus one data sets to gather information about the n minus one data sets and use this information when we analyze the nth data set.", "metrics": {"bleu_score": 1.205256842736819, "chrf_score": 23.031549235331898, "xcomet_score": 0.6556358337402344, "xcomet_qe_score": 0.697043776512146, "metricx_score": 15.987621307373047, "metricx_qe_score": 11.449352264404297, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "What we suggest is to add another fine-tuning phase.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 17.44943713652183, "xcomet_score": 0.7911218404769897, "xcomet_qe_score": 0.8595061302185059, "metricx_score": 13.504688262939453, "metricx_qe_score": 9.828969955444336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Preliminary multi-task fine-tuning phase.", "metrics": {"bleu_score": 8.745825313180626, "chrf_score": 26.006087383572364, "xcomet_score": 0.959627628326416, "xcomet_qe_score": 0.9857043623924255, "metricx_score": 6.842423915863037, "metricx_qe_score": 4.973022937774658, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "When you fine-tune the language model over n minus one datasets.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 19.912624171563547, "xcomet_score": 0.9081132411956787, "xcomet_qe_score": 1.0, "metricx_score": 22.04721450805664, "metricx_qe_score": 22.625808715820312, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Feinabstimmung durch, bei der wir das Ziel als Feinabstimmung betrachten, wenn wir das Sprachmodell über den nth Zieldatensatz feinabstimmen.", "metrics": {"bleu_score": 35.897462595683535, "chrf_score": 72.99586723220108, "xcomet_score": 0.7954170107841492, "xcomet_qe_score": 0.756137490272522, "metricx_score": 5.96993350982666, "metricx_qe_score": 4.799349784851074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "The state of the art in multitask fine tuning called mt-dnn.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 23.37170450032084, "xcomet_score": 0.8496066331863403, "xcomet_qe_score": 0.8916316032409668, "metricx_score": 9.840484619140625, "metricx_qe_score": 6.615857124328613, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MT-DNN, MT-DNN maintain a heads in the number of tasks in the training set.", "metrics": {"bleu_score": 2.719665272174911, "chrf_score": 18.958647793832252, "xcomet_score": 0.4124077558517456, "xcomet_qe_score": 0.8510459661483765, "metricx_score": 21.79336929321289, "metricx_qe_score": 19.483680725097656, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es vier Aufgaben im Trainingssatz, also mtcnn und vier Köpfe, wie Sie auf dem Bild sehen können.", "metrics": {"bleu_score": 54.92875839859339, "chrf_score": 66.28812377653492, "xcomet_score": 0.778984546661377, "xcomet_qe_score": 0.8150836229324341, "metricx_score": 7.750927925109863, "metricx_qe_score": 8.470355987548828, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es nimmt eine zufällige Charge aus dem Trainingssatz ab.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 45.787907675154244, "xcomet_score": 0.8967807292938232, "xcomet_qe_score": 0.8600829839706421, "metricx_score": 3.219938039779663, "metricx_qe_score": 2.533066511154175, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die gelaufene Charge zu einem, zum Beispiel, Singen und Zellenklassifizierungsthemen gehört, wird sie vorwärts und rückwärts durch den ersten Kopf ausgeführt.", "metrics": {"bleu_score": 4.935860893352708, "chrf_score": 39.51272879121724, "xcomet_score": 0.5595791339874268, "xcomet_qe_score": 0.6244701147079468, "metricx_score": 18.293067932128906, "metricx_qe_score": 17.35842514038086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zur Paarweise-Rangfolge gehört, wird die Aufgabe in umgekehrter Reihenfolge durch den letzten Kopf ausgeführt.", "metrics": {"bleu_score": 4.968018039415939, "chrf_score": 32.655130284213186, "xcomet_score": 0.8095207810401917, "xcomet_qe_score": 0.8376586437225342, "metricx_score": 6.198121070861816, "metricx_qe_score": 5.012909889221191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario verhalten sich die Datensätze des Tableau-Systems wie eine Anzahl von Klassen.", "metrics": {"bleu_score": 13.380161378318954, "chrf_score": 53.56401917015177, "xcomet_score": 0.9236700534820557, "xcomet_qe_score": 0.8496218919754028, "metricx_score": 3.0457797050476074, "metricx_qe_score": 3.286390781402588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "So gibt es viele Aufgaben.", "metrics": {"bleu_score": 32.46679154750991, "chrf_score": 63.003459073412216, "xcomet_score": 0.9456896781921387, "xcomet_qe_score": 0.9499039053916931, "metricx_score": 0.485775887966156, "metricx_qe_score": 0.5386202931404114, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Mtdnn maintains the number of classes, heads, output layers.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 15.314353299439063, "xcomet_score": 0.7863740921020508, "xcomet_qe_score": 0.9264624118804932, "metricx_score": 13.776840209960938, "metricx_qe_score": 13.584919929504395, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss mtcnn neue Kopfzeilen für einen neuen Datensatz mit einer neuen Aufgabe initialisieren.", "metrics": {"bleu_score": 68.65065103648593, "chrf_score": 79.02373409219294, "xcomet_score": 0.9080690145492554, "xcomet_qe_score": 0.8362652063369751, "metricx_score": 4.153040885925293, "metricx_qe_score": 5.134388446807861, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, genannt Task Reformation Fine Tuning, ist, dass wir in unserem Ansatz Task Reformation Fine Tuning verwenden. Anstatt mehrere Köpfe zu erhalten, reformulieren wir jeden Datensatz in ein Satzproklassifikationsproblem, das zwei Klassenaufgaben ist.", "metrics": {"bleu_score": 12.231415292654702, "chrf_score": 55.68135653818953, "xcomet_score": 0.48725563287734985, "xcomet_qe_score": 0.546525776386261, "metricx_score": 12.889629364013672, "metricx_qe_score": 12.64212703704834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Also schauen wir uns ein Beispiel an.", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 92.85427677964651, "xcomet_score": 0.989126443862915, "xcomet_qe_score": 0.9945032596588135, "metricx_score": 0.142201229929924, "metricx_qe_score": 0.11095048487186432, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Datensatz, der aus Entitäten, Merkmalen, Text und Klassen besteht.", "metrics": {"bleu_score": 64.52121005104219, "chrf_score": 73.91125005285495, "xcomet_score": 0.9887470006942749, "xcomet_qe_score": 0.9876417517662048, "metricx_score": 0.8849254846572876, "metricx_qe_score": 0.6319785714149475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe neu, indem wir den Text nicht mehr in niedrig und hoch klassifizieren, sondern den Text, die Zusammenfassung und die Klasse in wahr oder falsch einordnen.", "metrics": {"bleu_score": 16.29119279942046, "chrf_score": 49.91417048466088, "xcomet_score": 0.9721009731292725, "xcomet_qe_score": 0.934054970741272, "metricx_score": 0.6220206022262573, "metricx_qe_score": 0.8234525918960571, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In other words, we train the language model to classify an abstract n-class to abstract n-class if the abstract belongs to the class or not.", "metrics": {"bleu_score": 1.2734900295286804, "chrf_score": 25.495400686504166, "xcomet_score": 0.6879549622535706, "xcomet_qe_score": 0.8214492797851562, "metricx_score": 16.226716995239258, "metricx_qe_score": 12.467870712280273, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Also bleibt der Etikettvektor in diesem Fall immer bestehen, der immer aus zwei Klassen besteht.", "metrics": {"bleu_score": 39.84681131627584, "chrf_score": 65.87541913530319, "xcomet_score": 0.9937736988067627, "xcomet_qe_score": 0.9479048848152161, "metricx_score": 1.7144814729690552, "metricx_qe_score": 3.8493049144744873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren fein formulierten Feinabstimmungsschritt.", "metrics": {"bleu_score": 38.16330911371339, "chrf_score": 74.74586503876318, "xcomet_score": 0.9349205493927002, "xcomet_qe_score": 0.8795833587646484, "metricx_score": 3.820383071899414, "metricx_qe_score": 3.235219717025757, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "O let's see the full framework.", "metrics": {"bleu_score": 4.935157841536379, "chrf_score": 9.127971356610995, "xcomet_score": 0.8096197247505188, "xcomet_qe_score": 0.9555210471153259, "metricx_score": 13.261273384094238, "metricx_qe_score": 12.163583755493164, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "A dataset fades in too fast. A", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 10.27557402844213, "xcomet_score": 0.13579872250556946, "xcomet_qe_score": 0.16386646032333374, "metricx_score": 21.49850845336914, "metricx_qe_score": 12.075176239013672, "linguapy_score": [1, "ESTONIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Ausführung der Entität-Linking-Phase.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 43.470621628038515, "xcomet_score": 0.8178151845932007, "xcomet_qe_score": 0.8556041717529297, "metricx_score": 5.198418617248535, "metricx_qe_score": 6.625781059265137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "It extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "metrics": {"bleu_score": 2.3901021968803136, "chrf_score": 26.04762437311016, "xcomet_score": 0.9758628606796265, "xcomet_qe_score": 0.9721469879150391, "metricx_score": 16.97064208984375, "metricx_qe_score": 17.46430206298828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann reformuliert es die Aufgabe in eine Perle, eine Perle-Klassifizierungsaufgabe.", "metrics": {"bleu_score": 34.48444257953326, "chrf_score": 53.68179210378328, "xcomet_score": 0.7692368030548096, "xcomet_qe_score": 0.7866690158843994, "metricx_score": 12.00467586517334, "metricx_qe_score": 12.472228050231934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Apply the language model to the new task and output likelihood for each class.", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 16.791781845100935, "xcomet_score": 0.87586510181427, "xcomet_qe_score": 0.9645982980728149, "metricx_score": 16.26825523376465, "metricx_qe_score": 15.389891624450684, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Note that the language model is already fine-tuned over n minus one dataset using a preliminary multi-task fine-tuning.", "metrics": {"bleu_score": 2.4074859035470344, "chrf_score": 22.79944065499348, "xcomet_score": 0.86332106590271, "xcomet_qe_score": 0.9734222888946533, "metricx_score": 13.990478515625, "metricx_qe_score": 7.758019924163818, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu generierte Funktion in der Anzahl der Klassen.", "metrics": {"bleu_score": 66.99564302243967, "chrf_score": 89.46146251379228, "xcomet_score": 0.9795987010002136, "xcomet_qe_score": 0.9651497006416321, "metricx_score": 1.3330681324005127, "metricx_qe_score": 1.7990981340408325, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unseren Rahmen zu bewerten, verwenden wir einen 17-Klassen-Klassifikationsdatensatz, der in Größe, Merkmale, Balance, Domäne und anfänglicher Leistung variiert.", "metrics": {"bleu_score": 20.77097701007239, "chrf_score": 50.66753462544054, "xcomet_score": 0.8798483610153198, "xcomet_qe_score": 0.781807541847229, "metricx_score": 2.3344106674194336, "metricx_qe_score": 3.7178196907043457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "And as knowledge base we use Wikipedia.", "metrics": {"bleu_score": 11.044795567078939, "chrf_score": 32.276060367426346, "xcomet_score": 0.9890545606613159, "xcomet_qe_score": 1.0, "metricx_score": 19.379966735839844, "metricx_qe_score": 18.606225967407227, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir entwerfen unser Experiment so, dass wir bei der schnellen Ausbildung über 16 Datensätze und der Anwendung auf den 17. Datensatz einen Ausreißer ausschließen.", "metrics": {"bleu_score": 17.770114738246555, "chrf_score": 44.10108267850797, "xcomet_score": 0.7264751195907593, "xcomet_qe_score": 0.6767083406448364, "metricx_score": 3.813775062561035, "metricx_qe_score": 3.925680637359619, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "We also split each data set into a fold and apply a fold cross-validation.", "metrics": {"bleu_score": 2.458476536482737, "chrf_score": 11.491692912740694, "xcomet_score": 0.5425887703895569, "xcomet_qe_score": 0.7690070867538452, "metricx_score": 12.971694946289062, "metricx_qe_score": 9.127598762512207, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann erzeugen wir die neuen Merkmale und bewerten sie mit fünf Bewertungsklassifikatoren.", "metrics": {"bleu_score": 40.89601472043678, "chrf_score": 60.75521470224168, "xcomet_score": 0.9316037893295288, "xcomet_qe_score": 0.9837335348129272, "metricx_score": 1.103100061416626, "metricx_qe_score": 1.096177577972412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "We use in our experiment based bird based architecture.", "metrics": {"bleu_score": 4.990049701936832, "chrf_score": 30.207401876235117, "xcomet_score": 0.5323721766471863, "xcomet_qe_score": 0.781181275844574, "metricx_score": 19.38427734375, "metricx_qe_score": 15.360763549804688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse für unser Experiment.", "metrics": {"bleu_score": 36.55552228545123, "chrf_score": 80.45081663502715, "xcomet_score": 0.9799407720565796, "xcomet_qe_score": 0.9850043058395386, "metricx_score": 0.20770743489265442, "metricx_qe_score": 0.07273373007774353, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "You can see that we compare our framework to target dataset fine-tuning, target task fine-tuning, and a mtcnn preliminary fine-tuning.", "metrics": {"bleu_score": 1.986646657111829, "chrf_score": 14.011893946779578, "xcomet_score": 0.8148067593574524, "xcomet_qe_score": 0.8305953741073608, "metricx_score": 20.359331130981445, "metricx_qe_score": 20.037372589111328, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere umformulierte Feinabstimmung erreichte das beste Ergebnis, die beste Leistung.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 82.56085409354655, "xcomet_score": 0.9698505401611328, "xcomet_qe_score": 0.95751953125, "metricx_score": 0.33957478404045105, "metricx_qe_score": 0.9442270398139954, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "While mtdnn it achieved two percent improvement over the the target dataset fine-tuning.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 14.704863433701401, "xcomet_score": 0.7820456027984619, "xcomet_qe_score": 0.8724666833877563, "metricx_score": 20.94447898864746, "metricx_qe_score": 19.98021125793457, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "\"Our poach achieved six percent improvement.\"", "metrics": {"bleu_score": 3.4162113597999784, "chrf_score": 11.319510413734095, "xcomet_score": 0.49820539355278015, "xcomet_qe_score": 0.8068856000900269, "metricx_score": 24.630664825439453, "metricx_qe_score": 22.496490478515625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns den kleinen Datensatz ansehen, können wir sehen, dass die Leistung von mtdnn abnimmt und die Verbesserung der vorläufigen Multi-Task-Fine-Tuning-Phase um 1,5% abnimmt.", "metrics": {"bleu_score": 46.696578632524336, "chrf_score": 66.57441336854116, "xcomet_score": 0.9002468585968018, "xcomet_qe_score": 0.888814389705658, "metricx_score": 3.58738374710083, "metricx_qe_score": 3.7563371658325195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "But our performance increased to eleven percent compared to the target task fine-tuning alone.", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 15.50155788661383, "xcomet_score": 0.8971658945083618, "xcomet_qe_score": 0.9239453673362732, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "For summing, fast enables few-shot enrichment from thirty-five samples in our experiment.", "metrics": {"bleu_score": 3.377156414337854, "chrf_score": 21.766132376609523, "xcomet_score": 0.7548823356628418, "xcomet_qe_score": 0.7384828329086304, "metricx_score": 19.499618530273438, "metricx_qe_score": 19.125343322753906, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben, Datensätze.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 90.0929663869274, "xcomet_score": 0.9819139242172241, "xcomet_qe_score": 0.9792402982711792, "metricx_score": 0.6101759076118469, "metricx_qe_score": 1.068135142326355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells.", "metrics": {"bleu_score": 27.054113452696992, "chrf_score": 54.42421912540176, "xcomet_score": 0.798446536064148, "xcomet_qe_score": 0.8068912029266357, "metricx_score": 4.322042465209961, "metricx_qe_score": 5.432572841644287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "But it adds a reformulation phase.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 23.387629644614876, "xcomet_score": 0.9778146743774414, "xcomet_qe_score": 0.9968031644821167, "metricx_score": 15.858656883239746, "metricx_qe_score": 17.69023323059082, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ein Augmented Trainset, das ein Zielwert mit semantischer Bedeutung benötigt, damit wir es in das Sprachmodell einfügen und im Problem der Satzpaarklassifikation verwenden können.", "metrics": {"bleu_score": 19.140006170221074, "chrf_score": 64.31139675210223, "xcomet_score": 0.8712726831436157, "xcomet_qe_score": 0.8914657831192017, "metricx_score": 4.794859886169434, "metricx_qe_score": 4.992905616760254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 10.1276978086624, "xcomet_score": 0.9957995414733887, "xcomet_qe_score": 1.0, "metricx_score": 1.2424523830413818, "metricx_qe_score": 0.48872482776641846, "linguapy_score": [1, "ENGLISH"]}}
