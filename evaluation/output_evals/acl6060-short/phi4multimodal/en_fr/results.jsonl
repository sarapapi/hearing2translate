{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "\"Hi everyone, today I'm going to present our research work, learning to reason deductively, math problem solving as complex region extraction.\"", "metrics": {"bleu_score": 1.358105109291178, "chrf_score": 23.472886400838988, "xcomet_score": 0.7155941724777222, "xcomet_qe_score": 0.8320356011390686, "metricx_score": 15.631207466125488, "metricx_qe_score": 13.153488159179688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "I'm Alan from Bytedance AI Lab and this is a joint work with Chery from the University of Texas at Austin and Wei Lu from Suntech.", "metrics": {"bleu_score": 3.009594541052197, "chrf_score": 22.44764349772931, "xcomet_score": 0.5321205854415894, "xcomet_qe_score": 0.6797196865081787, "metricx_score": 13.453242301940918, "metricx_qe_score": 8.862770080566406, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "First, I'd like to talk about our motivation for reasoning.", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 25.861534925253228, "xcomet_score": 0.9787003993988037, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Here we show examples where multi-step reasoning is helpful.", "metrics": {"bleu_score": 2.302876686963141, "chrf_score": 14.967840568344368, "xcomet_score": 0.9753302335739136, "xcomet_qe_score": 1.0, "metricx_score": 23.668546676635742, "metricx_qe_score": 20.903114318847656, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Cette figure est tirée du papier de P dev où ils ont effectué des performances prometteuses pour résoudre le problème de méthode dans un scénario d'apprentissage à court terme.", "metrics": {"bleu_score": 11.857020645058961, "chrf_score": 46.52028117030621, "xcomet_score": 0.20715194940567017, "xcomet_qe_score": 0.3346711993217468, "metricx_score": 12.305660247802734, "metricx_qe_score": 11.54355525970459, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Sur le côté netpen, nous pouvons voir que si nous donnons des exemples avec juste des questions et des réponses, nous pourrions ne pas être en mesure d'obtenir les bonnes réponses.", "metrics": {"bleu_score": 74.23468479928046, "chrf_score": 81.55876388063312, "xcomet_score": 0.7442008256912231, "xcomet_qe_score": 0.7177709341049194, "metricx_score": 7.102121829986572, "metricx_qe_score": 6.434558391571045, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "metrics": {"bleu_score": 1.8203126785831367, "chrf_score": 29.13236970814917, "xcomet_score": 0.9500941038131714, "xcomet_qe_score": 0.9704749584197998, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Il est donc bon d'avoir une raison interprétable et multistapée comme sortie.", "metrics": {"bleu_score": 9.30514025247622, "chrf_score": 44.68992264892441, "xcomet_score": 0.6884170770645142, "xcomet_qe_score": 0.6914534568786621, "metricx_score": 9.216307640075684, "metricx_qe_score": 7.759610176086426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons aussi que le problème de Méthode est une application simple pour évaluer de telles capacités de raisonnement.", "metrics": {"bleu_score": 41.69080559564967, "chrf_score": 65.15117694697294, "xcomet_score": 0.6600847244262695, "xcomet_qe_score": 0.7227097749710083, "metricx_score": 8.828914642333984, "metricx_qe_score": 7.860652446746826, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici dans notre configuration de problème, étant donné les questions, nous devons résoudre cette question et obtenir les réponses numériques.", "metrics": {"bleu_score": 70.00855464920414, "chrf_score": 85.49360428565579, "xcomet_score": 0.9464696645736694, "xcomet_qe_score": 0.9229300022125244, "metricx_score": 1.555747151374817, "metricx_qe_score": 2.2053043842315674, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Dans nos ensembles de données, nous avons également la formule mathématique qui conduit à cette réponse particulière.", "metrics": {"bleu_score": 45.80519369844352, "chrf_score": 72.52916762927374, "xcomet_score": 0.9829877614974976, "xcomet_qe_score": 0.979748010635376, "metricx_score": 2.8213162422180176, "metricx_qe_score": 3.721214532852173, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Certaines hypothèses s'appliquent également, comme dans le travail précédent.", "metrics": {"bleu_score": 17.423472443716534, "chrf_score": 68.97632908042397, "xcomet_score": 0.9968241453170776, "xcomet_qe_score": 1.0, "metricx_score": 1.9701119661331177, "metricx_qe_score": 2.582414150238037, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "We assume the precision of quantities are known.", "metrics": {"bleu_score": 4.266331692956901, "chrf_score": 25.334680494582727, "xcomet_score": 0.9427655935287476, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 23.222091674804688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous considérons seulement des opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentielle.", "metrics": {"bleu_score": 77.39153128737975, "chrf_score": 90.73167869597584, "xcomet_score": 0.983163595199585, "xcomet_qe_score": 0.936048150062561, "metricx_score": 0.6588658094406128, "metricx_qe_score": 0.9013146162033081, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "metrics": {"bleu_score": 2.916495972453022, "chrf_score": 24.46335600817278, "xcomet_score": 0.9898557662963867, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le travail précédent sur la résolution de problèmes de méthode peut en fait être classé en modèle séquence à séquence et modèle séquence à arbre.", "metrics": {"bleu_score": 43.93434673594555, "chrf_score": 66.89468151130055, "xcomet_score": 0.5433379411697388, "xcomet_qe_score": 0.5064948797225952, "metricx_score": 7.098012924194336, "metricx_qe_score": 7.43640661239624, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le modèle de séquence à séquence traditionnel convertit l'expression en une séquence spécifique pour la génération.", "metrics": {"bleu_score": 62.72517339014035, "chrf_score": 90.33059746993679, "xcomet_score": 0.7777652740478516, "xcomet_qe_score": 0.7732614278793335, "metricx_score": 1.8375961780548096, "metricx_qe_score": 2.4929184913635254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est assez facile à implémenter, et il peut s'appliquer à de nombreux problèmes compliqués différents.", "metrics": {"bleu_score": 39.81163194689048, "chrf_score": 63.4635920226844, "xcomet_score": 0.8229573965072632, "xcomet_qe_score": 0.7718838453292847, "metricx_score": 1.9566823244094849, "metricx_qe_score": 2.380153179168701, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "But the drawbacks of the performance is actually generally not better than the structured model, and it is lack of the interpretability for prediction.", "metrics": {"bleu_score": 1.7179060012299232, "chrf_score": 27.973666895417388, "xcomet_score": 0.7609373331069946, "xcomet_qe_score": 0.8934679627418518, "metricx_score": 21.35068702697754, "metricx_qe_score": 17.564199447631836, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en fait, cette direction est encore assez populaire en raison du modèle transformateur.", "metrics": {"bleu_score": 47.302621872495855, "chrf_score": 65.78389346277422, "xcomet_score": 0.8726860880851746, "xcomet_qe_score": 0.8670468330383301, "metricx_score": 4.738114356994629, "metricx_qe_score": 3.398761510848999, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Dans les modèles basés sur les arbres, nous structurons effectivement ces expressions sous forme d'arbre et suivons un parcours préordonné dans la génération d'arbres.", "metrics": {"bleu_score": 29.78258772380938, "chrf_score": 67.17868778349587, "xcomet_score": 0.9423526525497437, "xcomet_qe_score": 0.9619656801223755, "metricx_score": 2.583333730697632, "metricx_qe_score": 3.33298921585083, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, nous continuons à générer les opérateurs jusqu'à ce que nous atteignions les feuilles, qui sont les quantités.", "metrics": {"bleu_score": 79.4483720649497, "chrf_score": 87.8220597667097, "xcomet_score": 0.8363213539123535, "xcomet_qe_score": 0.713945209980011, "metricx_score": 2.903754949569702, "metricx_qe_score": 3.7788174152374268, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, la bonne chose est qu'il nous donne en fait cette structure d'arbre binaire, et c'est en fait assez contournant parce que nous générons d'abord l'opérateur, puis, à la fin, nous générons les quantités.", "metrics": {"bleu_score": 48.96335675008738, "chrf_score": 71.8126944392941, "xcomet_score": 0.6849722862243652, "xcomet_qe_score": 0.7348146438598633, "metricx_score": 7.270380020141602, "metricx_qe_score": 7.767387390136719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est qu'il contient également des calculs répétitifs.", "metrics": {"bleu_score": 67.61304462994481, "chrf_score": 88.74044774297988, "xcomet_score": 0.9269711375236511, "xcomet_qe_score": 0.9851686954498291, "metricx_score": 1.7187960147857666, "metricx_qe_score": 1.1914159059524536, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, si nous regardons cette expression, 8 fois 3 plus 3, elle est en fait générée deux fois. Mais en fait, nous devrions réutiliser les résultats.", "metrics": {"bleu_score": 43.77121098094503, "chrf_score": 69.08507527170008, "xcomet_score": 0.9963977336883545, "xcomet_qe_score": 1.0, "metricx_score": 1.1119937896728516, "metricx_qe_score": 1.0044833421707153, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre approche proposée, nous voulons résoudre ces problèmes de manière étape par étape et interprétable.", "metrics": {"bleu_score": 59.046627330816754, "chrf_score": 86.23426574749374, "xcomet_score": 0.9997949600219727, "xcomet_qe_score": 1.0, "metricx_score": 1.2229535579681396, "metricx_qe_score": 1.0598959922790527, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, par exemple, ici, dans la deuxième étape, nous pouvons obtenir ces diviseurs, qui est vingt-sept.", "metrics": {"bleu_score": 51.23350305765596, "chrf_score": 85.56163315420321, "xcomet_score": 0.9388771057128906, "xcomet_qe_score": 0.9295851588249207, "metricx_score": 3.308849334716797, "metricx_qe_score": 5.271213054656982, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "We can also refer back to the original questions to find the relevant contents.", "metrics": {"bleu_score": 3.1251907639724417, "chrf_score": 28.424965269410546, "xcomet_score": 0.9946726560592651, "xcomet_qe_score": 0.9928059577941895, "metricx_score": 23.536849975585938, "metricx_qe_score": 20.826019287109375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les diviseurs.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9926035404205322, "xcomet_qe_score": 0.9813810586929321, "metricx_score": 2.1472244262695312, "metricx_qe_score": 2.927687406539917, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Alors, et puis, à ce troisième pas, nous obtenons en réalité le quotient.", "metrics": {"bleu_score": 16.753520397573755, "chrf_score": 65.31336737615308, "xcomet_score": 0.7902933359146118, "xcomet_qe_score": 0.8539385199546814, "metricx_score": 5.217314720153809, "metricx_qe_score": 4.637232303619385, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, et après ces trois étapes, nous pouvons en fait utiliser les résultats du deuxième étape et obtenir les résultats du quatrième étape, et enfin, nous pouvons obtenir les dividendes.", "metrics": {"bleu_score": 50.80233070431227, "chrf_score": 79.17623993696729, "xcomet_score": 0.9103170037269592, "xcomet_qe_score": 0.9347134232521057, "metricx_score": 5.656620979309082, "metricx_qe_score": 5.859289169311523, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, nous générons effectivement l'expression entière directement, plutôt que de générer un seul opérateur ou une seule quantité.", "metrics": {"bleu_score": 52.348985533904326, "chrf_score": 77.09607105955095, "xcomet_score": 0.9994806051254272, "xcomet_qe_score": 1.0, "metricx_score": 1.0592414140701294, "metricx_qe_score": 1.1882860660552979, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "So this makes the process more accurate.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 26.210567050479618, "xcomet_score": 0.7156963348388672, "xcomet_qe_score": 1.0, "metricx_score": 24.205717086791992, "metricx_qe_score": 21.42890167236328, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre système d'inférence déductive, nous commençons par un ensemble de quantités présentées dans les questions, ainsi que par quelques constantes comme notre initialisation.", "metrics": {"bleu_score": 24.9607719274767, "chrf_score": 61.9444576867036, "xcomet_score": 0.8698471784591675, "xcomet_qe_score": 0.8766984939575195, "metricx_score": 3.9729690551757812, "metricx_qe_score": 4.503876686096191, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, l'expression est représentée par eiijop.", "metrics": {"bleu_score": 42.88819424803536, "chrf_score": 94.99873664296585, "xcomet_score": 0.9685899019241333, "xcomet_qe_score": 0.9781104922294617, "metricx_score": 1.7999097108840942, "metricx_qe_score": 2.88234543800354, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "Where we perform operator from qi to qj and such expression is actually directed.", "metrics": {"bleu_score": 2.094878016776162, "chrf_score": 23.598472912580643, "xcomet_score": 0.8266582489013672, "xcomet_qe_score": 0.9485265612602234, "metricx_score": 23.997039794921875, "metricx_qe_score": 19.513681411743164, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc aussi la soustraction avec des mots ici pour représenter la direction opposée.", "metrics": {"bleu_score": 51.98157258729877, "chrf_score": 76.53413142811945, "xcomet_score": 0.9873389601707458, "xcomet_qe_score": 0.985069990158081, "metricx_score": 1.139958143234253, "metricx_qe_score": 1.5617053508758545, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "This is quite similar to relation extraction.", "metrics": {"bleu_score": 5.11459870708889, "chrf_score": 44.39857072568076, "xcomet_score": 0.9767123460769653, "xcomet_qe_score": 1.0, "metricx_score": 24.41703987121582, "metricx_qe_score": 19.445497512817383, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Dans un système déductif formel, à l'étape temporelle T, nous appliquons l'opérateur entre le couple qi et qj, et puis nous obtenons cette nouvelle expression.", "metrics": {"bleu_score": 21.91999473914722, "chrf_score": 62.31016151736427, "xcomet_score": 0.9360259771347046, "xcomet_qe_score": 0.9639726877212524, "metricx_score": 2.239392042160034, "metricx_qe_score": 2.258044719696045, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "We add it to the next state to become a new quantity.", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 17.12263746994907, "xcomet_score": 0.9483978748321533, "xcomet_qe_score": 0.9828684329986572, "metricx_score": 25.0, "metricx_qe_score": 22.78107452392578, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Ces diapositive visualisent donc en réalité l'évolution de l'état, où nous ajoutons continuellement des expressions à l'état actuel.", "metrics": {"bleu_score": 32.37353837818466, "chrf_score": 71.36944537393724, "xcomet_score": 0.874664306640625, "xcomet_qe_score": 0.7714179754257202, "metricx_score": 3.40964674949646, "metricx_qe_score": 4.120128154754639, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Dans nos implémentations de modèle, nous utilisons d'abord un modèle de langage préentraîné, qui peut être des oiseaux ou des robots, puis nous codons une phrase, puis nous obtenons ces représentations quantitatives.", "metrics": {"bleu_score": 37.599623542143966, "chrf_score": 66.99464533074787, "xcomet_score": 0.5483421087265015, "xcomet_qe_score": 0.6059036254882812, "metricx_score": 9.271256446838379, "metricx_qe_score": 9.054638862609863, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, une fois que nous avons les représentations quantitatives, nous pouvons commencer à faire des inférences.", "metrics": {"bleu_score": 54.017258985951415, "chrf_score": 77.62876558406028, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3627663850784302, "metricx_qe_score": 1.5809757709503174, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "\"Here we show an example of Q1 to obtain the replication for Q1 divided by Q2 and then times Q3.\"", "metrics": {"bleu_score": 1.3249308450474928, "chrf_score": 18.659369508899417, "xcomet_score": 0.7217777967453003, "xcomet_qe_score": 0.8097361922264099, "metricx_score": 20.22104835510254, "metricx_qe_score": 11.93234634399414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous obtenons la représentation paire, qui est essentiellement la concaténation entre Q1 et Q2. Ensuite, nous appliquons une réseau de transfert de poids, qui est paramétrisé par l'opérateur.", "metrics": {"bleu_score": 27.191046829978607, "chrf_score": 66.7137038391432, "xcomet_score": 0.653461754322052, "xcomet_qe_score": 0.6402875781059265, "metricx_score": 8.376546859741211, "metricx_qe_score": 7.50925350189209, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, nous obtenons la représentation de l'expression Q1 divisé par Q2.", "metrics": {"bleu_score": 47.063857795691845, "chrf_score": 83.57068076298184, "xcomet_score": 0.9838391542434692, "xcomet_qe_score": 0.9770201444625854, "metricx_score": 2.313589572906494, "metricx_qe_score": 3.2393617630004883, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "But in fact, in practice, in the inference stage, we might be able to get the incorrect expression as well.", "metrics": {"bleu_score": 2.352622489487909, "chrf_score": 28.399339199024954, "xcomet_score": 0.9802765846252441, "xcomet_qe_score": 0.985496997833252, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, toutes les expressions possibles sont égales à trois fois le nombre d'opérateurs.", "metrics": {"bleu_score": 39.56716729452429, "chrf_score": 75.60323634018809, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7303863763809204, "metricx_qe_score": 1.3927795886993408, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "La bonne chose ici est que nous pouvons facilement ajouter des contraintes pour contrôler cette recherche.", "metrics": {"bleu_score": 38.052336883085, "chrf_score": 72.70620733730759, "xcomet_score": 0.8445253372192383, "xcomet_qe_score": 0.8759803771972656, "metricx_score": 1.951869249343872, "metricx_qe_score": 2.6796483993530273, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement supprimer cette expression dans notre espace de recherche.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9995723962783813, "xcomet_qe_score": 0.9972200393676758, "metricx_score": 0.43808066844940186, "metricx_qe_score": 0.45326462388038635, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Dans le deuxième pas, nous faisons la même chose, mais la seule différence est que nous, la seule différence est une quantité de plus.", "metrics": {"bleu_score": 62.06800198581103, "chrf_score": 76.36457274388452, "xcomet_score": 0.5110268592834473, "xcomet_qe_score": 0.497189998626709, "metricx_score": 8.568794250488281, "metricx_qe_score": 9.440826416015625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "This quantity comes from the previous calculated expression.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 35.51456571221662, "xcomet_score": 0.983655571937561, "xcomet_qe_score": 1.0, "metricx_score": 11.825905799865723, "metricx_qe_score": 5.327550411224365, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Alors enfin, nous pouvons obtenir cette expression finale Q.", "metrics": {"bleu_score": 34.197835084663396, "chrf_score": 60.9233035492958, "xcomet_score": 0.6020877361297607, "xcomet_qe_score": 0.7626731395721436, "metricx_score": 10.838628768920898, "metricx_qe_score": 9.790804862976074, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "\"times q4 and we can also see the number of all the possible expression is different from the previous step.\"", "metrics": {"bleu_score": 1.6466642419110007, "chrf_score": 28.242310865149957, "xcomet_score": 0.5481895208358765, "xcomet_qe_score": 0.7067877650260925, "metricx_score": 22.145549774169922, "metricx_qe_score": 18.544145584106445, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "De telles différences rendent difficile l'application de la recherche de faisceau, car la distribution de probabilité entre ces deux étapes est déséquilibrée.", "metrics": {"bleu_score": 57.84879107039426, "chrf_score": 79.51074597302122, "xcomet_score": 0.890868604183197, "xcomet_qe_score": 0.9556728601455688, "metricx_score": 2.7105159759521484, "metricx_qe_score": 2.762756586074829, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "Le processus d'entraînement est similaire à l'entraînement d'un modèle séquence-à-réponse, où nous optimisons la perte à chaque étape de temps.", "metrics": {"bleu_score": 31.550525638206437, "chrf_score": 56.34801023384293, "xcomet_score": 0.6273179054260254, "xcomet_qe_score": 0.7592915296554565, "metricx_score": 2.788945198059082, "metricx_qe_score": 3.8200604915618896, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également cette tau pour représenter le moment où nous devons terminer ce processus de génération.", "metrics": {"bleu_score": 61.02624546684575, "chrf_score": 84.94816000439438, "xcomet_score": 0.9766644239425659, "xcomet_qe_score": 1.0, "metricx_score": 3.087925672531128, "metricx_qe_score": 4.177020072937012, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent de séquence en séquence, parce que l'espace est différent à chaque étape, tandis qu'en modèle séquence en séquence traditionnel, c'est le nombre de vocabulaire.", "metrics": {"bleu_score": 50.12760980737956, "chrf_score": 75.4761609125265, "xcomet_score": 0.559708833694458, "xcomet_qe_score": 0.6516841650009155, "metricx_score": 7.182153701782227, "metricx_qe_score": 7.821565628051758, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela nous permet également d'imposer certaines contraintes à partir de connaissances préalables.", "metrics": {"bleu_score": 85.5526185871245, "chrf_score": 87.87814989386374, "xcomet_score": 0.9677395820617676, "xcomet_qe_score": 0.9585351943969727, "metricx_score": 1.0327026844024658, "metricx_qe_score": 1.4040405750274658, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous conduisons des expériences sur les ensembles de données de problèmes mathématiques couramment utilisés, MATHWPS, MAT23K, MATQA et SWEM.", "metrics": {"bleu_score": 17.551752646320274, "chrf_score": 63.953095771108806, "xcomet_score": 0.7348531484603882, "xcomet_qe_score": 0.756393551826477, "metricx_score": 7.192271709442139, "metricx_qe_score": 6.909204483032227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons brièvement les résultats par rapport aux meilleures approches précédentes.", "metrics": {"bleu_score": 58.282339541526554, "chrf_score": 76.15969047688054, "xcomet_score": 0.9925990104675293, "xcomet_qe_score": 0.9682251214981079, "metricx_score": 0.8979421257972717, "metricx_qe_score": 1.1303930282592773, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Notre variante de meilleure performance est le raisonneur déductif de Roberta.", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 44.4467210969005, "xcomet_score": 0.9392996430397034, "xcomet_qe_score": 0.9430072903633118, "metricx_score": 2.602649211883545, "metricx_qe_score": 1.92576265335083, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "En effet, nous ne utilisons pas la recherche de faisceau en contraste avec les approches obvies utilisant la recherche de faisceau.", "metrics": {"bleu_score": 6.312748574267699, "chrf_score": 43.36221290503905, "xcomet_score": 0.8320660591125488, "xcomet_qe_score": 0.9082599878311157, "metricx_score": 4.833658218383789, "metricx_qe_score": 4.088180065155029, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, donc les meilleurs approches sont souvent un modèle basé sur un arbre.", "metrics": {"bleu_score": 25.884296648947053, "chrf_score": 61.31811525823137, "xcomet_score": 0.9852029085159302, "xcomet_qe_score": 1.0, "metricx_score": 2.4927051067352295, "metricx_qe_score": 3.439255952835083, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, au total, notre raisonneur est capable de surpasser de manière significative ce modèle basé sur des arbres.", "metrics": {"bleu_score": 26.60812517643414, "chrf_score": 56.50265421806141, "xcomet_score": 0.9588851928710938, "xcomet_qe_score": 0.9249261617660522, "metricx_score": 4.667392253875732, "metricx_qe_score": 6.910377502441406, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "But we can see the absolute number on MathQ or SWEM are not really high.", "metrics": {"bleu_score": 2.158229074594286, "chrf_score": 17.12555760145168, "xcomet_score": 0.6756778955459595, "xcomet_qe_score": 0.7899903059005737, "metricx_score": 23.222814559936523, "metricx_qe_score": 20.47627830505371, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "So refer to investigate the results on.", "metrics": {"bleu_score": 3.7954847898457067, "chrf_score": 12.124425832772344, "xcomet_score": 0.20974063873291016, "xcomet_qe_score": 0.6299530267715454, "metricx_score": 21.381608963012695, "metricx_qe_score": 17.900678634643555, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "Wamp and this dataset is challenging because the author tried to manually add something to confuse the NLP model, such as adding irrelevant information and extra quantities.", "metrics": {"bleu_score": 1.046231256134215, "chrf_score": 21.875530325379223, "xcomet_score": 0.6822117567062378, "xcomet_qe_score": 0.8169789910316467, "metricx_score": 21.260528564453125, "metricx_qe_score": 16.064830780029297, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre prédiction, nous trouvons que certains des valeurs intermédiaires sont en réalité négatifs.", "metrics": {"bleu_score": 42.29247984636107, "chrf_score": 81.87394328631918, "xcomet_score": 0.7944735288619995, "xcomet_qe_score": 0.8886990547180176, "metricx_score": 4.899803161621094, "metricx_qe_score": 4.228133201599121, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans cette question, nous demandons combien d'appels a-t-il pris?", "metrics": {"bleu_score": 22.098307323557727, "chrf_score": 61.452632163559315, "xcomet_score": 0.41536030173301697, "xcomet_qe_score": 0.5520496368408203, "metricx_score": 18.54004669189453, "metricx_qe_score": 18.512744903564453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "But we have some extra information like seventeen fewer pitches and Steven has eight pitches, which is totally irrelevant.", "metrics": {"bleu_score": 1.5570059225386168, "chrf_score": 23.899087108796785, "xcomet_score": 0.6545734405517578, "xcomet_qe_score": 0.7926841974258423, "metricx_score": 24.29401206970215, "metricx_qe_score": 12.71251392364502, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait des prédictions comme celle-ci, qui produit des valeurs négatives.", "metrics": {"bleu_score": 49.35578819979934, "chrf_score": 71.70129168638239, "xcomet_score": 0.9869339466094971, "xcomet_qe_score": 0.9980106353759766, "metricx_score": 1.8813458681106567, "metricx_qe_score": 1.46550452709198, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous observons ces deux expressions.", "metrics": {"bleu_score": 11.835764736093042, "chrf_score": 35.591235893124356, "xcomet_score": 0.2292582094669342, "xcomet_qe_score": 0.3586346507072449, "metricx_score": 16.36252784729004, "metricx_qe_score": 20.465259552001953, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "So we can actually limit this search space by removing like those results are negative so that we can make the make the answer correct.", "metrics": {"bleu_score": 1.4445809981770859, "chrf_score": 23.890769081078105, "xcomet_score": 0.47537297010421753, "xcomet_qe_score": 0.794758677482605, "metricx_score": 16.86870002746582, "metricx_qe_score": 16.30267906188965, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc découvert que de telles contraintes améliorent en fait beaucoup certains modèles.", "metrics": {"bleu_score": 12.500763055889768, "chrf_score": 56.351115995542735, "xcomet_score": 0.9911315441131592, "xcomet_qe_score": 0.9819685220718384, "metricx_score": 1.2690563201904297, "metricx_qe_score": 1.791956901550293, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "For example, for birds, we improved seven points. And then for the robot-based model, we actually improved two points.", "metrics": {"bleu_score": 2.9672574248035595, "chrf_score": 18.33696812328582, "xcomet_score": 0.4282170236110687, "xcomet_qe_score": 0.7057434320449829, "metricx_score": 16.677682876586914, "metricx_qe_score": 11.086996078491211, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Un meilleur modèle linguistique a une meilleure capacité d'analyse linguistique, donc le nombre ici est plus élevé pour Roberta et plus bas pour Bert.", "metrics": {"bleu_score": 28.847475931194513, "chrf_score": 44.08314146282985, "xcomet_score": 0.7625290155410767, "xcomet_qe_score": 0.9849028587341309, "metricx_score": 14.068068504333496, "metricx_qe_score": 4.143640518188477, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "And we also try to analyze the difficulty behind this.", "metrics": {"bleu_score": 3.42209762272661, "chrf_score": 20.944373550118566, "xcomet_score": 0.7602856159210205, "xcomet_qe_score": 0.9011576175689697, "metricx_score": 20.635751724243164, "metricx_qe_score": 16.0127010345459, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "We assume the number of unused quantity can be regarded as irrelevant information here.", "metrics": {"bleu_score": 2.5586897876995107, "chrf_score": 25.183682958449342, "xcomet_score": 0.9760391116142273, "xcomet_qe_score": 0.9884222149848938, "metricx_score": 24.015609741210938, "metricx_qe_score": 23.43635368347168, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, nous pouvons voir que nous avons le pourcentage de échantillons avec des quantités inutilisées. Et le jeu de données swam a la plus grande proportion.", "metrics": {"bleu_score": 43.022709313926356, "chrf_score": 77.53882047211805, "xcomet_score": 0.8493748903274536, "xcomet_qe_score": 0.7723801136016846, "metricx_score": 5.690225124359131, "metricx_qe_score": 6.383602619171143, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons également leur performance globale.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 91.35274158294273, "xcomet_score": 0.9710941314697266, "xcomet_qe_score": 0.981338620185852, "metricx_score": 1.0482797622680664, "metricx_qe_score": 1.4508838653564453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "For those samples without unused quantities, so the overall performance is actually higher than the performance is actually higher than the overall performance.", "metrics": {"bleu_score": 2.1300733682208985, "chrf_score": 33.65044624769594, "xcomet_score": 0.19429528713226318, "xcomet_qe_score": 0.34036046266555786, "metricx_score": 23.796314239501953, "metricx_qe_score": 22.44283103942871, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "But with those samples that with unused quantity is actually way worse than the way worse than.", "metrics": {"bleu_score": 2.031628835361819, "chrf_score": 18.46345969983866, "xcomet_score": 0.17889252305030823, "xcomet_qe_score": 0.5658111572265625, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "Performance for M and WPS, we don't really have too many desk cases, so I just ignore this part.", "metrics": {"bleu_score": 2.2731543567022867, "chrf_score": 23.36946243379929, "xcomet_score": 0.5324284434318542, "xcomet_qe_score": 0.717365026473999, "metricx_score": 14.375432968139648, "metricx_qe_score": 9.82945442199707, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous voulons montrer l'interprétabilité à travers un exemple de question et réponse.", "metrics": {"bleu_score": 44.80304273880272, "chrf_score": 67.08506212245634, "xcomet_score": 0.673058271408081, "xcomet_qe_score": 0.8467982411384583, "metricx_score": 2.934756278991699, "metricx_qe_score": 3.785095691680908, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, notre modèle fait en fait une prédiction erronée au premier pas.", "metrics": {"bleu_score": 18.751144583834648, "chrf_score": 46.51956942026949, "xcomet_score": 0.8937838077545166, "xcomet_qe_score": 0.9345738887786865, "metricx_score": 2.4733798503875732, "metricx_qe_score": 2.558201551437378, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc en fait corréler cette expression avec la phrase ci-dessous.", "metrics": {"bleu_score": 32.46827270101123, "chrf_score": 59.163339167340865, "xcomet_score": 0.9489301443099976, "xcomet_qe_score": 0.9909720420837402, "metricx_score": 3.277600049972534, "metricx_qe_score": 2.657036304473877, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons donc que cette phrase pourrait induire le modèle en erreur, conduisant à une prédiction incorrecte.", "metrics": {"bleu_score": 60.98820960308448, "chrf_score": 77.6503648329927, "xcomet_score": 0.9950029850006104, "xcomet_qe_score": 0.978378176689148, "metricx_score": 0.8621333837509155, "metricx_qe_score": 0.48236292600631714, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, planter un autre trente-cinq fait en sorte que le modèle pense qu'il devrait être un opérateur d'addition.", "metrics": {"bleu_score": 33.071084018361375, "chrf_score": 71.35443200744798, "xcomet_score": 0.6560627818107605, "xcomet_qe_score": 0.5096739530563354, "metricx_score": 5.759624481201172, "metricx_qe_score": 6.173722743988037, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc essayé de réviser la phrase pour qu'elle ressemble à ceci : \"Le nombre d'arbres de pêches est de 55 de moins que le nombre d'arbres de pommes.\"", "metrics": {"bleu_score": 14.380553624999493, "chrf_score": 39.44094436284251, "xcomet_score": 0.3921271860599518, "xcomet_qe_score": 0.6591355800628662, "metricx_score": 4.778260231018066, "metricx_qe_score": 3.9823689460754395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Nous le faisons pour transmettre une sémantique plus précise, de sorte que le modèle soit capable de faire une prédiction correcte.", "metrics": {"bleu_score": 40.90527244931956, "chrf_score": 70.98979453831532, "xcomet_score": 0.8839017152786255, "xcomet_qe_score": 0.8520383834838867, "metricx_score": 2.2228100299835205, "metricx_qe_score": 1.924586296081543, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Cette étude montre comment les prédictions interprétables nous aident à comprendre le comportement du modèle.", "metrics": {"bleu_score": 65.72677895577044, "chrf_score": 88.68604831326833, "xcomet_score": 0.9971239566802979, "xcomet_qe_score": 1.0, "metricx_score": 1.1754331588745117, "metricx_qe_score": 0.9381936192512512, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure notre travail, d'abord, notre modèle est en fait assez efficace.", "metrics": {"bleu_score": 49.35578819979934, "chrf_score": 74.98083029664036, "xcomet_score": 0.975652813911438, "xcomet_qe_score": 0.9849328994750977, "metricx_score": 2.306478500366211, "metricx_qe_score": 1.8707637786865234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "And we are able to provide interpretable solving procedure.", "metrics": {"bleu_score": 3.1085583786586426, "chrf_score": 24.19536413301212, "xcomet_score": 0.984652042388916, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 22.626855850219727, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "metrics": {"bleu_score": 3.8339615206201816, "chrf_score": 27.628621876650293, "xcomet_score": 0.963447630405426, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et la dernière chose est que le mécanisme sous-jacent ne s'applique pas seulement aux tâches de résolution de problèmes de mappage, mais aussi aux tâches qui impliquent une raison multistap.", "metrics": {"bleu_score": 59.781211692452956, "chrf_score": 77.53056768018583, "xcomet_score": 0.5993510484695435, "xcomet_qe_score": 0.5647561550140381, "metricx_score": 9.780253410339355, "metricx_qe_score": 9.676703453063965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "But we also have certain limitations.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 31.223132515673292, "xcomet_score": 0.9905883073806763, "xcomet_qe_score": 1.0, "metricx_score": 7.340494632720947, "metricx_qe_score": 2.835557460784912, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "Si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0386240482330322, "metricx_qe_score": 1.0148998498916626, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose est que, comme mentionné, parce que la distribution de probabilité est déséquilibrée entre les différents temps, il est également assez difficile d'appliquer les recherches sur les faisceaux.", "metrics": {"bleu_score": 55.48520551783481, "chrf_score": 78.18349207459144, "xcomet_score": 0.7132925987243652, "xcomet_qe_score": 0.730172872543335, "metricx_score": 3.985549211502075, "metricx_qe_score": 4.379805088043213, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Alors, c'est la fin de la présentation et les questions sont les bienvenues. Merci.", "metrics": {"bleu_score": 46.00160223062214, "chrf_score": 57.35780583275408, "xcomet_score": 0.9880624413490295, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.3595035076141357, "metricx_qe_score": 0.9911863803863525, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je suis de l'Université de Maastricht.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.34782254695892334, "metricx_qe_score": 0.36702096462249756, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai mon travail conjoint avec Jerry, qui porte sur un nouveau jeu de données pour la récupération d'articles statutaires.", "metrics": {"bleu_score": 25.642947901593647, "chrf_score": 53.449924771974544, "xcomet_score": 0.7633999586105347, "xcomet_qe_score": 0.7244322299957275, "metricx_score": 3.5255672931671143, "metricx_qe_score": 1.473861575126648, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Legal issues are an integral part of many people's lives.", "metrics": {"bleu_score": 3.124719790499494, "chrf_score": 15.69015487096351, "xcomet_score": 0.9880852699279785, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "But the majority of citizens have little to no knowledge about their rights and fundamental legal processes.", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 26.982359528783906, "xcomet_score": 0.9948492050170898, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worse, exploited.", "metrics": {"bleu_score": 1.7822401756265172, "chrf_score": 23.942704232128474, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Our work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "metrics": {"bleu_score": 1.7125508643432577, "chrf_score": 22.29996872146211, "xcomet_score": 0.9167107343673706, "xcomet_qe_score": 0.9888740181922913, "metricx_score": 25.0, "metricx_qe_score": 24.902555465698242, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "Such a system could provide a free, professional legal help service for unskilled humans.", "metrics": {"bleu_score": 2.908317710573757, "chrf_score": 25.316452700852278, "xcomet_score": 0.9078953862190247, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de plonger dans la contribution principale de ce travail, décrivons d'abord le problème de la récupération d'articles statuts.", "metrics": {"bleu_score": 30.91327937802876, "chrf_score": 63.687570108049975, "xcomet_score": 0.6894973516464233, "xcomet_qe_score": 0.6944681406021118, "metricx_score": 8.37646770477295, "metricx_qe_score": 7.344438552856445, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Envisagez une simple question sur une petite affaire, comme, quels sont les risques si je viole la confidentialité professionnelle?", "metrics": {"bleu_score": 32.70374154126593, "chrf_score": 58.69878750236691, "xcomet_score": 0.6811666488647461, "xcomet_qe_score": 0.6785576343536377, "metricx_score": 6.9068284034729, "metricx_qe_score": 6.351863384246826, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est nécessaire pour récupérer tous les articles statutaires pertinents d'un large corpus de législation.", "metrics": {"bleu_score": 33.59973059005528, "chrf_score": 67.44026788151116, "xcomet_score": 0.9453856945037842, "xcomet_qe_score": 1.0, "metricx_score": 3.7865474224090576, "metricx_qe_score": 2.867384433746338, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "This information retrieval task comes with its own set of challenges.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 26.854673993688337, "xcomet_score": 0.9653196334838867, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "First, it deals with two types of language.", "metrics": {"bleu_score": 4.996872151825361, "chrf_score": 20.484404767361745, "xcomet_score": 0.9559558629989624, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "Common natural language for the questions and complex legal language for the statutes.", "metrics": {"bleu_score": 2.9275822595890535, "chrf_score": 31.982711040128827, "xcomet_score": 0.9222612380981445, "xcomet_qe_score": 0.9883500337600708, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans les distributions linguistiques rend plus difficile pour un système de récupérer les candidats pertinents, car cela nécessite indirectement un système d'interprétation inhérent qui peut traduire une question naturelle en une question juridique qui correspond à la terminologie des statuts.", "metrics": {"bleu_score": 73.15441952621448, "chrf_score": 87.4962143000816, "xcomet_score": 0.8452436923980713, "xcomet_qe_score": 0.9104301333427429, "metricx_score": 5.182590007781982, "metricx_qe_score": 4.933302402496338, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le droit statutaire n'est pas une série d'articles indépendants qui peuvent être traités comme une source complète d'information à part entière, comme les nouvelles ou les recettes, par exemple.", "metrics": {"bleu_score": 44.78315454797505, "chrf_score": 72.62699472018541, "xcomet_score": 0.9738714694976807, "xcomet_qe_score": 1.0, "metricx_score": 4.371450901031494, "metricx_qe_score": 4.042853355407715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, c'est une collection structurée de dispositions juridiques qui ont un sens complet seulement lorsqu'elles sont considérées dans le contexte global, c'est-à-dire en conjonction avec les informations complémentaires des articles voisins, les champs et sous-champs auxquels ils appartiennent et leur place dans la structure de la loi.", "metrics": {"bleu_score": 53.529855849895874, "chrf_score": 76.70146681981646, "xcomet_score": 0.8000202775001526, "xcomet_qe_score": 0.9964373111724854, "metricx_score": 3.38014554977417, "metricx_qe_score": 2.1486122608184814, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles statutaires sont en paragraphe, qui est généralement l'unité de récupération typique dans la plupart des travaux de récupération.", "metrics": {"bleu_score": 34.11914740323361, "chrf_score": 62.16903649839921, "xcomet_score": 0.26866576075553894, "xcomet_qe_score": 0.4469014108181, "metricx_score": 13.653938293457031, "metricx_qe_score": 11.360772132873535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Here, there are long documents that may be up to six.", "metrics": {"bleu_score": 3.468317761317914, "chrf_score": 23.898939503347727, "xcomet_score": 0.5468701124191284, "xcomet_qe_score": 0.8015584945678711, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les progrès récents dans le domaine de l'ANP ont suscité un grand intérêt pour de nombreuses tâches juridiques, telles que la prédiction de jugements juridiques ou la revue automatique des contrats.", "metrics": {"bleu_score": 30.644064067193618, "chrf_score": 55.17626480316259, "xcomet_score": 0.6531472206115723, "xcomet_qe_score": 0.6850621700286865, "metricx_score": 4.3660407066345215, "metricx_qe_score": 2.8806982040405273, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "metrics": {"bleu_score": 1.7324044975269597, "chrf_score": 20.86789650867788, "xcomet_score": 0.7371089458465576, "xcomet_qe_score": 0.9033434391021729, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "In this work, we present a new, French-native citizen-centric data set to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "metrics": {"bleu_score": 1.142252338965159, "chrf_score": 23.95793224487869, "xcomet_score": 0.8803844451904297, "xcomet_qe_score": 0.9043000340461731, "metricx_score": 25.0, "metricx_qe_score": 23.879146575927734, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "Our Belgian statutory article retrieval data set, psrd, consists of more than one thousand one hundred articles.", "metrics": {"bleu_score": 1.5675444125361784, "chrf_score": 17.55572609547899, "xcomet_score": 0.30534353852272034, "xcomet_qe_score": 0.7185975909233093, "metricx_score": 17.433063507080078, "metricx_qe_score": 15.430173873901367, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "These questions cover a wide range of topics, from family, housing, money, to work and social security.", "metrics": {"bleu_score": 3.790498156271684, "chrf_score": 28.591585803657736, "xcomet_score": 0.9933294057846069, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty two thousand six hundred.", "metrics": {"bleu_score": 1.5880176593692206, "chrf_score": 21.242334587113927, "xcomet_score": 0.5047647953033447, "xcomet_qe_score": 0.8196185231208801, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Belgian codes of law. Let's now talk about how we collected these datasets.", "metrics": {"bleu_score": 2.627961710408444, "chrf_score": 20.640960163044547, "xcomet_score": 0.25179845094680786, "xcomet_qe_score": 0.3379294276237488, "metricx_score": 22.197908401489258, "metricx_qe_score": 21.229528427124023, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "First, we started by compiling a large corpus of legal articles.", "metrics": {"bleu_score": 3.7644257151903666, "chrf_score": 25.02927237892445, "xcomet_score": 0.9857778549194336, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "We considered thirty two publicly available Belgian codes and extracted all their articles as well as the corresponding section headings.", "metrics": {"bleu_score": 2.448896697858474, "chrf_score": 33.80565254754567, "xcomet_score": 0.9092661142349243, "xcomet_qe_score": 1.0, "metricx_score": 24.108835220336914, "metricx_qe_score": 22.80816078186035, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Then we gathered legal questions with references to relevant statutes.", "metrics": {"bleu_score": 3.098174990685587, "chrf_score": 22.40077651406896, "xcomet_score": 0.9778827428817749, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "To do so, we partner with a Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "metrics": {"bleu_score": 1.3794462224541233, "chrf_score": 20.223779632145096, "xcomet_score": 0.9967621564865112, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgian most common legal issues.", "metrics": {"bleu_score": 1.5837434379490964, "chrf_score": 22.37705553953269, "xcomet_score": 0.9691296815872192, "xcomet_qe_score": 0.9905999898910522, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "We collected thousands of questions annotated with categories, subcategories, and legal references to relevant statutes.", "metrics": {"bleu_score": 2.263300754846532, "chrf_score": 29.87783903232061, "xcomet_score": 0.9982888698577881, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons passé les références légales et filtré les questions dont les références n'étaient pas des articles de l'un des codes de loi que nous avons considérés.", "metrics": {"bleu_score": 61.113438984650095, "chrf_score": 79.5114096733605, "xcomet_score": 0.8603578209877014, "xcomet_qe_score": 0.9064023494720459, "metricx_score": 3.1461617946624756, "metricx_qe_score": 5.796303749084473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "The remaining references were matched and converted to the corresponding article IDs from all corpus.", "metrics": {"bleu_score": 4.891187874480726, "chrf_score": 33.63903411457379, "xcomet_score": 0.8231579065322876, "xcomet_qe_score": 0.922261118888855, "metricx_score": 22.097017288208008, "metricx_qe_score": 11.065885543823242, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from the", "metrics": {"bleu_score": 2.325874951816217, "chrf_score": 20.130653817364156, "xcomet_score": 0.5152638554573059, "xcomet_qe_score": 0.6939552426338196, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question est accompagnée d'une catégorie principale et d'une concaténation de sous-catégories.", "metrics": {"bleu_score": 50.47325154308107, "chrf_score": 80.4082245966848, "xcomet_score": 0.954633355140686, "xcomet_qe_score": 0.9636931419372559, "metricx_score": 5.552073955535889, "metricx_qe_score": 5.55289888381958, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "Et chaque article est accompagné d'une concaténation de leurs sous-sequents, en tête dans la structure de l'énoncé.", "metrics": {"bleu_score": 19.51797195341104, "chrf_score": 49.314298647980046, "xcomet_score": 0.43346962332725525, "xcomet_qe_score": 0.5650190114974976, "metricx_score": 13.348323822021484, "metricx_qe_score": 12.72999382019043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Cette information supplémentaire n'est pas utilisée dans le présent travail, mais pourrait être d'intérêt pour des recherches futures sur la récupération d'informations juridiques ou la classification juridique du texte.", "metrics": {"bleu_score": 37.158590373316436, "chrf_score": 76.17755766898591, "xcomet_score": 0.8669732809066772, "xcomet_qe_score": 0.9755640625953674, "metricx_score": 2.0524537563323975, "metricx_qe_score": 1.6109693050384521, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Let's look at some characteristics of our data sets.", "metrics": {"bleu_score": 3.7968017775955714, "chrf_score": 18.618913037737137, "xcomet_score": 0.9815976619720459, "xcomet_qe_score": 0.9988069534301758, "metricx_score": 8.244855880737305, "metricx_qe_score": 10.653936386108398, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "The questions are between five and forty four words long, with a median of forty words.", "metrics": {"bleu_score": 2.5540496664715904, "chrf_score": 19.83869961878217, "xcomet_score": 0.7745895385742188, "xcomet_qe_score": 0.8519039154052734, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "The articles are much longer, with a median length of 77 words, with 140", "metrics": {"bleu_score": 1.7639838596482365, "chrf_score": 12.984034668612916, "xcomet_score": 0.14193284511566162, "xcomet_qe_score": 0.5498466491699219, "metricx_score": 25.0, "metricx_qe_score": 19.83600425720215, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "Two of them exceeding one.", "metrics": {"bleu_score": 2.9859662827819125, "chrf_score": 7.359239388930041, "xcomet_score": 0.14176270365715027, "xcomet_qe_score": 0.14847300946712494, "metricx_score": 24.631677627563477, "metricx_qe_score": 21.605627059936523, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "Comme mentionné précédemment, la question couvrait un large éventail de sujets, avec environ 85 % d'entre eux étant soit sur la famille, l'habitation, l'argent ou la justice.", "metrics": {"bleu_score": 29.91528889155786, "chrf_score": 54.161742431027605, "xcomet_score": 0.7335209846496582, "xcomet_qe_score": 0.7803585529327393, "metricx_score": 4.754324913024902, "metricx_qe_score": 4.684566974639893, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "While the remaining fifteen percent concern either social security, foreigners, or work.", "metrics": {"bleu_score": 2.5586897876995107, "chrf_score": 26.97810661673192, "xcomet_score": 0.9986180067062378, "xcomet_qe_score": 0.9810539484024048, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "The articles are also very diverse, as they come from thirty two different Belgian codes that cover a large number of legal topics.", "metrics": {"bleu_score": 1.7911710595643588, "chrf_score": 22.89041432473427, "xcomet_score": 0.8933078050613403, "xcomet_qe_score": 1.0, "metricx_score": 21.325057983398438, "metricx_qe_score": 23.98705291748047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles recueillis de chaque de ces codes belges.", "metrics": {"bleu_score": 50.78431769269645, "chrf_score": 67.63849005247647, "xcomet_score": 0.9844306111335754, "xcomet_qe_score": 1.0, "metricx_score": 2.3239946365356445, "metricx_qe_score": 3.431075096130371, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Out of the 22,633 articles, only 1,612 are referred to as relevant to at least one of the following three categories.", "metrics": {"bleu_score": 3.062868772450979, "chrf_score": 16.11904756940489, "xcomet_score": 0.22328484058380127, "xcomet_qe_score": 0.6432902812957764, "metricx_score": 12.813754081726074, "metricx_qe_score": 4.459962368011475, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "\"One question in the data sets. And around 80% of these cited articles come from either the civil code, judicial codes, criminal investigation codes, or penal codes.\"", "metrics": {"bleu_score": 1.8289966666149708, "chrf_score": 31.03592592968787, "xcomet_score": 0.2405329942703247, "xcomet_qe_score": 0.7095412015914917, "metricx_score": 17.78239631652832, "metricx_qe_score": 14.236784934997559, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "\"Meanwhile, eighteen out of thirty-two codes have less than five articles mentioned as relevant to at least one question.\"", "metrics": {"bleu_score": 4.141141330484801, "chrf_score": 30.485085130806755, "xcomet_score": 0.9601860046386719, "xcomet_qe_score": 0.9699361324310303, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Which can be explained by the fact that those codes focus less on individuals and their concerns.", "metrics": {"bleu_score": 2.2854640586554065, "chrf_score": 24.984479915015363, "xcomet_score": 0.9200159907341003, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "En général, le nombre médian de citations pour ces articles cités est de 2, et moins de 25 % d'entre eux sont.", "metrics": {"bleu_score": 37.66622568934355, "chrf_score": 52.70464877129043, "xcomet_score": 0.17599302530288696, "xcomet_qe_score": 0.4189140796661377, "metricx_score": 14.801969528198242, "metricx_qe_score": 13.732542991638184, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant tous les ensembles de données, nous avons mené des comparaisons de plusieurs approches de récupération, y compris l'architecture lexicale et dense.", "metrics": {"bleu_score": 40.644776765505945, "chrf_score": 78.65412658138351, "xcomet_score": 0.8309887647628784, "xcomet_qe_score": 0.9457281827926636, "metricx_score": 3.8623504638671875, "metricx_qe_score": 3.74438214302063, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "Given a query and an article, a lexical model assigns a score to the query-article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "metrics": {"bleu_score": 2.876053444553946, "chrf_score": 29.33561841675652, "xcomet_score": 0.9583879709243774, "xcomet_qe_score": 0.9075160026550293, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "We experimented with the standard tfidf and bm25 ranking functions.", "metrics": {"bleu_score": 4.069582841180382, "chrf_score": 28.09198245685231, "xcomet_score": 0.8134088516235352, "xcomet_qe_score": 0.9136738777160645, "metricx_score": 18.288711547851562, "metricx_qe_score": 11.78650951385498, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que des articles contenant des mots-clés présents dans la requête.", "metrics": {"bleu_score": 64.7084148066781, "chrf_score": 85.61375321620676, "xcomet_score": 0.9920238256454468, "xcomet_qe_score": 1.0, "metricx_score": 0.9047468900680542, "metricx_qe_score": 0.9476295709609985, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "To overcome this limitation, we experiment with a neural-based architecture that can capture semantic relationship between queries and articles.", "metrics": {"bleu_score": 4.1185369091116995, "chrf_score": 39.416228179885834, "xcomet_score": 0.9722626209259033, "xcomet_qe_score": 0.9910863637924194, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle de b-encoder qui mappe les requêtes et les articles dans des représentations vectorielles denses et calcule un score de pertinence entre un pair de requête-article en fonction de la similarité de leurs embeddings.", "metrics": {"bleu_score": 28.97107963376972, "chrf_score": 67.34552542887037, "xcomet_score": 0.7307695746421814, "xcomet_qe_score": 0.7760733962059021, "metricx_score": 8.412890434265137, "metricx_qe_score": 7.310171127319336, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces imbeddings résultent généralement d'une opération de pooling sur l'output d'un modèle d'imbedding de mots.", "metrics": {"bleu_score": 33.08478035107363, "chrf_score": 59.38863733774903, "xcomet_score": 0.6160496473312378, "xcomet_qe_score": 0.7911309599876404, "metricx_score": 8.21389389038086, "metricx_qe_score": 8.879013061523438, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous avons étudié l'efficacité des encodeurs siamois B dans un ensemble d'évaluation à zéro tir, ce qui signifie que les modèles d'empreinte de mots pré-entraînés sont appliqués sans aucune fine-tuning supplémentaire.", "metrics": {"bleu_score": 22.510534424743234, "chrf_score": 61.353951624082356, "xcomet_score": 0.3384192883968353, "xcomet_qe_score": 0.35268598794937134, "metricx_score": 7.988855361938477, "metricx_qe_score": 7.104371547698975, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "We experiment with context-independent text encoder, namely word2vec and fastText, and context-dependent embedding models, namely Roberta and more specifically Camembert, which is a French Roberta model.", "metrics": {"bleu_score": 2.7065980191421555, "chrf_score": 32.25415592149184, "xcomet_score": 0.9370543956756592, "xcomet_qe_score": 0.9569129943847656, "metricx_score": 20.509174346923828, "metricx_qe_score": 16.12307357788086, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous entraînons notre propre modèle basé sur Camembert, Beyond Quarters.", "metrics": {"bleu_score": 15.934326838673726, "chrf_score": 39.76005994100144, "xcomet_score": 0.26646286249160767, "xcomet_qe_score": 0.2845487892627716, "metricx_score": 13.201189994812012, "metricx_qe_score": 15.271007537841797, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "On tous les ensembles de données. Notez que, pour l'entraînement, nous expérimentons avec les deux saveurs de l'architecture Biancoduro.", "metrics": {"bleu_score": 26.24310277292268, "chrf_score": 61.656279446536054, "xcomet_score": 0.1429130882024765, "xcomet_qe_score": 0.13302835822105408, "metricx_score": 18.815345764160156, "metricx_qe_score": 20.77206039428711, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and Tutoire, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "metrics": {"bleu_score": 2.0577818081016312, "chrf_score": 28.19527558957314, "xcomet_score": 0.5760046243667603, "xcomet_qe_score": 0.6648837327957153, "metricx_score": 25.0, "metricx_qe_score": 23.44773292541504, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons expérimenté avec la pondération moyenne maximale et la pondération de la similarité de cl, ainsi que le produit de point et le cosinus pour le calcul des similarités.", "metrics": {"bleu_score": 15.545328465618004, "chrf_score": 54.83623690856702, "xcomet_score": 0.6163449287414551, "xcomet_qe_score": 0.5734202861785889, "metricx_score": 8.053086280822754, "metricx_qe_score": 7.377542018890381, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le résultat d'une ligne de base sur le jeu de test.", "metrics": {"bleu_score": 22.62944003945279, "chrf_score": 58.64956379892239, "xcomet_score": 0.5240373611450195, "xcomet_qe_score": 0.6279733180999756, "metricx_score": 6.829404830932617, "metricx_qe_score": 7.150678634643555, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "Avec les méthodes lexicales ci-dessus, les encodeurs b-siamis évalués dans une configuration de zéro shots au milieu, et les encodeurs b-fine tune en dessous.", "metrics": {"bleu_score": 39.60970942970262, "chrf_score": 69.75481661677627, "xcomet_score": 0.46668821573257446, "xcomet_qe_score": 0.4736153483390808, "metricx_score": 15.157660484313965, "metricx_qe_score": 15.474126815795898, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Au total, les encodeurs finement ajustés ont nettement surpassé toutes les autres lignes de base.", "metrics": {"bleu_score": 10.123734869668828, "chrf_score": 36.525498414923966, "xcomet_score": 0.46152156591415405, "xcomet_qe_score": 0.6824468374252319, "metricx_score": 6.630762100219727, "metricx_qe_score": 6.364150524139404, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de deux tours s'est amélioré par rapport à sa variante siamoise sur la récupération à cent, mais a performé de manière similaire sur les autres métriques.", "metrics": {"bleu_score": 17.71672685027266, "chrf_score": 57.58070059804623, "xcomet_score": 0.47347673773765564, "xcomet_qe_score": 0.465019553899765, "metricx_score": 5.992424488067627, "metricx_qe_score": 6.653839111328125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Although bm twenty five underperformed the train beyond code significantly, its performance indicates that it's still a strong baseline for domain specific retrieval.", "metrics": {"bleu_score": 1.65345928425853, "chrf_score": 31.622668554241844, "xcomet_score": 0.6431127190589905, "xcomet_qe_score": 0.7349944114685059, "metricx_score": 21.454927444458008, "metricx_qe_score": 18.58405876159668, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "Concernant l'évaluation à zéro coup du binaire siamois, nous constatons que l'utilisation directe des embeddings d'un modèle camembert pré-entraîné sans optimisation pour la tâche d'extraction d'informations donne de mauvais résultats, ce qui est cohérent avec les résultats précédents.", "metrics": {"bleu_score": 56.30258672349745, "chrf_score": 73.45175844719998, "xcomet_score": 0.5175292491912842, "xcomet_qe_score": 0.4916383624076843, "metricx_score": 7.435392379760742, "metricx_qe_score": 7.017017364501953, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous avons observé que le vocoder basé sur word2vec a nettement dépassé le modèle fasttext et basé sur word, ce qui suggère que peut-être les embeddings pré-entraînés à niveau de mot sont plus appropriés pour la tâche que les embeddings à niveau de caractère ou de sous-mot. Lorsqu'ils sont utilisés hors de la boîte,", "metrics": {"bleu_score": 16.26463972037205, "chrf_score": 43.918795826989324, "xcomet_score": 0.175778329372406, "xcomet_qe_score": 0.2521904706954956, "metricx_score": 12.179533958435059, "metricx_qe_score": 11.743939399719238, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteuses, ces résultats suggèrent une ample opportunité d'amélioration par rapport à un expert en droit qualifié, qui peut finalement récupérer tous les articles pertinents pour toute question et ainsi obtenir des scores parfaits.", "metrics": {"bleu_score": 34.45261402978936, "chrf_score": 63.667489068101304, "xcomet_score": 0.9337643384933472, "xcomet_qe_score": 0.9616605043411255, "metricx_score": 3.2552952766418457, "metricx_qe_score": 3.1831343173980713, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concluons en discutant des deux limitations de tous les ensembles de données.", "metrics": {"bleu_score": 9.238430210261097, "chrf_score": 68.53071210243992, "xcomet_score": 0.8950001001358032, "xcomet_qe_score": 0.8679726123809814, "metricx_score": 3.960723876953125, "metricx_qe_score": 2.6253068447113037, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, le corpus de l'article est limité à ceux collectés des trente-deux codes belges considérés, qui ne couvrent pas l'ensemble du droit belge, car les articles des décrets, des directives et des ordonnances manquent.", "metrics": {"bleu_score": 50.61270087293234, "chrf_score": 82.00592660027175, "xcomet_score": 0.7529510259628296, "xcomet_qe_score": 0.7186421155929565, "metricx_score": 3.551726818084717, "metricx_qe_score": 3.4216907024383545, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "During the data set construction, all references to these uncollected articles are ignored, which causes some question to end up with only a fraction of the initial number of relevant articles.", "metrics": {"bleu_score": 1.6210010004797855, "chrf_score": 37.47446495243774, "xcomet_score": 0.9459679126739502, "xcomet_qe_score": 0.8784875869750977, "metricx_score": 24.06765365600586, "metricx_qe_score": 24.537643432617188, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "This information loss implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "metrics": {"bleu_score": 2.043962606050419, "chrf_score": 32.36113724925199, "xcomet_score": 0.761528491973877, "xcomet_qe_score": 0.9263384342193604, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous devons noter que non toutes les questions juridiques peuvent être résolues avec les statuts seuls.", "metrics": {"bleu_score": 14.577432272792732, "chrf_score": 50.07829598769826, "xcomet_score": 0.957689106464386, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 5.6738505363464355, "metricx_qe_score": 3.270397186279297, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question, puis-je expulser mes locataires s'ils font trop de bruit?", "metrics": {"bleu_score": 76.59552353576204, "chrf_score": 93.7305270305412, "xcomet_score": 0.9672999382019043, "xcomet_qe_score": 0.9713346362113953, "metricx_score": 1.4393807649612427, "metricx_qe_score": 1.9569288492202759, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "metrics": {"bleu_score": 1.431306716763, "chrf_score": 22.839621683182727, "xcomet_score": 0.5791447758674622, "xcomet_qe_score": 0.9681105613708496, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, le locataire devrait probablement se fier davantage au caselaw et trouver des précédents similaires à la situation actuelle.", "metrics": {"bleu_score": 34.38263528816037, "chrf_score": 68.04811233206809, "xcomet_score": 0.5088335275650024, "xcomet_qe_score": 0.5767079591751099, "metricx_score": 6.892538070678711, "metricx_qe_score": 6.711968421936035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "For example, the tenant makes two parties a week until two August.", "metrics": {"bleu_score": 2.537856360538449, "chrf_score": 15.498122128867752, "xcomet_score": 0.3796409070491791, "xcomet_qe_score": 0.7953659296035767, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, certaines questions sont mieux adaptées que d'autres à la tâche de récupération d'articles statuts. Et le domaine des moins adaptés reste à déterminer.", "metrics": {"bleu_score": 52.05725698398383, "chrf_score": 73.21271592545318, "xcomet_score": 0.7274032831192017, "xcomet_qe_score": 0.588153600692749, "metricx_score": 7.73290491104126, "metricx_qe_score": 7.85633659362793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "We hope that all work sparks interest in developing practical and reliable statutory article retrieval models.", "metrics": {"bleu_score": 2.033126908751098, "chrf_score": 22.671171638445312, "xcomet_score": 0.843425452709198, "xcomet_qe_score": 0.969595730304718, "metricx_score": 24.113868713378906, "metricx_qe_score": 23.36597442626953, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "That can help improve access to justice for all.", "metrics": {"bleu_score": 4.085507150363302, "chrf_score": 21.288931914611844, "xcomet_score": 0.9658377170562744, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "You can check out our paper at setencode at the following links. Thank you.", "metrics": {"bleu_score": 2.732111648124769, "chrf_score": 16.046746023618553, "xcomet_score": 0.7357778549194336, "xcomet_qe_score": 0.8162817358970642, "metricx_score": 17.011064529418945, "metricx_qe_score": 14.167181015014648, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, nous sommes heureux de présenter notre travail sur Vowels, un benchmark indépendant des tâches destiné à tester les modèles de vision et de langage avec des phénomènes linguistiques spécifiques.", "metrics": {"bleu_score": 46.660778114303845, "chrf_score": 75.58877297695486, "xcomet_score": 0.5297458171844482, "xcomet_qe_score": 0.6326612830162048, "metricx_score": 6.527608394622803, "metricx_qe_score": 6.21715784072876, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Why did we do the trouble in setting up this benchmark?", "metrics": {"bleu_score": 2.8666091494718775, "chrf_score": 14.039815417219012, "xcomet_score": 0.7039791941642761, "xcomet_qe_score": 0.9971965551376343, "metricx_score": 25.0, "metricx_qe_score": 24.371423721313477, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "\"Well, during the last years, we have seen an explosion of transformer-based vision and language models, pretrained on large amounts of image-text pairs.\"", "metrics": {"bleu_score": 1.460221867541373, "chrf_score": 27.77228658486836, "xcomet_score": 0.9569995403289795, "xcomet_qe_score": 0.9741590023040771, "metricx_score": 24.0671329498291, "metricx_qe_score": 22.685056686401367, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque l'un de ces modèles pousse l'état de l'art sur les tâches de vision et de langage, telles que la réponse aux questions visuelles, la raison de la common sense visuelle, la récupération d'images, le grounding des phrases.", "metrics": {"bleu_score": 32.42123210259748, "chrf_score": 64.03834584715192, "xcomet_score": 0.23060716688632965, "xcomet_qe_score": 0.29710909724235535, "metricx_score": 13.635724067687988, "metricx_qe_score": 13.507719039916992, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc reçu un message selon lequel les exactitudes de ces points de référence spécifiques aux tâches augmentent constamment.", "metrics": {"bleu_score": 31.806104725007426, "chrf_score": 62.15237586541604, "xcomet_score": 0.9403295516967773, "xcomet_qe_score": 0.8658338189125061, "metricx_score": 3.0438954830169678, "metricx_qe_score": 2.916386842727661, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "But do we know what the models have actually learned?", "metrics": {"bleu_score": 3.7477767366779213, "chrf_score": 13.049901040628056, "xcomet_score": 0.9662772417068481, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 24.301639556884766, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "metrics": {"bleu_score": 2.134170623411786, "chrf_score": 23.98344417533091, "xcomet_score": 0.953108549118042, "xcomet_qe_score": 0.9653360843658447, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "And the low score for this one.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 16.62160424116946, "xcomet_score": 0.9269646406173706, "xcomet_qe_score": 0.9944015741348267, "metricx_score": 20.401763916015625, "metricx_qe_score": 15.118833541870117, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Do vision and language models focus on the right thing?", "metrics": {"bleu_score": 2.8289458031628008, "chrf_score": 18.842865399193112, "xcomet_score": 0.8548588752746582, "xcomet_qe_score": 0.9926931858062744, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Or, se concentrent-ils sur les biais, comme le montrent les travaux précédents?", "metrics": {"bleu_score": 29.256127307315065, "chrf_score": 66.67598707627812, "xcomet_score": 0.9222779273986816, "xcomet_qe_score": 0.9789697527885437, "metricx_score": 2.2721312046051025, "metricx_qe_score": 2.6865599155426025, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour mieux éclairer cet aspect, nous proposons une direction plus agnostique au niveau des tâches et introduisons des vases qui testent la sensibilité des modèles de vision et de langage à des phénomènes linguistiques spécifiques qui affectent à la fois les modalités linguistiques et visuelles.", "metrics": {"bleu_score": 53.400403451642696, "chrf_score": 78.77951971515557, "xcomet_score": 0.4605865776538849, "xcomet_qe_score": 0.49277830123901367, "metricx_score": 8.894960403442383, "metricx_qe_score": 9.4007568359375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "We target existence, plurality, counting, spatial relations, actions, and entity coreference.", "metrics": {"bleu_score": 2.613677874373997, "chrf_score": 38.63994513110269, "xcomet_score": 0.9619249105453491, "xcomet_qe_score": 0.9836755990982056, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "But how do we test whether the vision and language models have captured these phenomena?", "metrics": {"bleu_score": 2.908317710573757, "chrf_score": 29.77388219971132, "xcomet_score": 0.9883451461791992, "xcomet_qe_score": 0.9964276552200317, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "By foiling, a method previously applied for vision and language models only for noun phrases by Ravi Shankar and collaborators, and on counting by us in previous work.", "metrics": {"bleu_score": 1.4040985145954226, "chrf_score": 26.738489846665974, "xcomet_score": 0.7515542507171631, "xcomet_qe_score": 0.7975770235061646, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "metrics": {"bleu_score": 1.6934096677198087, "chrf_score": 21.024712742615943, "xcomet_score": 0.9292744398117065, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous faisons ces altérations de phrases en nous concentrant sur six pièces spécifiques, telles que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la co-reference d'entités, où chaque pièce peut consister en un ou plusieurs instruments, au cas où nous aurions trouvé plus d'une manière intéressante de créer des instances de feuille.", "metrics": {"bleu_score": 66.74843477994177, "chrf_score": 80.49628938187686, "xcomet_score": 0.2539611756801605, "xcomet_qe_score": 0.2997497618198395, "metricx_score": 10.05860424041748, "metricx_qe_score": 10.5326566696167, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas de l'action PIECE, nous avons deux instruments, l'un dans lequel le verbe d'action est changé avec une action différente, et l'autre dans lequel les temps de l'action sont échangés.", "metrics": {"bleu_score": 55.80351516794008, "chrf_score": 77.47236897026367, "xcomet_score": 0.4207177758216858, "xcomet_qe_score": 0.4102260172367096, "metricx_score": 14.369622230529785, "metricx_qe_score": 13.447534561157227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Counting and coreference also are pieces that have more than one instrument.", "metrics": {"bleu_score": 2.8603449943861583, "chrf_score": 25.93757971846674, "xcomet_score": 0.7606971263885498, "xcomet_qe_score": 0.8568745851516724, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "And we create these foils by making sure that they fail to describe the image, that they are grammatical and otherwise valid sentences.", "metrics": {"bleu_score": 1.7911710595643588, "chrf_score": 27.520489534792063, "xcomet_score": 0.9677714109420776, "xcomet_qe_score": 0.9866379499435425, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "This is not easy to do because a false caption may be less likely than the original caption.", "metrics": {"bleu_score": 1.7287549675176845, "chrf_score": 19.972879323832355, "xcomet_score": 0.7107042074203491, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien qu'il ne soit pas impossible, il est statistiquement moins probable que les plantes coupent un homme que qu'un homme coupe des plantes. Et les grands modèles de vision et de langage pourraient en saisir.", "metrics": {"bleu_score": 51.240621788279, "chrf_score": 80.34845934896714, "xcomet_score": 0.6422075033187866, "xcomet_qe_score": 0.7379683256149292, "metricx_score": 5.438455104827881, "metricx_qe_score": 5.4835309982299805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Therefore, to obtain valid foils, we must take action.", "metrics": {"bleu_score": 4.406306339938217, "chrf_score": 19.416664406669756, "xcomet_score": 0.9806714057922363, "xcomet_qe_score": 0.9856106042861938, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "First, we make use of strong language models to propose foils.", "metrics": {"bleu_score": 5.862244939055158, "chrf_score": 25.88450075618363, "xcomet_score": 0.9584048986434937, "xcomet_qe_score": 0.969338059425354, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Second, we use natural language inference, or short nli, to filter out foils that could be still describing the image, since when constructing foils, we need to ensure that they fail to describe the image.", "metrics": {"bleu_score": 2.3569062221449553, "chrf_score": 28.396932700695377, "xcomet_score": 0.8746972680091858, "xcomet_qe_score": 0.9460856914520264, "metricx_score": 23.363460540771484, "metricx_qe_score": 22.205219268798828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "To test this automatically, we apply natural language inference with the following rationale.", "metrics": {"bleu_score": 2.7350835735481263, "chrf_score": 27.588958737446063, "xcomet_score": 0.9713727235794067, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 24.150941848754883, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "We consider an image to be the premise and its caption its entailed hypothesis.", "metrics": {"bleu_score": 3.1251907639724417, "chrf_score": 26.26405797417964, "xcomet_score": 0.9279828071594238, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous considérons la légende comme la prémisse et le film comme son hypothèse.", "metrics": {"bleu_score": 50.09092657036855, "chrf_score": 74.61430637651695, "xcomet_score": 0.7989404201507568, "xcomet_qe_score": 0.6557934284210205, "metricx_score": 6.253582000732422, "metricx_qe_score": 5.942955017089844, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "If an nli model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "metrics": {"bleu_score": 1.7557381354086663, "chrf_score": 28.195133988944754, "xcomet_score": 0.8504773378372192, "xcomet_qe_score": 0.907997190952301, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "If an nli predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image and we filter these foils out.", "metrics": {"bleu_score": 2.5802625919834825, "chrf_score": 28.68915445844255, "xcomet_score": 0.5652381181716919, "xcomet_qe_score": 0.5995258688926697, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "But this procedure is not perfect. It is just an indicator for valid foils.", "metrics": {"bleu_score": 2.732111648124769, "chrf_score": 24.52823618254163, "xcomet_score": 0.9959783554077148, "xcomet_qe_score": 1.0, "metricx_score": 23.355756759643555, "metricx_qe_score": 21.968677520751953, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, comme troisième mesure pour générer des faux valides, nous employons des annotateurs humains pour valider les données utilisées dans Vals.", "metrics": {"bleu_score": 61.587874428306336, "chrf_score": 79.05535999096958, "xcomet_score": 0.5179318785667419, "xcomet_qe_score": 0.5463048219680786, "metricx_score": 9.687332153320312, "metricx_qe_score": 9.340991973876953, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, après le filtrage et l'évaluation humaine, nous avons autant d'instances de test que décrites dans cette table.", "metrics": {"bleu_score": 45.76318980860575, "chrf_score": 81.65425949792929, "xcomet_score": 0.9994169473648071, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.0925869941711426, "metricx_qe_score": 1.8545483350753784, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que Valsa ne fournit aucun ensemble de données d'entraînement, mais seulement des données de test.", "metrics": {"bleu_score": 42.249424472275855, "chrf_score": 65.28586181812564, "xcomet_score": 0.8282252550125122, "xcomet_qe_score": 0.8364251255989075, "metricx_score": 2.346954107284546, "metricx_qe_score": 3.2162880897521973, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "Since it is a zero-shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "metrics": {"bleu_score": 1.439413740718659, "chrf_score": 24.754661319871076, "xcomet_score": 0.9725600481033325, "xcomet_qe_score": 0.9872356653213501, "metricx_score": 23.44379425048828, "metricx_qe_score": 24.041324615478516, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "Fine-tuning would only enable models to exploit artifacts or statistical biases in the data.", "metrics": {"bleu_score": 2.299921972415939, "chrf_score": 26.29335294871992, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998902082443237, "xcomet_qe_score": 1.0, "metricx_score": 1.3476738929748535, "metricx_qe_score": 2.4462342262268066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme nous l'avons dit, nous sommes intéressés à évaluer quelles capacités les modèles de vision et de langage ont après préformation.", "metrics": {"bleu_score": 29.128820942605923, "chrf_score": 69.14137383615201, "xcomet_score": 0.9845153093338013, "xcomet_qe_score": 0.9240915775299072, "metricx_score": 2.0603742599487305, "metricx_qe_score": 2.634361743927002, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "We experiment with five vision and language models on VOWELS, namely with CLIP, ALXLmert, Vilbert, Vilbert12in1, and Visualbert.", "metrics": {"bleu_score": 3.4656213960699764, "chrf_score": 26.49309287889788, "xcomet_score": 0.5145872831344604, "xcomet_qe_score": 0.6469598412513733, "metricx_score": 14.222198486328125, "metricx_qe_score": 9.313994407653809, "linguapy_score": [1, "TAGALOG"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "metrics": {"bleu_score": 2.890599638459958, "chrf_score": 32.93399504134449, "xcomet_score": 0.8532931804656982, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "metrics": {"bleu_score": 2.1878709256905156, "chrf_score": 31.481450996305888, "xcomet_score": 0.9227786064147949, "xcomet_qe_score": 0.9029033184051514, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "For more metrics and results on them, do check out our paper.", "metrics": {"bleu_score": 3.377156414337854, "chrf_score": 17.54189657204777, "xcomet_score": 0.9200966358184814, "xcomet_qe_score": 0.9875798225402832, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "The results with pairwise accuracy are shown here, and they are consistent with the results we got from the other metrics. It's that the best zero-shot performance is achieved by Vilbert twelve in one, followed by Vilbert, Alex, Mert, Clip, and finally, Visualbert.", "metrics": {"bleu_score": 1.139054792042459, "chrf_score": 23.87304725274002, "xcomet_score": 0.41525548696517944, "xcomet_qe_score": 0.47038358449935913, "metricx_score": 14.117049217224121, "metricx_qe_score": 7.569621562957764, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est notable comment les instruments centrés sur les objets individuels, comme l'existence et les phrases nominales, sont presque résolus par Wilbert 12 in 1, soulignant que les modèles sont capables d'identifier les objets nommés et leur présence dans les images.", "metrics": {"bleu_score": 59.989498704038944, "chrf_score": 81.34247292227063, "xcomet_score": 0.5799790620803833, "xcomet_qe_score": 0.5580054521560669, "metricx_score": 5.804239273071289, "metricx_qe_score": 5.841355323791504, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucun des morceaux restants ne peut être résolu de manière fiable dans nos configurations de défaillance adversaire.", "metrics": {"bleu_score": 60.28670503016433, "chrf_score": 63.28501477479137, "xcomet_score": 0.6522164344787598, "xcomet_qe_score": 0.7144067287445068, "metricx_score": 3.942831516265869, "metricx_qe_score": 2.348609447479248, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "We see from the lularity and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects or counting them in an image.", "metrics": {"bleu_score": 1.8884687851304391, "chrf_score": 28.761436868671858, "xcomet_score": 0.8937363624572754, "xcomet_qe_score": 0.9335811734199524, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "metrics": {"bleu_score": 4.1185369091116995, "chrf_score": 36.10720439522814, "xcomet_score": 0.8192603588104248, "xcomet_qe_score": 0.9651520252227783, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases, as we see in the actions piece.", "metrics": {"bleu_score": 2.727768996755739, "chrf_score": 34.01662691079021, "xcomet_score": 0.8087121248245239, "xcomet_qe_score": 0.9814682006835938, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "Du morceau de référence, nous découvrons que tracer plusieurs références à la même objet dans une image en utilisant des pronoms est également difficile pour les modèles de vision et de langage.", "metrics": {"bleu_score": 56.436265762553425, "chrf_score": 78.66172944580173, "xcomet_score": 0.6228306889533997, "xcomet_qe_score": 0.7008527517318726, "metricx_score": 7.326698303222656, "metricx_qe_score": 7.667361736297607, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "En tant qu'exercice de vérification de la raison, et parce qu'il s'agit d'un exercice intéressant, nous avons également effectué un test de deux modèles textuels uniquement, GPT1 et GPT2, pour évaluer si Vals est résolvable par ces modèles unimodaux en calculant la perplexité de la légende correcte et de la légende incorrecte, et en prédictant l'entrée avec la perplexité la plus basse.", "metrics": {"bleu_score": 30.103474534834504, "chrf_score": 60.68021662391258, "xcomet_score": 0.4725828766822815, "xcomet_qe_score": 0.43832528591156006, "metricx_score": 8.490778923034668, "metricx_qe_score": 8.282899856567383, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "\"If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\"", "metrics": {"bleu_score": 2.5894304957506913, "chrf_score": 31.142044962861632, "xcomet_score": 0.8396669626235962, "xcomet_qe_score": 0.9181859493255615, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est intéressant de voir que, dans certains cas, les modèles gpt text only ont capturé la plausibilité du monde mieux que les modèles vision et langage.", "metrics": {"bleu_score": 50.304346416105, "chrf_score": 73.76280829931345, "xcomet_score": 0.7767872214317322, "xcomet_qe_score": 0.7982953190803528, "metricx_score": 6.877003192901611, "metricx_qe_score": 7.086651802062988, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, Valsa est un point de référence qui utilise le prisme des constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant leurs capacités de visualisation.", "metrics": {"bleu_score": 43.827912657490714, "chrf_score": 68.04481443253341, "xcomet_score": 0.4681999981403351, "xcomet_qe_score": 0.5629124045372009, "metricx_score": 5.7362961769104, "metricx_qe_score": 6.247791767120361, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que les modèles de vision et de langage identifient bien les objets nommés dans leurs images, comme le montre le morceau d'existence, mais ont du mal à ancrer leur interdépendance et leurs relations dans les scènes visuelles lorsqu'ils sont contraints de respecter les indicateurs linguistiques.", "metrics": {"bleu_score": 48.44905942068554, "chrf_score": 79.5269698158721, "xcomet_score": 0.7260118722915649, "xcomet_qe_score": 0.6804507374763489, "metricx_score": 5.224381923675537, "metricx_qe_score": 6.47426700592041, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "We would really like to encourage the community to use valsa for measuring progress towards language grounding with vision and language models.", "metrics": {"bleu_score": 1.5756171878170462, "chrf_score": 28.149035117652684, "xcomet_score": 0.8058741092681885, "xcomet_qe_score": 0.8339336514472961, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "Et même plus, les valeurs pourraient être utilisées comme une évaluation indirecte de ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou le réglage fin pour voir si un ensemble de données aide les modèles à améliorer sur l'un des aspects testés par les valeurs.", "metrics": {"bleu_score": 39.097740837590266, "chrf_score": 71.43114582736166, "xcomet_score": 0.6214784383773804, "xcomet_qe_score": 0.6700838804244995, "metricx_score": 8.527538299560547, "metricx_qe_score": 7.922500133514404, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "If you're interested, do check out the Valls data on github and if you have any questions, do not hesitate to contact us.", "metrics": {"bleu_score": 3.435812002459847, "chrf_score": 25.46367913769639, "xcomet_score": 0.8139102458953857, "xcomet_qe_score": 0.8290369510650635, "metricx_score": 18.74631118774414, "metricx_qe_score": 16.295124053955078, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Hello, my name is Kamijima from the University of Tokyo.", "metrics": {"bleu_score": 7.495553473355845, "chrf_score": 30.100254781276554, "xcomet_score": 0.5348242521286011, "xcomet_qe_score": 0.8038543462753296, "metricx_score": 16.690996170043945, "metricx_qe_score": 12.17995548248291, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je présenterai un papier intitulé R and S, un ensemble de données à grande échelle pour la correction automatique des erreurs via la résumé des journaux de commit.", "metrics": {"bleu_score": 23.93884406276236, "chrf_score": 53.00171095458689, "xcomet_score": 0.2612987458705902, "xcomet_qe_score": 0.40008968114852905, "metricx_score": 8.973484992980957, "metricx_qe_score": 8.939584732055664, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "I will explain in this order.", "metrics": {"bleu_score": 5.693025330278465, "chrf_score": 15.676097991238894, "xcomet_score": 0.9605584144592285, "xcomet_qe_score": 1.0, "metricx_score": 5.734412670135498, "metricx_qe_score": 2.650315523147583, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "D'abord, je vais présenter la génération automatique de phrases que nous travaillons sur dans cette recherche.", "metrics": {"bleu_score": 38.79454582371661, "chrf_score": 72.11804058835376, "xcomet_score": 0.6929484605789185, "xcomet_qe_score": 0.6753048896789551, "metricx_score": 7.395239353179932, "metricx_qe_score": 6.179142475128174, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "Release note est un document technique qui résume les modifications distribuées avec chaque version d'un produit logiciel.", "metrics": {"bleu_score": 65.11582133926854, "chrf_score": 84.92444031161284, "xcomet_score": 0.8559612035751343, "xcomet_qe_score": 0.8936597108840942, "metricx_score": 3.442875623703003, "metricx_qe_score": 3.771838426589966, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "The image shows the reason note for budget two point six.", "metrics": {"bleu_score": 4.4946920642205725, "chrf_score": 18.207529569501226, "xcomet_score": 0.15664608776569366, "xcomet_qe_score": 0.23732401430606842, "metricx_score": 23.521371841430664, "metricx_qe_score": 22.367389678955078, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "These nodes play an important role in open source development, but they are time-consuming to prepare manually.", "metrics": {"bleu_score": 3.9132106810901734, "chrf_score": 29.882056412815533, "xcomet_score": 0.8452383279800415, "xcomet_qe_score": 0.8863617777824402, "metricx_score": 22.603036880493164, "metricx_qe_score": 20.892621994018555, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, il serait très utile d'être en mesure de générer automatiquement des notes de sortie de haute qualité.", "metrics": {"bleu_score": 57.286689958163855, "chrf_score": 78.98624268025134, "xcomet_score": 0.9059385061264038, "xcomet_qe_score": 0.9149307608604431, "metricx_score": 1.5232330560684204, "metricx_qe_score": 0.9381374716758728, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je me référerai à deux recherches précédentes sur la génération automatique de listes.", "metrics": {"bleu_score": 32.59169224191723, "chrf_score": 60.979235920286875, "xcomet_score": 0.691052258014679, "xcomet_qe_score": 0.6939939856529236, "metricx_score": 5.976779937744141, "metricx_qe_score": 5.339345455169678, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "The first is a system called Arlen, released in 2014.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 14.196136380104695, "xcomet_score": 0.23381555080413818, "xcomet_qe_score": 0.7576813697814941, "metricx_score": 21.34918785095215, "metricx_qe_score": 16.589990615844727, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il adopte un approche basée sur les règles, par exemple, en utilisant l'extracteur de changements pour extraire les différences de code, les modifications de bibliothèques et les modifications de documents des différences entre les versions, et enfin les combiner.", "metrics": {"bleu_score": 40.03641441429754, "chrf_score": 72.37646867951946, "xcomet_score": 0.907243013381958, "xcomet_qe_score": 0.9509096145629883, "metricx_score": 3.261507987976074, "metricx_qe_score": 1.7929670810699463, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus remarquable de ce système est l'extracteur d'issues dans l'angle supérieur droit.", "metrics": {"bleu_score": 41.353009772886615, "chrf_score": 74.74194950565216, "xcomet_score": 0.8560687303543091, "xcomet_qe_score": 0.9012729525566101, "metricx_score": 4.21666145324707, "metricx_qe_score": 5.960497856140137, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "Which must be linked to Jira, the issue tracking system, and can only be applied to projects that use Jira.", "metrics": {"bleu_score": 4.715146411135012, "chrf_score": 22.238753093790663, "xcomet_score": 0.7215760350227356, "xcomet_qe_score": 0.9961528778076172, "metricx_score": 15.104839324951172, "metricx_qe_score": 5.230062961578369, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, il ne peut pas être utilisé pour de nombreux projets sur Github.", "metrics": {"bleu_score": 72.97627709554281, "chrf_score": 86.86379402221719, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.68305903673172, "metricx_qe_score": 0.7658226490020752, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "The second is grief, recently announced in 2020.", "metrics": {"bleu_score": 4.990049701936832, "chrf_score": 20.794152387076686, "xcomet_score": 0.3600233793258667, "xcomet_qe_score": 0.6875368356704712, "metricx_score": 19.008432388305664, "metricx_qe_score": 16.398164749145508, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "2020. It is available on the internet and can be installed via pip.", "metrics": {"bleu_score": 10.511846841633776, "chrf_score": 36.19548445254148, "xcomet_score": 0.4453681707382202, "xcomet_qe_score": 0.6227707266807556, "metricx_score": 25.0, "metricx_qe_score": 24.90896224975586, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système possède un modèle de classification de texte simple et basé sur l'apprentissage, et produit l'une des cinq variables, telles que les fonctionnalités ou les corrections de bugs, pour chaque message de commit d'entrée.", "metrics": {"bleu_score": 38.137481974137245, "chrf_score": 75.05670135969727, "xcomet_score": 0.6777762174606323, "xcomet_qe_score": 0.783149778842926, "metricx_score": 2.8389062881469727, "metricx_qe_score": 2.780019760131836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "The image is a sample usage that returns a corrective or bug fix label.", "metrics": {"bleu_score": 2.923637789252517, "chrf_score": 22.38125439627105, "xcomet_score": 0.949699878692627, "xcomet_qe_score": 1.0, "metricx_score": 17.588281631469727, "metricx_qe_score": 14.343841552734375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "The Coarse-Face training data is fairly small, about five thousand, and will be shown in the experiments described below.", "metrics": {"bleu_score": 2.172142278996916, "chrf_score": 17.553948997076795, "xcomet_score": 0.530312180519104, "xcomet_qe_score": 0.7946421504020691, "metricx_score": 25.0, "metricx_qe_score": 18.07135581970215, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "The performance of the text classification model is not high.", "metrics": {"bleu_score": 3.7159390072518104, "chrf_score": 42.50397477369508, "xcomet_score": 0.9613691568374634, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 24.076751708984375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "I present to you two related researches, but they have problems of limited applicability and scarce data resources.", "metrics": {"bleu_score": 2.276859592073037, "chrf_score": 32.911650123864554, "xcomet_score": 0.8876899480819702, "xcomet_qe_score": 0.91898113489151, "metricx_score": 9.048735618591309, "metricx_qe_score": 8.218195915222168, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Our paper solves these two problems and automatically generates high quality release notes.", "metrics": {"bleu_score": 2.725762876425168, "chrf_score": 28.353691599654653, "xcomet_score": 0.9518171548843384, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le problème de la faible applicabilité, nous proposons un méthode de résumé de classification de haute qualité utilisant uniquement les messages de commit comme entrée.", "metrics": {"bleu_score": 12.286996020967836, "chrf_score": 60.18821258715017, "xcomet_score": 0.8168293833732605, "xcomet_qe_score": 0.8322814702987671, "metricx_score": 6.501153945922852, "metricx_qe_score": 5.614980697631836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "This proposed method can be used for all English book repositories.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 21.81252788806712, "xcomet_score": 0.7646690607070923, "xcomet_qe_score": 1.0, "metricx_score": 22.652814865112305, "metricx_qe_score": 11.99860668182373, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème des ressources de données limitées, nous avons construit un ensemble de données RLNSum composé d'environ 82 000 données en collectant des données à partir de dépôts GitHub publics en utilisant l'API GitHub.", "metrics": {"bleu_score": 50.17580746386066, "chrf_score": 72.65496420318603, "xcomet_score": 0.8869905471801758, "xcomet_qe_score": 0.9257413148880005, "metricx_score": 4.967548847198486, "metricx_qe_score": 4.520993709564209, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Next I describe our dataset.", "metrics": {"bleu_score": 5.815868174415823, "chrf_score": 11.60776448751943, "xcomet_score": 0.9509541988372803, "xcomet_qe_score": 0.9846479892730713, "metricx_score": 6.468189716339111, "metricx_qe_score": 2.1286332607269287, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Here is an example of data.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 16.69823355244291, "xcomet_score": 0.9515331983566284, "xcomet_qe_score": 1.0, "metricx_score": 13.314539909362793, "metricx_qe_score": 9.642425537109375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "The left side is a commit message and the right side is the release notes.", "metrics": {"bleu_score": 2.8403891990720456, "chrf_score": 22.02011968608175, "xcomet_score": 0.9318113327026367, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 24.67322540283203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "The reason notes are labeled as improvements of faces etc.", "metrics": {"bleu_score": 6.9161417925511355, "chrf_score": 18.027085450155315, "xcomet_score": 0.2930472493171692, "xcomet_qe_score": 0.7658257484436035, "metricx_score": 20.585018157958984, "metricx_qe_score": 16.686616897583008, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons configuré une tâche qui prend les messages de commit comme entrée et produit les noms de noeuds étiquetés.", "metrics": {"bleu_score": 30.50265331251898, "chrf_score": 48.63274863501415, "xcomet_score": 0.7201241254806519, "xcomet_qe_score": 0.7069569826126099, "metricx_score": 8.19996452331543, "metricx_qe_score": 7.154079914093018, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "This can be regarded as a summarization task.", "metrics": {"bleu_score": 4.266331692956901, "chrf_score": 11.139471460917607, "xcomet_score": 0.9523214101791382, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 21.963693618774414, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "We have predefined four labels: features, improvements, bug fixes, deprecations, removals, and breaking changes.", "metrics": {"bleu_score": 2.58939299545004, "chrf_score": 18.96516835380801, "xcomet_score": 0.9133012294769287, "xcomet_qe_score": 0.9827963709831238, "metricx_score": 24.46880340576172, "metricx_qe_score": 22.793231964111328, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "These values were set based on previous research and other factors.", "metrics": {"bleu_score": 2.6374077368969155, "chrf_score": 20.497949704925865, "xcomet_score": 0.9443910121917725, "xcomet_qe_score": 1.0, "metricx_score": 23.849008560180664, "metricx_qe_score": 23.21114730834961, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "The lease note on the bottom right and extracted from the lease note shown on the bottom left.", "metrics": {"bleu_score": 2.5277199920920967, "chrf_score": 21.20947881317369, "xcomet_score": 0.34556636214256287, "xcomet_qe_score": 0.7402589321136475, "metricx_score": 15.302183151245117, "metricx_qe_score": 9.480218887329102, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce moment, il est nécessaire de détecter les quatre labbes qui ont été établis à l'avance.", "metrics": {"bleu_score": 48.24766987096574, "chrf_score": 65.06377566610134, "xcomet_score": 0.6978389024734497, "xcomet_qe_score": 0.7064231038093567, "metricx_score": 8.359190940856934, "metricx_qe_score": 7.636834621429443, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "But the labels are not always consistent with each library's.", "metrics": {"bleu_score": 3.42209762272661, "chrf_score": 14.853155570609763, "xcomet_score": 0.5310990810394287, "xcomet_qe_score": 0.9240748286247253, "metricx_score": 25.0, "metricx_qe_score": 23.500097274780273, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le niveau d'amélioration inclut des améliorations, des améliorations, des optimisations, etc.", "metrics": {"bleu_score": 53.816073893351884, "chrf_score": 70.32108023037293, "xcomet_score": 0.5309059619903564, "xcomet_qe_score": 0.6562962532043457, "metricx_score": 6.398687839508057, "metricx_qe_score": 6.394852638244629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire de nos échelles d'étude pour chacune de ces variations de notation.", "metrics": {"bleu_score": 67.49454888262711, "chrf_score": 75.87547110684484, "xcomet_score": 0.4580041766166687, "xcomet_qe_score": 0.25835734605789185, "metricx_score": 9.025711059570312, "metricx_qe_score": 11.155314445495605, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Use it to detect the release note class and collect the text of the list that follows as the release note sentence for the class.", "metrics": {"bleu_score": 1.5093863149143307, "chrf_score": 25.79772108573809, "xcomet_score": 0.5772649049758911, "xcomet_qe_score": 0.8445093035697937, "metricx_score": 11.77187728881836, "metricx_qe_score": 7.614343166351318, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Next is a commit message.", "metrics": {"bleu_score": 5.484411595600381, "chrf_score": 21.15072151630286, "xcomet_score": 0.3093092441558838, "xcomet_qe_score": 0.992209792137146, "metricx_score": 16.2994384765625, "metricx_qe_score": 10.248659133911133, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Commit messages are not tied to each release.", "metrics": {"bleu_score": 4.062582855427254, "chrf_score": 20.835760514299146, "xcomet_score": 0.8885074853897095, "xcomet_qe_score": 1.0, "metricx_score": 24.86865234375, "metricx_qe_score": 24.628185272216797, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "As shown in the image below, if the current release is version 2.5 to 19, we need to identify.", "metrics": {"bleu_score": 1.3528045453700184, "chrf_score": 16.358313663398356, "xcomet_score": 0.326253205537796, "xcomet_qe_score": 0.6724685430526733, "metricx_score": 22.941791534423828, "metricx_qe_score": 20.33932876586914, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "The previous release version 2.5 to 18 and get it deep. This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "metrics": {"bleu_score": 0.9964194812460634, "chrf_score": 23.85136423760172, "xcomet_score": 0.47365856170654297, "xcomet_qe_score": 0.6094492673873901, "metricx_score": 25.0, "metricx_qe_score": 24.185365676879883, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "We created a heuristic matching rule to get the previous and next versions.", "metrics": {"bleu_score": 2.9275822595890535, "chrf_score": 24.494001754111096, "xcomet_score": 0.9819270372390747, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 24.502286911010742, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Day set analysis.", "metrics": {"bleu_score": 15.97357760615681, "chrf_score": 22.60675358571301, "xcomet_score": 0.32975471019744873, "xcomet_qe_score": 0.81794673204422, "metricx_score": 14.721508026123047, "metricx_qe_score": 11.013893127441406, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "In the end, 7200 repositories.", "metrics": {"bleu_score": 1.2192584915912204, "chrf_score": 5.505421734241868, "xcomet_score": 0.23797136545181274, "xcomet_qe_score": 0.7201589941978455, "metricx_score": 24.39864158630371, "metricx_qe_score": 22.4867000579834, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de tokens de note de sortie est de soixante-trois, ce qui est assez élevé pour une tâche de résumé.", "metrics": {"bleu_score": 60.50483057227279, "chrf_score": 69.99711593653211, "xcomet_score": 0.638359785079956, "xcomet_qe_score": 0.6967886686325073, "metricx_score": 6.099246978759766, "metricx_qe_score": 4.550705909729004, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre de tokens uniques est assez important, à 8 830 000.", "metrics": {"bleu_score": 18.322595730639303, "chrf_score": 34.43648118653287, "xcomet_score": 0.8303156495094299, "xcomet_qe_score": 0.9749196767807007, "metricx_score": 4.325811862945557, "metricx_qe_score": 2.14017653465271, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "Due to the large number of unique class and method names found in the library.", "metrics": {"bleu_score": 2.4110800669854027, "chrf_score": 25.133924232940526, "xcomet_score": 0.5847413539886475, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 20.09113883972168, "metricx_qe_score": 16.18985366821289, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Next, I will explain the proposed method.", "metrics": {"bleu_score": 5.669791110976001, "chrf_score": 26.79014539044599, "xcomet_score": 0.9506179094314575, "xcomet_qe_score": 0.9966390132904053, "metricx_score": 24.344215393066406, "metricx_qe_score": 11.867900848388672, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle d'extraction et d'abstraction de la largeur de classe consiste en deux modules neuronaux.", "metrics": {"bleu_score": 20.14941615706457, "chrf_score": 54.95059377297071, "xcomet_score": 0.7055478096008301, "xcomet_qe_score": 0.7291504740715027, "metricx_score": 5.9184250831604, "metricx_qe_score": 5.779911518096924, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "A classifier using bart or cold bart and a generator using bart.", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 19.001927409131543, "xcomet_score": 0.2981020212173462, "xcomet_qe_score": 0.69407057762146, "metricx_score": 19.536800384521484, "metricx_qe_score": 14.612762451171875, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "D'abord, ces utilise un classificateur pour classifier chaque message de commit en cinq classes de raison note, fonctionnalités, améliorations, corrections de bogues, suppressions, et autres.", "metrics": {"bleu_score": 24.695078865357793, "chrf_score": 59.85394450518703, "xcomet_score": 0.3502630889415741, "xcomet_qe_score": 0.28625431656837463, "metricx_score": 15.913047790527344, "metricx_qe_score": 17.630098342895508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "The commit messages classified as other are discarded.", "metrics": {"bleu_score": 5.0735520042259505, "chrf_score": 26.523679598232285, "xcomet_score": 0.9377412796020508, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 24.198156356811523, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Puis, ceas applique le générateur aux quatre documents de l'orange indépendamment et génère une note de liste pour chaque classe.", "metrics": {"bleu_score": 39.328368415488114, "chrf_score": 67.85765696385513, "xcomet_score": 0.26152095198631287, "xcomet_qe_score": 0.23429973423480988, "metricx_score": 12.509891510009766, "metricx_qe_score": 11.609068870544434, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages de commit et les messages de raison ne sont pas connues.", "metrics": {"bleu_score": 66.43548861507487, "chrf_score": 77.24852071888184, "xcomet_score": 0.6357413530349731, "xcomet_qe_score": 0.6471178531646729, "metricx_score": 11.025132179260254, "metricx_qe_score": 12.13289737701416, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classificateur, nous attribuons des niveaux de confiance à chaque message de commit d'entrée en utilisant les dix premiers caractères de chaque message de commit.", "metrics": {"bleu_score": 51.45116518529189, "chrf_score": 66.27905912129877, "xcomet_score": 0.6119401454925537, "xcomet_qe_score": 0.7873020768165588, "metricx_score": 5.59816837310791, "metricx_qe_score": 4.709239482879639, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "We model the class-wise abstractive summarization approach by two different methods.", "metrics": {"bleu_score": 3.1364240458810366, "chrf_score": 32.50441217222368, "xcomet_score": 0.8758645057678223, "xcomet_qe_score": 0.9891210794448853, "metricx_score": 24.24122428894043, "metricx_qe_score": 18.60994529724121, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons ga single, consiste en un seul réseau de connexion de sexe à sexe et génère un seul texte de message de commit de longue durée.", "metrics": {"bleu_score": 31.08254122668011, "chrf_score": 49.90600869303729, "xcomet_score": 0.06599532067775726, "xcomet_qe_score": 0.0681576207280159, "metricx_score": 18.098793029785156, "metricx_qe_score": 18.93522071838379, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "The output text can be divided into classified segments based on special class-specific endpoint symbols.", "metrics": {"bleu_score": 1.5567102923487885, "chrf_score": 27.07041759704334, "xcomet_score": 0.9308693408966064, "xcomet_qe_score": 0.9344232082366943, "metricx_score": 18.868112564086914, "metricx_qe_score": 10.986370086669922, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "Le deuxième méthode, méthode, que nous appelons csmatch, consiste en quatre réseaux différents, de secteur en secteur, chacun correspondant à l'une des classes de nœuds les plus proches.", "metrics": {"bleu_score": 24.96001284078824, "chrf_score": 57.83297303344097, "xcomet_score": 0.16349396109580994, "xcomet_qe_score": 0.21440425515174866, "metricx_score": 18.832841873168945, "metricx_qe_score": 16.400718688964844, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "Okay, let me explain the experiment.", "metrics": {"bleu_score": 5.795599612995366, "chrf_score": 17.497751021082138, "xcomet_score": 0.8565161228179932, "xcomet_qe_score": 0.9931985139846802, "metricx_score": 13.67519474029541, "metricx_qe_score": 6.029204845428467, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Five methods were compared, CAS, CAS single, CAS multi, clustering and previous study Griffith.", "metrics": {"bleu_score": 5.927827416165384, "chrf_score": 29.19699124153136, "xcomet_score": 0.7450628876686096, "xcomet_qe_score": 0.8522634506225586, "metricx_score": 14.945843696594238, "metricx_qe_score": 9.208000183105469, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation, dans certains cas, ces notes sont sorties dans plusieurs phrases.", "metrics": {"bleu_score": 54.88681296311372, "chrf_score": 72.35538521815059, "xcomet_score": 0.7587660551071167, "xcomet_qe_score": 0.7935377359390259, "metricx_score": 6.4183855056762695, "metricx_qe_score": 6.6498188972473145, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Since it is difficult to calculate the number of sentences as there, they are combined with spaces and treated as one long sentence.", "metrics": {"bleu_score": 1.65345928425853, "chrf_score": 24.679491375811903, "xcomet_score": 0.9247047901153564, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "The view is panoramic when the system outputs a short sentence.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 17.617943891909327, "xcomet_score": 0.23295745253562927, "xcomet_qe_score": 0.7390257716178894, "metricx_score": 22.237186431884766, "metricx_qe_score": 18.72212028503418, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité entraîne un niveau bleu inférieur dans les résultats de l'expérience décrits ci-après.", "metrics": {"bleu_score": 32.821002882577524, "chrf_score": 64.53982197702346, "xcomet_score": 0.9956614971160889, "xcomet_qe_score": 0.9669386744499207, "metricx_score": 2.9464304447174072, "metricx_qe_score": 4.223483562469482, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous calculons également la spécificité, car le rouge et le bleu ne peuvent pas être calculés si les notes de liste sont vides.", "metrics": {"bleu_score": 56.74773954614978, "chrf_score": 77.1815843106548, "xcomet_score": 0.7052921652793884, "xcomet_qe_score": 0.6536128520965576, "metricx_score": 5.78495979309082, "metricx_qe_score": 6.050443649291992, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "A high specificity means that the model correctly outputs an empty text in cases where the release nodes assume empty.", "metrics": {"bleu_score": 1.431306716763, "chrf_score": 21.741901946411623, "xcomet_score": 0.826171338558197, "xcomet_qe_score": 0.9292847514152527, "metricx_score": 25.0, "metricx_qe_score": 24.49490737915039, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Here are the results.", "metrics": {"bleu_score": 8.745825313180626, "chrf_score": 11.36785649859302, "xcomet_score": 0.42638856172561646, "xcomet_qe_score": 1.0, "metricx_score": 10.7799711227417, "metricx_qe_score": 4.641719818115234, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Since the dataset contains email addresses, hash values, etc., we also evaluated the cleaned dataset, which excludes them.", "metrics": {"bleu_score": 8.822535992802631, "chrf_score": 22.849364524838876, "xcomet_score": 0.9803398847579956, "xcomet_qe_score": 0.9959530830383301, "metricx_score": 21.230606079101562, "metricx_qe_score": 22.88079261779785, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "CAS and CAS achieved LRU scores more than ten points higher than the baselines.", "metrics": {"bleu_score": 2.330576016181471, "chrf_score": 21.188437947996263, "xcomet_score": 0.3933039903640747, "xcomet_qe_score": 0.7652866840362549, "metricx_score": 20.880857467651367, "metricx_qe_score": 16.463022232055664, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur le set de test propre, l'écart de score entre le méthode proposée et la base est de plus de 20%.", "metrics": {"bleu_score": 42.18427481900357, "chrf_score": 65.77679840511699, "xcomet_score": 0.6644377112388611, "xcomet_qe_score": 0.5198121070861816, "metricx_score": 7.613762378692627, "metricx_qe_score": 9.411623001098633, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "This result indicates that GHS and GHS have significant effects.", "metrics": {"bleu_score": 3.124719790499494, "chrf_score": 14.666896098778306, "xcomet_score": 0.22579260170459747, "xcomet_qe_score": 0.6465182304382324, "metricx_score": 17.864347457885742, "metricx_qe_score": 16.642911911010742, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "CAS got a better ROC score than CAS, suggesting that combining a classifier and a generator is effective in training the classifier using pseudo labels.", "metrics": {"bleu_score": 2.6931035230034044, "chrf_score": 25.76990305074631, "xcomet_score": 0.40507203340530396, "xcomet_qe_score": 0.6104719638824463, "metricx_score": 24.056549072265625, "metricx_qe_score": 20.76419448852539, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "The high coverage of CAS can be achieved properly because the classifier can focus on selecting relevant commit messages for each class.", "metrics": {"bleu_score": 1.645633343998552, "chrf_score": 24.64355677859463, "xcomet_score": 0.6118261218070984, "xcomet_qe_score": 0.8151559829711914, "metricx_score": 22.931652069091797, "metricx_qe_score": 17.161052703857422, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "The casemache tended to be higher, larger than the casemate.", "metrics": {"bleu_score": 2.8666091494718775, "chrf_score": 10.875716389225058, "xcomet_score": 0.20827937126159668, "xcomet_qe_score": 0.5251896381378174, "metricx_score": 25.0, "metricx_qe_score": 20.96487808227539, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each e-s notebook class.", "metrics": {"bleu_score": 3.4440626489727304, "chrf_score": 34.71994874953047, "xcomet_score": 0.7181921005249023, "xcomet_qe_score": 0.8768567442893982, "metricx_score": 23.73369598388672, "metricx_qe_score": 19.933422088623047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "Hear and error analysis.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 26.317877250883477, "xcomet_score": 0.3818272054195404, "xcomet_qe_score": 0.9321024417877197, "metricx_score": 12.412809371948242, "metricx_qe_score": 9.730535507202148, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes de CS tendent à produire des phrases plus courtes que les phrases de référence humaines.", "metrics": {"bleu_score": 73.51460991014885, "chrf_score": 84.29966029256819, "xcomet_score": 0.7814168930053711, "xcomet_qe_score": 0.7120217084884644, "metricx_score": 4.455237865447998, "metricx_qe_score": 4.559440612792969, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure de la droite, la phrase de référence a trois ou quatre phrases, tandis que cs a seulement une.", "metrics": {"bleu_score": 67.7593999948928, "chrf_score": 80.5827110115235, "xcomet_score": 0.7527093887329102, "xcomet_qe_score": 0.5764150619506836, "metricx_score": 8.02233600616455, "metricx_qe_score": 7.858319282531738, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette réticence du modèle est que, dans les données d'entraînement, seulement 33 % des phrases sont présentes au niveau des caractéristiques et 40 % au niveau des améliorations.", "metrics": {"bleu_score": 17.576877022645164, "chrf_score": 51.564292428904125, "xcomet_score": 0.7478228807449341, "xcomet_qe_score": 0.9347677230834961, "metricx_score": 3.147296190261841, "metricx_qe_score": 2.471304416656494, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes CAS ne peuvent pas générer des notes d'agrégation sans informations supplémentaires.", "metrics": {"bleu_score": 61.916913497995004, "chrf_score": 76.60941215201751, "xcomet_score": 0.7743791341781616, "xcomet_qe_score": 0.74139404296875, "metricx_score": 6.184029579162598, "metricx_qe_score": 5.217300891876221, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut à droite est un exemple d'un message de commit très désordonné. Et la phrase complète ne peut pas être générée sans référence à la requête ou au problème correspondant.", "metrics": {"bleu_score": 58.06656905707533, "chrf_score": 78.20957866960975, "xcomet_score": 0.8501665592193604, "xcomet_qe_score": 0.8907511830329895, "metricx_score": 4.0333991050720215, "metricx_qe_score": 3.680068254470825, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous montre que les deux messages de commit dans l'entrée sont liés et devraient être combinés en une seule phrase, mais il échoue à le faire.", "metrics": {"bleu_score": 41.4337303262533, "chrf_score": 68.30593885734584, "xcomet_score": 0.876250147819519, "xcomet_qe_score": 0.8922393321990967, "metricx_score": 5.82338285446167, "metricx_qe_score": 5.501931190490723, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Finally, a conclusion.", "metrics": {"bleu_score": 15.848738972120703, "chrf_score": 44.737984264318655, "xcomet_score": 0.7679756879806519, "xcomet_qe_score": 1.0, "metricx_score": 18.786991119384766, "metricx_qe_score": 16.856294631958008, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "We have built a new dataset for automatic phrase node generation.", "metrics": {"bleu_score": 2.6374077368969155, "chrf_score": 22.13606331999377, "xcomet_score": 0.691457986831665, "xcomet_qe_score": 0.7982283234596252, "metricx_score": 22.994403839111328, "metricx_qe_score": 10.184820175170898, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également formulé la tâche d'entrer des messages de commit et de les résumer, de manière à ce qu'elle soit applicable à tous les projets écrits en anglais.", "metrics": {"bleu_score": 36.925980201474815, "chrf_score": 62.45647455618444, "xcomet_score": 0.7237942814826965, "xcomet_qe_score": 0.7657114267349243, "metricx_score": 5.4860076904296875, "metricx_qe_score": 5.637287616729736, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Notre expérience montre que le procédé proposé génère des notes de risque moins bruyantes à une couverture plus élevée que les méthodes de base.", "metrics": {"bleu_score": 43.01606518769334, "chrf_score": 71.4765087762822, "xcomet_score": 0.6829321384429932, "xcomet_qe_score": 0.5718588829040527, "metricx_score": 6.292077541351318, "metricx_qe_score": 5.796542167663574, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Please check out our desert oasis on the top.", "metrics": {"bleu_score": 4.196114906296549, "chrf_score": 12.675175175175177, "xcomet_score": 0.17671021819114685, "xcomet_qe_score": 0.4937800467014313, "metricx_score": 20.83987808227539, "metricx_qe_score": 16.828712463378906, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 2.525252525252525, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.110304355621338, "metricx_qe_score": 0.48872482776641846, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Hello, my name is Safar Ali.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 13.552715325769224, "xcomet_score": 0.14368411898612976, "xcomet_qe_score": 0.19259926676750183, "metricx_score": 14.357641220092773, "metricx_qe_score": 8.187727928161621, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "Et je présenterai notre papier, future tabular data enrichment using fine-tuning transformers architectures.", "metrics": {"bleu_score": 3.9195460349665643, "chrf_score": 36.22671610780423, "xcomet_score": 0.5562844276428223, "xcomet_qe_score": 0.7126115560531616, "metricx_score": 11.758256912231445, "metricx_qe_score": 11.428763389587402, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Data scientists analyze data and mainly focus on manipulating the data's existing features.", "metrics": {"bleu_score": 2.1340743160056204, "chrf_score": 25.88868443862359, "xcomet_score": 0.9716144800186157, "xcomet_qe_score": 0.9829064607620239, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "But sometimes these features are limited.", "metrics": {"bleu_score": 5.693025330278465, "chrf_score": 16.17902203407641, "xcomet_score": 0.9883681535720825, "xcomet_qe_score": 0.9976193904876709, "metricx_score": 25.0, "metricx_qe_score": 23.2288761138916, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "Feature generation using another data source may add substantial information.", "metrics": {"bleu_score": 2.583112439191653, "chrf_score": 32.08509393791441, "xcomet_score": 0.9094783067703247, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Our research goal is automatic tabular data enrichment using external sources of free text.", "metrics": {"bleu_score": 2.393672168921959, "chrf_score": 29.691920252997818, "xcomet_score": 0.9819110631942749, "xcomet_qe_score": 0.9935675859451294, "metricx_score": 25.0, "metricx_qe_score": 22.622896194458008, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Suppose we have a tabular dataset and a knowledge base.", "metrics": {"bleu_score": 3.7159390072518104, "chrf_score": 22.214927315585754, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 24.1546630859375, "metricx_qe_score": 23.633676528930664, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "We need an automatic process which involve entity linking and text analysis to extract new features from the knowledge base free text.", "metrics": {"bleu_score": 1.5085799832618616, "chrf_score": 25.350839089327774, "xcomet_score": 0.909629225730896, "xcomet_qe_score": 0.9380192756652832, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Our framework first is exactly this automatic process.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 32.614438490902266, "xcomet_score": 0.7193058729171753, "xcomet_qe_score": 0.8076381683349609, "metricx_score": 18.454240798950195, "metricx_qe_score": 14.16227912902832, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "So let's see an example in a data set fed into fast.", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 14.72842779504492, "xcomet_score": 0.6510986089706421, "xcomet_qe_score": 0.8553993105888367, "metricx_score": 20.379337310791016, "metricx_qe_score": 15.355006217956543, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "In this example, the dataset is university dataset.", "metrics": {"bleu_score": 4.515183688171633, "chrf_score": 26.74366869196505, "xcomet_score": 0.9443535208702087, "xcomet_qe_score": 0.9715653657913208, "metricx_score": 23.835817337036133, "metricx_qe_score": 18.12618064880371, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "When its goal is to classify universities into low-ranked universities and high-ranked universities.", "metrics": {"bleu_score": 1.9869571647551538, "chrf_score": 35.14408974973237, "xcomet_score": 0.9914897680282593, "xcomet_qe_score": 0.9253767132759094, "metricx_score": 24.12012481689453, "metricx_qe_score": 24.74163818359375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "As knowledge base we use Wikipedia.", "metrics": {"bleu_score": 4.410363736106611, "chrf_score": 18.617989966098573, "xcomet_score": 0.9861994981765747, "xcomet_qe_score": 1.0, "metricx_score": 14.864158630371094, "metricx_qe_score": 13.528685569763184, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "The first phase of fist is entity linking.", "metrics": {"bleu_score": 5.0735520042259505, "chrf_score": 18.989502613744744, "xcomet_score": 0.6158894300460815, "xcomet_qe_score": 0.8122814297676086, "metricx_score": 24.333250045776367, "metricx_qe_score": 17.974058151245117, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "metrics": {"bleu_score": 2.024173370761941, "chrf_score": 24.513583959576803, "xcomet_score": 0.9957163333892822, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "And the text of the entities of the knowledge base is extracted and added to the dataset.", "metrics": {"bleu_score": 2.5540496664715904, "chrf_score": 24.326425383166796, "xcomet_score": 0.9414200782775879, "xcomet_qe_score": 0.991266131401062, "metricx_score": 24.019424438476562, "metricx_qe_score": 22.09562110900879, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "In this example, the text is the Wikipedia page abstract.", "metrics": {"bleu_score": 3.7726698069117846, "chrf_score": 29.46906141419527, "xcomet_score": 0.9349721670150757, "xcomet_qe_score": 1.0, "metricx_score": 21.69935417175293, "metricx_qe_score": 15.902045249938965, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Now we need to generate or extract features from the retrieved text.", "metrics": {"bleu_score": 2.6485681362909563, "chrf_score": 19.009821628441532, "xcomet_score": 0.8890489339828491, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 22.016536712646484, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc besoin d'une phase d'extraction de fonctionnalités, qui inclut l'analyse de texte.", "metrics": {"bleu_score": 35.218565358232354, "chrf_score": 71.1124246177534, "xcomet_score": 0.8827849626541138, "xcomet_qe_score": 0.8955923914909363, "metricx_score": 3.623997688293457, "metricx_qe_score": 3.975536584854126, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "And this is the main novelty of this paper, and I will deep dive into it in the next slides.", "metrics": {"bleu_score": 1.727223799216787, "chrf_score": 16.521286516830266, "xcomet_score": 0.9409810304641724, "xcomet_qe_score": 0.9978008270263672, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des fonctionnalités, il y a une phase de génération de fonctionnalités, où nous utilisons les fonctionnalités extraites pour générer un petit nombre de nouvelles fonctionnalités.", "metrics": {"bleu_score": 61.14887872946488, "chrf_score": 87.1023757773103, "xcomet_score": 0.9920938014984131, "xcomet_qe_score": 0.9996260404586792, "metricx_score": 1.1880669593811035, "metricx_qe_score": 1.386305332183838, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "First, generate features in the number of classes of the original dataset.", "metrics": {"bleu_score": 3.377156414337854, "chrf_score": 21.258826303414597, "xcomet_score": 0.7925273776054382, "xcomet_qe_score": 0.9496772289276123, "metricx_score": 11.165583610534668, "metricx_qe_score": 6.347663402557373, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "In this example, the original dataset has two classes.", "metrics": {"bleu_score": 8.29519350710986, "chrf_score": 30.900346860902644, "xcomet_score": 0.9876155853271484, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 23.675682067871094, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, il génère rapidement deux nouvelles fonctionnalités.", "metrics": {"bleu_score": 11.99014838091355, "chrf_score": 58.02708448742659, "xcomet_score": 0.6289045810699463, "xcomet_qe_score": 0.7729066610336304, "metricx_score": 4.673801422119141, "metricx_qe_score": 6.4701056480407715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "But if the dataset has five classes, first generate five new features.", "metrics": {"bleu_score": 6.285596338261262, "chrf_score": 17.55134262002274, "xcomet_score": 0.5212376117706299, "xcomet_qe_score": 0.8261669278144836, "metricx_score": 24.230405807495117, "metricx_qe_score": 21.322607040405273, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Each feature represents the likelihood for each class.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 20.878232190366006, "xcomet_score": 0.9040762186050415, "xcomet_qe_score": 1.0, "metricx_score": 25.0, "metricx_qe_score": 23.814733505249023, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "To analyze the text, we use the current state of the art of text analysis, which are transformer-based language models such as bert, gpt, xlnet, and et cetera.", "metrics": {"bleu_score": 1.6276888006478718, "chrf_score": 23.314891672245857, "xcomet_score": 0.8461258411407471, "xcomet_qe_score": 0.903842568397522, "metricx_score": 11.293039321899414, "metricx_qe_score": 9.422637939453125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "But it is not likely that we can train language model using the input datasets.", "metrics": {"bleu_score": 1.9046304733974748, "chrf_score": 15.201857073488902, "xcomet_score": 0.9517618417739868, "xcomet_qe_score": 0.9791598916053772, "metricx_score": 21.300270080566406, "metricx_qe_score": 16.250688552856445, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Un approche naïve sera donc une tâche de réglage de cible.", "metrics": {"bleu_score": 16.40212036255558, "chrf_score": 47.8555692253639, "xcomet_score": 0.6359210014343262, "xcomet_qe_score": 0.7031620740890503, "metricx_score": 8.729246139526367, "metricx_qe_score": 9.476701736450195, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans la phase d'extraction des caractéristiques, nous pouvons télécharger le modèle de langage pré-entraîné, affiner le modèle de langage sur le jeu de données cible.", "metrics": {"bleu_score": 20.66736214472914, "chrf_score": 67.17336478902348, "xcomet_score": 0.8337582349777222, "xcomet_qe_score": 0.8788563013076782, "metricx_score": 2.104710817337036, "metricx_qe_score": 1.7723172903060913, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, pour affiner le modèle de langue, pour classifier, pour classifier le texte en classes, abstraire en classes, basse ou haute.", "metrics": {"bleu_score": 37.368363717256074, "chrf_score": 73.57609713870812, "xcomet_score": 0.34184932708740234, "xcomet_qe_score": 0.4518616199493408, "metricx_score": 7.736403465270996, "metricx_qe_score": 8.08815860748291, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "Receive the language model output, which is the likelihood for each class, and use as new features.", "metrics": {"bleu_score": 2.060187754521775, "chrf_score": 19.735577061846225, "xcomet_score": 0.8643441200256348, "xcomet_qe_score": 0.9951825141906738, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "The problem with this approach is that the dataset may have few distinct entities tags.", "metrics": {"bleu_score": 1.998855581795249, "chrf_score": 24.452349701859386, "xcomet_score": 0.9076536893844604, "xcomet_qe_score": 0.9160535931587219, "metricx_score": 16.70838165283203, "metricx_qe_score": 10.096424102783203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "In our experiment, almost half of the data sets contain less than four hundred samples, and the smallest data set contains thirty-five samples in its initial training set.", "metrics": {"bleu_score": 1.4262733286728257, "chrf_score": 18.947964163072783, "xcomet_score": 0.9467885494232178, "xcomet_qe_score": 0.9540905952453613, "metricx_score": 14.50053882598877, "metricx_qe_score": 6.301040172576904, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, affiner un modèle de langage sur ce jeu de données sera inefficace.", "metrics": {"bleu_score": 11.310598110843994, "chrf_score": 58.57535158633434, "xcomet_score": 0.9494010210037231, "xcomet_qe_score": 0.9507580995559692, "metricx_score": 1.8491480350494385, "metricx_qe_score": 1.5158040523529053, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "But we can use prior knowledge about pre-analyzed data sets.", "metrics": {"bleu_score": 3.42209762272661, "chrf_score": 14.82780169228425, "xcomet_score": 0.9846490621566772, "xcomet_qe_score": 1.0, "metricx_score": 21.17841148376465, "metricx_qe_score": 13.95278549194336, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Because fast is we apply fast over a multiple data set, we can use the n minus one data sets to gather information about the n minus one data sets and use this information when we analyze the nth data set.", "metrics": {"bleu_score": 1.205256842736819, "chrf_score": 23.31720491843611, "xcomet_score": 0.63063645362854, "xcomet_qe_score": 0.697043776512146, "metricx_score": 16.406558990478516, "metricx_qe_score": 11.449352264404297, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "What we suggest is to add to add another fine-tuning phase.", "metrics": {"bleu_score": 3.7052472057637615, "chrf_score": 18.697894116231605, "xcomet_score": 0.3389139771461487, "xcomet_qe_score": 0.7076236605644226, "metricx_score": 23.214033126831055, "metricx_qe_score": 18.988603591918945, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "Eh, preliminary multi-task fine-tuning phase.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 30.01468898421314, "xcomet_score": 0.7645609378814697, "xcomet_qe_score": 0.8851447105407715, "metricx_score": 20.870769500732422, "metricx_qe_score": 12.224722862243652, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "When you fine-tune the language model over n minus one datasets.", "metrics": {"bleu_score": 3.4089919964838553, "chrf_score": 23.110138133926352, "xcomet_score": 0.9988504648208618, "xcomet_qe_score": 1.0, "metricx_score": 21.89189910888672, "metricx_qe_score": 22.625808715820312, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Et puis, nous exécutons une autre phase de réglage fin, qui est un réglage de la tâche cible, lorsque nous réglons le modèle de langue sur le cinquième ensemble de données de cible.", "metrics": {"bleu_score": 39.051508781145074, "chrf_score": 64.06471472028025, "xcomet_score": 0.5193401575088501, "xcomet_qe_score": 0.43107083439826965, "metricx_score": 8.041842460632324, "metricx_qe_score": 9.961671829223633, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "The state of the art in multitask multitask fine-tuning called mTDDNN.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 24.565683635256036, "xcomet_score": 0.632565975189209, "xcomet_qe_score": 0.8520338535308838, "metricx_score": 15.55661392211914, "metricx_qe_score": 12.677755355834961, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "In MT-DNN, MT-DNN maintain heads in the number of tasks in the training set.", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 18.731665544698544, "xcomet_score": 0.4148106873035431, "xcomet_qe_score": 0.8415931463241577, "metricx_score": 22.748567581176758, "metricx_qe_score": 18.680727005004883, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "O in this example, there are four tasks in the training set, so empty dnn and maintain four heads, as you can see at the image.", "metrics": {"bleu_score": 1.633898440122165, "chrf_score": 19.785962868682606, "xcomet_score": 0.5693777203559875, "xcomet_qe_score": 0.7507708072662354, "metricx_score": 21.775827407836914, "metricx_qe_score": 17.614158630371094, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "Et il échantillonne un lot aléatoire du jeu de formation.", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 76.49375083834039, "xcomet_score": 0.6655606031417847, "xcomet_qe_score": 0.27266597747802734, "metricx_score": 3.3705832958221436, "metricx_qe_score": 4.770931243896484, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot de données de test appartient à, par exemple, des tâches de classification de phrases en singulier, il est exécuté en avant et en arrière à travers la première tête.", "metrics": {"bleu_score": 29.146989838533948, "chrf_score": 56.65271103499057, "xcomet_score": 0.6306062936782837, "xcomet_qe_score": 0.6803861856460571, "metricx_score": 6.882318019866943, "metricx_qe_score": 6.684559345245361, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Et si la tranche aléatoire appartient à la classification par paires, une tâche est exécutée en descendant et en remontant le chemin jusqu'à la dernière tête.", "metrics": {"bleu_score": 20.664181816537027, "chrf_score": 54.73178961807743, "xcomet_score": 0.5491763353347778, "xcomet_qe_score": 0.5987206697463989, "metricx_score": 6.586589336395264, "metricx_qe_score": 7.237678050994873, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, un ensemble de données tabulaire varie en nombre de classes.", "metrics": {"bleu_score": 33.88714363186177, "chrf_score": 71.84317814781396, "xcomet_score": 0.9884172677993774, "xcomet_qe_score": 0.978740930557251, "metricx_score": 4.1334614753723145, "metricx_qe_score": 4.881061553955078, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "So there are many tasks.", "metrics": {"bleu_score": 5.815868174415823, "chrf_score": 10.50727259570157, "xcomet_score": 0.9229397177696228, "xcomet_qe_score": 1.0, "metricx_score": 24.367856979370117, "metricx_qe_score": 18.6107177734375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "Mtdnn maintains the number of classes, heads, output layers.", "metrics": {"bleu_score": 4.941373395476232, "chrf_score": 24.11450660287952, "xcomet_score": 0.8293372392654419, "xcomet_qe_score": 0.9264624118804932, "metricx_score": 20.06549835205078, "metricx_qe_score": 13.584919929504395, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, mdnn doit initialiser de nouvelles têtes pour un nouveau jeu de données avec une nouvelle tâche.", "metrics": {"bleu_score": 49.030470692026626, "chrf_score": 70.77098205940949, "xcomet_score": 0.7825239896774292, "xcomet_qe_score": 0.70412278175354, "metricx_score": 6.478283882141113, "metricx_qe_score": 6.125823497772217, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche, appelée task reformulation fine tuning, est que, dans notre approche, task reformulation fine tuning, au lieu de maintenir plusieurs têtes, nous reformulons chaque ensemble de données en un problème de classification de phrase par phrase, qui est un problème de deux classes.", "metrics": {"bleu_score": 30.543002726379697, "chrf_score": 68.10002060682092, "xcomet_score": 0.3628418743610382, "xcomet_qe_score": 0.36901673674583435, "metricx_score": 12.030749320983887, "metricx_qe_score": 11.297894477844238, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "So let's see an example.", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 21.07674831508111, "xcomet_score": 0.6541913747787476, "xcomet_qe_score": 1.0, "metricx_score": 19.918973922729492, "metricx_qe_score": 13.044326782226562, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Here is our input dataset, which consists of entities, features, text, and classes.", "metrics": {"bleu_score": 4.832054932113933, "chrf_score": 24.922299435160543, "xcomet_score": 0.8779569864273071, "xcomet_qe_score": 1.0, "metricx_score": 19.134201049804688, "metricx_qe_score": 15.03557014465332, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous reformulons la tâche de classifier le texte en bas et en haut pour classer le texte, l'abstract et la classe en vrai ou faux.", "metrics": {"bleu_score": 54.563506431020485, "chrf_score": 70.19816883326823, "xcomet_score": 0.6948819160461426, "xcomet_qe_score": 0.5571293830871582, "metricx_score": 8.237915992736816, "metricx_qe_score": 8.069703102111816, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous entraînons le modèle de langage pour classer une classe abstraite en classe abstraite si l'abstraction appartient à la classe ou non.", "metrics": {"bleu_score": 25.81912525064455, "chrf_score": 55.75727947221672, "xcomet_score": 0.32481813430786133, "xcomet_qe_score": 0.4003642797470093, "metricx_score": 11.701494216918945, "metricx_qe_score": 12.637674331665039, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le vecteur étiqueté dans ce cas particulier reste toujours, qui consiste toujours en deux classes.", "metrics": {"bleu_score": 38.021155610492436, "chrf_score": 70.44216196553388, "xcomet_score": 0.4478096663951874, "xcomet_qe_score": 0.5438176393508911, "metricx_score": 8.721843719482422, "metricx_qe_score": 10.575042724609375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et cet est l'algorithme pour notre approche de réglage fin reformulée.", "metrics": {"bleu_score": 16.21599014882373, "chrf_score": 57.44810009004784, "xcomet_score": 0.8978704214096069, "xcomet_qe_score": 0.9324882626533508, "metricx_score": 7.701265335083008, "metricx_qe_score": 9.493281364440918, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "O let's see the full framework.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 11.511614816814287, "xcomet_score": 0.5503563284873962, "xcomet_qe_score": 0.9555210471153259, "metricx_score": 16.321462631225586, "metricx_qe_score": 12.163583755493164, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "A dataset fades in too fast. A.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 10.701837599717388, "xcomet_score": 0.14089365303516388, "xcomet_qe_score": 0.15781298279762268, "metricx_score": 22.744401931762695, "metricx_qe_score": 15.621891975402832, "linguapy_score": [1, "ESTONIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "And then a fast execute entity linking phase.", "metrics": {"bleu_score": 5.669791110976001, "chrf_score": 23.20559522690547, "xcomet_score": 0.6794312000274658, "xcomet_qe_score": 0.784534215927124, "metricx_score": 19.195344924926758, "metricx_qe_score": 14.921003341674805, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "It extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "metrics": {"bleu_score": 2.448896697858474, "chrf_score": 25.95225369561186, "xcomet_score": 0.9638146162033081, "xcomet_qe_score": 0.9721469879150391, "metricx_score": 22.906084060668945, "metricx_qe_score": 17.46430206298828, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "Then it reformulates the task into a sentence pair classification task.", "metrics": {"bleu_score": 2.9381581998927433, "chrf_score": 36.93506456731352, "xcomet_score": 0.7846595048904419, "xcomet_qe_score": 0.9381982684135437, "metricx_score": 19.621843338012695, "metricx_qe_score": 12.02575397491455, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "Apply the language model to the new task and output likelihood for each class.", "metrics": {"bleu_score": 1.8830168484966994, "chrf_score": 20.581976933611752, "xcomet_score": 0.7811084985733032, "xcomet_qe_score": 0.9645982980728149, "metricx_score": 21.993364334106445, "metricx_qe_score": 15.389891624450684, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Note that the language model is already fine-tuned over n minus one dataset using a preliminary multi-task fine-tuning.", "metrics": {"bleu_score": 1.950443326499412, "chrf_score": 25.391874291361354, "xcomet_score": 0.8667944073677063, "xcomet_qe_score": 0.9734222888946533, "metricx_score": 16.880962371826172, "metricx_qe_score": 7.758019924163818, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "metrics": {"bleu_score": 3.302210650832087, "chrf_score": 22.02358852597922, "xcomet_score": 0.9062379002571106, "xcomet_qe_score": 0.8957700729370117, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "To evaluate our framework, we use a seventeen tabular classification dataset, which varies in size, features, balance, domain, and initial performance.", "metrics": {"bleu_score": 2.172054551709621, "chrf_score": 37.5543277659314, "xcomet_score": 0.7624690532684326, "xcomet_qe_score": 0.929519772529602, "metricx_score": 24.546871185302734, "metricx_qe_score": 22.408689498901367, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "And as knowledge base we use Wikipedia.", "metrics": {"bleu_score": 3.983253478176822, "chrf_score": 18.781189803359577, "xcomet_score": 0.9728206396102905, "xcomet_qe_score": 1.0, "metricx_score": 22.86846160888672, "metricx_qe_score": 18.606225967407227, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "We design our experiment as leave one out, an evaluation when we train fast over sixteen datasets and apply it to the seventeenth dataset.", "metrics": {"bleu_score": 1.4445809981770859, "chrf_score": 20.88338787409533, "xcomet_score": 0.560197114944458, "xcomet_qe_score": 0.7860441207885742, "metricx_score": 19.55709457397461, "metricx_qe_score": 15.646950721740723, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "We also split each data set into a fold and apply a fold cross-validation.", "metrics": {"bleu_score": 2.299921972415939, "chrf_score": 21.47983983244974, "xcomet_score": 0.40812769532203674, "xcomet_qe_score": 0.7690070867538452, "metricx_score": 13.181955337524414, "metricx_qe_score": 9.127598762512207, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Then we generate the new features and evaluate them using five evaluation classifiers.", "metrics": {"bleu_score": 2.4617934274488045, "chrf_score": 24.34328918343844, "xcomet_score": 0.9505280256271362, "xcomet_qe_score": 0.9990553855895996, "metricx_score": 25.0, "metricx_qe_score": 23.88465118408203, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "We use in our experiment based bird based architecture.", "metrics": {"bleu_score": 2.0837289954869336, "chrf_score": 19.3952966965306, "xcomet_score": 0.24463675916194916, "xcomet_qe_score": 0.781181275844574, "metricx_score": 20.89708709716797, "metricx_qe_score": 15.360763549804688, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Here are the results for our experiment.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 16.93970660111552, "xcomet_score": 0.9578968286514282, "xcomet_qe_score": 0.9910026788711548, "metricx_score": 14.033044815063477, "metricx_qe_score": 14.141873359680176, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "You can see that we compare our framework to target dataset fine-tuning, target task fine-tuning, and a mtcnn preliminary fine-tuning.", "metrics": {"bleu_score": 1.645633343998552, "chrf_score": 20.60160415595764, "xcomet_score": 0.8164927959442139, "xcomet_qe_score": 0.8305953741073608, "metricx_score": 23.98138427734375, "metricx_qe_score": 20.037372589111328, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "And our reformulated fine-tuning achieve the best result, the best performance.", "metrics": {"bleu_score": 6.178110636313396, "chrf_score": 33.40315599275322, "xcomet_score": 0.921737551689148, "xcomet_qe_score": 0.9613531827926636, "metricx_score": 20.43292999267578, "metricx_qe_score": 21.299591064453125, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "While mtdnn achieved two percent improvement over the target dataset fine-tuning.", "metrics": {"bleu_score": 1.7386863385674487, "chrf_score": 17.185346325653864, "xcomet_score": 0.9052777290344238, "xcomet_qe_score": 0.9351884722709656, "metricx_score": 25.0, "metricx_qe_score": 24.826032638549805, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "Our poach achieved six percent improvement.", "metrics": {"bleu_score": 4.410363736106611, "chrf_score": 21.370294390032445, "xcomet_score": 0.6292093992233276, "xcomet_qe_score": 0.8074094653129578, "metricx_score": 25.0, "metricx_qe_score": 23.202058792114258, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "\"When we look on the small data set, we can see that the performance of MT-DNN decreases and the improvement of the preliminary multi-task fine-tuning phase decreases to 1.5%.\"", "metrics": {"bleu_score": 1.5393730252811677, "chrf_score": 24.97293653000069, "xcomet_score": 0.8168238401412964, "xcomet_qe_score": 0.8690710067749023, "metricx_score": 8.862799644470215, "metricx_qe_score": 6.951469421386719, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "But our performance increased to eleven percent compared to the target task fine-tuning alone.", "metrics": {"bleu_score": 2.7350835735481263, "chrf_score": 35.09509101368568, "xcomet_score": 0.9516613483428955, "xcomet_qe_score": 0.9239453673362732, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "For summing, fast enables few-shot enrichment from thirty five samples in our experiment.", "metrics": {"bleu_score": 2.393672168921959, "chrf_score": 19.25267482911416, "xcomet_score": 0.6213236451148987, "xcomet_qe_score": 0.7415028810501099, "metricx_score": 23.317163467407227, "metricx_qe_score": 20.69426155090332, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "It uses one architecture for all tasks, datasets.", "metrics": {"bleu_score": 4.515183688171633, "chrf_score": 32.62569950514382, "xcomet_score": 0.9664733409881592, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 24.160425186157227, "metricx_qe_score": 20.487512588500977, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "And he keeps the head of the model.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 12.99971165610668, "xcomet_score": 0.8161413669586182, "xcomet_qe_score": 0.787628173828125, "metricx_score": 14.860369682312012, "metricx_qe_score": 17.949615478515625, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "But it adds a reformulation phase.", "metrics": {"bleu_score": 7.492442692259767, "chrf_score": 42.31742082941333, "xcomet_score": 0.9953646659851074, "xcomet_qe_score": 0.9968031644821167, "metricx_score": 21.272260665893555, "metricx_qe_score": 17.69023323059082, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "It's augmented the training set and it's needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "metrics": {"bleu_score": 1.3093533030128615, "chrf_score": 29.4934631164598, "xcomet_score": 0.7884677648544312, "xcomet_qe_score": 0.8947531580924988, "metricx_score": 20.9930362701416, "metricx_qe_score": 18.025033950805664, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Thank you.", "metrics": {"bleu_score": 0.0, "chrf_score": 2.525252525252525, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.110304355621338, "metricx_qe_score": 0.48872482776641846, "linguapy_score": [1, "ENGLISH"]}}
