{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我想谈谈我们对于推理的动机。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们展示了一个多步骤推理有帮助的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，最好将可解释的多步骤推理作为输出。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "某些假设也适用于之前的工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设数量的精确度是已知的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，复杂的运算符实际上可以分解成这些基本运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "传统的序列到序列模型将表达式转换为特定的序列以进行生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这很容易实现，可以概括成许多不同的复杂问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但因为转换器模型的原因，实际上这个方向仍然很受欢迎。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，其中还包含一些重复的计算。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在第二步中，我们可以得到这些除数，即27。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也可以回头参考原始问题来查找相关内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这些步骤中，我们得到了除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后在第三步，我们实际上得到了商。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这使得这个过程更加准确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "表达式由e i j o p表示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在这里也有减法与单词代表相反的方向。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这与关系提取 非常相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们把它添加到下一个状态，成为一个新的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一旦我们得到数量陈述，我们就可以开始做推理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们得到表达式表达q_1除以q_2。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里所有可能的表达式等于运算符数量的三倍。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，这个数量来自之前计算的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终可以得到最后这个表达式q_3乘以q_4。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还可以看到，所有可能的表达式的数字与之前的步骤不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它还允许我们根据先前的知识施加某些约束。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们简要地展示了与之前最佳方法相比的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们表现最好的变体是Roberta-DeductiveReasoner。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "没错。最好的方法通常是基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总的来说，我们的推理能够显著优于这个基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以看到，MathQA或SVAMP上的绝对数字并不高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步研究SVAMP的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的预测中，我们发现一些中间值实际上是负数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在这些问题中，我们问Jake有多少个苹果？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的模型做出了一些这样的预测，产生了负值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们观察到这两个表达式实际上有相似的分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步发现，针对某些模型，这种约束实际上改善了很多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还试图分析所有这些数据集背后的困难。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设这里的未使用数量的数量可以被视为不相关的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们还展示了整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们想通过一个问题扰动的例子来展示可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们的模型实际上在第一步就做出了错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以将这个表达式与这里的句子相关联。好。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为这个句子可能会误导模型做出错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里再植入一个35，会使得模型以为它是一个加法运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试将句子修改为类似梨树的数量比苹果树少35棵。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使其传达更准确的语义，以便模型能够使预测正确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这项研究展示了可解释预测如何帮助我们理解模型行为。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对我们的工作做个总结，首先我们的模型实际上是非常有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们能够提供可解释的解决程序。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也有一定的局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们有大量 数量的运算符或常量，内存消耗可能相当高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我的演讲到此结束，欢迎各位提出问题。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "法律问题是许多人生活中不可或缺的一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但大多数公民对他们的权利和基本法律程序知之甚少。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这样一个系统可以为非技术人员提供免费的专业法律援助服务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "需要一个模型来从大量立法中检索所有相关的法定条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种信息检索 任务有其自身的一系列挑战。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，它涉及两种类型的语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，有一些有可能是长达六千字的长文档。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，让我们来谈谈我们是如何收集这个数据集的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们从汇编大量语料库的法律条款开始。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们参考相关法规收集了法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，每个问题都具有主类别和一系列子类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个条款都带有法律结构中子序列标题的联结。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看我们的数据集的一些特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题的长度在5到44个单词之间，中位数为14个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最长的一条有5790个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "则其余的15%则涉及社会保障、外国人或工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是从这些比利时法典中收集的条款总数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在22633个条款中，只有1612个与数据集中的至少一个问题相关。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以解释为，这些法典较少关注个人及个人关心的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用标准的 TF-IDF和BM25排序函数进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些嵌入通常来自于对单词嵌入模型输出的池化操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，针对训练，我们尝试使用了双编码器架构的两种风格。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们在测试集上的基线结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，微调的双编码器明显优于所有其他基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，让我们讨论一下数据集的两个局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，租户每周举行两次派对，直到凌晨2点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以帮助改善所有人对司法的利用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为什么要费尽心思设立这个基准呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们是否知道模型实际上学到了什么？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这一个的低分呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言模型关注的是正确的事情吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "还是像之前的工作所显示的那样，他们专注于偏差？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的目标是存在性、复数、计数、空间关系、动作和实体共指。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们如何测试视觉和语言模型是否捕获了这种现象？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "计数和共指也是具有多种工具的方面。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这并不容易，因为被干扰的标题可能比原始标题更不可能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，要制造有效的干扰，我们必须想方设法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们利用强大的语言模型来提出干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为图像是前提，其标题是其附带的假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们认为标题是前提，而干扰词是其假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但这个过程并不完美，它只是一个有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，VALSE不提供任何训练数据，而仅提供测试数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "微调只会使模型能够利用数据中的工件或统计 偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们都知道，这些模型喜欢作弊和走捷径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有关更多指标及其结果，请查看我们的论文。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我是东京大学的Kamezawa。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将按照这个顺序解释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个图像显示的是vuejs库的2.6.4版本的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，如果能够自动生成高质量的发行说明，那将是非常有用的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将遵从之前的两项关于自动生成发行说明的研究。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一个是被称为ARENA的系统 ，发布于2014年。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统最显著的特征是右上角的问题提取器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "换句话说，它不能用于GitHub上的许多项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二个是Glyph ，最近在2020年宣布。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它可以在互联网上下载，并可以通过pip安装。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此图像是一个返回纠正或错误修复标签的示例用法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Glyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "文本分类模型的表现不佳。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的论文解决了这两个问题，并自动生成了高质量的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个提议的方法可以用于所有英语存储库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将介绍我们的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是数据的示例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "左侧是提交消息，右侧是发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明被标记为优化或修复等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以看作是一项总结 任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些都是基于之前的研究和其他因素设定的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右下角的发行说明是从左下角的发行说明中提取的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，有必要检测事先设置好的四个标签。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，标签并不总是与每个存储库一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，改进标签包括改进、增强、优化等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来是提交消息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "提交信息并不与每个版本相联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们创建了一个启发式匹配规则来获取上一个和下一个版本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，收集到了7200个存储库和82000份数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，独特的令牌数量也相当是大的，有883万个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是由于在资源库中发现了大量独特的类或方法名称。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将解释所提议的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "被归类为“其他”的提交消息将被丢弃。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们通过两种不同的方法对分类抽象总结方法进行建模。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "输出的文本可以根据特殊的类特定端点符号分为分类段落。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好，让我解释一下实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于评估，在某些情况下，发行说明是以多个句子形式输出的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当系统输出一个短句时，BLEU会受到惩罚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS和CAS的ROUGE-L得分比基线高10分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些结果表明CEAS和CAS受到严重影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里有一个错误分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS方法倾向于输出比人类参考句子更短的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在右图中，引用句子有3或4个句子 ，而CAS只有1个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，一个结论。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们已经建立了一个新的数据集，用于自动生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请查看我们在GitHub上的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。我的名字是Asaf Harari。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但有时，这些特征是有限的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用另一个数据来源生成特征可能会增加大量的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "假设我们有一个表格数据集和一个知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的框架FeSTE正是这个自动过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们来看看在一个数据集中输入FeSTE的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，数据集是大学数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当它的目标是将大学分为低排名的大学和高排名的大学时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用维基百科作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "FeSTE的第一阶段是实体链接。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且知识库的实体文本被提取出来，并添加到数据集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，文本是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，我们需要从检索 文本中生成或提取特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们需要进行特征提取阶段，其中包括文本分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，在原始数据集的类别数量中生成特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，原始数据集有两个类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，FeSTE生成两个特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但如果数据集有五个类，FeSTE就会生成五个新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个特征表示每个类的可能性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们不可能用输入数据集来训练语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有一个朴素的方法是：目标任务微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种方法的问题是，数据集可能只有几个不同的实体/文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个数据集上微调语言模型将是无效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以使用关于预先分析的数据集的先验知识。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的建议是，添加另一个微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个初步的多任务微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当你在n减1数据集上微调语言模型时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最先进的多任务多任务微调技术称为MTDNN。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在MTDNN中，MTDNN在训练集的任务数量上保持着头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从训练集中随机抽取一批。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的场景中，表格数据集在类的数量上有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "存在很多的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "MTDNN保持了类、头、输出层的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看一个例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里是我们的输入数据集，由实体、特征、文本和类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，标签向量在这种情况下始终保持……它总是由两个类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这就是我们精细的、重新制定的微调方法的算法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看完整的框架。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集送入FeSTE。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，FeSTE执行实体链接阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，它将任务重新表述为一个成对的句子分类任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "将语言模型应用于新的任务，并对每一类的输出可能性进行分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还是使用维基百科来作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还将每个数据集分成四折，并应用四折交叉验证。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们生成新的特征，并使用五个评估分类器对其进行评估。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，我们使用基础BERT基础架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们实验的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而我们重新制定的微调实现了最好的结果，最好的表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而MTDNN比目标 数据集 微调提高了2%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法实现了6%的改进。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但与单独的目标任务微调相比，我们的表现提高到了11%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它使用一个架构用于所有任务和数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且它保留了模型的头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但它增加了重新制定阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我想谈谈我们对于推理的动机。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们展示了一个多步骤推理有帮助的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，最好将可解释的多步骤推理作为输出。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "某些假设也适用于之前的工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设数量的精确度是已知的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，复杂的运算符实际上可以分解成这些基本运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "传统的序列到序列模型将表达式转换为特定的序列以进行生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这很容易实现，可以概括成许多不同的复杂问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但因为转换器模型的原因，实际上这个方向仍然很受欢迎。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，其中还包含一些重复的计算。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在第二步中，我们可以得到这些除数，即27。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也可以回头参考原始问题来查找相关内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这些步骤中，我们得到了除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后在第三步，我们实际上得到了商。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这使得这个过程更加准确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "表达式由e i j o p表示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在这里也有减法与单词代表相反的方向。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这与关系提取 非常相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们把它添加到下一个状态，成为一个新的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一旦我们得到数量陈述，我们就可以开始做推理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们得到表达式表达q_1除以q_2。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里所有可能的表达式等于运算符数量的三倍。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，这个数量来自之前计算的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终可以得到最后这个表达式q_3乘以q_4。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还可以看到，所有可能的表达式的数字与之前的步骤不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它还允许我们根据先前的知识施加某些约束。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们简要地展示了与之前最佳方法相比的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们表现最好的变体是Roberta-DeductiveReasoner。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "没错。最好的方法通常是基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总的来说，我们的推理能够显著优于这个基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以看到，MathQA或SVAMP上的绝对数字并不高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步研究SVAMP的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的预测中，我们发现一些中间值实际上是负数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在这些问题中，我们问Jake有多少个苹果？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的模型做出了一些这样的预测，产生了负值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们观察到这两个表达式实际上有相似的分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步发现，针对某些模型，这种约束实际上改善了很多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还试图分析所有这些数据集背后的困难。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设这里的未使用数量的数量可以被视为不相关的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们还展示了整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们想通过一个问题扰动的例子来展示可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们的模型实际上在第一步就做出了错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以将这个表达式与这里的句子相关联。好。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为这个句子可能会误导模型做出错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里再植入一个35，会使得模型以为它是一个加法运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试将句子修改为类似梨树的数量比苹果树少35棵。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使其传达更准确的语义，以便模型能够使预测正确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这项研究展示了可解释预测如何帮助我们理解模型行为。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对我们的工作做个总结，首先我们的模型实际上是非常有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们能够提供可解释的解决程序。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也有一定的局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们有大量 数量的运算符或常量，内存消耗可能相当高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我的演讲到此结束，欢迎各位提出问题。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "法律问题是许多人生活中不可或缺的一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但大多数公民对他们的权利和基本法律程序知之甚少。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这样一个系统可以为非技术人员提供免费的专业法律援助服务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "需要一个模型来从大量立法中检索所有相关的法定条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种信息检索 任务有其自身的一系列挑战。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，它涉及两种类型的语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，有一些有可能是长达六千字的长文档。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，让我们来谈谈我们是如何收集这个数据集的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们从汇编大量语料库的法律条款开始。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们参考相关法规收集了法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，每个问题都具有主类别和一系列子类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个条款都带有法律结构中子序列标题的联结。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看我们的数据集的一些特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题的长度在5到44个单词之间，中位数为14个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最长的一条有5790个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "则其余的15%则涉及社会保障、外国人或工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是从这些比利时法典中收集的条款总数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在22633个条款中，只有1612个与数据集中的至少一个问题相关。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以解释为，这些法典较少关注个人及个人关心的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用标准的 TF-IDF和BM25排序函数进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些嵌入通常来自于对单词嵌入模型输出的池化操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，针对训练，我们尝试使用了双编码器架构的两种风格。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们在测试集上的基线结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，微调的双编码器明显优于所有其他基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，让我们讨论一下数据集的两个局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，租户每周举行两次派对，直到凌晨2点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以帮助改善所有人对司法的利用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为什么要费尽心思设立这个基准呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们是否知道模型实际上学到了什么？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这一个的低分呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言模型关注的是正确的事情吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "还是像之前的工作所显示的那样，他们专注于偏差？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的目标是存在性、复数、计数、空间关系、动作和实体共指。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们如何测试视觉和语言模型是否捕获了这种现象？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "计数和共指也是具有多种工具的方面。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这并不容易，因为被干扰的标题可能比原始标题更不可能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，要制造有效的干扰，我们必须想方设法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们利用强大的语言模型来提出干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为图像是前提，其标题是其附带的假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们认为标题是前提，而干扰词是其假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但这个过程并不完美，它只是一个有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，VALSE不提供任何训练数据，而仅提供测试数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "微调只会使模型能够利用数据中的工件或统计 偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们都知道，这些模型喜欢作弊和走捷径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有关更多指标及其结果，请查看我们的论文。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我是东京大学的Kamezawa。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将按照这个顺序解释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个图像显示的是vuejs库的2.6.4版本的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，如果能够自动生成高质量的发行说明，那将是非常有用的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将遵从之前的两项关于自动生成发行说明的研究。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一个是被称为ARENA的系统 ，发布于2014年。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统最显著的特征是右上角的问题提取器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "换句话说，它不能用于GitHub上的许多项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二个是Glyph ，最近在2020年宣布。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它可以在互联网上下载，并可以通过pip安装。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此图像是一个返回纠正或错误修复标签的示例用法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Glyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "文本分类模型的表现不佳。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的论文解决了这两个问题，并自动生成了高质量的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个提议的方法可以用于所有英语存储库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将介绍我们的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是数据的示例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "左侧是提交消息，右侧是发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明被标记为优化或修复等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以看作是一项总结 任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些都是基于之前的研究和其他因素设定的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右下角的发行说明是从左下角的发行说明中提取的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，有必要检测事先设置好的四个标签。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，标签并不总是与每个存储库一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，改进标签包括改进、增强、优化等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来是提交消息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "提交信息并不与每个版本相联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们创建了一个启发式匹配规则来获取上一个和下一个版本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，收集到了7200个存储库和82000份数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，独特的令牌数量也相当是大的，有883万个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是由于在资源库中发现了大量独特的类或方法名称。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将解释所提议的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "被归类为“其他”的提交消息将被丢弃。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们通过两种不同的方法对分类抽象总结方法进行建模。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "输出的文本可以根据特殊的类特定端点符号分为分类段落。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好，让我解释一下实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于评估，在某些情况下，发行说明是以多个句子形式输出的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当系统输出一个短句时，BLEU会受到惩罚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS和CAS的ROUGE-L得分比基线高10分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些结果表明CEAS和CAS受到严重影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里有一个错误分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS方法倾向于输出比人类参考句子更短的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在右图中，引用句子有3或4个句子 ，而CAS只有1个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，一个结论。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们已经建立了一个新的数据集，用于自动生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请查看我们在GitHub上的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。我的名字是Asaf Harari。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但有时，这些特征是有限的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用另一个数据来源生成特征可能会增加大量的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "假设我们有一个表格数据集和一个知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的框架FeSTE正是这个自动过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们来看看在一个数据集中输入FeSTE的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，数据集是大学数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当它的目标是将大学分为低排名的大学和高排名的大学时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用维基百科作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "FeSTE的第一阶段是实体链接。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且知识库的实体文本被提取出来，并添加到数据集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，文本是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，我们需要从检索 文本中生成或提取特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们需要进行特征提取阶段，其中包括文本分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，在原始数据集的类别数量中生成特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，原始数据集有两个类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，FeSTE生成两个特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但如果数据集有五个类，FeSTE就会生成五个新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个特征表示每个类的可能性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们不可能用输入数据集来训练语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有一个朴素的方法是：目标任务微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种方法的问题是，数据集可能只有几个不同的实体/文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个数据集上微调语言模型将是无效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以使用关于预先分析的数据集的先验知识。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的建议是，添加另一个微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个初步的多任务微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当你在n减1数据集上微调语言模型时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最先进的多任务多任务微调技术称为MTDNN。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在MTDNN中，MTDNN在训练集的任务数量上保持着头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从训练集中随机抽取一批。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的场景中，表格数据集在类的数量上有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "存在很多的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "MTDNN保持了类、头、输出层的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看一个例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里是我们的输入数据集，由实体、特征、文本和类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，标签向量在这种情况下始终保持……它总是由两个类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这就是我们精细的、重新制定的微调方法的算法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看完整的框架。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集送入FeSTE。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，FeSTE执行实体链接阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，它将任务重新表述为一个成对的句子分类任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "将语言模型应用于新的任务，并对每一类的输出可能性进行分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还是使用维基百科来作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还将每个数据集分成四折，并应用四折交叉验证。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们生成新的特征，并使用五个评估分类器对其进行评估。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，我们使用基础BERT基础架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们实验的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而我们重新制定的微调实现了最好的结果，最好的表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而MTDNN比目标 数据集 微调提高了2%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法实现了6%的改进。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但与单独的目标任务微调相比，我们的表现提高到了11%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它使用一个架构用于所有任务和数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且它保留了模型的头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但它增加了重新制定阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我想谈谈我们对于推理的动机。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们展示了一个多步骤推理有帮助的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，最好将可解释的多步骤推理作为输出。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "某些假设也适用于之前的工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设数量的精确度是已知的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，复杂的运算符实际上可以分解成这些基本运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "传统的序列到序列模型将表达式转换为特定的序列以进行生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这很容易实现，可以概括成许多不同的复杂问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但因为转换器模型的原因，实际上这个方向仍然很受欢迎。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，其中还包含一些重复的计算。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在第二步中，我们可以得到这些除数，即27。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也可以回头参考原始问题来查找相关内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这些步骤中，我们得到了除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后在第三步，我们实际上得到了商。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这使得这个过程更加准确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "表达式由e i j o p表示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在这里也有减法与单词代表相反的方向。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这与关系提取 非常相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们把它添加到下一个状态，成为一个新的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一旦我们得到数量陈述，我们就可以开始做推理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们得到表达式表达q_1除以q_2。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里所有可能的表达式等于运算符数量的三倍。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，这个数量来自之前计算的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终可以得到最后这个表达式q_3乘以q_4。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还可以看到，所有可能的表达式的数字与之前的步骤不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它还允许我们根据先前的知识施加某些约束。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们简要地展示了与之前最佳方法相比的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们表现最好的变体是Roberta-DeductiveReasoner。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "没错。最好的方法通常是基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总的来说，我们的推理能够显著优于这个基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以看到，MathQA或SVAMP上的绝对数字并不高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步研究SVAMP的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的预测中，我们发现一些中间值实际上是负数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在这些问题中，我们问Jake有多少个苹果？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的模型做出了一些这样的预测，产生了负值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们观察到这两个表达式实际上有相似的分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步发现，针对某些模型，这种约束实际上改善了很多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还试图分析所有这些数据集背后的困难。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设这里的未使用数量的数量可以被视为不相关的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们还展示了整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们想通过一个问题扰动的例子来展示可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们的模型实际上在第一步就做出了错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以将这个表达式与这里的句子相关联。好。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为这个句子可能会误导模型做出错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里再植入一个35，会使得模型以为它是一个加法运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试将句子修改为类似梨树的数量比苹果树少35棵。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使其传达更准确的语义，以便模型能够使预测正确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这项研究展示了可解释预测如何帮助我们理解模型行为。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对我们的工作做个总结，首先我们的模型实际上是非常有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们能够提供可解释的解决程序。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也有一定的局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们有大量 数量的运算符或常量，内存消耗可能相当高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我的演讲到此结束，欢迎各位提出问题。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "法律问题是许多人生活中不可或缺的一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但大多数公民对他们的权利和基本法律程序知之甚少。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这样一个系统可以为非技术人员提供免费的专业法律援助服务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "需要一个模型来从大量立法中检索所有相关的法定条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种信息检索 任务有其自身的一系列挑战。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，它涉及两种类型的语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，有一些有可能是长达六千字的长文档。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，让我们来谈谈我们是如何收集这个数据集的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们从汇编大量语料库的法律条款开始。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们参考相关法规收集了法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，每个问题都具有主类别和一系列子类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个条款都带有法律结构中子序列标题的联结。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看我们的数据集的一些特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题的长度在5到44个单词之间，中位数为14个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最长的一条有5790个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "则其余的15%则涉及社会保障、外国人或工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是从这些比利时法典中收集的条款总数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在22633个条款中，只有1612个与数据集中的至少一个问题相关。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以解释为，这些法典较少关注个人及个人关心的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用标准的 TF-IDF和BM25排序函数进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些嵌入通常来自于对单词嵌入模型输出的池化操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，针对训练，我们尝试使用了双编码器架构的两种风格。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们在测试集上的基线结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，微调的双编码器明显优于所有其他基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，让我们讨论一下数据集的两个局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，租户每周举行两次派对，直到凌晨2点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以帮助改善所有人对司法的利用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为什么要费尽心思设立这个基准呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们是否知道模型实际上学到了什么？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这一个的低分呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言模型关注的是正确的事情吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "还是像之前的工作所显示的那样，他们专注于偏差？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的目标是存在性、复数、计数、空间关系、动作和实体共指。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们如何测试视觉和语言模型是否捕获了这种现象？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "计数和共指也是具有多种工具的方面。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这并不容易，因为被干扰的标题可能比原始标题更不可能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，要制造有效的干扰，我们必须想方设法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们利用强大的语言模型来提出干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为图像是前提，其标题是其附带的假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们认为标题是前提，而干扰词是其假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但这个过程并不完美，它只是一个有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，VALSE不提供任何训练数据，而仅提供测试数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "微调只会使模型能够利用数据中的工件或统计 偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们都知道，这些模型喜欢作弊和走捷径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有关更多指标及其结果，请查看我们的论文。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我是东京大学的Kamezawa。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将按照这个顺序解释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个图像显示的是vuejs库的2.6.4版本的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，如果能够自动生成高质量的发行说明，那将是非常有用的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将遵从之前的两项关于自动生成发行说明的研究。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一个是被称为ARENA的系统 ，发布于2014年。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统最显著的特征是右上角的问题提取器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "换句话说，它不能用于GitHub上的许多项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二个是Glyph ，最近在2020年宣布。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它可以在互联网上下载，并可以通过pip安装。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此图像是一个返回纠正或错误修复标签的示例用法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Glyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "文本分类模型的表现不佳。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的论文解决了这两个问题，并自动生成了高质量的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个提议的方法可以用于所有英语存储库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将介绍我们的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是数据的示例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "左侧是提交消息，右侧是发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明被标记为优化或修复等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以看作是一项总结 任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些都是基于之前的研究和其他因素设定的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右下角的发行说明是从左下角的发行说明中提取的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，有必要检测事先设置好的四个标签。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，标签并不总是与每个存储库一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，改进标签包括改进、增强、优化等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来是提交消息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "提交信息并不与每个版本相联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们创建了一个启发式匹配规则来获取上一个和下一个版本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，收集到了7200个存储库和82000份数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，独特的令牌数量也相当是大的，有883万个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是由于在资源库中发现了大量独特的类或方法名称。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将解释所提议的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "被归类为“其他”的提交消息将被丢弃。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们通过两种不同的方法对分类抽象总结方法进行建模。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "输出的文本可以根据特殊的类特定端点符号分为分类段落。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好，让我解释一下实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于评估，在某些情况下，发行说明是以多个句子形式输出的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当系统输出一个短句时，BLEU会受到惩罚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS和CAS的ROUGE-L得分比基线高10分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些结果表明CEAS和CAS受到严重影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里有一个错误分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS方法倾向于输出比人类参考句子更短的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在右图中，引用句子有3或4个句子 ，而CAS只有1个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，一个结论。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们已经建立了一个新的数据集，用于自动生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请查看我们在GitHub上的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。我的名字是Asaf Harari。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但有时，这些特征是有限的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用另一个数据来源生成特征可能会增加大量的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "假设我们有一个表格数据集和一个知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的框架FeSTE正是这个自动过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们来看看在一个数据集中输入FeSTE的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，数据集是大学数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当它的目标是将大学分为低排名的大学和高排名的大学时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用维基百科作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "FeSTE的第一阶段是实体链接。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且知识库的实体文本被提取出来，并添加到数据集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，文本是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，我们需要从检索 文本中生成或提取特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们需要进行特征提取阶段，其中包括文本分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，在原始数据集的类别数量中生成特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，原始数据集有两个类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，FeSTE生成两个特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但如果数据集有五个类，FeSTE就会生成五个新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个特征表示每个类的可能性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们不可能用输入数据集来训练语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有一个朴素的方法是：目标任务微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种方法的问题是，数据集可能只有几个不同的实体/文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个数据集上微调语言模型将是无效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以使用关于预先分析的数据集的先验知识。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的建议是，添加另一个微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个初步的多任务微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当你在n减1数据集上微调语言模型时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最先进的多任务多任务微调技术称为MTDNN。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在MTDNN中，MTDNN在训练集的任务数量上保持着头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从训练集中随机抽取一批。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的场景中，表格数据集在类的数量上有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "存在很多的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "MTDNN保持了类、头、输出层的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看一个例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里是我们的输入数据集，由实体、特征、文本和类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，标签向量在这种情况下始终保持……它总是由两个类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这就是我们精细的、重新制定的微调方法的算法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看完整的框架。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集送入FeSTE。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，FeSTE执行实体链接阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，它将任务重新表述为一个成对的句子分类任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "将语言模型应用于新的任务，并对每一类的输出可能性进行分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还是使用维基百科来作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还将每个数据集分成四折，并应用四折交叉验证。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们生成新的特征，并使用五个评估分类器对其进行评估。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，我们使用基础BERT基础架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们实验的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而我们重新制定的微调实现了最好的结果，最好的表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而MTDNN比目标 数据集 微调提高了2%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法实现了6%的改进。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但与单独的目标任务微调相比，我们的表现提高到了11%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它使用一个架构用于所有任务和数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且它保留了模型的头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但它增加了重新制定阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。\n我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。\n首先，我想谈谈我们对于推理的动机。\n在这里，我们展示了一个多步骤推理有帮助的例子。\n这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。\n在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。\n但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。\n所以，最好将可解释的多步骤推理作为输出。\n我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。\n在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。\n在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。\n某些假设也适用于之前的工作。\n我们假设数量的精确度是已知的。\n并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。\n此外，复杂的运算符实际上可以分解成这些基本运算符。\n之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。\n传统的序列到序列模型将表达式转换为特定的序列以进行生成。\n这很容易实现，可以概括成许多不同的复杂问题。\n但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。\n但因为转换器模型的原因，实际上这个方向仍然很受欢迎。\n因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。\n所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。\n这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。\n其次，其中还包含一些重复的计算。\n如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。\n在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。\n例如，在第二步中，我们可以得到这些除数，即27。\n我们也可以回头参考原始问题来查找相关内容。\n在这些步骤中，我们得到了除数。\n然后在第三步，我们实际上得到了商。\n好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。\n在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。\n这使得这个过程更加准确。\n在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。\n表达式由e i j o p表示。\n我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。\n我们在这里也有减法与单词代表相反的方向。\n这与关系提取 非常相似。\n在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。\n我们把它添加到下一个状态，成为一个新的数量。\n这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。\n在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。\n一旦我们得到数量陈述，我们就可以开始做推理。\n这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。\n首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。\n最后，我们得到表达式表达q_1除以q_2。\n但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。\n这里所有可能的表达式等于运算符数量的三倍。\n这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。\n例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。\n所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。\n所以，这个数量来自之前计算的表达式。\n我们最终可以得到最后这个表达式q_3乘以q_4。\n我们还可以看到，所有可能的表达式的数字与之前的步骤不同。\n这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。\n训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。\n在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。\n这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。\n它还允许我们根据先前的知识施加某些约束。\n我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。\n在这里，我们简要地展示了与之前最佳方法相比的结果。\n我们表现最好的变体是Roberta-DeductiveReasoner。\n事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。\n没错。最好的方法通常是基于树的模型。\n总的来说，我们的推理能够显著优于这个基于树的模型。\n但我们可以看到，MathQA或SVAMP上的绝对数字并不高。\n我们进一步研究SVAMP的结果。\n这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。\n在我们的预测中，我们发现一些中间值实际上是负数。\n例如，在这些问题中，我们问Jake有多少个苹果？\n但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。\n我们的模型做出了一些这样的预测，产生了负值。\n我们观察到这两个表达式实际上有相似的分数。\n我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。\n我们进一步发现，针对某些模型，这种约束实际上改善了很多。\n例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。\n因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。\n我们还试图分析所有这些数据集背后的困难。\n我们假设这里的未使用数量的数量可以被视为不相关的信息。\n在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。\n在这里，我们还展示了整体表现。\n对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。\n但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。\n对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。\n最后，我们想通过一个问题扰动的例子来展示可解释性。\n在这里，我们的模型实际上在第一步就做出了错误的预测。\n我们实际上可以将这个表达式与这里的句子相关联。好。\n我们认为这个句子可能会误导模型做出错误的预测。\n在这里再植入一个35，会使得模型以为它是一个加法运算符。\n我们尝试将句子修改为类似梨树的数量比苹果树少35棵。\n我们使其传达更准确的语义，以便模型能够使预测正确。\n这项研究展示了可解释预测如何帮助我们理解模型行为。\n对我们的工作做个总结，首先我们的模型实际上是非常有效的。\n我们能够提供可解释的解决程序。\n我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。\n最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。\n我们也有一定的局限性。\n如果我们有大量 数量的运算符或常量，内存消耗可能相当高。\n第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。\n我的演讲到此结束，欢迎各位提出问题。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。\n我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。\n法律问题是许多人生活中不可或缺的一部分。\n但大多数公民对他们的权利和基本法律程序知之甚少。\n结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。\n所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。\n这样一个系统可以为非技术人员提供免费的专业法律援助服务。\n在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。\n给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？\n需要一个模型来从大量立法中检索所有相关的法定条款。\n这种信息检索 任务有其自身的一系列挑战。\n首先，它涉及两种类型的语言。\n针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。\n这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。\n此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。\n相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。\n最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。\n在这里，有一些有可能是长达六千字的长文档。\n自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。\n但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。\n在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。\n我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。\n这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。\n每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。\n现在，让我们来谈谈我们是如何收集这个数据集的。\n首先，我们从汇编大量语料库的法律条款开始。\n我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。\n然后，我们参考相关法规收集了法律问题。\n为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。\n我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。\n我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。\n最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。\n其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。\n我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。\n此外，每个问题都具有主类别和一系列子类别。\n每个条款都带有法律结构中子序列标题的联结。\n这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。\n让我们来看看我们的数据集的一些特征。\n这些问题的长度在5到44个单词之间，中位数为14个单词。\n条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。\n最长的一条有5790个单词。\n如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。\n则其余的15%则涉及社会保障、外国人或工作。\n这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。\n以下是从这些比利时法典中收集的条款总数。\n在22633个条款中，只有1612个与数据集中的至少一个问题相关。\n这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。\n与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。\n这可以解释为，这些法典较少关注个人及个人关心的问题。\n总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。\n使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。\n给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。\n我们使用标准的 TF-IDF和BM25排序函数进行实验。\n这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。\n为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。\n我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。\n这些嵌入通常来自于对单词嵌入模型输出的池化操作。\n首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。\n我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。\n此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。\n请注意，针对训练，我们尝试使用了双编码器架构的两种风格。\n第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。\n我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。\n以下是我们在测试集上的基线结果。\n上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。\n总体而言，微调的双编码器明显优于所有其他基线。\n双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。\n虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。\n关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。\n此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。\n虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。\n最后，让我们讨论一下数据集的两个局限性。\n首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。\n在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。\n因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。\n其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。\n例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？\n在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。\n相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。\n例如，租户每周举行两次派对，直到凌晨2点。\n因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。\n我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。\n这可以帮助改善所有人对司法的利用。\n您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。\n我们为什么要费尽心思设立这个基准呢？\n那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。\n这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。\n因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。\n但我们是否知道模型实际上学到了什么？\n视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？\n而这一个的低分呢？\n视觉和语言模型关注的是正确的事情吗？\n还是像之前的工作所显示的那样，他们专注于偏差？\n为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。\n我们的目标是存在性、复数、计数、空间关系、动作和实体共指。\n但是，我们如何测试视觉和语言模型是否捕获了这种现象？\n通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。\n干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。\n当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。\n例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。\n计数和共指也是具有多种工具的方面。\n当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。\n这并不容易，因为被干扰的标题可能比原始标题更不可能。\n例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。\n所以，要制造有效的干扰，我们必须想方设法。\n首先，我们利用强大的语言模型来提出干扰。\n其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。\n为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。\n我们认为图像是前提，其标题是其附带的假设。\n此外，我们认为标题是前提，而干扰词是其假设。\n如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。\n如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。\n但这个过程并不完美，它只是一个有效干扰词的指标。\n所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。\n因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。\n请注意，VALSE不提供任何训练数据，而仅提供测试数据。\n由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。\n微调只会使模型能够利用数据中的工件或统计 偏差。\n我们都知道，这些模型喜欢作弊和走捷径。\n正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。\n我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。\n我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。\n也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。\n有关更多指标及其结果，请查看我们的论文。\n这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。\n值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。\n但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。\n我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。\n关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。\n他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。\n从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。\n作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。\n如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。\n有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。\n因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。\n我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。\n我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。\n更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。\n如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "大家好，我是东京大学的Kamezawa。\n我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。\n我将按照这个顺序解释。\n首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。\n发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。\n这个图像显示的是vuejs库的2.6.4版本的发行说明。\n发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。\n因此，如果能够自动生成高质量的发行说明，那将是非常有用的。\n我将遵从之前的两项关于自动生成发行说明的研究。\n第一个是被称为ARENA的系统 ，发布于2014年。\n它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。\n这个系统最显著的特征是右上角的问题提取器。\n这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。\n换句话说，它不能用于GitHub上的许多项目。\n第二个是Glyph ，最近在2020年宣布。\n它可以在互联网上下载，并可以通过pip安装。\n这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。\n此图像是一个返回纠正或错误修复标签的示例用法。\nGlyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。\n文本分类模型的表现不佳。\n我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。\n我们的论文解决了这两个问题，并自动生成了高质量的发行说明。\n面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。\n这个提议的方法可以用于所有英语存储库。\n对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。\n接下来，我将介绍我们的数据集。\n以下是数据的示例。\n左侧是提交消息，右侧是发行说明。\n发行说明被标记为优化或修复等。\n我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。\n这可以看作是一项总结 任务。\n我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。\n这些都是基于之前的研究和其他因素设定的。\n右下角的发行说明是从左下角的发行说明中提取的。\n现在，有必要检测事先设置好的四个标签。\n但是，标签并不总是与每个存储库一致。\n例如，改进标签包括改进、增强、优化等。\n我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。\n这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。\n接下来是提交消息。\n提交信息并不与每个版本相联系。\n如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。\n这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。\n我们创建了一个启发式匹配规则来获取上一个和下一个版本。\n数据集分析。\n最后，收集到了7200个存储库和82000份数据。\n此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。\n此外，独特的令牌数量也相当是大的，有883万个。\n这是由于在资源库中发现了大量独特的类或方法名称。\n接下来，我将解释所提议的方法。\n这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。\n一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。\n首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。\n被归类为“其他”的提交消息将被丢弃。\n然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。\n在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。\n所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。\n我们通过两种不同的方法对分类抽象总结方法进行建模。\n第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。\n输出的文本可以根据特殊的类特定端点符号分为分类段落。\n第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。\n好，让我解释一下实验。\n我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。\n关于评估，在某些情况下，发行说明是以多个句子形式输出的。\n由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。\n当系统输出一个短句时，BLEU会受到惩罚。\n在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。\n最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。\n更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。\n结果如下。\n由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。\nCEAS和CAS的ROUGE-L得分比基线高10分以上。\n特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。\n这些结果表明CEAS和CAS受到严重影响。\nCEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。\nCEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。\nCAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。\n这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。\n这里有一个错误分析。\nCAS方法倾向于输出比人类参考句子更短的句子。\n在右图中，引用句子有3或4个句子 ，而CAS只有1个。\n这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。\n此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。\n右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。\n下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。\n最后，一个结论。\n我们已经建立了一个新的数据集，用于自动生成发行说明。\n我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。\n我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。\n请查看我们在GitHub上的数据集。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "大家好。我的名字是Asaf Harari。\n我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。\n数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。\n但有时，这些特征是有限的。\n使用另一个数据来源生成特征可能会增加大量的信息。\n我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。\n假设我们有一个表格数据集和一个知识库。\n我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。\n我们的框架FeSTE正是这个自动过程。\n我们来看看在一个数据集中输入FeSTE的例子。\n在这个例子中，数据集是大学数据集。\n当它的目标是将大学分为低排名的大学和高排名的大学时。\n我们使用维基百科作为知识库。\nFeSTE的第一阶段是实体链接。\n当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。\n并且知识库的实体文本被提取出来，并添加到数据集中。\n在这个例子中，文本是维基百科页面的摘要。\n现在，我们需要从检索 文本中生成或提取特征。\n因此，我们需要进行特征提取阶段，其中包括文本分析。\n这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。\n在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。\n首先，在原始数据集的类别数量中生成特征。\n在这个例子中，原始数据集有两个类别。\n所以，FeSTE生成两个特征。\n但如果数据集有五个类，FeSTE就会生成五个新的特征。\n每个特征表示每个类的可能性。\n为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。\n但是，我们不可能用输入数据集来训练语言模型。\n因此，有一个朴素的方法是：目标任务微调。\n因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。\n在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。\n接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。\n这种方法的问题是，数据集可能只有几个不同的实体/文本。\n在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。\n因此，在这个数据集上微调语言模型将是无效的。\n但我们可以使用关于预先分析的数据集的先验知识。\n因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。\n我们的建议是，添加另一个微调阶段。\n一个初步的多任务微调阶段。\n当你在n减1数据集上微调语言模型时。\n然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。\n最先进的多任务多任务微调技术称为MTDNN。\n在MTDNN中，MTDNN在训练集的任务数量上保持着头部。\n因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。\n它从训练集中随机抽取一批。\n而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。\n而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。\n在我们的场景中，表格数据集在类的数量上有所不同。\n存在很多的任务。\nMTDNN保持了类、头、输出层的数量。\n另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。\n我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。\n让我们来看一个例子。\n这里是我们的输入数据集，由实体、特征、文本和类组成。\n而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。\n或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。\n因此，标签向量在这种情况下始终保持……它总是由两个类组成。\n而这就是我们精细的、重新制定的微调方法的算法。\n让我们来看看完整的框架。\n数据集送入FeSTE。\n然后，FeSTE执行实体链接阶段。\n它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。\n然后，它将任务重新表述为一个成对的句子分类任务。\n将语言模型应用于新的任务，并对每一类的输出可能性进行分析。\n现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。\n然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。\n为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。\n我们还是使用维基百科来作为知识库。\n我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。\n我们还将每个数据集分成四折，并应用四折交叉验证。\n然后，我们生成新的特征，并使用五个评估分类器对其进行评估。\n在我们的实验中，我们使用基础BERT基础架构。\n以下是我们实验的结果。\n你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。\n而我们重新制定的微调实现了最好的结果，最好的表现。\n而MTDNN比目标 数据集 微调提高了2%。\n我们的方法实现了6%的改进。\n当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。\n但与单独的目标任务微调相比，我们的表现提高到了11%。\n总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。\n它使用一个架构用于所有任务和数据集。\n而且它保留了模型的头部。\n但它增加了重新制定阶段。\n它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我想谈谈我们对于推理的动机。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们展示了一个多步骤推理有帮助的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，最好将可解释的多步骤推理作为输出。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "某些假设也适用于之前的工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设数量的精确度是已知的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，复杂的运算符实际上可以分解成这些基本运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "传统的序列到序列模型将表达式转换为特定的序列以进行生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这很容易实现，可以概括成许多不同的复杂问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但因为转换器模型的原因，实际上这个方向仍然很受欢迎。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，其中还包含一些重复的计算。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在第二步中，我们可以得到这些除数，即27。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也可以回头参考原始问题来查找相关内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这些步骤中，我们得到了除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后在第三步，我们实际上得到了商。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这使得这个过程更加准确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "表达式由e i j o p表示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在这里也有减法与单词代表相反的方向。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这与关系提取 非常相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们把它添加到下一个状态，成为一个新的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一旦我们得到数量陈述，我们就可以开始做推理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们得到表达式表达q_1除以q_2。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里所有可能的表达式等于运算符数量的三倍。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，这个数量来自之前计算的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终可以得到最后这个表达式q_3乘以q_4。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还可以看到，所有可能的表达式的数字与之前的步骤不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它还允许我们根据先前的知识施加某些约束。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们简要地展示了与之前最佳方法相比的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们表现最好的变体是Roberta-DeductiveReasoner。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "没错。最好的方法通常是基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总的来说，我们的推理能够显著优于这个基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以看到，MathQA或SVAMP上的绝对数字并不高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步研究SVAMP的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的预测中，我们发现一些中间值实际上是负数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在这些问题中，我们问Jake有多少个苹果？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的模型做出了一些这样的预测，产生了负值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们观察到这两个表达式实际上有相似的分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步发现，针对某些模型，这种约束实际上改善了很多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还试图分析所有这些数据集背后的困难。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设这里的未使用数量的数量可以被视为不相关的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们还展示了整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们想通过一个问题扰动的例子来展示可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们的模型实际上在第一步就做出了错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以将这个表达式与这里的句子相关联。好。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为这个句子可能会误导模型做出错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里再植入一个35，会使得模型以为它是一个加法运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试将句子修改为类似梨树的数量比苹果树少35棵。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使其传达更准确的语义，以便模型能够使预测正确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这项研究展示了可解释预测如何帮助我们理解模型行为。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对我们的工作做个总结，首先我们的模型实际上是非常有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们能够提供可解释的解决程序。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也有一定的局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们有大量 数量的运算符或常量，内存消耗可能相当高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我的演讲到此结束，欢迎各位提出问题。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "法律问题是许多人生活中不可或缺的一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但大多数公民对他们的权利和基本法律程序知之甚少。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这样一个系统可以为非技术人员提供免费的专业法律援助服务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "需要一个模型来从大量立法中检索所有相关的法定条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种信息检索 任务有其自身的一系列挑战。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，它涉及两种类型的语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，有一些有可能是长达六千字的长文档。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，让我们来谈谈我们是如何收集这个数据集的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们从汇编大量语料库的法律条款开始。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们参考相关法规收集了法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，每个问题都具有主类别和一系列子类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个条款都带有法律结构中子序列标题的联结。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看我们的数据集的一些特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题的长度在5到44个单词之间，中位数为14个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最长的一条有5790个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "则其余的15%则涉及社会保障、外国人或工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是从这些比利时法典中收集的条款总数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在22633个条款中，只有1612个与数据集中的至少一个问题相关。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以解释为，这些法典较少关注个人及个人关心的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用标准的 TF-IDF和BM25排序函数进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些嵌入通常来自于对单词嵌入模型输出的池化操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，针对训练，我们尝试使用了双编码器架构的两种风格。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们在测试集上的基线结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，微调的双编码器明显优于所有其他基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，让我们讨论一下数据集的两个局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，租户每周举行两次派对，直到凌晨2点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以帮助改善所有人对司法的利用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为什么要费尽心思设立这个基准呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们是否知道模型实际上学到了什么？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这一个的低分呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言模型关注的是正确的事情吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "还是像之前的工作所显示的那样，他们专注于偏差？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的目标是存在性、复数、计数、空间关系、动作和实体共指。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们如何测试视觉和语言模型是否捕获了这种现象？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "计数和共指也是具有多种工具的方面。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这并不容易，因为被干扰的标题可能比原始标题更不可能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，要制造有效的干扰，我们必须想方设法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们利用强大的语言模型来提出干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为图像是前提，其标题是其附带的假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们认为标题是前提，而干扰词是其假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但这个过程并不完美，它只是一个有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，VALSE不提供任何训练数据，而仅提供测试数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "微调只会使模型能够利用数据中的工件或统计 偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们都知道，这些模型喜欢作弊和走捷径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有关更多指标及其结果，请查看我们的论文。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我是东京大学的Kamezawa。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将按照这个顺序解释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个图像显示的是vuejs库的2.6.4版本的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，如果能够自动生成高质量的发行说明，那将是非常有用的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将遵从之前的两项关于自动生成发行说明的研究。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一个是被称为ARENA的系统 ，发布于2014年。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统最显著的特征是右上角的问题提取器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "换句话说，它不能用于GitHub上的许多项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二个是Glyph ，最近在2020年宣布。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它可以在互联网上下载，并可以通过pip安装。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此图像是一个返回纠正或错误修复标签的示例用法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Glyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "文本分类模型的表现不佳。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的论文解决了这两个问题，并自动生成了高质量的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个提议的方法可以用于所有英语存储库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将介绍我们的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是数据的示例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "左侧是提交消息，右侧是发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明被标记为优化或修复等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以看作是一项总结 任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些都是基于之前的研究和其他因素设定的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右下角的发行说明是从左下角的发行说明中提取的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，有必要检测事先设置好的四个标签。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，标签并不总是与每个存储库一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，改进标签包括改进、增强、优化等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来是提交消息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "提交信息并不与每个版本相联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们创建了一个启发式匹配规则来获取上一个和下一个版本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，收集到了7200个存储库和82000份数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，独特的令牌数量也相当是大的，有883万个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是由于在资源库中发现了大量独特的类或方法名称。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将解释所提议的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "被归类为“其他”的提交消息将被丢弃。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们通过两种不同的方法对分类抽象总结方法进行建模。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "输出的文本可以根据特殊的类特定端点符号分为分类段落。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好，让我解释一下实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于评估，在某些情况下，发行说明是以多个句子形式输出的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当系统输出一个短句时，BLEU会受到惩罚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS和CAS的ROUGE-L得分比基线高10分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些结果表明CEAS和CAS受到严重影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里有一个错误分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS方法倾向于输出比人类参考句子更短的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在右图中，引用句子有3或4个句子 ，而CAS只有1个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，一个结论。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们已经建立了一个新的数据集，用于自动生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请查看我们在GitHub上的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。我的名字是Asaf Harari。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但有时，这些特征是有限的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用另一个数据来源生成特征可能会增加大量的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "假设我们有一个表格数据集和一个知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的框架FeSTE正是这个自动过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们来看看在一个数据集中输入FeSTE的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，数据集是大学数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当它的目标是将大学分为低排名的大学和高排名的大学时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用维基百科作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "FeSTE的第一阶段是实体链接。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且知识库的实体文本被提取出来，并添加到数据集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，文本是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，我们需要从检索 文本中生成或提取特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们需要进行特征提取阶段，其中包括文本分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，在原始数据集的类别数量中生成特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，原始数据集有两个类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，FeSTE生成两个特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但如果数据集有五个类，FeSTE就会生成五个新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个特征表示每个类的可能性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们不可能用输入数据集来训练语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有一个朴素的方法是：目标任务微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种方法的问题是，数据集可能只有几个不同的实体/文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个数据集上微调语言模型将是无效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以使用关于预先分析的数据集的先验知识。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的建议是，添加另一个微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个初步的多任务微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当你在n减1数据集上微调语言模型时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最先进的多任务多任务微调技术称为MTDNN。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在MTDNN中，MTDNN在训练集的任务数量上保持着头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从训练集中随机抽取一批。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的场景中，表格数据集在类的数量上有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "存在很多的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "MTDNN保持了类、头、输出层的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看一个例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里是我们的输入数据集，由实体、特征、文本和类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，标签向量在这种情况下始终保持……它总是由两个类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这就是我们精细的、重新制定的微调方法的算法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看完整的框架。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集送入FeSTE。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，FeSTE执行实体链接阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，它将任务重新表述为一个成对的句子分类任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "将语言模型应用于新的任务，并对每一类的输出可能性进行分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还是使用维基百科来作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还将每个数据集分成四折，并应用四折交叉验证。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们生成新的特征，并使用五个评估分类器对其进行评估。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，我们使用基础BERT基础架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们实验的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而我们重新制定的微调实现了最好的结果，最好的表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而MTDNN比目标 数据集 微调提高了2%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法实现了6%的改进。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但与单独的目标任务微调相比，我们的表现提高到了11%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它使用一个架构用于所有任务和数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且它保留了模型的头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但它增加了重新制定阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "大家好。我的名字是Asaf Harari。\n我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。\n数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。\n但有时，这些特征是有限的。\n使用另一个数据来源生成特征可能会增加大量的信息。\n我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。\n假设我们有一个表格数据集和一个知识库。\n我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。\n我们的框架FeSTE正是这个自动过程。\n我们来看看在一个数据集中输入FeSTE的例子。\n在这个例子中，数据集是大学数据集。\n当它的目标是将大学分为低排名的大学和高排名的大学时。\n我们使用维基百科作为知识库。\nFeSTE的第一阶段是实体链接。\n当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。\n并且知识库的实体文本被提取出来，并添加到数据集中。\n在这个例子中，文本是维基百科页面的摘要。\n现在，我们需要从检索 文本中生成或提取特征。\n因此，我们需要进行特征提取阶段，其中包括文本分析。\n这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。\n在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。\n首先，在原始数据集的类别数量中生成特征。\n在这个例子中，原始数据集有两个类别。\n所以，FeSTE生成两个特征。\n但如果数据集有五个类，FeSTE就会生成五个新的特征。\n每个特征表示每个类的可能性。\n为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。\n但是，我们不可能用输入数据集来训练语言模型。\n因此，有一个朴素的方法是：目标任务微调。\n因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。\n在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。\n接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。\n这种方法的问题是，数据集可能只有几个不同的实体/文本。\n在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。\n因此，在这个数据集上微调语言模型将是无效的。\n但我们可以使用关于预先分析的数据集的先验知识。\n因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。\n我们的建议是，添加另一个微调阶段。\n一个初步的多任务微调阶段。\n当你在n减1数据集上微调语言模型时。\n然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。\n最先进的多任务多任务微调技术称为MTDNN。\n在MTDNN中，MTDNN在训练集的任务数量上保持着头部。\n因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。\n它从训练集中随机抽取一批。\n而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。\n而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。\n在我们的场景中，表格数据集在类的数量上有所不同。\n存在很多的任务。\nMTDNN保持了类、头、输出层的数量。\n另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。\n我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。\n让我们来看一个例子。\n这里是我们的输入数据集，由实体、特征、文本和类组成。\n而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。\n或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。\n因此，标签向量在这种情况下始终保持……它总是由两个类组成。\n而这就是我们精细的、重新制定的微调方法的算法。\n让我们来看看完整的框架。\n数据集送入FeSTE。\n然后，FeSTE执行实体链接阶段。\n它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。\n然后，它将任务重新表述为一个成对的句子分类任务。\n将语言模型应用于新的任务，并对每一类的输出可能性进行分析。\n现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。\n然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。\n为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。\n我们还是使用维基百科来作为知识库。\n我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。\n我们还将每个数据集分成四折，并应用四折交叉验证。\n然后，我们生成新的特征，并使用五个评估分类器对其进行评估。\n在我们的实验中，我们使用基础BERT基础架构。\n以下是我们实验的结果。\n你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。\n而我们重新制定的微调实现了最好的结果，最好的表现。\n而MTDNN比目标 数据集 微调提高了2%。\n我们的方法实现了6%的改进。\n当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。\n但与单独的目标任务微调相比，我们的表现提高到了11%。\n总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。\n它使用一个架构用于所有任务和数据集。\n而且它保留了模型的头部。\n但它增加了重新制定阶段。\n它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。\n我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。\n首先，我想谈谈我们对于推理的动机。\n在这里，我们展示了一个多步骤推理有帮助的例子。\n这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。\n在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。\n但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。\n所以，最好将可解释的多步骤推理作为输出。\n我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。\n在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。\n在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。\n某些假设也适用于之前的工作。\n我们假设数量的精确度是已知的。\n并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。\n此外，复杂的运算符实际上可以分解成这些基本运算符。\n之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。\n传统的序列到序列模型将表达式转换为特定的序列以进行生成。\n这很容易实现，可以概括成许多不同的复杂问题。\n但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。\n但因为转换器模型的原因，实际上这个方向仍然很受欢迎。\n因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。\n所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。\n这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。\n其次，其中还包含一些重复的计算。\n如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。\n在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。\n例如，在第二步中，我们可以得到这些除数，即27。\n我们也可以回头参考原始问题来查找相关内容。\n在这些步骤中，我们得到了除数。\n然后在第三步，我们实际上得到了商。\n好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。\n在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。\n这使得这个过程更加准确。\n在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。\n表达式由e i j o p表示。\n我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。\n我们在这里也有减法与单词代表相反的方向。\n这与关系提取 非常相似。\n在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。\n我们把它添加到下一个状态，成为一个新的数量。\n这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。\n在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。\n一旦我们得到数量陈述，我们就可以开始做推理。\n这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。\n首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。\n最后，我们得到表达式表达q_1除以q_2。\n但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。\n这里所有可能的表达式等于运算符数量的三倍。\n这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。\n例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。\n所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。\n所以，这个数量来自之前计算的表达式。\n我们最终可以得到最后这个表达式q_3乘以q_4。\n我们还可以看到，所有可能的表达式的数字与之前的步骤不同。\n这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。\n训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。\n在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。\n这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。\n它还允许我们根据先前的知识施加某些约束。\n我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。\n在这里，我们简要地展示了与之前最佳方法相比的结果。\n我们表现最好的变体是Roberta-DeductiveReasoner。\n事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。\n没错。最好的方法通常是基于树的模型。\n总的来说，我们的推理能够显著优于这个基于树的模型。\n但我们可以看到，MathQA或SVAMP上的绝对数字并不高。\n我们进一步研究SVAMP的结果。\n这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。\n在我们的预测中，我们发现一些中间值实际上是负数。\n例如，在这些问题中，我们问Jake有多少个苹果？\n但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。\n我们的模型做出了一些这样的预测，产生了负值。\n我们观察到这两个表达式实际上有相似的分数。\n我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。\n我们进一步发现，针对某些模型，这种约束实际上改善了很多。\n例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。\n因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。\n我们还试图分析所有这些数据集背后的困难。\n我们假设这里的未使用数量的数量可以被视为不相关的信息。\n在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。\n在这里，我们还展示了整体表现。\n对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。\n但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。\n对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。\n最后，我们想通过一个问题扰动的例子来展示可解释性。\n在这里，我们的模型实际上在第一步就做出了错误的预测。\n我们实际上可以将这个表达式与这里的句子相关联。好。\n我们认为这个句子可能会误导模型做出错误的预测。\n在这里再植入一个35，会使得模型以为它是一个加法运算符。\n我们尝试将句子修改为类似梨树的数量比苹果树少35棵。\n我们使其传达更准确的语义，以便模型能够使预测正确。\n这项研究展示了可解释预测如何帮助我们理解模型行为。\n对我们的工作做个总结，首先我们的模型实际上是非常有效的。\n我们能够提供可解释的解决程序。\n我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。\n最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。\n我们也有一定的局限性。\n如果我们有大量 数量的运算符或常量，内存消耗可能相当高。\n第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。\n我的演讲到此结束，欢迎各位提出问题。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。\n我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。\n法律问题是许多人生活中不可或缺的一部分。\n但大多数公民对他们的权利和基本法律程序知之甚少。\n结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。\n所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。\n这样一个系统可以为非技术人员提供免费的专业法律援助服务。\n在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。\n给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？\n需要一个模型来从大量立法中检索所有相关的法定条款。\n这种信息检索 任务有其自身的一系列挑战。\n首先，它涉及两种类型的语言。\n针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。\n这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。\n此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。\n相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。\n最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。\n在这里，有一些有可能是长达六千字的长文档。\n自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。\n但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。\n在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。\n我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。\n这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。\n每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。\n现在，让我们来谈谈我们是如何收集这个数据集的。\n首先，我们从汇编大量语料库的法律条款开始。\n我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。\n然后，我们参考相关法规收集了法律问题。\n为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。\n我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。\n我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。\n最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。\n其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。\n我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。\n此外，每个问题都具有主类别和一系列子类别。\n每个条款都带有法律结构中子序列标题的联结。\n这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。\n让我们来看看我们的数据集的一些特征。\n这些问题的长度在5到44个单词之间，中位数为14个单词。\n条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。\n最长的一条有5790个单词。\n如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。\n则其余的15%则涉及社会保障、外国人或工作。\n这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。\n以下是从这些比利时法典中收集的条款总数。\n在22633个条款中，只有1612个与数据集中的至少一个问题相关。\n这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。\n与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。\n这可以解释为，这些法典较少关注个人及个人关心的问题。\n总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。\n使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。\n给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。\n我们使用标准的 TF-IDF和BM25排序函数进行实验。\n这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。\n为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。\n我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。\n这些嵌入通常来自于对单词嵌入模型输出的池化操作。\n首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。\n我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。\n此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。\n请注意，针对训练，我们尝试使用了双编码器架构的两种风格。\n第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。\n我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。\n以下是我们在测试集上的基线结果。\n上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。\n总体而言，微调的双编码器明显优于所有其他基线。\n双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。\n虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。\n关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。\n此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。\n虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。\n最后，让我们讨论一下数据集的两个局限性。\n首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。\n在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。\n因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。\n其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。\n例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？\n在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。\n相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。\n例如，租户每周举行两次派对，直到凌晨2点。\n因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。\n我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。\n这可以帮助改善所有人对司法的利用。\n您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。\n我们为什么要费尽心思设立这个基准呢？\n那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。\n这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。\n因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。\n但我们是否知道模型实际上学到了什么？\n视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？\n而这一个的低分呢？\n视觉和语言模型关注的是正确的事情吗？\n还是像之前的工作所显示的那样，他们专注于偏差？\n为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。\n我们的目标是存在性、复数、计数、空间关系、动作和实体共指。\n但是，我们如何测试视觉和语言模型是否捕获了这种现象？\n通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。\n干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。\n当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。\n例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。\n计数和共指也是具有多种工具的方面。\n当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。\n这并不容易，因为被干扰的标题可能比原始标题更不可能。\n例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。\n所以，要制造有效的干扰，我们必须想方设法。\n首先，我们利用强大的语言模型来提出干扰。\n其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。\n为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。\n我们认为图像是前提，其标题是其附带的假设。\n此外，我们认为标题是前提，而干扰词是其假设。\n如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。\n如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。\n但这个过程并不完美，它只是一个有效干扰词的指标。\n所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。\n因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。\n请注意，VALSE不提供任何训练数据，而仅提供测试数据。\n由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。\n微调只会使模型能够利用数据中的工件或统计 偏差。\n我们都知道，这些模型喜欢作弊和走捷径。\n正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。\n我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。\n我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。\n也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。\n有关更多指标及其结果，请查看我们的论文。\n这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。\n值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。\n但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。\n我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。\n关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。\n他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。\n从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。\n作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。\n如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。\n有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。\n因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。\n我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。\n我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。\n更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。\n如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "大家好，我是东京大学的Kamezawa。\n我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。\n我将按照这个顺序解释。\n首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。\n发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。\n这个图像显示的是vuejs库的2.6.4版本的发行说明。\n发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。\n因此，如果能够自动生成高质量的发行说明，那将是非常有用的。\n我将遵从之前的两项关于自动生成发行说明的研究。\n第一个是被称为ARENA的系统 ，发布于2014年。\n它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。\n这个系统最显著的特征是右上角的问题提取器。\n这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。\n换句话说，它不能用于GitHub上的许多项目。\n第二个是Glyph ，最近在2020年宣布。\n它可以在互联网上下载，并可以通过pip安装。\n这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。\n此图像是一个返回纠正或错误修复标签的示例用法。\nGlyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。\n文本分类模型的表现不佳。\n我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。\n我们的论文解决了这两个问题，并自动生成了高质量的发行说明。\n面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。\n这个提议的方法可以用于所有英语存储库。\n对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。\n接下来，我将介绍我们的数据集。\n以下是数据的示例。\n左侧是提交消息，右侧是发行说明。\n发行说明被标记为优化或修复等。\n我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。\n这可以看作是一项总结 任务。\n我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。\n这些都是基于之前的研究和其他因素设定的。\n右下角的发行说明是从左下角的发行说明中提取的。\n现在，有必要检测事先设置好的四个标签。\n但是，标签并不总是与每个存储库一致。\n例如，改进标签包括改进、增强、优化等。\n我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。\n这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。\n接下来是提交消息。\n提交信息并不与每个版本相联系。\n如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。\n这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。\n我们创建了一个启发式匹配规则来获取上一个和下一个版本。\n数据集分析。\n最后，收集到了7200个存储库和82000份数据。\n此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。\n此外，独特的令牌数量也相当是大的，有883万个。\n这是由于在资源库中发现了大量独特的类或方法名称。\n接下来，我将解释所提议的方法。\n这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。\n一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。\n首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。\n被归类为“其他”的提交消息将被丢弃。\n然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。\n在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。\n所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。\n我们通过两种不同的方法对分类抽象总结方法进行建模。\n第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。\n输出的文本可以根据特殊的类特定端点符号分为分类段落。\n第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。\n好，让我解释一下实验。\n我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。\n关于评估，在某些情况下，发行说明是以多个句子形式输出的。\n由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。\n当系统输出一个短句时，BLEU会受到惩罚。\n在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。\n最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。\n更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。\n结果如下。\n由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。\nCEAS和CAS的ROUGE-L得分比基线高10分以上。\n特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。\n这些结果表明CEAS和CAS受到严重影响。\nCEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。\nCEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。\nCAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。\n这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。\n这里有一个错误分析。\nCAS方法倾向于输出比人类参考句子更短的句子。\n在右图中，引用句子有3或4个句子 ，而CAS只有1个。\n这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。\n此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。\n右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。\n下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。\n最后，一个结论。\n我们已经建立了一个新的数据集，用于自动生成发行说明。\n我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。\n我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。\n请查看我们在GitHub上的数据集。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我想谈谈我们对于推理的动机。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们展示了一个多步骤推理有帮助的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，最好将可解释的多步骤推理作为输出。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "某些假设也适用于之前的工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设数量的精确度是已知的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，复杂的运算符实际上可以分解成这些基本运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "传统的序列到序列模型将表达式转换为特定的序列以进行生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这很容易实现，可以概括成许多不同的复杂问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但因为转换器模型的原因，实际上这个方向仍然很受欢迎。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，其中还包含一些重复的计算。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在第二步中，我们可以得到这些除数，即27。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也可以回头参考原始问题来查找相关内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这些步骤中，我们得到了除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后在第三步，我们实际上得到了商。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这使得这个过程更加准确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "表达式由e i j o p表示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在这里也有减法与单词代表相反的方向。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这与关系提取 非常相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们把它添加到下一个状态，成为一个新的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一旦我们得到数量陈述，我们就可以开始做推理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们得到表达式表达q_1除以q_2。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里所有可能的表达式等于运算符数量的三倍。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，这个数量来自之前计算的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终可以得到最后这个表达式q_3乘以q_4。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还可以看到，所有可能的表达式的数字与之前的步骤不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它还允许我们根据先前的知识施加某些约束。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们简要地展示了与之前最佳方法相比的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们表现最好的变体是Roberta-DeductiveReasoner。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "没错。最好的方法通常是基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总的来说，我们的推理能够显著优于这个基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以看到，MathQA或SVAMP上的绝对数字并不高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步研究SVAMP的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的预测中，我们发现一些中间值实际上是负数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在这些问题中，我们问Jake有多少个苹果？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的模型做出了一些这样的预测，产生了负值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们观察到这两个表达式实际上有相似的分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步发现，针对某些模型，这种约束实际上改善了很多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还试图分析所有这些数据集背后的困难。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设这里的未使用数量的数量可以被视为不相关的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们还展示了整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们想通过一个问题扰动的例子来展示可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们的模型实际上在第一步就做出了错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以将这个表达式与这里的句子相关联。好。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为这个句子可能会误导模型做出错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里再植入一个35，会使得模型以为它是一个加法运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试将句子修改为类似梨树的数量比苹果树少35棵。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使其传达更准确的语义，以便模型能够使预测正确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这项研究展示了可解释预测如何帮助我们理解模型行为。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对我们的工作做个总结，首先我们的模型实际上是非常有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们能够提供可解释的解决程序。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也有一定的局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们有大量 数量的运算符或常量，内存消耗可能相当高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我的演讲到此结束，欢迎各位提出问题。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "法律问题是许多人生活中不可或缺的一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但大多数公民对他们的权利和基本法律程序知之甚少。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这样一个系统可以为非技术人员提供免费的专业法律援助服务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "需要一个模型来从大量立法中检索所有相关的法定条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种信息检索 任务有其自身的一系列挑战。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，它涉及两种类型的语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，有一些有可能是长达六千字的长文档。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，让我们来谈谈我们是如何收集这个数据集的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们从汇编大量语料库的法律条款开始。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们参考相关法规收集了法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，每个问题都具有主类别和一系列子类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个条款都带有法律结构中子序列标题的联结。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看我们的数据集的一些特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题的长度在5到44个单词之间，中位数为14个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最长的一条有5790个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "则其余的15%则涉及社会保障、外国人或工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是从这些比利时法典中收集的条款总数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在22633个条款中，只有1612个与数据集中的至少一个问题相关。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以解释为，这些法典较少关注个人及个人关心的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用标准的 TF-IDF和BM25排序函数进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些嵌入通常来自于对单词嵌入模型输出的池化操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，针对训练，我们尝试使用了双编码器架构的两种风格。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们在测试集上的基线结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，微调的双编码器明显优于所有其他基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，让我们讨论一下数据集的两个局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，租户每周举行两次派对，直到凌晨2点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以帮助改善所有人对司法的利用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为什么要费尽心思设立这个基准呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们是否知道模型实际上学到了什么？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这一个的低分呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言模型关注的是正确的事情吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "还是像之前的工作所显示的那样，他们专注于偏差？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的目标是存在性、复数、计数、空间关系、动作和实体共指。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们如何测试视觉和语言模型是否捕获了这种现象？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "计数和共指也是具有多种工具的方面。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这并不容易，因为被干扰的标题可能比原始标题更不可能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，要制造有效的干扰，我们必须想方设法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们利用强大的语言模型来提出干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为图像是前提，其标题是其附带的假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们认为标题是前提，而干扰词是其假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但这个过程并不完美，它只是一个有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，VALSE不提供任何训练数据，而仅提供测试数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "微调只会使模型能够利用数据中的工件或统计 偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们都知道，这些模型喜欢作弊和走捷径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有关更多指标及其结果，请查看我们的论文。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我是东京大学的Kamezawa。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将按照这个顺序解释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个图像显示的是vuejs库的2.6.4版本的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，如果能够自动生成高质量的发行说明，那将是非常有用的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将遵从之前的两项关于自动生成发行说明的研究。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一个是被称为ARENA的系统 ，发布于2014年。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统最显著的特征是右上角的问题提取器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "换句话说，它不能用于GitHub上的许多项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二个是Glyph ，最近在2020年宣布。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它可以在互联网上下载，并可以通过pip安装。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此图像是一个返回纠正或错误修复标签的示例用法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Glyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "文本分类模型的表现不佳。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的论文解决了这两个问题，并自动生成了高质量的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个提议的方法可以用于所有英语存储库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将介绍我们的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是数据的示例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "左侧是提交消息，右侧是发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明被标记为优化或修复等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以看作是一项总结 任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些都是基于之前的研究和其他因素设定的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右下角的发行说明是从左下角的发行说明中提取的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，有必要检测事先设置好的四个标签。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，标签并不总是与每个存储库一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，改进标签包括改进、增强、优化等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来是提交消息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "提交信息并不与每个版本相联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们创建了一个启发式匹配规则来获取上一个和下一个版本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，收集到了7200个存储库和82000份数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，独特的令牌数量也相当是大的，有883万个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是由于在资源库中发现了大量独特的类或方法名称。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将解释所提议的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "被归类为“其他”的提交消息将被丢弃。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们通过两种不同的方法对分类抽象总结方法进行建模。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "输出的文本可以根据特殊的类特定端点符号分为分类段落。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好，让我解释一下实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于评估，在某些情况下，发行说明是以多个句子形式输出的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当系统输出一个短句时，BLEU会受到惩罚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS和CAS的ROUGE-L得分比基线高10分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些结果表明CEAS和CAS受到严重影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里有一个错误分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS方法倾向于输出比人类参考句子更短的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在右图中，引用句子有3或4个句子 ，而CAS只有1个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，一个结论。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们已经建立了一个新的数据集，用于自动生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请查看我们在GitHub上的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。我的名字是Asaf Harari。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但有时，这些特征是有限的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用另一个数据来源生成特征可能会增加大量的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "假设我们有一个表格数据集和一个知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的框架FeSTE正是这个自动过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们来看看在一个数据集中输入FeSTE的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，数据集是大学数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当它的目标是将大学分为低排名的大学和高排名的大学时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用维基百科作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "FeSTE的第一阶段是实体链接。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且知识库的实体文本被提取出来，并添加到数据集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，文本是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，我们需要从检索 文本中生成或提取特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们需要进行特征提取阶段，其中包括文本分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，在原始数据集的类别数量中生成特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，原始数据集有两个类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，FeSTE生成两个特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但如果数据集有五个类，FeSTE就会生成五个新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个特征表示每个类的可能性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们不可能用输入数据集来训练语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有一个朴素的方法是：目标任务微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种方法的问题是，数据集可能只有几个不同的实体/文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个数据集上微调语言模型将是无效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以使用关于预先分析的数据集的先验知识。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的建议是，添加另一个微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个初步的多任务微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当你在n减1数据集上微调语言模型时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最先进的多任务多任务微调技术称为MTDNN。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在MTDNN中，MTDNN在训练集的任务数量上保持着头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从训练集中随机抽取一批。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的场景中，表格数据集在类的数量上有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "存在很多的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "MTDNN保持了类、头、输出层的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看一个例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里是我们的输入数据集，由实体、特征、文本和类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，标签向量在这种情况下始终保持……它总是由两个类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这就是我们精细的、重新制定的微调方法的算法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看完整的框架。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集送入FeSTE。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，FeSTE执行实体链接阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，它将任务重新表述为一个成对的句子分类任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "将语言模型应用于新的任务，并对每一类的输出可能性进行分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还是使用维基百科来作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还将每个数据集分成四折，并应用四折交叉验证。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们生成新的特征，并使用五个评估分类器对其进行评估。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，我们使用基础BERT基础架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们实验的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而我们重新制定的微调实现了最好的结果，最好的表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而MTDNN比目标 数据集 微调提高了2%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法实现了6%的改进。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但与单独的目标任务微调相比，我们的表现提高到了11%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它使用一个架构用于所有任务和数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且它保留了模型的头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但它增加了重新制定阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "大家好。我的名字是Asaf Harari。\n我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。\n数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。\n但有时，这些特征是有限的。\n使用另一个数据来源生成特征可能会增加大量的信息。\n我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。\n假设我们有一个表格数据集和一个知识库。\n我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。\n我们的框架FeSTE正是这个自动过程。\n我们来看看在一个数据集中输入FeSTE的例子。\n在这个例子中，数据集是大学数据集。\n当它的目标是将大学分为低排名的大学和高排名的大学时。\n我们使用维基百科作为知识库。\nFeSTE的第一阶段是实体链接。\n当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。\n并且知识库的实体文本被提取出来，并添加到数据集中。\n在这个例子中，文本是维基百科页面的摘要。\n现在，我们需要从检索 文本中生成或提取特征。\n因此，我们需要进行特征提取阶段，其中包括文本分析。\n这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。\n在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。\n首先，在原始数据集的类别数量中生成特征。\n在这个例子中，原始数据集有两个类别。\n所以，FeSTE生成两个特征。\n但如果数据集有五个类，FeSTE就会生成五个新的特征。\n每个特征表示每个类的可能性。\n为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。\n但是，我们不可能用输入数据集来训练语言模型。\n因此，有一个朴素的方法是：目标任务微调。\n因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。\n在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。\n接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。\n这种方法的问题是，数据集可能只有几个不同的实体/文本。\n在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。\n因此，在这个数据集上微调语言模型将是无效的。\n但我们可以使用关于预先分析的数据集的先验知识。\n因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。\n我们的建议是，添加另一个微调阶段。\n一个初步的多任务微调阶段。\n当你在n减1数据集上微调语言模型时。\n然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。\n最先进的多任务多任务微调技术称为MTDNN。\n在MTDNN中，MTDNN在训练集的任务数量上保持着头部。\n因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。\n它从训练集中随机抽取一批。\n而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。\n而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。\n在我们的场景中，表格数据集在类的数量上有所不同。\n存在很多的任务。\nMTDNN保持了类、头、输出层的数量。\n另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。\n我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。\n让我们来看一个例子。\n这里是我们的输入数据集，由实体、特征、文本和类组成。\n而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。\n或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。\n因此，标签向量在这种情况下始终保持……它总是由两个类组成。\n而这就是我们精细的、重新制定的微调方法的算法。\n让我们来看看完整的框架。\n数据集送入FeSTE。\n然后，FeSTE执行实体链接阶段。\n它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。\n然后，它将任务重新表述为一个成对的句子分类任务。\n将语言模型应用于新的任务，并对每一类的输出可能性进行分析。\n现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。\n然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。\n为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。\n我们还是使用维基百科来作为知识库。\n我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。\n我们还将每个数据集分成四折，并应用四折交叉验证。\n然后，我们生成新的特征，并使用五个评估分类器对其进行评估。\n在我们的实验中，我们使用基础BERT基础架构。\n以下是我们实验的结果。\n你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。\n而我们重新制定的微调实现了最好的结果，最好的表现。\n而MTDNN比目标 数据集 微调提高了2%。\n我们的方法实现了6%的改进。\n当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。\n但与单独的目标任务微调相比，我们的表现提高到了11%。\n总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。\n它使用一个架构用于所有任务和数据集。\n而且它保留了模型的头部。\n但它增加了重新制定阶段。\n它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。\n我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。\n首先，我想谈谈我们对于推理的动机。\n在这里，我们展示了一个多步骤推理有帮助的例子。\n这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。\n在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。\n但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。\n所以，最好将可解释的多步骤推理作为输出。\n我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。\n在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。\n在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。\n某些假设也适用于之前的工作。\n我们假设数量的精确度是已知的。\n并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。\n此外，复杂的运算符实际上可以分解成这些基本运算符。\n之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。\n传统的序列到序列模型将表达式转换为特定的序列以进行生成。\n这很容易实现，可以概括成许多不同的复杂问题。\n但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。\n但因为转换器模型的原因，实际上这个方向仍然很受欢迎。\n因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。\n所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。\n这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。\n其次，其中还包含一些重复的计算。\n如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。\n在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。\n例如，在第二步中，我们可以得到这些除数，即27。\n我们也可以回头参考原始问题来查找相关内容。\n在这些步骤中，我们得到了除数。\n然后在第三步，我们实际上得到了商。\n好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。\n在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。\n这使得这个过程更加准确。\n在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。\n表达式由e i j o p表示。\n我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。\n我们在这里也有减法与单词代表相反的方向。\n这与关系提取 非常相似。\n在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。\n我们把它添加到下一个状态，成为一个新的数量。\n这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。\n在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。\n一旦我们得到数量陈述，我们就可以开始做推理。\n这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。\n首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。\n最后，我们得到表达式表达q_1除以q_2。\n但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。\n这里所有可能的表达式等于运算符数量的三倍。\n这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。\n例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。\n所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。\n所以，这个数量来自之前计算的表达式。\n我们最终可以得到最后这个表达式q_3乘以q_4。\n我们还可以看到，所有可能的表达式的数字与之前的步骤不同。\n这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。\n训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。\n在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。\n这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。\n它还允许我们根据先前的知识施加某些约束。\n我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。\n在这里，我们简要地展示了与之前最佳方法相比的结果。\n我们表现最好的变体是Roberta-DeductiveReasoner。\n事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。\n没错。最好的方法通常是基于树的模型。\n总的来说，我们的推理能够显著优于这个基于树的模型。\n但我们可以看到，MathQA或SVAMP上的绝对数字并不高。\n我们进一步研究SVAMP的结果。\n这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。\n在我们的预测中，我们发现一些中间值实际上是负数。\n例如，在这些问题中，我们问Jake有多少个苹果？\n但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。\n我们的模型做出了一些这样的预测，产生了负值。\n我们观察到这两个表达式实际上有相似的分数。\n我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。\n我们进一步发现，针对某些模型，这种约束实际上改善了很多。\n例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。\n因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。\n我们还试图分析所有这些数据集背后的困难。\n我们假设这里的未使用数量的数量可以被视为不相关的信息。\n在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。\n在这里，我们还展示了整体表现。\n对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。\n但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。\n对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。\n最后，我们想通过一个问题扰动的例子来展示可解释性。\n在这里，我们的模型实际上在第一步就做出了错误的预测。\n我们实际上可以将这个表达式与这里的句子相关联。好。\n我们认为这个句子可能会误导模型做出错误的预测。\n在这里再植入一个35，会使得模型以为它是一个加法运算符。\n我们尝试将句子修改为类似梨树的数量比苹果树少35棵。\n我们使其传达更准确的语义，以便模型能够使预测正确。\n这项研究展示了可解释预测如何帮助我们理解模型行为。\n对我们的工作做个总结，首先我们的模型实际上是非常有效的。\n我们能够提供可解释的解决程序。\n我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。\n最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。\n我们也有一定的局限性。\n如果我们有大量 数量的运算符或常量，内存消耗可能相当高。\n第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。\n我的演讲到此结束，欢迎各位提出问题。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。\n我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。\n法律问题是许多人生活中不可或缺的一部分。\n但大多数公民对他们的权利和基本法律程序知之甚少。\n结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。\n所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。\n这样一个系统可以为非技术人员提供免费的专业法律援助服务。\n在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。\n给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？\n需要一个模型来从大量立法中检索所有相关的法定条款。\n这种信息检索 任务有其自身的一系列挑战。\n首先，它涉及两种类型的语言。\n针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。\n这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。\n此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。\n相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。\n最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。\n在这里，有一些有可能是长达六千字的长文档。\n自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。\n但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。\n在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。\n我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。\n这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。\n每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。\n现在，让我们来谈谈我们是如何收集这个数据集的。\n首先，我们从汇编大量语料库的法律条款开始。\n我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。\n然后，我们参考相关法规收集了法律问题。\n为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。\n我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。\n我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。\n最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。\n其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。\n我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。\n此外，每个问题都具有主类别和一系列子类别。\n每个条款都带有法律结构中子序列标题的联结。\n这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。\n让我们来看看我们的数据集的一些特征。\n这些问题的长度在5到44个单词之间，中位数为14个单词。\n条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。\n最长的一条有5790个单词。\n如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。\n则其余的15%则涉及社会保障、外国人或工作。\n这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。\n以下是从这些比利时法典中收集的条款总数。\n在22633个条款中，只有1612个与数据集中的至少一个问题相关。\n这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。\n与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。\n这可以解释为，这些法典较少关注个人及个人关心的问题。\n总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。\n使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。\n给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。\n我们使用标准的 TF-IDF和BM25排序函数进行实验。\n这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。\n为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。\n我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。\n这些嵌入通常来自于对单词嵌入模型输出的池化操作。\n首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。\n我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。\n此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。\n请注意，针对训练，我们尝试使用了双编码器架构的两种风格。\n第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。\n我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。\n以下是我们在测试集上的基线结果。\n上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。\n总体而言，微调的双编码器明显优于所有其他基线。\n双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。\n虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。\n关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。\n此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。\n虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。\n最后，让我们讨论一下数据集的两个局限性。\n首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。\n在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。\n因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。\n其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。\n例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？\n在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。\n相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。\n例如，租户每周举行两次派对，直到凌晨2点。\n因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。\n我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。\n这可以帮助改善所有人对司法的利用。\n您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。\n我们为什么要费尽心思设立这个基准呢？\n那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。\n这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。\n因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。\n但我们是否知道模型实际上学到了什么？\n视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？\n而这一个的低分呢？\n视觉和语言模型关注的是正确的事情吗？\n还是像之前的工作所显示的那样，他们专注于偏差？\n为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。\n我们的目标是存在性、复数、计数、空间关系、动作和实体共指。\n但是，我们如何测试视觉和语言模型是否捕获了这种现象？\n通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。\n干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。\n当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。\n例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。\n计数和共指也是具有多种工具的方面。\n当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。\n这并不容易，因为被干扰的标题可能比原始标题更不可能。\n例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。\n所以，要制造有效的干扰，我们必须想方设法。\n首先，我们利用强大的语言模型来提出干扰。\n其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。\n为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。\n我们认为图像是前提，其标题是其附带的假设。\n此外，我们认为标题是前提，而干扰词是其假设。\n如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。\n如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。\n但这个过程并不完美，它只是一个有效干扰词的指标。\n所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。\n因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。\n请注意，VALSE不提供任何训练数据，而仅提供测试数据。\n由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。\n微调只会使模型能够利用数据中的工件或统计 偏差。\n我们都知道，这些模型喜欢作弊和走捷径。\n正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。\n我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。\n我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。\n也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。\n有关更多指标及其结果，请查看我们的论文。\n这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。\n值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。\n但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。\n我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。\n关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。\n他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。\n从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。\n作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。\n如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。\n有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。\n因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。\n我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。\n我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。\n更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。\n如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "大家好，我是东京大学的Kamezawa。\n我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。\n我将按照这个顺序解释。\n首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。\n发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。\n这个图像显示的是vuejs库的2.6.4版本的发行说明。\n发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。\n因此，如果能够自动生成高质量的发行说明，那将是非常有用的。\n我将遵从之前的两项关于自动生成发行说明的研究。\n第一个是被称为ARENA的系统 ，发布于2014年。\n它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。\n这个系统最显著的特征是右上角的问题提取器。\n这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。\n换句话说，它不能用于GitHub上的许多项目。\n第二个是Glyph ，最近在2020年宣布。\n它可以在互联网上下载，并可以通过pip安装。\n这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。\n此图像是一个返回纠正或错误修复标签的示例用法。\nGlyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。\n文本分类模型的表现不佳。\n我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。\n我们的论文解决了这两个问题，并自动生成了高质量的发行说明。\n面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。\n这个提议的方法可以用于所有英语存储库。\n对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。\n接下来，我将介绍我们的数据集。\n以下是数据的示例。\n左侧是提交消息，右侧是发行说明。\n发行说明被标记为优化或修复等。\n我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。\n这可以看作是一项总结 任务。\n我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。\n这些都是基于之前的研究和其他因素设定的。\n右下角的发行说明是从左下角的发行说明中提取的。\n现在，有必要检测事先设置好的四个标签。\n但是，标签并不总是与每个存储库一致。\n例如，改进标签包括改进、增强、优化等。\n我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。\n这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。\n接下来是提交消息。\n提交信息并不与每个版本相联系。\n如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。\n这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。\n我们创建了一个启发式匹配规则来获取上一个和下一个版本。\n数据集分析。\n最后，收集到了7200个存储库和82000份数据。\n此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。\n此外，独特的令牌数量也相当是大的，有883万个。\n这是由于在资源库中发现了大量独特的类或方法名称。\n接下来，我将解释所提议的方法。\n这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。\n一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。\n首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。\n被归类为“其他”的提交消息将被丢弃。\n然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。\n在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。\n所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。\n我们通过两种不同的方法对分类抽象总结方法进行建模。\n第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。\n输出的文本可以根据特殊的类特定端点符号分为分类段落。\n第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。\n好，让我解释一下实验。\n我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。\n关于评估，在某些情况下，发行说明是以多个句子形式输出的。\n由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。\n当系统输出一个短句时，BLEU会受到惩罚。\n在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。\n最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。\n更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。\n结果如下。\n由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。\nCEAS和CAS的ROUGE-L得分比基线高10分以上。\n特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。\n这些结果表明CEAS和CAS受到严重影响。\nCEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。\nCEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。\nCAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。\n这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。\n这里有一个错误分析。\nCAS方法倾向于输出比人类参考句子更短的句子。\n在右图中，引用句子有3或4个句子 ，而CAS只有1个。\n这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。\n此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。\n右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。\n下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。\n最后，一个结论。\n我们已经建立了一个新的数据集，用于自动生成发行说明。\n我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。\n我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。\n请查看我们在GitHub上的数据集。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我想谈谈我们对于推理的动机。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们展示了一个多步骤推理有帮助的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，最好将可解释的多步骤推理作为输出。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "某些假设也适用于之前的工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设数量的精确度是已知的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，复杂的运算符实际上可以分解成这些基本运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "传统的序列到序列模型将表达式转换为特定的序列以进行生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这很容易实现，可以概括成许多不同的复杂问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但因为转换器模型的原因，实际上这个方向仍然很受欢迎。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，其中还包含一些重复的计算。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在第二步中，我们可以得到这些除数，即27。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也可以回头参考原始问题来查找相关内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这些步骤中，我们得到了除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后在第三步，我们实际上得到了商。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这使得这个过程更加准确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "表达式由e i j o p表示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在这里也有减法与单词代表相反的方向。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这与关系提取 非常相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们把它添加到下一个状态，成为一个新的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一旦我们得到数量陈述，我们就可以开始做推理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们得到表达式表达q_1除以q_2。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里所有可能的表达式等于运算符数量的三倍。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，这个数量来自之前计算的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终可以得到最后这个表达式q_3乘以q_4。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还可以看到，所有可能的表达式的数字与之前的步骤不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它还允许我们根据先前的知识施加某些约束。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们简要地展示了与之前最佳方法相比的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们表现最好的变体是Roberta-DeductiveReasoner。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "没错。最好的方法通常是基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总的来说，我们的推理能够显著优于这个基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以看到，MathQA或SVAMP上的绝对数字并不高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步研究SVAMP的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的预测中，我们发现一些中间值实际上是负数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在这些问题中，我们问Jake有多少个苹果？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的模型做出了一些这样的预测，产生了负值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们观察到这两个表达式实际上有相似的分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步发现，针对某些模型，这种约束实际上改善了很多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还试图分析所有这些数据集背后的困难。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设这里的未使用数量的数量可以被视为不相关的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们还展示了整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们想通过一个问题扰动的例子来展示可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们的模型实际上在第一步就做出了错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以将这个表达式与这里的句子相关联。好。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为这个句子可能会误导模型做出错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里再植入一个35，会使得模型以为它是一个加法运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试将句子修改为类似梨树的数量比苹果树少35棵。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使其传达更准确的语义，以便模型能够使预测正确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这项研究展示了可解释预测如何帮助我们理解模型行为。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对我们的工作做个总结，首先我们的模型实际上是非常有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们能够提供可解释的解决程序。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也有一定的局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们有大量 数量的运算符或常量，内存消耗可能相当高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我的演讲到此结束，欢迎各位提出问题。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "法律问题是许多人生活中不可或缺的一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但大多数公民对他们的权利和基本法律程序知之甚少。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这样一个系统可以为非技术人员提供免费的专业法律援助服务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "需要一个模型来从大量立法中检索所有相关的法定条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种信息检索 任务有其自身的一系列挑战。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，它涉及两种类型的语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，有一些有可能是长达六千字的长文档。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，让我们来谈谈我们是如何收集这个数据集的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们从汇编大量语料库的法律条款开始。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们参考相关法规收集了法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，每个问题都具有主类别和一系列子类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个条款都带有法律结构中子序列标题的联结。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看我们的数据集的一些特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题的长度在5到44个单词之间，中位数为14个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最长的一条有5790个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "则其余的15%则涉及社会保障、外国人或工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是从这些比利时法典中收集的条款总数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在22633个条款中，只有1612个与数据集中的至少一个问题相关。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以解释为，这些法典较少关注个人及个人关心的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用标准的 TF-IDF和BM25排序函数进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些嵌入通常来自于对单词嵌入模型输出的池化操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，针对训练，我们尝试使用了双编码器架构的两种风格。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们在测试集上的基线结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，微调的双编码器明显优于所有其他基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，让我们讨论一下数据集的两个局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，租户每周举行两次派对，直到凌晨2点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以帮助改善所有人对司法的利用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为什么要费尽心思设立这个基准呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们是否知道模型实际上学到了什么？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这一个的低分呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言模型关注的是正确的事情吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "还是像之前的工作所显示的那样，他们专注于偏差？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的目标是存在性、复数、计数、空间关系、动作和实体共指。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们如何测试视觉和语言模型是否捕获了这种现象？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "计数和共指也是具有多种工具的方面。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这并不容易，因为被干扰的标题可能比原始标题更不可能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，要制造有效的干扰，我们必须想方设法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们利用强大的语言模型来提出干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为图像是前提，其标题是其附带的假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们认为标题是前提，而干扰词是其假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但这个过程并不完美，它只是一个有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，VALSE不提供任何训练数据，而仅提供测试数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "微调只会使模型能够利用数据中的工件或统计 偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们都知道，这些模型喜欢作弊和走捷径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有关更多指标及其结果，请查看我们的论文。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我是东京大学的Kamezawa。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将按照这个顺序解释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个图像显示的是vuejs库的2.6.4版本的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，如果能够自动生成高质量的发行说明，那将是非常有用的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将遵从之前的两项关于自动生成发行说明的研究。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一个是被称为ARENA的系统 ，发布于2014年。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统最显著的特征是右上角的问题提取器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "换句话说，它不能用于GitHub上的许多项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二个是Glyph ，最近在2020年宣布。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它可以在互联网上下载，并可以通过pip安装。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此图像是一个返回纠正或错误修复标签的示例用法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Glyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "文本分类模型的表现不佳。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的论文解决了这两个问题，并自动生成了高质量的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个提议的方法可以用于所有英语存储库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将介绍我们的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是数据的示例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "左侧是提交消息，右侧是发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明被标记为优化或修复等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以看作是一项总结 任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些都是基于之前的研究和其他因素设定的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右下角的发行说明是从左下角的发行说明中提取的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，有必要检测事先设置好的四个标签。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，标签并不总是与每个存储库一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，改进标签包括改进、增强、优化等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来是提交消息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "提交信息并不与每个版本相联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们创建了一个启发式匹配规则来获取上一个和下一个版本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，收集到了7200个存储库和82000份数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，独特的令牌数量也相当是大的，有883万个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是由于在资源库中发现了大量独特的类或方法名称。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将解释所提议的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "被归类为“其他”的提交消息将被丢弃。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们通过两种不同的方法对分类抽象总结方法进行建模。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "输出的文本可以根据特殊的类特定端点符号分为分类段落。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好，让我解释一下实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于评估，在某些情况下，发行说明是以多个句子形式输出的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当系统输出一个短句时，BLEU会受到惩罚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS和CAS的ROUGE-L得分比基线高10分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些结果表明CEAS和CAS受到严重影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里有一个错误分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS方法倾向于输出比人类参考句子更短的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在右图中，引用句子有3或4个句子 ，而CAS只有1个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，一个结论。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们已经建立了一个新的数据集，用于自动生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请查看我们在GitHub上的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。我的名字是Asaf Harari。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但有时，这些特征是有限的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用另一个数据来源生成特征可能会增加大量的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "假设我们有一个表格数据集和一个知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的框架FeSTE正是这个自动过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们来看看在一个数据集中输入FeSTE的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，数据集是大学数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当它的目标是将大学分为低排名的大学和高排名的大学时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用维基百科作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "FeSTE的第一阶段是实体链接。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且知识库的实体文本被提取出来，并添加到数据集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，文本是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，我们需要从检索 文本中生成或提取特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们需要进行特征提取阶段，其中包括文本分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，在原始数据集的类别数量中生成特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，原始数据集有两个类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，FeSTE生成两个特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但如果数据集有五个类，FeSTE就会生成五个新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个特征表示每个类的可能性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们不可能用输入数据集来训练语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有一个朴素的方法是：目标任务微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种方法的问题是，数据集可能只有几个不同的实体/文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个数据集上微调语言模型将是无效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以使用关于预先分析的数据集的先验知识。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的建议是，添加另一个微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个初步的多任务微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当你在n减1数据集上微调语言模型时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最先进的多任务多任务微调技术称为MTDNN。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在MTDNN中，MTDNN在训练集的任务数量上保持着头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从训练集中随机抽取一批。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的场景中，表格数据集在类的数量上有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "存在很多的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "MTDNN保持了类、头、输出层的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看一个例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里是我们的输入数据集，由实体、特征、文本和类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，标签向量在这种情况下始终保持……它总是由两个类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这就是我们精细的、重新制定的微调方法的算法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看完整的框架。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集送入FeSTE。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，FeSTE执行实体链接阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，它将任务重新表述为一个成对的句子分类任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "将语言模型应用于新的任务，并对每一类的输出可能性进行分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还是使用维基百科来作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还将每个数据集分成四折，并应用四折交叉验证。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们生成新的特征，并使用五个评估分类器对其进行评估。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，我们使用基础BERT基础架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们实验的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而我们重新制定的微调实现了最好的结果，最好的表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而MTDNN比目标 数据集 微调提高了2%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法实现了6%的改进。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但与单独的目标任务微调相比，我们的表现提高到了11%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它使用一个架构用于所有任务和数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且它保留了模型的头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但它增加了重新制定阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "大家好。我的名字是Asaf Harari。\n我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。\n数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。\n但有时，这些特征是有限的。\n使用另一个数据来源生成特征可能会增加大量的信息。\n我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。\n假设我们有一个表格数据集和一个知识库。\n我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。\n我们的框架FeSTE正是这个自动过程。\n我们来看看在一个数据集中输入FeSTE的例子。\n在这个例子中，数据集是大学数据集。\n当它的目标是将大学分为低排名的大学和高排名的大学时。\n我们使用维基百科作为知识库。\nFeSTE的第一阶段是实体链接。\n当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。\n并且知识库的实体文本被提取出来，并添加到数据集中。\n在这个例子中，文本是维基百科页面的摘要。\n现在，我们需要从检索 文本中生成或提取特征。\n因此，我们需要进行特征提取阶段，其中包括文本分析。\n这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。\n在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。\n首先，在原始数据集的类别数量中生成特征。\n在这个例子中，原始数据集有两个类别。\n所以，FeSTE生成两个特征。\n但如果数据集有五个类，FeSTE就会生成五个新的特征。\n每个特征表示每个类的可能性。\n为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。\n但是，我们不可能用输入数据集来训练语言模型。\n因此，有一个朴素的方法是：目标任务微调。\n因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。\n在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。\n接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。\n这种方法的问题是，数据集可能只有几个不同的实体/文本。\n在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。\n因此，在这个数据集上微调语言模型将是无效的。\n但我们可以使用关于预先分析的数据集的先验知识。\n因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。\n我们的建议是，添加另一个微调阶段。\n一个初步的多任务微调阶段。\n当你在n减1数据集上微调语言模型时。\n然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。\n最先进的多任务多任务微调技术称为MTDNN。\n在MTDNN中，MTDNN在训练集的任务数量上保持着头部。\n因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。\n它从训练集中随机抽取一批。\n而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。\n而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。\n在我们的场景中，表格数据集在类的数量上有所不同。\n存在很多的任务。\nMTDNN保持了类、头、输出层的数量。\n另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。\n我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。\n让我们来看一个例子。\n这里是我们的输入数据集，由实体、特征、文本和类组成。\n而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。\n或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。\n因此，标签向量在这种情况下始终保持……它总是由两个类组成。\n而这就是我们精细的、重新制定的微调方法的算法。\n让我们来看看完整的框架。\n数据集送入FeSTE。\n然后，FeSTE执行实体链接阶段。\n它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。\n然后，它将任务重新表述为一个成对的句子分类任务。\n将语言模型应用于新的任务，并对每一类的输出可能性进行分析。\n现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。\n然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。\n为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。\n我们还是使用维基百科来作为知识库。\n我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。\n我们还将每个数据集分成四折，并应用四折交叉验证。\n然后，我们生成新的特征，并使用五个评估分类器对其进行评估。\n在我们的实验中，我们使用基础BERT基础架构。\n以下是我们实验的结果。\n你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。\n而我们重新制定的微调实现了最好的结果，最好的表现。\n而MTDNN比目标 数据集 微调提高了2%。\n我们的方法实现了6%的改进。\n当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。\n但与单独的目标任务微调相比，我们的表现提高到了11%。\n总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。\n它使用一个架构用于所有任务和数据集。\n而且它保留了模型的头部。\n但它增加了重新制定阶段。\n它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。\n我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。\n首先，我想谈谈我们对于推理的动机。\n在这里，我们展示了一个多步骤推理有帮助的例子。\n这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。\n在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。\n但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。\n所以，最好将可解释的多步骤推理作为输出。\n我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。\n在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。\n在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。\n某些假设也适用于之前的工作。\n我们假设数量的精确度是已知的。\n并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。\n此外，复杂的运算符实际上可以分解成这些基本运算符。\n之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。\n传统的序列到序列模型将表达式转换为特定的序列以进行生成。\n这很容易实现，可以概括成许多不同的复杂问题。\n但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。\n但因为转换器模型的原因，实际上这个方向仍然很受欢迎。\n因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。\n所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。\n这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。\n其次，其中还包含一些重复的计算。\n如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。\n在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。\n例如，在第二步中，我们可以得到这些除数，即27。\n我们也可以回头参考原始问题来查找相关内容。\n在这些步骤中，我们得到了除数。\n然后在第三步，我们实际上得到了商。\n好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。\n在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。\n这使得这个过程更加准确。\n在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。\n表达式由e i j o p表示。\n我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。\n我们在这里也有减法与单词代表相反的方向。\n这与关系提取 非常相似。\n在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。\n我们把它添加到下一个状态，成为一个新的数量。\n这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。\n在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。\n一旦我们得到数量陈述，我们就可以开始做推理。\n这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。\n首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。\n最后，我们得到表达式表达q_1除以q_2。\n但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。\n这里所有可能的表达式等于运算符数量的三倍。\n这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。\n例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。\n所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。\n所以，这个数量来自之前计算的表达式。\n我们最终可以得到最后这个表达式q_3乘以q_4。\n我们还可以看到，所有可能的表达式的数字与之前的步骤不同。\n这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。\n训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。\n在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。\n这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。\n它还允许我们根据先前的知识施加某些约束。\n我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。\n在这里，我们简要地展示了与之前最佳方法相比的结果。\n我们表现最好的变体是Roberta-DeductiveReasoner。\n事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。\n没错。最好的方法通常是基于树的模型。\n总的来说，我们的推理能够显著优于这个基于树的模型。\n但我们可以看到，MathQA或SVAMP上的绝对数字并不高。\n我们进一步研究SVAMP的结果。\n这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。\n在我们的预测中，我们发现一些中间值实际上是负数。\n例如，在这些问题中，我们问Jake有多少个苹果？\n但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。\n我们的模型做出了一些这样的预测，产生了负值。\n我们观察到这两个表达式实际上有相似的分数。\n我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。\n我们进一步发现，针对某些模型，这种约束实际上改善了很多。\n例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。\n因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。\n我们还试图分析所有这些数据集背后的困难。\n我们假设这里的未使用数量的数量可以被视为不相关的信息。\n在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。\n在这里，我们还展示了整体表现。\n对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。\n但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。\n对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。\n最后，我们想通过一个问题扰动的例子来展示可解释性。\n在这里，我们的模型实际上在第一步就做出了错误的预测。\n我们实际上可以将这个表达式与这里的句子相关联。好。\n我们认为这个句子可能会误导模型做出错误的预测。\n在这里再植入一个35，会使得模型以为它是一个加法运算符。\n我们尝试将句子修改为类似梨树的数量比苹果树少35棵。\n我们使其传达更准确的语义，以便模型能够使预测正确。\n这项研究展示了可解释预测如何帮助我们理解模型行为。\n对我们的工作做个总结，首先我们的模型实际上是非常有效的。\n我们能够提供可解释的解决程序。\n我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。\n最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。\n我们也有一定的局限性。\n如果我们有大量 数量的运算符或常量，内存消耗可能相当高。\n第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。\n我的演讲到此结束，欢迎各位提出问题。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。\n我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。\n法律问题是许多人生活中不可或缺的一部分。\n但大多数公民对他们的权利和基本法律程序知之甚少。\n结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。\n所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。\n这样一个系统可以为非技术人员提供免费的专业法律援助服务。\n在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。\n给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？\n需要一个模型来从大量立法中检索所有相关的法定条款。\n这种信息检索 任务有其自身的一系列挑战。\n首先，它涉及两种类型的语言。\n针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。\n这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。\n此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。\n相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。\n最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。\n在这里，有一些有可能是长达六千字的长文档。\n自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。\n但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。\n在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。\n我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。\n这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。\n每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。\n现在，让我们来谈谈我们是如何收集这个数据集的。\n首先，我们从汇编大量语料库的法律条款开始。\n我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。\n然后，我们参考相关法规收集了法律问题。\n为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。\n我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。\n我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。\n最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。\n其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。\n我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。\n此外，每个问题都具有主类别和一系列子类别。\n每个条款都带有法律结构中子序列标题的联结。\n这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。\n让我们来看看我们的数据集的一些特征。\n这些问题的长度在5到44个单词之间，中位数为14个单词。\n条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。\n最长的一条有5790个单词。\n如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。\n则其余的15%则涉及社会保障、外国人或工作。\n这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。\n以下是从这些比利时法典中收集的条款总数。\n在22633个条款中，只有1612个与数据集中的至少一个问题相关。\n这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。\n与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。\n这可以解释为，这些法典较少关注个人及个人关心的问题。\n总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。\n使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。\n给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。\n我们使用标准的 TF-IDF和BM25排序函数进行实验。\n这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。\n为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。\n我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。\n这些嵌入通常来自于对单词嵌入模型输出的池化操作。\n首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。\n我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。\n此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。\n请注意，针对训练，我们尝试使用了双编码器架构的两种风格。\n第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。\n我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。\n以下是我们在测试集上的基线结果。\n上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。\n总体而言，微调的双编码器明显优于所有其他基线。\n双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。\n虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。\n关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。\n此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。\n虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。\n最后，让我们讨论一下数据集的两个局限性。\n首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。\n在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。\n因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。\n其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。\n例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？\n在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。\n相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。\n例如，租户每周举行两次派对，直到凌晨2点。\n因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。\n我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。\n这可以帮助改善所有人对司法的利用。\n您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。\n我们为什么要费尽心思设立这个基准呢？\n那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。\n这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。\n因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。\n但我们是否知道模型实际上学到了什么？\n视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？\n而这一个的低分呢？\n视觉和语言模型关注的是正确的事情吗？\n还是像之前的工作所显示的那样，他们专注于偏差？\n为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。\n我们的目标是存在性、复数、计数、空间关系、动作和实体共指。\n但是，我们如何测试视觉和语言模型是否捕获了这种现象？\n通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。\n干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。\n当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。\n例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。\n计数和共指也是具有多种工具的方面。\n当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。\n这并不容易，因为被干扰的标题可能比原始标题更不可能。\n例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。\n所以，要制造有效的干扰，我们必须想方设法。\n首先，我们利用强大的语言模型来提出干扰。\n其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。\n为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。\n我们认为图像是前提，其标题是其附带的假设。\n此外，我们认为标题是前提，而干扰词是其假设。\n如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。\n如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。\n但这个过程并不完美，它只是一个有效干扰词的指标。\n所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。\n因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。\n请注意，VALSE不提供任何训练数据，而仅提供测试数据。\n由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。\n微调只会使模型能够利用数据中的工件或统计 偏差。\n我们都知道，这些模型喜欢作弊和走捷径。\n正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。\n我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。\n我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。\n也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。\n有关更多指标及其结果，请查看我们的论文。\n这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。\n值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。\n但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。\n我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。\n关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。\n他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。\n从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。\n作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。\n如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。\n有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。\n因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。\n我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。\n我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。\n更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。\n如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "大家好，我是东京大学的Kamezawa。\n我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。\n我将按照这个顺序解释。\n首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。\n发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。\n这个图像显示的是vuejs库的2.6.4版本的发行说明。\n发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。\n因此，如果能够自动生成高质量的发行说明，那将是非常有用的。\n我将遵从之前的两项关于自动生成发行说明的研究。\n第一个是被称为ARENA的系统 ，发布于2014年。\n它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。\n这个系统最显著的特征是右上角的问题提取器。\n这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。\n换句话说，它不能用于GitHub上的许多项目。\n第二个是Glyph ，最近在2020年宣布。\n它可以在互联网上下载，并可以通过pip安装。\n这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。\n此图像是一个返回纠正或错误修复标签的示例用法。\nGlyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。\n文本分类模型的表现不佳。\n我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。\n我们的论文解决了这两个问题，并自动生成了高质量的发行说明。\n面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。\n这个提议的方法可以用于所有英语存储库。\n对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。\n接下来，我将介绍我们的数据集。\n以下是数据的示例。\n左侧是提交消息，右侧是发行说明。\n发行说明被标记为优化或修复等。\n我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。\n这可以看作是一项总结 任务。\n我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。\n这些都是基于之前的研究和其他因素设定的。\n右下角的发行说明是从左下角的发行说明中提取的。\n现在，有必要检测事先设置好的四个标签。\n但是，标签并不总是与每个存储库一致。\n例如，改进标签包括改进、增强、优化等。\n我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。\n这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。\n接下来是提交消息。\n提交信息并不与每个版本相联系。\n如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。\n这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。\n我们创建了一个启发式匹配规则来获取上一个和下一个版本。\n数据集分析。\n最后，收集到了7200个存储库和82000份数据。\n此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。\n此外，独特的令牌数量也相当是大的，有883万个。\n这是由于在资源库中发现了大量独特的类或方法名称。\n接下来，我将解释所提议的方法。\n这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。\n一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。\n首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。\n被归类为“其他”的提交消息将被丢弃。\n然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。\n在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。\n所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。\n我们通过两种不同的方法对分类抽象总结方法进行建模。\n第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。\n输出的文本可以根据特殊的类特定端点符号分为分类段落。\n第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。\n好，让我解释一下实验。\n我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。\n关于评估，在某些情况下，发行说明是以多个句子形式输出的。\n由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。\n当系统输出一个短句时，BLEU会受到惩罚。\n在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。\n最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。\n更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。\n结果如下。\n由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。\nCEAS和CAS的ROUGE-L得分比基线高10分以上。\n特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。\n这些结果表明CEAS和CAS受到严重影响。\nCEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。\nCEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。\nCAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。\n这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。\n这里有一个错误分析。\nCAS方法倾向于输出比人类参考句子更短的句子。\n在右图中，引用句子有3或4个句子 ，而CAS只有1个。\n这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。\n此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。\n右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。\n下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。\n最后，一个结论。\n我们已经建立了一个新的数据集，用于自动生成发行说明。\n我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。\n我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。\n请查看我们在GitHub上的数据集。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我想谈谈我们对于推理的动机。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们展示了一个多步骤推理有帮助的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，最好将可解释的多步骤推理作为输出。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "某些假设也适用于之前的工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设数量的精确度是已知的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，复杂的运算符实际上可以分解成这些基本运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "传统的序列到序列模型将表达式转换为特定的序列以进行生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这很容易实现，可以概括成许多不同的复杂问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但因为转换器模型的原因，实际上这个方向仍然很受欢迎。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，其中还包含一些重复的计算。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在第二步中，我们可以得到这些除数，即27。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也可以回头参考原始问题来查找相关内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这些步骤中，我们得到了除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后在第三步，我们实际上得到了商。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这使得这个过程更加准确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "表达式由e i j o p表示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在这里也有减法与单词代表相反的方向。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这与关系提取 非常相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们把它添加到下一个状态，成为一个新的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一旦我们得到数量陈述，我们就可以开始做推理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们得到表达式表达q_1除以q_2。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里所有可能的表达式等于运算符数量的三倍。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，这个数量来自之前计算的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终可以得到最后这个表达式q_3乘以q_4。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还可以看到，所有可能的表达式的数字与之前的步骤不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它还允许我们根据先前的知识施加某些约束。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们简要地展示了与之前最佳方法相比的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们表现最好的变体是Roberta-DeductiveReasoner。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "没错。最好的方法通常是基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总的来说，我们的推理能够显著优于这个基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以看到，MathQA或SVAMP上的绝对数字并不高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步研究SVAMP的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的预测中，我们发现一些中间值实际上是负数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在这些问题中，我们问Jake有多少个苹果？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的模型做出了一些这样的预测，产生了负值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们观察到这两个表达式实际上有相似的分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步发现，针对某些模型，这种约束实际上改善了很多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还试图分析所有这些数据集背后的困难。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设这里的未使用数量的数量可以被视为不相关的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们还展示了整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们想通过一个问题扰动的例子来展示可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们的模型实际上在第一步就做出了错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以将这个表达式与这里的句子相关联。好。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为这个句子可能会误导模型做出错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里再植入一个35，会使得模型以为它是一个加法运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试将句子修改为类似梨树的数量比苹果树少35棵。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使其传达更准确的语义，以便模型能够使预测正确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这项研究展示了可解释预测如何帮助我们理解模型行为。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对我们的工作做个总结，首先我们的模型实际上是非常有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们能够提供可解释的解决程序。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也有一定的局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们有大量 数量的运算符或常量，内存消耗可能相当高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我的演讲到此结束，欢迎各位提出问题。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "法律问题是许多人生活中不可或缺的一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但大多数公民对他们的权利和基本法律程序知之甚少。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这样一个系统可以为非技术人员提供免费的专业法律援助服务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "需要一个模型来从大量立法中检索所有相关的法定条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种信息检索 任务有其自身的一系列挑战。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，它涉及两种类型的语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，有一些有可能是长达六千字的长文档。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，让我们来谈谈我们是如何收集这个数据集的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们从汇编大量语料库的法律条款开始。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们参考相关法规收集了法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，每个问题都具有主类别和一系列子类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个条款都带有法律结构中子序列标题的联结。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看我们的数据集的一些特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题的长度在5到44个单词之间，中位数为14个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最长的一条有5790个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "则其余的15%则涉及社会保障、外国人或工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是从这些比利时法典中收集的条款总数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在22633个条款中，只有1612个与数据集中的至少一个问题相关。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以解释为，这些法典较少关注个人及个人关心的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用标准的 TF-IDF和BM25排序函数进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些嵌入通常来自于对单词嵌入模型输出的池化操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，针对训练，我们尝试使用了双编码器架构的两种风格。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们在测试集上的基线结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，微调的双编码器明显优于所有其他基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，让我们讨论一下数据集的两个局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，租户每周举行两次派对，直到凌晨2点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以帮助改善所有人对司法的利用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为什么要费尽心思设立这个基准呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们是否知道模型实际上学到了什么？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这一个的低分呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言模型关注的是正确的事情吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "还是像之前的工作所显示的那样，他们专注于偏差？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的目标是存在性、复数、计数、空间关系、动作和实体共指。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们如何测试视觉和语言模型是否捕获了这种现象？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "计数和共指也是具有多种工具的方面。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这并不容易，因为被干扰的标题可能比原始标题更不可能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，要制造有效的干扰，我们必须想方设法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们利用强大的语言模型来提出干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为图像是前提，其标题是其附带的假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们认为标题是前提，而干扰词是其假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但这个过程并不完美，它只是一个有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，VALSE不提供任何训练数据，而仅提供测试数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "微调只会使模型能够利用数据中的工件或统计 偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们都知道，这些模型喜欢作弊和走捷径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有关更多指标及其结果，请查看我们的论文。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我是东京大学的Kamezawa。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将按照这个顺序解释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个图像显示的是vuejs库的2.6.4版本的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，如果能够自动生成高质量的发行说明，那将是非常有用的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将遵从之前的两项关于自动生成发行说明的研究。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一个是被称为ARENA的系统 ，发布于2014年。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统最显著的特征是右上角的问题提取器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "换句话说，它不能用于GitHub上的许多项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二个是Glyph ，最近在2020年宣布。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它可以在互联网上下载，并可以通过pip安装。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此图像是一个返回纠正或错误修复标签的示例用法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Glyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "文本分类模型的表现不佳。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的论文解决了这两个问题，并自动生成了高质量的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个提议的方法可以用于所有英语存储库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将介绍我们的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是数据的示例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "左侧是提交消息，右侧是发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明被标记为优化或修复等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以看作是一项总结 任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些都是基于之前的研究和其他因素设定的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右下角的发行说明是从左下角的发行说明中提取的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，有必要检测事先设置好的四个标签。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，标签并不总是与每个存储库一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，改进标签包括改进、增强、优化等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来是提交消息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "提交信息并不与每个版本相联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们创建了一个启发式匹配规则来获取上一个和下一个版本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，收集到了7200个存储库和82000份数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，独特的令牌数量也相当是大的，有883万个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是由于在资源库中发现了大量独特的类或方法名称。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将解释所提议的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "被归类为“其他”的提交消息将被丢弃。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们通过两种不同的方法对分类抽象总结方法进行建模。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "输出的文本可以根据特殊的类特定端点符号分为分类段落。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好，让我解释一下实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于评估，在某些情况下，发行说明是以多个句子形式输出的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当系统输出一个短句时，BLEU会受到惩罚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS和CAS的ROUGE-L得分比基线高10分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些结果表明CEAS和CAS受到严重影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里有一个错误分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS方法倾向于输出比人类参考句子更短的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在右图中，引用句子有3或4个句子 ，而CAS只有1个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，一个结论。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们已经建立了一个新的数据集，用于自动生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请查看我们在GitHub上的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。我的名字是Asaf Harari。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但有时，这些特征是有限的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用另一个数据来源生成特征可能会增加大量的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "假设我们有一个表格数据集和一个知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的框架FeSTE正是这个自动过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们来看看在一个数据集中输入FeSTE的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，数据集是大学数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当它的目标是将大学分为低排名的大学和高排名的大学时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用维基百科作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "FeSTE的第一阶段是实体链接。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且知识库的实体文本被提取出来，并添加到数据集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，文本是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，我们需要从检索 文本中生成或提取特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们需要进行特征提取阶段，其中包括文本分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，在原始数据集的类别数量中生成特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，原始数据集有两个类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，FeSTE生成两个特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但如果数据集有五个类，FeSTE就会生成五个新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个特征表示每个类的可能性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们不可能用输入数据集来训练语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有一个朴素的方法是：目标任务微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种方法的问题是，数据集可能只有几个不同的实体/文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个数据集上微调语言模型将是无效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以使用关于预先分析的数据集的先验知识。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的建议是，添加另一个微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个初步的多任务微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当你在n减1数据集上微调语言模型时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最先进的多任务多任务微调技术称为MTDNN。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在MTDNN中，MTDNN在训练集的任务数量上保持着头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从训练集中随机抽取一批。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的场景中，表格数据集在类的数量上有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "存在很多的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "MTDNN保持了类、头、输出层的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看一个例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里是我们的输入数据集，由实体、特征、文本和类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，标签向量在这种情况下始终保持……它总是由两个类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这就是我们精细的、重新制定的微调方法的算法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看完整的框架。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集送入FeSTE。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，FeSTE执行实体链接阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，它将任务重新表述为一个成对的句子分类任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "将语言模型应用于新的任务，并对每一类的输出可能性进行分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还是使用维基百科来作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还将每个数据集分成四折，并应用四折交叉验证。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们生成新的特征，并使用五个评估分类器对其进行评估。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，我们使用基础BERT基础架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们实验的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而我们重新制定的微调实现了最好的结果，最好的表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而MTDNN比目标 数据集 微调提高了2%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法实现了6%的改进。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但与单独的目标任务微调相比，我们的表现提高到了11%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它使用一个架构用于所有任务和数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且它保留了模型的头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但它增加了重新制定阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "大家好。我的名字是Asaf Harari。\n我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。\n数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。\n但有时，这些特征是有限的。\n使用另一个数据来源生成特征可能会增加大量的信息。\n我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。\n假设我们有一个表格数据集和一个知识库。\n我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。\n我们的框架FeSTE正是这个自动过程。\n我们来看看在一个数据集中输入FeSTE的例子。\n在这个例子中，数据集是大学数据集。\n当它的目标是将大学分为低排名的大学和高排名的大学时。\n我们使用维基百科作为知识库。\nFeSTE的第一阶段是实体链接。\n当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。\n并且知识库的实体文本被提取出来，并添加到数据集中。\n在这个例子中，文本是维基百科页面的摘要。\n现在，我们需要从检索 文本中生成或提取特征。\n因此，我们需要进行特征提取阶段，其中包括文本分析。\n这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。\n在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。\n首先，在原始数据集的类别数量中生成特征。\n在这个例子中，原始数据集有两个类别。\n所以，FeSTE生成两个特征。\n但如果数据集有五个类，FeSTE就会生成五个新的特征。\n每个特征表示每个类的可能性。\n为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。\n但是，我们不可能用输入数据集来训练语言模型。\n因此，有一个朴素的方法是：目标任务微调。\n因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。\n在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。\n接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。\n这种方法的问题是，数据集可能只有几个不同的实体/文本。\n在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。\n因此，在这个数据集上微调语言模型将是无效的。\n但我们可以使用关于预先分析的数据集的先验知识。\n因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。\n我们的建议是，添加另一个微调阶段。\n一个初步的多任务微调阶段。\n当你在n减1数据集上微调语言模型时。\n然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。\n最先进的多任务多任务微调技术称为MTDNN。\n在MTDNN中，MTDNN在训练集的任务数量上保持着头部。\n因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。\n它从训练集中随机抽取一批。\n而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。\n而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。\n在我们的场景中，表格数据集在类的数量上有所不同。\n存在很多的任务。\nMTDNN保持了类、头、输出层的数量。\n另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。\n我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。\n让我们来看一个例子。\n这里是我们的输入数据集，由实体、特征、文本和类组成。\n而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。\n或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。\n因此，标签向量在这种情况下始终保持……它总是由两个类组成。\n而这就是我们精细的、重新制定的微调方法的算法。\n让我们来看看完整的框架。\n数据集送入FeSTE。\n然后，FeSTE执行实体链接阶段。\n它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。\n然后，它将任务重新表述为一个成对的句子分类任务。\n将语言模型应用于新的任务，并对每一类的输出可能性进行分析。\n现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。\n然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。\n为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。\n我们还是使用维基百科来作为知识库。\n我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。\n我们还将每个数据集分成四折，并应用四折交叉验证。\n然后，我们生成新的特征，并使用五个评估分类器对其进行评估。\n在我们的实验中，我们使用基础BERT基础架构。\n以下是我们实验的结果。\n你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。\n而我们重新制定的微调实现了最好的结果，最好的表现。\n而MTDNN比目标 数据集 微调提高了2%。\n我们的方法实现了6%的改进。\n当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。\n但与单独的目标任务微调相比，我们的表现提高到了11%。\n总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。\n它使用一个架构用于所有任务和数据集。\n而且它保留了模型的头部。\n但它增加了重新制定阶段。\n它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。\n我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。\n首先，我想谈谈我们对于推理的动机。\n在这里，我们展示了一个多步骤推理有帮助的例子。\n这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。\n在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。\n但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。\n所以，最好将可解释的多步骤推理作为输出。\n我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。\n在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。\n在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。\n某些假设也适用于之前的工作。\n我们假设数量的精确度是已知的。\n并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。\n此外，复杂的运算符实际上可以分解成这些基本运算符。\n之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。\n传统的序列到序列模型将表达式转换为特定的序列以进行生成。\n这很容易实现，可以概括成许多不同的复杂问题。\n但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。\n但因为转换器模型的原因，实际上这个方向仍然很受欢迎。\n因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。\n所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。\n这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。\n其次，其中还包含一些重复的计算。\n如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。\n在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。\n例如，在第二步中，我们可以得到这些除数，即27。\n我们也可以回头参考原始问题来查找相关内容。\n在这些步骤中，我们得到了除数。\n然后在第三步，我们实际上得到了商。\n好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。\n在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。\n这使得这个过程更加准确。\n在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。\n表达式由e i j o p表示。\n我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。\n我们在这里也有减法与单词代表相反的方向。\n这与关系提取 非常相似。\n在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。\n我们把它添加到下一个状态，成为一个新的数量。\n这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。\n在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。\n一旦我们得到数量陈述，我们就可以开始做推理。\n这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。\n首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。\n最后，我们得到表达式表达q_1除以q_2。\n但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。\n这里所有可能的表达式等于运算符数量的三倍。\n这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。\n例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。\n所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。\n所以，这个数量来自之前计算的表达式。\n我们最终可以得到最后这个表达式q_3乘以q_4。\n我们还可以看到，所有可能的表达式的数字与之前的步骤不同。\n这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。\n训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。\n在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。\n这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。\n它还允许我们根据先前的知识施加某些约束。\n我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。\n在这里，我们简要地展示了与之前最佳方法相比的结果。\n我们表现最好的变体是Roberta-DeductiveReasoner。\n事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。\n没错。最好的方法通常是基于树的模型。\n总的来说，我们的推理能够显著优于这个基于树的模型。\n但我们可以看到，MathQA或SVAMP上的绝对数字并不高。\n我们进一步研究SVAMP的结果。\n这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。\n在我们的预测中，我们发现一些中间值实际上是负数。\n例如，在这些问题中，我们问Jake有多少个苹果？\n但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。\n我们的模型做出了一些这样的预测，产生了负值。\n我们观察到这两个表达式实际上有相似的分数。\n我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。\n我们进一步发现，针对某些模型，这种约束实际上改善了很多。\n例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。\n因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。\n我们还试图分析所有这些数据集背后的困难。\n我们假设这里的未使用数量的数量可以被视为不相关的信息。\n在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。\n在这里，我们还展示了整体表现。\n对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。\n但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。\n对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。\n最后，我们想通过一个问题扰动的例子来展示可解释性。\n在这里，我们的模型实际上在第一步就做出了错误的预测。\n我们实际上可以将这个表达式与这里的句子相关联。好。\n我们认为这个句子可能会误导模型做出错误的预测。\n在这里再植入一个35，会使得模型以为它是一个加法运算符。\n我们尝试将句子修改为类似梨树的数量比苹果树少35棵。\n我们使其传达更准确的语义，以便模型能够使预测正确。\n这项研究展示了可解释预测如何帮助我们理解模型行为。\n对我们的工作做个总结，首先我们的模型实际上是非常有效的。\n我们能够提供可解释的解决程序。\n我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。\n最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。\n我们也有一定的局限性。\n如果我们有大量 数量的运算符或常量，内存消耗可能相当高。\n第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。\n我的演讲到此结束，欢迎各位提出问题。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。\n我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。\n法律问题是许多人生活中不可或缺的一部分。\n但大多数公民对他们的权利和基本法律程序知之甚少。\n结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。\n所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。\n这样一个系统可以为非技术人员提供免费的专业法律援助服务。\n在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。\n给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？\n需要一个模型来从大量立法中检索所有相关的法定条款。\n这种信息检索 任务有其自身的一系列挑战。\n首先，它涉及两种类型的语言。\n针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。\n这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。\n此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。\n相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。\n最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。\n在这里，有一些有可能是长达六千字的长文档。\n自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。\n但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。\n在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。\n我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。\n这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。\n每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。\n现在，让我们来谈谈我们是如何收集这个数据集的。\n首先，我们从汇编大量语料库的法律条款开始。\n我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。\n然后，我们参考相关法规收集了法律问题。\n为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。\n我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。\n我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。\n最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。\n其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。\n我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。\n此外，每个问题都具有主类别和一系列子类别。\n每个条款都带有法律结构中子序列标题的联结。\n这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。\n让我们来看看我们的数据集的一些特征。\n这些问题的长度在5到44个单词之间，中位数为14个单词。\n条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。\n最长的一条有5790个单词。\n如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。\n则其余的15%则涉及社会保障、外国人或工作。\n这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。\n以下是从这些比利时法典中收集的条款总数。\n在22633个条款中，只有1612个与数据集中的至少一个问题相关。\n这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。\n与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。\n这可以解释为，这些法典较少关注个人及个人关心的问题。\n总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。\n使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。\n给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。\n我们使用标准的 TF-IDF和BM25排序函数进行实验。\n这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。\n为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。\n我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。\n这些嵌入通常来自于对单词嵌入模型输出的池化操作。\n首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。\n我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。\n此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。\n请注意，针对训练，我们尝试使用了双编码器架构的两种风格。\n第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。\n我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。\n以下是我们在测试集上的基线结果。\n上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。\n总体而言，微调的双编码器明显优于所有其他基线。\n双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。\n虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。\n关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。\n此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。\n虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。\n最后，让我们讨论一下数据集的两个局限性。\n首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。\n在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。\n因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。\n其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。\n例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？\n在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。\n相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。\n例如，租户每周举行两次派对，直到凌晨2点。\n因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。\n我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。\n这可以帮助改善所有人对司法的利用。\n您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。\n我们为什么要费尽心思设立这个基准呢？\n那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。\n这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。\n因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。\n但我们是否知道模型实际上学到了什么？\n视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？\n而这一个的低分呢？\n视觉和语言模型关注的是正确的事情吗？\n还是像之前的工作所显示的那样，他们专注于偏差？\n为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。\n我们的目标是存在性、复数、计数、空间关系、动作和实体共指。\n但是，我们如何测试视觉和语言模型是否捕获了这种现象？\n通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。\n干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。\n当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。\n例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。\n计数和共指也是具有多种工具的方面。\n当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。\n这并不容易，因为被干扰的标题可能比原始标题更不可能。\n例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。\n所以，要制造有效的干扰，我们必须想方设法。\n首先，我们利用强大的语言模型来提出干扰。\n其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。\n为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。\n我们认为图像是前提，其标题是其附带的假设。\n此外，我们认为标题是前提，而干扰词是其假设。\n如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。\n如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。\n但这个过程并不完美，它只是一个有效干扰词的指标。\n所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。\n因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。\n请注意，VALSE不提供任何训练数据，而仅提供测试数据。\n由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。\n微调只会使模型能够利用数据中的工件或统计 偏差。\n我们都知道，这些模型喜欢作弊和走捷径。\n正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。\n我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。\n我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。\n也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。\n有关更多指标及其结果，请查看我们的论文。\n这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。\n值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。\n但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。\n我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。\n关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。\n他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。\n从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。\n作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。\n如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。\n有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。\n因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。\n我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。\n我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。\n更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。\n如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "大家好，我是东京大学的Kamezawa。\n我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。\n我将按照这个顺序解释。\n首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。\n发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。\n这个图像显示的是vuejs库的2.6.4版本的发行说明。\n发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。\n因此，如果能够自动生成高质量的发行说明，那将是非常有用的。\n我将遵从之前的两项关于自动生成发行说明的研究。\n第一个是被称为ARENA的系统 ，发布于2014年。\n它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。\n这个系统最显著的特征是右上角的问题提取器。\n这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。\n换句话说，它不能用于GitHub上的许多项目。\n第二个是Glyph ，最近在2020年宣布。\n它可以在互联网上下载，并可以通过pip安装。\n这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。\n此图像是一个返回纠正或错误修复标签的示例用法。\nGlyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。\n文本分类模型的表现不佳。\n我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。\n我们的论文解决了这两个问题，并自动生成了高质量的发行说明。\n面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。\n这个提议的方法可以用于所有英语存储库。\n对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。\n接下来，我将介绍我们的数据集。\n以下是数据的示例。\n左侧是提交消息，右侧是发行说明。\n发行说明被标记为优化或修复等。\n我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。\n这可以看作是一项总结 任务。\n我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。\n这些都是基于之前的研究和其他因素设定的。\n右下角的发行说明是从左下角的发行说明中提取的。\n现在，有必要检测事先设置好的四个标签。\n但是，标签并不总是与每个存储库一致。\n例如，改进标签包括改进、增强、优化等。\n我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。\n这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。\n接下来是提交消息。\n提交信息并不与每个版本相联系。\n如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。\n这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。\n我们创建了一个启发式匹配规则来获取上一个和下一个版本。\n数据集分析。\n最后，收集到了7200个存储库和82000份数据。\n此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。\n此外，独特的令牌数量也相当是大的，有883万个。\n这是由于在资源库中发现了大量独特的类或方法名称。\n接下来，我将解释所提议的方法。\n这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。\n一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。\n首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。\n被归类为“其他”的提交消息将被丢弃。\n然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。\n在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。\n所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。\n我们通过两种不同的方法对分类抽象总结方法进行建模。\n第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。\n输出的文本可以根据特殊的类特定端点符号分为分类段落。\n第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。\n好，让我解释一下实验。\n我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。\n关于评估，在某些情况下，发行说明是以多个句子形式输出的。\n由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。\n当系统输出一个短句时，BLEU会受到惩罚。\n在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。\n最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。\n更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。\n结果如下。\n由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。\nCEAS和CAS的ROUGE-L得分比基线高10分以上。\n特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。\n这些结果表明CEAS和CAS受到严重影响。\nCEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。\nCEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。\nCAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。\n这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。\n这里有一个错误分析。\nCAS方法倾向于输出比人类参考句子更短的句子。\n在右图中，引用句子有3或4个句子 ，而CAS只有1个。\n这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。\n此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。\n右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。\n下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。\n最后，一个结论。\n我们已经建立了一个新的数据集，用于自动生成发行说明。\n我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。\n我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。\n请查看我们在GitHub上的数据集。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我想谈谈我们对于推理的动机。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们展示了一个多步骤推理有帮助的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，最好将可解释的多步骤推理作为输出。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "某些假设也适用于之前的工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设数量的精确度是已知的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，复杂的运算符实际上可以分解成这些基本运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "传统的序列到序列模型将表达式转换为特定的序列以进行生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这很容易实现，可以概括成许多不同的复杂问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但因为转换器模型的原因，实际上这个方向仍然很受欢迎。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，其中还包含一些重复的计算。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在第二步中，我们可以得到这些除数，即27。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也可以回头参考原始问题来查找相关内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这些步骤中，我们得到了除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后在第三步，我们实际上得到了商。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这使得这个过程更加准确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "表达式由e i j o p表示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在这里也有减法与单词代表相反的方向。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这与关系提取 非常相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们把它添加到下一个状态，成为一个新的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一旦我们得到数量陈述，我们就可以开始做推理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们得到表达式表达q_1除以q_2。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里所有可能的表达式等于运算符数量的三倍。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，这个数量来自之前计算的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终可以得到最后这个表达式q_3乘以q_4。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还可以看到，所有可能的表达式的数字与之前的步骤不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它还允许我们根据先前的知识施加某些约束。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们简要地展示了与之前最佳方法相比的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们表现最好的变体是Roberta-DeductiveReasoner。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "没错。最好的方法通常是基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总的来说，我们的推理能够显著优于这个基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以看到，MathQA或SVAMP上的绝对数字并不高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步研究SVAMP的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的预测中，我们发现一些中间值实际上是负数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在这些问题中，我们问Jake有多少个苹果？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的模型做出了一些这样的预测，产生了负值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们观察到这两个表达式实际上有相似的分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步发现，针对某些模型，这种约束实际上改善了很多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还试图分析所有这些数据集背后的困难。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设这里的未使用数量的数量可以被视为不相关的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们还展示了整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们想通过一个问题扰动的例子来展示可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们的模型实际上在第一步就做出了错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以将这个表达式与这里的句子相关联。好。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为这个句子可能会误导模型做出错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里再植入一个35，会使得模型以为它是一个加法运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试将句子修改为类似梨树的数量比苹果树少35棵。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使其传达更准确的语义，以便模型能够使预测正确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这项研究展示了可解释预测如何帮助我们理解模型行为。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对我们的工作做个总结，首先我们的模型实际上是非常有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们能够提供可解释的解决程序。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也有一定的局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们有大量 数量的运算符或常量，内存消耗可能相当高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我的演讲到此结束，欢迎各位提出问题。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "法律问题是许多人生活中不可或缺的一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但大多数公民对他们的权利和基本法律程序知之甚少。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这样一个系统可以为非技术人员提供免费的专业法律援助服务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "需要一个模型来从大量立法中检索所有相关的法定条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种信息检索 任务有其自身的一系列挑战。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，它涉及两种类型的语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，有一些有可能是长达六千字的长文档。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，让我们来谈谈我们是如何收集这个数据集的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们从汇编大量语料库的法律条款开始。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们参考相关法规收集了法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，每个问题都具有主类别和一系列子类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个条款都带有法律结构中子序列标题的联结。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看我们的数据集的一些特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题的长度在5到44个单词之间，中位数为14个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最长的一条有5790个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "则其余的15%则涉及社会保障、外国人或工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是从这些比利时法典中收集的条款总数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在22633个条款中，只有1612个与数据集中的至少一个问题相关。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以解释为，这些法典较少关注个人及个人关心的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用标准的 TF-IDF和BM25排序函数进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些嵌入通常来自于对单词嵌入模型输出的池化操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，针对训练，我们尝试使用了双编码器架构的两种风格。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们在测试集上的基线结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，微调的双编码器明显优于所有其他基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，让我们讨论一下数据集的两个局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，租户每周举行两次派对，直到凌晨2点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以帮助改善所有人对司法的利用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为什么要费尽心思设立这个基准呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们是否知道模型实际上学到了什么？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这一个的低分呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言模型关注的是正确的事情吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "还是像之前的工作所显示的那样，他们专注于偏差？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的目标是存在性、复数、计数、空间关系、动作和实体共指。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们如何测试视觉和语言模型是否捕获了这种现象？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "计数和共指也是具有多种工具的方面。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这并不容易，因为被干扰的标题可能比原始标题更不可能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，要制造有效的干扰，我们必须想方设法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们利用强大的语言模型来提出干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为图像是前提，其标题是其附带的假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们认为标题是前提，而干扰词是其假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但这个过程并不完美，它只是一个有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，VALSE不提供任何训练数据，而仅提供测试数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "微调只会使模型能够利用数据中的工件或统计 偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们都知道，这些模型喜欢作弊和走捷径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有关更多指标及其结果，请查看我们的论文。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我是东京大学的Kamezawa。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将按照这个顺序解释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个图像显示的是vuejs库的2.6.4版本的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，如果能够自动生成高质量的发行说明，那将是非常有用的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将遵从之前的两项关于自动生成发行说明的研究。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一个是被称为ARENA的系统 ，发布于2014年。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统最显著的特征是右上角的问题提取器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "换句话说，它不能用于GitHub上的许多项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二个是Glyph ，最近在2020年宣布。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它可以在互联网上下载，并可以通过pip安装。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此图像是一个返回纠正或错误修复标签的示例用法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Glyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "文本分类模型的表现不佳。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的论文解决了这两个问题，并自动生成了高质量的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个提议的方法可以用于所有英语存储库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将介绍我们的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是数据的示例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "左侧是提交消息，右侧是发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明被标记为优化或修复等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以看作是一项总结 任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些都是基于之前的研究和其他因素设定的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右下角的发行说明是从左下角的发行说明中提取的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，有必要检测事先设置好的四个标签。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，标签并不总是与每个存储库一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，改进标签包括改进、增强、优化等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来是提交消息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "提交信息并不与每个版本相联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们创建了一个启发式匹配规则来获取上一个和下一个版本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，收集到了7200个存储库和82000份数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，独特的令牌数量也相当是大的，有883万个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是由于在资源库中发现了大量独特的类或方法名称。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将解释所提议的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "被归类为“其他”的提交消息将被丢弃。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们通过两种不同的方法对分类抽象总结方法进行建模。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "输出的文本可以根据特殊的类特定端点符号分为分类段落。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好，让我解释一下实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于评估，在某些情况下，发行说明是以多个句子形式输出的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当系统输出一个短句时，BLEU会受到惩罚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS和CAS的ROUGE-L得分比基线高10分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些结果表明CEAS和CAS受到严重影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里有一个错误分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS方法倾向于输出比人类参考句子更短的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在右图中，引用句子有3或4个句子 ，而CAS只有1个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，一个结论。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们已经建立了一个新的数据集，用于自动生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请查看我们在GitHub上的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。我的名字是Asaf Harari。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但有时，这些特征是有限的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用另一个数据来源生成特征可能会增加大量的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "假设我们有一个表格数据集和一个知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的框架FeSTE正是这个自动过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们来看看在一个数据集中输入FeSTE的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，数据集是大学数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当它的目标是将大学分为低排名的大学和高排名的大学时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用维基百科作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "FeSTE的第一阶段是实体链接。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且知识库的实体文本被提取出来，并添加到数据集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，文本是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，我们需要从检索 文本中生成或提取特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们需要进行特征提取阶段，其中包括文本分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，在原始数据集的类别数量中生成特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，原始数据集有两个类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，FeSTE生成两个特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但如果数据集有五个类，FeSTE就会生成五个新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个特征表示每个类的可能性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们不可能用输入数据集来训练语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有一个朴素的方法是：目标任务微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种方法的问题是，数据集可能只有几个不同的实体/文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个数据集上微调语言模型将是无效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以使用关于预先分析的数据集的先验知识。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的建议是，添加另一个微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个初步的多任务微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当你在n减1数据集上微调语言模型时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最先进的多任务多任务微调技术称为MTDNN。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在MTDNN中，MTDNN在训练集的任务数量上保持着头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从训练集中随机抽取一批。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的场景中，表格数据集在类的数量上有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "存在很多的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "MTDNN保持了类、头、输出层的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看一个例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里是我们的输入数据集，由实体、特征、文本和类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，标签向量在这种情况下始终保持……它总是由两个类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这就是我们精细的、重新制定的微调方法的算法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看完整的框架。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集送入FeSTE。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，FeSTE执行实体链接阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，它将任务重新表述为一个成对的句子分类任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "将语言模型应用于新的任务，并对每一类的输出可能性进行分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还是使用维基百科来作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还将每个数据集分成四折，并应用四折交叉验证。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们生成新的特征，并使用五个评估分类器对其进行评估。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，我们使用基础BERT基础架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们实验的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而我们重新制定的微调实现了最好的结果，最好的表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而MTDNN比目标 数据集 微调提高了2%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法实现了6%的改进。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但与单独的目标任务微调相比，我们的表现提高到了11%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它使用一个架构用于所有任务和数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且它保留了模型的头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但它增加了重新制定阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "大家好。我的名字是Asaf Harari。\n我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。\n数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。\n但有时，这些特征是有限的。\n使用另一个数据来源生成特征可能会增加大量的信息。\n我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。\n假设我们有一个表格数据集和一个知识库。\n我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。\n我们的框架FeSTE正是这个自动过程。\n我们来看看在一个数据集中输入FeSTE的例子。\n在这个例子中，数据集是大学数据集。\n当它的目标是将大学分为低排名的大学和高排名的大学时。\n我们使用维基百科作为知识库。\nFeSTE的第一阶段是实体链接。\n当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。\n并且知识库的实体文本被提取出来，并添加到数据集中。\n在这个例子中，文本是维基百科页面的摘要。\n现在，我们需要从检索 文本中生成或提取特征。\n因此，我们需要进行特征提取阶段，其中包括文本分析。\n这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。\n在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。\n首先，在原始数据集的类别数量中生成特征。\n在这个例子中，原始数据集有两个类别。\n所以，FeSTE生成两个特征。\n但如果数据集有五个类，FeSTE就会生成五个新的特征。\n每个特征表示每个类的可能性。\n为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。\n但是，我们不可能用输入数据集来训练语言模型。\n因此，有一个朴素的方法是：目标任务微调。\n因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。\n在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。\n接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。\n这种方法的问题是，数据集可能只有几个不同的实体/文本。\n在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。\n因此，在这个数据集上微调语言模型将是无效的。\n但我们可以使用关于预先分析的数据集的先验知识。\n因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。\n我们的建议是，添加另一个微调阶段。\n一个初步的多任务微调阶段。\n当你在n减1数据集上微调语言模型时。\n然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。\n最先进的多任务多任务微调技术称为MTDNN。\n在MTDNN中，MTDNN在训练集的任务数量上保持着头部。\n因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。\n它从训练集中随机抽取一批。\n而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。\n而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。\n在我们的场景中，表格数据集在类的数量上有所不同。\n存在很多的任务。\nMTDNN保持了类、头、输出层的数量。\n另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。\n我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。\n让我们来看一个例子。\n这里是我们的输入数据集，由实体、特征、文本和类组成。\n而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。\n或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。\n因此，标签向量在这种情况下始终保持……它总是由两个类组成。\n而这就是我们精细的、重新制定的微调方法的算法。\n让我们来看看完整的框架。\n数据集送入FeSTE。\n然后，FeSTE执行实体链接阶段。\n它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。\n然后，它将任务重新表述为一个成对的句子分类任务。\n将语言模型应用于新的任务，并对每一类的输出可能性进行分析。\n现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。\n然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。\n为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。\n我们还是使用维基百科来作为知识库。\n我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。\n我们还将每个数据集分成四折，并应用四折交叉验证。\n然后，我们生成新的特征，并使用五个评估分类器对其进行评估。\n在我们的实验中，我们使用基础BERT基础架构。\n以下是我们实验的结果。\n你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。\n而我们重新制定的微调实现了最好的结果，最好的表现。\n而MTDNN比目标 数据集 微调提高了2%。\n我们的方法实现了6%的改进。\n当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。\n但与单独的目标任务微调相比，我们的表现提高到了11%。\n总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。\n它使用一个架构用于所有任务和数据集。\n而且它保留了模型的头部。\n但它增加了重新制定阶段。\n它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。\n我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。\n首先，我想谈谈我们对于推理的动机。\n在这里，我们展示了一个多步骤推理有帮助的例子。\n这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。\n在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。\n但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。\n所以，最好将可解释的多步骤推理作为输出。\n我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。\n在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。\n在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。\n某些假设也适用于之前的工作。\n我们假设数量的精确度是已知的。\n并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。\n此外，复杂的运算符实际上可以分解成这些基本运算符。\n之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。\n传统的序列到序列模型将表达式转换为特定的序列以进行生成。\n这很容易实现，可以概括成许多不同的复杂问题。\n但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。\n但因为转换器模型的原因，实际上这个方向仍然很受欢迎。\n因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。\n所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。\n这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。\n其次，其中还包含一些重复的计算。\n如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。\n在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。\n例如，在第二步中，我们可以得到这些除数，即27。\n我们也可以回头参考原始问题来查找相关内容。\n在这些步骤中，我们得到了除数。\n然后在第三步，我们实际上得到了商。\n好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。\n在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。\n这使得这个过程更加准确。\n在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。\n表达式由e i j o p表示。\n我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。\n我们在这里也有减法与单词代表相反的方向。\n这与关系提取 非常相似。\n在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。\n我们把它添加到下一个状态，成为一个新的数量。\n这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。\n在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。\n一旦我们得到数量陈述，我们就可以开始做推理。\n这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。\n首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。\n最后，我们得到表达式表达q_1除以q_2。\n但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。\n这里所有可能的表达式等于运算符数量的三倍。\n这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。\n例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。\n所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。\n所以，这个数量来自之前计算的表达式。\n我们最终可以得到最后这个表达式q_3乘以q_4。\n我们还可以看到，所有可能的表达式的数字与之前的步骤不同。\n这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。\n训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。\n在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。\n这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。\n它还允许我们根据先前的知识施加某些约束。\n我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。\n在这里，我们简要地展示了与之前最佳方法相比的结果。\n我们表现最好的变体是Roberta-DeductiveReasoner。\n事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。\n没错。最好的方法通常是基于树的模型。\n总的来说，我们的推理能够显著优于这个基于树的模型。\n但我们可以看到，MathQA或SVAMP上的绝对数字并不高。\n我们进一步研究SVAMP的结果。\n这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。\n在我们的预测中，我们发现一些中间值实际上是负数。\n例如，在这些问题中，我们问Jake有多少个苹果？\n但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。\n我们的模型做出了一些这样的预测，产生了负值。\n我们观察到这两个表达式实际上有相似的分数。\n我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。\n我们进一步发现，针对某些模型，这种约束实际上改善了很多。\n例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。\n因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。\n我们还试图分析所有这些数据集背后的困难。\n我们假设这里的未使用数量的数量可以被视为不相关的信息。\n在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。\n在这里，我们还展示了整体表现。\n对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。\n但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。\n对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。\n最后，我们想通过一个问题扰动的例子来展示可解释性。\n在这里，我们的模型实际上在第一步就做出了错误的预测。\n我们实际上可以将这个表达式与这里的句子相关联。好。\n我们认为这个句子可能会误导模型做出错误的预测。\n在这里再植入一个35，会使得模型以为它是一个加法运算符。\n我们尝试将句子修改为类似梨树的数量比苹果树少35棵。\n我们使其传达更准确的语义，以便模型能够使预测正确。\n这项研究展示了可解释预测如何帮助我们理解模型行为。\n对我们的工作做个总结，首先我们的模型实际上是非常有效的。\n我们能够提供可解释的解决程序。\n我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。\n最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。\n我们也有一定的局限性。\n如果我们有大量 数量的运算符或常量，内存消耗可能相当高。\n第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。\n我的演讲到此结束，欢迎各位提出问题。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。\n我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。\n法律问题是许多人生活中不可或缺的一部分。\n但大多数公民对他们的权利和基本法律程序知之甚少。\n结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。\n所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。\n这样一个系统可以为非技术人员提供免费的专业法律援助服务。\n在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。\n给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？\n需要一个模型来从大量立法中检索所有相关的法定条款。\n这种信息检索 任务有其自身的一系列挑战。\n首先，它涉及两种类型的语言。\n针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。\n这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。\n此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。\n相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。\n最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。\n在这里，有一些有可能是长达六千字的长文档。\n自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。\n但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。\n在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。\n我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。\n这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。\n每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。\n现在，让我们来谈谈我们是如何收集这个数据集的。\n首先，我们从汇编大量语料库的法律条款开始。\n我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。\n然后，我们参考相关法规收集了法律问题。\n为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。\n我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。\n我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。\n最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。\n其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。\n我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。\n此外，每个问题都具有主类别和一系列子类别。\n每个条款都带有法律结构中子序列标题的联结。\n这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。\n让我们来看看我们的数据集的一些特征。\n这些问题的长度在5到44个单词之间，中位数为14个单词。\n条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。\n最长的一条有5790个单词。\n如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。\n则其余的15%则涉及社会保障、外国人或工作。\n这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。\n以下是从这些比利时法典中收集的条款总数。\n在22633个条款中，只有1612个与数据集中的至少一个问题相关。\n这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。\n与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。\n这可以解释为，这些法典较少关注个人及个人关心的问题。\n总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。\n使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。\n给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。\n我们使用标准的 TF-IDF和BM25排序函数进行实验。\n这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。\n为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。\n我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。\n这些嵌入通常来自于对单词嵌入模型输出的池化操作。\n首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。\n我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。\n此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。\n请注意，针对训练，我们尝试使用了双编码器架构的两种风格。\n第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。\n我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。\n以下是我们在测试集上的基线结果。\n上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。\n总体而言，微调的双编码器明显优于所有其他基线。\n双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。\n虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。\n关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。\n此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。\n虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。\n最后，让我们讨论一下数据集的两个局限性。\n首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。\n在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。\n因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。\n其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。\n例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？\n在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。\n相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。\n例如，租户每周举行两次派对，直到凌晨2点。\n因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。\n我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。\n这可以帮助改善所有人对司法的利用。\n您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。\n我们为什么要费尽心思设立这个基准呢？\n那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。\n这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。\n因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。\n但我们是否知道模型实际上学到了什么？\n视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？\n而这一个的低分呢？\n视觉和语言模型关注的是正确的事情吗？\n还是像之前的工作所显示的那样，他们专注于偏差？\n为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。\n我们的目标是存在性、复数、计数、空间关系、动作和实体共指。\n但是，我们如何测试视觉和语言模型是否捕获了这种现象？\n通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。\n干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。\n当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。\n例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。\n计数和共指也是具有多种工具的方面。\n当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。\n这并不容易，因为被干扰的标题可能比原始标题更不可能。\n例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。\n所以，要制造有效的干扰，我们必须想方设法。\n首先，我们利用强大的语言模型来提出干扰。\n其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。\n为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。\n我们认为图像是前提，其标题是其附带的假设。\n此外，我们认为标题是前提，而干扰词是其假设。\n如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。\n如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。\n但这个过程并不完美，它只是一个有效干扰词的指标。\n所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。\n因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。\n请注意，VALSE不提供任何训练数据，而仅提供测试数据。\n由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。\n微调只会使模型能够利用数据中的工件或统计 偏差。\n我们都知道，这些模型喜欢作弊和走捷径。\n正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。\n我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。\n我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。\n也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。\n有关更多指标及其结果，请查看我们的论文。\n这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。\n值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。\n但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。\n我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。\n关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。\n他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。\n从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。\n作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。\n如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。\n有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。\n因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。\n我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。\n我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。\n更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。\n如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "大家好，我是东京大学的Kamezawa。\n我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。\n我将按照这个顺序解释。\n首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。\n发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。\n这个图像显示的是vuejs库的2.6.4版本的发行说明。\n发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。\n因此，如果能够自动生成高质量的发行说明，那将是非常有用的。\n我将遵从之前的两项关于自动生成发行说明的研究。\n第一个是被称为ARENA的系统 ，发布于2014年。\n它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。\n这个系统最显著的特征是右上角的问题提取器。\n这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。\n换句话说，它不能用于GitHub上的许多项目。\n第二个是Glyph ，最近在2020年宣布。\n它可以在互联网上下载，并可以通过pip安装。\n这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。\n此图像是一个返回纠正或错误修复标签的示例用法。\nGlyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。\n文本分类模型的表现不佳。\n我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。\n我们的论文解决了这两个问题，并自动生成了高质量的发行说明。\n面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。\n这个提议的方法可以用于所有英语存储库。\n对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。\n接下来，我将介绍我们的数据集。\n以下是数据的示例。\n左侧是提交消息，右侧是发行说明。\n发行说明被标记为优化或修复等。\n我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。\n这可以看作是一项总结 任务。\n我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。\n这些都是基于之前的研究和其他因素设定的。\n右下角的发行说明是从左下角的发行说明中提取的。\n现在，有必要检测事先设置好的四个标签。\n但是，标签并不总是与每个存储库一致。\n例如，改进标签包括改进、增强、优化等。\n我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。\n这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。\n接下来是提交消息。\n提交信息并不与每个版本相联系。\n如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。\n这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。\n我们创建了一个启发式匹配规则来获取上一个和下一个版本。\n数据集分析。\n最后，收集到了7200个存储库和82000份数据。\n此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。\n此外，独特的令牌数量也相当是大的，有883万个。\n这是由于在资源库中发现了大量独特的类或方法名称。\n接下来，我将解释所提议的方法。\n这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。\n一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。\n首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。\n被归类为“其他”的提交消息将被丢弃。\n然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。\n在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。\n所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。\n我们通过两种不同的方法对分类抽象总结方法进行建模。\n第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。\n输出的文本可以根据特殊的类特定端点符号分为分类段落。\n第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。\n好，让我解释一下实验。\n我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。\n关于评估，在某些情况下，发行说明是以多个句子形式输出的。\n由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。\n当系统输出一个短句时，BLEU会受到惩罚。\n在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。\n最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。\n更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。\n结果如下。\n由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。\nCEAS和CAS的ROUGE-L得分比基线高10分以上。\n特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。\n这些结果表明CEAS和CAS受到严重影响。\nCEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。\nCEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。\nCAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。\n这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。\n这里有一个错误分析。\nCAS方法倾向于输出比人类参考句子更短的句子。\n在右图中，引用句子有3或4个句子 ，而CAS只有1个。\n这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。\n此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。\n右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。\n下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。\n最后，一个结论。\n我们已经建立了一个新的数据集，用于自动生成发行说明。\n我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。\n我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。\n请查看我们在GitHub上的数据集。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我想谈谈我们对于推理的动机。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们展示了一个多步骤推理有帮助的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，最好将可解释的多步骤推理作为输出。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "某些假设也适用于之前的工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设数量的精确度是已知的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，复杂的运算符实际上可以分解成这些基本运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "传统的序列到序列模型将表达式转换为特定的序列以进行生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这很容易实现，可以概括成许多不同的复杂问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但因为转换器模型的原因，实际上这个方向仍然很受欢迎。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，其中还包含一些重复的计算。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在第二步中，我们可以得到这些除数，即27。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也可以回头参考原始问题来查找相关内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这些步骤中，我们得到了除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后在第三步，我们实际上得到了商。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这使得这个过程更加准确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "表达式由e i j o p表示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在这里也有减法与单词代表相反的方向。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这与关系提取 非常相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们把它添加到下一个状态，成为一个新的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一旦我们得到数量陈述，我们就可以开始做推理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们得到表达式表达q_1除以q_2。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里所有可能的表达式等于运算符数量的三倍。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，这个数量来自之前计算的表达式。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终可以得到最后这个表达式q_3乘以q_4。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还可以看到，所有可能的表达式的数字与之前的步骤不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它还允许我们根据先前的知识施加某些约束。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们简要地展示了与之前最佳方法相比的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们表现最好的变体是Roberta-DeductiveReasoner。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "没错。最好的方法通常是基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总的来说，我们的推理能够显著优于这个基于树的模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以看到，MathQA或SVAMP上的绝对数字并不高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步研究SVAMP的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的预测中，我们发现一些中间值实际上是负数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在这些问题中，我们问Jake有多少个苹果？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的模型做出了一些这样的预测，产生了负值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们观察到这两个表达式实际上有相似的分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们进一步发现，针对某些模型，这种约束实际上改善了很多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还试图分析所有这些数据集背后的困难。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们假设这里的未使用数量的数量可以被视为不相关的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们还展示了整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们想通过一个问题扰动的例子来展示可解释性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，我们的模型实际上在第一步就做出了错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们实际上可以将这个表达式与这里的句子相关联。好。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为这个句子可能会误导模型做出错误的预测。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里再植入一个35，会使得模型以为它是一个加法运算符。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试将句子修改为类似梨树的数量比苹果树少35棵。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使其传达更准确的语义，以便模型能够使预测正确。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这项研究展示了可解释预测如何帮助我们理解模型行为。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对我们的工作做个总结，首先我们的模型实际上是非常有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们能够提供可解释的解决程序。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们也有一定的局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果我们有大量 数量的运算符或常量，内存消耗可能相当高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我的演讲到此结束，欢迎各位提出问题。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "法律问题是许多人生活中不可或缺的一部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但大多数公民对他们的权利和基本法律程序知之甚少。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这样一个系统可以为非技术人员提供免费的专业法律援助服务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "需要一个模型来从大量立法中检索所有相关的法定条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种信息检索 任务有其自身的一系列挑战。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，它涉及两种类型的语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这里，有一些有可能是长达六千字的长文档。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，让我们来谈谈我们是如何收集这个数据集的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们从汇编大量语料库的法律条款开始。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们参考相关法规收集了法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，每个问题都具有主类别和一系列子类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个条款都带有法律结构中子序列标题的联结。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看我们的数据集的一些特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些问题的长度在5到44个单词之间，中位数为14个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最长的一条有5790个单词。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "则其余的15%则涉及社会保障、外国人或工作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是从这些比利时法典中收集的条款总数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在22633个条款中，只有1612个与数据集中的至少一个问题相关。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以解释为，这些法典较少关注个人及个人关心的问题。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用标准的 TF-IDF和BM25排序函数进行实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些嵌入通常来自于对单词嵌入模型输出的池化操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，针对训练，我们尝试使用了双编码器架构的两种风格。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们在测试集上的基线结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总体而言，微调的双编码器明显优于所有其他基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，让我们讨论一下数据集的两个局限性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，租户每周举行两次派对，直到凌晨2点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以帮助改善所有人对司法的利用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为什么要费尽心思设立这个基准呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们是否知道模型实际上学到了什么？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这一个的低分呢？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "视觉和语言模型关注的是正确的事情吗？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "还是像之前的工作所显示的那样，他们专注于偏差？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的目标是存在性、复数、计数、空间关系、动作和实体共指。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们如何测试视觉和语言模型是否捕获了这种现象？", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "计数和共指也是具有多种工具的方面。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这并不容易，因为被干扰的标题可能比原始标题更不可能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，要制造有效的干扰，我们必须想方设法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我们利用强大的语言模型来提出干扰。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们认为图像是前提，其标题是其附带的假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，我们认为标题是前提，而干扰词是其假设。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但这个过程并不完美，它只是一个有效干扰词的指标。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请注意，VALSE不提供任何训练数据，而仅提供测试数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "微调只会使模型能够利用数据中的工件或统计 偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们都知道，这些模型喜欢作弊和走捷径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有关更多指标及其结果，请查看我们的论文。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好，我是东京大学的Kamezawa。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将按照这个顺序解释。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个图像显示的是vuejs库的2.6.4版本的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，如果能够自动生成高质量的发行说明，那将是非常有用的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将遵从之前的两项关于自动生成发行说明的研究。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一个是被称为ARENA的系统 ，发布于2014年。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统最显著的特征是右上角的问题提取器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "换句话说，它不能用于GitHub上的许多项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二个是Glyph ，最近在2020年宣布。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它可以在互联网上下载，并可以通过pip安装。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此图像是一个返回纠正或错误修复标签的示例用法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Glyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "文本分类模型的表现不佳。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的论文解决了这两个问题，并自动生成了高质量的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个提议的方法可以用于所有英语存储库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将介绍我们的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是数据的示例。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "左侧是提交消息，右侧是发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "发行说明被标记为优化或修复等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这可以看作是一项总结 任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些都是基于之前的研究和其他因素设定的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右下角的发行说明是从左下角的发行说明中提取的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，有必要检测事先设置好的四个标签。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，标签并不总是与每个存储库一致。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "例如，改进标签包括改进、增强、优化等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来是提交消息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "提交信息并不与每个版本相联系。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们创建了一个启发式匹配规则来获取上一个和下一个版本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，收集到了7200个存储库和82000份数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，独特的令牌数量也相当是大的，有883万个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是由于在资源库中发现了大量独特的类或方法名称。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接下来，我将解释所提议的方法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "被归类为“其他”的提交消息将被丢弃。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们通过两种不同的方法对分类抽象总结方法进行建模。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "输出的文本可以根据特殊的类特定端点符号分为分类段落。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "好，让我解释一下实验。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "关于评估，在某些情况下，发行说明是以多个句子形式输出的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当系统输出一个短句时，BLEU会受到惩罚。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "结果如下。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS和CAS的ROUGE-L得分比基线高10分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这些结果表明CEAS和CAS受到严重影响。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里有一个错误分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CAS方法倾向于输出比人类参考句子更短的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在右图中，引用句子有3或4个句子 ，而CAS只有1个。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最后，一个结论。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们已经建立了一个新的数据集，用于自动生成发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "请查看我们在GitHub上的数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "大家好。我的名字是Asaf Harari。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但有时，这些特征是有限的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "使用另一个数据来源生成特征可能会增加大量的信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "假设我们有一个表格数据集和一个知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的框架FeSTE正是这个自动过程。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们来看看在一个数据集中输入FeSTE的例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，数据集是大学数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当它的目标是将大学分为低排名的大学和高排名的大学时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们使用维基百科作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "FeSTE的第一阶段是实体链接。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "并且知识库的实体文本被提取出来，并添加到数据集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，文本是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，我们需要从检索 文本中生成或提取特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，我们需要进行特征提取阶段，其中包括文本分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "首先，在原始数据集的类别数量中生成特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，原始数据集有两个类别。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "所以，FeSTE生成两个特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但如果数据集有五个类，FeSTE就会生成五个新的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "每个特征表示每个类的可能性。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但是，我们不可能用输入数据集来训练语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，有一个朴素的方法是：目标任务微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这种方法的问题是，数据集可能只有几个不同的实体/文本。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个数据集上微调语言模型将是无效的。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但我们可以使用关于预先分析的数据集的先验知识。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的建议是，添加另一个微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "一个初步的多任务微调阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当你在n减1数据集上微调语言模型时。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "最先进的多任务多任务微调技术称为MTDNN。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在MTDNN中，MTDNN在训练集的任务数量上保持着头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从训练集中随机抽取一批。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的场景中，表格数据集在类的数量上有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "存在很多的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "MTDNN保持了类、头、输出层的数量。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看一个例子。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "这里是我们的输入数据集，由实体、特征、文本和类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "因此，标签向量在这种情况下始终保持……它总是由两个类组成。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而这就是我们精细的、重新制定的微调方法的算法。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "让我们来看看完整的框架。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "数据集送入FeSTE。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，FeSTE执行实体链接阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，它将任务重新表述为一个成对的句子分类任务。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "将语言模型应用于新的任务，并对每一类的输出可能性进行分析。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还是使用维基百科来作为知识库。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们还将每个数据集分成四折，并应用四折交叉验证。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "然后，我们生成新的特征，并使用五个评估分类器对其进行评估。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "在我们的实验中，我们使用基础BERT基础架构。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "以下是我们实验的结果。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而我们重新制定的微调实现了最好的结果，最好的表现。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而MTDNN比目标 数据集 微调提高了2%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "我们的方法实现了6%的改进。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但与单独的目标任务微调相比，我们的表现提高到了11%。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它使用一个架构用于所有任务和数据集。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "而且它保留了模型的头部。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "但它增加了重新制定阶段。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "谢谢。", "tgt_lang": "zh"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "大家好。我的名字是Asaf Harari。\n我将介绍我们的论文《使用微调转换器架构的少样本表格式数据充实》。\n数据科学家对数据进行分析，主要侧重于对数据的现有特征进行操作。\n但有时，这些特征是有限的。\n使用另一个数据来源生成特征可能会增加大量的信息。\n我们的研究目标是，利用外部来源的自由文本自动丰富表格数据。\n假设我们有一个表格数据集和一个知识库。\n我们需要一个自动过程，其中包括实体链接和文本分析，以从知识库的自由文本中提取新的特征。\n我们的框架FeSTE正是这个自动过程。\n我们来看看在一个数据集中输入FeSTE的例子。\n在这个例子中，数据集是大学数据集。\n当它的目标是将大学分为低排名的大学和高排名的大学时。\n我们使用维基百科作为知识库。\nFeSTE的第一阶段是实体链接。\n当每个实体，在这个例子中是指大学名称，被链接到知识库中的一个实体。\n并且知识库的实体文本被提取出来，并添加到数据集中。\n在这个例子中，文本是维基百科页面的摘要。\n现在，我们需要从检索 文本中生成或提取特征。\n因此，我们需要进行特征提取阶段，其中包括文本分析。\n这是本论文的主要新颖之处，我将在接下来的幻灯片中深入探讨。\n在特征提取阶段之后，还有一个特征生成阶段，我们使用提取的特征来生成少量的新特征。\n首先，在原始数据集的类别数量中生成特征。\n在这个例子中，原始数据集有两个类别。\n所以，FeSTE生成两个特征。\n但如果数据集有五个类，FeSTE就会生成五个新的特征。\n每个特征表示每个类的可能性。\n为了分析文本，我们使用了目前最先进的文本分析方法，即基于转换器的语言模型，如BERT、GPT、XLNet等。\n但是，我们不可能用输入数据集来训练语言模型。\n因此，有一个朴素的方法是：目标任务微调。\n因此，在特征提取阶段，我们可以下载预训练的语言模型，在目标数据集上微调语言模型。\n在这个例子中，要对语言模型进行微调，将文本分类，抽象成类，低或高。\n接收语言模型的输出，也就是每个类别的可能性，并作为新的特征使用。\n这种方法的问题是，数据集可能只有几个不同的实体/文本。\n在我们的实验中，几乎有一半的数据集包含少于400个样本，最小的数据集包含35个样本，在一个训练集中。\n因此，在这个数据集上微调语言模型将是无效的。\n但我们可以使用关于预先分析的数据集的先验知识。\n因为FeSTE，我们在多个数据集上应用FeSTE，我们可以使用n减1的数据集来收集n减1的数据集的信息，并在分析第n个数据集时使用这些信息。\n我们的建议是，添加另一个微调阶段。\n一个初步的多任务微调阶段。\n当你在n减1数据集上微调语言模型时。\n然后，我们执行另一个微调阶段，即目标任务微调，此时我们在第n个目标数据集上微调语言模型。\n最先进的多任务多任务微调技术称为MTDNN。\n在MTDNN中，MTDNN在训练集的任务数量上保持着头部。\n因此，在这个例子中，训练集里有四个任务，所以MTDNN维持四个头，正如在图像上看到的那样。\n它从训练集中随机抽取一批。\n而如果他们的随机批属于一个，例如单句分类任务，它就会通过第一个头执行前向和后向路径。\n而如果随机批属于成对排名任务，它就会通过最后一个头执行前向和后向路径。\n在我们的场景中，表格数据集在类的数量上有所不同。\n存在很多的任务。\nMTDNN保持了类、头、输出层的数量。\n另外，MTDNN需要为一个新的数据集和一个新的任务初始化新的头。\n我们的方法，称为“任务重构微调”，它是在我们的方法任务重构微调，而不是维护多个头，我们把每个数据集重构为每个分类问题的一个句子，也就是两个类的任务。\n让我们来看一个例子。\n这里是我们的输入数据集，由实体、特征、文本和类组成。\n而且，我们将任务从对文本进行低级或高级分类，重新表述为对文本、抽象和类别进行真或假的分类。\n或者换句话说，我们训练了语言模型，将一个抽象和类划分为抽象和类，无论抽象属不属于类。\n因此，标签向量在这种情况下始终保持……它总是由两个类组成。\n而这就是我们精细的、重新制定的微调方法的算法。\n让我们来看看完整的框架。\n数据集送入FeSTE。\n然后，FeSTE执行实体链接阶段。\n它从知识库中提取文本，在本例子中，它是维基百科页面的摘要。\n然后，它将任务重新表述为一个成对的句子分类任务。\n将语言模型应用于新的任务，并对每一类的输出可能性进行分析。\n现在，语言模型已经用初步的多任务微调在n减1的数据集上进行了微调。\n然后，在类的数量上，我们用语言模型的输出向量作为新生成的特征。\n为了评估我们的框架，我们使用了17个表格分类数据集，这些数据集在大小、特征、平衡、域和初始表现上都有所不同。\n我们还是使用维基百科来作为知识库。\n我们将实验设计为留出一个评估，在16个数据集上训练FeSTe，并将其应用于第17个数据集。\n我们还将每个数据集分成四折，并应用四折交叉验证。\n然后，我们生成新的特征，并使用五个评估分类器对其进行评估。\n在我们的实验中，我们使用基础BERT基础架构。\n以下是我们实验的结果。\n你可以看到，我们将我们的框架与目标数据集微调……目标数据集微调和MTDNN初步微调进行了比较。\n而我们重新制定的微调实现了最好的结果，最好的表现。\n而MTDNN比目标 数据集 微调提高了2%。\n我们的方法实现了6%的改进。\n当我们在小数据集上看时，我们可以看到MTDNN的表现下降了，初步的多任务微调阶段的改进下降到1.5%。\n但与单独的目标任务微调相比，我们的表现提高到了11%。\n总而言之，在我们的实验中，FeSTE可以从35个样品中进行少量的富集。\n它使用一个架构用于所有任务和数据集。\n而且它保留了模型的头部。\n但它增加了重新制定阶段。\n它增加了训练集，它需要一个具有语义的目标值，这样我们就可以把它输入到语言模型中，并在句对分类问题中使用它。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "大家好。今天我将介绍我们的研究工作：《学习演绎推理：作为复杂关系提取的数学文字问题解决方法》。\n我是ByteDance 人工智能实验室的Allan，以下是我与德克萨斯大学奥斯汀分校的Jierui Li和SUTD的Wei Lu的合作成果。\n首先，我想谈谈我们对于推理的动机。\n在这里，我们展示了一个多步骤推理有帮助的例子。\n这个数字取自PaLM的论文，他们在这个论文中进行了提示，以解决少样本学习情况下的网络问题。\n在左侧我们可以看到，如果我们给出一些只有问题和答案的例子，我们可能无法获得正确的答案。\n但是，如果我们给出更多的推理描述，那么这里的模型将能够预测推理描述，同样也会做出正确的预测。\n所以，最好将可解释的多步骤推理作为输出。\n我们还认为，数学文字问题是一个用来评估这种推理能力的简明应用。\n在我们的问题设置中，围绕疑问，我们需要解决这个疑问，并获得数字答案。\n在我们的数据集中，还向我们提供了数学表达式，该表达式也导向这个特定的答案。\n某些假设也适用于之前的工作。\n我们假设数量的精确度是已知的。\n并且我们只考虑基本运算符，如加法、减法、乘法、除法和指数。\n此外，复杂的运算符实际上可以分解成这些基本运算符。\n之前解决数学文字问题的工作实际上可以分为序列到序列和序列到树模型。\n传统的序列到序列模型将表达式转换为特定的序列以进行生成。\n这很容易实现，可以概括成许多不同的复杂问题。\n但缺点是，其表现实际上并不比结构化模型好，并且缺乏用于预测的可解释性。\n但因为转换器模型的原因，实际上这个方向仍然很受欢迎。\n因此，在基于树的模型中，我们实际上以树的形式进行这些表达式的结构化，并在树代中遵循预先排序的遍历。\n所以在这里，我们继续生成运算符，直到我们到达叶子，也就是数量。\n这里的好处是，它实际上给了我们这个二进制树结构，但实际上它非常违反直觉，因为我们首先生成运算符，然后在最后生成数量。\n其次，其中还包含一些重复的计算。\n如果我们看一下这个表达式，八乘三加三实际上生成两次，但实际上我们应该重复使用结果。\n在我们提出的方法中，我们希望一步一步地以可解释的方式解决这些问题。\n例如，在第二步中，我们可以得到这些除数，即27。\n我们也可以回头参考原始问题来查找相关内容。\n在这些步骤中，我们得到了除数。\n然后在第三步，我们实际上得到了商。\n好的。经过这三个步骤，我们实际上可以重复使用第二个步骤的结果，然后得到第四个步骤的结果，最后可以得到被除数。\n在这里我们实际上直接生成整个表达式，而不是生成单个运算符或数量。\n这使得这个过程更加准确。\n在我们的演绎系统中，我们首先从问题中提供的一堆量开始，并且还包括一些常数作为我们的初始状态。\n表达式由e i j o p表示。\n我们执行从q_i到q_j的运算符，这样的表达式实际上是定向的。\n我们在这里也有减法与单词代表相反的方向。\n这与关系提取 非常相似。\n在形式演绎系统中，在时间步骤t ，我们在q_i和q_j对之间应用运算符，然后我们得到这个新表达式。\n我们把它添加到下一个状态，成为一个新的数量。\n这些幻灯片实际上可视化了我们不断向当前状态添加表达式的状态的演变。\n在我们的模型实现中，我们首先使用预训练语言模型，它可以是BERTs或Robertas，然后我们编码句子，然后我们得到这些数量陈述。\n一旦我们得到数量陈述，我们就可以开始做推理。\n这里我们展示了一个q_1的例子，以获得针对q_2除以q_2再乘以q_3的表达。\n首先，我们得到配对表达，它基本上只是q_1和q_2之间的联结，然后我们应用一个由运算符参数化的前馈网络。\n最后，我们得到表达式表达q_1除以q_2。\n但实际上，在实践中，在推理阶段，我们也可能会得到错误的表达式。\n这里所有可能的表达式等于运算符数量的三倍。\n这里的好处是我们可以轻松地添加约束条件，来控制这个搜索这个搜索空间。\n例如，如果此表达式不被允许，那么我们可以简单地在我们的搜索空间中删除此表达式。\n所以在第二步中，我们做同样的事情，但唯一的区别是多了一个数量。\n所以，这个数量来自之前计算的表达式。\n我们最终可以得到最后这个表达式q_3乘以q_4。\n我们还可以看到，所有可能的表达式的数字与之前的步骤不同。\n这种差异使得应用波束搜索变得困难，因为这两个步骤之间的概率分布是不平衡的。\n训练过程类似于训练 序列到序列 模型，我们在每个时间步骤中优化损失。\n在这里，我们也使用这个tau来表示我们何时应该终止这个生成过程。\n这里的空间从序列到序列是不同的，因为空间在每个时间步不同，而在传统的序列到序列 模型中，这是词汇的数字。\n它还允许我们根据先前的知识施加某些约束。\n我们对常用的数学文字问题 数据集、MAWPS、Math23K、MathQA和SVAMP进行实验。\n在这里，我们简要地展示了与之前最佳方法相比的结果。\n我们表现最好的变体是Roberta-DeductiveReasoner。\n事实上，我们不使用波束搜索。相反，所有之前的方法都使用波束搜索。\n没错。最好的方法通常是基于树的模型。\n总的来说，我们的推理能够显著优于这个基于树的模型。\n但我们可以看到，MathQA或SVAMP上的绝对数字并不高。\n我们进一步研究SVAMP的结果。\n这个数据集具有挑战性，因为作者试图手动添加一些东西来混淆NLP模型，例如添加不相关的信息和额外的数量。\n在我们的预测中，我们发现一些中间值实际上是负数。\n例如，在这些问题中，我们问Jake有多少个苹果？\n但我们有一些额外的信息，例如照片少了17张，Seventeen有8张照片，但这些信息完全无关紧要。\n我们的模型做出了一些这样的预测，产生了负值。\n我们观察到这两个表达式实际上有相似的分数。\n我们实际上可以通过删除负数的结果来限制这个搜索空间，这样我们就可以得出正确的答案。\n我们进一步发现，针对某些模型，这种约束实际上改善了很多。\n例如，对于BERT，我们提高了7分。然后，对于Roberta基础模型，我们实际上提高了两分。\n因此，更好的语言模型具有更好的语言理解能力，因此，这里的数字对于Roberta来说更高，对于BERT来说更低。\n我们还试图分析所有这些数据集背后的困难。\n我们假设这里的未使用数量的数量可以被视为不相关的信息。\n在这里我们可以看到，我们有未使用数量的样本的百分比，其中SVAMP数据集占了最大的部分。\n在这里，我们还展示了整体表现。\n对于那些没有未使用数量的样本，其整体表现实际上高于整体表现。\n但是，对于具有未使用数量的样本，其表现实际上比整体表现差得多。\n对于MAWPS，我们其实没有太多的测试例子，所以我会忽略掉这一部分。\n最后，我们想通过一个问题扰动的例子来展示可解释性。\n在这里，我们的模型实际上在第一步就做出了错误的预测。\n我们实际上可以将这个表达式与这里的句子相关联。好。\n我们认为这个句子可能会误导模型做出错误的预测。\n在这里再植入一个35，会使得模型以为它是一个加法运算符。\n我们尝试将句子修改为类似梨树的数量比苹果树少35棵。\n我们使其传达更准确的语义，以便模型能够使预测正确。\n这项研究展示了可解释预测如何帮助我们理解模型行为。\n对我们的工作做个总结，首先我们的模型实际上是非常有效的。\n我们能够提供可解释的解决程序。\n我们可以简单地将一些先前的知识作为约束，这样就可以帮助提高表现。\n最后一点是，底层机制不仅适用于解决任务的网络问题，也适用于涉及多步骤推理的其他任务。\n我们也有一定的局限性。\n如果我们有大量 数量的运算符或常量，内存消耗可能相当高。\n第二件事是，如前所述，由于不同时间步骤之间的概率分布不平衡，因此应用波束搜索策略也非常具有挑战性。\n我的演讲到此结束，欢迎各位提出问题。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "大家好，我叫Antoine，来自马斯特里赫特大学。\n我将展示我与Jerry的合作结果，它是针对法定条款检索的新数据集。\n法律问题是许多人生活中不可或缺的一部分。\n但大多数公民对他们的权利和基本法律程序知之甚少。\n结果，许多无法承担法律专家昂贵费用的弱势公民得不到保护，或者（更糟糕的是）受到剥削。\n所有工作旨在通过开发针对法定条款的高效检索系统，来弥合公民与法律之间的鸿沟。\n这样一个系统可以为非技术人员提供免费的专业法律援助服务。\n在深入探讨这项工作的主要贡献之前，让我们首先描述法定条款检索的问题。\n给出一个关于法律问题的简单问题，例如，如果我违反专业保密规定，我会承担怎么风险？\n需要一个模型来从大量立法中检索所有相关的法定条款。\n这种信息检索 任务有其自身的一系列挑战。\n首先，它涉及两种类型的语言。\n针对问题本身的通用自然语言，以及针对法规使用的复杂法律语言。\n这种语言分布的差异使得系统更难检索到相关候选信息，因为它间接需要一个固有的解释系统，可以将自然问题翻译成与法规术语相匹配的法律问题。\n此外，成文法不是一堆可以自身作为完整信息来源的独立条款，举例来说，不像新闻或食谱那样。\n相反，它是法律条款的结构化集合，只有在整体上下文中考虑时才具有完整的意义，也就是说，连同相邻条款的补充信息，它们所属的字段和子字段，以及它们在法律结构中的位置。\n最后，法定条款不是小段落，而小段落通常是大多数检索作品中的典型检索单元。\n在这里，有一些有可能是长达六千字的长文档。\n自然语言处理中的最新进展引发了对许多法律任务的巨大兴趣，例如法律判断预测或自动联系人合同审查。\n但由于缺乏较大的高质量标签化数据集，法定条款检索基本上没有受到影响。\n在这项工作中，我们提出了一个新的以法国本土公民为中心的数据集，以研究检索模型是否可以接近法律专家执行法定条款检索任务的效率和可靠性。\n我们的比利时法定条款检索数据集BSARD由比利时公民提出的1100多个法律问题组成。\n这些问题涵盖了从家庭、住房、金钱到工作和社会安全等一系列主题。\n每个问题都由经验丰富的法学家标记，并参考了比利时法典中超过22,600篇法律条款的语料库中的相关条款。\n现在，让我们来谈谈我们是如何收集这个数据集的。\n首先，我们从汇编大量语料库的法律条款开始。\n我们考虑了32个公开可用的比利时法典，并提取了所有条款以及相应的章节标题。\n然后，我们参考相关法规收集了法律问题。\n为此，我们与比利时律师事务所合作，该事务所每年收到约4000封来自比利时公民的电子邮件，他们就个人法律问题征求意见。\n我们很幸运能够访问他们的网站，在这个网站上他们经验丰富的法学家团队解决比利时人最常见的法律问题。\n我们收集了数以千计的问题，并用类别、子类别和相关法规的法律参考进行了注释。\n最后，我们浏览了法律参考文献，并过滤掉参考文献不包含在我们所考虑的其中任何一部法律条款的问题。\n其余的参考文献被匹配，并转换为我们语料库中相应的条款ID。\n我们最终得到了 10108 个问题，每个问题都仔细地标记了我们大型语料库的22633个法定条款中的相关条款的ID。\n此外，每个问题都具有主类别和一系列子类别。\n每个条款都带有法律结构中子序列标题的联结。\n这些额外的信息未在当前工作中使用，但可能对今后关于法律信息检索或法律文本分类的研究有所帮助。\n让我们来看看我们的数据集的一些特征。\n这些问题的长度在5到44个单词之间，中位数为14个单词。\n条款则要长得多，中位数为77个单词 ，其中有142条超过1000单词。\n最长的一条有5790个单词。\n如前所述，这些问题涵盖了广泛的主题，其中约85%的主题是关于家庭、住房、金钱或正义。\n则其余的15%则涉及社会保障、外国人或工作。\n这些法律条款也非常多样化，因为它们来自32个不同的比利时法典，涵盖了大量 数量的法律主题。\n以下是从这些比利时法典中收集的条款总数。\n在22633个条款中，只有1612个与数据集中的至少一个问题相关。\n这些被引用的条款中约有80%来自民法典、司法法典、刑事调查法典或刑法典。\n与此同时，32个法典中有18个中提到的与至少一个问题相关的条款少于5个。\n这可以解释为，这些法典较少关注个人及个人关心的问题。\n总体而言，这些被引用条款的引用次数中位数为2次，其中引用次数超过5次的不到25%。\n使用所有数据集，我们对几种检索方法进行了基准测试，包括词汇和密集架构。\n给定一个查询和一个条款，词汇模型通过计算该条款中每个术语的权重总和来为查询条款对分配一个分数。\n我们使用标准的 TF-IDF和BM25排序函数进行实验。\n这些方法的主要问题是，它们只能检索包含有查询中存在的关键字的条款。\n为了克服这个限制，我们尝试了一种基于神经的架构，它可以捕获查询和条款之间的语义关系。\n我们使用双编码器模型将查询和条款映射到密集的向量陈述中，并通过查询条款对嵌入的相似度计算它们之间的相关性分数。\n这些嵌入通常来自于对单词嵌入模型输出的池化操作。\n首先，我们研究了Siamese双编码器在零样本评估设置中的有效性，这意味着预训练的单词嵌入模型可以直接拿来使用，无需进行任何额外的微调。\n我们尝试了与上下文无关的文本编码器，即word2vec和fastText，以及上下文相关的嵌入模型，即Roberta，更具体地说是CamemBERT，它是个法语Roberta模型。\n此外，我们在数据集上训练我们自己的基于CamemBERT的 模型双编码器。\n请注意，针对训练，我们尝试使用了双编码器架构的两种风格。\n第一种是siamese，它使用一个独特的单词嵌入模型，将查询和条款一起映射到一个共享的密集向量空间；另一种是双塔，它使用两个独立的单词嵌入模型，将查询和条款分别编码到不同的嵌入空间。\n我们试验了均值、最大值和CLS集合，以及计算相似性的乘积和余弦。\n以下是我们在测试集上的基线结果。\n上面是词汇方法，中间是在零样本设定中评估的siamese双编码器，下面是微调的双编码器。\n总体而言，微调的双编码器明显优于所有其他基线。\n双塔模型在召回率上比其siamese模型高出了100，但在其他指标上表现相似。\n虽然BM25的表现明显低于训练好的双编码器，但它的表现表明，它仍然是特定领域检索的一个强大基线。\n关于siamese双编码器的零样本评估，我们发现直接使用预训练的CamemBERT模型的嵌入，而不对信息检索任务进行优化，结果很差，这与之前的发现一致。\n此外，我们观察到，基于word2vec的双编码器的表现明显优于基于fastText和BERT的模型，这表明在直接使用时，也许预训练的词级嵌入比字符级或子词级嵌入对这项任务更适合。\n虽然有希望，但这些结果表明，与一个熟练的法律专家相比，还有很多改进的机会，因为他最终可以检索到任何问题的所有相关条款，从而获得满分。\n最后，让我们讨论一下数据集的两个局限性。\n首先，条款的内容仅限于从比利时32部法典中收集的条款，这并不包括整个比利时的法律，因为法令、指令和条例中的条款都没有。\n在构建数据集的过程中，所有对这些未收集的条款的引用都被忽略，这导致一些问题最终只有最初相关条款数量的一小部分。\n因此，这一信息意味着其余相关条款中包含的答案可能是不完整的，尽管它仍然完全合适。\n其次，我们应该注意，并非所有的法律问题都可以仅通过法规来回答。\n例如这个问题：如果我的租户制造太多噪音，我可以驱逐他们吗？\n在成文法中可能没有详细的答案来量化允许驱逐的特定噪音阈值。\n相反，房东可能应该更多地依靠判例法，找到与他们目前情况相似的先例。\n例如，租户每周举行两次派对，直到凌晨2点。\n因此，有些问题比其他问题更适合于法定条款检索任务，而不太适合的问题所在的领域还有待确定。\n我们希望我们的工作能够激发在开发实用可靠的法定条款检索模型方面的兴趣。\n这可以帮助改善所有人对司法的利用。\n您可以在以下链接查看我们的论文、数据集和法典。谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "大家好，很高兴向你们介绍我们的工作成果——VALSE，这是一个独立于任务的基准，旨在用特定的语言现象测试视觉和语言模型。\n我们为什么要费尽心思设立这个基准呢？\n那是因为，在过去的几年里，我们看到了基于转换器的视觉和语言模型在大量的图像文本对上进行预训练的爆炸性增长。\n这些模型中的每一个都在视觉和语言任务上推动了最先进的技术，如视觉问题回答、视觉常识推理、图像检索，以及短语领域。\n因此，我们得到了一个信息，这些任务的准确性和特定基准正在稳步提升。\n但我们是否知道模型实际上学到了什么？\n视觉和语言转换器在为这个图像和这个句子分配高分时，所理解的是什么呢？\n而这一个的低分呢？\n视觉和语言模型关注的是正确的事情吗？\n还是像之前的工作所显示的那样，他们专注于偏差？\n为了进一步阐明这方面的问题，我们提出了一个与任务更加无关的方向，并引入VALSE，对于影响语言和视觉形态的特定语言现象，其测试视觉和语言模型的敏感性。\n我们的目标是存在性、复数、计数、空间关系、动作和实体共指。\n但是，我们如何测试视觉和语言模型是否捕获了这种现象？\n通过干扰Ravi Shekhar和合作者以前只应用于视觉和语言模型的名词短语的方法，以及我们在之前工作中对计数的方法。\n干扰的意思是，我们获取一个图像的标题，通过改变标题，使其不再描述图像中的物体，从而造成干扰。\n当我们在做这些短语改动时，重点关注了六个具体的方面，如存在性、复数、计数、空间关系、动作和实体共指，其中每个方面都可能包含一种或多种工具，以备我们发现不止一个有趣的方式来创造干扰实例。\n例如，在动作方面，我们有两种工具，在一种当中是用不同的动作改变动作动词，在另一种当中是动作被交换。\n计数和共指也是具有多种工具的方面。\n当我们创造这些干扰时，要确保它们不能描述图像，它们符合语法，且仍然是有效的句子。\n这并不容易，因为被干扰的标题可能比原始标题更不可能。\n例如，虽然这不是不可能的，但从统计学上来说，植物砍人的可能性比人砍植物的可能性要小，较大的视觉和语言模型可以发现这一点。\n所以，要制造有效的干扰，我们必须想方设法。\n首先，我们利用强大的语言模型来提出干扰。\n其次，我们使用自然语言推断或简短NLI来过滤可能仍在描述图像的干扰词，因为在构建干扰词时，我们需要确保它们无法描述图像。\n为了自动检验这一点，我们应用了自然语言推理，其基本原理如下。\n我们认为图像是前提，其标题是其附带的假设。\n此外，我们认为标题是前提，而干扰词是其假设。\n如果NLI 模型预测干扰词与标题相矛盾或保持中立，我们将其作为有效干扰词的指标。\n如果NLI预测干扰词是标题中所包含的，那么它就不可能是一个好的干扰词，因为根据反证法，它将给出图像的真实描述，我们将这些干扰词过滤掉。\n但这个过程并不完美，它只是一个有效干扰词的指标。\n所以，作为生成有效干扰词的第三项措施，我们使用人类 注释着来验证VALSE中使用的数据。\n因此，经过过滤和人工评估后，我们拥有与本表中所述的测试实例一样多的测试实例。\n请注意，VALSE不提供任何训练数据，而仅提供测试数据。\n由于它仅是一个零样本测试基准，因此它旨在利用预训练后的视觉和语言模型的现存功能。\n微调只会使模型能够利用数据中的工件或统计 偏差。\n我们都知道，这些模型喜欢作弊和走捷径。\n正如我们所说，我们有兴趣评估视觉和语言模型在预训练后具有哪些能力。\n我们在VALSE上尝试了五种视觉和语言模型，即使用CLIP、LXMert、ViLBERT、ViLBERT十二合一和VisualBERT。\n我们最重要的两个评估指标是模型在将图像句子对分类为标题和干扰词的准确性。\n也许与这段视频更相关的是，我们将展示我们更宽容的指标，即成对的准确性，它衡量的是正确的图像文本对的图像句子对齐得分是否大于其受干扰的对。\n有关更多指标及其结果，请查看我们的论文。\n这里显示了成对的准确度的结果，它们与我们从其他指标中得到的结果一致，即ViLBERT十二分之一取得了最佳的零样本表现，其次是ViLBERT、LXMert、CLIP，最后是VisualBERT。\n值得注意的是，以个别对象（如存在性和名词短语）为中心的工具几乎被ViLBERT十二分之一解决了，这突出表明模型能够识别已命名的对象和它们在图片中的存在。\n但是，在我们的对抗性干扰设置中，其余的部分都不能被可靠地解决。\n我们从复数和计数工具中看到，视觉和语言模型难以区分对单个和多个对象的引用，或在图像中计算它们。\n关系部分表明，它们难以正确地分类图像中对象之间的命名空间关系。\n他们也很难区分动作和识别动作的参与者，即使像我们在动作这块看到的那样有合理性偏差的支持。\n从核心推理这一块，我们发现通过使用代词来追踪对图像中同一对象的多个引用，对于视觉和语言模型来说也是困难的。\n作为理智的检查，同时也因为这是一个有趣的实验，我们还对两个纯文本模型（GPT one和GPT two）进行了基准测试，以评估VALSE是否可由这些单模态模型解决，方法是抛开图像不管，计算正确标题和受干扰标题的困惑度，并预测具有最低困惑度的条目。\n如果受干扰标题的困惑度更高，我们认为这表明受干扰的标题可能存在合理性偏差或其他语言偏差。\n有趣的是，在某些情况下，纯文本的GPT模型比视觉和语言模型更好地捕捉了世界的合理性。\n因此，总的来说，VALSE是一个基准，它使用语言构造的镜头，通过硬性测试社区的视觉接地能力，来帮助其改善视觉和语言模型。\n我们的实验表明，视觉和语言模型能很好地识别命名对象及其在图片中的存在（如“存在性”部分所示），但在被迫尊重语言指标时，却很难在视觉场景中建立它们的相互依存性和关系。\n我们非常希望鼓励社区使用VALSE来衡量用视觉和语言模型实现语言接地的进展。\n更重要的是，VALSE可以作为数据集的间接评估，因为可以在训练或微调前后对模型进行评估，以了解数据集是否有助于模型在VALSE测试的任何方面得到改善。\n如果您有兴趣，请查看GitHub上的VALSE数据。如果您有任何疑问，请随时与我们联系。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "大家好，我是东京大学的Kamezawa。\n我将发表一篇论文，题目为《RNSum：通过提交日志总结自动生成发行说明的大规模数据集》。\n我将按照这个顺序解释。\n首先，我将介绍我们在这项研究中正在进行的自动发行说明生成。\n发行说明是一个技术文档，它总结了软件产品的每个版本所分发的更改。\n这个图像显示的是vuejs库的2.6.4版本的发行说明。\n发行说明在开源开发中起着重要作用，但手动准备它们是很耗时的。\n因此，如果能够自动生成高质量的发行说明，那将是非常有用的。\n我将遵从之前的两项关于自动生成发行说明的研究。\n第一个是被称为ARENA的系统 ，发布于2014年。\n它采取了一种基于规则的方法，例如使用变化提取器从不同版本的差异中提取所有的差异、库的变化和文件的变化，最后再将它们结合起来。\n这个系统最显著的特征是右上角的问题提取器。\n这必须留给问题跟踪器系统 JIRA ，并且只能应用于使用JIRA的项目。\n换句话说，它不能用于GitHub上的许多项目。\n第二个是Glyph ，最近在2020年宣布。\n它可以在互联网上下载，并可以通过pip安装。\n这个系统有一个简单的基于学习的文本分类模型，并为每个输入的提交信息输出五个标签之一，如特征或错误修复。\n此图像是一个返回纠正或错误修复标签的示例用法。\nGlyph的训练数据相当小，约为五千，并将在下面描述的实验中显示。\n文本分类模型的表现不佳。\n我提出了两个相关的研究，但它们的问题是适用性有限和数据资源稀缺。\n我们的论文解决了这两个问题，并自动生成了高质量的发行说明。\n面对适用性有限的问题，我们提出了一种只使用提交信息作为输入的高质量的分类总结方法。\n这个提议的方法可以用于所有英语存储库。\n对于第二个数据资源稀缺的问题，我们通过使用GitHub API从公共GitHub存储库收集数据，建立了由大约八万两千条数据组成的RNSum数据集。\n接下来，我将介绍我们的数据集。\n以下是数据的示例。\n左侧是提交消息，右侧是发行说明。\n发行说明被标记为优化或修复等。\n我们设置了一个任务，将提交信息作为输入，并输出一个标签化的发行说明。\n这可以看作是一项总结 任务。\n我们预先定义了四个标签：特征、优化、错误修复、弃用删除和重大更改。\n这些都是基于之前的研究和其他因素设定的。\n右下角的发行说明是从左下角的发行说明中提取的。\n现在，有必要检测事先设置好的四个标签。\n但是，标签并不总是与每个存储库一致。\n例如，改进标签包括改进、增强、优化等。\n我们为这些符号变体中的每一个准备了一个大约30个标签的词汇列表。\n这是为了检测发行说明类，并收集后面的发行文本作为该类的发行说明句子。\n接下来是提交消息。\n提交信息并不与每个版本相联系。\n如下面的图像所示，如果当前的版本是2.5219的版本，那么我们需要识别之前的版本2.5218，并得到一个差异。\n这有点繁琐，而且仅仅得到一个发布列表并查看前后的情况是不够的。\n我们创建了一个启发式匹配规则来获取上一个和下一个版本。\n数据集分析。\n最后，收集到了7200个存储库和82000份数据。\n此外，发行说明令牌的平均数量为63，这对于一个总结任务来说是相当高的。\n此外，独特的令牌数量也相当是大的，有883万个。\n这是由于在资源库中发现了大量独特的类或方法名称。\n接下来，我将解释所提议的方法。\n这个先按类别抽取然后抽象总结的模型是由两个神经模块组成的。\n一个是使用BERT或CodeBERT的分类器，另一个是使用BART的生成器。\n首先，CEAS使用分类器将每条提交信息分为五个发行说明类别，其中使用了“改进”、“错误修复”、“弃用”，以及“其他”。\n被归类为“其他”的提交消息将被丢弃。\n然后CEAS将生成器独立地应用于四个标签化 文档，并为每个类别生成发行说明。\n在这项任务中，提交信息和发行说明之间的直接对应关系并不清楚。\n所以，为了训练分类器，这就是为什么我们使用每条提交信息的前十个字符，来对每个输入的提交信息重新分配调查。\n我们通过两种不同的方法对分类抽象总结方法进行建模。\n第一种方法是我们称为CAS-Single的模型，它由一个单一的六对六网络组成，并生成一个单一的发行说明文本，给出输入提交信息的串联。\n输出的文本可以根据特殊的类特定端点符号分为分类段落。\n第二种方法，方法，我们称之为CAS-Multi，由四个不同的seq2seq网络组成，每个网络都对应于一个固定的发行说明类别。\n好，让我解释一下实验。\n我们比较了五种方法：CEAS、CAS-Single、CAS-Multi、Clustering，以及之前的研究“Glyph”。\n关于评估，在某些情况下，发行说明是以多个句子形式输出的。\n由于很难计算出这些句子的数量，所以用空格合并，作为一个长句处理。\n当系统输出一个短句时，BLEU会受到惩罚。\n在接下来描述的实验结果中，这种惩罚导致了较低的BLEU值。\n最后，我们还计算了特异性，因为如果发行说明是空的，就无法计算ROUG和BLEU。\n更高的特异性意味着，在发行说明假定为空的情况下，模型会正确地输出一个空文本。\n结果如下。\n由于该数据集包含电子邮件地址、哈希值等内容，所以我们还评估了经过清理的数据集，其中不包括这些内容。\nCEAS和CAS的ROUGE-L得分比基线高10分以上。\n特别是在干净的测试集上，建议的方法和基线之间的分数差距跃升到20分以上。\n这些结果表明CEAS和CAS受到严重影响。\nCEAS比CAS得到了更好的ROUGE-L分数，这表明将分类器和生成器结合在一起对使用伪标签训练分类器是有效的。\nCEAS的高覆盖率之所以能够实现，可能是因为分类器可以专注于为每个类别选择相关的提交信息。\nCAS -Multi倾向于比CAS -Single产生更高的ROUGE -L。\n这代表着，为每个发行说明类别独立开发不同的抽象总结模型也是有效的。\n这里有一个错误分析。\nCAS方法倾向于输出比人类参考句子更短的句子。\n在右图中，引用句子有3或4个句子 ，而CAS只有1个。\n这个模型不愿输出的原因是，在训练数据中，只有33%的句子出现在特征标签中，40%出现在改进标签中。\n此外，如果没有额外的信息，CAS方法就无法生成准确的发行说明。\n右边最上面的例子是一个非常混乱的提交消息的例子，如果不参考相应的进度或问题，就无法生成完整的句子。\n下面的例子显示，输入中的两个提交信息是相关的，应该合并成一个句子，但它没有这么做。\n最后，一个结论。\n我们已经建立了一个新的数据集，用于自动生成发行说明。\n我们还制定了一项输入提交信息并对其进行总结的任务，以便适用于所有用英语写的项目。\n我们的实验表明，与基线相比，所提出的方法在更高的覆盖率下产生了更少干扰的发行说明。\n请查看我们在GitHub上的数据集。\n谢谢。", "src_lang": "en", "tgt_lang": "zh", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
