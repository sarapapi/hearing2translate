{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "zh", "output": "Assa Farahari将介绍我们的论文《通过微调的基于转换器架构进行表单数据增强》。数据科学家分析数据，主要关注数据的现有特征。但有时这些特征是有限的。使用其他数据源的特征生成可能会添加大量信息。我们的研究目标是自动地使用外部来源的文本进行表单数据增强。假设我们有一个表单数据集和一个知识库。我们需要一个自动化的过程,涉及实体链接和文本分析来从知识库的文本中提取新特征。我们的框架FASt正是这个自动化过程。所以让我们看一个例子。在FASt的第一个数据集中,数据集是大学数据集,其目标是将大学分类为低排名和高排名大学。作为知识库,我们使用维基百科。FASt的第一个阶段是实体链接。当知识库中的实体名称被链接到知识库中的实体时,并且知识库的文本被提取到数据集中。在这个例子中,知识库的文本是维基百科的摘要。现在我们需要生成或提取文本中提取的特征。因此,我们需要一个特征提取阶段,包括文本分析。这个是本论文的主要内容,我将在接下来的幻灯片中深入探讨。特征提取阶段后是特征生成阶段,我们使用提取的特征生成新的特征。FASt在原始数据集中生成的特征数量等于原始数据集的类数。在这个例子中,原始数据集有两个类,因此FASt生成两个新特征。但如果原始数据集有五个类,则FASt生成五个新特征。每个特征都表示原始数据集中每个类的可能性。要分析文本,我们使用当前的文本分析技术,即基于转换器的语言模型,如BERT、GPT等。但如果我们无法使用输入数据集训练语言模型,那么我们需要采用目标任务微调的方法。在特征提取阶段,我们可以下载预训练的语言模型,微调该模型在目标数据集上。以此类推,在这个例子中,我们微调语言模型以将文本分类为两类low或high。我们接收语言模型输出,即每类的可能性,并将其用作新特征。特征提取阶段的问题是数据集中实体文本的数量可能很少。在我们的实验中,几乎一半的数据集中实体文本的数量少于400个样本,最小的数据集中实体文本的数量为35个样本。因此,在这种数据集上微调语言模型将是无效的。但是,我们可以使用先前分析过的数据集的信息,因为我们应用FASt在多个数据集上。我们可以使用N-1数据集来收集N-1数据集的信息,并在分析N数据集时使用这些信息。我们建议添加另一个微调阶段,即初步多任务微调阶段,在此阶段中微调语言模型在N-1数据集上。然后执行另一个微调阶段,即目标任务微调。最先进的多任务微调称为M-T-D-NN。在M-T-D-NN中,保持N个任务的头部。因此,在这个例子中,训练集中有四个任务,因此M-T-D-NN保持四个头部。它从训练集中随机抽取一个批次,如果该批次属于单句分类任务,则执行前向和后向路径通过第一个头部。如果该批次属于对句排名任务,则执行前向和后向路径通过最后一个头部。在我们的场景中,表单数据集的类数可能会变化。因此,M-T-D-NN需要为新数据集初始化新的头部。我们的方法称为任务重新表述微调。我们在我们的方法中将任务重新表述为句子分类问题,即两类任务。我们训练语言模型将句子分类为true或false。我们对输入数据集的算法如下。FASt将数据集输入到FASt,然后执行实体链接阶段。它提取知识库的文本,例如维基百科的摘要。然后我们将任务重新表述为句子分类问题。应用语言模型到新任务,并输出每类的可能性。注意语言模型已经在N-1数据集上使用预先微调。然后使用语言模型输出作为新特征的输出。"}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "zh", "output": "大家好, 今天我要介绍一下我们研究工作《学习推理复杂推理的数学问题解决》。我是来自BYDANCEAI实验室的Alan,这是一项与来自德克萨斯大学奥斯汀分校的Chery和来自SUTD的Weilu的联合工作。首先我想谈谈我们对推理的动机。我们在PAPERS论文中展示了一个场景,在短时间学习中解决数学问题。我们在图表的左侧可以看到,如果给出更多的推理描述,模型就能预测正确的推理描述并做出正确的预测。因此,具有可解释的多步推理输出。我们认为数学问题是评估这种推理能力的一个简单应用。我们的问题设置中,给定问题需要解决并得到数字答案。在我们的数据集中,我们还给出了数学表达式,这也导致了这个特定答案。我们还需要遵循一些假设。与之前的工作一样,我们假设数量的精度是已知的,我们只考虑基本运算，如加法、减法、乘法、除法和指数运算。进一步地,复杂的运算实际上可以分解为这些基本运算。因此,在传统的序列到序列模型中,我们将表达式转换为特定的序列进行生成。它很容易实现,并且可以泛化到许多复杂的问题。但是,性能通常并不比结构模型好。缺乏可解释的预测。因此,这种方向仍然很受欢迎,因为转换模型。树基模型实际上将这些表达式结构化为树形式,并遵循树生成的先后顺序。在这里,我们继续生成运算符,直到到达叶子,即数量。这里的好处是我们首先生成运算符,然后在最后生成数量。第二件好处是它还包含一些重复计算。例如,在这个表达式中,8乘以3加3实际上是生成了两次,但实际上我们应该重用第二步的结果。我们的提出的方法是逐步地解决这些问题,并且是可解释的。比如在第二步中,我们可以找到这个除数,并且可以通过原始问题找到相关内容。在第三步中,我们实际上得到商。经过这三步,我们可以重复第二步的结果,然后得到第四步的结果。然后我们可以得到商。这里我们直接生成整个表达式,而不是生成单个运算符或量。因此,这个过程更准确。我们的deductive系统首先从问题中呈现的数量和一些常数开始。表达式由Eijop表示,其中我们执行从q1到qj的运算符。这个表达式实际上是有方向的。这里有减法的反向表示。与形式的deductive系统类似,在时间步长T中,我们应用运算符在q1和qj对之间。然后我们得到新的表达式。我们将其添加到下一个状态，成为新的量。在我们的模型实现中,我们首先使用预训练的语言模型,可以是BERT或RoBERTa。然后我们编码句子,然后我们得到这些量的表示。然后我们可以开始做推理。在推理阶段,我们展示一个例子,要得到Q1除以Q2的分数。首先我们得到Q1和Q2的对表示,然后应用一个参数化的反馈网络。最后我们得到表达式表示Q1除以Q2。但是,在实践中，在推理阶段我们可能会得到错误的表达式。这里所有可能的表达式等于运算符的数量。好处是我们可以添加一些约束来控制搜索空间。例如,如果这个表达式不允许,我们可以简单地删除这个表达式。第二步中我们做同样的事情,但只有一个多余的量。最后我们得到Q3乘以Q4。我们还可以看到两个步骤的可能表达式的数量与之前的不同。这样使得应用Bing搜索变得困难,因为每个时间步的概率分布都不平衡。因此,我们在MWPS、Math23K、MathQA和SWAMP上进行训练。我们简要展示了与以前的最佳方法相比的结果。我们的最佳的Roberta推理器。实际上我们不使用Bing搜索。其他的应用都是树基模型。我们的推理器实际上比树基模型明显优越。但在MathQA或SWAMP上表现不太好。我们进一步研究了SWAMP上的结果。这个数据集很有挑战性,因为作者试图手动添加一些信息来迷惑NLP模型,比如添加一些无关的信息和额外的数量。我们在预测中发现一些中间值实际上是负数的。例如,我们问杰克有多少苹果,但有一些额外的信息,比如斯蒂芬有8个苹果,这完全是无关的。因此,我们的模型做出类似的预测,这就是生产3倍的数量。我们在第二步中做了相同的事情。只有一个不同之处。这个量来自前一个计算的表达式。最后我们得到Q3乘以Q4。我们还可以看到两个步骤的可能表达式的数量与之前的不同。这样使得搜索空间变得不平衡。我们在MWPS上没有太多的例子,所以我就忽略了这个部分。最后,我们通过问题和预测来展示模型的可解释性。我们认为这个句子可能会误导模型到错误的预测。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型。我们认为这个句子可能会误导模型"}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "zh", "output": "你好，我是来自马斯特里赫特大学的Antoine。我将介绍我与Gerry共同完成的关于新数据集的法定文章检索。法律问题是许多人生活中不可或缺的一部分,但大多数公民对他们的权利和基本法律程序知之甚少。因此,许多无力的公民被剥夺了保护或甚至被剥削。我们的工作旨在弥合公民和法律之间的鸿沟,通过开发有效检索法定文章的系统。这样的系统可以为无技能的人提供免费的专业法律帮助服务。"}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "zh", "output": "我们很高兴向大家介绍我们的工作《VAlues》，这是一个针对特定语言现象的任务独立基准测试。我们为什么要建立这个基准测试?"}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "zh", "output": "您好，我是来自东京大学的神户。我要介绍的论文题为《通过提交日志总结自动生成版本说明文档》。我将按照以下顺序解释。首先，我将介绍我们在本研究中正在研究的自动版本说明文档生成。版本说明文档是技术文档，概述了每个软件版本的分发。图片显示了版本说明文档的版本2.6.4。版本说明文档在开源开发中起着重要作用，但手动准备版本说明文档是很耗时的。因此，能够自动生成高质量版本说明文档将非常有用。我要介绍的两项前期研究是关于自动版本说明文档生成的。第一个是一个名为Aranea的系统。2014年发布。它采用基于规则的方法。例如，使用差异提取器来提取核心差异、库更改和文档更改。然后将它们组合在一起。该系统的最显著功能是问题提取器。位于右上角。必须链接到Jira，发布问题的系统。只能应用于使用Jira的项目。换句话说，它不能用于许多项目。第二项是Griff。最近在2020年宣布。它可以在互联网上使用，并且可以通过pip安装。该系统具有简单的文本分类模型，并为每个输入提交消息输出一个或多个特征或修复。示例图像显示了一个示例用例，返回了一个修复级别。Griff的训练数据非常小，大约5,000个。将在下面的实验中显示。该文本分类模型的性能不是很高。示例图像显示了一个示例用例，返回了一个修复级别。我们介绍了两项相关的研究，但存在两个问题：适用性受限和数据资源不足。我们的论文解决了这两个问题。解决了适用性问题，我们提出了一个高质量的分类摘要方法。使用提交提交消息作为输入。该方法可以用于所有英语版本。解决了第二个问题，我们建立了一个包含大约8,200个数据的RNSUM数据集。通过使用GitHub API从公共GitHub存储库中收集数据。接下来，我将描述我们的数据集。以下是示例数据。左边是提交消息，右边是版本说明文档。版本说明文档被标记为功能、改进、补丁、增量、删除和破坏更改。这些标签是根据以前的研究和其他事实设置的。版本说明文档在右下角和提取的提交版本之间显示。现在，必须识别前一个版本和后一个版本。获取它们之间的差异。这个过程有点繁琐，但仅查看版本说明文档和提交版本是不够的。我们创建了一个启发式匹配规则来获取前一个版本和后一个版本。数据集分析。最后，我将介绍我们提出的方法。提议的模型包括两个神经网络。一个使用Bert或Transformer的分类器和一个使用Bert的生成器。首先，CEAS使用分类器将每个提交消息分类为五个版本说明文档类。其他类的提交消息被忽略。然后，CEAS应用了生成器，分别对四个类的文档生成版本说明文档。由于提交消息和版本说明文档之间没有直接对应关系，因此在训练分类器时使用提交消息的前10个字符作为输入。我们对提议的摘要方法进行了两种不同的建模。第一个模型称为GAS单。由一个单一的层到层网络生成一个单一的版本说明文档文本。输出文本可以根据特定的类特征分割成不同的类段。第二种方法称为GAS多。由四个不同的层到层网络，每个对应于一个版本说明文档类。"}
