{"dataset_id": "acl_6060", "sample_id": 0, "src_audio": "/acl6060/audio/dev/0.wav", "src_ref": "Hi, this is Elena and I'm going to be presenting our work, Detecting Unassimilated Borrowings in Spanish: An Annotated Corpus and Approaches to Modeling.", "tgt_ref": "Bonjour, je m’appelle Elena et je vais vous présenter notre travail, détecter les emprunts non assimilés en espagnol : un corpus annoté et des approches de modélisation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_audio": "/acl6060/audio/dev/1.wav", "src_ref": "So we're going to be covering what lexical borrowing is, the task that we proposed, the dataset that we have released and some models that we explored.", "tgt_ref": "Nous allons donc couvrir ce qu’est l’emprunt lexical, la tâche que nous avons proposée, les données que nous avons publiées et certains modèles que nous avons explorés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_audio": "/acl6060/audio/dev/2.wav", "src_ref": "But to begin with, what is lexical borrowing and why it matters as an NLP task?", "tgt_ref": "Mais pour commencer, qu’est-ce que l’emprunt lexical et pourquoi est-ce important en tant que tâche de TAL traitement automatique du langage naturel ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_audio": "/acl6060/audio/dev/3.wav", "src_ref": "Well, lexical borrowing is basically the incorporation of words from one language into another language.", "tgt_ref": "Eh bien, l’emprunt lexical est fondamentalement l’incorporation de mots d’une langue dans une autre langue.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_audio": "/acl6060/audio/dev/4.wav", "src_ref": "For instance, in Spanish we use words that come from English.", "tgt_ref": "Par exemple, en espagnol, nous utilisons des mots qui viennent de l’anglais.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_audio": "/acl6060/audio/dev/5.wav", "src_ref": "And here you have a few examples, words such as podcast, app, and online crowdfunding, all these are English words that we sometimes use in Spanish.", "tgt_ref": "Et ici, vous avez quelques exemples : des mots tels que podcast, app et crowdfunding en ligne ; tous ces mots sont des mots anglais que nous utilisons parfois en espagnol.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_audio": "/acl6060/audio/dev/6.wav", "src_ref": "Lexical borrowing is a type of linguistic borrowing um which is basically reproducing in one language patterns of other languages.", "tgt_ref": "L’emprunt lexical est un type d’emprunt linguistique qui consiste essentiellement à reproduire dans une langue des modèles d’autres langues.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_audio": "/acl6060/audio/dev/7.wav", "src_ref": "And borrowing and code switching have sometimes been compared and described as a continuum, code switching being ah the thing that bilinguals do where they mix two languages at the same time.", "tgt_ref": "Et l’emprunt et l’alternance codique ont parfois été comparés et décrits comme un continuum, l’alternance codique étant la chose que font les bilingues lorsqu’ils mélangent deux langues en même temps.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_audio": "/acl6060/audio/dev/8.wav", "src_ref": "There are however some differences between lexical borrowing and code-switching.", "tgt_ref": "Il y a cependant quelques différences entre l’emprunt lexical et l’alternance codique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_audio": "/acl6060/audio/dev/9.wav", "src_ref": "We're going to be focusing on lexical borrowing.", "tgt_ref": "Nous allons nous concentrer sur l’emprunt lexical.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_audio": "/acl6060/audio/dev/10.wav", "src_ref": "Code switching is something that is done by bilinguals and by definition the code switches are not integrated into any of the languages in use, whereas lexical borrowing is something that is also done by monolinguals.", "tgt_ref": "L’alternance codique est quelque chose qui est fait par les bilingues et par définition, les alternances codiques ne sont pas intégrées dans l’une des langues utilisées, alors que l’emprunt lexical est quelque chose qui est également fait par les monolingues.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_audio": "/acl6060/audio/dev/11.wav", "src_ref": "The borrowings will comply with the grammar of the recipient language.", "tgt_ref": "Les emprunts seront conformes à la grammaire de la langue du destinataire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_audio": "/acl6060/audio/dev/12.wav", "src_ref": "And borrowings can eventually be integrated into the recipient language.", "tgt_ref": "Et les emprunts peuvent éventuellement être intégrés dans la langue du destinataire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_audio": "/acl6060/audio/dev/13.wav", "src_ref": "So why is borrowing an interesting phenomenon?", "tgt_ref": "Alors pourquoi emprunter un phénomène intéressant ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_audio": "/acl6060/audio/dev/14.wav", "src_ref": "Well, from the point of view of linguistics, borrowing is a manifestation of of how languages change and how they interact.", "tgt_ref": "Eh bien, du point de vue de la linguistique, l’emprunt est une manifestation de la façon dont les langues changent et comment elles interagissent.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_audio": "/acl6060/audio/dev/15.wav", "src_ref": "And also lexical borrowings are a source of new words.", "tgt_ref": "Et aussi, les emprunts lexicaux sont une source de nouveaux mots.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_audio": "/acl6060/audio/dev/16.wav", "src_ref": "Here you have some examples of lexical borrowings that have been incorporated into the Spanish language as new words.", "tgt_ref": "Ici, vous avez quelques exemples d’emprunts lexicaux qui ont été incorporés dans la langue espagnole en tant que nouveaux mots.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_audio": "/acl6060/audio/dev/17.wav", "src_ref": "In terms of NLP ah borrowings are a common source of out-of-vocabulary words.", "tgt_ref": "En termes de TAL traitement automatique du langage naturel, les emprunts sont une source courante de mots hors-vocabulaire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_audio": "/acl6060/audio/dev/18.wav", "src_ref": "And in fact, automatically detecting lexical borrowings ah has proven to be useful for NLP downstream tasks such as parsing, text-to-speech synthesis or machine translation.", "tgt_ref": "Et en effet, détecter automatiquement les emprunts lexicaux s’est avéré utile pour les tâches downstream de TAL traitement automatique du langage naturel telles que l’analyse syntaxique, la synthèse texte-parole ou la traduction automatique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_audio": "/acl6060/audio/dev/19.wav", "src_ref": "There has been a growing interest in the influence of English on other languages ah particularly ah related to English lexical borrowings, borrowings which sometimes have been called Anglicisms.", "tgt_ref": "Il y a eu un intérêt croissant pour l’influence de l’anglais sur d’autres langues, en particulier les emprunts lexicaux anglais, des emprunts qui ont parfois été appelés anglicismes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_audio": "/acl6060/audio/dev/20.wav", "src_ref": "And here, you have some examples of ah work on automatic detection of borrowings in ah some of these languages.", "tgt_ref": "Et ici, vous avez quelques exemples de travail sur la détection automatique des emprunts dans certaines de ces langues.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_audio": "/acl6060/audio/dev/21.wav", "src_ref": "So the task that we propose is to detect unassimilated lexical borrowings in Spanish newswire.", "tgt_ref": "Donc, la tâche que nous proposons est de détecter les emprunts lexicaux non assimilés dans le fil d’actualité espagnol.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_audio": "/acl6060/audio/dev/22.wav", "src_ref": "Which means that we are interested in extracting ah words borrowed from other languages that are being used in Spanish newspapers but that have not been integrated or assimilated into the recipient language.", "tgt_ref": "Ce qui signifie que cela nous intéresse d'extraire les mots empruntés à d’autres langues qui sont utilisés dans les journaux espagnols, mais qui n’ont pas été intégrés ou assimilés dans la langue du destinataire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_audio": "/acl6060/audio/dev/23.wav", "src_ref": "So not yet integrated into Spanish.", "tgt_ref": "Donc pas encore intégrés à l’espagnol.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_audio": "/acl6060/audio/dev/24.wav", "src_ref": "Here you have an example.", "tgt_ref": "Vous avez ici un exemple.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_audio": "/acl6060/audio/dev/25.wav", "src_ref": "This is a sentence in Spanish: Las prendas bestsellers se estampan con motivos florales, animal print o retales tipo patchwork.", "tgt_ref": "Ceci est une phrase en espagnol : Las prendas bestsellers se estampan con motivos florales, animal print o retales tipo patchwork.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_audio": "/acl6060/audio/dev/26.wav", "src_ref": "Um, and as you can see, there are three spans of texts which are actually English words like bestseller, animal print and patchwork.", "tgt_ref": "Hum, et comme vous pouvez le voir, il y a trois étendages de textes qui sont en réalité des mots anglais comme bestseller, animal print et patchwork.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_audio": "/acl6060/audio/dev/27.wav", "src_ref": "These are the type of spans that we are interested in extracting and detecting.", "tgt_ref": "Il s’agit du type d’étendages qu'il nous intéresse d'extraire et de détecter.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_audio": "/acl6060/audio/dev/28.wav", "src_ref": "There has been previous word on Anglicism detection ah which consists consisted of a CRF model for Anglicism detection on Spanish Newswire.", "tgt_ref": "Il y a eu un mot antérieur sur la détection de l’anglicisme qui consiste en un modèle CRF pour la détection de l’anglicisme sur le fil d’actualité espagnol.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_audio": "/acl6060/audio/dev/29.wav", "src_ref": "This model achieved an F1 score of eighty six.", "tgt_ref": "Ce modèle a obtenu un score F1 de quatre-vingt-six.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_audio": "/acl6060/audio/dev/30.wav", "src_ref": "But there were some limitations both um in the dataset and the modeling approach.", "tgt_ref": "Mais il y avait des limites à la fois dans les données et dans l’approche de modélisation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_audio": "/acl6060/audio/dev/31.wav", "src_ref": "So the dataset focused exclusively on one source of news, consisted only of headlines.", "tgt_ref": "Ainsi, les données se concentraient exclusivement sur une source d'actualités, ne comprenaient que des titres.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_audio": "/acl6060/audio/dev/32.wav", "src_ref": "And also there was an overlap in the borrowings that appear in the training set and the test set.", "tgt_ref": "Et il y avait aussi un chevauchement dans les emprunts qui apparaissent dans l’ensemble de formation et l’ensemble de test.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_audio": "/acl6060/audio/dev/33.wav", "src_ref": "This prevented the assessment of whether the modeling approach could actually generalize to previously unseen borrowings.", "tgt_ref": "Cela a empêché d’évaluer si l’approche de modélisation pouvait effectivement se généraliser aux emprunts précédemment invisibles.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_audio": "/acl6060/audio/dev/34.wav", "src_ref": "So what we aim is to tackle some of these limitations in the task.", "tgt_ref": "Nous visons donc à nous attaquer à certaines de ces limites dans la tâche.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_audio": "/acl6060/audio/dev/35.wav", "src_ref": "So to begin we, to begin with, we created a new dataset.", "tgt_ref": "Alors, pour commencer, nous avons créé de nouvelles données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_audio": "/acl6060/audio/dev/36.wav", "src_ref": "Ah the aim at a new dataset that was annotated with lexical borrowings and the aim was to create a test set that was as difficult as possible.", "tgt_ref": "Avec de nouvelles données qui ont été annotées avec des emprunts lexicaux, le but était de créer un ensemble de test aussi difficile que possible.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_audio": "/acl6060/audio/dev/37.wav", "src_ref": "So there would be minimal overlap in words and topics between the training set and test set.", "tgt_ref": "Il y aurait donc un chevauchement minimal entre les mots et les sujets entre l’ensemble de formation et l’ensemble de test.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_audio": "/acl6060/audio/dev/38.wav", "src_ref": "And as a result, well, the test set comes from sources and dates that we're not seeing in the training set.", "tgt_ref": "Et par conséquent, eh bien, l’ensemble de test provient de sources et de dates que nous ne voyons pas dans l’ensemble de formation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_audio": "/acl6060/audio/dev/39.wav", "src_ref": "Here you can see that there's no overlap in the in the time.", "tgt_ref": "Ici, vous pouvez voir qu’il n’y a pas de chevauchement dans le temps.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_audio": "/acl6060/audio/dev/40.wav", "src_ref": "It's also, the test set is also very borrowing-dense.", "tgt_ref": "L’ensemble de test est aussi très dense en termes d’emprunt.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_audio": "/acl6060/audio/dev/41.wav", "src_ref": "Just to give you some numbers, if the training set contains six borrowings per each thousand tokens, the test set contained twenty borrowings per each thousand tokens.", "tgt_ref": "Juste pour vous donner quelques chiffres, si l’ensemble de formation contient six emprunts pour mille gages, l’ensemble de test contenait vingt emprunts pour mille gages.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_audio": "/acl6060/audio/dev/42.wav", "src_ref": "The test set contained as many out of vocabulary words as possible.", "tgt_ref": "L’ensemble de test contenait autant de mots hors-vocabulaire que possible.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_audio": "/acl6060/audio/dev/43.wav", "src_ref": "In fact, ninety two percent of the borrowings in the test set are OOV.", "tgt_ref": "En effet, quatre-vingt-douze pour cent des emprunts dans l’ensemble de test sont des OOV.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_audio": "/acl6060/audio/dev/44.wav", "src_ref": "So, they were not seen during training.", "tgt_ref": "Ils n’ont donc pas été vus pendant la formation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_audio": "/acl6060/audio/dev/45.wav", "src_ref": "And the corpus consisted basically of a collection of texts that came from different sources of Spanish newspapers.", "tgt_ref": "Et le corpus consistait essentiellement en une collection de textes provenant de différentes sources de journaux espagnols.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_audio": "/acl6060/audio/dev/46.wav", "src_ref": "And ah it was annotated by hand ah using two tags.", "tgt_ref": "Et il a été annoté à la main en utilisant deux étiquettes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_audio": "/acl6060/audio/dev/47.wav", "src_ref": "One for English lexical borrowings which is the majority of lexical borrowings in Spanish, and then the label other for borrowings from other languages.", "tgt_ref": "Une pour les emprunts lexicaux anglais, constituant la majorité des emprunts lexicaux en espagnol, puis l’autre étiquette pour les emprunts d’autres langues.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_audio": "/acl6060/audio/dev/48.wav", "src_ref": "We use CONLL formats and we used BIO encoding so that we could encode ah single token borrowings such as app or multi token borrowings such as machine learning.", "tgt_ref": "Nous utilisons les formats CoNLL et avons utilisé l’encodage BIO pour pouvoir encoder des emprunts de gages simples tels que app ou des emprunts de gages multiples tels que l'apprentissage automatique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_audio": "/acl6060/audio/dev/49.wav", "src_ref": "These are the numbers of the corpus.", "tgt_ref": "Ce sont les chiffres du corpus.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_audio": "/acl6060/audio/dev/50.wav", "src_ref": "As you can see, it amounts to roughly three hundred seventy thousand tokens.", "tgt_ref": "Comme vous pouvez le voir, il s’élève à environ trois cent soixante-dix mille gages.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_audio": "/acl6060/audio/dev/51.wav", "src_ref": "And here you have the number of spans that were labeled as English and the spans that were labeled as other borrowings and how many of them were unique.", "tgt_ref": "Et ici, vous avez le nombre d’étendages qui ont été étiquetés comme anglais et les étendages qui ont été étiquetés comme autres emprunts, et combien d’entre eux étaient uniques.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_audio": "/acl6060/audio/dev/52.wav", "src_ref": "And here you have a couple of examples of the of the set of the dataset.", "tgt_ref": "Et ici, vous avez quelques exemples de l’ensemble des données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_audio": "/acl6060/audio/dev/53.wav", "src_ref": "As you can see for instance here, we have ah in the first example, we have the borrowing batch cooking which is a multi word borrowing.", "tgt_ref": "Comme vous pouvez le voir ici, par exemple, nous avons dans le premier exemple le batch cooking emprunteur qui est un emprunt de mots multiples.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_audio": "/acl6060/audio/dev/54.wav", "src_ref": "And we have annotated it using the BIO um encode.", "tgt_ref": "Et nous l’avons annoté en utilisant l’encodage BIO.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_audio": "/acl6060/audio/dev/55.wav", "src_ref": "So the BIO was used for words in Spanish so not for words that were not borrowed.", "tgt_ref": "Donc le BIO a été utilisé pour des mots en espagnol, et non pour des mots qui n’ont pas été empruntés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_audio": "/acl6060/audio/dev/56.wav", "src_ref": "And here in this second example, you have benching and crash which are also labeled as borrowings from English.", "tgt_ref": "Et ici, dans ce deuxième exemple, vous avez benching et crash qui sont également étiquetés comme des emprunts de l’anglais.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_audio": "/acl6060/audio/dev/57.wav", "src_ref": "So, once we had the dataset, we explored several models for the task of extracting and detecting these lexical borrowings.", "tgt_ref": "Donc, une fois que nous avons eu les données, nous avons exploré plusieurs modèles pour la tâche d’extraction et de détection de ces emprunts lexicaux.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_audio": "/acl6060/audio/dev/58.wav", "src_ref": "The first one that we tried was the conditional random field model.", "tgt_ref": "Le premier que nous avons essayé était le modèle de champ aléatoire conditionnel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_audio": "/acl6060/audio/dev/59.wav", "src_ref": "Ah, this was the model that had been used on previous work.", "tgt_ref": "Ah, c’était le modèle qui avait été utilisé sur le travail antérieur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_audio": "/acl6060/audio/dev/60.wav", "src_ref": "And we used the same handcrafted features from that from those from that work.", "tgt_ref": "Et nous avons utilisé les mêmes fonctions faites main à partir de celles de ce travail.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_audio": "/acl6060/audio/dev/61.wav", "src_ref": "As you can see, these are the features.", "tgt_ref": "Comme vous pouvez le voir, voici les fonctions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_audio": "/acl6060/audio/dev/62.wav", "src_ref": "These are binary features such as the word or the token in upper case?", "tgt_ref": "Ce sont des fonctions binaires telles que le mot ou le gage en majuscules ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_audio": "/acl6060/audio/dev/63.wav", "src_ref": "Is it title titlecase?", "tgt_ref": "Est-ce une casse de titre ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_audio": "/acl6060/audio/dev/64.wav", "src_ref": "Is it a quotation mark?", "tgt_ref": "Est-ce un guillemet ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_audio": "/acl6060/audio/dev/65.wav", "src_ref": "Things like that, which are the type of features that one would expect in a named entity recognition task.", "tgt_ref": "Des choses comme ça, qui sont le type de fonctions que l’on attendrait d’une tâche de named entity recognition.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_audio": "/acl6060/audio/dev/66.wav", "src_ref": "These are the results that we got.", "tgt_ref": "Voici les résultats que nous avons obtenus.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_audio": "/acl6060/audio/dev/67.wav", "src_ref": "We obtain fifty five F1 score using the the CRF model with handcrafted features.", "tgt_ref": "Nous obtenons cinquante-cinq points en F1 en utilisant le modèle CRF avec des fonctions faites main.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_audio": "/acl6060/audio/dev/68.wav", "src_ref": "Which is a huge different difference um compared to the reported F1 score of eighty six, which was the result obtained with the same CRF model, same features but on a different dataset also for Spanish lexical borrowing detection.", "tgt_ref": "Ce qui est une énorme différence comparée au score F1 de quatre-vingt-six rapporté, qui était le résultat obtenu avec le même modèle CRF, les mêmes fonctions mais sur des données différentes également pour la détection de l’emprunt lexical espagnol.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_audio": "/acl6060/audio/dev/69.wav", "src_ref": "So, this proves that the dataset that we created is more difficult and that we needed to explore more sophisticated models for these tasks.", "tgt_ref": "Donc, cela prouve que les données que nous avons créées sont plus difficiles et que nous devions explorer des modèles plus sophistiqués pour ces tâches.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_audio": "/acl6060/audio/dev/70.wav", "src_ref": "So, we tested two transformer based models.", "tgt_ref": "Nous avons donc testé deux modèles basés sur la conversion.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_audio": "/acl6060/audio/dev/71.wav", "src_ref": "We used BETO which is a monolingual BERT model trained for Spanish and also multilingual BERT.", "tgt_ref": "Nous avons utilisé BETO qui est un modèle de Représentations d'encodeurs bidirectionnels à partir de transformateurs monolingue formé pour l’espagnol, mais aussi des Représentations d'encodeurs bidirectionnels à partir de transformateurs multilingues.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_audio": "/acl6060/audio/dev/72.wav", "src_ref": "Both models we use them through the transformers library by HuggingFace.", "tgt_ref": "Nous utilisons les deux modèles à travers la bibliothèque de conversion d’HuggingFace.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_audio": "/acl6060/audio/dev/73.wav", "src_ref": "These are the results that we got.", "tgt_ref": "Voici les résultats que nous avons obtenus.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_audio": "/acl6060/audio/dev/74.wav", "src_ref": "As you can see, multilingual BERT performs better than BETO both on the development set and on the test set and across all metrics.", "tgt_ref": "Comme vous pouvez le voir, les Représentations d'encodeurs bidirectionnels à partir de transformateurs multilingues fonctionnent mieux que les BETO à la fois sur l’ensemble de développement et sur l’ensemble de test, et à travers tous les indicateurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_audio": "/acl6060/audio/dev/75.wav", "src_ref": "Just so we have ah an idea to compare, the CRF model obtained an eighty two.", "tgt_ref": "Juste pour que nous ayons une idée à comparer, le modèle CRF a obtenu un quatre-vingt-deux.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_audio": "/acl6060/audio/dev/76.wav", "src_ref": "The CRF model obtained a fifty five obtained a fifty five F1 score, whereas the multilingual BERT obtained eighty two, which is a big difference.", "tgt_ref": "Le modèle CRF a obtenu cinquante-cinq points en F1, tandis que les Représentations d'encodeurs bidirectionnels à partir de transformateurs multilingues ont obtenu quatre-vingt-deux, ce qui est une grande différence.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_audio": "/acl6060/audio/dev/77.wav", "src_ref": "So, once that we had those results, we asked ourselves another question which is, could we find a BiLSTM-CRF model, feed it with different types of embeddings, embeddings that encode different types of linguistic information and perform outperform the results obtained by transformer based models?", "tgt_ref": "Donc, une fois que nous avons eu ces résultats, nous nous sommes posés une autre question qui est : pourrions-nous trouver un modèle BiLSTM-CRF, l’alimenter avec différents types d’intégrations, des intégrations qui encodent différents types d’informations linguistiques, et dépasser les résultats obtenus par les modèles basés sur la conversion ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_audio": "/acl6060/audio/dev/78.wav", "src_ref": "So in order to do so, we ran some preliminary experiments, we we run this by BiLSTM-CRF model using flare library.", "tgt_ref": "Donc, pour ce faire, nous avons effectué quelques expériences préliminaires ; nous avons exécuté ceci par le biais du modèle BiLSTM-CRF en utilisant la bibliothèque Flare.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_audio": "/acl6060/audio/dev/79.wav", "src_ref": "And we tried experimented with different type of embeddings like transformer-based but also fast-text, character embeddings, and so on.", "tgt_ref": "Et nous avons essayé d’expérimenter différents types d’intégrations comme celles basées sur la conversion, mais aussi des intégrations de caractères, de texte rapide et ainsi de suite.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_audio": "/acl6060/audio/dev/80.wav", "src_ref": "What we found out was that transformer-based embeddings performed better than non contextualized embeddings, that the combination of English BERT and Spanish BETO embeddings outperform multilingual BERT embeddings.", "tgt_ref": "Ce que nous avons découvert, c’est que les intégrations basées sur la conversion ont obtenu de meilleurs résultats que les intégrations non contextualisées, et que la combinaison d’intégrations de Représentations d'encodeurs bidirectionnels à partir de transformateurs en anglais et de BETO en espagnol dépasse les intégrations de Représentations d'encodeurs bidirectionnels à partir de transformateurs multilingues.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_audio": "/acl6060/audio/dev/81.wav", "src_ref": "And that BPE embeddings produced better F1 and character embeddings produce better recall.", "tgt_ref": "Et aussi, que les intégrations de BPE produisent un meilleur F1 et les intégrations de caractères, un meilleur rappel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_audio": "/acl6060/audio/dev/82.wav", "src_ref": "With that in mind, these were the best performing results that we got.", "tgt_ref": "Dans cet esprit, ce sont les meilleurs résultats que nous avons obtenus.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_audio": "/acl6060/audio/dev/83.wav", "src_ref": "Both models were BiLSTM-CRF models using flare.", "tgt_ref": "Les deux modèles étaient des modèles BiLSTM-CRF utilisant Flare.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_audio": "/acl6060/audio/dev/84.wav", "src_ref": "One was fed with BETO and BERT embeddings and BPE, and the other one BETO and BERT embeddings and BPE and also character embeddings.", "tgt_ref": "L’un a été alimenté avec des intégrations de BETO, de Représentations d'encodeurs bidirectionnels à partir de transformateurs et de BPE, et l’autre avec des intégrations de BETO, de Représentations d'encodeurs bidirectionnels à partir de transformateurs, de BPE et aussi des intégrations de caractères.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_audio": "/acl6060/audio/dev/85.wav", "src_ref": "This last one was the one that produced the highest F1 score on the test set, although the highest score on the development set was obtained by the one without character embeddings.", "tgt_ref": "Ce dernier était celui qui a produit le score F1 le plus élevé sur l’ensemble de test, bien que le score le plus élevé sur l’ensemble de développement ait été obtenu par celui sans intégrations de caractères.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_audio": "/acl6060/audio/dev/86.wav", "src_ref": "Just ah to bear in mind that the best result that we got with multilingual BERT obtained an F1 of seventy six on the development set and eighty two on the test set.", "tgt_ref": "Gardons juste à l’esprit que le meilleur résultat que nous avons obtenu avec Représentations d'encodeurs bidirectionnels à partir de transformateurs multilingues était un F1 de soixante-seize sur l’ensemble de développement et quatre-vingt-deux sur l’ensemble de test.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_audio": "/acl6060/audio/dev/87.wav", "src_ref": "So this is an improvement compared to those results.", "tgt_ref": "C’est donc une amélioration comparée à ces résultats.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_audio": "/acl6060/audio/dev/88.wav", "src_ref": "Finally, we asked ourselves another question which was can lexical borrowing detection be framed as transfer learning from language identification in code switching?", "tgt_ref": "Enfin, nous nous sommes posés une autre question qui était de savoir si la détection d’emprunt lexical pouvait être encadrée comme apprentissage par transfert de l’identification de langue dans l’alternance codique ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_audio": "/acl6060/audio/dev/89.wav", "src_ref": "So, we run the same BiLSTM-CRF model that we had run using flare, but instead of using these unadapted transformer-based BETO and BERT embeddings, we used code switch embeddings.", "tgt_ref": "Nous exécutons alors le même modèle BiLSTM-CRF que nous avions exécuté en utilisant Flare, mais au lieu d’utiliser ces intégrations de BETO et Représentations d'encodeurs bidirectionnels à partir de transformateurs basées sur la conversion non adaptées, nous avons utilisé les intégrations d’alternance codique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_audio": "/acl6060/audio/dev/90.wav", "src_ref": "What are code switch embeddings?", "tgt_ref": "Qu’est-ce que les intégrations d’alternance codique ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_audio": "/acl6060/audio/dev/91.wav", "src_ref": "Well these are um embeddings that are have been fine tuned transformer-based embeddings that have been pretrained for language identification on the Spanish English section of the LinCE code switching dataset.", "tgt_ref": "Eh bien, ce sont des intégrations qui ont été des intégrations basées sur la conversion ajustée, qui ont été préformées pour l’identification de langue sur la section anglaise espagnole des données d’alternance codique LinCE.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_audio": "/acl6060/audio/dev/92.wav", "src_ref": "LinCE is a dataset on code switching that has a section on Spanish English, Spanish English code switching.", "tgt_ref": "LinCE est un ensemble de données sur l’alternance codique qui comporte une section sur l’anglais espagnol, l’alternance codique anglais espagnol.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_audio": "/acl6060/audio/dev/93.wav", "src_ref": "So we fed our BiLSTM-CRF with code switch embeddings and optionally character embeddings, BPE embeddings and so on.", "tgt_ref": "Nous avons donc alimenté notre BiLSTM-CRF avec des intégrations d’alternance codique et éventuellement des intégrations de caractères, des intégrations de BPE et ainsi de suite.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_audio": "/acl6060/audio/dev/94.wav", "src_ref": "The best result that we got was eighty four point twenty two, which is the highest across all the models that we tried on the test set.", "tgt_ref": "Le meilleur résultat que nous avons obtenu était quatre-vingt-quatre points vingt-deux, ce qui est le plus élevé parmi tous les modèles que nous avons essayés sur l’ensemble de test.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_audio": "/acl6060/audio/dev/95.wav", "src_ref": "Although the best result F1 score that we got on the development set, which was seventy nine, was lower than the best result obtained by the BiLSTM-CRF fed with unadapted embeddings.", "tgt_ref": "Bien que le meilleur score F1 que nous ayons obtenu sur l’ensemble de développement, qui était de soixante-dix-neuf, était inférieur au meilleur résultat obtenu par le BiLSTM-CRF alimenté avec des intégrations non adaptées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_audio": "/acl6060/audio/dev/96.wav", "src_ref": "So, some conclusions from our work.", "tgt_ref": "Voilà donc les conclusions de notre travail.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_audio": "/acl6060/audio/dev/97.wav", "src_ref": "We have ah we have produced a new dataset of Spanish newswire that is annotated with unassimilated lexical borrowings.", "tgt_ref": "Nous avons produit de nouvelles données de fil d’actualité espagnol qui sont annotées avec des emprunts lexicaux non assimilés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_audio": "/acl6060/audio/dev/98.wav", "src_ref": "This dataset is more borrowing dense and OOV-rich than previous resources.", "tgt_ref": "Ces données sont plus denses en matière d’emprunt et riches en OOV par rapport aux ressources antérieures.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_audio": "/acl6060/audio/dev/99.wav", "src_ref": "We have explored four types of models for lexical borrowing detection.", "tgt_ref": "Nous avons exploré quatre types de modèles pour la détection d’emprunt lexical.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_audio": "/acl6060/audio/dev/100.wav", "src_ref": "Um. In terms of error analysis, well, recall was a weak point for all models.", "tgt_ref": "Hum. En termes d’analyse des erreurs, eh bien, le rappel était un point faible pour tous les modèles.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_audio": "/acl6060/audio/dev/101.wav", "src_ref": "Ah, as you can see here, some frequent false negatives include uppercase borrowings, words that exist in both English and Spanish, for instance.", "tgt_ref": "Ah, comme vous pouvez le voir ici, certains faux négatifs fréquents incluent des emprunts en majuscules, des mots qui existent à la fois en anglais et en espagnol, par exemple.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_audio": "/acl6060/audio/dev/102.wav", "src_ref": "Also interestingly, BPE embeddings seem to improve F1 score.", "tgt_ref": "Il est également intéressant de noter que les intégrations de BPE semblent améliorer le score F1.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_audio": "/acl6060/audio/dev/103.wav", "src_ref": "And character embedding seem to improve recall.", "tgt_ref": "Et l’intégration de caractères semble améliorer le rappel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_audio": "/acl6060/audio/dev/104.wav", "src_ref": "Which ah it's an interesting finding that perhaps we can explore on future work.", "tgt_ref": "Ce qui est une découverte intéressante que peut-être nous pouvons explorer sur les travaux futurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_audio": "/acl6060/audio/dev/105.wav", "src_ref": "Um. Well, this is everything that I have.", "tgt_ref": "Hum. Eh bien, c’est tout ce que j’ai.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_audio": "/acl6060/audio/dev/106.wav", "src_ref": "Thank you so much for listening.", "tgt_ref": "Merci beaucoup pour votre écoute.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_audio": "/acl6060/audio/dev/107.wav", "src_ref": "My name is Antoine.", "tgt_ref": "Je m’appelle Antoine.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_audio": "/acl6060/audio/dev/108.wav", "src_ref": "I'm a PhD student at the University of Massachusetts Amherst.", "tgt_ref": "Je suis doctorant à l’Université du Massachusetts à Amherst.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_audio": "/acl6060/audio/dev/109.wav", "src_ref": "I am presenting our paper KinyaBERT: a Morphology-aware Kinyarwanda Language Model.", "tgt_ref": "Je vous présente notre article KinyaBERT : un modèle de langue en kinyarwanda conscient de la morphologie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_audio": "/acl6060/audio/dev/110.wav", "src_ref": "Today, I'll talk about the motivation for this research.", "tgt_ref": "Aujourd’hui, je vais parler de la motivation pour ces recherches.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_audio": "/acl6060/audio/dev/111.wav", "src_ref": "Then I'll present KinyaBERT model architecture in detail.", "tgt_ref": "Ensuite, je présenterai en détail l’architecture du modèle KinyaBERT.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_audio": "/acl6060/audio/dev/112.wav", "src_ref": "I'll then talk about our experimental results, then finish with some conclusions.", "tgt_ref": "Je parlerai ensuite de nos résultats expérimentaux, puis je terminerai par quelques conclusions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_audio": "/acl6060/audio/dev/113.wav", "src_ref": "We all know that recent natural language processing advances have been made possible by the use of pretrained language models such as BERT.", "tgt_ref": "Nous savons tous que les progrès récents du traitement du langage naturel ont été rendus possibles par l’utilisation de modèles de langues préformées tels que les Représentations d'encodeurs bidirectionnels à partir de transformateurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_audio": "/acl6060/audio/dev/114.wav", "src_ref": "However, there are still a number of limitations.", "tgt_ref": "Cependant, il y a encore un certain nombre de limitations.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_audio": "/acl6060/audio/dev/115.wav", "src_ref": "Due to the complex morphology that is expressed by most morphologically rich languages, the ubiquitous byte pair encoding tokenization algorithm that I used cannot extract the exact subword lexical units, meaning the morphemes, which are needed for effective representation.", "tgt_ref": "En raison de la morphologie complexe qui est exprimée par la plupart des langues morphologiquement riches, l’algorithme de marquage byte pair encoding omniprésent que j’ai utilisé ne peut pas extraire les unités lexicales sous-mots exactes, signifiant les morphèmes, qui sont nécessaires pour une représentation efficace.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_audio": "/acl6060/audio/dev/116.wav", "src_ref": "For example, here we have three Kinyarwanda words that have several morphemes in them, but the BPE algorithms cannot extract them.", "tgt_ref": "Par exemple, ici, nous avons trois mots en kinyarwanda ayant plusieurs morphèmes en eux, mais les algorithmes de BPE ne peuvent pas les extraire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_audio": "/acl6060/audio/dev/117.wav", "src_ref": "This is because some morphological rules produce different surface forms that hide the exact lexical information, and BPE, which is solely based on the surface forms, does not have access to this lexical model.", "tgt_ref": "En effet, certaines règles morphologiques produisent différentes formes de surface qui cachent l’information lexicale exacte, et le BPE, qui est uniquement basé sur les formes de surface, n’a pas accès à ce modèle lexical.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_audio": "/acl6060/audio/dev/118.wav", "src_ref": "The second challenge is that even if one had access to an oracle morphological analyzer, replacing BPE tokens with morphemes is not enough to express the morphological compositionality.", "tgt_ref": "Le deuxième défi est que même si l’on avait accès à un analyseur morphologique oracle, remplacer les gages de BPE par des morphèmes n’est pas suffisant pour exprimer la compositionnalité morphologique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_audio": "/acl6060/audio/dev/119.wav", "src_ref": "A third gap in the research is that new pretrained language models are most often evaluated on high resource languages.", "tgt_ref": "Une troisième lacune dans les recherches est que les nouveaux modèles de langue préformée sont le plus souvent évalués sur des langues à ressources élevées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_audio": "/acl6060/audio/dev/120.wav", "src_ref": "And we need to assess their applicability on low resources and diverse languages as well.", "tgt_ref": "Et nous devons évaluer leur applicabilité sur des ressources faibles et diverses langues également.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_audio": "/acl6060/audio/dev/121.wav", "src_ref": "Therefore, we present KinyaBERT, which is a simple but effective adaptation of the BERT architecture that is meant to more effectively handle morphologically rich languages.", "tgt_ref": "Par conséquent, nous présentons KinyaBERT, qui est une adaptation simple mais efficace de l’architecture des Représentations d'encodeurs bidirectionnels à partir de transformateurs destinée à gérer plus efficacement les langues morphologiquement riches.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_audio": "/acl6060/audio/dev/122.wav", "src_ref": "We evaluate KinyaBERT on Kinyarwanda, a low resource morphologically rich language, which is spoken by more than twelve million people across Eastern and Central Africa.", "tgt_ref": "Nous évaluons KinyaBERT sur le kinyarwanda, une langue low resource riche morphologiquement, qui est parlée par plus de douze millions de personnes à travers l’Afrique de l’Est et centrale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_audio": "/acl6060/audio/dev/123.wav", "src_ref": "The input to the model is either a sentence or a document.", "tgt_ref": "La saisie du modèle est soit une phrase, soit un document.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_audio": "/acl6060/audio/dev/124.wav", "src_ref": "For example here, we have John twarahamubonye biradutangaza, which means we were surprised to find John there.", "tgt_ref": "Par exemple, ici, nous avons John twarahamubonye biradutangaza, qui signifie « nous avons été surpris de trouver John là-bas ».", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_audio": "/acl6060/audio/dev/125.wav", "src_ref": "As you can see, Kinyarwanda words contains several morphemes that contain different information in them.", "tgt_ref": "Comme vous pouvez le voir, les mots en kinyarwanda comprennent plusieurs morphèmes qui renferment différentes informations.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_audio": "/acl6060/audio/dev/126.wav", "src_ref": "Therefore, in our model, we pass this sentence or a document to a morphological analyzer.", "tgt_ref": "Par conséquent, dans notre modèle, nous faisons passer cette phrase ou un document à un analyseur morphologique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_audio": "/acl6060/audio/dev/127.wav", "src_ref": "Which then generates morphemes contained in each of the words.", "tgt_ref": "Ce qui engendre alors des morphèmes contenus dans chacun des mots.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_audio": "/acl6060/audio/dev/128.wav", "src_ref": "The morphemes usually are made of the stem and zero or more affixes.", "tgt_ref": "Les morphèmes sont généralement constitués du radical et de zéro ou plus d’affixes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_audio": "/acl6060/audio/dev/129.wav", "src_ref": "The affixes may indicate tense, aspect, subject or object in verbs, and more often relates to the Bantu noun class for subjects and objects.", "tgt_ref": "Les affixes peuvent indiquer le temps, l’aspect, le sujet ou l’objet dans les verbes, et se rapportent plus souvent à la classe nom bantoue pour les sujets et les objets.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_audio": "/acl6060/audio/dev/130.wav", "src_ref": "The morphological analyzer also produces a part of speech tag for each of the words.", "tgt_ref": "L’analyseur morphologique produit également une étiquette de partie de discours pour chacun des mots.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_audio": "/acl6060/audio/dev/131.wav", "src_ref": "After this step, we make embeddings for the spee- for the part of speech tags.", "tgt_ref": "Après cette étape, nous faisons des intégrations pour le dis- pour les étiquettes de la partie de discours.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_audio": "/acl6060/audio/dev/132.wav", "src_ref": "Embeddings for the affixes.", "tgt_ref": "Intégrations pour les affixes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_audio": "/acl6060/audio/dev/133.wav", "src_ref": "And embeddings for the stem.", "tgt_ref": "Et intégrations pour le radical.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_audio": "/acl6060/audio/dev/134.wav", "src_ref": "These are the morphology level, these are the morphology level embeddings.", "tgt_ref": "Il s’agit du niveau morphologique ; il s’agit des intégrations de niveau morphologique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_audio": "/acl6060/audio/dev/135.wav", "src_ref": "We then pass these embeddings through a morphology encoder, which is a small transformer encoder that is applied to each word independently.", "tgt_ref": "Nous faisons ensuite passer ces intégrations à travers un encodeur morphologique, qui est un petit encodeur de conversion appliqué à chaque mot indépendamment.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_audio": "/acl6060/audio/dev/136.wav", "src_ref": "The output of the are the vectors that are contextualized with the morphological information at each word.", "tgt_ref": "Les résultats sont les vecteurs contextualisés avec les informations morphologiques à chaque mot.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_audio": "/acl6060/audio/dev/137.wav", "src_ref": "Now, we perform composition where the morphological embeddings corresponding to part of speech and stem are concatenated together.", "tgt_ref": "Maintenant, nous effectuons une composition où les intégrations morphologiques correspondant à une partie de discours et au radical sont concaténées ensemble.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_audio": "/acl6060/audio/dev/138.wav", "src_ref": "We further concat we further concatenate them with another stem embedding at the sentence level.", "tgt_ref": "Nous les concaténons en outre avec une autre intégration du radical au niveau de la phrase.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_audio": "/acl6060/audio/dev/139.wav", "src_ref": "Then we form an input to the main sentence or document encoder.", "tgt_ref": "Ensuite, nous formons une saisie à la phrase principale ou l’encodeur de document.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_audio": "/acl6060/audio/dev/140.wav", "src_ref": "The final output are contextualized embeddings that can be used for downstream NLP tasks.", "tgt_ref": "Le résultat final donne des intégrations contextualisées qui peuvent être utilisées pour les tâches de TAL traitement automatique du langage naturel downstream.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_audio": "/acl6060/audio/dev/141.wav", "src_ref": "For a morphological analyzer, we use finite state two level morphology principles with custom implementation that is tailored to the Kinyarwanda language.", "tgt_ref": "Pour un analyseur morphologique, nous utilisons des principes de morphologie à deux niveaux à états finis avec une mise en œuvre personnalisée adaptée à la langue kinyarwanda.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_audio": "/acl6060/audio/dev/142.wav", "src_ref": "We effectively model the morphology of all Kinyarwanda words, including verbals, nouns, demonstrative and possessive pronouns, numerals, and others.", "tgt_ref": "Nous modélisons efficacement la morphologie de tous les mots en kinyarwanda, y compris les verbes, les noms, les pronoms démonstratifs et possessifs, les chiffres et autres.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_audio": "/acl6060/audio/dev/143.wav", "src_ref": "We use an unsupervised part of speech tagging algorithm.", "tgt_ref": "Nous utilisons une partie non supervisée d’algorithme de classification de discours.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_audio": "/acl6060/audio/dev/144.wav", "src_ref": "A first order factored model is used to account for morphology probability, basically the probability that is assigned by the morphological analyzer.", "tgt_ref": "Un modèle factorisé de premier ordre est utilisé pour rendre compte de la probabilité morphologique, essentiellement la probabilité attribuée par l’analyseur morphologique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_audio": "/acl6060/audio/dev/145.wav", "src_ref": "We also take into consideration the part of speech tag precedence as well as the syntactic agreements that are present in the in the input words.", "tgt_ref": "Nous prenons également en considération la priorité de l’étiquette de la partie de discours ainsi que les accords syntaxiques qui sont présents dans les mots de saisie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_audio": "/acl6060/audio/dev/146.wav", "src_ref": "The part of speech tagger uses a bidi bidirectional inference which improves upon the more often used Viterbi algorithm for decoding.", "tgt_ref": "Le marqueur de partie de discours utilise une inférence bidirectionnelle bidi qui améliore le plus souvent l’algorithme Viterbi utilisé pour le décodage.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_audio": "/acl6060/audio/dev/147.wav", "src_ref": "A few remarks here for positional encoding.", "tgt_ref": "Quelques remarques ici pour l'encodage positionnel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_audio": "/acl6060/audio/dev/148.wav", "src_ref": "One, the morphology encoder does not use any positional encoding.", "tgt_ref": "Premièrement, l’encodeur morphologique n’utilise aucun encodage positionnel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_audio": "/acl6060/audio/dev/149.wav", "src_ref": "This is because each of the morphemes occupies a known slot in the morphological model.", "tgt_ref": "C’est parce que chacun des morphèmes occupe un emplacement connu dans le modèle morphologique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_audio": "/acl6060/audio/dev/150.wav", "src_ref": "Therefore, positional information is inherent when the morphemes are given.", "tgt_ref": "Par conséquent, l’information positionnelle est inhérente lorsque les morphèmes sont donnés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_audio": "/acl6060/audio/dev/151.wav", "src_ref": "Second, the sentence encoder uses the so-called untied relative positional embeddings, which have been recently published at ICLR conference.", "tgt_ref": "Deuxièmement, l’encodeur de phrase utilise les intégrations positionnelles relatives dites non liées, qui ont été récemment publiées lors de la conférence ICLR.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_audio": "/acl6060/audio/dev/152.wav", "src_ref": "This positional embeddings essentially disentangles positional correlations from token to token attention computation.", "tgt_ref": "Ces intégrations positionnelles démêlent essentiellement les corrélations positionnelles de calcul d’attention gage à gage.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_audio": "/acl6060/audio/dev/153.wav", "src_ref": "Similar to BERT, we use a masked language model pre-training objective.", "tgt_ref": "De manière similaire aux Représentations d'encodeurs bidirectionnels à partir de transformateurs, nous utilisons un objectif de préformation de modèle de langue masqué.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_audio": "/acl6060/audio/dev/154.wav", "src_ref": "Essentially we have to predict both the stem and the affixes that are associated with the words.", "tgt_ref": "Essentiellement, nous devons prévenir à la fois le radical et les affixes qui sont associés aux mots.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_audio": "/acl6060/audio/dev/155.wav", "src_ref": "During pre-training, fifteen percent of all words are considered for prediction, of which eighty percent are masked, ten percent are swapped with random words, and ten percent are left unchanged.", "tgt_ref": "Pendant la préformation, quinze pour cent de tous les mots sont considérés pour la prévention, dont quatre-vingt pour cent sont masqués, dix pour cent sont échangés avec des mots aléatoires et dix pour cent sont laissés inchangés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_audio": "/acl6060/audio/dev/156.wav", "src_ref": "For affix prediction, we face some multi label classification problem.", "tgt_ref": "Pour la prévention d’affixe, nous faisons face à un problème de classification multi-étiquettes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_audio": "/acl6060/audio/dev/157.wav", "src_ref": "For this, we either group together affixes into a fixed number of sets and predict the set as a class label.", "tgt_ref": "Pour cela, nous regroupons les affixes ensemble dans un nombre fixe d’ensembles et prévenons l’ensemble comme une étiquette de classe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_audio": "/acl6060/audio/dev/158.wav", "src_ref": "The other option is to predict the affix probability vector.", "tgt_ref": "Ou bien, l’autre option est de prévenir le vecteur de probabilité d’affixe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_audio": "/acl6060/audio/dev/159.wav", "src_ref": "We evaluate both of these approaches in our experiments.", "tgt_ref": "Nous évaluons ces deux approches dans nos expériences.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_audio": "/acl6060/audio/dev/160.wav", "src_ref": "We pre-train KinyaBERT on about two and half gigabytes of Kinyarwanda text, and compare it to three baseline models.", "tgt_ref": "Nous préformons KinyaBERT sur environ deux giga-octets et demi de texte kinyarwanda, et le comparons à trois modèles de base.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_audio": "/acl6060/audio/dev/161.wav", "src_ref": "One is a multilingual model called XLM-R, that is trained on a large text corpora that is made of multiple languages.", "tgt_ref": "L’un est un modèle multilingue appelé XLM-R, qui est formé sur un grand corpus de texte composé de plusieurs langues.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_audio": "/acl6060/audio/dev/162.wav", "src_ref": "The other two baselines are pretrained on the same Kinyarwanda text using either the byte pair encoding algorithm or using morphological analysis without using the two tier transformer encoder architecture.", "tgt_ref": "Les deux autres bases sont préformées sur le même texte kinyarwanda en utilisant soit l’algorithme de byte pair encoding, soit l’analyse morphologique sans utiliser l’architecture encodeur de conversion à deux niveaux.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_audio": "/acl6060/audio/dev/163.wav", "src_ref": "All models are configured in the base architecture, which is about between a hundred and a hundred and ten million parameters, with Kinyarwanda with KinyaBERT using the least number of parameters.", "tgt_ref": "Tous les modèles sont configurés dans l’architecture de base, qui est d’environ cent à cent et dix millions de paramètres, avec le kinyarwanda avec KinyaBERT utilisant le plus petit nombre de paramètres.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_audio": "/acl6060/audio/dev/164.wav", "src_ref": "All models except the multilingual are pretrained for thirty two thousand gradient updates with a batch size of two thousand five hundred and sixty sequences in each batch.", "tgt_ref": "Tous les modèles sauf les multilingues sont préformés pour trente-deux mille mises à jour de pentes avec une taille de lot de deux mille cinq cent soixante séquences dans chaque lot.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_audio": "/acl6060/audio/dev/165.wav", "src_ref": "We evaluate the pretrained models on three sets of tasks.", "tgt_ref": "Nous évaluons les modèles préformés sur trois ensembles de tâches.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_audio": "/acl6060/audio/dev/166.wav", "src_ref": "One is the GLUE benchmark which has often been used for evaluating the effectiveness of pretrained language models.", "tgt_ref": "L’une est la référence GLUE qui a souvent été utilisée pour évaluer l’efficacité des modèles de langue préformée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_audio": "/acl6060/audio/dev/167.wav", "src_ref": "We obtain our GLUE benchmark data by translating the original benchmark data into Kinyarwanda using Google Translate.", "tgt_ref": "Nous obtenons nos données de référence GLUE en traduisant les données de référence originales en kinyarwanda à l’aide de Google Translate.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_audio": "/acl6060/audio/dev/168.wav", "src_ref": "The second task is Kinyarwanda named entity recognition benchmark, which is a high quality dataset that was annotated by trained native speakers.", "tgt_ref": "La deuxième tâche est la référence de reconnaissance d'entité nommée kinyarwanda, qui est un ensemble de données de haute qualité ayant été annoté par des locuteurs natifs formés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_audio": "/acl6060/audio/dev/169.wav", "src_ref": "The third one is a news categorization task where we pull news articles from several websites and collecting their categorization tags that were assigned by the authors and then essentially trying to predict the same, the the same categories.", "tgt_ref": "La troisième est une tâche de catégorisation des actualités où nous extrayons des articles de actualités de plusieurs sites web et collectons leurs étiquettes de catégorisation qui ont été attribuées par les auteurs, puis essayons essentiellement de prévenir ces dernières, les mêmes catégories.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_audio": "/acl6060/audio/dev/170.wav", "src_ref": "And now we go to the results.", "tgt_ref": "Et maintenant, passons aux résultats.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_audio": "/acl6060/audio/dev/171.wav", "src_ref": "For the GLUE benchmark, we find that KinyaBERT consistently outperforms baseline models.", "tgt_ref": "Pour la référence GLUE, nous constatons que KinyaBERT dépasse systématiquement les modèles de référence.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_audio": "/acl6060/audio/dev/172.wav", "src_ref": "Here we show the average performance for ten finetuning runs.", "tgt_ref": "Ici, nous montrons la performance moyenne pour dix cycles de raffinement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_audio": "/acl6060/audio/dev/173.wav", "src_ref": "We also run a user evaluation of the translations that are produced by Google Translate.", "tgt_ref": "Nous effectuons également une évaluation des traductions produites par Google Translate.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_audio": "/acl6060/audio/dev/174.wav", "src_ref": "Essentially, user users rated about six thousand examples, assigning scores on a scale from one to four, assessing the quality of the translations.", "tgt_ref": "Essentiellement, les utilisateurs ont évalué environ six mille exemples, en attribuant des scores sur une échelle de un à quatre et en évaluant la qualité des traductions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_audio": "/acl6060/audio/dev/175.wav", "src_ref": "The result is that many translations were noisy.", "tgt_ref": "Le résultat est que beaucoup de traductions étaient bruyantes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_audio": "/acl6060/audio/dev/176.wav", "src_ref": "But, all models had to cope with the same translation noise, and the relative performance between the models is still important to notice.", "tgt_ref": "Mais tous les modèles ont dû faire face au même bruit de traduction, et la performance relative entre les modèles est toujours importante à remarquer.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_audio": "/acl6060/audio/dev/177.wav", "src_ref": "For the named entity recognition task, we also find that KinyaBERT gives the best performance with the affix distribution regression variant performing best.", "tgt_ref": "Pour la tâche de reconnaissance d'entité nommée, nous constatons également que KinyaBERT fournit les meilleures performances avec la variante de régression de distribution d’affixes fonctionnant le mieux.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_audio": "/acl6060/audio/dev/178.wav", "src_ref": "These results are also averages of ten finetuning runs.", "tgt_ref": "Ces résultats sont également des moyennes de dix cycles de raffinement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_audio": "/acl6060/audio/dev/179.wav", "src_ref": "For the news categorization task, we find mixed results.", "tgt_ref": "Pour la tâche de catégorisation des actualités, nous trouvons des résultats mitigés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_audio": "/acl6060/audio/dev/180.wav", "src_ref": "Previous work on text classification for Kinyarwanda had found that simple keyword detection is mostly enough for solving this specific task.", "tgt_ref": "Le travail antérieur sur la classification de texte pour le kinyarwanda avait trouvé que la détection de mot-clé simple est surtout suffisante pour résoudre cette tâche spécifique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_audio": "/acl6060/audio/dev/181.wav", "src_ref": "Therefore, there is less gain from using pretrained language models.", "tgt_ref": "Par conséquent, il y a moins d'avantage à utiliser des modèles de langue préformée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_audio": "/acl6060/audio/dev/182.wav", "src_ref": "On this particular task of news categorization.", "tgt_ref": "Sur cette tâche particulière de catégorisation des actualités.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_audio": "/acl6060/audio/dev/183.wav", "src_ref": "We also conducted an ablation study to see if there are alternative structures that improve performance.", "tgt_ref": "Nous avons également mené une étude d’ablation pour voir s’il existe des structures alternatives qui améliorent les performances.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_audio": "/acl6060/audio/dev/184.wav", "src_ref": "For the GLUE benchmark, we find that using affix sets consistently performs better, while affix probability regression objective yields the best performance on named entity recognition.", "tgt_ref": "Pour la référence GLUE, nous constatons que l’utilisation d’ensembles d’affixes donne constamment de meilleurs résultats, tandis que l’objectif de régression de probabilité d’affixe fournit les meilleures performances sur la reconnaissance d'entité nommée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_audio": "/acl6060/audio/dev/185.wav", "src_ref": "Also by looking at the low scores for finetuning, we find that KinyaBERT has better convergence in most cases.", "tgt_ref": "De plus, en examinant les faibles scores pour le raffinement, nous constatons que KinyaBERT a une meilleure convergence dans la plupart des cas.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_audio": "/acl6060/audio/dev/186.wav", "src_ref": "So to conclude, this work has demonstrated the effectiveness of explicitly using morphological information in pretrained language models.", "tgt_ref": "Donc, pour conclure, ce travail a démontré l’efficacité de l’utilisation explicite des informations morphologiques dans les modèles de langue préformée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_audio": "/acl6060/audio/dev/187.wav", "src_ref": "The proposed two tier transformer encoder architecture enables capturing morphological complexity morphological compositionality, which is an important aspect of morphologically rich languages.", "tgt_ref": "L’architecture à deux niveaux proposée permet de capturer la compositionnalité morphologique de la complexité morphologique, qui est un aspect important des langues morphologiquement riches.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_audio": "/acl6060/audio/dev/188.wav", "src_ref": "These findings should motivate further research into morphology aware language pretrained language models.", "tgt_ref": "Ces résultats devraient motiver davantage les recherches sur les modèles de langue préformée conscients de la morphologie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_audio": "/acl6060/audio/dev/189.wav", "src_ref": "Hello, my name is Michał Pietruszka and it is my pleasure to present to you the paper titled Sparsifying Transformer Models with Trainable Representation Pooling.", "tgt_ref": "Bonjour, je m’appelle Michal Pietruszka et j’ai le plaisir de vous présenter l’article intitulé Modèles de conversion parcimonieux avec la mise en commun de la représentation adaptative.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_audio": "/acl6060/audio/dev/190.wav", "src_ref": "A work done at Applica AI in cooperation with Lukasz Borchmann and Lukasz Garncarek.", "tgt_ref": "Un travail réalisé à Applica intelligence artificielle en coopération avec Lukasz Borchmann et Lukasz Garncarek.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_audio": "/acl6060/audio/dev/191.wav", "src_ref": "Let me start with the problems our work targets.", "tgt_ref": "Permettez-moi de commencer par les problèmes que nous visons dans le cadre de notre travail.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_audio": "/acl6060/audio/dev/192.wav", "src_ref": "Our method works well for the cases where long inputs are considered.", "tgt_ref": "Notre méthode fonctionne bien pour les cas où de longues saisies sont considérées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_audio": "/acl6060/audio/dev/193.wav", "src_ref": "Roughly speaking, it is meant for the task orders and input of over two thousand tokens and the targets are shorter than the provided inputs.", "tgt_ref": "En gros, c’est pour les ordres de tâche et de saisie de plus de deux mille gages, et les cibles sont plus courtes que les saisies fournies.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_audio": "/acl6060/audio/dev/194.wav", "src_ref": "This has some specific applications in NLP.", "tgt_ref": "Cela a des applications spécifiques en TAL traitement automatique du langage naturel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_audio": "/acl6060/audio/dev/195.wav", "src_ref": "For example, one can imagine that given a long document, there's a need to summarize it, classify, answer the question about it, extract information or some key phrases.", "tgt_ref": "Par exemple, on peut imaginer qu’étant donné qu’un document est long, il est nécessaire de le résumer, de classer, de répondre à la question à ce sujet et d’extraire des informations ou certaines expressions clés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_audio": "/acl6060/audio/dev/196.wav", "src_ref": "Let me recall the vanilla transformer and our and its issue of its attention complexity that depends on the square of the input line.", "tgt_ref": "Permettez-moi de rappeler la conversion vanille et sa question de sa complexité d’attention qui dépend du carré de la ligne de saisie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_audio": "/acl6060/audio/dev/197.wav", "src_ref": "In the vanilla transformer, with full attention connectivity, relations of each token to every other token have to be calculated.", "tgt_ref": "Dans la conversion vanille, avec une connectivité de pleine attention, les relations de chaque gage à chaque autre gage doivent être calculées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_audio": "/acl6060/audio/dev/198.wav", "src_ref": "The computational complexity of attention, this depends on the number of layers l, sequence length n, another sequence length, and the dimensionality of representations.", "tgt_ref": "La complexité informatique de l’attention, qui dépend du nombre de couches l, de la longueur de séquence n, d’une autre longueur de séquence et de la dimensionnalité des représentations.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_audio": "/acl6060/audio/dev/199.wav", "src_ref": "Similarly, in the decoder's cross attention, to this picture on the right side, the only difference here is that the target tokens are attending to the input tokens in this case.", "tgt_ref": "De même, dans l’attention croisée du décodeur, à cette image sur le côté droit, la seule différence ici est que les gages cibles sont attentifs aux gages de saisie dans ce cas.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_audio": "/acl6060/audio/dev/200.wav", "src_ref": "Which can be seen also in this formula.", "tgt_ref": "Ce que l’on retrouve également dans cette formule.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_audio": "/acl6060/audio/dev/201.wav", "src_ref": "The BLEU score represents relations that have to be calculated.", "tgt_ref": "Le score BLEU représente les relations qui doivent être calculées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_audio": "/acl6060/audio/dev/202.wav", "src_ref": "In case of the full attention, we need to calculate every relations within the input sequence.", "tgt_ref": "Dans le cas de la pleine attention, nous devons calculer toutes les relations dans la séquence de saisie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_audio": "/acl6060/audio/dev/203.wav", "src_ref": "Now, we see what happens when we have a blockwise encoder that works by limiting the tokens connectivity so that they can only see other nearby tokens.", "tgt_ref": "Maintenant, nous voyons ce qui se passe lorsque nous avons un encodeur par bloc qui fonctionne en limitant la connectivité des gages afin qu’ils ne puissent voir que les autres gages à proximité.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_audio": "/acl6060/audio/dev/204.wav", "src_ref": "The text is read in chunks which can drastically reduce the number of computations on the encoder side, but does not improve the decoder's cross attention as every input token is passed to the decoder anyway.", "tgt_ref": "Le texte est lu en morceaux, ce qui peut réduire considérablement le nombre de calculs du côté de l’encodeur, mais n’améliore pas l’attention croisée du décodeur car chaque gage de saisie est de toute façon transmis au décodeur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_audio": "/acl6060/audio/dev/205.wav", "src_ref": "This method is often referred to as fusion in decoder.", "tgt_ref": "Cette méthode est souvent appelée fusion dans le décodeur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_audio": "/acl6060/audio/dev/206.wav", "src_ref": "The improvement here can be interpreted as changing one of the dependencies of n to another constant m representing the block size.", "tgt_ref": "L’amélioration ici peut être interprétée comme changeant l’une des dépendances de n en une autre constante m représentant la taille du bloc.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_audio": "/acl6060/audio/dev/207.wav", "src_ref": "Our key observation is that most tokens are irrelevant for a wide variety of tasks and can be almost completely disregarded. This is exemplified on the slide.", "tgt_ref": "Notre observation clé est que la plupart des gages ne sont pas pertinents pour une grande variété de tâches et peuvent être presque complètement ignorés. Ceci est illustré sur la diapositive.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_audio": "/acl6060/audio/dev/208.wav", "src_ref": "The only parts of the inputs are relevant to the desired output.", "tgt_ref": "Les seules parties des saisies sont pertinentes pour la sortie souhaitée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_audio": "/acl6060/audio/dev/209.wav", "src_ref": "For example.", "tgt_ref": "Par exemple.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_audio": "/acl6060/audio/dev/210.wav", "src_ref": "One can read an article once marking the most important parts with a highlighter, and then produce a summary based on this part from the middle stage only.", "tgt_ref": "On peut lire un article une fois en marquant les parties les plus importantes avec un surligneur, puis produire un résumé basé sur cette partie à partir du stade intermédiaire seulement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_audio": "/acl6060/audio/dev/211.wav", "src_ref": "The cost of highlighting and deciding if the current token is essential to produce the summary is thus cheap and depends only on the token's representation.", "tgt_ref": "Le coût de la mise en surbrillance et de la décision de savoir si le gage actuel est essentiel pour produire le résumé est donc peu élevé et ne dépend que de la représentation du gage.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_audio": "/acl6060/audio/dev/212.wav", "src_ref": "The pooling of the highlighted tokens is possible.", "tgt_ref": "La mise en commun des gages en surbrillance est possible.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_audio": "/acl6060/audio/dev/213.wav", "src_ref": "Thanks to our top k operator and its cost is negligible.", "tgt_ref": "Grâce à notre meilleur opérateur k, son coût est négligeable.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_audio": "/acl6060/audio/dev/214.wav", "src_ref": "The cost of producing a summary from a shortened input is also much lower than in the vanilla model when the whole input is considered.", "tgt_ref": "Le coût de production d’un résumé à partir d’une saisie raccourcie est également beaucoup plus faible que dans le modèle vanille lorsque la saisie complète est prise en compte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_audio": "/acl6060/audio/dev/215.wav", "src_ref": "But here's a question.", "tgt_ref": "Mais une question se pose.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_audio": "/acl6060/audio/dev/216.wav", "src_ref": "How to select important tokens and backpropagate gradients to that selection?", "tgt_ref": "Comment sélectionner les gages importants et rétropropager les pentes vers cette sélection ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_audio": "/acl6060/audio/dev/217.wav", "src_ref": "The essential underlying problem that we solve is to propose the trainable selection mechanism.", "tgt_ref": "Le problème sous-jacent essentiel que nous résolvons est de proposer le mécanisme de sélection adaptatif.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_audio": "/acl6060/audio/dev/218.wav", "src_ref": "One that can allow for gradient to be back propagated during the training so that the network can learn to select the most important tokens.", "tgt_ref": "Celui qui peut permettre à la pente de se rétropropager pendant la formation afin que le réseau puisse apprendre à sélectionner les gages les plus importants.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_audio": "/acl6060/audio/dev/219.wav", "src_ref": "More precisely", "tgt_ref": "Plus précisément", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_audio": "/acl6060/audio/dev/220.wav", "src_ref": "Given some embeddings underscore obtained from a simple linear layer, the task is to return the highest scoring embeddings. First, the sequence is permuted and pairs are prepared so that the higher scoring vector is taken with the lower scoring one.", "tgt_ref": "Compte tenu de certains soulignements d’intégrations obtenus à partir d’une couche linéaire simple, la tâche est de renvoyer les intégrations au score le plus élevé. Tout d’abord, la séquence est permutée et les paires sont préparées de manière à ce que le vecteur de score le plus élevé soit pris avec le vecteur de score le plus faible.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_audio": "/acl6060/audio/dev/221.wav", "src_ref": "Next, weights are calculated using boosted softmax over scores.", "tgt_ref": "Ensuite, les poids sont calculés à l’aide de softmax boosté sur les scores.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_audio": "/acl6060/audio/dev/222.wav", "src_ref": "After each tournament round, new vectors and scores are composed as a linear combination of those pairs with the obtained weights.", "tgt_ref": "Après chaque tour de tournoi, de nouveaux vecteurs et scores sont composés comme une combinaison linéaire de ces paires avec les poids obtenus.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_audio": "/acl6060/audio/dev/223.wav", "src_ref": "So in short, we combine them linearly by performing a softmax over their scores.", "tgt_ref": "Donc, en bref, nous les combinons linéairement en effectuant un softmax sur leurs scores.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_audio": "/acl6060/audio/dev/224.wav", "src_ref": "And while combining two tokens, some noise can be produces produced.", "tgt_ref": "Et tout en combinant deux gages, un certain bruit peut être produit.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_audio": "/acl6060/audio/dev/225.wav", "src_ref": "But it also allows the gradients to be propagated to all input embeddings.", "tgt_ref": "Mais cela permet aussi de propager les pentes à toutes les intégrations de saisie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_audio": "/acl6060/audio/dev/226.wav", "src_ref": "In short, a trainable top k we propose is based on performing a tournament like soft selection at each step.", "tgt_ref": "En bref, un top k adaptatif que nous proposons est basé sur l’exécution d’un tournoi comme la sélection souple à chaque étape.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_audio": "/acl6060/audio/dev/227.wav", "src_ref": "And from a different perspective, the representation pooling follows the encoder layer.", "tgt_ref": "Et d’un point de vue différent, la mise en commun de la représentation suit la couche de l’encodeur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_audio": "/acl6060/audio/dev/228.wav", "src_ref": "First, each representation is scored and then only those with the highest scores are passed to the next layer.", "tgt_ref": "Tout d’abord, chaque représentation est notée, puis seules celles qui ont les scores les plus élevés sont passées à la couche suivante.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_audio": "/acl6060/audio/dev/229.wav", "src_ref": "Encoding can be performed as in standard transformer architecture on the full length input.", "tgt_ref": "L’encodage peut être effectué comme dans l’architecture de conversion standard sur la saisie pleine longueur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_audio": "/acl6060/audio/dev/230.wav", "src_ref": "It is however possible to process text in blocks of fixed length of fixed length and globally select the best representation.", "tgt_ref": "Il est cependant possible de traiter le texte par blocs de longueur fixe et de sélectionner globalement la meilleure représentation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_audio": "/acl6060/audio/dev/231.wav", "src_ref": "Here is an example of the representation pooling introduced after the encoder.", "tgt_ref": "Voici un exemple de la mise en commun de représentation introduite après l’encodeur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_audio": "/acl6060/audio/dev/232.wav", "src_ref": "This directly influenced the cause of cross attention, which depends not on the input length N, but the constant K, representing the pooled length.", "tgt_ref": "Cela a directement influencé la cause de l’attention croisée, qui ne dépend pas de la longueur de saisie N, mais de la constante K, représentant la longueur mise en commun.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_audio": "/acl6060/audio/dev/233.wav", "src_ref": "This constant informs how many representations are selected and passed to the decoder.", "tgt_ref": "Cette constante indique combien de représentations sont sélectionnées et transmises au décodeur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_audio": "/acl6060/audio/dev/234.wav", "src_ref": "Producing a summary from a shorter text is significantly cheaper than previous solution.", "tgt_ref": "Produire un résumé à partir d’un texte plus court est nettement moins cher que la solution antérieure.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_audio": "/acl6060/audio/dev/235.wav", "src_ref": "As the sequence length can be shortened by a large factor.", "tgt_ref": "Comme la longueur de séquence qui peut être raccourcie par un grand facteur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_audio": "/acl6060/audio/dev/236.wav", "src_ref": "For example, we successfully used k of sixteen or even sixty times four or even sixty four times smaller than the value of n in our experiments.", "tgt_ref": "Par exemple, nous avons utilisé avec succès le k seize ou même soixante-quatre fois plus petit que la valeur de n dans nos expériences.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_audio": "/acl6060/audio/dev/237.wav", "src_ref": "Please note that the beneficial impact of blockwise encoding and self attention is sustained.", "tgt_ref": "Veuillez noter que l’impact bénéfique de l’encodage par blocs et de l’attention personnelle est maintenu.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_audio": "/acl6060/audio/dev/238.wav", "src_ref": "Remember that the computational cost of attention depend on the square of the input length.", "tgt_ref": "Rappelez-vous que le coût informatique de l’attention dépend du carré de la longueur de saisie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_audio": "/acl6060/audio/dev/239.wav", "src_ref": "Reducing it the input earlier during the encoding process can significantly lower the costs.", "tgt_ref": "Réduire plus tôt la saisie pendant le processus d’encodage peut baisser considérablement les coûts.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_audio": "/acl6060/audio/dev/240.wav", "src_ref": "For the pyramidion model, we narrowed down the size of the representation on the output of each of each chosen layer, leading to the exponential reduction of computational cost as the encoding proceeds.", "tgt_ref": "Pour le modèle pyramidion, nous avons réduit la taille de la représentation sur la sortie de chaque couche choisie, conduisant à la réduction exponentielle du coût informatique au fur et à mesure que l’encodage progresse.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_audio": "/acl6060/audio/dev/241.wav", "src_ref": "As you can see, the total computational cost of a full encoder here is less than two times the cost of the full-sized first layer.", "tgt_ref": "Comme vous pouvez le voir, le coût informatique total d’un encodeur complet est ici moins de deux fois le coût de la première couche pleine grandeur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_audio": "/acl6060/audio/dev/242.wav", "src_ref": "When pooling is introduced earlier, the sum of all purple squares is thus bounded to a constant, not dependent on the number of layers l.", "tgt_ref": "Lorsque la mise en commun est introduite plus tôt, la somme de tous les carrés violets est donc liée à une constante, qui ne dépend pas du nombre de couches l.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_audio": "/acl6060/audio/dev/243.wav", "src_ref": "But on the constant c, which can be influenced by the placing of the pooling layers within the network.", "tgt_ref": "Mais sur la constante c, qui peut être influencée par le placement des couches de mise en commun au sein du réseau.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_audio": "/acl6060/audio/dev/244.wav", "src_ref": "Our improvements were benchmarked on eight thousand tokens long inputs.", "tgt_ref": "Nos améliorations ont été évaluées sur la base de huit mille longues saisies de gages.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_audio": "/acl6060/audio/dev/245.wav", "src_ref": "And the figure shows that when pooling is engaged, the best scalability for the network's depth is achieved.", "tgt_ref": "Et la figure montre que lorsque la mise en commun est engagée, la meilleure évolutivité pour la profondeur du réseau est atteinte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_audio": "/acl6060/audio/dev/246.wav", "src_ref": "Here one can note that training the pyramidion of twenty four layers can be cheaper than training a two layer vanilla transformer on such long inputs.", "tgt_ref": "Ici, on peut noter que la formation du pyramidion de vingt-quatre couches peut être moins chère que la formation d’une conversion vanille à deux couches sur des saisies aussi longues.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_audio": "/acl6060/audio/dev/247.wav", "src_ref": "Not to mention how easily vanilla transformer can go out of memory for such a long input.", "tgt_ref": "Sans parler de la facilité avec laquelle la conversion vanille peut perdre la mémoire pour une si longue saisie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_audio": "/acl6060/audio/dev/248.wav", "src_ref": "The qual quality qual qualitative comparison of our trend pyramidion to other baseline is performed on the long document summarization task, or given the body of an article from arXiv or PubMed, the task is to generate its abstract.", "tgt_ref": "La comparaison qual qualité qual qualitative de notre pyramidion tendance à d’autres bases est effectuée sur la longue tâche de synthèse de document, ou compte tenu du corps d’un article d’arXiv ou PubMed, la tâche est de générer son résumé.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_audio": "/acl6060/audio/dev/249.wav", "src_ref": "Thus, one can see blockwise, which is our baseline, performs on the level of the re, recent state-of-the-art models, while the pyramidion retains or improves the performance of this competitive baseline.", "tgt_ref": "Ainsi, on peut voir bloc par bloc, qui est notre base, ce qui est effectué au niveau du re, les modèles ultra-modernes récents, tandis que le pyramidion conserve ou améliore la performance de cette base compétitive.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_audio": "/acl6060/audio/dev/250.wav", "src_ref": "At the same time, our model is eighty percent faster to train and over four hundred fifty percent faster at inference when compared to the blockwise baseline.", "tgt_ref": "En même temps, notre modèle est quatre-vingts pour cent plus rapide à former et plus de quatre cent cinquante pour cent plus rapide à l’inférence quand il est comparé à la base par bloc.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_audio": "/acl6060/audio/dev/251.wav", "src_ref": "Both models have much lower parameter counts and were trained from scratch on the chosen tasks.", "tgt_ref": "Les deux modèles ont un nombre de paramètres beaucoup plus faible et ont été formés à partir de zéro sur les tâches choisies.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_audio": "/acl6060/audio/dev/252.wav", "src_ref": "Previous approaches to to achieve a similar performance had to use more parameters and leverage pretrained foundation foundational models and additional language pretraining objective to achieve similar performance.", "tgt_ref": "Les approches antérieures visant à atteindre un rendement similaire devaient utiliser plus de paramètres et tirer parti des modèles fondamentaux de base préformés, ainsi que de l’objectif de préformation en langue supplémentaire pour atteindre un rendement similaire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_audio": "/acl6060/audio/dev/253.wav", "src_ref": "We invite you to read our full paper and use our GitHub code.", "tgt_ref": "Nous vous invitons à lire notre article complet et à utiliser notre code GitHub.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_audio": "/acl6060/audio/dev/254.wav", "src_ref": "Thank you for watching.", "tgt_ref": "Merci d’avoir regardé cette vidéo.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_audio": "/acl6060/audio/dev/255.wav", "src_ref": "Hello, this is Jiawei Zhou from Harvard University.", "tgt_ref": "Bonjour, je m’appelle Jiawei Zhou de l’Université d’Harvard.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_audio": "/acl6060/audio/dev/256.wav", "src_ref": "I am very glad to present our work on Online Semantic Parsing for Latency Reduction in Task-Oriented Dialogue.", "tgt_ref": "Je suis très heureux de présenter notre travail sur l’analyse syntaxique et sémantique en ligne pour la réduction de la latence dans le dialogue orienté sur la tâche.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_audio": "/acl6060/audio/dev/257.wav", "src_ref": "This is joint work with Jason, Michael, Anthony and Sam from Microsoft Semantic Machines.", "tgt_ref": "Il s’agit d’un travail commun avec Jason, Michael, Anthony et Sam de Semantic Machines par Microsoft.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_audio": "/acl6060/audio/dev/258.wav", "src_ref": "In task-oriented dialogue, a user interacts with the system that handles requests from user utterances usually in speaking.", "tgt_ref": "Dans le dialogue orienté sur la tâche, un utilisateur interagit avec le système qui traite les discours de l’utilisateur énoncés généralement en parlant.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_audio": "/acl6060/audio/dev/259.wav", "src_ref": "From the finish of the user utterance to the system response there is often a noticeable delay.", "tgt_ref": "De la fin du discours de l’utilisateur à la réponse du système, il y a souvent un retard notable.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_audio": "/acl6060/audio/dev/260.wav", "src_ref": "Under the hood, the user utterance is translated into an executable program.", "tgt_ref": "Sous le capot, le discours de l’utilisateur est traduit en un programme exécutable.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_audio": "/acl6060/audio/dev/261.wav", "src_ref": "Which is then executed so that the system can respond properly.", "tgt_ref": "Celui-ci est ensuite exécuté afin que le système puisse répondre correctement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_audio": "/acl6060/audio/dev/262.wav", "src_ref": "Because the program is represented as a semantic graph that outlines the computation, where node represents a function invocation and its children are the arguments.", "tgt_ref": "Parce que le programme est représenté comme un graphique sémantique qui décrit le calcul, où le nodule représente une invocation de fonction et ses enfants sont les arguments.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_audio": "/acl6060/audio/dev/263.wav", "src_ref": "The great nodes mark instantaneous operations, but the others are slow to execute.", "tgt_ref": "Les grands nodules marquent des opérations instantanées, mais les autres mettent du temps à s’exécuter.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_audio": "/acl6060/audio/dev/264.wav", "src_ref": "The simple example here we show, these programs can often be more complicated graphs beyond the tree structures.", "tgt_ref": "Dans l’exemple simple que nous montrons ici, ces programmes peuvent souvent être des graphiques plus compliqués au-delà des structures arborescentes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_audio": "/acl6060/audio/dev/265.wav", "src_ref": "In this talk, we ask the question, can we start generating the program and executing it before the user even finishes the utterance so that the faster response can be achieved by the system?", "tgt_ref": "Dans cette conférence, nous posons la question : pouvons-nous commencer à générer le programme et à l’exécuter avant même que l’utilisateur ait terminé le discours, afin que le système puisse obtenir une réponse plus rapide ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_audio": "/acl6060/audio/dev/266.wav", "src_ref": "This is the online prediction and decision problem.", "tgt_ref": "C’est la prévention en ligne et le problème de décision.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_audio": "/acl6060/audio/dev/267.wav", "src_ref": "There are a lot of others in this realm.", "tgt_ref": "Il y en a beaucoup d’autres dans ce domaine.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_audio": "/acl6060/audio/dev/268.wav", "src_ref": "Examples include simultaneous translation where a live interpreter translates one language to another in real time, smart text auto completion to guess the user intent, and Uber pool where the drivers are sent to where they might be needed based on the predicted demand.", "tgt_ref": "Les exemples incluent la traduction simultanée où un interprète en direct traduit une langue en une autre en temps réel, la saisie automatique intelligente du texte pour deviner l’intention de l’utilisateur, et Uber pool où les chauffeurs sont envoyés là où ils pourraient être nécessaires en fonction de la demande prévue.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_audio": "/acl6060/audio/dev/269.wav", "src_ref": "All of these scenarios have one thing in common.", "tgt_ref": "Tous ces scénarios ont une chose en commun.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_audio": "/acl6060/audio/dev/270.wav", "src_ref": "That is, it is beneficial to make decisions before seeing all the input.", "tgt_ref": "C’est-à-dire qu’il est bénéfique de prendre des décisions avant de voir toutes les saisies.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_audio": "/acl6060/audio/dev/271.wav", "src_ref": "In our case, we are going to deal with online semantic parsing, which could be expected to be challenging as we have to guess what the user might say.", "tgt_ref": "Dans notre cas, nous allons traiter de l’analyse syntaxique et sémantique en ligne, ce qui pourrait être difficile car nous devons deviner ce que l’utilisateur pourrait dire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_audio": "/acl6060/audio/dev/272.wav", "src_ref": "And it is also underexplored with no formal evaluation metric.", "tgt_ref": "Et cela est également sous-exploré sans indicateur d’évaluation formel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_audio": "/acl6060/audio/dev/273.wav", "src_ref": "First, let's look at how an ordinary system works.", "tgt_ref": "Tout d’abord, regardons comment fonctionne un système ordinaire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_audio": "/acl6060/audio/dev/274.wav", "src_ref": "It is operating offline by parsing to the program only at the end of the user utterance.", "tgt_ref": "Il fonctionne hors ligne par l'analyse syntaxique du programme uniquement à la fin du discours de l’utilisateur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_audio": "/acl6060/audio/dev/275.wav", "src_ref": "Here, the character graph is predicted after seeing all the information.", "tgt_ref": "Ici, le graphique de caractères est prévenu après avoir vu toutes les informations.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_audio": "/acl6060/audio/dev/276.wav", "src_ref": "In contrast, we are proposing an online system that compares at every utterance prefix.", "tgt_ref": "En revanche, nous proposons un système en ligne qui compare à chaque préfixe de discours.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_audio": "/acl6060/audio/dev/277.wav", "src_ref": "For example, each time we see a new token, we predict a new graph.", "tgt_ref": "Par exemple, chaque fois que nous voyons un nouveau gage, nous prévenons un nouveau graphique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_audio": "/acl6060/audio/dev/278.wav", "src_ref": "Notice that there could be errors.", "tgt_ref": "Notez qu’il peut y avoir des erreurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_audio": "/acl6060/audio/dev/279.wav", "src_ref": "At the position of at the pool party with Barack Obama, we got a graph with the right nodes on the person and the event subject, but guess the wrong timing information.", "tgt_ref": "À l’emplacement de la pool party avec Barack Obama, nous avons obtenu un graphique avec les bons nodules sur la personne et le sujet d’activité, mais deviné les mauvaises informations de timing.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_audio": "/acl6060/audio/dev/280.wav", "src_ref": "This process goes on until we receive the full user utterance.", "tgt_ref": "Ce processus se poursuit jusqu’à ce que nous recevions le discours complet de l’utilisateur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_audio": "/acl6060/audio/dev/281.wav", "src_ref": "How would this affect the execution timeline in the offline system?", "tgt_ref": "Comment cela affecterait-il la chronologie d’exécution dans le système hors ligne ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_audio": "/acl6060/audio/dev/282.wav", "src_ref": "We'll get the program graph at the end so that the system can start execution at this point.", "tgt_ref": "Nous obtiendrons le graphique de programme à la fin afin que le système puisse commencer l’exécution à ce stade.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_audio": "/acl6060/audio/dev/283.wav", "src_ref": "Remember that the great nodes are fast operations, so we only consider the execution timeline of the colored slow functions.", "tgt_ref": "Rappelez-vous que les grands nodules sont des opérations rapides ; nous ne considérons donc que la chronologie d’exécution des fonctions lentes colorées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_audio": "/acl6060/audio/dev/284.wav", "src_ref": "First, these two find person functions can be executed in parallel, highlighted in white from the pink box as they have no dependency on other functions.", "tgt_ref": "Premièrement, ces deux fonctions Trouver une personne peuvent être exécutées en parallèle, surlignées en blanc à partir de la case rose car elles n’ont pas de dépendance à d’autres fonctions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_audio": "/acl6060/audio/dev/285.wav", "src_ref": "Next, the node create event can then get executed after obtaining results from lower level nodes and then the top function yield so the whole program is finished.", "tgt_ref": "Ensuite, l’activité de création de nodules peut ensuite être exécutée après avoir obtenu des résultats à partir de nodules de niveau inférieur, puis la fonction supérieure mène à l’achèvement de l’ensemble du programme.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_audio": "/acl6060/audio/dev/286.wav", "src_ref": "The execution process is strict, restricted to the program dependency structure where some operations cannot be parallelized which induces a noticeable delay.", "tgt_ref": "Le processus d’exécution est strict, limité à la structure de dépendance du programme où certaines opérations ne peuvent pas être parallélisées, ce qui induit un retard notable.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_audio": "/acl6060/audio/dev/287.wav", "src_ref": "In our online system, where we predict as we go, the program execution can start earlier.", "tgt_ref": "Dans notre système en ligne, où nous prévenons au fur et à mesure, l’exécution du programme peut commencer plus tôt.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_audio": "/acl6060/audio/dev/288.wav", "src_ref": "Here, at the prefix after Obama we predict confidently that the find person function should be in the program, but the rest may contain errors as they are grayed out.", "tgt_ref": "Ici, au préfixe après Obama, nous prévenons en toute confiance que la fonction Trouver une personne devrait être dans le programme, mais le reste peut contenir des erreurs car elles sont grisées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_audio": "/acl6060/audio/dev/289.wav", "src_ref": "The execution of the node can be immediately started as a step.", "tgt_ref": "L’exécution du nodule peut être immédiatement commencée comme une étape.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_audio": "/acl6060/audio/dev/290.wav", "src_ref": "Then, with more tokens, we predict a totally new graph, but part of it has already being executed.", "tgt_ref": "Ensuite, avec plus de gages, nous prévenons un graphique totalement nouveau, mais une partie est déjà en cours d’exécution.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_audio": "/acl6060/audio/dev/291.wav", "src_ref": "So, we only need to consider the rest of the nodes that we are confident about as well.", "tgt_ref": "Donc, nous n’avons qu’à considérer le reste des nodules sur lesquels nous sommes confiants.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_audio": "/acl6060/audio/dev/292.wav", "src_ref": "Here, another find person can be executed in parallel.", "tgt_ref": "Ici, une autre fonction Trouver une personne peut être exécutée en parallèle.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_audio": "/acl6060/audio/dev/293.wav", "src_ref": "Again, we may have wrong predictions.", "tgt_ref": "Encore une fois, nous pouvons avoir des préventions erronées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_audio": "/acl6060/audio/dev/294.wav", "src_ref": "With more text, we have more ability to make it right.", "tgt_ref": "Avec plus de texte, nous avons plus de capacité à faire les choses correctement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_audio": "/acl6060/audio/dev/295.wav", "src_ref": "Such as the event time here where AM is also anticipated correctly.", "tgt_ref": "Comme l’heure de l’activité ici où AM est également anticipé correctement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_audio": "/acl6060/audio/dev/296.wav", "src_ref": "Then, we can start executing the rest following the program dependency structure.", "tgt_ref": "Ensuite, nous pouvons commencer à exécuter le reste en suivant la structure de dépendance du programme.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_audio": "/acl6060/audio/dev/297.wav", "src_ref": "By overlapping the execution timeline with the utterance timeline, we save a big amount of time.", "tgt_ref": "En chevauchant la chronologie d’exécution avec la chronologie du discours, nous gagnons beaucoup de temps.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_audio": "/acl6060/audio/dev/298.wav", "src_ref": "So we proposed the task of online semantic parsing.", "tgt_ref": "Nous avons donc proposé la tâche d’analyse syntaxique et sémantique en ligne.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_audio": "/acl6060/audio/dev/299.wav", "src_ref": "One underlying assumption is that the execution time dominates the model prediction time.", "tgt_ref": "Une hypothèse sous-jacente est que le temps d’exécution domine le temps de prévention du modèle.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_audio": "/acl6060/audio/dev/300.wav", "src_ref": "So we could only gain time by predicting earlier.", "tgt_ref": "Donc, nous ne pouvions gagner du temps qu’en prévenant plus tôt.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_audio": "/acl6060/audio/dev/301.wav", "src_ref": "Another assumption is that as the prediction and execution happen in the background, that it is not visible to users.", "tgt_ref": "Une autre hypothèse est que, comme la prévention et l’exécution se produisent en arrière-plan, cela n’est pas visible par les utilisateurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_audio": "/acl6060/audio/dev/302.wav", "src_ref": "It is not necessary to maintain a consistent parsing history.", "tgt_ref": "Il n’est pas nécessaire de maintenir un historique d’analyse syntaxique cohérent.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_audio": "/acl6060/audio/dev/303.wav", "src_ref": "So, we reparse from scratch after each token.", "tgt_ref": "Donc, nous réanalysons à partir de zéro après chaque gage.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_audio": "/acl6060/audio/dev/304.wav", "src_ref": "In particular, we propose a two step approach.", "tgt_ref": "En particulier, nous proposons une approche en deux étapes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_audio": "/acl6060/audio/dev/305.wav", "src_ref": "A proposed step that predicts a graph with complete structure and a select step that selects the nodes that are worth executing at this time.", "tgt_ref": "Une étape proposée qui prévient un graphique avec une structure complète et une étape de sélection qui sélectionne les nodules valant la peine d’être exécutés pour le moment.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_audio": "/acl6060/audio/dev/306.wav", "src_ref": "We had two variants of the proposed method.", "tgt_ref": "Nous avions deux variantes de la méthode proposée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_audio": "/acl6060/audio/dev/307.wav", "src_ref": "First approach combines a language model completion with full utterance to graph parsing.", "tgt_ref": "La première approche combine l’achèvement d’un modèle de langue avec un discours complet à analyse syntaxique de graphique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_audio": "/acl6060/audio/dev/308.wav", "src_ref": "In particular, the prefix after Obama is first completed through a finetuned BART language model and then translated into a program with full offline parser.", "tgt_ref": "En particulier, le préfixe après Obama est d’abord complété par un modèle de langue BART raffiné, puis traduit en un programme avec un analyseur hors ligne complet.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_audio": "/acl6060/audio/dev/309.wav", "src_ref": "The second approach directly predicts the program from user utterance prefixes.", "tgt_ref": "La seconde approche prévient directement le programme à partir des préfixes de discours de l’utilisateur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_audio": "/acl6060/audio/dev/310.wav", "src_ref": "This is achieved by training a single online parser to translate to the goal graph from each prefix.", "tgt_ref": "Ceci est réalisé en formant un seul analyseur en ligne à traduire au graphique objectif à partir de chaque préfixe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_audio": "/acl6060/audio/dev/311.wav", "src_ref": "This facilitates the model to learn the right anticipation.", "tgt_ref": "Cela facilite au modèle l’apprentissage de la bonne anticipation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_audio": "/acl6060/audio/dev/312.wav", "src_ref": "In a bit more detail, how do we generate these graphs?", "tgt_ref": "Avec un peu plus de détails, comment générons-nous ces graphiques ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_audio": "/acl6060/audio/dev/313.wav", "src_ref": "We formulate the problem by generating a serial version of the graph.", "tgt_ref": "Nous formulons le problème en générant une version série du graphique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_audio": "/acl6060/audio/dev/314.wav", "src_ref": "Each node or edge is represented by an action.", "tgt_ref": "Chaque nodule ou arête est représenté(e) par une action.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_audio": "/acl6060/audio/dev/315.wav", "src_ref": "Here, we start from the first node.", "tgt_ref": "Ici, nous commençons par le premier nodule.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_audio": "/acl6060/audio/dev/316.wav", "src_ref": "The number below records the absolute index in action history.", "tgt_ref": "Le nombre ci-dessous enregistre l’indice absolu dans l’historique des actions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_audio": "/acl6060/audio/dev/317.wav", "src_ref": "Then, we got the second node.", "tgt_ref": "Ensuite, nous avons le deuxième nodule.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_audio": "/acl6060/audio/dev/318.wav", "src_ref": "Next, is the edge between them.", "tgt_ref": "Ensuite, il y a l’arête entre eux.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_audio": "/acl6060/audio/dev/319.wav", "src_ref": "It contains the pointer to the index of the previous node and the edge label.", "tgt_ref": "Il contient le pointeur vers l’indice du nodule antérieur et l’étiquette d’arête.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_audio": "/acl6060/audio/dev/320.wav", "src_ref": "Zero here means connecting the most recent node with the node generated by the zeroth action and next node next edge.", "tgt_ref": "Zéro signifie ici connecter le nodule le plus récent avec le nodule généré par l’action zéro, le nodule suivant et l’arête suivante.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_audio": "/acl6060/audio/dev/321.wav", "src_ref": "This process goes on until we generate the full graph.", "tgt_ref": "Ce processus se poursuit jusqu’à ce que nous générions le graphique complet.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_audio": "/acl6060/audio/dev/322.wav", "src_ref": "The underlying model is based on transformer with self pointing mechanism similar to a previous transition based parser.", "tgt_ref": "Le modèle sous-jacent est basé sur un transformateur avec un mécanisme de pointage automatique similaire à un analyseur basé sur la transition antérieure.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_audio": "/acl6060/audio/dev/323.wav", "src_ref": "After generating a complete graph, we obtained the action level probabilities that correspond to different parts of the graph.", "tgt_ref": "Après avoir généré un graphique complet, nous avons obtenu les probabilités de niveau d’action qui correspondent aux différentes parties du graphique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_audio": "/acl6060/audio/dev/324.wav", "src_ref": "We select confidence subgraphs based on the thresholding heuristic to be executed.", "tgt_ref": "Nous sélectionnons des sous-graphiques de confiance en fonction de l’heuristique de seuillage à exécuter.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_audio": "/acl6060/audio/dev/325.wav", "src_ref": "Later on, we're going to vary the threshold to achieve different tradeoffs between the latency reduction and the execution cost.", "tgt_ref": "Plus tard, nous allons modifier le seuil pour obtenir différents compromis entre la réduction de la latence et le coût d’exécution.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_audio": "/acl6060/audio/dev/326.wav", "src_ref": "For formal evaluation of the online methods, we propose final latency reduction or FLR metric.", "tgt_ref": "Pour une évaluation formelle des méthodes en ligne, nous proposons une réduction finale de la latence ou un indicateur FLR.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_audio": "/acl6060/audio/dev/327.wav", "src_ref": "Here's a recap of how an offline system finishes the execution timeline.", "tgt_ref": "Voici un récapitulatif de la façon dont un système hors ligne termine la chronologie d’exécution.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_audio": "/acl6060/audio/dev/328.wav", "src_ref": "In online systems, execution overlaps with the utterance timeline, so it ends earlier.", "tgt_ref": "Dans les systèmes en ligne, l’exécution chevauche la chronologie de discours ; donc elle se termine plus tôt.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_audio": "/acl6060/audio/dev/329.wav", "src_ref": "FLR is defined as the reduction time compared to the offline system, marked by the end of the execution.", "tgt_ref": "FLR est défini comme le temps de réduction comparé au système hors ligne, marqué par la fin de l’exécution.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_audio": "/acl6060/audio/dev/330.wav", "src_ref": "We conduct experiments on two large conversational semantic parsing datasets, SMCalFlow and TreeDST.", "tgt_ref": "Nous menons des expériences sur deux grandes données d’analyse syntaxique et sémantique conversationnelle, SMCalFlow et TreeDST.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_audio": "/acl6060/audio/dev/331.wav", "src_ref": "Our graph based parser when operating offline, achieves state-of-the-art performance on parsing on both datasets.", "tgt_ref": "Notre analyseur basé sur le graphique, lorsqu’il fonctionne hors ligne, atteint des performances de pointe sur l’analyse syntaxique sur les deux données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_audio": "/acl6060/audio/dev/332.wav", "src_ref": "The LM complete model also achieves nontrivial BLEU gain compared with the simple baseline of node completion.", "tgt_ref": "Le modèle complet de LM réalise également un gain BLEU non trivial comparé à la simple base de l’achèvement du nodule.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_audio": "/acl6060/audio/dev/333.wav", "src_ref": "Now, let's look at the prediction accuracy of our prefix to graph parser.", "tgt_ref": "Examinons maintenant la précision de prévention de notre préfixe pour l’analyseur de graphique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_audio": "/acl6060/audio/dev/334.wav", "src_ref": "We test the match F1 score of graph tuples between the generation and the go graph in validation data in y axis for each prefix length in x axis represented by percentages.", "tgt_ref": "Nous testons le score F1 de correspondance des tuples de graphique entre la génération et le graphique dans les données de validation dans l’axe y pour chaque longueur de préfixe, et dans l’axe x représenté par des pourcentages.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_audio": "/acl6060/audio/dev/335.wav", "src_ref": "Each of these curves represents a different model with the only difference in training data.", "tgt_ref": "Chacune de ces courbes représente un modèle différent avec la seule différence de données de formation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_audio": "/acl6060/audio/dev/336.wav", "src_ref": "The bottom curve is the offline parser, and we mix in prefix data in different lengths to transition the model to an online parser.", "tgt_ref": "La courbe du bas est l’analyseur hors ligne, et nous mélangeons les données de préfixe en différentes longueurs pour faire passer le modèle à un analyseur en ligne.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_audio": "/acl6060/audio/dev/337.wav", "src_ref": "For example, the legend prefix eighty percent plus means the model is trained with prefix data with prefix length larger than eighty percent of the full utterance length.", "tgt_ref": "Par exemple, le préfixe de légende quatre-vingts pour cent plus signifie que le modèle est formé avec les données de préfixe ayant une longueur de préfixe supérieure à quatre-vingts pour cent de la longueur totale du discours.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_audio": "/acl6060/audio/dev/338.wav", "src_ref": "The upper left corner is the desired area.", "tgt_ref": "Le coin supérieur gauche est la zone souhaitée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_audio": "/acl6060/audio/dev/339.wav", "src_ref": "As we can see, the offline parser in black curve is not doing well on the prefix data.", "tgt_ref": "Comme nous pouvons le voir, l’analyseur hors ligne en courbe noire ne se porte pas bien sur les données de préfixe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_audio": "/acl6060/audio/dev/340.wav", "src_ref": "As we're mixing more prefixes in training, the curve is lifting upper and left, performing better on all the prefix lengths.", "tgt_ref": "Comme nous mélangeons plus de préfixes dans la formation, la courbe se soulève en haut à gauche, en étant plus performante sur toutes les longueurs de préfixe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_audio": "/acl6060/audio/dev/341.wav", "src_ref": "However, the full utterance parsing performance is not affected in the upper right dot.", "tgt_ref": "Cependant, la performance complète d’analyse syntaxique du discours n’est pas affectée dans le point supérieur droit.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_audio": "/acl6060/audio/dev/342.wav", "src_ref": "Based on these strong results, how much latency do we reduce?", "tgt_ref": "Sur la base de ces résultats solides, combien de latence réduisons-nous ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_audio": "/acl6060/audio/dev/343.wav", "src_ref": "We measure the time by the number of source tokens and simulate different function execution times.", "tgt_ref": "Nous mesurons le temps par le nombre de gages sources et simulons différents temps d’exécution de fonction.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_audio": "/acl6060/audio/dev/344.wav", "src_ref": "The curves show the tradeoff between the FLR metric and the execution cost, measured by the number of excessive function costs that are not correct.", "tgt_ref": "Les courbes montrent le compromis entre l’indicateur FLR et le coût d’exécution, mesuré par le nombre de coûts de fonction excessifs qui ne sont pas corrects.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_audio": "/acl6060/audio/dev/345.wav", "src_ref": "This is achieved by varying the subgraph selection threshold.", "tgt_ref": "Ceci est réalisé en faisant varier le seuil de sélection du sous-graphique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_audio": "/acl6060/audio/dev/346.wav", "src_ref": "A higher threshold selects fewer functions of mistake, but obtains a smaller FLR, whereas the lower threshold more aggressively selects and executes programs.", "tgt_ref": "Un seuil plus élevé sélectionne moins de fonctions d’erreur, mais obtient un FLR plus petit, tandis que le seuil inférieur sélectionne et exécute les programmes de manière plus agressive.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_audio": "/acl6060/audio/dev/347.wav", "src_ref": "We compare the two approaches we propose and a baseline that does nothing but directly applying the offline parser for online use.", "tgt_ref": "Nous comparons les deux approches que nous proposons et une base qui ne fait rien d’autre que d’appliquer directement l’analyseur hors ligne pour l’utilisation en ligne.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_audio": "/acl6060/audio/dev/348.wav", "src_ref": "The upper left region is has the best FLR and cost tradeoff.", "tgt_ref": "La région supérieure gauche a le meilleur compromis FLR et coût.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_audio": "/acl6060/audio/dev/349.wav", "src_ref": "We see both of our methods beat the baseline by a large margin, and they perform more similarly on TreeDST.", "tgt_ref": "Nous voyons nos deux méthodes battre la ligne de base par une grande marge, et elles fonctionnent de manière plus similaire sur TreeDST.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_audio": "/acl6060/audio/dev/350.wav", "src_ref": "While individual function execution is faster, there tends to be more run executions and lower latency reduction room.", "tgt_ref": "Bien que l’exécution des fonctions individuelles soit plus rapide, cela tend à y avoir plus d’exécutions lancées et une marge de réduction de la latence plus faible.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_audio": "/acl6060/audio/dev/351.wav", "src_ref": "When individual function execution is slower, there is more room for FLR improvement.", "tgt_ref": "Lorsque l’exécution des fonctions individuelles est plus lente, il y a plus de marge pour l’amélioration du FLR.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_audio": "/acl6060/audio/dev/352.wav", "src_ref": "Our two approaches achieve better performance in different cost cost regions.", "tgt_ref": "Nos deux approches permettent d’obtenir de meilleurs résultats dans différentes régions de coûts.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_audio": "/acl6060/audio/dev/353.wav", "src_ref": "Overall, we achieve thirty to sixty three percent relative latency reduction depending on execution time and allowed cost.", "tgt_ref": "Dans l’ensemble, nous obtenons une réduction de latence relative de trente à soixante-trois pour cent en fonction du temps d’exécution et du coût autorisé.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_audio": "/acl6060/audio/dev/354.wav", "src_ref": "Finally, we have a breakdown of average latency reduction in tokens for each type of the function node when the allowed cost is three run executions.", "tgt_ref": "Enfin, nous avons une répartition de la réduction de latence moyenne en gages pour chaque type de nodule de fonction lorsque le coût autorisé est de trois exécutions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_audio": "/acl6060/audio/dev/355.wav", "src_ref": "As we can see, there are gains all over the board.", "tgt_ref": "Comme nous pouvons le voir, il y a des gains partout.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_audio": "/acl6060/audio/dev/356.wav", "src_ref": "There are also some functions on which we gain impressive latency reduction where the red bar is much longer, such as find manager and recipient.", "tgt_ref": "Il y a aussi certaines fonctions sur lesquelles nous obtenons une réduction de latence impressionnante où la barre rouge est beaucoup plus longue, comme trouver le gestionnaire et le destinataire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_audio": "/acl6060/audio/dev/357.wav", "src_ref": "These are low level functions that do not have much dependency on others.", "tgt_ref": "Ce sont des fonctions de bas niveau qui n’ont pas beaucoup de dépendance des autres.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_audio": "/acl6060/audio/dev/358.wav", "src_ref": "In conclusion, we proposed online semantic parsing as new task to explore with the rigorous latency reduction metric.", "tgt_ref": "En conclusion, nous avons proposé une analyse syntaxique et sémantique en ligne comme nouvelle tâche à explorer avec l’indicateur rigoureux de réduction de la latence.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_audio": "/acl6060/audio/dev/359.wav", "src_ref": "With a strong graph based semantic parser, we achieve relatively good latency reduction either through our pipeline approach with LM completion and a full parser or directly through a learned parser on the prefixes.", "tgt_ref": "Avec un analyseur sémantique basé sur le graphique fort, nous obtenons une réduction de latence relativement bonne soit par notre approche pipeline avec l’achèvement du LM et un analyseur complet, soit directement par un analyseur appris sur les préfixes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_audio": "/acl6060/audio/dev/360.wav", "src_ref": "Moreover, our approach can be a general framework and can be applied to other executable semantic representations in different domains.", "tgt_ref": "De plus, notre approche peut être un cadre général et être appliquée à d’autres représentations sémantiques exécutables dans différents domaines.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_audio": "/acl6060/audio/dev/361.wav", "src_ref": "Future works could explore smarter prediction and execution integration method.", "tgt_ref": "Les travaux futurs pourraient explorer la méthode d’intégration de prévention et d’exécution plus intelligente.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_audio": "/acl6060/audio/dev/362.wav", "src_ref": "Thanks for your listening.", "tgt_ref": "Merci de votre attention.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_audio": "/acl6060/audio/dev/363.wav", "src_ref": "Hi.", "tgt_ref": "Bonjour.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_audio": "/acl6060/audio/dev/364.wav", "src_ref": "I'm going to discuss our work on generating retrieval augmented counterfactuals for question answering tasks.", "tgt_ref": "Je vais discuter de notre travail sur la génération de contrefactuels améliorés d’extraction pour les tâches de réponse aux questions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_audio": "/acl6060/audio/dev/365.wav", "src_ref": "This is work done during my internship at Google Research, where I was mentored by Matthew Lamm and Ian Tenney.", "tgt_ref": "C’est le travail effectué lors de mon stage chez le centre de recherches Google, où j’ai été encadré par Matthew Lamm et Ian Tenney.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_audio": "/acl6060/audio/dev/366.wav", "src_ref": "To motivate the task, let me begin by defining a counterfactual.", "tgt_ref": "Pour motiver la tâche, permettez-moi de commencer par définir un contrefactuel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_audio": "/acl6060/audio/dev/367.wav", "src_ref": "In this work, we define a counterfactual as a perturbation of the input text that differs in some meaningful controlled way from the original text.", "tgt_ref": "Dans ce travail, nous définissons un contrefactuel comme une perturbation du texte de saisie qui diffère d’une manière contrôlée significative du texte original.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_audio": "/acl6060/audio/dev/368.wav", "src_ref": "And allows us to reason about the changes in the outcome or the task label.", "tgt_ref": "Et cela nous permet de raisonner sur les changements dans le résultat ou l’étiquette de tâche.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_audio": "/acl6060/audio/dev/369.wav", "src_ref": "For instance, changing the words fascinating to captivating or expected to mind-numbing changes the sentiment for this movie review.", "tgt_ref": "Par exemple, changer les mots fascinants en captivants ou supposés abrutissants change le sentiment pour cette critique de film.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_audio": "/acl6060/audio/dev/370.wav", "src_ref": "Similarly, adding the qualifier women's to the question changes the answer to the question in the example below.", "tgt_ref": "De même, l’ajout du qualificatif féminin à la question modifie la réponse à la question dans l’exemple ci-dessous.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_audio": "/acl6060/audio/dev/371.wav", "src_ref": "Humans are typically robust to such perturbations compared to NLP models trained on the task.", "tgt_ref": "Les humains sont généralement robustes à de telles perturbations comparés aux modèles de TAL traitement automatique du langage naturel formés sur la tâche.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_audio": "/acl6060/audio/dev/372.wav", "src_ref": "Why is that?", "tgt_ref": "Pourquoi ça ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_audio": "/acl6060/audio/dev/373.wav", "src_ref": "The dataset may be sampled with systematic biases that lead to a simple decision boundary that is violated by the counterfactual.", "tgt_ref": "Les données peuvent être échantillonnées avec des biais systématiques qui conduisent à une limite de décision simple violée par le contrefactuel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_audio": "/acl6060/audio/dev/374.wav", "src_ref": "As shown in this 2D classification problem.", "tgt_ref": "Comme le montre ce problème de classification 2D.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_audio": "/acl6060/audio/dev/375.wav", "src_ref": "My work has found that adding counterfactual examples to the training data can make the model robust to such perturbations.", "tgt_ref": "Mon travail a révélé que l’ajout d’exemples contrefactuels aux données de formation peut rendre le modèle robuste à de telles perturbations.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_audio": "/acl6060/audio/dev/376.wav", "src_ref": "So, if counterfactuals are valuable, how can we generate them?", "tgt_ref": "Donc, si les contrefactuels sont précieux, comment pouvons-nous les générer ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_audio": "/acl6060/audio/dev/377.wav", "src_ref": "This task is especially hard for NLP because here are three examples from three different NLP tasks.", "tgt_ref": "Cette tâche est particulièrement difficile pour le TAL traitement automatique du langage naturel car il y a ici trois exemples de trois tâches de TAL traitement automatique du langage naturel différentes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_audio": "/acl6060/audio/dev/378.wav", "src_ref": "As you can see, examples that violate the decision boundary between outcomes need to be very carefully crafted by perturbing some attributes of the text that are underlined here.", "tgt_ref": "Comme vous pouvez le voir, les exemples qui violent la limite de décision entre les résultats doivent être très soigneusement élaborés en perturbant certains attributs du texte qui sont soulignés ici.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_audio": "/acl6060/audio/dev/379.wav", "src_ref": "This could be done by human annotation, but this is expensive and biased.", "tgt_ref": "Cela pourrait être fait par annotation civique, mais cela est coûteux et partial.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_audio": "/acl6060/audio/dev/380.wav", "src_ref": "Some prior work has focused on using syntax trees or semantic role labeling.", "tgt_ref": "Certains travaux antérieurs se sont concentrés sur l’utilisation d’arbres de syntaxe ou d'étiquetage de rôle sémantique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_audio": "/acl6060/audio/dev/381.wav", "src_ref": "But the set of perturbations generated by these techniques are limited by the semantic framework.", "tgt_ref": "Mais l’ensemble des perturbations générées par ces techniques sont limitées par le cadre sémantique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_audio": "/acl6060/audio/dev/382.wav", "src_ref": "More recent work has used masked language models to fill in masked portions of the text to change labels.", "tgt_ref": "Des travaux plus récents ont utilisé des modèles de langue masqués pour remplir des parties masquées du texte afin de changer les étiquettes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_audio": "/acl6060/audio/dev/383.wav", "src_ref": "But finding what parts of the text to perturb can be challenging.", "tgt_ref": "Mais trouver quelles parties du texte perturber peut être difficile.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_audio": "/acl6060/audio/dev/384.wav", "src_ref": "There are more challenges to generating counterfactuals for question answering specifically.", "tgt_ref": "Il y a plus de défis à générer des contrefactuels pour la réponse aux questions spécifiquement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_audio": "/acl6060/audio/dev/385.wav", "src_ref": "This task requires background knowledge.", "tgt_ref": "Cette tâche nécessite des connaissances de base.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_audio": "/acl6060/audio/dev/386.wav", "src_ref": "For instance, to perturb the original question is Indiana Jones Temple of Doom a prequel?", "tgt_ref": "Par exemple, pour perturber la question originale : est-ce qu'Indiana Jones et le Temple maudit est une préquelle ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_audio": "/acl6060/audio/dev/387.wav", "src_ref": "We need to be aware of the other movies in the franchise to get to a question like is Indiana Jones Raiders of the Lost Ark a prequel?", "tgt_ref": "Nous devons être au courant des autres films de la franchise pour arriver à une question comme : est-ce qu’Indiana Jones et les Aventuriers de l'arche perdue est une préquelle ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_audio": "/acl6060/audio/dev/388.wav", "src_ref": "Furthermore, random perturbations can lead to questions that are not answerable with the available evidence or have false premises.", "tgt_ref": "En outre, des perturbations aléatoires peuvent conduire à des questions qui ne répondent pas avec les preuves disponibles ou ont de fausses prémisses.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_audio": "/acl6060/audio/dev/389.wav", "src_ref": "Moreover, some question perturbations can lead to significant semantic drift from the original input.", "tgt_ref": "De plus, certaines perturbations de question peuvent conduire à une dérive sémantique significative par rapport à la saisie originale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_audio": "/acl6060/audio/dev/390.wav", "src_ref": "For instance, this question is Indiana Jones practicing child slavery in Temple of Doom?", "tgt_ref": "Par exemple, est-ce qu’Indiana Jones pratique l’esclavage des enfants dans le Temple maudit ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_audio": "/acl6060/audio/dev/391.wav", "src_ref": "We propose a very simple yet effective technique called retrieve generate filter or RGF, to tackle counterfactual perturbations of questions, and also aims to tackle all the other aforementioned challenges.", "tgt_ref": "Nous proposons une technique très simple mais efficace appelée Retrieve Generate Filter ou RGF, pour s’attaquer aux perturbations contrefactuelles des questions, et qui vise également à relever tous les autres défis susmentionnés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_audio": "/acl6060/audio/dev/392.wav", "src_ref": "The core intuition behind RGF is that the necessary background information that is needed to generate perturbations may be present in the near misses made by a question answering model.", "tgt_ref": "L’intuition de base derrière le RGF est que les informations d’arrière-plan nécessaires pour générer des perturbations peuvent être présentes dans les quasi-accidents causés par un modèle de réponse aux questions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_audio": "/acl6060/audio/dev/393.wav", "src_ref": "For instance, the state-of-the-art model REALM produces the following top k answers to the question who is the captain of the Richmond Football Club?", "tgt_ref": "Par exemple, le modèle REALM à la fine pointe de la technologie produit les premières réponses k suivantes à la question : qui est le capitaine du Richmond Football Club ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_audio": "/acl6060/audio/dev/394.wav", "src_ref": "While it does recover the original reference passage and answer Trent Cotchin as the top most choice.", "tgt_ref": "Bien qu’il récupère le passage de référence original et répond Trent Cotchin en premier choix.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_audio": "/acl6060/audio/dev/395.wav", "src_ref": "It also retrieves additional passages and answers which can be used to guide question perturbation.", "tgt_ref": "Il extrait également des passages et des réponses supplémentaires qui peuvent être utilisés pour guider la perturbation de question.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_audio": "/acl6060/audio/dev/396.wav", "src_ref": "For instance, it recovers two more answers corresponding to the captains of the reserve team and the women's team of the same club, and this can lead to interesting edits.", "tgt_ref": "Par exemple, il récupère deux autres réponses correspondant aux capitaines de l’équipe de réserve et de l’équipe féminine du même club, ce qui peut conduire à des modifications intéressantes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_audio": "/acl6060/audio/dev/397.wav", "src_ref": "To summarize, RGF first retrieves top k most relevant answers and contexts which don't match the reference answer in context.", "tgt_ref": "Pour résumer, le RGF extrait d’abord les premières réponses k les plus pertinentes et les contextes qui ne correspondent pas à la réponse de référence dans le contexte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_audio": "/acl6060/audio/dev/398.wav", "src_ref": "Following this step, the question generation model conditions on these alternate answers to generate a question that corresponds to them.", "tgt_ref": "Suite à cette étape, le modèle de production de questions conditionne ces réponses alternatives pour générer une question qui leur correspond.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_audio": "/acl6060/audio/dev/399.wav", "src_ref": "And finally, we can filter the generated questions based on minimality or based on the type of semantic perturbation we are interested in introducing.", "tgt_ref": "Et enfin, nous pouvons filtrer les questions générées en fonction de la minimalité ou du type de perturbation sémantique que nous voulons introduire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_audio": "/acl6060/audio/dev/400.wav", "src_ref": "Going over each step in greater detail for retrieval, we use a retrieve then read model like REALM that takes as input the original question, and a large corpus like Wikipedia.", "tgt_ref": "En passant en revue chaque étape plus en détail pour l’extraction, nous utilisons un modèle lu comme REALM qui prend comme saisie la question originale, et un grand corpus comme Wikipédia.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_audio": "/acl6060/audio/dev/401.wav", "src_ref": "It consists of two modules.", "tgt_ref": "Il est constitué de deux modules.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_audio": "/acl6060/audio/dev/402.wav", "src_ref": "The retriever module performs similarity search over a dense index of passages to retrieve the top k most relevant passages to the question.", "tgt_ref": "Le module d’extraction effectue des recherches de similarité sur un indice dense de passages pour extraire les passages k les plus pertinents à la question.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_audio": "/acl6060/audio/dev/403.wav", "src_ref": "And a reader module then extracts a span from each passage as a potential answer.", "tgt_ref": "Et un module de lecture extrait ensuite un étendage de chaque passage en tant que réponse potentielle.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_audio": "/acl6060/audio/dev/404.wav", "src_ref": "REALM retrieves the gold passage and answer in most cases.", "tgt_ref": "REALM extrait le passage d’or et la réponse dans la plupart des cas.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_audio": "/acl6060/audio/dev/405.wav", "src_ref": "However, in this work, we are more interested in the answers and context that it retrieves further down the line.", "tgt_ref": "Cependant, dans ce travail, nous sommes plus intéressés par les réponses et le contexte qu’il extrait plus loin dans la ligne.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_audio": "/acl6060/audio/dev/406.wav", "src_ref": "In the next step, question generation, we use these alternate answers and contexts to regenerate new questions that correspond to these alternatives.", "tgt_ref": "Dans l’étape suivante, production de questions, nous utilisons ces réponses alternatives et contextes pour générer de nouvelles questions qui correspondent à ces alternatives.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_audio": "/acl6060/audio/dev/407.wav", "src_ref": "Question generation model is a pre trained text-to-text transformer that is fine-tuned on the NQ data to generate a question for an answer that's marked in context.", "tgt_ref": "Le modèle de production de questions est une conversion texte-à-texte préformé qui est raffiné sur les données NQ pour générer une question pour une réponse marquée dans le contexte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_audio": "/acl6060/audio/dev/408.wav", "src_ref": "During inference we supply the question generation model, the alternative answer and context that we retrieved in the previous step.", "tgt_ref": "Au cours de l’inférence, nous fournissons le modèle de production de questions, la réponse alternative et le contexte que nous avons extraits à l’étape antérieure.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_audio": "/acl6060/audio/dev/409.wav", "src_ref": "For example, for the query who is the captain of the Richmond Football Club? REALM retrieves passages about the club's women's team, captained by Jess Kennedy, and the question generation model generates the query who captained Richmond Football Club's first ever women's team?", "tgt_ref": "Par exemple, pour la question : qui est le capitaine du Richmond Football Club ? REALM extrait des passages sur l’équipe féminine du club, dirigée par Jess Kennedy, et le modèle de production de questions génère la requête « qui a été le capitaine de la toute première équipe féminine du Richmond Football Club ? »", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_audio": "/acl6060/audio/dev/410.wav", "src_ref": "Which has a specific semantic perturbation.", "tgt_ref": "Qui a une perturbation sémantique spécifique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_audio": "/acl6060/audio/dev/411.wav", "src_ref": "In a similar fashion, we also get queries like who captained Richmond's VFL Reserve team?", "tgt_ref": "D’une manière similaire, nous recevons également des questions comme : qui était capitaine de l’équipe de réserve VFL de Richmond ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_audio": "/acl6060/audio/dev/412.wav", "src_ref": "Or who did graham negate in the grand final last year?", "tgt_ref": "Ou qui Graham a-t-il invalidé lors de la grande finale l’année dernière ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_audio": "/acl6060/audio/dev/413.wav", "src_ref": "Finally, we filter out a subset of the generated queries based on some desired characteristics.", "tgt_ref": "Enfin, nous filtrons un sous-ensemble des requêtes générées en fonction de certaines caractéristiques souhaitées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_audio": "/acl6060/audio/dev/414.wav", "src_ref": "As motivated earlier, we would like to ensure that the new question is still semantically close to the original.", "tgt_ref": "Comme motivé plus tôt, nous aimerions nous assurer que la nouvelle question est toujours sémantiquement proche de l’originale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_audio": "/acl6060/audio/dev/415.wav", "src_ref": "For filtering techniques that doesn't require additional supervision, we simply retain new questions that have a small token label edit distance from the original question.", "tgt_ref": "Pour les techniques de filtrage qui ne nécessitent pas de supervision supplémentaire, nous conservons simplement de nouvelles questions qui ont une petite distance d’édition de l’étiquette de gage par rapport à la question d’origine.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 416, "src_audio": "/acl6060/audio/dev/416.wav", "src_ref": "For example, we remove the question who did graham negate in the grand final last year?", "tgt_ref": "Par exemple, nous supprimons la question : qui Graham a-t-il invalidé lors de la grande finale l’année dernière ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 417, "src_audio": "/acl6060/audio/dev/417.wav", "src_ref": "Because it has a longer edit distance from the original question.", "tgt_ref": "Car elle a une distance d’édition plus longue par rapport à la question d’origine.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 418, "src_audio": "/acl6060/audio/dev/418.wav", "src_ref": "In our experiments, we demonstrate that this simple heuristic can be used to augment and queue training data.", "tgt_ref": "Dans nos expériences, nous démontrons que cette heuristique simple peut être utilisée pour améliorer et mettre en file d’attente les données de formation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 419, "src_audio": "/acl6060/audio/dev/419.wav", "src_ref": "We also experiment with a filtering strategy that is based on the type of semantic perturbation.", "tgt_ref": "Nous expérimentons également une stratégie de filtrage basée sur le type de perturbation sémantique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 420, "src_audio": "/acl6060/audio/dev/420.wav", "src_ref": "To this end, we use a general purpose query decomposition framework called QED.", "tgt_ref": "À cette fin, nous utilisons un cadre de décomposition de requête à usage général appelé QED.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 421, "src_audio": "/acl6060/audio/dev/421.wav", "src_ref": "QED identifies two parts to the question, a predicate and a reference.", "tgt_ref": "QED identifie deux parties à la question, un prédicat et une référence.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 422, "src_audio": "/acl6060/audio/dev/422.wav", "src_ref": "References are noun phrases in the question that correspond to entities in the context.", "tgt_ref": "Les références sont des syntagmes nominaux dans la question qui correspondent à des entités dans le contexte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 423, "src_audio": "/acl6060/audio/dev/423.wav", "src_ref": "A predicate is basically the remaining portion of the question.", "tgt_ref": "Un prédicat est essentiellement la partie restante de la question.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 424, "src_audio": "/acl6060/audio/dev/424.wav", "src_ref": "For example, we are able to decompose the query who captained Richmond's first ever women's team into two references: Richmond Football Club women's team and the predicate who captained X.", "tgt_ref": "Par exemple, nous sommes en mesure de décomposer la requête « qui a dirigé la toute première équipe féminine de Richmond en deux références » : l’équipe féminine du Richmond Football Club et le prédicat qui a dirigé X.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 425, "src_audio": "/acl6060/audio/dev/425.wav", "src_ref": "A model trained on reference predicate annotations for NQ gives us this question decomposition.", "tgt_ref": "Un modèle formé sur les annotations du prédicat de référence pour NQ nous fournit cette décomposition de question.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 426, "src_audio": "/acl6060/audio/dev/426.wav", "src_ref": "Decomposing both the original and generated question based on QED allows us to categorize our generated counterfactuals for evaluation.", "tgt_ref": "La décomposition à la fois de la question originale et générée basée sur QED nous permet de catégoriser nos contrefactuels générés pour l’évaluation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 427, "src_audio": "/acl6060/audio/dev/427.wav", "src_ref": "Specifically, we obtain two groups of questions.", "tgt_ref": "Plus précisément, nous obtenons deux groupes de questions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 428, "src_audio": "/acl6060/audio/dev/428.wav", "src_ref": "Those that undergo a reference change while retaining predicates, and those that undergo a predicate change and optionally add references.", "tgt_ref": "Ceux qui subissent un changement de référence tout en conservant les prédicats, et ceux qui subissent un changement de prédicat et ajoutent éventuellement des références.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 429, "src_audio": "/acl6060/audio/dev/429.wav", "src_ref": "For instance, who captained Richmond's VFL reserve team is a reference change?", "tgt_ref": "Par exemple, qui a été capitaine de l’équipe de réserve de Richmond VFL est-il un changement de référence ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 430, "src_audio": "/acl6060/audio/dev/430.wav", "src_ref": "While, who wears number nine for the club is a predicate change.", "tgt_ref": "Alors que, qui porte le numéro neuf pour le club est un changement de prédicat.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 431, "src_audio": "/acl6060/audio/dev/431.wav", "src_ref": "We now evaluate the effectiveness of RGF perturbations when augmented to training data.", "tgt_ref": "Nous évaluons maintenant l’efficacité des perturbations RGF lorsqu’elles sont améliorées par rapport aux données de formation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 432, "src_audio": "/acl6060/audio/dev/432.wav", "src_ref": "So, to effectively evaluate the effectiveness of counterfactual augmentation in particular, we experiment with two strong data augmentation baselines.", "tgt_ref": "Ainsi, pour évaluer efficacement l’efficacité de l’élargissement contrefactuel en particulier, nous expérimentons deux bases de forte amélioration de données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 433, "src_audio": "/acl6060/audio/dev/433.wav", "src_ref": "The first baseline, called random answer and question generation, adds data that has no relation with the original question.", "tgt_ref": "La première base, appelée réponse aléatoire et production de questions, ajoute des données qui n’ont pas de relation avec la question originale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 434, "src_audio": "/acl6060/audio/dev/434.wav", "src_ref": "That is, passages and answers are simply randomly sampled from Wikipedia.", "tgt_ref": "Autrement dit, les passages et les réponses sont simplement échantillonnés au hasard à partir de Wikipédia.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 28, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 435, "src_audio": "/acl6060/audio/dev/435.wav", "src_ref": "This baseline basically adds more data that looks like NQ.", "tgt_ref": "Cette base ajoute essentiellement plus de données ressemblant à NQ.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 436, "src_audio": "/acl6060/audio/dev/436.wav", "src_ref": "With the second baseline gold answer and question generation, we specifically update the retrieval portion of our method.", "tgt_ref": "Avec la deuxième réponse d’or de base et la production de questions, nous mettons spécifiquement à jour la partie extraction de notre méthode.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 437, "src_audio": "/acl6060/audio/dev/437.wav", "src_ref": "Here, alternate answers are just chosen from the same passage that contained the gold answer.", "tgt_ref": "Ici, les réponses alternatives sont simplement choisies à partir du même passage qui contenait la réponse d’or.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 438, "src_audio": "/acl6060/audio/dev/438.wav", "src_ref": "How base how do the baselines and RGF ah augmentation perform on reading comprehension where the model has access to question and context?", "tgt_ref": "Comment l’élargissement des bases et du RGF fonctionne sur la reading comprehension où le modèle a accès à la question et au contexte ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 439, "src_audio": "/acl6060/audio/dev/439.wav", "src_ref": "We experiment with six out of domain datasets and present results here, where data is the training data is doubled in augmentation.", "tgt_ref": "Nous expérimentons avec six données hors domaine et présentons les résultats ici, où les données qui sont les training data sont doublées dans l’élargissement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 440, "src_audio": "/acl6060/audio/dev/440.wav", "src_ref": "We find that both data augmentation baselines are not able to improve our domain generalization.", "tgt_ref": "Nous constatons que les deux bases d’amélioration de données ne sont pas en mesure d’améliorer notre généralisation du domaine.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 441, "src_audio": "/acl6060/audio/dev/441.wav", "src_ref": "In fact, an ensemble of six models trained on the original data seems to be the most competitive baseline.", "tgt_ref": "En effet, un ensemble de six modèles formés sur les données originales semble être la base la plus compétitive.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 442, "src_audio": "/acl6060/audio/dev/442.wav", "src_ref": "Comparing against that baseline, we find that RGF counterfactuals are able to improve out of domain performance while maintaining in domain performance.", "tgt_ref": "En comparant avec cette base, nous constatons que les contrefactuels RGF sont capables d’améliorer les performances hors domaine tout en maintenant les performances de domaine.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 443, "src_audio": "/acl6060/audio/dev/443.wav", "src_ref": "This suggests that filling in the reasoning gaps of the model via counterfactual augmentation is more effective than adding more data from the training distribution.", "tgt_ref": "Cela suggère que combler les lacunes de raisonnement du modèle via l’élargissement contrefactuel est plus efficace que d’ajouter plus de données de la distribution de formation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 444, "src_audio": "/acl6060/audio/dev/444.wav", "src_ref": "Furthermore, we find that using retrieval to sample alternative outcomes or answers is important for effective CDA.", "tgt_ref": "En outre, nous constatons que l’utilisation de l’extraction pour échantillonner d’autres résultats ou réponses est importante pour un CDA efficace.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 445, "src_audio": "/acl6060/audio/dev/445.wav", "src_ref": "We also experiment with open domain QA setting where the model only sees the question and once again we evaluate on four out of domain datasets.", "tgt_ref": "Nous expérimentons également un paramètre QA de domaine ouvert où le modèle ne voit que la question et une fois de plus, nous évaluons sur quatre données hors domaine.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 446, "src_audio": "/acl6060/audio/dev/446.wav", "src_ref": "We find that baseline models are not as effective for out of domain generalization.", "tgt_ref": "Nous constatons que les modèles de référence ne sont pas aussi efficaces pour notre généralisation hors domaine.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 447, "src_audio": "/acl6060/audio/dev/447.wav", "src_ref": "However, data augmentation with RGF shows more significant improvements.", "tgt_ref": "Cependant, l’amélioration de données avec RGF montre des améliorations plus significatives.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 448, "src_audio": "/acl6060/audio/dev/448.wav", "src_ref": "We even improve in the in domain NQ dataset.", "tgt_ref": "Nous nous améliorons même dans les données NQ de domaine.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 449, "src_audio": "/acl6060/audio/dev/449.wav", "src_ref": "We hypothesized that the counterfactual data augmentation aids the model in learning better query encodings for very similar queries.", "tgt_ref": "Nous avons émis l’hypothèse que l’amélioration de données contrefactuelle aide le modèle à apprendre de meilleurs encodages de requête pour des requêtes très similaires.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 29, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 450, "src_audio": "/acl6060/audio/dev/450.wav", "src_ref": "Finally, we also evaluate on the model's ability to improve consistency in the local neighborhood of the original question.", "tgt_ref": "Enfin, nous évaluons également la capacité du modèle à améliorer la cohérence dans le voisinage local de la question originale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 451, "src_audio": "/acl6060/audio/dev/451.wav", "src_ref": "Consistency measures the proportion of questions correctly answered by the model where both the original and the counterfactual query are correctly answered.", "tgt_ref": "La cohérence mesure la proportion de questions correctement répondues par le modèle où à la fois la requête originale et celle contrefactuelle reçoivent une réponse correcte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 452, "src_audio": "/acl6060/audio/dev/452.wav", "src_ref": "This explicitly helps us to measure the model's robustness to small perturbations in the neighborhood of the original input.", "tgt_ref": "Cela nous aide explicitement à mesurer la robustesse du modèle à de petites perturbations dans le voisinage de la saisie originale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 453, "src_audio": "/acl6060/audio/dev/453.wav", "src_ref": "We experiment with five datasets which contain pairs of questions that are semantically close to each other.", "tgt_ref": "Nous expérimentons avec cinq données qui contiennent des paires de questions sémantiquement proches les unes des autres.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 454, "src_audio": "/acl6060/audio/dev/454.wav", "src_ref": "Apart from the three datasets AQA, AmbigQA and QUOREF-Contrast set that are already available, we also evaluate on RGF counterfactuals that are paired with original NQ questions based on whether they underwent a predicate change or reference change.", "tgt_ref": "Mis à part les trois données AQA, AmbigQA et QUOREF-Contrast définies qui sont déjà disponibles, nous évaluons également sur les contrefactuels RGF qui sont synchronisés avec les questions NQ originales selon qu'elles ont subi un changement de prédicat ou un changement de référence.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 455, "src_audio": "/acl6060/audio/dev/455.wav", "src_ref": "These subsets were annotated in-house to eliminate noise and are provided as a resource.", "tgt_ref": "Ces sous-ensembles ont été annotés en interne pour éliminer le bruit et sont fournis en tant que ressource.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 456, "src_audio": "/acl6060/audio/dev/456.wav", "src_ref": "All baselines are unable to significantly improve consistency with the ensemble model improving consistency by a small margin.", "tgt_ref": "Toutes les bases sont incapables d’améliorer de manière significative la cohérence avec le modèle d’ensemble en améliorant la cohérence d’une petite marge.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 457, "src_audio": "/acl6060/audio/dev/457.wav", "src_ref": "However, RGF counterfactual augmentation has impressive gains in consistency both on prior datasets and the two subsets we curated for reference and predicate perturbations.", "tgt_ref": "Cependant, l’élargissement contrefactuel du RGF a des gains impressionnants en cohérence à la fois sur les données antérieures et les deux sous-ensembles que nous avons sélectionnés pour les perturbations de référence et de prédicat.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 458, "src_audio": "/acl6060/audio/dev/458.wav", "src_ref": "Note that the augmented RGF data is not biased by perturbation type, only the evaluation sets are.", "tgt_ref": "Notez que les données RGF améliorées ne sont pas biaisées par le type de perturbation, seuls les ensembles d’évaluation le sont.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 459, "src_audio": "/acl6060/audio/dev/459.wav", "src_ref": "In fact, a qualitative inspection of the kinds of counterfactuals generated show that the generated questions contain several diverse perturbations.", "tgt_ref": "En effet, une inspection qualitative des types de contrefactuels générés montre que les questions générées contiennent plusieurs perturbations diverses.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 460, "src_audio": "/acl6060/audio/dev/460.wav", "src_ref": "For instance, this original question on the population of Walnut Grove, Minnesota is perturbed along different dimensions like town, state, country, and along different predicates like location, poverty, number of schools.", "tgt_ref": "Par exemple, cette question originale sur la population de Walnut Grove, au Minnesota, est perturbée par différentes dimensions comme la ville, l’État, le pays, et par différents prédicats comme l’emplacement, la pauvreté et le nombre d’écoles.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 461, "src_audio": "/acl6060/audio/dev/461.wav", "src_ref": "Audio of perturbations are context specific.", "tgt_ref": "L’audio des perturbations est spécifique au contexte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 462, "src_audio": "/acl6060/audio/dev/462.wav", "src_ref": "For example, for this other question about the Wimbledon ah singles tournament, the perturbation is along type of game, type of tournament, or the game outcome.", "tgt_ref": "Par exemple, pour cette autre question sur le tournoi en simple de Wimbledon, la perturbation est liée au type de jeu, au type de tournoi ou au résultat du jeu.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 463, "src_audio": "/acl6060/audio/dev/463.wav", "src_ref": "Final takeaways; we tackle the task of counterfactual data augmentation and perturbations for information seeking queries and tackle its unique challenges via a reversal of the generation approach, over generate using near misses of the model and filter based on perturbation type or minimality.", "tgt_ref": "Derniers points à retenir : nous abordons la tâche d’amélioration des données contrefactuelle et les perturbations pour les requêtes recherchant des informations et abordons ses défis uniques via un renversement de l’approche de génération, et générons plus en utilisant des quasi-accidents du modèle et un filtre basé sur le type de perturbation ou la minimalité.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 464, "src_audio": "/acl6060/audio/dev/464.wav", "src_ref": "We find that this technique requires no additional supervision and the examples are labeled for augmentation.", "tgt_ref": "Nous constatons que cette technique ne nécessite aucune supervision supplémentaire et les exemples sont étiquetés pour l’élargissement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 30, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 465, "src_audio": "/acl6060/audio/dev/465.wav", "src_ref": "Augmentation improves out of domain generalization and neighborhood consistency.", "tgt_ref": "L’élargissement améliore la généralisation de domaine et la cohérence du voisinage.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 31, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 466, "src_audio": "/acl6060/audio/dev/466.wav", "src_ref": "And we find that RGF counterfactuals are semantically diverse without introducing bias during augmentation.", "tgt_ref": "Et nous constatons que les contrefactuels RGF sont sémantiquement divers sans introduire de biais lors de l’élargissement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 31, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 467, "src_audio": "/acl6060/audio/dev/467.wav", "src_ref": "Thank you.", "tgt_ref": "Merci.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 31, "subset": "dev"}}
{"dataset_id": "acl_6060", "sample_id": 468, "src_audio": "/acl6060/audio/eval/468.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "tgt_ref": "Bonjour tout le monde. Aujourd'hui, je vais vous présenter notre travail de recherche « Apprendre à raisonner par déduction » : résolution de problèmes de mots mathématiques comme extraction de relation complexe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 469, "src_audio": "/acl6060/audio/eval/469.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "tgt_ref": "Je m'appelle Allan du laboratoire d'intelligence artificielle ByteDance, et ceci est un travail en commun avec Jierui Li de l'Université du Texas à Austin et Wei Lu du SUTD.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 470, "src_audio": "/acl6060/audio/eval/470.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "tgt_ref": "Tout d'abord, j'aimerais parler de notre motivation pour le raisonnement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 471, "src_audio": "/acl6060/audio/eval/471.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "tgt_ref": "Donc ici, nous montrons un exemple où le raisonnement en plusieurs étapes est utile.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 472, "src_audio": "/acl6060/audio/eval/472.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "tgt_ref": "Ce chiffre est donc tiré de l'article PaLM où ils incitent à résoudre le problème de réseau dans le scénario d'apprentissage de quelques prises de vue.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 473, "src_audio": "/acl6060/audio/eval/473.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "tgt_ref": "Donc, sur le côté gauche, nous pouvons voir que si nous fournissons quelques exemples avec juste des questions et des réponses, nous pourrions ne pas être en mesure d'obtenir les bonnes réponses.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 474, "src_audio": "/acl6060/audio/eval/474.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "tgt_ref": "Mais si nous fournissons plus de description du raisonnement, le modèle est capable de prévenir la description du raisonnement, mais aussi d'effectuer ici une prévention correcte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 475, "src_audio": "/acl6060/audio/eval/475.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "tgt_ref": "Il est alors bon d'avoir comme résultat un raisonnement à plusieurs étapes interprétable.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 476, "src_audio": "/acl6060/audio/eval/476.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "tgt_ref": "Et nous pensons également que les problèmes de mots mathématiques sont une application directe pour évaluer de telles capacités de raisonnement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 477, "src_audio": "/acl6060/audio/eval/477.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "tgt_ref": "Donc ici, dans notre configuration de problème, compte tenu des questions, nous devons résoudre cette question et obtenir les réponses numériques.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 478, "src_audio": "/acl6060/audio/eval/478.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "tgt_ref": "Ainsi, dans nos données, nous recevons également l‘expression mathématique qui conduit à cette réponse particulière.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 479, "src_audio": "/acl6060/audio/eval/479.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "tgt_ref": "Donc, certaines hypothèses s'appliquent également comme dans les travaux antérieurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 480, "src_audio": "/acl6060/audio/eval/480.wav", "src_ref": "We assume the precision of quantities are known.", "tgt_ref": "Nous supposons que la précision des quantités est connue.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 481, "src_audio": "/acl6060/audio/eval/481.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "tgt_ref": "Et nous ne considérons que les opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentielle.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 482, "src_audio": "/acl6060/audio/eval/482.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "tgt_ref": "En outre, les opérateurs compliqués peuvent effectivement être décomposés en ces opérateurs de base.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 0, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 483, "src_audio": "/acl6060/audio/eval/483.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "tgt_ref": "Ainsi, le travail antérieur dans la résolution de problèmes de mots mathématiques peut en effet être classé dans un modèle séquence à séquence et séquence à arbre.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 484, "src_audio": "/acl6060/audio/eval/484.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "tgt_ref": "Le modèle séquence à séquence traditionnel convertit donc l'expression en une séquence spécifique pour la génération.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 485, "src_audio": "/acl6060/audio/eval/485.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "tgt_ref": "Il est assez facile à mettre en œuvre et peut être généralisé à de nombreux problèmes compliqués différents.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 486, "src_audio": "/acl6060/audio/eval/486.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "tgt_ref": "Mais les inconvénients sont que la performance n'est généralement pas meilleure que le modèle structuré et son manque d'interopérabilité pour la prévention.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 487, "src_audio": "/acl6060/audio/eval/487.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "tgt_ref": "Mais en réalité, cette direction est encore très populaire en raison du modèle de conversion.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 488, "src_audio": "/acl6060/audio/eval/488.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "tgt_ref": "Donc, dans les modèles à base d'arbre, nous structurons en réalité ces expressions sous forme d'arbre et suivons une traversée préordonnée dans les générations d'arbres.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 489, "src_audio": "/acl6060/audio/eval/489.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "tgt_ref": "Donc ici, nous continuons à produire les opérateurs jusqu'à ce que nous atteignions les feuilles, qui sont les quantités.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 490, "src_audio": "/acl6060/audio/eval/490.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "tgt_ref": "Donc ici, la bonne chose est qu'en fait, cela nous donne cette structure d'arbre binaire. Mais en réalité, c'est assez contre-intuitif parce que nous générons d'abord l'opérateur et ensuite, à la fin, nous générons les quantités.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 491, "src_audio": "/acl6060/audio/eval/491.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "tgt_ref": "Et la deuxième chose est que cela contient également des calculs répétitifs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 492, "src_audio": "/acl6060/audio/eval/492.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "tgt_ref": "Donc ici, si nous regardons cette expression, huit fois trois plus trois est en fait généré deux fois, mais en réalité, nous devrions réutiliser les résultats.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 493, "src_audio": "/acl6060/audio/eval/493.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "tgt_ref": "Ainsi, dans notre approche proposée, nous voulons résoudre ces problèmes étape par étape et de manière interprétable.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 494, "src_audio": "/acl6060/audio/eval/494.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "tgt_ref": "Par exemple, ici dans la deuxième étape, nous pouvons obtenir ces diviseurs qui sont vingt-sept.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 495, "src_audio": "/acl6060/audio/eval/495.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "tgt_ref": "Et nous pouvons également nous référer aux questions originales pour trouver le contenu pertinent.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 496, "src_audio": "/acl6060/audio/eval/496.wav", "src_ref": "And in these steps we obtain the divisors.", "tgt_ref": "Et dans ces étapes, nous obtenons les diviseurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 497, "src_audio": "/acl6060/audio/eval/497.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "tgt_ref": "Puis, à cette troisième étape, nous obtenons alors le quotient.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 1, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 498, "src_audio": "/acl6060/audio/eval/498.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "tgt_ref": "Très bien. Et après ces trois étapes, nous pouvons alors réutiliser les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape, et enfin, nous pouvons obtenir les dividendes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 499, "src_audio": "/acl6060/audio/eval/499.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "tgt_ref": "Donc ici, nous générons en réalité l'expression entière directement plutôt que de produire un seul opérateur ou une seule quantité.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 500, "src_audio": "/acl6060/audio/eval/500.wav", "src_ref": "So this makes the process more accurate.", "tgt_ref": "Cela rend le processus plus précis.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 501, "src_audio": "/acl6060/audio/eval/501.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "tgt_ref": "Ainsi, dans notre système déductif, nous commençons d'abord par un tas de quantités présentées dans les questions et incluant également une certaine constante comme notre état initial.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 502, "src_audio": "/acl6060/audio/eval/502.wav", "src_ref": "So, the expression is represented by e i j o p.", "tgt_ref": "Ainsi, l'expression est représentée par e i j o p.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 503, "src_audio": "/acl6060/audio/eval/503.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "tgt_ref": "Où nous effectuons l'opérateur de q_i à q_j, et cette expression est en fait dirigée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 504, "src_audio": "/acl6060/audio/eval/504.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "tgt_ref": "Donc, nous avons également ici la soustraction avec des mots pour représenter la direction opposée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 505, "src_audio": "/acl6060/audio/eval/505.wav", "src_ref": "This is quite similar to relation extraction.", "tgt_ref": "C'est tout à fait similaire à l'extraction de relation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 506, "src_audio": "/acl6060/audio/eval/506.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "tgt_ref": "Donc, dans un système déductif formel, à un pas de temps t, on applique l'opérateur entre la paire q_i et q_j, puis on obtient cette nouvelle expression.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 507, "src_audio": "/acl6060/audio/eval/507.wav", "src_ref": "We add it to the next state to become a new quantity.", "tgt_ref": "Nous l'ajoutons à l'état suivant pour devenir une nouvelle quantité.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 508, "src_audio": "/acl6060/audio/eval/508.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "tgt_ref": "Ainsi, ces diapositives visualisent en réalité l'évolution de l'état où nous continuons à ajouter de l'expression à l'état actuel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 509, "src_audio": "/acl6060/audio/eval/509.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "tgt_ref": "Donc, dans nos implémentations de modèle, nous utilisons d'abord un modèle de langue préformée qui peut être BERT ou Roberta, puis nous encodons la phrase et obtenons ensuite ces représentations de quantité.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 510, "src_audio": "/acl6060/audio/eval/510.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "tgt_ref": "Donc, une fois que nous obtenons les représentations de quantité, nous pouvons commencer à faire l'inférence.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 511, "src_audio": "/acl6060/audio/eval/511.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "tgt_ref": "Nous montrons ici un exemple de q_1 pour obtenir la représentation pour q_2 divisée par q_2 multipliée par q_3.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 512, "src_audio": "/acl6060/audio/eval/512.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "tgt_ref": "Tout d'abord, nous obtenons la représentation de paire, qui n'est essentiellement que l'enchaînement entre q_1 et q_2, puis nous appliquons un réseau prédictif qui est paramétré par l'opérateur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 2, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 513, "src_audio": "/acl6060/audio/eval/513.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "tgt_ref": "Et enfin, nous obtenons la représentation de l'expression q_1 divisée par q_2.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 514, "src_audio": "/acl6060/audio/eval/514.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "tgt_ref": "Mais en réalité, dans la pratique, au stade de l'inférence, nous pourrions également obtenir une expression incorrecte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 515, "src_audio": "/acl6060/audio/eval/515.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "tgt_ref": "Donc ici, toute l'expression possible est égale à trois fois le nombre d'opérateurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 516, "src_audio": "/acl6060/audio/eval/516.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "tgt_ref": "Alors, ce qui est bien ici, c'est que nous pouvons facilement ajouter des contraintes pour contrôler cet espace de recherche.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 517, "src_audio": "/acl6060/audio/eval/517.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "tgt_ref": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement supprimer cette expression dans notre espace de recherche.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 518, "src_audio": "/acl6060/audio/eval/518.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "tgt_ref": "Donc, dans la deuxième étape, nous faisons la même chose, mais la seule différence est que nous avons une quantité de plus.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 519, "src_audio": "/acl6060/audio/eval/519.wav", "src_ref": "So this quantity come from the previous calculated expression.", "tgt_ref": "Cette quantité provient donc de l'expression calculée antérieure.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 520, "src_audio": "/acl6060/audio/eval/520.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "tgt_ref": "Finalement, nous pouvons obtenir cette expression finale q_3 multipliée par q_4.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 521, "src_audio": "/acl6060/audio/eval/521.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "tgt_ref": "Et nous pouvons également voir que le nombre de toutes les expressions possibles est différent de l'étape antérieure.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 522, "src_audio": "/acl6060/audio/eval/522.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "tgt_ref": "Ainsi, une telle différence rend difficile l'application de la beam search car la distribution de probabilité entre ces deux étapes est déséquilibrée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 523, "src_audio": "/acl6060/audio/eval/523.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "tgt_ref": "La procédure de formation est donc similaire à la formation d'un modèle séquence à séquence où nous optimisons la perte à chaque pas de temps.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 524, "src_audio": "/acl6060/audio/eval/524.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "tgt_ref": "Et ici, nous utilisons également ce tau pour représenter le moment où nous devrions mettre fin à ce processus de génération.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 525, "src_audio": "/acl6060/audio/eval/525.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "tgt_ref": "Et ici, l'espace est différent de séquence à séquence car il est différent à chaque pas de temps, alors que dans le modèle séquence à séquence traditionnel, c'est le nombre de vocabulaire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 526, "src_audio": "/acl6060/audio/eval/526.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "tgt_ref": "Et cela nous permet également d'imposer certaines contraintes à partir de connaissances antérieures.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 527, "src_audio": "/acl6060/audio/eval/527.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "tgt_ref": "Nous menons donc des expériences sur les données de problèmes de mots mathématiques, MAWPS, Math23K, MathQA et SVAMP couramment utilisées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 3, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 528, "src_audio": "/acl6060/audio/eval/528.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "tgt_ref": "Et ici, nous montrons brièvement les résultats comparés aux meilleures approches antérieures.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 529, "src_audio": "/acl6060/audio/eval/529.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "tgt_ref": "Donc, notre variante la plus performante est Roberta-DeuctiveReasoner.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 530, "src_audio": "/acl6060/audio/eval/530.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "tgt_ref": "Et en réalité, nous n'utilisons pas la beam search ; au contraire, toutes les approches antérieures utilisent la beam search.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 531, "src_audio": "/acl6060/audio/eval/531.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "tgt_ref": "Très bien. Ainsi, les meilleures approches sont souvent un modèle à base d'arbre.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 532, "src_audio": "/acl6060/audio/eval/532.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "tgt_ref": "Donc, dans l'ensemble, notre raisonneur est capable de dépasser significativement ce modèle à base d'arbre.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 533, "src_audio": "/acl6060/audio/eval/533.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "tgt_ref": "Mais nous pouvons voir que les nombres absolus sur MathQA ou SVAMP ne sont pas vraiment élevés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 534, "src_audio": "/acl6060/audio/eval/534.wav", "src_ref": "So we further investigate the results on SVAMP.", "tgt_ref": "Nous étudions donc plus en détail les résultats sur SVAMP.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 535, "src_audio": "/acl6060/audio/eval/535.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "tgt_ref": "Et ces données sont difficiles parce que l'auteur a essayé d'ajouter manuellement quelque chose pour confondre le modèle TAL traitement automatique du langage naturel comme ajouter des informations non pertinentes et des quantités supplémentaires.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 536, "src_audio": "/acl6060/audio/eval/536.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "tgt_ref": "Donc, dans notre prévention, nous trouvons que certaines des valeurs intermédiaires sont en réalité négatives.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 537, "src_audio": "/acl6060/audio/eval/537.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "tgt_ref": "Par exemple, dans ces questions, nous demandons « combien de pommes a Jake ? »", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 538, "src_audio": "/acl6060/audio/eval/538.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "tgt_ref": "Mais nous avons des informations supplémentaires comme « dix-sept photos de moins », et « Steven en a huit », ce qui est totalement hors de propos.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 539, "src_audio": "/acl6060/audio/eval/539.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "tgt_ref": "Ainsi, notre modèle effectue une prévention comme celle-ci qui produit des valeurs négatives.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 540, "src_audio": "/acl6060/audio/eval/540.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "tgt_ref": "Et nous constatons que ces deux expressions ont en réalité des scores similaires.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 541, "src_audio": "/acl6060/audio/eval/541.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "tgt_ref": "Nous pouvons alors limiter cet espace de recherche en supprimant les résultats négatifs afin que nous puissions rendre la réponse correcte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 542, "src_audio": "/acl6060/audio/eval/542.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "tgt_ref": "Nous trouvons donc que cette contrainte améliore en réalité beaucoup pour certains modèles.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 4, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 543, "src_audio": "/acl6060/audio/eval/543.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "tgt_ref": "Par exemple, pour les Représentations d'encodeurs bidirectionnels à partir de transformateurs, nous améliorons sept points, puis pour le modèle de base Roberta, nous avons amélioré deux points.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 544, "src_audio": "/acl6060/audio/eval/544.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "tgt_ref": "Le meilleur modèle de langue a donc de meilleures capacités de compréhension de la langue de sorte que le nombre ici est plus élevé pour Roberta et plus bas pour les Représentations d'encodeurs bidirectionnels à partir de transformateurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 545, "src_audio": "/acl6060/audio/eval/545.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "tgt_ref": "Et nous essayons également d'analyser la difficulté derrière toutes ces données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 546, "src_audio": "/acl6060/audio/eval/546.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "tgt_ref": "Nous supposons que le nombre de quantités inutilisées peut être considéré ici comme une information non pertinente.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 547, "src_audio": "/acl6060/audio/eval/547.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "tgt_ref": "Donc ici, nous pouvons voir que nous avons le pourcentage d'échantillons avec des quantités inutilisées, et les données SVAMP ont la plus grande partie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 548, "src_audio": "/acl6060/audio/eval/548.wav", "src_ref": "And here we also show the overall performance.", "tgt_ref": "Et ici, nous montrons également la performance globale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 549, "src_audio": "/acl6060/audio/eval/549.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "tgt_ref": "Pour ces échantillons sans quantités inutilisées, la performance est en réalité supérieure à la performance globale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 550, "src_audio": "/acl6060/audio/eval/550.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "tgt_ref": "Mais avec ces échantillons ayant une quantité inutilisée, c'est en fait bien pire que la performance globale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 551, "src_audio": "/acl6060/audio/eval/551.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "tgt_ref": "Pour MAWPS, nous n'avons pas vraiment trop de cas de test, alors j'ignore simplement cette partie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 552, "src_audio": "/acl6060/audio/eval/552.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "tgt_ref": "Finalement, nous voulons montrer l'interopérabilité à travers un exemple de perturbation de question.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 553, "src_audio": "/acl6060/audio/eval/553.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "tgt_ref": "Donc ici, notre modèle effectue en réalité une prévention erronée à la première étape.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 554, "src_audio": "/acl6060/audio/eval/554.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "tgt_ref": "Ainsi, nous pouvons effectivement corréler cette expression avec la phrase ici. Très bien.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 555, "src_audio": "/acl6060/audio/eval/555.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "tgt_ref": "Nous pensons donc que cette phrase pourrait induire le modèle en erreur avec des préventions incorrectes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 556, "src_audio": "/acl6060/audio/eval/556.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "tgt_ref": "Donc ici, en planter trente-cinq autres fait penser au modèle qu'il devrait être un opérateur d'addition.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 557, "src_audio": "/acl6060/audio/eval/557.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "tgt_ref": "Nous essayons alors de réviser la phrase pour que cela soit quelque chose comme « le nombre de poiriers est inférieur de trente-cinq à celui des pommiers ».", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 5, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 558, "src_audio": "/acl6060/audio/eval/558.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "tgt_ref": "Nous faisons en sorte de transmettre une sémantique plus précise afin que le modèle soit capable de rendre la prévention correcte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 559, "src_audio": "/acl6060/audio/eval/559.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "tgt_ref": "Ainsi, cette étude montre comment les préventions interprétables nous aident à comprendre le comportement du modèle.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 560, "src_audio": "/acl6060/audio/eval/560.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "tgt_ref": "Donc, pour conclure notre travail, notre modèle est en réalité assez efficace.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 561, "src_audio": "/acl6060/audio/eval/561.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "tgt_ref": "Et nous sommes en mesure de fournir une procédure de résolution interprétable.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 562, "src_audio": "/acl6060/audio/eval/562.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "tgt_ref": "Et nous pouvons facilement incorporer des connaissances antérieures en tant que contraintes qui peuvent aider à améliorer la performance.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 563, "src_audio": "/acl6060/audio/eval/563.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "tgt_ref": "Et la dernière chose est que le mécanisme sous-jacent ne s'applique pas seulement aux tâches de résolution des problèmes de réseau, mais aussi aux autres tâches qui impliquent un raisonnement à plusieurs étapes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 564, "src_audio": "/acl6060/audio/eval/564.wav", "src_ref": "We also have certain limitations.", "tgt_ref": "Nous avons également certaines limites.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 565, "src_audio": "/acl6060/audio/eval/565.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "tgt_ref": "Si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 566, "src_audio": "/acl6060/audio/eval/566.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "tgt_ref": "Et la deuxième chose est que, comme mentionné, puisque la distribution de probabilité est déséquilibrée entre les différentes étapes de temps, il est donc également assez difficile d'appliquer la stratégie de beam search.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 567, "src_audio": "/acl6060/audio/eval/567.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "Nous arrivons donc à la fin de la discussion, et vos questions sont les bienvenues. Merci.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 568, "src_audio": "/acl6060/audio/eval/568.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "tgt_ref": "Bonjour, je m'appelle Antoine et je suis de l'Université de Maastricht.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 569, "src_audio": "/acl6060/audio/eval/569.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "tgt_ref": "Je vais vous présenter mon travail en commun avec Jerry, qui porte sur de nouvelles données pour l'extraction des articles de droit.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 570, "src_audio": "/acl6060/audio/eval/570.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "tgt_ref": "Les questions juridiques font partie intégrante de la vie de nombreuses personnes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 571, "src_audio": "/acl6060/audio/eval/571.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "tgt_ref": "Mais la majorité des citoyens ont peu de connaissances sur leurs droits et leurs processus juridiques fondamentaux.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 572, "src_audio": "/acl6060/audio/eval/572.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "tgt_ref": "En conséquence, de nombreux citoyens vulnérables qui n'ont pas les moyens de se payer l'aide coûteuse d'un expert juridique sont laissés sans protection ou, pire encore, exploités.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 6, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 573, "src_audio": "/acl6060/audio/eval/573.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "tgt_ref": "Tous les travaux visent à combler le fossé entre les personnes et la loi en développant un système d'extraction efficace pour les articles de droit.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 574, "src_audio": "/acl6060/audio/eval/574.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "tgt_ref": "Un tel système pourrait fournir un service d'aide juridique professionnel gratuit aux personnes non qualifiées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 575, "src_audio": "/acl6060/audio/eval/575.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "tgt_ref": "Avant de plonger dans la principale contribution de ce travail, nous allons d'abord décrire le problème d'extraction des articles de droit.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 576, "src_audio": "/acl6060/audio/eval/576.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "tgt_ref": "Compte tenu d'une simple question sur une question juridique telle que : « qu'est-ce que je risque si je viole la confidentialité professionnelle ? »", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 577, "src_audio": "/acl6060/audio/eval/577.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "tgt_ref": "Un modèle est nécessaire pour extraire tous les articles de droit pertinents d'un grand corpus législatif.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 578, "src_audio": "/acl6060/audio/eval/578.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "tgt_ref": "Cette tâche d'extraction des informations comporte son propre ensemble de défis.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 579, "src_audio": "/acl6060/audio/eval/579.wav", "src_ref": "First, it deals with two types of language.", "tgt_ref": "Tout d'abord, elle traite de deux types de langue.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 580, "src_audio": "/acl6060/audio/eval/580.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "tgt_ref": "La langue naturelle commune pour les questions et la langue juridique complexe pour les lois.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 581, "src_audio": "/acl6060/audio/eval/581.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "tgt_ref": "Cette différence dans les distributions de langue rend plus difficile pour un système d'extraire les candidats pertinents, car cela nécessite indirectement un système d'interprétation inhérent qui peut traduire une question naturelle en une question juridique correspondant à la terminologie des lois.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 582, "src_audio": "/acl6060/audio/eval/582.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "tgt_ref": "En outre, le droit écrit n'est pas une pile d'articles indépendants qui peuvent être traités comme une source complète d'informations par eux-mêmes, contrairement aux nouvelles ou aux recettes, par exemple.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 583, "src_audio": "/acl6060/audio/eval/583.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "tgt_ref": "Au lieu de cela, il s'agit d'un ensemble structuré de dispositions juridiques qui n'ont un sens entier que lorsqu'elles sont considérées dans le contexte global, c'est-à-dire avec les informations supplémentaires des articles voisins, les domaines et sous-domaines auxquels elles appartiennent et leur place dans la structure de la loi.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 584, "src_audio": "/acl6060/audio/eval/584.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "tgt_ref": "Enfin, les articles de droit ne sont pas de petits paragraphes constituant généralement l'unité d'extraction typique dans la plupart des travaux d'extraction.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 585, "src_audio": "/acl6060/audio/eval/585.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "tgt_ref": "Ici, il y a de longs documents qui peuvent aller jusqu'à six mille mots.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 586, "src_audio": "/acl6060/audio/eval/586.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "tgt_ref": "Les recent advances en matière de TAL traitement automatique du langage naturel ont suscité un vif intérêt pour de nombreuses tâches juridiques, telles que la prévention du jugement juridique ou l'examen des contrats de contacts automatisés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 587, "src_audio": "/acl6060/audio/eval/587.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "tgt_ref": "Mais l'extraction de l'article de droit est restée essentiellement inchangée en raison du manque de grandes données étiquetées de haute qualité.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 7, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 588, "src_audio": "/acl6060/audio/eval/588.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "tgt_ref": "Dans ce travail, nous présentons de nouvelles données centrées sur le citoyen natif français pour étudier si l'extraction des modèles peut se rapprocher de l'efficacité et de la fiabilité d'un expert juridique pour la tâche d'extraction de l'article de droit.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 589, "src_audio": "/acl6060/audio/eval/589.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "tgt_ref": "Nos données d'extraction de l'article de droit belge BSARD se composent de plus de mille cent questions juridiques posées par des citoyens belges.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 590, "src_audio": "/acl6060/audio/eval/590.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "tgt_ref": "Ces questions couvrent un wide range de sujets allant de la famille au logement, à l'argent, au travail et à la sécurité sociale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 591, "src_audio": "/acl6060/audio/eval/591.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "tgt_ref": "Chacune d'entre elles a été étiquetée par des juristes expérimentés avec des références à des articles pertinents d'un corpus de plus de vingt-deux mille six cents articles juridiques de codes de droit belge.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 592, "src_audio": "/acl6060/audio/eval/592.wav", "src_ref": "Let's now talk about how we collected this dataset.", "tgt_ref": "Parlons maintenant de la façon dont nous avons collecté ces données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 593, "src_audio": "/acl6060/audio/eval/593.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "tgt_ref": "Tout d'abord, nous avons commencé par compiler un grand corpus d'articles juridiques.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 594, "src_audio": "/acl6060/audio/eval/594.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "tgt_ref": "Nous avons examiné trente-deux codes belges accessibles au public et extrait tous les articles ainsi que les titres de section correspondants.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 595, "src_audio": "/acl6060/audio/eval/595.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "tgt_ref": "Ensuite, nous avons rassemblé les questions juridiques avec les références aux lois pertinentes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 596, "src_audio": "/acl6060/audio/eval/596.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "tgt_ref": "Pour ce faire, nous nous associons au cabinet d'avocats belge qui reçoit chaque année environ quatre mille courriels de citoyens belges demandant des conseils sur une question juridique personnelle.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 597, "src_audio": "/acl6060/audio/eval/597.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "tgt_ref": "Nous avons eu la chance d'avoir accès à leurs sites web, où leur équipe de juristes expérimentés aborde les questions juridiques les plus courantes des Belges.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 598, "src_audio": "/acl6060/audio/eval/598.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "tgt_ref": "Nous avons recueilli des milliers de questions annotées avec des catégories, des sous-catégories et des références juridiques aux lois pertinentes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 599, "src_audio": "/acl6060/audio/eval/599.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "tgt_ref": "Enfin, nous avons fait passer les références juridiques et filtré les questions dont les références n'étaient pas des articles dans l'un des codes de droit que nous avons considérés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 600, "src_audio": "/acl6060/audio/eval/600.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "tgt_ref": "Les références restantes ont été appariées et converties aux identifiants d'article correspondants de notre corpus.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 601, "src_audio": "/acl6060/audio/eval/601.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "tgt_ref": "Nous nous sommes finalement retrouvés avec mille cent huit questions, chacune soigneusement étiquetée avec les identifiants des articles pertinents de notre grand corpus de vingt-deux mille six cent trente-trois articles de droit.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 602, "src_audio": "/acl6060/audio/eval/602.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "tgt_ref": "De plus, chaque question est accompagnée de la catégorie principale et d'un enchaînement de sous-catégories.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 8, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 603, "src_audio": "/acl6060/audio/eval/603.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "tgt_ref": "Et chaque article comporte un enchaînement de la rubrique de sous-séquence dans la structure de la loi.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 604, "src_audio": "/acl6060/audio/eval/604.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "tgt_ref": "Ces informations supplémentaires ne sont pas utilisées dans le présent travail, mais pourraient présenter un intérêt pour des recherches futures sur l'extraction d'informations juridiques ou la classification de textes juridiques.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 605, "src_audio": "/acl6060/audio/eval/605.wav", "src_ref": "Let's look at some characteristic of our dataset.", "tgt_ref": "Jetons un coup d'œil à certaines caractéristiques de nos données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 606, "src_audio": "/acl6060/audio/eval/606.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "tgt_ref": "Les questions comportent entre cinq et quarante-quatre mots avec une moyenne de quatorze mots.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 607, "src_audio": "/acl6060/audio/eval/607.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "tgt_ref": "Les articles sont beaucoup plus longs avec une longueur moyenne de soixante-dix-sept mots, avec cent quarante-deux d'entre eux dépassant les mille mots.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 608, "src_audio": "/acl6060/audio/eval/608.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "tgt_ref": "Le plus long étant jusqu'à cinq mille sept cent quatre-vingt-dix mots.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 609, "src_audio": "/acl6060/audio/eval/609.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "tgt_ref": "Comme mentionné précédemment, les questions couvrent un wide range de sujets, dont environ quatre-vingt-cinq pour cent concernent la famille, le logement, l'argent ou la justice.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 610, "src_audio": "/acl6060/audio/eval/610.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "tgt_ref": "Alors que les quinze pour cent restants concernent la sécurité sociale, les étrangers ou le travail.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 611, "src_audio": "/acl6060/audio/eval/611.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "tgt_ref": "L'article est également très diversifié car il provient de trente-deux codes belges différents qui couvrent un grand nombre de sujets juridiques.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 612, "src_audio": "/acl6060/audio/eval/612.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "tgt_ref": "Voici le nombre total d'articles collectés à partir de chacun de ces codes belges.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 613, "src_audio": "/acl6060/audio/eval/613.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "tgt_ref": "Sur les vingt-deux mille six cent trente-trois articles, seuls mille six cent douze sont désignés comme pertinents à au moins une question dans les données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 614, "src_audio": "/acl6060/audio/eval/614.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "tgt_ref": "Et environ quatre-vingts pour cent de ces articles cités proviennent du code civil, des codes judiciaires, des codes d'enquête criminelle ou des codes pénaux.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 615, "src_audio": "/acl6060/audio/eval/615.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "tgt_ref": "Pendant ce temps, dix-huit des trente-deux codes ont moins de cinq articles mentionnés comme pertinents pour au moins une question.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 616, "src_audio": "/acl6060/audio/eval/616.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "tgt_ref": "Ce qui peut s'expliquer par le fait que ces codes se concentraient moins sur les individus et leurs préoccupations.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 617, "src_audio": "/acl6060/audio/eval/617.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "tgt_ref": "Dans l'ensemble, le nombre moyen de citations pour ces articles cités est de deux, et moins de vingt-cinq pour cent d'entre eux sont cités plus de cinq fois.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 9, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 618, "src_audio": "/acl6060/audio/eval/618.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "tgt_ref": "En utilisant toutes les données, nous avons comparé plusieurs approches d'extraction, y compris l'architecture lexicale et dense.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 619, "src_audio": "/acl6060/audio/eval/619.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "tgt_ref": "Étant donné une requête et un article, un modèle lexical attribue un score à la paire d'articles de requête en calculant la somme sur les termes de requête des poids de chacun de ces termes dans cet article.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 620, "src_audio": "/acl6060/audio/eval/620.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "tgt_ref": "Nous expérimentons avec les fonctions de classement TF-IDF et BM25 standard.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 621, "src_audio": "/acl6060/audio/eval/621.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "tgt_ref": "Le principal problème de ces approches est qu'elles ne peuvent extraire que les articles contenant des mots-clés présents dans la requête.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 622, "src_audio": "/acl6060/audio/eval/622.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "tgt_ref": "Pour surmonter cette limitation, nous expérimentons une architecture neuronale qui peut capturer les relations sémantiques entre les requêtes et l'article.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 623, "src_audio": "/acl6060/audio/eval/623.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "tgt_ref": "Nous utilisons un modèle bi-encodeur qui cartographie les requêtes et les articles en représentations vecteurs denses et calculons un score de pertinence entre une paire d'articles de requête par la similitude de leurs intégrations.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 624, "src_audio": "/acl6060/audio/eval/624.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "tgt_ref": "Ces intégrations résultent typiquement d'une opération de pooling sur la sortie d'un modèle d'intégration de mots.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 625, "src_audio": "/acl6060/audio/eval/625.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "tgt_ref": "Tout d'abord, nous étudions l'efficacité des bi-encodeurs siamois dans une configuration d'évaluation « zero shot », ce qui signifie que des modèles d'intégration de mots préformés sont appliqués immédiatement sans aucun raffinement supplémentaire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 626, "src_audio": "/acl6060/audio/eval/626.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "tgt_ref": "Nous expérimentons avec l'encodeur de texte indépendant du contexte, à savoir word2vec et fastText, et des modèles d'intégration dépendants du contexte, à savoir Roberta et plus précisément CamemBERT qui est un modèle Roberta français.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 627, "src_audio": "/acl6060/audio/eval/627.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "tgt_ref": "De plus, nous formons nos propres bi-encodeurs de modèles basés sur CamemBERT sur nos données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 628, "src_audio": "/acl6060/audio/eval/628.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "tgt_ref": "Notez que pour la formation, nous expérimentons avec les deux modèles de l'architecture bi-encodeur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 629, "src_audio": "/acl6060/audio/eval/629.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "tgt_ref": "Le siamois, qui utilise un modèle d'intégration de mots unique cartographiant la requête et l'article ensemble dans un vector space dense partagé, et le modèle à deux tours, qui utilise deux modèles d'intégration de mots indépendants encodant la requête et l'article séparément dans différents espaces d'intégration.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 630, "src_audio": "/acl6060/audio/eval/630.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "tgt_ref": "Nous expérimentons la mise en commun moyenne, maximale et CLS, ainsi que le produit et cosinus pour calculer les similitudes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 631, "src_audio": "/acl6060/audio/eval/631.wav", "src_ref": "Here are the result of our baseline on the test sets.", "tgt_ref": "Voici le résultat de notre base sur les ensembles de test.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 632, "src_audio": "/acl6060/audio/eval/632.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "tgt_ref": "Avec les méthodes lexicales ci-dessus, les bi-encodeurs siamois ont évalué dans une configuration zero shot au milieu, et les bi-encodeurs raffinés ci-dessous.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 10, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 633, "src_audio": "/acl6060/audio/eval/633.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "tgt_ref": "Dans l'ensemble, le bi-encodeur raffiné dépasse de manière significative toutes les autres bases.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 634, "src_audio": "/acl6060/audio/eval/634.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "tgt_ref": "Le modèle à deux tours s'améliore par rapport à ses variantes siamoises lors du rappel à cent, mais fonctionne de la même manière sur les autres indicateurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 635, "src_audio": "/acl6060/audio/eval/635.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "tgt_ref": "Bien que BM25 ait sous-performé le bi-encodeur formé de manière significative, ses performances indiquent qu'il s'agit toujours d'une base solide pour l'extraction spécifique au domaine.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 636, "src_audio": "/acl6060/audio/eval/636.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "tgt_ref": "En ce qui concerne l'évaluation zero shot du bi-encodeur siamois, nous constatons que l'utilisation directe des intégrations d'un modèle CamemBERT préformé sans optimiser pour la tâche d'extraction d'informations donne de mauvais résultats, ce qui est cohérent avec les résultats antérieurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 637, "src_audio": "/acl6060/audio/eval/637.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "tgt_ref": "En outre, nous observons que le bi-encodeur basé sur word2vec a dépassé de manière significative les modèles basés sur fastText et les Représentations d'encodeurs bidirectionnels à partir de transformateurs, suggérant que peut-être les intégrations de niveau mot préformées sont plus appropriées pour la tâche que les intégrations de niveau caractère ou sous-mot lorsqu'elles sont utilisées immédiatement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 638, "src_audio": "/acl6060/audio/eval/638.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "tgt_ref": "Bien que prometteurs, ces résultats suggèrent de nombreuses possibilités d'amélioration comparé à un expert juridique qualifié qui peut éventuellement extraire tous les articles pertinents à n'importe quelle question, et ainsi obtenir des scores parfaits.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 639, "src_audio": "/acl6060/audio/eval/639.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "tgt_ref": "Concluons en discutant de deux limites de nos données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 640, "src_audio": "/acl6060/audio/eval/640.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "tgt_ref": "Premièrement, le corpus d'article est limité à ceux collectés à partir des trente-deux codes belges considérés, ce qui ne couvre pas l'ensemble du droit belge car les articles des décrets, directives et ordonnances sont manquants.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 641, "src_audio": "/acl6060/audio/eval/641.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "tgt_ref": "Au cours de la construction des données, toutes les références à ces articles non collectés sont ignorées, ce qui fait que certaines questions ne se retrouvent qu'avec une fraction du nombre initial d'articles pertinents.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 642, "src_audio": "/acl6060/audio/eval/642.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "tgt_ref": "Cette information implique donc que la réponse contenue dans les autres articles pertinents pourrait être incomplète, bien qu'elle soit toujours tout à fait appropriée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 643, "src_audio": "/acl6060/audio/eval/643.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "tgt_ref": "Deuxièmement, il convient de noter qu'on ne peut pas répondre à toutes les questions juridiques uniquement par des lois.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 644, "src_audio": "/acl6060/audio/eval/644.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "tgt_ref": "Par exemple, la question « puis-je expulser mes locataires s'ils font trop de bruit ? »", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 645, "src_audio": "/acl6060/audio/eval/645.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "tgt_ref": "Elle peut ne pas avoir de réponse détaillée dans le droit écrit qui quantifie un seuil de bruit spécifique à partir duquel l'expulsion est autorisée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 646, "src_audio": "/acl6060/audio/eval/646.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "tgt_ref": "Au lieu de cela, le propriétaire devrait probablement s'appuyer davantage sur la jurisprudence et trouver des antécédents similaires à sa situation actuelle.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 647, "src_audio": "/acl6060/audio/eval/647.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "tgt_ref": "Par exemple, les locataires font la fête deux fois par semaine jusqu'à deux heures du matin.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 11, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 648, "src_audio": "/acl6060/audio/eval/648.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "tgt_ref": "Par conséquent, certaines questions sont mieux adaptées que d'autres à la tâche d'extraction de l'article de droit, et le domaine des moins adaptées reste à déterminer.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 649, "src_audio": "/acl6060/audio/eval/649.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "tgt_ref": "Nous espérons que nos travaux susciteront l'intérêt pour l'élaboration de modèles d'extraction d'article de droit pratiques et fiables.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 650, "src_audio": "/acl6060/audio/eval/650.wav", "src_ref": "That can help improve access to justice for all.", "tgt_ref": "Cela peut aider à améliorer l'accès à la justice pour tous.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 651, "src_audio": "/acl6060/audio/eval/651.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "Vous pouvez consulter notre article, nos données et notre code aux liens suivants. Merci.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 652, "src_audio": "/acl6060/audio/eval/652.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "tgt_ref": "Bonjour, nous sommes heureux de vous présenter notre travail sur VALSE ; un indice de référence indépendant de la tâche destiné à tester les modèles de langue et de vision avec des phénomènes linguistiques spécifiques.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 653, "src_audio": "/acl6060/audio/eval/653.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "tgt_ref": "Pourquoi avons-nous pris la peine de mettre en place cet indice de référence ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 654, "src_audio": "/acl6060/audio/eval/654.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "tgt_ref": "Eh bien, au cours des dernières années, nous avons vu une explosion de la vision basée sur le transformateur et des modèles de langue préformés sur de grandes quantités de paires de textes d'images.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 655, "src_audio": "/acl6060/audio/eval/655.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "tgt_ref": "Chacun de ces modèles pousse les tâches de pointe en matière de vision et de langue telles que la réponse aux questions visuelles, le raisonnement de bon sens visuel, l'extraction d'images et les bases de phrases.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 656, "src_audio": "/acl6060/audio/eval/656.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "tgt_ref": "Nous avons donc reçu un message : les précisions sur ces tâches et les indices de référence spécifiques augmentent régulièrement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 657, "src_audio": "/acl6060/audio/eval/657.wav", "src_ref": "But do we know what the models have actually learned?", "tgt_ref": "Mais savons-nous ce que les modèles ont réellement appris ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 658, "src_audio": "/acl6060/audio/eval/658.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "tgt_ref": "Qu'est-ce qu'une vision et un transformateur de langue ont compris lors de l'attribution d'un score élevé pour que cette image et cette phrase correspondent ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 659, "src_audio": "/acl6060/audio/eval/659.wav", "src_ref": "And the low score for this one?", "tgt_ref": "Et le score bas pour celle-ci ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 660, "src_audio": "/acl6060/audio/eval/660.wav", "src_ref": "Do vision and language models focus on the right thing?", "tgt_ref": "Est-ce que les modèles de langue et de vision se concentrent sur la bonne chose ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 661, "src_audio": "/acl6060/audio/eval/661.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "tgt_ref": "Ou se concentrent-ils sur les biais comme le montre le travail antérieur ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 662, "src_audio": "/acl6060/audio/eval/662.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "tgt_ref": "Pour éclairer davantage cet aspect, nous proposons une direction plus indépendante des tâches et introduisons VALSE qui teste la sensibilité des modèles de langue et de vision à des phénomènes linguistiques spécifiques affectant à la fois les modalités linguistiques et visuelles.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 12, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 663, "src_audio": "/acl6060/audio/eval/663.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "tgt_ref": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la coréférence sur les entités.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 664, "src_audio": "/acl6060/audio/eval/664.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "tgt_ref": "Mais comment tester si les modèles de langue et de vision ont capturé ce phénomène ?", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 665, "src_audio": "/acl6060/audio/eval/665.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "tgt_ref": "En pratiquant le foiling sur une méthode précédemment appliquée pour les modèles de langue et de vision seulement pour des phrases nominales de Ravi Shekhar et de ses collaborateurs, et en comptant par nous dans les travaux antérieurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 666, "src_audio": "/acl6060/audio/eval/666.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "tgt_ref": "Effectuer un foiling signifie essentiellement que nous prenons la légende d'une image et produisons un foil en modifiant la légende de sorte qu'elle ne décrive plus l'image.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 667, "src_audio": "/acl6060/audio/eval/667.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "tgt_ref": "Et nous apportons ces modifications de phrases en nous concentrant sur six éléments spécifiques tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la coréférence sur les entités, où chaque élément peut consister en un ou plusieurs instruments, au cas où nous aurions trouvé plus d'une façon intéressante de créer des instances de foil.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 668, "src_audio": "/acl6060/audio/eval/668.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "tgt_ref": "Par exemple, dans le cas de l'élément d'actions, nous avons deux instruments, un dans lequel le verbe d'action est modifié avec une action différente, et un dans lequel les acteurs sont échangés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 669, "src_audio": "/acl6060/audio/eval/669.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "tgt_ref": "Le comptage et la coréférence sont également des éléments qui ont plusieurs instruments.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 670, "src_audio": "/acl6060/audio/eval/670.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "tgt_ref": "Et nous créons ces foils en nous assurant qu'ils ne décrivent pas l'image et que ce sont des phrases grammaticales et autrement valides.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 671, "src_audio": "/acl6060/audio/eval/671.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "tgt_ref": "Ce n'est pas facile à faire car une légende ayant subi un foil peut être moins probable que la légende originale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 672, "src_audio": "/acl6060/audio/eval/672.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "tgt_ref": "Par exemple, bien que ce ne soit pas impossible, il est statistiquement moins probable que les plantes coupent un homme qu'un homme coupe les plantes, et la grande vision et les modèles de langue pourraient capter cela.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 673, "src_audio": "/acl6060/audio/eval/673.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "tgt_ref": "Par conséquent, pour obtenir des foils valides, nous devons agir.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 674, "src_audio": "/acl6060/audio/eval/674.wav", "src_ref": "First, we make use of strong language models to propose foils.", "tgt_ref": "Tout d'abord, nous utilisons des modèles de langue forts pour proposer des foils.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 675, "src_audio": "/acl6060/audio/eval/675.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "tgt_ref": "Deuxièmement, nous utilisons l'inférence de la langue naturelle ou la NLI courte pour filtrer les foils qui pourraient encore décrire l'image, car lors de la construction des foils, nous devons nous assurer qu'ils ne décrivent pas l'image.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 676, "src_audio": "/acl6060/audio/eval/676.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "tgt_ref": "Pour tester cela automatiquement, nous appliquons l'inférence de la langue naturelle avec la justification suivante.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 677, "src_audio": "/acl6060/audio/eval/677.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "tgt_ref": "Nous considérons qu'une image est la prémisse et sa légende son hypothèse implicite.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 13, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 678, "src_audio": "/acl6060/audio/eval/678.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "tgt_ref": "En outre, nous considérons la légende comme la prémisse, et le foil est son hypothèse.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 679, "src_audio": "/acl6060/audio/eval/679.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "tgt_ref": "Si un modèle NLI prévient que le foil est en contradiction ou neutre par rapport à la légende, nous considérons cela comme un indicateur d'un foil valide.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 680, "src_audio": "/acl6060/audio/eval/680.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "tgt_ref": "Si une NLI prévient le foil à engendrer par la légende, cela ne peut pas être un bon foil, car par transitivité, cela donnera une description véridique de l'image et nous filtrons ces foils.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 681, "src_audio": "/acl6060/audio/eval/681.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "tgt_ref": "Mais cette procédure n'est pas parfaite, il s'agit simplement d'un indicateur pour les foils valides.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 682, "src_audio": "/acl6060/audio/eval/682.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "tgt_ref": "Par conséquent, comme troisième mesure pour produire des foils valides, nous utilisons des annotateurs humains pour valider les données utilisées dans VALSE.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 683, "src_audio": "/acl6060/audio/eval/683.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "tgt_ref": "Donc, après filtrage et évaluation humaine, nous avons autant d'instances de test que décrit dans ce tableau.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 684, "src_audio": "/acl6060/audio/eval/684.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "tgt_ref": "Notez que VALSE ne fournit pas de données de formation mais seulement des données de test.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 685, "src_audio": "/acl6060/audio/eval/685.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "tgt_ref": "Comme il s'agit uniquement d'un indicateur de référence de test zero shot, il est conçu pour tirer parti des capacités existantes des modèles de langue et de vision après la préformation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 686, "src_audio": "/acl6060/audio/eval/686.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "tgt_ref": "Le raffinement permettrait seulement aux modèles d'exploiter des artefacts ou des biais statistiques dans les données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 687, "src_audio": "/acl6060/audio/eval/687.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "tgt_ref": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 688, "src_audio": "/acl6060/audio/eval/688.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "tgt_ref": "Et comme nous l'avons dit, cela nous intéresse d'évaluer les capacités des modèles de langue et de vision après la préformation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 689, "src_audio": "/acl6060/audio/eval/689.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "tgt_ref": "Nous expérimentons avec cinq modèles de langue et de vision sur VALSE, à savoir avec CLIP, LXMert, ViLBERT, ViLBERT douze en un, et VisualBERT.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 690, "src_audio": "/acl6060/audio/eval/690.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "tgt_ref": "Deux de nos indicateurs d'évaluation les plus importants sont la précision des modèles dans la classification de paires de phrases images en légendes et foils.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 691, "src_audio": "/acl6060/audio/eval/691.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "tgt_ref": "Peut-être plus pertinent pour cette vidéo, nous présenterons notre indicateur plus permissif, la précision par paire, qui mesure si le score de sentence alignment d'image est plus élevé pour la bonne paire de texte image que pour sa paire ayant subi un foil.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 692, "src_audio": "/acl6060/audio/eval/692.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "tgt_ref": "Pour plus d'indicateurs et de résultats, consultez notre article.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 14, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 693, "src_audio": "/acl6060/audio/eval/693.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "tgt_ref": "Les résultats avec une précision par paire sont montrés ici et ils sont cohérents avec les résultats que nous avons obtenus des autres indicateurs. La meilleure performance zero shot est obtenue par ViLBERT douze en un, suivi de ViLBERT, LXMert, CLIP, et enfin VisualBERT.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 694, "src_audio": "/acl6060/audio/eval/694.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "tgt_ref": "Il est remarquable de voir comment les instruments centrés sur les objets individuels comme l'existence et les phrases nominales sont presque résolus par ViLBERT douze en un, en soulignant que les modèles sont capables d'identifier des objets nommés et leur présence dans les images.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 695, "src_audio": "/acl6060/audio/eval/695.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "tgt_ref": "Cependant, aucun des éléments restants ne peut être résolu de manière fiable dans nos paramètres de foiling antagonistes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 696, "src_audio": "/acl6060/audio/eval/696.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "tgt_ref": "Nous voyons à partir des instruments de pluralité et de comptage que les modèles de langue et de vision ont du mal à distinguer les références à des objets uniques par rapport à plusieurs, ou à les compter dans une image.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 697, "src_audio": "/acl6060/audio/eval/697.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "tgt_ref": "L'élément de relation montre qu'ils ont des difficultés à classer correctement une relation spatiale nommée entre des objets dans une image.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 698, "src_audio": "/acl6060/audio/eval/698.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "tgt_ref": "Ils ont également du mal à distinguer les actions et à identifier leurs participants, même s'ils sont soutenus par des biais de plausibilité comme nous le voyons dans l'élément d'actions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 699, "src_audio": "/acl6060/audio/eval/699.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "tgt_ref": "À partir de l'élément de coréférence, nous découvrons que relever plusieurs références au même objet dans une image en utilisant des pronoms est également difficile pour les modèles de langue et de vision.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 700, "src_audio": "/acl6060/audio/eval/700.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "tgt_ref": "Pour vérifier la santé mentale, et parce que c'est une expérience intéressante, nous comparons également deux modèles à texte seulement, GPT un et GPT deux, pour évaluer si VALSE peut être résolu par ces modèles unimodaux en calculant la perplexité de la légende correcte et ayant subi un foil, sans image ici, et en prévenant l'entrée avec la plus faible perplexité.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 701, "src_audio": "/acl6060/audio/eval/701.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "tgt_ref": "Si la perplexité est plus élevée pour le foil, nous considérons cela comme une indication que la légende ayant subi un foil peut souffrir de biais de plausibilité ou d'autres biais linguistiques.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 702, "src_audio": "/acl6060/audio/eval/702.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "tgt_ref": "Et il est intéressant de voir que dans certains cas, les modèles GPT à texte seulement ont capturé la plausibilité du monde mieux que les modèles de langue et de vision.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 703, "src_audio": "/acl6060/audio/eval/703.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "tgt_ref": "Donc, pour résumer, VALSE est un indicateur de référence qui utilise l'objectif des constructions linguistiques pour aider la communauté à améliorer les modèles de langue et de vision en testant durement leurs capacités de bases visuelles.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 704, "src_audio": "/acl6060/audio/eval/704.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "tgt_ref": "Nos expériences montrent que les modèles de langue et de vision identifient bien les objets nommés et leur présence dans les images, comme le montre l'élément d'existence, mais luttent pour ancrer leur interdépendance et leurs relations dans des scènes visuelles lorsqu'ils sont forcés de respecter des indicateurs linguistiques.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 705, "src_audio": "/acl6060/audio/eval/705.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "tgt_ref": "Nous aimerions vraiment encourager la communauté à utiliser VALSE pour mesurer les progrès vers les bases de la langue avec des modèles de langue et de vision.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 706, "src_audio": "/acl6060/audio/eval/706.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "tgt_ref": "Et plus encore, VALSE pourrait être utilisé comme une évaluation indirecte des données, car les modèles pourraient être évalués avant et après la formation ou le raffinement pour voir si des données aident les modèles à améliorer l'un des aspects testés par VALSE.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 707, "src_audio": "/acl6060/audio/eval/707.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "Si vous êtes intéressé, consultez les données VALSE sur GitHub, et si vous avez des questions, n'hésitez pas à nous contacter.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 15, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 708, "src_audio": "/acl6060/audio/eval/708.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "tgt_ref": "Bonjour, je m'appelle Kamezawa de l'Université de Tokyo.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 709, "src_audio": "/acl6060/audio/eval/709.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "tgt_ref": "Je vais vous présenter un article intitulé RNSum : des données à grande échelle pour la génération automatique de note de version via la synthèse des journaux de validation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 710, "src_audio": "/acl6060/audio/eval/710.wav", "src_ref": "I'll be explaining in this order.", "tgt_ref": "Je vais vous expliquer dans cet ordre.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 711, "src_audio": "/acl6060/audio/eval/711.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "tgt_ref": "Tout d'abord, je vais présenter la génération de note de version automatique sur laquelle nous travaillons dans cette recherche.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 712, "src_audio": "/acl6060/audio/eval/712.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "tgt_ref": "Une note de version est un document technique qui résume les modifications distribuées à chaque version d'un produit logiciel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 713, "src_audio": "/acl6060/audio/eval/713.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "tgt_ref": "L'image montre une note de version pour la version deux point six point quatre de la bibliothèque Vuejs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 714, "src_audio": "/acl6060/audio/eval/714.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "tgt_ref": "Les notes de version jouent un rôle important dans le développement open source, mais elles mettent du temps à être préparées manuellement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 715, "src_audio": "/acl6060/audio/eval/715.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "tgt_ref": "Par conséquent, il serait très utile de pouvoir générer automatiquement des notes de version de haute qualité.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 716, "src_audio": "/acl6060/audio/eval/716.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "tgt_ref": "Je m'en remettrai à deux recherches antérieures sur la génération automatique de notes de version.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 717, "src_audio": "/acl6060/audio/eval/717.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "tgt_ref": "La première est un système appelé ARENA sorti en deux-mille-quatorze.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 718, "src_audio": "/acl6060/audio/eval/718.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "tgt_ref": "Il faut une approche basée sur des règles, par exemple, en utilisant l'extracteur de changement pour extraire toutes les différences, les changements de bibliothèque et les changements de document à partir des différences entre les versions, et enfin, en les combinant.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 719, "src_audio": "/acl6060/audio/eval/719.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "tgt_ref": "La caractéristique la plus notable de ce système est l'extracteur de problèmes dans le coin supérieur droit.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 720, "src_audio": "/acl6060/audio/eval/720.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "tgt_ref": "Le système de suivi des problèmes, qui doit être laissé à Jira, ne peut être appliqué qu'aux projets qui utilisent Jira.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 721, "src_audio": "/acl6060/audio/eval/721.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "tgt_ref": "En d'autres mots, il ne peut pas être utilisé pour de nombreux projets sur GitHub.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 722, "src_audio": "/acl6060/audio/eval/722.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "tgt_ref": "La seconde est Glyphe, récemment annoncée en deux-mille-vingt.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 16, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 723, "src_audio": "/acl6060/audio/eval/723.wav", "src_ref": "It is available on the internet and can be installed via pip.", "tgt_ref": "Elle est disponible sur internet et peut être installée via pip.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 724, "src_audio": "/acl6060/audio/eval/724.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "tgt_ref": "Ce système a un modèle de classification de texte basé sur l'apprentissage simple et produit l'une des cinq étiquettes telles que les fonctions ou corrections de bugs pour chaque message de validation de saisie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 725, "src_audio": "/acl6060/audio/eval/725.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "tgt_ref": "Cette image est un exemple d'utilisation qui renvoie une étiquette de correction ou de débogage.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 726, "src_audio": "/acl6060/audio/eval/726.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "tgt_ref": "Les données de formation de Glyphe sont assez petites, environ cinq mille, et seront montrées dans les expériences décrites ci-dessous.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 727, "src_audio": "/acl6060/audio/eval/727.wav", "src_ref": "The performance of the text classification model is not high.", "tgt_ref": "Les performances du modèle de classification de texte ne sont pas élevées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 728, "src_audio": "/acl6060/audio/eval/728.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "tgt_ref": "Je présente deux recherches connexes, mais leurs problèmes sont l'applicabilité limitée et les ressources de données rares.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 729, "src_audio": "/acl6060/audio/eval/729.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "tgt_ref": "Notre article résout ces deux problèmes et génère automatiquement des notes de version de haute qualité.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 730, "src_audio": "/acl6060/audio/eval/730.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "tgt_ref": "Avec un problème d'applicabilité limitée, nous proposons une méthode de synthèse par classe de haute qualité en utilisant uniquement des messages de validation comme saisie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 731, "src_audio": "/acl6060/audio/eval/731.wav", "src_ref": "This proposed method can be used for all English repositories.", "tgt_ref": "Cette méthode proposée peut être utilisée pour tous les référentiels anglais.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 732, "src_audio": "/acl6060/audio/eval/732.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "tgt_ref": "Pour le deuxième problème de ressources de données rares, nous avons construit nos données RNSum composées d'environ quatre-vingt-deux mille éléments de données en collectant des données à partir de référentiels GitHub publics en utilisant l'API GitHub.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 733, "src_audio": "/acl6060/audio/eval/733.wav", "src_ref": "Next, I'll describe our dataset.", "tgt_ref": "Ensuite, je vais décrire nos données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 734, "src_audio": "/acl6060/audio/eval/734.wav", "src_ref": "Here is an example of data.", "tgt_ref": "Voici un exemple de données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 735, "src_audio": "/acl6060/audio/eval/735.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "tgt_ref": "Le côté gauche est un message de validation et le côté droit représente les notes de version.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 736, "src_audio": "/acl6060/audio/eval/736.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "tgt_ref": "Les notes de version sont étiquetées comme améliorations ou correctifs, etc.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 737, "src_audio": "/acl6060/audio/eval/737.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "tgt_ref": "Nous avons mis en place une tâche qui prend les messages de validation comme saisie et sorties des notes de version étiquetées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 17, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 738, "src_audio": "/acl6060/audio/eval/738.wav", "src_ref": "This can be regarded as a summarization task.", "tgt_ref": "Cela peut être considéré comme une tâche de synthèse.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 739, "src_audio": "/acl6060/audio/eval/739.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "tgt_ref": "Nous avons prédéfini quatre étiquettes : fonctions, améliorations, corrections de bugs, suppressions de dépréciations et modifications de rupture.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 740, "src_audio": "/acl6060/audio/eval/740.wav", "src_ref": "These were set based on previous research and other factors.", "tgt_ref": "Celles-ci ont été établies sur la base de la recherche antérieure et d'autres facteurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 741, "src_audio": "/acl6060/audio/eval/741.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "tgt_ref": "La note de version en bas à droite est extraite de la note de version en bas à gauche.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 742, "src_audio": "/acl6060/audio/eval/742.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "tgt_ref": "À ce stade, il est nécessaire de détecter les quatre étiquettes qui ont été mises en place à l'avance.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 743, "src_audio": "/acl6060/audio/eval/743.wav", "src_ref": "But the labels are not always consistent with each repository.", "tgt_ref": "Mais les étiquettes ne sont pas toujours cohérentes avec chaque référentiel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 744, "src_audio": "/acl6060/audio/eval/744.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "tgt_ref": "Par exemple, l'étiquette d'améliorations inclut des améliorations, des perfectionnements, des optimisations, etc.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 745, "src_audio": "/acl6060/audio/eval/745.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "tgt_ref": "Nous avons préparé une liste de vocabulaire d'une trentaine d'étiquettes pour chacune de ces variations de notation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 746, "src_audio": "/acl6060/audio/eval/746.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "tgt_ref": "Il s'agit de détecter la classe de note de version et de collecter le texte de la version qui suit en tant que phrase de note de version pour la classe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 747, "src_audio": "/acl6060/audio/eval/747.wav", "src_ref": "Next is a commit message.", "tgt_ref": "Ensuite, il y a un message de validation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 748, "src_audio": "/acl6060/audio/eval/748.wav", "src_ref": "Commit messages are not tied to each release.", "tgt_ref": "Les messages de validation ne sont pas liés à chaque version.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 749, "src_audio": "/acl6060/audio/eval/749.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "tgt_ref": "Comme le montre l'image ci-dessous, si la version actuelle est la version deux point cinq à dix-neuf, nous devons identifier la version deux point cinq à dix-huit antérieure et obtenir un diff.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 750, "src_audio": "/acl6060/audio/eval/750.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "tgt_ref": "C'est un peu fastidieux et il ne suffit pas d'obtenir une liste de versions et de regarder l'avant et l'après.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 751, "src_audio": "/acl6060/audio/eval/751.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "tgt_ref": "Nous avons créé une règle de correspondance heuristique pour obtenir les versions antérieures et suivantes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 752, "src_audio": "/acl6060/audio/eval/752.wav", "src_ref": "Dataset analysis.", "tgt_ref": "Analyse des données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 18, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 753, "src_audio": "/acl6060/audio/eval/753.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "tgt_ref": "En fin de compte, sept mille deux cents dépôts et quatre-vingt-deux mille éléments de données ont été recueillis.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 754, "src_audio": "/acl6060/audio/eval/754.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "tgt_ref": "En outre, le nombre moyen de gages de notes de version est de soixante-trois, ce qui est assez élevé pour une tâche de synthèse.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 755, "src_audio": "/acl6060/audio/eval/755.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "tgt_ref": "De même, le nombre de gages uniques est assez grand, s'élevant à huit mille huit cent trente mille.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 756, "src_audio": "/acl6060/audio/eval/756.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "tgt_ref": "Cela est dû au grand nombre de noms de méthode ou de classe unique trouvés dans le référentiel.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 757, "src_audio": "/acl6060/audio/eval/757.wav", "src_ref": "Next, I will explain the proposed method.", "tgt_ref": "Ensuite, je vais expliquer la méthode proposée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 758, "src_audio": "/acl6060/audio/eval/758.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "tgt_ref": "Le modèle de synthèse extractive puis abstractive par classe se compose de deux modules neuronaux.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 759, "src_audio": "/acl6060/audio/eval/759.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "tgt_ref": "Un classificateur utilisant BERT ou CodeBERT et un générateur utilisant BART.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 760, "src_audio": "/acl6060/audio/eval/760.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "tgt_ref": "Tout d'abord, CEAS utilise un classificateur pour classer chaque message de validation en cinq classes de notes de version, qui utilisent des améliorations, des corrections de bogues, des dépréciations et d'autres.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 761, "src_audio": "/acl6060/audio/eval/761.wav", "src_ref": "The commit messages classified as other are discarded.", "tgt_ref": "Les messages de validation classés comme autres sont supprimés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 762, "src_audio": "/acl6060/audio/eval/762.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "tgt_ref": "Ensuite, CEAS applique le générateur aux quatre documents étiquetés indépendamment et génère des notes de version pour chaque classe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 763, "src_audio": "/acl6060/audio/eval/763.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "tgt_ref": "Dans cette tâche, les correspondances directes entre les messages de validation et les notes de version ne sont pas connues.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 764, "src_audio": "/acl6060/audio/eval/764.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "tgt_ref": "Par conséquent, pour former le classificateur, nous avons réaffecté les enquêtes à chaque message de validation de saisie en utilisant les dix premiers caractères de chaque message de validation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 765, "src_audio": "/acl6060/audio/eval/765.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "tgt_ref": "Nous avons modélisé l'approche de synthèse abstractive par classe à travers deux méthodes différentes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 766, "src_audio": "/acl6060/audio/eval/766.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "tgt_ref": "Le premier modèle, que nous appelons CAS unique, se compose d'un réseau de six à six unique et génère un seul texte de note de version donnant un enchaînement de messages de validation de saisie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 767, "src_audio": "/acl6060/audio/eval/767.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "tgt_ref": "Les textes de sortie peuvent être divisés en segments par classe sur la base de symboles de point d'extrémité particuliers, spécifiques à la classe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 19, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 768, "src_audio": "/acl6060/audio/eval/768.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "tgt_ref": "La seconde méthode, que nous appelons CAS multiple, se compose de quatre réseaux seq2seq différents, dont chacun correspond à l'une des classes de notes de version fixes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 769, "src_audio": "/acl6060/audio/eval/769.wav", "src_ref": "Okay, let me explain the experiments.", "tgt_ref": "Ok, je vais vous expliquer les expériences.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 770, "src_audio": "/acl6060/audio/eval/770.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "tgt_ref": "Cinq méthodes ont été comparées : CEAS, CAS unique, CAS multiple, regroupement et étude antérieure, Glyph.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 771, "src_audio": "/acl6060/audio/eval/771.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "tgt_ref": "En ce qui concerne l'évaluation, dans certains cas, les notes de version sont produites en plusieurs phrases.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 772, "src_audio": "/acl6060/audio/eval/772.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "tgt_ref": "Puisqu'il est difficile de calculer le nombre de phrases telles qu'elles sont, elles sont combinées avec des espaces et traitées comme une seule phrase longue.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 773, "src_audio": "/acl6060/audio/eval/773.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "tgt_ref": "Le BLEU est pénalisé lorsque le système produit une phrase courte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 774, "src_audio": "/acl6060/audio/eval/774.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "tgt_ref": "Cette pénalité se traduit par une valeur BLEU inférieure dans les résultats de l'expérience décrits ci-dessous.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 775, "src_audio": "/acl6060/audio/eval/775.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "tgt_ref": "Enfin, nous calculons également la spécificité car ROUGE et BLEU ne peuvent pas être calculés si les notes de version sont vides.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 776, "src_audio": "/acl6060/audio/eval/776.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "tgt_ref": "Une spécificité plus élevée signifie que le modèle produit correctement un texte vide dans les cas où les notes de version sont supposées être vides.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 777, "src_audio": "/acl6060/audio/eval/777.wav", "src_ref": "Here are the results.", "tgt_ref": "Les résultats sont indiqués ci-après.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 778, "src_audio": "/acl6060/audio/eval/778.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "tgt_ref": "Étant donné que les données contiennent des adresses électroniques, des valeurs hachées, etc., nous avons également évalué les données nettoyées, ce qui les exclut.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 779, "src_audio": "/acl6060/audio/eval/779.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "tgt_ref": "Le CEAS et le CAS ont obtenu des scores de ROUGE-L supérieurs de plus de dix points par rapport aux bases.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 780, "src_audio": "/acl6060/audio/eval/780.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "tgt_ref": "En particulier, sur l'ensemble de test propre, l'écart de score entre la méthode proposée et les bases a atteint plus de vingt points.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 781, "src_audio": "/acl6060/audio/eval/781.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "tgt_ref": "Ces résultats indiquent que le CEAS et le CAS sont considérablement touchés.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 782, "src_audio": "/acl6060/audio/eval/782.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "tgt_ref": "Le CEAS a obtenu un meilleur score ROUGE-L que le CAS, ce qui suggère que la combinaison d'un classificateur et d'un générateur est efficace pour former le classificateur à l'aide de pseudo-étiquettes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 20, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 783, "src_audio": "/acl6060/audio/eval/783.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "tgt_ref": "Une couverture élevée du CEAS peut être obtenue probablement car le classificateur peut se concentrer sur la sélection des messages de validation pertinents pour chaque classe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 784, "src_audio": "/acl6060/audio/eval/784.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "tgt_ref": "Le CAS multiple tendait à produire plus de ROUGE-L que le CAS unique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 785, "src_audio": "/acl6060/audio/eval/785.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "tgt_ref": "En suggérant qu'il est également efficace de développer indépendamment et différemment des modèles de abstractive summarization pour chaque classe de note de version.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 786, "src_audio": "/acl6060/audio/eval/786.wav", "src_ref": "Here are an error analysis.", "tgt_ref": "Voici une analyse d'erreur.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 787, "src_audio": "/acl6060/audio/eval/787.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "tgt_ref": "Les méthodes CAS ont tendance à produire des phrases plus courtes que les phrases de référence humaines.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 788, "src_audio": "/acl6060/audio/eval/788.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "tgt_ref": "Dans la figure de droite, la phrase de référence a trois ou quatre phrases, tandis que le CAS n'en a qu'une.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 789, "src_audio": "/acl6060/audio/eval/789.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "tgt_ref": "La raison de la réticence de ce modèle est que dans les données de formation, seulement trente-trois pour cent des phrases sont présentes dans l'étiquette des fonctions et quarante pour cent dans l'étiquette des améliorations.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 790, "src_audio": "/acl6060/audio/eval/790.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "tgt_ref": "En outre, les méthodes CAS ne peuvent pas générer des notes de version précises sans informations supplémentaires.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 791, "src_audio": "/acl6060/audio/eval/791.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "tgt_ref": "L'exemple en haut à droite est un exemple de message de validation très désordonné, et la phrase complète ne peut pas être générée sans référence à la progression ou au problème correspondant(e).", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 792, "src_audio": "/acl6060/audio/eval/792.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "tgt_ref": "L'exemple ci-dessous montre que les deux messages de validation dans la saisie sont liés et doivent être combinés en une phrase, mais cela n'est pas fait.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 793, "src_audio": "/acl6060/audio/eval/793.wav", "src_ref": "Finally, a conclusion.", "tgt_ref": "Enfin, passons à la conclusion.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 794, "src_audio": "/acl6060/audio/eval/794.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "tgt_ref": "Nous avons construit de nouvelles données pour la génération automatique de notes de version.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 795, "src_audio": "/acl6060/audio/eval/795.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "tgt_ref": "Nous avons également formulé une tâche consistant à saisir des messages de validation et à les résumer afin qu'ils soient applicables à tous les projets écrits en anglais.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 796, "src_audio": "/acl6060/audio/eval/796.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "tgt_ref": "Nos expériences montrent que la méthode proposée génère des notes de version moins bruyantes à une couverture plus élevée que les bases.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 797, "src_audio": "/acl6060/audio/eval/797.wav", "src_ref": "Please check out our dataset on GitHub.", "tgt_ref": "Veuillez consulter nos données sur GitHub.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 21, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 798, "src_audio": "/acl6060/audio/eval/798.wav", "src_ref": "Thank you.", "tgt_ref": "Merci.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 799, "src_audio": "/acl6060/audio/eval/799.wav", "src_ref": "Hello. My name is Asaf Harari.", "tgt_ref": "Bonjour. Je m'appelle Asaf Harari.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 800, "src_audio": "/acl6060/audio/eval/800.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "tgt_ref": "Et je vais vous présenter notre article : enrichissement de données tabulaires en quelques coups à l'aide d'architectures de transformateurs raffinées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 801, "src_audio": "/acl6060/audio/eval/801.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "tgt_ref": "Les scientifiques analysent les données et se concentrent principalement sur la manipulation des fonctions existantes des données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 802, "src_audio": "/acl6060/audio/eval/802.wav", "src_ref": "But sometimes, these features are limited.", "tgt_ref": "Mais parfois, ces fonctions sont limitées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 803, "src_audio": "/acl6060/audio/eval/803.wav", "src_ref": "Feature generation using another data source may add substantial information.", "tgt_ref": "La génération de fonctions en utilisant une autre source de données peut ajouter des informations substantielles.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 804, "src_audio": "/acl6060/audio/eval/804.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "tgt_ref": "Notre objectif de recherche est l'enrichissement automatique de données tabulaires en utilisant des textes libres de sources externes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 805, "src_audio": "/acl6060/audio/eval/805.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "tgt_ref": "Supposons que nous ayons des données tabulaires et une base de connaissances.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 806, "src_audio": "/acl6060/audio/eval/806.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "tgt_ref": "Nous avons besoin d'un processus automatique qui implique la liaison d'entités et l'analyse de texte pour extraire de nouvelles fonctions du texte libre de la base de connaissances.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 807, "src_audio": "/acl6060/audio/eval/807.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "tgt_ref": "Notre cadre FeSTE est exactement ce processus automatique.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 808, "src_audio": "/acl6060/audio/eval/808.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "tgt_ref": "Voyons donc un exemple dans des données introduites dans FeSTE.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 809, "src_audio": "/acl6060/audio/eval/809.wav", "src_ref": "In this example, the dataset is university dataset.", "tgt_ref": "Dans cet exemple, les données sont des données universitaires.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 810, "src_audio": "/acl6060/audio/eval/810.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "tgt_ref": "Quand l'objectif est de classer les universités en universités de bas rang et en universités de haut rang.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 811, "src_audio": "/acl6060/audio/eval/811.wav", "src_ref": "As knowledge base, we use Wikipedia.", "tgt_ref": "En tant que base de connaissances, nous utilisons Wikipédia.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 812, "src_audio": "/acl6060/audio/eval/812.wav", "src_ref": "The first phase of FeSTE is entity linking.", "tgt_ref": "La première phase de FeSTE est la liaison d'entités.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 22, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 813, "src_audio": "/acl6060/audio/eval/813.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "tgt_ref": "Lorsque chaque entité, dans cet exemple, le nom de l'université, est liée à une entité au sein de la base de connaissances.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 814, "src_audio": "/acl6060/audio/eval/814.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "tgt_ref": "Et le texte des entités de la base de connaissances est extrait et ajouté aux données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 815, "src_audio": "/acl6060/audio/eval/815.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "tgt_ref": "Dans cet exemple, le texte est le résumé de la page Wikipédia.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 816, "src_audio": "/acl6060/audio/eval/816.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "tgt_ref": "Maintenant, nous devons générer ou extraire des fonctions à partir du texte extrait.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 817, "src_audio": "/acl6060/audio/eval/817.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "tgt_ref": "Nous avons donc besoin de la phase d'extraction des fonctions qui comprend l'analyse de texte.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 818, "src_audio": "/acl6060/audio/eval/818.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "tgt_ref": "Il s'agit de la principale nouveauté de cet article et je vais mieux l'expliquer dans les prochaines diapositives.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 819, "src_audio": "/acl6060/audio/eval/819.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "tgt_ref": "Après la phase d'extraction des fonctions, il y a une phase de génération de fonctions lorsque nous utilisons les fonctions extraites pour générer un petit nombre de nouvelles fonctions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 820, "src_audio": "/acl6060/audio/eval/820.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "tgt_ref": "Générez d'abord les fonctions dans le nombre de classes des données d'origine.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 821, "src_audio": "/acl6060/audio/eval/821.wav", "src_ref": "In this example, the original dataset has two classes.", "tgt_ref": "Dans cet exemple, les données d'origine ont deux classes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 822, "src_audio": "/acl6060/audio/eval/822.wav", "src_ref": "So, FeSTE generates two new features.", "tgt_ref": "Ainsi, FeSTE génère deux nouvelles fonctions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 823, "src_audio": "/acl6060/audio/eval/823.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "tgt_ref": "Mais si les données ont cinq classes, FeSTE génère cinq nouvelles fonctions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 824, "src_audio": "/acl6060/audio/eval/824.wav", "src_ref": "Each feature represents the likelihood for each class.", "tgt_ref": "Chaque fonction représente la probabilité pour chaque classe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 825, "src_audio": "/acl6060/audio/eval/825.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "tgt_ref": "Pour analyser le texte, nous utilisons les analyses de texte de pointe, qui sont des modèles de langue basés sur la conversion comme BERT, GPT, XLNet etc.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 826, "src_audio": "/acl6060/audio/eval/826.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "tgt_ref": "Mais il est peu probable que nous puissions former des modèles de langue en utilisant les données de saisie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 827, "src_audio": "/acl6060/audio/eval/827.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "tgt_ref": "Ainsi, une approche naïve sera le raffinement de la tâche cible.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 23, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 828, "src_audio": "/acl6060/audio/eval/828.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "tgt_ref": "Dans la phase d'extraction des fonctions, nous pouvons télécharger des modèles de langue préformée et raffiner le modèle de langue sur les données cibles.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 829, "src_audio": "/acl6060/audio/eval/829.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "tgt_ref": "Dans cet exemple, raffiner le modèle de langue, classer le texte en classes, résumer en classes, basses ou hautes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 830, "src_audio": "/acl6060/audio/eval/830.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "tgt_ref": "Recevoir les résultats du modèle de langue, qui sont la probabilité pour chaque classe et les utiliser comme nouvelles fonctions.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 831, "src_audio": "/acl6060/audio/eval/831.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "tgt_ref": "Le problème avec cette approche est que les données peuvent avoir peu d'entités / de textes distinct(e)s.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 832, "src_audio": "/acl6060/audio/eval/832.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "tgt_ref": "Dans notre expérience, près de la moitié des données contiennent moins de quatre cents échantillons et les plus petites données contiennent trente-cinq échantillons dans un ensemble de formation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 833, "src_audio": "/acl6060/audio/eval/833.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "tgt_ref": "Donc, pour raffiner un modèle de langue sur cela, les données seront inefficaces.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 834, "src_audio": "/acl6060/audio/eval/834.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "tgt_ref": "Mais nous pouvons utiliser des connaissances préalables sur des données préanalysées.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 835, "src_audio": "/acl6060/audio/eval/835.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "tgt_ref": "Puisque nous appliquons FeSTE sur des données multiples, nous pouvons utiliser les données n moins un pour recueillir des informations sur les données n moins un, et utiliser ces informations lorsque nous analysons les nièmes données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 836, "src_audio": "/acl6060/audio/eval/836.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "tgt_ref": "Ce que nous suggérons, c'est d'ajouter une autre phase de raffinement.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 837, "src_audio": "/acl6060/audio/eval/837.wav", "src_ref": "A preliminary multitask finetuning phase.", "tgt_ref": "Une phase de raffinement multitâche préliminaire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 838, "src_audio": "/acl6060/audio/eval/838.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "tgt_ref": "Lorsque vous raffinez le modèle de langue sur les données n moins un.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 839, "src_audio": "/acl6060/audio/eval/839.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "tgt_ref": "Et ensuite, nous exécutons une autre phase de raffinement qui est un raffinement de tâche cible, lorsque nous raffinons le modèle de langue sur les nièmes données cibles.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 840, "src_audio": "/acl6060/audio/eval/840.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "tgt_ref": "Le raffinement multitâche de pointe appelé MTDNN.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 841, "src_audio": "/acl6060/audio/eval/841.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "tgt_ref": "Le MTDNN maintient les têtes dans le nombre de tâches dans l'ensemble de formation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 842, "src_audio": "/acl6060/audio/eval/842.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "tgt_ref": "Donc, dans cet exemple, il y a quatre tâches dans l'ensemble de formation. Le MTDNN maintient alors quatre têtes comme vous pouvez le voir sur l'image.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 24, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 843, "src_audio": "/acl6060/audio/eval/843.wav", "src_ref": "And it samples a random batch from ah from the training set.", "tgt_ref": "Et il échantillonne un lot aléatoire de l'ensemble de formation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 844, "src_audio": "/acl6060/audio/eval/844.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "tgt_ref": "Et si elles appartiennent à un lot aléatoire, par exemple, une seule tâche de classification de phrases, il exécute des chemins d'aller et retour à travers la première tête.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 845, "src_audio": "/acl6060/audio/eval/845.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "tgt_ref": "Et si le lot aléatoire appartient à la tâche de classement par paire, il exécute un chemin d'aller et retour dans la dernière tête.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 846, "src_audio": "/acl6060/audio/eval/846.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "tgt_ref": "Dans notre scénario, les données tabulaires varient dans le nombre de classes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 847, "src_audio": "/acl6060/audio/eval/847.wav", "src_ref": "So there are many tasks.", "tgt_ref": "Il y a donc beaucoup de tâches.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 848, "src_audio": "/acl6060/audio/eval/848.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "tgt_ref": "Le MTDNN a maintenu le nombre de classes, de têtes et de couches de sortie.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 849, "src_audio": "/acl6060/audio/eval/849.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "tgt_ref": "Et en outre, le MTDNN doit initialiser de nouvelles têtes pour de nouvelles données avec une nouvelle tâche.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 850, "src_audio": "/acl6060/audio/eval/850.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "tgt_ref": "Notre approche, appelée raffinement de reformulation de tâche, est dans notre raffinement de reformulation de tâche d'approche. Au lieu de maintenir plusieurs têtes, nous reformulons chaque donnée dans une phrase par problème de classification, étant des tâches de deux classes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 851, "src_audio": "/acl6060/audio/eval/851.wav", "src_ref": "So let's see an example.", "tgt_ref": "Prenons donc un exemple.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 852, "src_audio": "/acl6060/audio/eval/852.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "tgt_ref": "Voici nos données de saisie qui se composent d'entités, de fonctions, de texte et de classes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 853, "src_audio": "/acl6060/audio/eval/853.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "tgt_ref": "Et nous reformulons la tâche à partir d'une classification du texte en bas ou haut pour classer le texte, le résumé et la classe en vrai ou faux.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 854, "src_audio": "/acl6060/audio/eval/854.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "tgt_ref": "Ou en d'autres mots, nous avons formé le modèle de langue pour classer un résumé et une classe en résumé et classe, si le résumé appartient à la classe ou non.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 855, "src_audio": "/acl6060/audio/eval/855.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "tgt_ref": "Donc dans ce cas, le vecteur d'étiquette consiste toujours en deux classes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 856, "src_audio": "/acl6060/audio/eval/856.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "tgt_ref": "Et il s'agit de l'algorithme pour notre très bonne approche de raffinement reformulée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 857, "src_audio": "/acl6060/audio/eval/857.wav", "src_ref": "So let's see the full framework.", "tgt_ref": "Voyons le cadre complet.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 25, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 858, "src_audio": "/acl6060/audio/eval/858.wav", "src_ref": "Dataset fed into FeSTE.", "tgt_ref": "Les données sont introduites dans FeSTE.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 859, "src_audio": "/acl6060/audio/eval/859.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "tgt_ref": "Puis FeSTE exécute la phase de liaison d'entités.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 860, "src_audio": "/acl6060/audio/eval/860.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "tgt_ref": "Il extrait le texte de la base de connaissances, qui dans cet exemple est le résumé de la page Wikipédia.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 861, "src_audio": "/acl6060/audio/eval/861.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "tgt_ref": "Ensuite, il a reformulé la tâche en une tâche de classification des phrases par paire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 862, "src_audio": "/acl6060/audio/eval/862.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "tgt_ref": "Il a appliqué le modèle de langue à la nouvelle tâche et la probabilité de sortie pour chaque classe.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 863, "src_audio": "/acl6060/audio/eval/863.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "tgt_ref": "Et maintenant, le modèle de langue est déjà raffiné sur des données n moins un en utilisant un raffinement multitâche préliminaire.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 864, "src_audio": "/acl6060/audio/eval/864.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "tgt_ref": "Ensuite, nous utilisons le vecteur de sortie du modèle de langue comme une fonction nouvellement générée dans le nombre de classes.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 865, "src_audio": "/acl6060/audio/eval/865.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "tgt_ref": "Pour évaluer notre cadre, nous utilisons dix-sept données de classification tabulaires qui varient en taille, fonctions, équilibre, domaine et performance initiale.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 866, "src_audio": "/acl6060/audio/eval/866.wav", "src_ref": "And as knowledge base we use Wikipedia.", "tgt_ref": "Et en tant que base de connaissances, nous utilisons Wikipédia.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 867, "src_audio": "/acl6060/audio/eval/867.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "tgt_ref": "Nous concevons notre expérience comme une évaluation où nous formons FeSTe sur seize données et l'appliquons à la dix-septième donnée.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 868, "src_audio": "/acl6060/audio/eval/868.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "tgt_ref": "Nous divisons également chaque donnée en quatre plis et appliquons une validation croisée de quatre plis.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 869, "src_audio": "/acl6060/audio/eval/869.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "tgt_ref": "Ensuite, nous générons les nouvelles fonctions et les évaluons en utilisant cinq classificateurs d'évaluation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 870, "src_audio": "/acl6060/audio/eval/870.wav", "src_ref": "We use in our experiments base BERT base architecture.", "tgt_ref": "Nous utilisons dans nos expériences l'architecture de base des Représentations d'encodeurs bidirectionnels à partir de transformateurs.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 871, "src_audio": "/acl6060/audio/eval/871.wav", "src_ref": "Here are the results for our experiments.", "tgt_ref": "Voici les résultats de nos expériences.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 872, "src_audio": "/acl6060/audio/eval/872.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "tgt_ref": "Vous pouvez voir que nous comparons notre cadre au raffinement des données cibles, au raffinement de la tâche cible et à un raffinement préliminaire MTDNN.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 26, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 873, "src_audio": "/acl6060/audio/eval/873.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "tgt_ref": "Et notre raffinement reformulé atteint le meilleur résultat et la meilleure performance.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 874, "src_audio": "/acl6060/audio/eval/874.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "tgt_ref": "Alors que le MTDNN a obtenu une amélioration de deux pour cent par rapport au raffinement des données cibles.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 875, "src_audio": "/acl6060/audio/eval/875.wav", "src_ref": "Our approach achieved six percent improvement.", "tgt_ref": "Notre approche a obtenu une amélioration de six pour cent.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 876, "src_audio": "/acl6060/audio/eval/876.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "tgt_ref": "Lorsque nous regardons les petites données, nous pouvons voir que la performance du MTDNN diminue et l'amélioration de la phase de raffinement multitâche préliminaire diminue aussi à un virgule cinq pour cent.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 877, "src_audio": "/acl6060/audio/eval/877.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "tgt_ref": "Mais notre performance a augmenté à onze pour cent comparé au raffinement de tâche cible seul.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 878, "src_audio": "/acl6060/audio/eval/878.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "tgt_ref": "Pour résumer, FeSTE permet un enrichissement en quelques coups à partir de trente-cinq échantillons dans nos expériences.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 879, "src_audio": "/acl6060/audio/eval/879.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "tgt_ref": "Il utilise une architecture pour toutes les tâches et données.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 880, "src_audio": "/acl6060/audio/eval/880.wav", "src_ref": "And it keeps the head of ah of the model.", "tgt_ref": "Et il garde la tête du modèle.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 881, "src_audio": "/acl6060/audio/eval/881.wav", "src_ref": "But it adds reformulation phase.", "tgt_ref": "Mais cela ajoute une phase de reformulation.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 882, "src_audio": "/acl6060/audio/eval/882.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "tgt_ref": "Il augmente l'ensemble de formation et a besoin d'une valeur cible avec un sens sémantique afin que nous puissions l'introduire dans le modèle de langue et l'utiliser dans le problème de classification par paire de phrases.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
{"dataset_id": "acl_6060", "sample_id": 883, "src_audio": "/acl6060/audio/eval/883.wav", "src_ref": "Thank you.", "tgt_ref": "Merci.", "src_lang": "en", "tgt_lang": "fr", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "doc_id": 27, "subset": "eval"}}
