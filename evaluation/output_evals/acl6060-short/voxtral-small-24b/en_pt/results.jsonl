{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "pt", "output": "Olá a todos. Hoje vou apresentar nosso trabalho de pesquisa Aprendendo a raciocinar dedutivamente: resolução de problemas matemáticos como extração de raciocínio complexo.", "metrics": {"bleu_score": 44.47968795807286, "chrf_score": 70.5088941136745, "xcomet_score": 0.8208056688308716, "xcomet_qe_score": 0.8606517314910889, "metricx_score": 4.452845096588135, "metricx_qe_score": 2.5234575271606445, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "pt", "output": "Sou Alan do Laboratório de IA da Baidu e este é um trabalho conjunto com Jiri da Universidade do Texas em Austin e Weilu da SUTD.", "metrics": {"bleu_score": 37.88531061566416, "chrf_score": 64.45016421980495, "xcomet_score": 0.6560916900634766, "xcomet_qe_score": 0.6673422455787659, "metricx_score": 3.821061611175537, "metricx_qe_score": 2.877441883087158, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, gostaria de falar sobre nossa motivação para a razão.", "metrics": {"bleu_score": 51.37480412538583, "chrf_score": 76.47885486451845, "xcomet_score": 0.8890296220779419, "xcomet_qe_score": 0.8602907061576843, "metricx_score": 5.379889965057373, "metricx_qe_score": 6.318094253540039, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, mostramos exemplos em que o raciocínio em várias etapas é útil.", "metrics": {"bleu_score": 44.534504264163466, "chrf_score": 72.15950215171993, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2474963665008545, "metricx_qe_score": 0.26125001907348633, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "pt", "output": "Esta figura foi retirada do artigo, onde eles realizam o prompt para resolver o problema de matemática em um cenário de aprendizado com poucos exemplos.", "metrics": {"bleu_score": 21.081851067789188, "chrf_score": 58.16029134880708, "xcomet_score": 0.5884889960289001, "xcomet_qe_score": 0.7000120878219604, "metricx_score": 9.502462387084961, "metricx_qe_score": 9.229432106018066, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, no lado do painel, podemos ver que, se dermos alguns exemplos com apenas correção e respostas, talvez não consigamos obter as respostas corretas.", "metrics": {"bleu_score": 56.4688325154375, "chrf_score": 70.27283011169905, "xcomet_score": 0.7571319341659546, "xcomet_qe_score": 0.6859351992607117, "metricx_score": 9.090660095214844, "metricx_qe_score": 8.528157234191895, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "pt", "output": "Mas se dermos uma descrição mais raciocinada, o modelo é capaz de prever a descrição raciocinada e também fazer uma previsão correta aqui.", "metrics": {"bleu_score": 70.28500549171714, "chrf_score": 80.75837921693491, "xcomet_score": 0.854587197303772, "xcomet_qe_score": 0.9647045135498047, "metricx_score": 4.554340362548828, "metricx_qe_score": 5.221138000488281, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, é bom ter raciocínio interpretável em várias etapas como saída.", "metrics": {"bleu_score": 27.968424579665367, "chrf_score": 79.38554631432396, "xcomet_score": 0.9966243505477905, "xcomet_qe_score": 1.0, "metricx_score": 1.2581498622894287, "metricx_qe_score": 3.173551559448242, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "pt", "output": "E também acreditamos que o problema do método é uma aplicação direta para avaliar tais habilidades de raciocínio.", "metrics": {"bleu_score": 41.682189465797684, "chrf_score": 73.15848100598224, "xcomet_score": 0.7889924049377441, "xcomet_qe_score": 0.7383843660354614, "metricx_score": 8.840070724487305, "metricx_qe_score": 8.837444305419922, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "pt", "output": "Então, aqui, no nosso problema, dadas as perguntas, precisamos resolver essa pergunta e obter as respostas numéricas.", "metrics": {"bleu_score": 42.77972007454006, "chrf_score": 68.76204924908124, "xcomet_score": 0.9745161533355713, "xcomet_qe_score": 0.9629986882209778, "metricx_score": 1.636962890625, "metricx_qe_score": 2.034876823425293, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, em nossos conjuntos de dados, também nos é fornecida a expressão matemática que leva a esta resposta específica.", "metrics": {"bleu_score": 46.43186698761531, "chrf_score": 67.13479766988465, "xcomet_score": 0.9822595119476318, "xcomet_qe_score": 0.9745217561721802, "metricx_score": 2.1616482734680176, "metricx_qe_score": 3.1895720958709717, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "pt", "output": "Assim, certas suposições também se aplicam como no trabalho anterior.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9888443946838379, "xcomet_qe_score": 0.9758886694908142, "metricx_score": 2.446652889251709, "metricx_qe_score": 3.7686705589294434, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "pt", "output": "Suponhamos que a precisão das quantidades é desconhecida.", "metrics": {"bleu_score": 61.04735835807847, "chrf_score": 79.53888481742804, "xcomet_score": 0.5433288812637329, "xcomet_qe_score": 0.6260825395584106, "metricx_score": 8.256876945495605, "metricx_qe_score": 7.539092540740967, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "pt", "output": "E consideramos apenas operadores básicos, como adição, subtração, multiplicação, divisão e exponenciação.", "metrics": {"bleu_score": 70.85876411943929, "chrf_score": 94.41918397224867, "xcomet_score": 0.9998117685317993, "xcomet_qe_score": 1.0, "metricx_score": 0.6277773380279541, "metricx_qe_score": 0.6494056582450867, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, operadores complicados podem ser de fato decompostos nesses operadores básicos.", "metrics": {"bleu_score": 33.649324423301536, "chrf_score": 79.18001129116072, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.2933191061019897, "metricx_qe_score": 1.6987316608428955, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, trabalhos anteriores em resolução de problemas matemáticos podem ser categorizados em modelos de sequência para sequência e sequência para árvore.", "metrics": {"bleu_score": 26.626928257104723, "chrf_score": 68.09797661194533, "xcomet_score": 0.7349473237991333, "xcomet_qe_score": 0.7562239170074463, "metricx_score": 4.759206771850586, "metricx_qe_score": 5.060701370239258, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "pt", "output": "Então, os modelos tradicionais de sequência para sequência convertem a expressão em uma sequência específica para geração.", "metrics": {"bleu_score": 20.236360012390456, "chrf_score": 74.37770832453572, "xcomet_score": 0.8521984219551086, "xcomet_qe_score": 0.80611252784729, "metricx_score": 2.4223642349243164, "metricx_qe_score": 3.8915836811065674, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "pt", "output": "É bastante fácil de implementar e pode ser generalizado para muitos problemas diferentes e complicados.", "metrics": {"bleu_score": 33.15796151992084, "chrf_score": 76.63251079398134, "xcomet_score": 0.9986734390258789, "xcomet_qe_score": 1.0, "metricx_score": 0.5120000243186951, "metricx_qe_score": 0.49150004982948303, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "pt", "output": "Mas a desvantagem do desempenho é que, na verdade, não é melhor do que o modelo estrutural, e ele carece de interpretabilidade para previsão.", "metrics": {"bleu_score": 35.89746259568356, "chrf_score": 69.02024627982671, "xcomet_score": 0.9681062698364258, "xcomet_qe_score": 0.9647343158721924, "metricx_score": 3.5343503952026367, "metricx_qe_score": 3.7258760929107666, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "pt", "output": "Mas, na verdade, essa direção ainda é bastante popular por causa do modelo Transformer.", "metrics": {"bleu_score": 70.85876411943929, "chrf_score": 84.67772582759135, "xcomet_score": 0.9821223020553589, "xcomet_qe_score": 0.9858717918395996, "metricx_score": 3.164940595626831, "metricx_qe_score": 3.401171922683716, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, nos modelos baseados em árvores, estruturamos essas expressões na forma de árvore e seguimos uma travessia pré-ordem na geração de árvores.", "metrics": {"bleu_score": 40.868893290046785, "chrf_score": 71.15431672295611, "xcomet_score": 0.8813793659210205, "xcomet_qe_score": 0.7591449022293091, "metricx_score": 5.16098165512085, "metricx_qe_score": 6.091158390045166, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.", "metrics": {"bleu_score": 83.38719597502187, "chrf_score": 89.71714031368657, "xcomet_score": 0.9792633056640625, "xcomet_qe_score": 0.9630165100097656, "metricx_score": 2.8568830490112305, "metricx_qe_score": 4.170072555541992, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "pt", "output": "Então, aqui, a coisa boa é que ele realmente nos dá essa estrutura de árvore binária, e é... mas, na verdade, é bastante contraintuitivo, porque geramos o operador primeiro e, depois, no final, geramos as quantidades.", "metrics": {"bleu_score": 44.795328508157404, "chrf_score": 81.3881328954295, "xcomet_score": 0.9762452840805054, "xcomet_qe_score": 0.9681198596954346, "metricx_score": 3.2692840099334717, "metricx_qe_score": 5.8743205070495605, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "pt", "output": "A segunda coisa é que também contém alguns cálculos repetitivos.", "metrics": {"bleu_score": 81.55395405382076, "chrf_score": 96.6194216145392, "xcomet_score": 0.9998668432235718, "xcomet_qe_score": 0.9991341829299927, "metricx_score": 0.7234416007995605, "metricx_qe_score": 0.8282637596130371, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, se olharmos para essa expressão, 8 vezes 3 mais 3 é, na verdade, gerada duas vezes. Mas, na verdade, devemos reutilizar os resultados.", "metrics": {"bleu_score": 27.967313420783547, "chrf_score": 64.09287799401517, "xcomet_score": 0.9695814847946167, "xcomet_qe_score": 0.9744112491607666, "metricx_score": 1.422513484954834, "metricx_qe_score": 1.649965763092041, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "pt", "output": "Em nossa abordagem proposta, queremos resolver esses problemas de maneira interpretável e passo a passo.", "metrics": {"bleu_score": 34.953658971976616, "chrf_score": 73.13008852832029, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.5231043100357056, "metricx_qe_score": 1.778569221496582, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, aqui no segundo passo, podemos obter este divisor, que é 27.", "metrics": {"bleu_score": 47.554235777270286, "chrf_score": 69.64214684854676, "xcomet_score": 0.9697753190994263, "xcomet_qe_score": 0.9553203582763672, "metricx_score": 1.3547968864440918, "metricx_qe_score": 5.271279335021973, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "pt", "output": "Também podemos nos referir às perguntas originais para encontrar os conteúdos relevantes.", "metrics": {"bleu_score": 49.39370396127886, "chrf_score": 77.11920525715482, "xcomet_score": 0.999291181564331, "xcomet_qe_score": 1.0, "metricx_score": 0.8637806177139282, "metricx_qe_score": 0.7726926803588867, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "pt", "output": "Nessas etapas, obtemos os divisores.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 63.17723935864462, "xcomet_score": 0.9975005388259888, "xcomet_qe_score": 0.9749532341957092, "metricx_score": 1.5771371126174927, "metricx_qe_score": 2.580298662185669, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "pt", "output": "Então, e depois, nesta terceira etapa, obtemos a cotação.", "metrics": {"bleu_score": 3.0890553181566975, "chrf_score": 25.70079357178379, "xcomet_score": 0.9649215936660767, "xcomet_qe_score": 0.974449872970581, "metricx_score": 8.367554664611816, "metricx_qe_score": 6.4578142166137695, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "pt", "output": "Tudo bem, e depois dessas três etapas, podemos realmente usar os resultados da segunda etapa e, em seguida, obter os resultados da quarta etapa, e, finalmente, podemos obter os dividendos.", "metrics": {"bleu_score": 33.4012855287867, "chrf_score": 58.62795993080353, "xcomet_score": 0.9759616851806641, "xcomet_qe_score": 0.9660555124282837, "metricx_score": 2.681561231613159, "metricx_qe_score": 3.3042619228363037, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, na verdade, geramos a expressão inteira diretamente, em vez de gerar um único operador ou quantidade.", "metrics": {"bleu_score": 39.10803275292361, "chrf_score": 72.25370087833299, "xcomet_score": 0.9993578195571899, "xcomet_qe_score": 0.9993870258331299, "metricx_score": 0.7792676091194153, "metricx_qe_score": 1.1648242473602295, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "pt", "output": "Isso torna o processo mais preciso.", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 90.73437609644506, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.21219311654567719, "metricx_qe_score": 0.247283935546875, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "pt", "output": "No nosso sistema dedutivo, começamos com um conjunto de quantidades apresentadas nas questões e também incluindo algumas constantes como nosso estado inicial.", "metrics": {"bleu_score": 34.38263528816037, "chrf_score": 70.95636797445285, "xcomet_score": 0.9544574022293091, "xcomet_qe_score": 0.9270215630531311, "metricx_score": 3.0744173526763916, "metricx_qe_score": 3.767472505569458, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "pt", "output": "A expressão é representada por EIJOP.", "metrics": {"bleu_score": 18.448373350246094, "chrf_score": 66.4187330648499, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.539353847503662, "metricx_qe_score": 4.68563175201416, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "pt", "output": "Onde realizamos a operação de QI para QJ e tal expressão é, na verdade, direcionada.", "metrics": {"bleu_score": 17.603947382649423, "chrf_score": 56.54335077739563, "xcomet_score": 0.92908775806427, "xcomet_qe_score": 0.8971728086471558, "metricx_score": 4.245677471160889, "metricx_qe_score": 5.39339542388916, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, também temos a subtração reversa aqui para representar a direção oposta.", "metrics": {"bleu_score": 65.15132562023375, "chrf_score": 77.28792317688021, "xcomet_score": 0.9527850151062012, "xcomet_qe_score": 0.9341249465942383, "metricx_score": 2.9488065242767334, "metricx_qe_score": 3.578740119934082, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "pt", "output": "Isso é bastante semelhante à extração de relações.", "metrics": {"bleu_score": 19.070828081828378, "chrf_score": 55.03181485135092, "xcomet_score": 0.9885498285293579, "xcomet_qe_score": 1.0, "metricx_score": 2.0481057167053223, "metricx_qe_score": 2.1850502490997314, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, em um sistema dedutivo formal, em um instante t, aplicamos o operador entre o par QI e QJ e, então, obtemos essas novas expressões.", "metrics": {"bleu_score": 30.092652279202415, "chrf_score": 61.62853801969143, "xcomet_score": 0.9813371896743774, "xcomet_qe_score": 0.9848096370697021, "metricx_score": 1.9348485469818115, "metricx_qe_score": 2.416227102279663, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "pt", "output": "Adicionamos ao próximo estado para se tornar uma nova quantidade.", "metrics": {"bleu_score": 89.31539818068698, "chrf_score": 90.63898435384111, "xcomet_score": 0.9747055768966675, "xcomet_qe_score": 0.9562721252441406, "metricx_score": 2.364100217819214, "metricx_qe_score": 2.9189260005950928, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "pt", "output": "Então, este slide realmente visualiza a evolução dos estados, onde continuamos adicionando expressões aos estados atuais.", "metrics": {"bleu_score": 4.814971807094068, "chrf_score": 51.41105442958083, "xcomet_score": 0.9389289617538452, "xcomet_qe_score": 0.9507976770401001, "metricx_score": 4.683887481689453, "metricx_qe_score": 5.237194061279297, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "pt", "output": "Em nossas implementações de modelos, primeiro usamos um modelo de linguagem pré-treinado, que pode ser o BERT ou o RoBERTa, e depois codificamos uma sentença e obtemos essas representações quantitativas.", "metrics": {"bleu_score": 29.17504250950499, "chrf_score": 71.69314839368016, "xcomet_score": 0.7898748517036438, "xcomet_qe_score": 0.9267653822898865, "metricx_score": 1.9482483863830566, "metricx_qe_score": 1.5572471618652344, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "pt", "output": "Então, uma vez que obtemos as representações quantitativas, podemos começar a fazer inferências.", "metrics": {"bleu_score": 39.375553105513404, "chrf_score": 76.09721564439683, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4863203763961792, "metricx_qe_score": 0.39420121908187866, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, mostramos um exemplo de Q1 para obter a representação de Q1 dividida por Q2 e, em seguida, multiplicada por Q3.", "metrics": {"bleu_score": 19.626464143255905, "chrf_score": 60.46575675067505, "xcomet_score": 0.9314248561859131, "xcomet_qe_score": 0.9545720815658569, "metricx_score": 6.966034412384033, "metricx_qe_score": 7.135016441345215, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, obtemos a representação de pares, que é basicamente a concatenação entre Q1 e Q2, e depois aplicamos uma rede feedforward, que é parametrizada pelo operador.", "metrics": {"bleu_score": 32.90474778117879, "chrf_score": 68.61645485614767, "xcomet_score": 0.8582860231399536, "xcomet_qe_score": 0.9406304359436035, "metricx_score": 5.313071250915527, "metricx_qe_score": 5.206309795379639, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "pt", "output": "E, finalmente, obtemos a representação da expressão Q1/Q2.", "metrics": {"bleu_score": 37.28051436687862, "chrf_score": 68.09738400746083, "xcomet_score": 0.9358094930648804, "xcomet_qe_score": 0.9556022882461548, "metricx_score": 2.3484108448028564, "metricx_qe_score": 3.543715000152588, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "pt", "output": "Mas, na verdade, na prática, na fase de inferência, podemos obter a expressão incorreta também.", "metrics": {"bleu_score": 50.34173127933707, "chrf_score": 69.53679143434317, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.6969871520996094, "metricx_qe_score": 2.8730132579803467, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, aqui todas as expressões possíveis são iguais a três vezes o número de operadores.", "metrics": {"bleu_score": 42.649937722961525, "chrf_score": 66.27358508836932, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.1374198198318481, "metricx_qe_score": 3.201706647872925, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "pt", "output": "A coisa boa aqui é que podemos facilmente adicionar restrições para controlar este espaço de busca.", "metrics": {"bleu_score": 64.96072343867387, "chrf_score": 82.56064397670673, "xcomet_score": 0.9813508987426758, "xcomet_qe_score": 0.9760539531707764, "metricx_score": 1.0605665445327759, "metricx_qe_score": 1.7537262439727783, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, se essa expressão não for permitida, podemos simplesmente remover essa expressão do nosso espaço de busca.", "metrics": {"bleu_score": 52.62439702634462, "chrf_score": 82.48347144429012, "xcomet_score": 0.9846043586730957, "xcomet_qe_score": 0.9925087690353394, "metricx_score": 0.3198489248752594, "metricx_qe_score": 0.4091433882713318, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "pt", "output": "Então, na segunda etapa, fazemos a mesma coisa, mas a única diferença é que temos mais uma quantidade.", "metrics": {"bleu_score": 57.18839190796756, "chrf_score": 71.02540245212508, "xcomet_score": 0.9381712675094604, "xcomet_qe_score": 0.867171049118042, "metricx_score": 2.8274118900299072, "metricx_qe_score": 4.524950981140137, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "pt", "output": "Essa quantidade vem da expressão calculada anteriormente.", "metrics": {"bleu_score": 42.13952948452608, "chrf_score": 78.2274087421915, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.28368180990219116, "metricx_qe_score": 0.3026748299598694, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, finalmente podemos obter esta expressão final Q.", "metrics": {"bleu_score": 18.32556812998321, "chrf_score": 62.22878993169666, "xcomet_score": 0.8078817129135132, "xcomet_qe_score": 0.8176128268241882, "metricx_score": 6.174571990966797, "metricx_qe_score": 9.451116561889648, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "pt", "output": "E também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9661812782287598, "xcomet_qe_score": 0.8900951743125916, "metricx_score": 2.473680257797241, "metricx_qe_score": 3.697856903076172, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, tais diferenças tornam difícil aplicar a busca por feixe, pois a distribuição de probabilidade entre essas duas etapas está desequilibrada.", "metrics": {"bleu_score": 19.38341802345665, "chrf_score": 63.789615839483396, "xcomet_score": 0.9756141901016235, "xcomet_qe_score": 0.9783531427383423, "metricx_score": 1.2358496189117432, "metricx_qe_score": 1.2942332029342651, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "pt", "output": "O procedimento de treinamento é semelhante ao treinamento de um modelo de sequência para sequência, onde otimizamos a perda em cada etapa de tempo.", "metrics": {"bleu_score": 68.81978646512874, "chrf_score": 87.38649871625606, "xcomet_score": 0.8077077865600586, "xcomet_qe_score": 0.8079472780227661, "metricx_score": 2.5211808681488037, "metricx_qe_score": 3.914785861968994, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, também usamos esse tau para representar quando devemos encerrar esse processo de geração.", "metrics": {"bleu_score": 49.35578819979934, "chrf_score": 86.0359313999412, "xcomet_score": 0.999990701675415, "xcomet_qe_score": 0.99993896484375, "metricx_score": 2.0187621116638184, "metricx_qe_score": 4.474776268005371, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, o espaço é diferente de sequência para sequência, pois o espaço é diferente a cada vez, enquanto no modelo tradicional de sequência para sequência, é o número de vocabulário.", "metrics": {"bleu_score": 43.300849065349134, "chrf_score": 72.84155075199666, "xcomet_score": 0.547216534614563, "xcomet_qe_score": 0.5165539383888245, "metricx_score": 6.559539794921875, "metricx_qe_score": 9.577739715576172, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "pt", "output": "E também nos permite impor certas restrições a partir do conhecimento prévio.", "metrics": {"bleu_score": 53.44445934790542, "chrf_score": 81.046778007189, "xcomet_score": 0.9666078090667725, "xcomet_qe_score": 0.9493609666824341, "metricx_score": 0.8579880595207214, "metricx_qe_score": 1.0531901121139526, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, realizamos experimentos em conjuntos de dados de problemas matemáticos comumente usados, MAWPS, Math23K, MathQA e SWAMP.", "metrics": {"bleu_score": 39.736789390277664, "chrf_score": 65.34809336613202, "xcomet_score": 0.8276845216751099, "xcomet_qe_score": 0.962762176990509, "metricx_score": 3.6520609855651855, "metricx_qe_score": 2.6669511795043945, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, mostramos brevemente os resultados comparados com as melhores abordagens anteriores.", "metrics": {"bleu_score": 82.4236750264605, "chrf_score": 94.80586766479506, "xcomet_score": 0.9965410232543945, "xcomet_qe_score": 0.9799026250839233, "metricx_score": 0.5986055731773376, "metricx_qe_score": 0.6058953404426575, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, nossa variante de melhor desempenho é o Roberta Detective Reasoner.", "metrics": {"bleu_score": 17.474335703431752, "chrf_score": 73.53640143438697, "xcomet_score": 0.9172672033309937, "xcomet_qe_score": 0.9472914934158325, "metricx_score": 3.7130026817321777, "metricx_qe_score": 4.331786632537842, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "pt", "output": "E, de fato, não usamos a busca de feixe em contraste com abordagens óbvias que usam a busca de feixe.", "metrics": {"bleu_score": 9.849349468888725, "chrf_score": 35.858476020952786, "xcomet_score": 0.7213137149810791, "xcomet_qe_score": 0.8237774968147278, "metricx_score": 5.0799713134765625, "metricx_qe_score": 4.064579963684082, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "pt", "output": "Tudo bem. Então, as melhores abordagens são frequentemente modelos baseados em árvores.", "metrics": {"bleu_score": 26.36932645412712, "chrf_score": 54.81809545983184, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2721625566482544, "metricx_qe_score": 0.8692595958709717, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, de modo geral, nosso raciocínio consegue superar significativamente este modelo de árvore de decisão.", "metrics": {"bleu_score": 17.59989309236993, "chrf_score": 61.78837558485951, "xcomet_score": 0.912402868270874, "xcomet_qe_score": 0.9381024241447449, "metricx_score": 1.851531982421875, "metricx_qe_score": 1.1732854843139648, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "pt", "output": "Mas podemos ver que o número absoluto no MathQA ou no SWAG não é realmente alto.", "metrics": {"bleu_score": 22.048872820716333, "chrf_score": 54.60241402721616, "xcomet_score": 0.8308497667312622, "xcomet_qe_score": 0.8558157682418823, "metricx_score": 5.386774063110352, "metricx_qe_score": 5.95607328414917, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, investigamos mais os resultados no", "metrics": {"bleu_score": 31.850355294022695, "chrf_score": 64.56370254256257, "xcomet_score": 0.7022666931152344, "xcomet_qe_score": 0.6308009624481201, "metricx_score": 6.948795318603516, "metricx_qe_score": 5.177797794342041, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "pt", "output": "SWAMP, e este conjunto de dados é desafiador porque o autor tentou adicionar manualmente algo para confundir o modelo de PLN, como adicionar informações ambientais e quantidades extras.", "metrics": {"bleu_score": 51.48030774310147, "chrf_score": 81.96684556642987, "xcomet_score": 0.4333445429801941, "xcomet_qe_score": 0.4304159879684448, "metricx_score": 13.116571426391602, "metricx_qe_score": 12.91243839263916, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, em nossa previsão, encontramos que alguns dos valores intermediários são, na verdade, negativos.", "metrics": {"bleu_score": 37.06128964618466, "chrf_score": 70.68024936653491, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6469196081161499, "metricx_qe_score": 0.7194707989692688, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, nesta questão, perguntamos quantas maçãs Drake tem.", "metrics": {"bleu_score": 29.167552921712726, "chrf_score": 67.95086740064671, "xcomet_score": 0.7243070602416992, "xcomet_qe_score": 0.7562439441680908, "metricx_score": 5.2116827964782715, "metricx_qe_score": 5.0470805168151855, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "pt", "output": "Mas temos algumas informações extras, como 17 arremessos de Fielder e 8 arremessos de Stephen, que são totalmente irrelevantes.", "metrics": {"bleu_score": 8.388695821090426, "chrf_score": 46.75898480575798, "xcomet_score": 0.5337260961532593, "xcomet_qe_score": 0.675600528717041, "metricx_score": 12.049808502197266, "metricx_qe_score": 6.815058708190918, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "pt", "output": "Então, nosso modelo faz algumas previsões como esta, que está produzindo valores negativos.", "metrics": {"bleu_score": 19.25161443439357, "chrf_score": 72.52892259105128, "xcomet_score": 0.9829171895980835, "xcomet_qe_score": 0.9624662399291992, "metricx_score": 2.980604887008667, "metricx_qe_score": 2.1568760871887207, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "pt", "output": "Observamos essas duas expressões", "metrics": {"bleu_score": 5.551583143267181, "chrf_score": 35.032784494634726, "xcomet_score": 0.31317028403282166, "xcomet_qe_score": 0.6462588906288147, "metricx_score": 19.952861785888672, "metricx_qe_score": 17.614622116088867, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, podemos realmente limitar este espaço de busca removendo os resultados negativos, para que possamos tornar a resposta correta.", "metrics": {"bleu_score": 48.7859542097654, "chrf_score": 79.40892716758768, "xcomet_score": 0.8683593273162842, "xcomet_qe_score": 0.8294343948364258, "metricx_score": 4.538702964782715, "metricx_qe_score": 5.21004581451416, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, descobrimos que tal restrição realmente melhora bastante alguns modelos.", "metrics": {"bleu_score": 16.40212036255558, "chrf_score": 55.708665408837696, "xcomet_score": 0.9943815469741821, "xcomet_qe_score": 0.992315411567688, "metricx_score": 2.065995931625366, "metricx_qe_score": 2.04971981048584, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, para pássaros, melhoramos em 7 pontos, e para o modelo baseado em robô, melhoramos em 2 pontos.", "metrics": {"bleu_score": 18.27443475086954, "chrf_score": 51.64298961808602, "xcomet_score": 0.5588802099227905, "xcomet_qe_score": 0.619232177734375, "metricx_score": 13.670708656311035, "metricx_qe_score": 13.410651206970215, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, um modelo de linguagem melhor tem uma capacidade de compreensão de linguagem melhor, de modo que o número aqui é maior para Roberta e menor para BERT.", "metrics": {"bleu_score": 22.095731396358687, "chrf_score": 61.14217064196804, "xcomet_score": 0.9947768449783325, "xcomet_qe_score": 0.9965683221817017, "metricx_score": 1.8368144035339355, "metricx_qe_score": 2.144970417022705, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "pt", "output": "Também tentamos analisar a dificuldade por trás disso.", "metrics": {"bleu_score": 24.385000379404747, "chrf_score": 53.01016126023973, "xcomet_score": 0.7576658725738525, "xcomet_qe_score": 0.7012054920196533, "metricx_score": 5.123996257781982, "metricx_qe_score": 8.516805648803711, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, supomos que o número de quantidade não utilizada pode ser considerado como informação irrelevante.", "metrics": {"bleu_score": 24.26438274389041, "chrf_score": 79.21861265100662, "xcomet_score": 0.9785811901092529, "xcomet_qe_score": 0.9833719730377197, "metricx_score": 2.6954355239868164, "metricx_qe_score": 3.09970760345459, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui podemos ver que temos a porcentagem de amostras que não usamos quantidades e o conjunto de dados SWAMP tem a maior proporção.", "metrics": {"bleu_score": 33.886267264337874, "chrf_score": 69.99208608579201, "xcomet_score": 0.8838149309158325, "xcomet_qe_score": 0.8418864607810974, "metricx_score": 7.101707458496094, "metricx_qe_score": 8.308876991271973, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui também mostramos o desempenho geral.", "metrics": {"bleu_score": 70.1396726799769, "chrf_score": 94.73915332955248, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.299202024936676, "metricx_qe_score": 0.5081391334533691, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "pt", "output": "Para aquelas amostras sem quantidades usadas, o desempenho geral é na verdade maior do que o desempenho geral.", "metrics": {"bleu_score": 43.59493824807389, "chrf_score": 74.66020620005752, "xcomet_score": 0.6161097288131714, "xcomet_qe_score": 0.4164246916770935, "metricx_score": 5.858210563659668, "metricx_qe_score": 9.684112548828125, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "pt", "output": "Mas com aquelas amostras que têm uma quantidade não usada, é na verdade muito pior do que o... muito pior do que...", "metrics": {"bleu_score": 15.511550090520089, "chrf_score": 45.443909768534134, "xcomet_score": 0.45356807112693787, "xcomet_qe_score": 0.5614229440689087, "metricx_score": 14.481794357299805, "metricx_qe_score": 16.034975051879883, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "pt", "output": "Para o desempenho, no caso do MAWP, não temos muitos casos de disco, então eu simplesmente ignoro essa parte.", "metrics": {"bleu_score": 34.53786557868503, "chrf_score": 69.97780074305288, "xcomet_score": 0.6465432047843933, "xcomet_qe_score": 0.6172189116477966, "metricx_score": 8.511941909790039, "metricx_qe_score": 9.063326835632324, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "pt", "output": "Finalmente, queremos mostrar a interpretabilidade por meio de um exemplo de previsão de falhas.", "metrics": {"bleu_score": 47.92365811426397, "chrf_score": 68.90755678719502, "xcomet_score": 0.7523429989814758, "xcomet_qe_score": 0.7808331847190857, "metricx_score": 6.13383674621582, "metricx_qe_score": 5.251100540161133, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, nosso modelo faz uma previsão errada no primeiro passo.", "metrics": {"bleu_score": 47.64047777451161, "chrf_score": 75.38369686837306, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9918860197067261, "metricx_qe_score": 0.9118624925613403, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "pt", "output": "Então, podemos realmente correlacionar essa expressão com a frase aqui, tudo bem?", "metrics": {"bleu_score": 28.295596283263514, "chrf_score": 79.51310933995236, "xcomet_score": 0.9963105916976929, "xcomet_qe_score": 0.9984011650085449, "metricx_score": 0.6689449548721313, "metricx_qe_score": 1.128166675567627, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, acreditamos que essa frase pode estar induzindo o modelo a uma previsão incorreta.", "metrics": {"bleu_score": 13.259061490238889, "chrf_score": 53.96863759941777, "xcomet_score": 0.9996660947799683, "xcomet_qe_score": 0.9978290796279907, "metricx_score": 0.5997024774551392, "metricx_qe_score": 0.639153778553009, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, plantar outro 35 faz o modelo pensar que deve ser um operador de adição.", "metrics": {"bleu_score": 50.945362863007105, "chrf_score": 70.39632280518776, "xcomet_score": 0.7353763580322266, "xcomet_qe_score": 0.5676759481430054, "metricx_score": 4.7947587966918945, "metricx_qe_score": 6.882423400878906, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "pt", "output": "Então, tentamos revisar a frase para algo como \"o número de pereiras é 55 menor do que o de macieiras\".", "metrics": {"bleu_score": 18.747025716022478, "chrf_score": 57.56655815193563, "xcomet_score": 0.938522458076477, "xcomet_qe_score": 0.9532889723777771, "metricx_score": 5.439632892608643, "metricx_qe_score": 5.273991107940674, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "pt", "output": "Então, fazemos com que ele transmita uma semântica mais precisa, de modo que o modelo possa fazer a previsão correta.", "metrics": {"bleu_score": 44.9978150715202, "chrf_score": 67.19891925289612, "xcomet_score": 0.9825739860534668, "xcomet_qe_score": 0.9828145503997803, "metricx_score": 1.4539135694503784, "metricx_qe_score": 1.2172245979309082, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "pt", "output": "Este estudo mostra como as previsões interpretáveis nos ajudam a entender o comportamento do modelo.", "metrics": {"bleu_score": 65.72677895577044, "chrf_score": 82.44176667106102, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0858381986618042, "metricx_qe_score": 0.9799302220344543, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, para concluir nosso trabalho, nosso modelo é, na verdade, bastante eficiente.", "metrics": {"bleu_score": 20.43378654533579, "chrf_score": 56.36802155636034, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.6305999755859375, "metricx_qe_score": 1.1989326477050781, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "pt", "output": "E somos capazes de fornecer um procedimento de resolução interpretável.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8213241100311279, "metricx_qe_score": 1.3524597883224487, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "pt", "output": "E podemos facilmente incorporar algum conhecimento prévio como restrição, o que pode ajudar a melhorar o desempenho.", "metrics": {"bleu_score": 79.12619863720215, "chrf_score": 97.81703499604805, "xcomet_score": 0.9989457130432129, "xcomet_qe_score": 0.9947923421859741, "metricx_score": 1.1728992462158203, "metricx_qe_score": 1.4524670839309692, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "pt", "output": "E a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio em várias etapas.", "metrics": {"bleu_score": 88.39836644191527, "chrf_score": 92.06261339823776, "xcomet_score": 0.993249773979187, "xcomet_qe_score": 0.9928238391876221, "metricx_score": 0.9268302917480469, "metricx_qe_score": 1.0146455764770508, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "pt", "output": "Mas também temos certas limitações.", "metrics": {"bleu_score": 50.81327481546149, "chrf_score": 93.8440976719106, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.04917246103286743, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "pt", "output": "Se tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8757706880569458, "metricx_qe_score": 0.8983515501022339, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "pt", "output": "E a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada em diferentes passos de tempo, também é bastante desafiador aplicar a busca de feixe.", "metrics": {"bleu_score": 78.07014316465984, "chrf_score": 84.88718391844263, "xcomet_score": 0.838792085647583, "xcomet_qe_score": 0.8616500496864319, "metricx_score": 2.9268312454223633, "metricx_qe_score": 3.935375690460205, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "pt", "output": "Este é o fim da palestra e as perguntas são bem-vindas. Obrigado.", "metrics": {"bleu_score": 71.38957847176475, "chrf_score": 90.91884246929614, "xcomet_score": 0.9999065399169922, "xcomet_qe_score": 0.9993921518325806, "metricx_score": 0.27652665972709656, "metricx_qe_score": 0.3706345558166504, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "pt", "output": "Olá, meu nome é Antoine e sou da Universidade de Maastricht.", "metrics": {"bleu_score": 81.49492131269727, "chrf_score": 93.39775544177442, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.48195788264274597, "metricx_qe_score": 0.19944792985916138, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "pt", "output": "Vou apresentar meu trabalho conjunto com o Jerry, que trata de um novo conjunto de dados para a recuperação de artigos estatutários.", "metrics": {"bleu_score": 51.981601535894555, "chrf_score": 85.06663709960532, "xcomet_score": 0.9636491537094116, "xcomet_qe_score": 0.8236417770385742, "metricx_score": 1.2794852256774902, "metricx_qe_score": 1.118618130683899, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "pt", "output": "Questões legais são uma parte integrante da vida de muitas pessoas.", "metrics": {"bleu_score": 73.48889200874659, "chrf_score": 93.93589890868117, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6165235042572021, "metricx_qe_score": 0.9200009107589722, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "pt", "output": "Mas a maioria dos cidadãos tem pouco ou nenhum conhecimento sobre seus direitos e processos legais fundamentais.", "metrics": {"bleu_score": 69.12804407652906, "chrf_score": 91.83235261309986, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.581822395324707, "metricx_qe_score": 0.5356807708740234, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "pt", "output": "Como resultado, muitos cidadãos vulneráveis que não podem pagar pela assistência cara de um especialista jurídico ficam desprotegidos ou, pior ainda, são explorados.", "metrics": {"bleu_score": 55.42373671228977, "chrf_score": 79.78307000459463, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5930364727973938, "metricx_qe_score": 0.6272422075271606, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "pt", "output": "Nosso trabalho visa preencher a lacuna entre as pessoas e a lei, desenvolvendo um sistema eficaz de recuperação de artigos legais.", "metrics": {"bleu_score": 35.04300832392594, "chrf_score": 57.408722399719146, "xcomet_score": 0.954063892364502, "xcomet_qe_score": 0.8806160688400269, "metricx_score": 3.74800705909729, "metricx_qe_score": 3.662066698074341, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "pt", "output": "Um sistema assim poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.", "metrics": {"bleu_score": 81.93228857188173, "chrf_score": 93.45636864717173, "xcomet_score": 0.993453860282898, "xcomet_qe_score": 0.9744552969932556, "metricx_score": 1.34636652469635, "metricx_qe_score": 2.0006232261657715, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "pt", "output": "Antes de mergulharmos na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.", "metrics": {"bleu_score": 87.39351325046809, "chrf_score": 97.33085074581098, "xcomet_score": 0.9875257015228271, "xcomet_qe_score": 0.9140729904174805, "metricx_score": 1.4917051792144775, "metricx_qe_score": 2.7642054557800293, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "pt", "output": "Dada uma pergunta simples sobre o assunto de alelos, como \"O que arrisco se violar a confidencialidade profissional?\"", "metrics": {"bleu_score": 17.58818104423743, "chrf_score": 57.82939023968614, "xcomet_score": 0.7310056686401367, "xcomet_qe_score": 0.617315411567688, "metricx_score": 8.4693021774292, "metricx_qe_score": 9.42053508758545, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "pt", "output": "É necessário um modelo para recuperar todos os artigos estatutários relevantes de um grande corpo de legislação.", "metrics": {"bleu_score": 56.86658363061539, "chrf_score": 85.2161554883648, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.7457435131072998, "metricx_qe_score": 2.2832343578338623, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "pt", "output": "Essa tarefa de recuperação de informações vem com seu próprio conjunto de desafios.", "metrics": {"bleu_score": 72.85959997974687, "chrf_score": 91.54242697352774, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5091642737388611, "metricx_qe_score": 0.31586989760398865, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, ele lida com dois tipos de linguagem.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 90.90962038606844, "xcomet_score": 0.9316500425338745, "xcomet_qe_score": 0.9864420890808105, "metricx_score": 0.9986432790756226, "metricx_qe_score": 1.3294919729232788, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "pt", "output": "Linguagem natural comum para as perguntas e linguagem legal complexa para os estatutos.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 86.93880469363852, "xcomet_score": 0.9936614036560059, "xcomet_qe_score": 0.9854483604431152, "metricx_score": 2.251082181930542, "metricx_qe_score": 2.089169502258301, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "pt", "output": "Essa diferença nas distribuições de linguagem torna mais difícil para um sistema recuperar candidatos relevantes, pois exige indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural em uma pergunta jurídica que corresponda à terminologia das leis.", "metrics": {"bleu_score": 64.32156215369966, "chrf_score": 83.19035787560112, "xcomet_score": 0.9705231189727783, "xcomet_qe_score": 0.860763430595398, "metricx_score": 3.5315654277801514, "metricx_qe_score": 3.9474129676818848, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por si só, como notícias ou receitas, por exemplo.", "metrics": {"bleu_score": 79.35848893573245, "chrf_score": 85.49350391259976, "xcomet_score": 0.9735190868377686, "xcomet_qe_score": 0.98931884765625, "metricx_score": 2.197148323059082, "metricx_qe_score": 3.515242576599121, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "pt", "output": "Em vez disso, é uma coleção estruturada de disposições legais que têm um significado completo apenas quando consideradas em seu contexto geral, ou seja, juntamente com as informações suplementares de seus artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.", "metrics": {"bleu_score": 78.04243332888781, "chrf_score": 92.83911562653944, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6706362962722778, "metricx_qe_score": 0.8125365972518921, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "pt", "output": "Por último, os artigos estatutários não são pequenos parágrafos, que geralmente é a unidade de recuperação típica na maioria dos trabalhos de recuperação.", "metrics": {"bleu_score": 51.47982081610748, "chrf_score": 82.48165898451411, "xcomet_score": 0.6965257525444031, "xcomet_qe_score": 0.7453991174697876, "metricx_score": 4.480276107788086, "metricx_qe_score": 6.454948902130127, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui, há documentos longos que podem ter até 6.000 palavras.", "metrics": {"bleu_score": 52.50459577889848, "chrf_score": 69.86868767982865, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.168068766593933, "metricx_qe_score": 0.9818003177642822, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "pt", "output": "Os recentes avanços em PLN despertaram grande interesse em muitas tarefas jurídicas, como previsão de julgamento jurídico ou revisão automática de contrato.", "metrics": {"bleu_score": 21.81359087876922, "chrf_score": 64.60994066704238, "xcomet_score": 0.791839599609375, "xcomet_qe_score": 0.8391284942626953, "metricx_score": 4.379950046539307, "metricx_qe_score": 3.8720507621765137, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "pt", "output": "Mas a recuperação de artigos estatutários permaneceu principalmente intocada devido à falta de grandes conjuntos de dados rotulados de alta qualidade.", "metrics": {"bleu_score": 65.4705869701392, "chrf_score": 88.74622541410797, "xcomet_score": 0.9499361515045166, "xcomet_qe_score": 0.8819551467895508, "metricx_score": 4.046178340911865, "metricx_qe_score": 4.98828649520874, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "pt", "output": "Neste trabalho, apresentamos um novo conjunto de dados em francês, voltado para o cidadão, para estudar se um modelo de recuperação pode aproximar a eficiência e a confiabilidade de um especialista jurídico para a tarefa de recuperação de artigos legais.", "metrics": {"bleu_score": 47.244555047851954, "chrf_score": 77.18854278993884, "xcomet_score": 0.7288833856582642, "xcomet_qe_score": 0.6756640672683716, "metricx_score": 5.089718341827393, "metricx_qe_score": 5.298393726348877, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "pt", "output": "O conjunto de dados de recuperação de artigos estatutários belgas consiste em mais de 1.100 leis.", "metrics": {"bleu_score": 26.74754400186342, "chrf_score": 56.34242722789304, "xcomet_score": 0.6005641222000122, "xcomet_qe_score": 0.671789288520813, "metricx_score": 12.739936828613281, "metricx_qe_score": 13.14453411102295, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "pt", "output": "Essas perguntas abrangem uma ampla gama de tópicos, desde família, moradia, dinheiro, trabalho e segurança social.", "metrics": {"bleu_score": 81.37489370974959, "chrf_score": 86.05214762356505, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5269884467124939, "metricx_qe_score": 0.47695809602737427, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "pt", "output": "Cada um deles foi rotulado por um jurista experiente com referências a artigos relevantes de um corpus de mais de 22.600.", "metrics": {"bleu_score": 34.55226413107887, "chrf_score": 52.31203958443198, "xcomet_score": 0.5601403713226318, "xcomet_qe_score": 0.6076846122741699, "metricx_score": 7.4155964851379395, "metricx_qe_score": 12.071785926818848, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos agora falar sobre como coletamos esses conjuntos de dados.", "metrics": {"bleu_score": 46.92470064105599, "chrf_score": 70.1258378924065, "xcomet_score": 0.9919066429138184, "xcomet_qe_score": 0.9840200543403625, "metricx_score": 0.9537842869758606, "metricx_qe_score": 0.9143826961517334, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, começamos compilando um grande corpus de artigos legais.", "metrics": {"bleu_score": 17.676084425360003, "chrf_score": 53.97694690841599, "xcomet_score": 0.9785085916519165, "xcomet_qe_score": 0.9779907464981079, "metricx_score": 2.3899662494659424, "metricx_qe_score": 1.4362233877182007, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "pt", "output": "Consideramos 32 códigos belgas de acesso público e extraímos todos os seus artigos, bem como os cabeçalhos das seções correspondentes.", "metrics": {"bleu_score": 32.21135973222974, "chrf_score": 60.68325502916559, "xcomet_score": 0.9643136262893677, "xcomet_qe_score": 1.0, "metricx_score": 1.835108757019043, "metricx_qe_score": 1.975427508354187, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "pt", "output": "Em seguida, reunimos perguntas jurídicas com referências a estatutos relevantes.", "metrics": {"bleu_score": 73.48889200874659, "chrf_score": 88.15674526408978, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2641140222549438, "metricx_qe_score": 2.070004463195801, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "pt", "output": "Para isso, associamo-nos a um escritório de advocacia belga que recebe, todos os anos, cerca de 4.000 e-mails de cidadãos belgas que pedem conselhos sobre questões legais pessoais.", "metrics": {"bleu_score": 38.32544339233122, "chrf_score": 60.189013014257895, "xcomet_score": 0.992121696472168, "xcomet_qe_score": 1.0, "metricx_score": 1.5601118803024292, "metricx_qe_score": 1.1453691720962524, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "pt", "output": "Tivemos a sorte de ter acesso aos sites deles, onde sua equipe de juristas experientes aborda os problemas jurídicos mais comuns da Bélgica.", "metrics": {"bleu_score": 37.345311611682654, "chrf_score": 70.58323922306622, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.9621262550354004, "metricx_qe_score": 1.6577777862548828, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "pt", "output": "Coletamos milhares de perguntas, anotadas com categorias, subcategorias e referências legais a estatutos relevantes.", "metrics": {"bleu_score": 76.24658586234858, "chrf_score": 91.16447659948767, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.4769117832183838, "metricx_qe_score": 1.7388373613357544, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "pt", "output": "Por fim, passamos as referências legais e filtramos as perguntas cujas referências não eram artigos de um dos códigos de lei que consideramos.", "metrics": {"bleu_score": 48.5011324041493, "chrf_score": 81.0789919524851, "xcomet_score": 0.9760825634002686, "xcomet_qe_score": 0.9594374299049377, "metricx_score": 2.527606964111328, "metricx_qe_score": 4.511195182800293, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "pt", "output": "As referências restantes foram correspondidas e convertidas para os IDs de artigos correspondentes do OCorpus.", "metrics": {"bleu_score": 28.572802657788227, "chrf_score": 60.8688804705819, "xcomet_score": 0.8305695056915283, "xcomet_qe_score": 0.9318121671676636, "metricx_score": 5.098696231842041, "metricx_qe_score": 4.819194793701172, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "pt", "output": "Chegamos a 1.108 perguntas, cada uma cuidadosamente rotulada com as ideias dos artigos relevantes da Wikipedia.", "metrics": {"bleu_score": 14.330731471670756, "chrf_score": 38.19295963158189, "xcomet_score": 0.3174244165420532, "xcomet_qe_score": 0.2101942002773285, "metricx_score": 14.84274673461914, "metricx_qe_score": 16.258180618286133, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, cada pergunta vem com uma categoria principal e uma concatenação de subcategorias.", "metrics": {"bleu_score": 81.53551038173119, "chrf_score": 97.26877318350053, "xcomet_score": 0.997773289680481, "xcomet_qe_score": 0.9875147342681885, "metricx_score": 1.2583645582199097, "metricx_qe_score": 1.7294353246688843, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "pt", "output": "E cada artigo vem com a concatenação de seus títulos subsequentes na estrutura da lei.", "metrics": {"bleu_score": 47.92365811426397, "chrf_score": 73.45673095856009, "xcomet_score": 0.9968292713165283, "xcomet_qe_score": 0.935390293598175, "metricx_score": 3.3707473278045654, "metricx_qe_score": 4.389062404632568, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "pt", "output": "Essas informações adicionais não são usadas no trabalho atual, mas podem ser de interesse para pesquisas futuras sobre recuperação de informações jurídicas ou classificação de textos jurídicos.", "metrics": {"bleu_score": 17.829219655748442, "chrf_score": 63.46817894711606, "xcomet_score": 0.9995616674423218, "xcomet_qe_score": 1.0, "metricx_score": 0.3121393024921417, "metricx_qe_score": 0.385040283203125, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos ver algumas características de todos os conjuntos de dados.", "metrics": {"bleu_score": 17.542198478193427, "chrf_score": 69.3935360995488, "xcomet_score": 0.8848586082458496, "xcomet_qe_score": 0.8793050646781921, "metricx_score": 6.576719760894775, "metricx_qe_score": 5.230355262756348, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "pt", "output": "As perguntas têm entre 5 e 44 palavras, com uma mediana de 14 palavras.", "metrics": {"bleu_score": 29.197216182514165, "chrf_score": 49.623620757773956, "xcomet_score": 0.9949421882629395, "xcomet_qe_score": 0.9909505844116211, "metricx_score": 0.9141494035720825, "metricx_qe_score": 0.6070696711540222, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "pt", "output": "Os artigos são muito mais longos, com uma mediana de 77 palavras, com 140.", "metrics": {"bleu_score": 25.544982886965226, "chrf_score": 39.52073730922105, "xcomet_score": 0.6283016204833984, "xcomet_qe_score": 0.6478127241134644, "metricx_score": 15.948969841003418, "metricx_qe_score": 15.004538536071777, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "pt", "output": "Dois deles excederam 1.000.", "metrics": {"bleu_score": 2.634191962725227, "chrf_score": 7.092776781346812, "xcomet_score": 0.15752050280570984, "xcomet_qe_score": 0.15069495141506195, "metricx_score": 23.00385856628418, "metricx_qe_score": 16.27704429626465, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "pt", "output": "Como mencionado anteriormente, a questão abrange uma ampla gama de tópicos, com cerca de 85% deles sendo sobre família, moradia, dinheiro ou justiça.", "metrics": {"bleu_score": 53.77631568462311, "chrf_score": 68.77498906325084, "xcomet_score": 0.8919944167137146, "xcomet_qe_score": 0.88134765625, "metricx_score": 3.9866347312927246, "metricx_qe_score": 3.37148380279541, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "pt", "output": "enquanto os 15% restantes dizem respeito à segurança social, estrangeiros ou trabalho.", "metrics": {"bleu_score": 43.56033805378097, "chrf_score": 74.0569635262321, "xcomet_score": 0.9620919227600098, "xcomet_qe_score": 0.9706652164459229, "metricx_score": 2.1269123554229736, "metricx_qe_score": 2.8204517364501953, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "pt", "output": "Os artigos também são muito diversos, pois provêm de 32 diferentes códigos belgas que abrangem um grande número de tópicos legais.", "metrics": {"bleu_score": 30.370035667110344, "chrf_score": 64.64850128433565, "xcomet_score": 0.9634473323822021, "xcomet_qe_score": 0.9900791645050049, "metricx_score": 0.7499224543571472, "metricx_qe_score": 0.5266299843788147, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui está o número total de artigos coletados de cada um desses códigos belgas.", "metrics": {"bleu_score": 57.73502691896262, "chrf_score": 81.94928467911937, "xcomet_score": 0.9947435855865479, "xcomet_qe_score": 1.0, "metricx_score": 3.12457275390625, "metricx_qe_score": 4.193922996520996, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "pt", "output": "Dos 22.633 artigos, apenas 1.612 são considerados relevantes para pelo menos um dos 100 tópicos.", "metrics": {"bleu_score": 9.935082684285225, "chrf_score": 34.723577191028355, "xcomet_score": 0.3689698576927185, "xcomet_qe_score": 0.8937066793441772, "metricx_score": 6.767920970916748, "metricx_qe_score": 3.5359151363372803, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "pt", "output": "Uma questão nos conjuntos de dados. E cerca de 80% desses artigos citados vêm do Código Civil, do Código Judiciário, do Código de Investigação Criminal ou do Código Penal.", "metrics": {"bleu_score": 11.276958806531855, "chrf_score": 50.50508391246225, "xcomet_score": 0.253178209066391, "xcomet_qe_score": 0.1296037882566452, "metricx_score": 11.029999732971191, "metricx_qe_score": 12.223655700683594, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "pt", "output": "Enquanto isso, 18 dos 32 códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.", "metrics": {"bleu_score": 70.20458686590516, "chrf_score": 81.66302018826508, "xcomet_score": 0.9474256038665771, "xcomet_qe_score": 0.9042794704437256, "metricx_score": 1.3500549793243408, "metricx_qe_score": 1.8413476943969727, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "pt", "output": "O que pode ser explicado pelo fato de que o código de justiça penal se concentra menos nos indivíduos e em suas preocupações.", "metrics": {"bleu_score": 30.33668865762665, "chrf_score": 70.55676535381573, "xcomet_score": 0.9118859767913818, "xcomet_qe_score": 0.8600321412086487, "metricx_score": 3.7506675720214844, "metricx_qe_score": 3.9372494220733643, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "pt", "output": "No geral, o número mediano de citações para esses artigos citados é de 2, e menos de 25% deles têm", "metrics": {"bleu_score": 38.430809495795074, "chrf_score": 55.959782575057446, "xcomet_score": 0.6692146062850952, "xcomet_qe_score": 0.7336061000823975, "metricx_score": 13.336236000061035, "metricx_qe_score": 7.63313102722168, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "pt", "output": "Usando nossos conjuntos de dados, avaliamos vários métodos de recuperação, incluindo arquiteturas lexicais e densas.", "metrics": {"bleu_score": 27.545321289806534, "chrf_score": 68.520000211634, "xcomet_score": 0.9572880268096924, "xcomet_qe_score": 0.8923557996749878, "metricx_score": 1.2079851627349854, "metricx_qe_score": 1.9540027379989624, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "pt", "output": "Dado um termo de consulta e um artigo, um modelo lexical atribui uma pontuação à consulta do artigo calculando a soma dos termos de consulta dos pesos de cada um desses termos naquele artigo.", "metrics": {"bleu_score": 57.59805547278501, "chrf_score": 79.60665119097335, "xcomet_score": 0.7470502853393555, "xcomet_qe_score": 0.7570772171020508, "metricx_score": 5.6055803298950195, "metricx_qe_score": 6.307827949523926, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "pt", "output": "Fazemos experimentos com as funções de classificação TF-IDF e BM25 padrão.", "metrics": {"bleu_score": 71.02992180127417, "chrf_score": 85.4188042386598, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.1221375465393066, "metricx_qe_score": 2.6263344287872314, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "pt", "output": "O principal problema dessas abordagens é que elas só conseguem recuperar artigos que contenham palavras-chave presentes na consulta.", "metrics": {"bleu_score": 57.77966168512882, "chrf_score": 85.64457453638306, "xcomet_score": 0.9978227615356445, "xcomet_qe_score": 0.941847562789917, "metricx_score": 0.6668124794960022, "metricx_qe_score": 0.7715522050857544, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "pt", "output": "Para superar essa limitação, experimentamos uma arquitetura baseada em rede neural que pode capturar a relação semântica entre consultas e artigos.", "metrics": {"bleu_score": 33.57306484097324, "chrf_score": 79.05889203197388, "xcomet_score": 0.9741578102111816, "xcomet_qe_score": 0.9363363981246948, "metricx_score": 0.7560669183731079, "metricx_qe_score": 0.9102106094360352, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "pt", "output": "Utilizamos um modelo de codificador B que mapeia consultas e artigos em representações vetoriais densas e calcula uma pontuação de relevância entre um par de consulta e artigo pela similaridade de seus embeddings.", "metrics": {"bleu_score": 52.25561043328323, "chrf_score": 77.82190071126807, "xcomet_score": 0.6817403435707092, "xcomet_qe_score": 0.6933576464653015, "metricx_score": 7.615516662597656, "metricx_qe_score": 8.049629211425781, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "pt", "output": "Esses embeddings geralmente resultam de uma operação de pooling na saída de um modelo de embedding de palavras.", "metrics": {"bleu_score": 50.727846440621036, "chrf_score": 58.518425768868575, "xcomet_score": 0.5653858780860901, "xcomet_qe_score": 0.6619843244552612, "metricx_score": 10.170580863952637, "metricx_qe_score": 8.48694133758545, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, estudamos a eficácia dos codificadores Siamese em um cenário de avaliação zero-shot, o que significa que os modelos de incorporação de madeira pré-treinados são aplicados diretamente, sem nenhum ajuste fino adicional.", "metrics": {"bleu_score": 26.15386655084595, "chrf_score": 62.814728186284206, "xcomet_score": 0.5015162229537964, "xcomet_qe_score": 0.5897217392921448, "metricx_score": 9.897232055664062, "metricx_qe_score": 8.69568920135498, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "pt", "output": "Fazemos experimentos com codificadores de texto independentes de contexto, ou seja, Word2Vec e FastText, e modelos de incorporação dependentes de contexto, ou seja, RoBERTa e, mais especificamente, CamemBERT, que é um modelo de RoBERTa em francês.", "metrics": {"bleu_score": 22.673168629911785, "chrf_score": 68.21280458706528, "xcomet_score": 0.8737911581993103, "xcomet_qe_score": 0.9363243579864502, "metricx_score": 2.372675657272339, "metricx_qe_score": 2.3067049980163574, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, treinamos nosso próprio modelo baseado em CamemBERT, o BeyondCoder.", "metrics": {"bleu_score": 27.091430531233918, "chrf_score": 49.27082023937199, "xcomet_score": 0.7236951589584351, "xcomet_qe_score": 0.7653483152389526, "metricx_score": 7.937257766723633, "metricx_qe_score": 9.137195587158203, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "pt", "output": "Em todos os conjuntos de dados. Observe que, para o treinamento, experimentamos com as duas versões da arquitetura Bi-Encoder.", "metrics": {"bleu_score": 10.086853619665545, "chrf_score": 60.13298871871853, "xcomet_score": 0.7024135589599609, "xcomet_qe_score": 0.6132634878158569, "metricx_score": 9.781320571899414, "metricx_qe_score": 11.57302474975586, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "pt", "output": "Siamese, que utiliza um modelo de embedding de palavras único que mapeia a consulta e o artigo juntos em um espaço vetorial denso compartilhado, e Duas Torres, que utiliza dois modelos de embedding de palavras independentes que codificam a consulta e o artigo separadamente em espaços de embedding diferentes.", "metrics": {"bleu_score": 43.80139643462749, "chrf_score": 68.51227437543315, "xcomet_score": 0.43671315908432007, "xcomet_qe_score": 0.500246524810791, "metricx_score": 8.578617095947266, "metricx_qe_score": 7.795180320739746, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "pt", "output": "Fizemos experimentos com média, máximo e agrupamento CLS, bem como produto escalar e cosseno para calcular similaridades.", "metrics": {"bleu_score": 19.83544145418288, "chrf_score": 49.30707606445622, "xcomet_score": 0.832766592502594, "xcomet_qe_score": 0.8719348311424255, "metricx_score": 4.6025285720825195, "metricx_qe_score": 3.8337323665618896, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui estão os resultados de nossa linha de base no conjunto de teste.", "metrics": {"bleu_score": 26.58483576665878, "chrf_score": 73.03209740838528, "xcomet_score": 0.8637065291404724, "xcomet_qe_score": 0.7638146877288818, "metricx_score": 3.416660785675049, "metricx_qe_score": 5.707827568054199, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "pt", "output": "Com os métodos lexicais acima, os codificadores B siameses avaliados em um cenário de zero-shot no meio e os codificadores B ajustados finamente abaixo.", "metrics": {"bleu_score": 36.19779110707069, "chrf_score": 63.99142900411512, "xcomet_score": 0.6237964034080505, "xcomet_qe_score": 0.7739682197570801, "metricx_score": 8.276453971862793, "metricx_qe_score": 7.700699329376221, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "pt", "output": "No geral, o decodificador B de ajuste fino supera significativamente todos os outros modelos de linha de base.", "metrics": {"bleu_score": 15.316824552082009, "chrf_score": 59.97216145960454, "xcomet_score": 0.8245524168014526, "xcomet_qe_score": 0.8832517862319946, "metricx_score": 7.2642059326171875, "metricx_qe_score": 7.146187782287598, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "pt", "output": "O modelo de duas torres melhora em relação à sua variante siamesa no recall em 100, mas tem desempenho semelhante nas outras métricas.", "metrics": {"bleu_score": 49.948630153272354, "chrf_score": 75.11015345243146, "xcomet_score": 0.8830007910728455, "xcomet_qe_score": 0.90706467628479, "metricx_score": 5.691058158874512, "metricx_qe_score": 5.7683515548706055, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "pt", "output": "Embora o BM25 tenha ficado aquém do treinado BERT Coders significativamente, seu desempenho indica que ainda é uma linha de base forte para a recuperação específica do domínio.", "metrics": {"bleu_score": 29.900681795338027, "chrf_score": 64.23960850976181, "xcomet_score": 0.7224971652030945, "xcomet_qe_score": 0.6942156553268433, "metricx_score": 8.389986038208008, "metricx_qe_score": 8.79788589477539, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "pt", "output": "Quanto à avaliação zero-shot do codificador siamês, descobrimos que usar diretamente os embeddings de um modelo pré-treinado CamemBERT sem otimizar para a tarefa de recuperação de informações resulta em resultados ruins, o que é consistente com achados anteriores.", "metrics": {"bleu_score": 39.042373255571334, "chrf_score": 75.57145663055117, "xcomet_score": 0.6878616809844971, "xcomet_qe_score": 0.7202599048614502, "metricx_score": 4.7073469161987305, "metricx_qe_score": 3.9760444164276123, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, observamos que o codificador BERT baseado em Word2Vec superou significativamente o modelo baseado em FastText e BERT, sugerindo que talvez os embeddings de nível de palavra pré-treinados sejam mais apropriados para a tarefa do que os embeddings de nível de caractere ou subpalavra, quando usados diretamente.", "metrics": {"bleu_score": 32.470655394167764, "chrf_score": 69.4383777968005, "xcomet_score": 0.5906890034675598, "xcomet_qe_score": 0.6203286647796631, "metricx_score": 7.945629596710205, "metricx_qe_score": 7.135509490966797, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "pt", "output": "Embora promissores, esses resultados sugerem uma ampla oportunidade de melhoria em comparação com um especialista experiente que eventualmente pode recuperar todos os artigos relevantes para qualquer pergunta e, portanto, obter pontuações perfeitas.", "metrics": {"bleu_score": 52.92031904718656, "chrf_score": 78.82999466021438, "xcomet_score": 0.9869691133499146, "xcomet_qe_score": 0.9827708601951599, "metricx_score": 2.456202268600464, "metricx_qe_score": 4.189763069152832, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos concluir discutindo duas limitações de nossos conjuntos de dados.", "metrics": {"bleu_score": 46.92470064105599, "chrf_score": 84.3538899591102, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9326750040054321, "metricx_qe_score": 0.9488751292228699, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, o corpus do artigo é limitado àqueles coletados dos 32 códigos belgas considerados, o que não cobre toda a lei belga, pois faltam artigos de decretos, diretivas e ordenanças.", "metrics": {"bleu_score": 37.26772786815288, "chrf_score": 56.101188347028575, "xcomet_score": 0.846422553062439, "xcomet_qe_score": 0.8589634895324707, "metricx_score": 4.376716613769531, "metricx_qe_score": 3.9773449897766113, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "pt", "output": "Durante a construção do conjunto de dados, todas as referências a esses artigos não coletados são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.", "metrics": {"bleu_score": 86.63332145328006, "chrf_score": 93.5415970224446, "xcomet_score": 0.9901537895202637, "xcomet_qe_score": 0.9711427688598633, "metricx_score": 2.2886247634887695, "metricx_qe_score": 2.8656270503997803, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "pt", "output": "Essa perda de informação implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora ainda seja totalmente apropriada.", "metrics": {"bleu_score": 62.89898918404589, "chrf_score": 80.36486779324437, "xcomet_score": 0.9810460805892944, "xcomet_qe_score": 0.9796967506408691, "metricx_score": 2.4146835803985596, "metricx_qe_score": 2.813678026199341, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "pt", "output": "Em segundo lugar, devemos notar que nem todas as questões legais podem ser respondidas apenas com estatutos.", "metrics": {"bleu_score": 45.45091839935172, "chrf_score": 71.42804693869735, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9081447124481201, "metricx_qe_score": 1.460587501525879, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, a pergunta \"Posso expulsar meus inquilinos se eles fizerem muito barulho?\"", "metrics": {"bleu_score": 42.9513694636652, "chrf_score": 73.45048339349304, "xcomet_score": 0.9725733995437622, "xcomet_qe_score": 0.9854698181152344, "metricx_score": 1.6626207828521729, "metricx_qe_score": 1.7190933227539062, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "pt", "output": "Pode não haver uma resposta detalhada na lei que quantifique um nível específico de ruído que permita a despejo.", "metrics": {"bleu_score": 12.3565157483022, "chrf_score": 54.42850344420288, "xcomet_score": 0.92425936460495, "xcomet_qe_score": 0.8720567226409912, "metricx_score": 4.033308506011963, "metricx_qe_score": 3.0952181816101074, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "pt", "output": "Em vez disso, o proprietário provavelmente deveria confiar mais no direito consuetudinário e encontrar precedentes semelhantes à sua situação atual.", "metrics": {"bleu_score": 65.54353481249281, "chrf_score": 83.03711414323313, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 4.051290512084961, "metricx_qe_score": 4.668227672576904, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, o inquilino faz duas festas por semana até as 22h.", "metrics": {"bleu_score": 31.744430345967675, "chrf_score": 62.86609544596067, "xcomet_score": 0.9493528008460999, "xcomet_qe_score": 0.9027018547058105, "metricx_score": 6.615665435791016, "metricx_qe_score": 4.893031597137451, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas ainda precisa ser determinado.", "metrics": {"bleu_score": 79.71998219503662, "chrf_score": 83.78597365640371, "xcomet_score": 0.98381507396698, "xcomet_qe_score": 0.8556650876998901, "metricx_score": 2.08164381980896, "metricx_qe_score": 3.653876304626465, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "pt", "output": "Esperamos que nosso trabalho desperte interesse no desenvolvimento de modelos práticos e confiáveis de recuperação de artigos estatutários.", "metrics": {"bleu_score": 59.859453134337784, "chrf_score": 91.94266747434203, "xcomet_score": 0.9888429641723633, "xcomet_qe_score": 0.9111999273300171, "metricx_score": 1.099609375, "metricx_qe_score": 1.3426518440246582, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "pt", "output": "Isso pode ajudar a melhorar o acesso à justiça para todos.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.36027467250823975, "metricx_qe_score": 0.5917980074882507, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "pt", "output": "Você pode conferir nosso artigo, dados e código nos seguintes links. Obrigado.", "metrics": {"bleu_score": 25.49428341528868, "chrf_score": 59.523472018209276, "xcomet_score": 0.9721658229827881, "xcomet_qe_score": 1.0, "metricx_score": 0.5689922571182251, "metricx_qe_score": 0.5700542330741882, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "pt", "output": "Olá, estamos felizes em apresentar nosso trabalho sobre o VALSE, um benchmark independente de tarefas, destinado a testar modelos de visão e linguagem com fenômenos linguísticos específicos.", "metrics": {"bleu_score": 35.365562765107335, "chrf_score": 73.0073053926172, "xcomet_score": 0.9468202590942383, "xcomet_qe_score": 0.9205692410469055, "metricx_score": 3.6041886806488037, "metricx_qe_score": 3.31300950050354, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "pt", "output": "Por que nos demos ao trabalho de configurar este benchmark?", "metrics": {"bleu_score": 8.606119900909883, "chrf_score": 28.47700280098205, "xcomet_score": 0.9754507541656494, "xcomet_qe_score": 1.0, "metricx_score": 5.274106502532959, "metricx_qe_score": 3.5104970932006836, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "pt", "output": "Bem, nos últimos anos, vimos uma explosão de modelos de visão e linguagem baseados em transformadores, pré-treinados em grandes quantidades de pares de imagem-texto.", "metrics": {"bleu_score": 47.10414827699271, "chrf_score": 82.6837261060415, "xcomet_score": 0.9853678941726685, "xcomet_qe_score": 0.9835807085037231, "metricx_score": 2.689235210418701, "metricx_qe_score": 3.230893135070801, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "pt", "output": "Cada um desses modelos avança o estado da arte em tarefas de visão e linguagem, como resposta a perguntas visuais, raciocínio de senso comum visual, recuperação de imagens, ancoragem de frases.", "metrics": {"bleu_score": 20.567868158470002, "chrf_score": 52.89119143050544, "xcomet_score": 0.7846171259880066, "xcomet_qe_score": 0.7741382122039795, "metricx_score": 5.382073402404785, "metricx_qe_score": 4.782246112823486, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "pt", "output": "Então, recebemos uma mensagem: as acurácias nesses benchmarks específicos de tarefa estão aumentando de forma constante.", "metrics": {"bleu_score": 29.720875426237964, "chrf_score": 59.886877181221074, "xcomet_score": 0.9427478313446045, "xcomet_qe_score": 0.9418168067932129, "metricx_score": 5.825279235839844, "metricx_qe_score": 5.355733871459961, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "pt", "output": "Mas sabemos o que os modelos realmente aprenderam?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8622552752494812, "metricx_qe_score": 1.9458999633789062, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "pt", "output": "O que um transformador de visão e linguagem entende quando atribui uma pontuação alta para que esta imagem e esta frase combinem?", "metrics": {"bleu_score": 45.26762556658673, "chrf_score": 67.15885672128779, "xcomet_score": 0.9190285205841064, "xcomet_qe_score": 0.825224757194519, "metricx_score": 2.3731703758239746, "metricx_qe_score": 2.968590021133423, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "pt", "output": "E a pontuação mais baixa para este.", "metrics": {"bleu_score": 25.848657697858535, "chrf_score": 77.23532667641747, "xcomet_score": 0.8831503987312317, "xcomet_qe_score": 0.9556118249893188, "metricx_score": 1.819245457649231, "metricx_qe_score": 1.6339566707611084, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "pt", "output": "Os modelos de visão e linguagem focam no que é certo?", "metrics": {"bleu_score": 15.580105704117443, "chrf_score": 46.93845692306931, "xcomet_score": 0.9966753721237183, "xcomet_qe_score": 0.9783897399902344, "metricx_score": 2.120863199234009, "metricx_qe_score": 3.4418914318084717, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "pt", "output": "Ou eles se concentram em vieses, como demonstrado em trabalhos anteriores?", "metrics": {"bleu_score": 4.368583925857938, "chrf_score": 46.996107514007164, "xcomet_score": 0.8978986144065857, "xcomet_qe_score": 0.9525589942932129, "metricx_score": 2.6826889514923096, "metricx_qe_score": 1.5091763734817505, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "pt", "output": "Para lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica em relação à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de visão e linguagem a fenômenos linguísticos específicos que afetam tanto a modalidade linguística quanto a visual.", "metrics": {"bleu_score": 61.338469589075125, "chrf_score": 86.24335256604, "xcomet_score": 0.7511841058731079, "xcomet_qe_score": 0.7914251685142517, "metricx_score": 2.064736843109131, "metricx_qe_score": 3.010409116744995, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "pt", "output": "Nós focamos em existência, pluralidade, contagem, relações espaciais, ações e coreferência de entidades.", "metrics": {"bleu_score": 56.52080307919821, "chrf_score": 81.54477088662928, "xcomet_score": 0.9487562775611877, "xcomet_qe_score": 0.9526257514953613, "metricx_score": 3.338881731033325, "metricx_qe_score": 4.021676540374756, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "pt", "output": "Mas como testamos se os modelos de visão e linguagem captaram esse fenômeno?", "metrics": {"bleu_score": 48.41524713034602, "chrf_score": 71.94322664725425, "xcomet_score": 0.9449294805526733, "xcomet_qe_score": 0.9758328795433044, "metricx_score": 1.1275819540023804, "metricx_qe_score": 1.8823453187942505, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "pt", "output": "por meio de FOILing, um método anteriormente aplicado para modelos de visão e linguagem apenas para frases nominais por Ravi Shekhar e colaboradores e para contagem por nós em trabalhos anteriores.", "metrics": {"bleu_score": 48.3573975211448, "chrf_score": 76.44143040627382, "xcomet_score": 0.6249624490737915, "xcomet_qe_score": 0.7870347499847412, "metricx_score": 8.931280136108398, "metricx_qe_score": 6.904023170471191, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "pt", "output": "\"Foiling\" significa, basicamente, que pegamos a legenda de uma imagem e produzimos um \"foil\" alterando a legenda de modo que ela não descreva mais a imagem.", "metrics": {"bleu_score": 31.443515194397026, "chrf_score": 62.85864203064443, "xcomet_score": 0.6709996461868286, "xcomet_qe_score": 0.9712091088294983, "metricx_score": 7.835204124450684, "metricx_qe_score": 6.184060573577881, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "pt", "output": "E fazemos essas alterações de frase focando em seis partes específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada parte pode consistir em um ou mais instrumentos, caso tenhamos encontrado mais de uma maneira interessante de criar instâncias de FOIL.", "metrics": {"bleu_score": 63.133495200987205, "chrf_score": 80.01232131347807, "xcomet_score": 0.6887906193733215, "xcomet_qe_score": 0.6900525093078613, "metricx_score": 4.559803009033203, "metricx_qe_score": 4.790163993835449, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, no caso da peça de ação, temos dois instrumentos, um em que o verbo de ação é alterado por uma ação diferente e outro em que os actantes são trocados.", "metrics": {"bleu_score": 77.21060576667051, "chrf_score": 87.76831411852703, "xcomet_score": 0.7254438400268555, "xcomet_qe_score": 0.6720039248466492, "metricx_score": 4.878018379211426, "metricx_qe_score": 6.230745315551758, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "pt", "output": "Contagem e correferência também são peças que têm mais de um instrumento.", "metrics": {"bleu_score": 76.11606003349888, "chrf_score": 87.63593286062218, "xcomet_score": 0.796010434627533, "xcomet_qe_score": 0.7172844409942627, "metricx_score": 3.9774932861328125, "metricx_qe_score": 5.924042224884033, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "pt", "output": "E criamos essas folhas ao garantir que elas não descrevam a imagem, que sejam gramaticalmente corretas e, de outra forma, frases válidas.", "metrics": {"bleu_score": 8.74664932833685, "chrf_score": 49.31625247438925, "xcomet_score": 0.5711373090744019, "xcomet_qe_score": 0.6404874920845032, "metricx_score": 7.541383266448975, "metricx_qe_score": 8.546279907226562, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "pt", "output": "Isso não é fácil de fazer, pois uma legenda alterada pode ser menos provável do que a legenda original.", "metrics": {"bleu_score": 63.64058876086589, "chrf_score": 79.52841206217218, "xcomet_score": 0.9445453882217407, "xcomet_qe_score": 0.9790887832641602, "metricx_score": 1.151123285293579, "metricx_qe_score": 1.4646233320236206, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem cortar plantas, e grandes modelos de visão e linguagem poderiam captar isso.", "metrics": {"bleu_score": 68.75965181003812, "chrf_score": 87.02390415830864, "xcomet_score": 0.937836766242981, "xcomet_qe_score": 0.9242919683456421, "metricx_score": 5.003876686096191, "metricx_qe_score": 4.7427544593811035, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, para obter folhas válidas, devemos agir.", "metrics": {"bleu_score": 52.53819788848316, "chrf_score": 63.52528670629356, "xcomet_score": 0.7875575423240662, "xcomet_qe_score": 0.9743894338607788, "metricx_score": 7.319972515106201, "metricx_qe_score": 3.821815252304077, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, fazemos uso de modelos linguísticos fortes para propor folhas.", "metrics": {"bleu_score": 50.16513759455242, "chrf_score": 68.32119531128174, "xcomet_score": 0.6488994359970093, "xcomet_qe_score": 0.7481447458267212, "metricx_score": 8.134649276733398, "metricx_qe_score": 6.221218109130859, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "pt", "output": "Em segundo lugar, utilizamos a inferência de linguagem natural, ou NLI, para filtrar os foils que ainda poderiam descrever a imagem, pois, ao construir foils, é necessário garantir que eles não descrevam a imagem.", "metrics": {"bleu_score": 14.755030339831421, "chrf_score": 53.77085299522002, "xcomet_score": 0.6927300691604614, "xcomet_qe_score": 0.8126916885375977, "metricx_score": 10.839144706726074, "metricx_qe_score": 9.873056411743164, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "pt", "output": "Para testar isso automaticamente, aplicamos inferência de linguagem natural com a seguinte lógica.", "metrics": {"bleu_score": 14.247788801610149, "chrf_score": 61.958130246766316, "xcomet_score": 0.9998018741607666, "xcomet_qe_score": 1.0, "metricx_score": 0.9764822125434875, "metricx_qe_score": 0.8583123683929443, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "pt", "output": "Consideramos uma imagem como premissa e sua legenda como hipótese implícita.", "metrics": {"bleu_score": 25.745264623946024, "chrf_score": 74.1823540465117, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5402061343193054, "metricx_qe_score": 0.4487861692905426, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, consideramos a legenda como premissa e a armadilha como sua hipótese.", "metrics": {"bleu_score": 44.300069361967545, "chrf_score": 70.85844289776414, "xcomet_score": 0.7970630526542664, "xcomet_qe_score": 0.7221870422363281, "metricx_score": 4.220662593841553, "metricx_qe_score": 4.437226295471191, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "pt", "output": "Se um modelo NLI prevê que a FOIL contradiz ou é neutra em relação à legenda, consideramos isso um indicador de uma FOIL válida.", "metrics": {"bleu_score": 50.11690455862063, "chrf_score": 62.145802657366076, "xcomet_score": 0.6698307991027832, "xcomet_qe_score": 0.70259028673172, "metricx_score": 7.236695766448975, "metricx_qe_score": 5.659169673919678, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "pt", "output": "Se um NLI prevê que o foil é uma consequência da legenda, ele não pode ser um bom foil, pois, por transitividade, ele fornecerá uma descrição verdadeira da imagem e nós filtramos esses foils.", "metrics": {"bleu_score": 23.27791012589559, "chrf_score": 54.134582691944686, "xcomet_score": 0.42815494537353516, "xcomet_qe_score": 0.5461660623550415, "metricx_score": 15.328917503356934, "metricx_qe_score": 10.264665603637695, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "pt", "output": "Mas este procedimento não é perfeito. É apenas um indicador de folhas válidas.", "metrics": {"bleu_score": 44.80304273880272, "chrf_score": 72.19406937548143, "xcomet_score": 0.7302312850952148, "xcomet_qe_score": 0.8850415945053101, "metricx_score": 4.466758728027344, "metricx_qe_score": 1.6648354530334473, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, como uma terceira medida para gerar FOIs válidos, empregamos anotadores humanos para validar os dados usados no VALSE.", "metrics": {"bleu_score": 77.393215404741, "chrf_score": 82.1422184220682, "xcomet_score": 0.8882756233215332, "xcomet_qe_score": 0.9795359373092651, "metricx_score": 4.556202411651611, "metricx_qe_score": 4.29314661026001, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "pt", "output": "Então, depois de filtrar e avaliar manualmente, temos tantas instâncias de teste quanto as descritas nesta tabela.", "metrics": {"bleu_score": 31.56961170682444, "chrf_score": 59.36301465873238, "xcomet_score": 0.9947788715362549, "xcomet_qe_score": 0.9955407381057739, "metricx_score": 1.8431780338287354, "metricx_qe_score": 1.2808414697647095, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "pt", "output": "Observe que o VALSE não fornece dados de treinamento, apenas dados de teste.", "metrics": {"bleu_score": 48.176104471900615, "chrf_score": 67.18859831267648, "xcomet_score": 0.9752967357635498, "xcomet_qe_score": 1.0, "metricx_score": 0.7187739014625549, "metricx_qe_score": 0.8126687407493591, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "pt", "output": "Como é um benchmark de teste de zero-shot, ele é projetado para aproveitar as capacidades existentes de modelos de visão e linguagem após o pré-treinamento.", "metrics": {"bleu_score": 26.54061218609977, "chrf_score": 61.65604905587243, "xcomet_score": 0.725269079208374, "xcomet_qe_score": 0.7529213428497314, "metricx_score": 5.578763961791992, "metricx_qe_score": 4.893984794616699, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "pt", "output": "O ajuste fino permitiria que os modelos explorassem artefatos ou vies estatísticos nos dados.", "metrics": {"bleu_score": 27.88241097922203, "chrf_score": 71.15709975706349, "xcomet_score": 0.765081524848938, "xcomet_qe_score": 0.7963820695877075, "metricx_score": 3.670795440673828, "metricx_qe_score": 3.2541699409484863, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "pt", "output": "E todos nós sabemos que esses modelos gostam de trapacear e pegar atalhos.", "metrics": {"bleu_score": 37.257423107540355, "chrf_score": 69.10029625173813, "xcomet_score": 0.9247369766235352, "xcomet_qe_score": 0.9953135251998901, "metricx_score": 2.136314630508423, "metricx_qe_score": 2.6740260124206543, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "pt", "output": "E, como dissemos, estamos interessados em avaliar quais capacidades os modelos de visão e linguagem têm após o pré-treinamento.", "metrics": {"bleu_score": 60.974546643373756, "chrf_score": 86.67772141952041, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.740092396736145, "metricx_qe_score": 2.1859850883483887, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "pt", "output": "Fazemos experimentos com cinco modelos de visão e linguagem no VALSE, a saber, com CLIP, ALIGN, ViLBERT, ViLBERT 12 em 1 e VisualBERT.", "metrics": {"bleu_score": 21.93664451144313, "chrf_score": 63.395510715161926, "xcomet_score": 0.7777113914489746, "xcomet_qe_score": 0.7559600472450256, "metricx_score": 4.983290195465088, "metricx_qe_score": 5.803777694702148, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "pt", "output": "Duas de nossas métricas de avaliação mais importantes são a precisão dos modelos na classificação de pares de imagens e frases em legendas e não-legendas.", "metrics": {"bleu_score": 26.613685332453084, "chrf_score": 70.74705815071594, "xcomet_score": 0.9481344223022461, "xcomet_qe_score": 0.9812870025634766, "metricx_score": 2.2146873474121094, "metricx_qe_score": 2.004601001739502, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "pt", "output": "Talvez mais relevante para este vídeo, vamos mostrar nossa métrica mais permissiva, a precisão de pares, que mede se a pontuação de alinhamento de imagem e frase é maior para o par correto de imagem e texto do que para seu par enganador.", "metrics": {"bleu_score": 52.18702638854797, "chrf_score": 75.99771104040758, "xcomet_score": 0.754233717918396, "xcomet_qe_score": 0.6527878046035767, "metricx_score": 3.882891893386841, "metricx_qe_score": 3.987128973007202, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "pt", "output": "Para mais métricas e resultados, confira nosso artigo.", "metrics": {"bleu_score": 40.084360380296616, "chrf_score": 69.62411905041328, "xcomet_score": 0.9951534271240234, "xcomet_qe_score": 0.9875531196594238, "metricx_score": 0.20906475186347961, "metricx_qe_score": 0.21637922525405884, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "pt", "output": "Os resultados com precisão pareada são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas. O melhor desempenho zero-shot é alcançado pelo VilBERT 12 em 1, seguido pelo VilBERT, AlexMERT, CLIP e, finalmente, VisualBERT.", "metrics": {"bleu_score": 50.98968829423863, "chrf_score": 78.25598742372793, "xcomet_score": 0.48494163155555725, "xcomet_qe_score": 0.5042436122894287, "metricx_score": 6.721371650695801, "metricx_qe_score": 6.135572910308838, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "pt", "output": "É notável como os instrumentos centrados em objetos individuais, como a existência e as frases nominais, são quase resolvidos pelo Wilbert 12 em 1, destacando que os modelos são capazes de identificar objetos nomeados e sua presença nas imagens.", "metrics": {"bleu_score": 39.49583000624658, "chrf_score": 75.38430115855772, "xcomet_score": 0.6792668104171753, "xcomet_qe_score": 0.6314734220504761, "metricx_score": 4.881058216094971, "metricx_qe_score": 5.349788665771484, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "pt", "output": "No entanto, nenhuma das peças restantes pode ser resolvida de forma confiável em nossos cenários de falha adversarial.", "metrics": {"bleu_score": 58.75766810867467, "chrf_score": 66.85874109317673, "xcomet_score": 0.8745771646499634, "xcomet_qe_score": 0.7639919519424438, "metricx_score": 2.0556130409240723, "metricx_qe_score": 2.6678411960601807, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "pt", "output": "Vemos, a partir dos instrumentos de contagem e de pluralidade, que os modelos de visão e linguagem têm dificuldade em distinguir referências a objetos únicos em comparação com múltiplos ou contá-los em uma imagem.", "metrics": {"bleu_score": 38.15680677485231, "chrf_score": 79.90660070475901, "xcomet_score": 0.8662272691726685, "xcomet_qe_score": 0.8787380456924438, "metricx_score": 2.382389783859253, "metricx_qe_score": 2.5451955795288086, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "pt", "output": "A parte de relação mostra que eles têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos em uma imagem.", "metrics": {"bleu_score": 61.39776196756082, "chrf_score": 89.57163721383927, "xcomet_score": 0.8617146015167236, "xcomet_qe_score": 0.8768754601478577, "metricx_score": 2.8715500831604004, "metricx_qe_score": 4.09419584274292, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "pt", "output": "Eles também têm dificuldade em distinguir ações e identificar seus participantes, mesmo que apoiados por vieses de plausibilidade, como vemos no artigo sobre ações.", "metrics": {"bleu_score": 48.85744139976469, "chrf_score": 79.28429504333519, "xcomet_score": 0.8390673398971558, "xcomet_qe_score": 0.8338114023208618, "metricx_score": 3.6103789806365967, "metricx_qe_score": 3.9104151725769043, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "pt", "output": "A partir do artigo sobre correferência, descobrimos que rastrear múltiplas referências ao mesmo objeto em uma imagem usando pronomes também é difícil para modelos de visão e linguagem.", "metrics": {"bleu_score": 46.35164799875345, "chrf_score": 79.63555154826896, "xcomet_score": 0.7878472208976746, "xcomet_qe_score": 0.8422303199768066, "metricx_score": 2.8739774227142334, "metricx_qe_score": 3.3556556701660156, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "pt", "output": "Como verificação de sanidade e porque é um experimento interessante, também fazemos o benchmark de dois modelos de texto, GPT-1 e GPT-2, para avaliar se o VALSE é solucionável por esses modelos unimodais, calculando a perplexidade da legenda correta e da legenda enganosa (sem imagem aqui) e prevendo a entrada com a menor perplexidade.", "metrics": {"bleu_score": 47.2957995826036, "chrf_score": 75.76569860022715, "xcomet_score": 0.7284811735153198, "xcomet_qe_score": 0.7136846780776978, "metricx_score": 5.8027119636535645, "metricx_qe_score": 6.940792083740234, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "pt", "output": "Se a perplexidade for maior para o foil, consideramos isso como uma indicação de que a legenda com foil pode sofrer de viés de plausibilidade ou outros vieses linguísticos.", "metrics": {"bleu_score": 30.7137308263447, "chrf_score": 65.05335309379655, "xcomet_score": 0.605193555355072, "xcomet_qe_score": 0.6732474565505981, "metricx_score": 9.948217391967773, "metricx_qe_score": 10.018899917602539, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "pt", "output": "É interessante ver que, em alguns casos, os modelos GPT de texto puro captaram melhor a plausibilidade do mundo do que os modelos de visão e linguagem.", "metrics": {"bleu_score": 54.85914097105215, "chrf_score": 76.56275962682977, "xcomet_score": 0.9573478698730469, "xcomet_qe_score": 0.8907414674758911, "metricx_score": 2.1118569374084473, "metricx_qe_score": 2.590092658996582, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, para resumir, o VALSE é um benchmark que usa a lente de construções linguísticas para ajudar a comunidade a melhorar os modelos de visão e linguagem, testando de forma rigorosa suas capacidades de ancoragem visual.", "metrics": {"bleu_score": 49.33345403179337, "chrf_score": 72.48848221367481, "xcomet_score": 0.8376622200012207, "xcomet_qe_score": 0.9581094980239868, "metricx_score": 6.0100789070129395, "metricx_qe_score": 6.328841209411621, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "pt", "output": "Nossos experimentos mostram que os modelos de visão e linguagem identificam bem os objetos nomeados em sua presença nas imagens, como mostrado na parte de existência, mas têm dificuldade para fundamentar sua interdependência e relações em cenas visuais quando forçados a respeitar os indicadores linguísticos.", "metrics": {"bleu_score": 54.03485083346388, "chrf_score": 82.84819452294087, "xcomet_score": 0.740789532661438, "xcomet_qe_score": 0.6959284543991089, "metricx_score": 3.4232490062713623, "metricx_qe_score": 3.7341372966766357, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "pt", "output": "Gostaríamos de incentivar a comunidade a usar o VALSE para medir o progresso em direção ao aprendizado de linguagem com modelos de visão e linguagem.", "metrics": {"bleu_score": 51.955285452323935, "chrf_score": 70.17936284119607, "xcomet_score": 0.927433967590332, "xcomet_qe_score": 0.9692418575286865, "metricx_score": 4.516668796539307, "metricx_qe_score": 5.617251396179199, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, o Vals poderia ser usado como uma avaliação indireta de conjuntos de dados, pois os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para verificar se um conjunto de dados ajuda os modelos a melhorar em algum dos aspectos testados pelo Vals.", "metrics": {"bleu_score": 69.10307927762864, "chrf_score": 86.56240602484797, "xcomet_score": 0.783241868019104, "xcomet_qe_score": 0.7503290772438049, "metricx_score": 4.81695032119751, "metricx_qe_score": 5.202194690704346, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "pt", "output": "Se estiver interessado, confira os dados do Vals no GitHub e, se tiver alguma dúvida, não hesite em entrar em contato conosco.", "metrics": {"bleu_score": 21.62050865049026, "chrf_score": 46.97191451229813, "xcomet_score": 0.863688588142395, "xcomet_qe_score": 0.8872162699699402, "metricx_score": 2.4017343521118164, "metricx_qe_score": 3.643524646759033, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "pt", "output": "Olá, meu nome é Kamizawa, da Universidade de Tóquio.", "metrics": {"bleu_score": 46.59538415189962, "chrf_score": 77.41470211266014, "xcomet_score": 0.9437602162361145, "xcomet_qe_score": 0.9533834457397461, "metricx_score": 0.5642532706260681, "metricx_qe_score": 0.2516182065010071, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "pt", "output": "Vou apresentar um artigo intitulado \"RNNSum: um grande conjunto de dados para a geração automática de resumos de logs de commit\".", "metrics": {"bleu_score": 23.03118027366836, "chrf_score": 54.861188305961164, "xcomet_score": 0.8618537187576294, "xcomet_qe_score": 0.8973280787467957, "metricx_score": 5.735121726989746, "metricx_qe_score": 6.033376693725586, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "pt", "output": "Há experiência nisso.", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 11.838924827802538, "xcomet_score": 0.12250632047653198, "xcomet_qe_score": 0.11146486550569534, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, vou introduzir a geração automática de resumos em que estamos trabalhando nesta pesquisa.", "metrics": {"bleu_score": 27.022488359306863, "chrf_score": 59.63464625578611, "xcomet_score": 0.9018313884735107, "xcomet_qe_score": 0.9726428985595703, "metricx_score": 3.4077556133270264, "metricx_qe_score": 2.8114211559295654, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "pt", "output": "As notas de lançamento são um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.", "metrics": {"bleu_score": 78.84044396805872, "chrf_score": 91.23054176555377, "xcomet_score": 0.9996861219406128, "xcomet_qe_score": 0.9803593158721924, "metricx_score": 0.4191945791244507, "metricx_qe_score": 0.8261535167694092, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "pt", "output": "A imagem mostra as notas de lançamento da versão 2.6.", "metrics": {"bleu_score": 13.714776985037803, "chrf_score": 52.40645361855649, "xcomet_score": 0.5720889568328857, "xcomet_qe_score": 0.33190277218818665, "metricx_score": 6.7921857833862305, "metricx_qe_score": 7.202614784240723, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "pt", "output": "Essa biblioteca JUS. Esses nós desempenham um papel importante no desenvolvimento de código aberto, mas são demorados para serem preparados manualmente.", "metrics": {"bleu_score": 45.663378549673126, "chrf_score": 70.68688779348231, "xcomet_score": 0.3863981068134308, "xcomet_qe_score": 0.06780438870191574, "metricx_score": 18.878597259521484, "metricx_qe_score": 20.06511878967285, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, seria muito útil poder gerar automaticamente notas de lançamento de alta qualidade.", "metrics": {"bleu_score": 45.980029022599005, "chrf_score": 72.83484556808749, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5498978495597839, "metricx_qe_score": 0.6360129714012146, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "pt", "output": "Farei referência a duas pesquisas anteriores sobre geração automática de resumos.", "metrics": {"bleu_score": 34.0089486243384, "chrf_score": 62.75698647120749, "xcomet_score": 0.9156163334846497, "xcomet_qe_score": 0.9938342571258545, "metricx_score": 3.1721835136413574, "metricx_qe_score": 1.5563017129898071, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "pt", "output": "O primeiro é um sistema chamado Arena, lançado em 2014.", "metrics": {"bleu_score": 63.40466277046863, "chrf_score": 84.12356342018738, "xcomet_score": 0.9795624017715454, "xcomet_qe_score": 0.9469609260559082, "metricx_score": 0.3556353449821472, "metricx_qe_score": 2.383610248565674, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "pt", "output": "Ele adota uma abordagem baseada em regras, por exemplo, usando o extrator de mudanças para extrair diferenças de código, mudanças de biblioteca e mudanças de documentação a partir das diferenças entre os lançamentos e, finalmente, combiná-las.", "metrics": {"bleu_score": 48.27192476322906, "chrf_score": 69.81946276907645, "xcomet_score": 0.8105835318565369, "xcomet_qe_score": 0.9296811819076538, "metricx_score": 3.353071451187134, "metricx_qe_score": 1.9056774377822876, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "pt", "output": "A característica mais notável desse sistema é o extrator de problemas no canto superior direito.", "metrics": {"bleu_score": 81.53551038173119, "chrf_score": 95.54926611011737, "xcomet_score": 0.911648154258728, "xcomet_qe_score": 0.836272120475769, "metricx_score": 2.6696536540985107, "metricx_qe_score": 4.727017402648926, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "pt", "output": "que deve ser vinculado ao JIRA, o sistema de rastreamento de problemas, e só pode ser aplicado a projetos que usam o JIRA.", "metrics": {"bleu_score": 55.56398916079419, "chrf_score": 64.78161266232928, "xcomet_score": 0.8766369819641113, "xcomet_qe_score": 0.7815916538238525, "metricx_score": 3.400942325592041, "metricx_qe_score": 3.1612462997436523, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "pt", "output": "Em outras palavras, não pode ser usado para muitos projetos no GitHub.", "metrics": {"bleu_score": 91.93227152249175, "chrf_score": 95.10909462135557, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.49708977341651917, "metricx_qe_score": 0.9543209075927734, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "pt", "output": "O segundo é o luto. Recentemente anunciado em 2013,", "metrics": {"bleu_score": 17.242221289766626, "chrf_score": 57.779334648196034, "xcomet_score": 0.18382346630096436, "xcomet_qe_score": 0.46797582507133484, "metricx_score": 20.125099182128906, "metricx_qe_score": 18.61922264099121, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "pt", "output": "Está disponível na internet e pode ser armazenado em um pip.", "metrics": {"bleu_score": 57.067457770559976, "chrf_score": 64.8083352186398, "xcomet_score": 0.867584228515625, "xcomet_qe_score": 0.8145861625671387, "metricx_score": 6.077980995178223, "metricx_qe_score": 8.39158821105957, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "pt", "output": "Este sistema tem um modelo de classificação de texto baseado em aprendizado simples e produz uma de cinco etiquetas, como \"recursos\" ou \"correções\", para cada mensagem de commit de entrada.", "metrics": {"bleu_score": 25.616091588776825, "chrf_score": 60.988033145848895, "xcomet_score": 0.7424823045730591, "xcomet_qe_score": 0.849669873714447, "metricx_score": 3.1136693954467773, "metricx_qe_score": 2.772395372390747, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "pt", "output": "A imagem é um exemplo de uso que retorna uma lista coletiva de rótulos de correção de bugs.", "metrics": {"bleu_score": 11.268706361337427, "chrf_score": 42.55610054469621, "xcomet_score": 0.8407703638076782, "xcomet_qe_score": 0.9237732887268066, "metricx_score": 7.227175235748291, "metricx_qe_score": 7.055822849273682, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "pt", "output": "Os dados de treinamento do Quora são bastante pequenos, cerca de 5.000, e serão mostrados nos experimentos descritos abaixo.", "metrics": {"bleu_score": 48.7920940032142, "chrf_score": 70.5095017061977, "xcomet_score": 0.6329216957092285, "xcomet_qe_score": 0.6490871906280518, "metricx_score": 11.443498611450195, "metricx_qe_score": 12.517806053161621, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "pt", "output": "O desempenho do modelo de cruzamento de texto não é alto.", "metrics": {"bleu_score": 53.107253497886994, "chrf_score": 64.76408333989556, "xcomet_score": 0.8336236476898193, "xcomet_qe_score": 0.8448160886764526, "metricx_score": 4.554075717926025, "metricx_qe_score": 4.637617588043213, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "pt", "output": "Apresento duas pesquisas relacionadas, mas há problemas de aplicabilidade limitada e escassez de recursos de dados.", "metrics": {"bleu_score": 51.7935102212525, "chrf_score": 83.1542393012787, "xcomet_score": 0.9944279193878174, "xcomet_qe_score": 0.993468165397644, "metricx_score": 0.7717568278312683, "metricx_qe_score": 0.9059368968009949, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "pt", "output": "Nosso artigo resolve esses dois problemas e gera automaticamente notas de lançamento de alta qualidade.", "metrics": {"bleu_score": 48.18716588757115, "chrf_score": 87.3095713122481, "xcomet_score": 0.9896761178970337, "xcomet_qe_score": 0.9744632244110107, "metricx_score": 0.7407063245773315, "metricx_qe_score": 1.250081181526184, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "pt", "output": "Para o problema de aplicabilidade limitada, propomos um método de sumarização de pull request de alta qualidade usando apenas a mensagem de commit como entrada.", "metrics": {"bleu_score": 43.06458327265977, "chrf_score": 70.51287868855196, "xcomet_score": 0.7843894958496094, "xcomet_qe_score": 0.7953522205352783, "metricx_score": 4.315915107727051, "metricx_qe_score": 4.744198799133301, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "pt", "output": "Esse método proposto pode ser usado para todas as dependências em inglês.", "metrics": {"bleu_score": 48.44273237963865, "chrf_score": 68.13227498914361, "xcomet_score": 0.8386338949203491, "xcomet_qe_score": 0.8196032047271729, "metricx_score": 6.86030912399292, "metricx_qe_score": 5.16605281829834, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "pt", "output": "Para o segundo problema de recursos de dados escassos, construímos um conjunto de dados R e SUM consistindo de cerca de 82.000 pontos de dados coletando dados de repositórios públicos do GitHub usando a API do GitHub.", "metrics": {"bleu_score": 52.13698886525063, "chrf_score": 76.38514906287371, "xcomet_score": 0.8011383414268494, "xcomet_qe_score": 0.8109501004219055, "metricx_score": 6.194318771362305, "metricx_qe_score": 5.912985324859619, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "pt", "output": "A seguir, descrevo o conjunto.", "metrics": {"bleu_score": 5.244835934727967, "chrf_score": 37.157977405316494, "xcomet_score": 0.7771734595298767, "xcomet_qe_score": 0.8007628917694092, "metricx_score": 5.038714408874512, "metricx_qe_score": 4.885856628417969, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui está um exemplo de dados.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9989265203475952, "xcomet_qe_score": 0.9954147338867188, "metricx_score": 0.192732572555542, "metricx_qe_score": 0.2367323637008667, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "pt", "output": "O lado esquerdo é a mensagem de commit e o lado direito são as notas de lançamento.", "metrics": {"bleu_score": 68.99302125555486, "chrf_score": 79.73019140921268, "xcomet_score": 0.8371115922927856, "xcomet_qe_score": 0.8505010604858398, "metricx_score": 5.179813385009766, "metricx_qe_score": 4.2346720695495605, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "pt", "output": "As notas de lançamento são rotuladas como \"melhorias\", \"correções\", etc.", "metrics": {"bleu_score": 44.81501736040872, "chrf_score": 82.34156424602848, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6548928022384644, "metricx_qe_score": 1.0401275157928467, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "pt", "output": "Configuramos uma tarefa que recebe as mensagens de commit como entrada e produz os nós de árvore bruta como saída.", "metrics": {"bleu_score": 16.202795457177032, "chrf_score": 50.417951236437354, "xcomet_score": 0.6828886270523071, "xcomet_qe_score": 0.7073271870613098, "metricx_score": 7.125988960266113, "metricx_qe_score": 7.31533145904541, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "pt", "output": "Isso pode ser considerado uma tarefa de resumo.", "metrics": {"bleu_score": 27.75806054476853, "chrf_score": 63.709456022819666, "xcomet_score": 0.9927988052368164, "xcomet_qe_score": 1.0, "metricx_score": 0.667525589466095, "metricx_qe_score": 0.48746341466903687, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "pt", "output": "Temos quatro rótulos predefinidos: recursos, melhorias, correções de bugs, duplicações, removíveis e mudanças de interrupção.", "metrics": {"bleu_score": 41.35171000263378, "chrf_score": 61.35808281686569, "xcomet_score": 0.6099240183830261, "xcomet_qe_score": 0.4966338276863098, "metricx_score": 8.538034439086914, "metricx_qe_score": 7.01588249206543, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "pt", "output": "Esses foram definidos com base em pesquisas anteriores e outros fatos.", "metrics": {"bleu_score": 72.92571723872932, "chrf_score": 90.45546880090544, "xcomet_score": 0.9504756927490234, "xcomet_qe_score": 0.9311774373054504, "metricx_score": 2.9813072681427, "metricx_qe_score": 3.2440037727355957, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "pt", "output": "Os nós da folha no canto inferior direito são extraídos dos nós da folha mostrados no canto inferior esquerdo.", "metrics": {"bleu_score": 30.82627646062185, "chrf_score": 56.10886153066155, "xcomet_score": 0.5628474950790405, "xcomet_qe_score": 0.47566238045692444, "metricx_score": 12.779112815856934, "metricx_qe_score": 10.776304244995117, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "pt", "output": "Neste momento, é necessário detectar as quatro armadilhas que foram preparadas antecipadamente.", "metrics": {"bleu_score": 30.315070099566324, "chrf_score": 54.13657821527712, "xcomet_score": 0.9020681381225586, "xcomet_qe_score": 0.9983292818069458, "metricx_score": 4.347980499267578, "metricx_qe_score": 3.8186020851135254, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "pt", "output": "Mas os rótulos nem sempre são consistentes em cada repositório.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 91.66259699023166, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.1663528680801392, "metricx_qe_score": 1.271602988243103, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "pt", "output": "Por exemplo, a etiqueta de melhoria inclui melhorias, aprimoramentos, otimizações, etc.", "metrics": {"bleu_score": 16.232485867016514, "chrf_score": 60.20972906988481, "xcomet_score": 0.9719129800796509, "xcomet_qe_score": 0.9658571481704712, "metricx_score": 2.487292528152466, "metricx_qe_score": 3.879012107849121, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "pt", "output": "Preparamos uma lista de vocabulário de palavras-chave para cada uma dessas variações de notação.", "metrics": {"bleu_score": 52.03811689332097, "chrf_score": 66.39843363372808, "xcomet_score": 0.9133511781692505, "xcomet_qe_score": 0.8969616293907166, "metricx_score": 6.059662818908691, "metricx_qe_score": 6.425063133239746, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "pt", "output": "Use-o para detectar as classes de notas de lançamento e corrigir o texto do resto que segue como a frase de notas de lançamento para a classe.", "metrics": {"bleu_score": 37.791389119000044, "chrf_score": 67.55589884313935, "xcomet_score": 0.49047738313674927, "xcomet_qe_score": 0.32474902272224426, "metricx_score": 12.768352508544922, "metricx_qe_score": 14.903528213500977, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "pt", "output": "A seguir, vem uma mensagem de compromisso.", "metrics": {"bleu_score": 20.164945583740657, "chrf_score": 46.51202044121586, "xcomet_score": 0.8660445213317871, "xcomet_qe_score": 0.864564836025238, "metricx_score": 4.6312994956970215, "metricx_qe_score": 3.8051111698150635, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "pt", "output": "As mensagens de commit não estão vinculadas a cada release.", "metrics": {"bleu_score": 48.326978309062206, "chrf_score": 63.7447540478478, "xcomet_score": 0.855121374130249, "xcomet_qe_score": 0.9254249334335327, "metricx_score": 6.918877124786377, "metricx_qe_score": 5.262378692626953, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "pt", "output": "Como mostrado na imagem abaixo, se a versão atual é 2.5.19, precisamos identificar", "metrics": {"bleu_score": 27.237263536121674, "chrf_score": 51.74759715593008, "xcomet_score": 0.5715574026107788, "xcomet_qe_score": 0.6410380601882935, "metricx_score": 15.54160213470459, "metricx_qe_score": 14.550137519836426, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "pt", "output": "Qualifique a versão do lançamento anterior (2.5.18) e obtenha sua profundidade. Isso é um pouco tedioso e não é suficiente apenas obter uma lista de lançamentos e olhar antes e depois.", "metrics": {"bleu_score": 26.69749412959399, "chrf_score": 62.06411455766245, "xcomet_score": 0.492518812417984, "xcomet_qe_score": 0.41570767760276794, "metricx_score": 21.657352447509766, "metricx_qe_score": 22.216201782226562, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "pt", "output": "Criamos uma regra heurística de correspondência para obter as versões anterior e seguinte.", "metrics": {"bleu_score": 61.82518852201092, "chrf_score": 89.23451669306031, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.904869019985199, "metricx_qe_score": 1.3428288698196411, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "pt", "output": "Você se conhece?", "metrics": {"bleu_score": 0.0, "chrf_score": 8.976834360221863, "xcomet_score": 0.12107586115598679, "xcomet_qe_score": 0.09654727578163147, "metricx_score": 23.074485778808594, "metricx_qe_score": 14.647451400756836, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "pt", "output": "No final, 7.200 repositórios.", "metrics": {"bleu_score": 3.932742381668659, "chrf_score": 23.10916757431812, "xcomet_score": 0.16214898228645325, "xcomet_qe_score": 0.1437053680419922, "metricx_score": 22.308868408203125, "metricx_qe_score": 23.698257446289062, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, o número médio de tokens de nó de liberação é 63, o que é bastante alto para uma tarefa de resumo.", "metrics": {"bleu_score": 62.17362321691956, "chrf_score": 65.7087935804655, "xcomet_score": 0.5719689726829529, "xcomet_qe_score": 0.6238874197006226, "metricx_score": 6.116513252258301, "metricx_qe_score": 5.311237335205078, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, o número de tokens únicos é bastante grande, em 830.000.", "metrics": {"bleu_score": 60.638269883199015, "chrf_score": 65.2653888507888, "xcomet_score": 0.8238747119903564, "xcomet_qe_score": 0.8913378715515137, "metricx_score": 4.29739236831665, "metricx_qe_score": 4.319769859313965, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "pt", "output": "Devido ao grande número de nomes de classes e métodos exclusivos encontrados na biblioteca.", "metrics": {"bleu_score": 32.547779910216, "chrf_score": 57.76324160931227, "xcomet_score": 0.8742185831069946, "xcomet_qe_score": 0.8912804126739502, "metricx_score": 5.118231773376465, "metricx_qe_score": 4.578784942626953, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "pt", "output": "A seguir, explicarei o método proposto.", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 81.25439236151075, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.20741215348243713, "metricx_qe_score": 1.3086270093917847, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "pt", "output": "O modelo de resumo extrativo e abstrativo de classe consiste em dois módulos neurais.", "metrics": {"bleu_score": 32.078739729528806, "chrf_score": 59.53351061383781, "xcomet_score": 0.8763003945350647, "xcomet_qe_score": 0.8590943217277527, "metricx_score": 2.802046537399292, "metricx_qe_score": 2.629333972930908, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "pt", "output": "Um classificador usando BERT ou CodeBERT e um gerador usando BART.", "metrics": {"bleu_score": 43.64990448369015, "chrf_score": 71.6028187772546, "xcomet_score": 0.9990454912185669, "xcomet_qe_score": 0.99379563331604, "metricx_score": 2.6566216945648193, "metricx_qe_score": 1.9778809547424316, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, o CAS usa um classificador para classificar cada mensagem de commit em cinco classes de notas de liberação: features, implementações, correções de bugs, duplicações e outros.", "metrics": {"bleu_score": 53.08684724877998, "chrf_score": 71.50405012183751, "xcomet_score": 0.48765212297439575, "xcomet_qe_score": 0.55028235912323, "metricx_score": 9.177042961120605, "metricx_qe_score": 8.711739540100098, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "pt", "output": "As mensagens de commit são classificadas como \"outros\" ou descartadas.", "metrics": {"bleu_score": 17.474335703431752, "chrf_score": 69.37210168003571, "xcomet_score": 0.8498822450637817, "xcomet_qe_score": 0.8666515350341797, "metricx_score": 6.7178263664245605, "metricx_qe_score": 5.9591240882873535, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "pt", "output": "Em seguida, o CAS aplica o gerador aos quatro documentos de rótulo e gera um nó de lista para cada classe.", "metrics": {"bleu_score": 42.992838075029, "chrf_score": 58.50631623276609, "xcomet_score": 0.549247145652771, "xcomet_qe_score": 0.49268805980682373, "metricx_score": 11.25206184387207, "metricx_qe_score": 11.988821029663086, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "pt", "output": "Nesta tarefa, as correspondências diretas entre as mensagens de commit e os motivos não são conhecidas.", "metrics": {"bleu_score": 48.91355043014831, "chrf_score": 70.07365381714308, "xcomet_score": 0.7040513753890991, "xcomet_qe_score": 0.7362731695175171, "metricx_score": 10.554633140563965, "metricx_qe_score": 11.365135192871094, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, para treinar o classificador, atribuímos pseudo-rotulos a cada mensagem de commit de entrada usando os primeiros dez caracteres de cada mensagem de commit.", "metrics": {"bleu_score": 39.539657703493944, "chrf_score": 64.99499915799669, "xcomet_score": 0.8013438582420349, "xcomet_qe_score": 0.9646698236465454, "metricx_score": 6.215317726135254, "metricx_qe_score": 5.638885021209717, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "pt", "output": "Modelamos os resumos abstratos por classe de nossa abordagem por dois métodos diferentes.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 61.154338993688626, "xcomet_score": 0.8850830793380737, "xcomet_qe_score": 0.9560644626617432, "metricx_score": 4.487881183624268, "metricx_qe_score": 3.5020148754119873, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "pt", "output": "O primeiro modelo, que chamamos de GHS único, consiste em uma única rede seq2seq e gera um único texto longo de notas de compromisso, dado uma concatenação de mensagens de compromisso de entrada.", "metrics": {"bleu_score": 32.965803420548404, "chrf_score": 63.872120807735996, "xcomet_score": 0.3581353425979614, "xcomet_qe_score": 0.4308680295944214, "metricx_score": 13.200163841247559, "metricx_qe_score": 11.444732666015625, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "pt", "output": "O texto de saída pode ser dividido em segmentos de classe com base em símbolos de ponto final específicos da classe.", "metrics": {"bleu_score": 43.39995636194441, "chrf_score": 67.69384413661955, "xcomet_score": 0.9608591794967651, "xcomet_qe_score": 0.9136161804199219, "metricx_score": 1.4918030500411987, "metricx_qe_score": 2.2388758659362793, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "pt", "output": "O segundo método, que chamamos de CAS-Match, consiste em quatro diferentes redes sec2sec, cada uma correspondendo a uma das classes de nós de saída.", "metrics": {"bleu_score": 33.18857939056734, "chrf_score": 60.29473623224016, "xcomet_score": 0.5979081392288208, "xcomet_qe_score": 0.5868520736694336, "metricx_score": 8.096768379211426, "metricx_qe_score": 8.351690292358398, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "pt", "output": "Ok, vamos explicar o experimento.", "metrics": {"bleu_score": 8.643019616048525, "chrf_score": 35.14642851024908, "xcomet_score": 0.8812401294708252, "xcomet_qe_score": 0.8659365773200989, "metricx_score": 3.4074950218200684, "metricx_qe_score": 1.5451732873916626, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "pt", "output": "Foram comparados cinco métodos: CES, CES-single, CES-multi, Plassering e o estudo anterior, GRIFF.", "metrics": {"bleu_score": 41.2295470431275, "chrf_score": 67.99935470191122, "xcomet_score": 0.5361090898513794, "xcomet_qe_score": 0.47071269154548645, "metricx_score": 11.95176887512207, "metricx_qe_score": 14.49912166595459, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "pt", "output": "Quanto à avaliação, em alguns casos, as notas são emitidas em múltiplas sentenças.", "metrics": {"bleu_score": 50.96772803089438, "chrf_score": 61.330697065628485, "xcomet_score": 0.8766534328460693, "xcomet_qe_score": 0.8513402342796326, "metricx_score": 3.4130303859710693, "metricx_qe_score": 5.0251665115356445, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "pt", "output": "Como é difícil calcular o número de sentenças, os zeros são combinados com espaços e tratados como uma única sentença longa.", "metrics": {"bleu_score": 36.66340989897011, "chrf_score": 66.33142575611204, "xcomet_score": 0.742072343826294, "xcomet_qe_score": 0.8529709577560425, "metricx_score": 13.640268325805664, "metricx_qe_score": 11.491499900817871, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "pt", "output": "O azul é penalizado quando o sistema produz uma frase curta.", "metrics": {"bleu_score": 54.52469119630866, "chrf_score": 72.97339753943464, "xcomet_score": 0.9676533937454224, "xcomet_qe_score": 0.9858287572860718, "metricx_score": 6.094181537628174, "metricx_qe_score": 6.0484795570373535, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "pt", "output": "Essa penalidade resulta em um valor de BRU menor nos resultados do experimento descritos a seguir.", "metrics": {"bleu_score": 32.22538601891173, "chrf_score": 75.85675344386173, "xcomet_score": 0.8581345081329346, "xcomet_qe_score": 0.9596651792526245, "metricx_score": 5.614255905151367, "metricx_qe_score": 6.779698848724365, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "pt", "output": "Finalmente, também calculamos a especificidade, pois o Rouge e o Bleu não podem ser calculados se as notas de lançamento estiverem vazias.", "metrics": {"bleu_score": 64.04279457035709, "chrf_score": 84.67562014762632, "xcomet_score": 0.796343207359314, "xcomet_qe_score": 0.7200204133987427, "metricx_score": 2.762085437774658, "metricx_qe_score": 4.6508965492248535, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "pt", "output": "Uma alta especificidade significa que o modelo corretamente produz textos vazios em casos em que os nós de referência assumem vazio.", "metrics": {"bleu_score": 27.005825328901402, "chrf_score": 62.48279074057448, "xcomet_score": 0.8643510937690735, "xcomet_qe_score": 0.8569619655609131, "metricx_score": 3.8832881450653076, "metricx_qe_score": 5.240353584289551, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui estão os resultados.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9909548759460449, "xcomet_qe_score": 0.9847924709320068, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "pt", "output": "Como o conjunto de dados contém endereços de e-mail, valores de hash, etc., também avaliamos o conjunto de dados limpo, que os exclui.", "metrics": {"bleu_score": 81.77482498436096, "chrf_score": 93.02646815889828, "xcomet_score": 0.9978775978088379, "xcomet_qe_score": 0.9972505569458008, "metricx_score": 2.3698506355285645, "metricx_qe_score": 3.650362014770508, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "pt", "output": "O CAS e o CLS obtiveram pontuações ROUGE mais de 10 pontos acima das linhas de base.", "metrics": {"bleu_score": 25.890790939055332, "chrf_score": 56.83440301265161, "xcomet_score": 0.6776770353317261, "xcomet_qe_score": 0.6602018475532532, "metricx_score": 9.219252586364746, "metricx_qe_score": 9.968070030212402, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "pt", "output": "Em particular, no conjunto de teste limpo, a diferença de pontuação entre o método proposto e o baseline saltou para mais de 20 pontos.", "metrics": {"bleu_score": 61.044484872668754, "chrf_score": 76.452382459151, "xcomet_score": 0.8505516052246094, "xcomet_qe_score": 0.6195251941680908, "metricx_score": 6.086927890777588, "metricx_qe_score": 6.678184509277344, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "pt", "output": "Esses resultados indicam que o CES e o CES são significativamente eficazes.", "metrics": {"bleu_score": 15.727800941615351, "chrf_score": 68.64288787953564, "xcomet_score": 0.40146276354789734, "xcomet_qe_score": 0.42140254378318787, "metricx_score": 17.47100067138672, "metricx_qe_score": 18.970317840576172, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "pt", "output": "O CAS obteve uma pontuação F1 melhor do que o CAS, sugerindo que a combinação de um classificador e um gerador é eficaz e que o treinamento do classificador usando pseudolabels é eficaz.", "metrics": {"bleu_score": 47.96764499683208, "chrf_score": 76.1770590779626, "xcomet_score": 0.37924855947494507, "xcomet_qe_score": 0.3666329085826874, "metricx_score": 14.565228462219238, "metricx_qe_score": 15.88931655883789, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "pt", "output": "A alta cobertura de CAS pode ser alcançada provavelmente porque o classificador pode focar em selecionar mensagens de commit relevantes para cada classe.", "metrics": {"bleu_score": 49.86020415687824, "chrf_score": 74.52727085726643, "xcomet_score": 0.718778669834137, "xcomet_qe_score": 0.8161588907241821, "metricx_score": 7.764209747314453, "metricx_qe_score": 7.510276794433594, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "pt", "output": "O CAS-March tende a ter um valor mais alto do que o CAS-Single.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 42.25502510695739, "xcomet_score": 0.4753715395927429, "xcomet_qe_score": 0.389889121055603, "metricx_score": 18.478904724121094, "metricx_qe_score": 20.050622940063477, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "pt", "output": "sugerindo que também é eficaz desenvolver independentemente diferentes modelos de resumo abstrato para cada classe de nó de leitura.", "metrics": {"bleu_score": 32.91598889023261, "chrf_score": 62.86172582223835, "xcomet_score": 0.6144102811813354, "xcomet_qe_score": 0.6606056094169617, "metricx_score": 6.485264778137207, "metricx_qe_score": 5.814403057098389, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui está uma análise de erro.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9807403087615967, "xcomet_qe_score": 0.9617619514465332, "metricx_score": 0.5178695321083069, "metricx_qe_score": 0.5742115378379822, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "pt", "output": "Os métodos CS tendem a produzir sentenças mais curtas do que as sentenças de referência humanas.", "metrics": {"bleu_score": 32.22538601891173, "chrf_score": 62.555930985218865, "xcomet_score": 0.8798062801361084, "xcomet_qe_score": 0.8937618732452393, "metricx_score": 5.800265789031982, "metricx_qe_score": 4.922662734985352, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "pt", "output": "Na figura à direita, a sentença de referência tem três ou quatro sentenças, enquanto o CUS tem apenas uma.", "metrics": {"bleu_score": 54.53155321934839, "chrf_score": 73.79646977321205, "xcomet_score": 0.7552963495254517, "xcomet_qe_score": 0.803852379322052, "metricx_score": 7.3502583503723145, "metricx_qe_score": 7.2649383544921875, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "pt", "output": "A razão para essa relutância do modelo é que, nos dados de treinamento, apenas 33% das sentenças estão presentes no rótulo de recursos e 40% no rótulo de melhorias.", "metrics": {"bleu_score": 35.564978980971205, "chrf_score": 59.36738517807624, "xcomet_score": 0.7650197744369507, "xcomet_qe_score": 0.782170295715332, "metricx_score": 3.0517373085021973, "metricx_qe_score": 3.073734998703003, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, os métodos CS não conseguem gerar nós de vértice precisos sem informações adicionais.", "metrics": {"bleu_score": 38.53856918030313, "chrf_score": 64.92495154376118, "xcomet_score": 0.6889234781265259, "xcomet_qe_score": 0.6811704635620117, "metricx_score": 8.755165100097656, "metricx_qe_score": 7.594452381134033, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "pt", "output": "O exemplo superior à direita é um exemplo de uma mensagem de commit muito confusa, e a frase completa não pode ser gerada sem referência à solicitação ou problema correspondente.", "metrics": {"bleu_score": 79.62043815447007, "chrf_score": 86.12560088111375, "xcomet_score": 0.8699725866317749, "xcomet_qe_score": 0.9148145914077759, "metricx_score": 5.236471176147461, "metricx_qe_score": 4.1492204666137695, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "pt", "output": "O exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas em uma única frase, mas não o faz.", "metrics": {"bleu_score": 82.66114125804579, "chrf_score": 95.036968557687, "xcomet_score": 0.9734120965003967, "xcomet_qe_score": 0.9096729159355164, "metricx_score": 1.4448405504226685, "metricx_qe_score": 1.5039474964141846, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "pt", "output": "Finalmente, um conclusor.", "metrics": {"bleu_score": 10.400597689005304, "chrf_score": 34.912070323705294, "xcomet_score": 0.7236411571502686, "xcomet_qe_score": 0.7674378156661987, "metricx_score": 7.283745288848877, "metricx_qe_score": 6.8401689529418945, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "pt", "output": "Construímos um novo conjunto de dados para a criação automática de legendas.", "metrics": {"bleu_score": 40.818511424237265, "chrf_score": 64.91190613100328, "xcomet_score": 0.8444924354553223, "xcomet_qe_score": 0.8362073302268982, "metricx_score": 6.325692653656006, "metricx_qe_score": 5.542715549468994, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "pt", "output": "Também nos encarregamos da tarefa de inserir mensagens de compromisso e resumir para que seja aplicável a todos os projetos escritos em inglês.", "metrics": {"bleu_score": 54.89938756679379, "chrf_score": 70.97021764424034, "xcomet_score": 0.7768809199333191, "xcomet_qe_score": 0.7719250917434692, "metricx_score": 4.785765647888184, "metricx_qe_score": 5.014035701751709, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "pt", "output": "Nosso experimento mostra que o método proposto gera menos ruído de folha a uma cobertura maior do que as linhas de base.", "metrics": {"bleu_score": 32.66749259684756, "chrf_score": 53.367517819907974, "xcomet_score": 0.7085753679275513, "xcomet_qe_score": 0.6613451242446899, "metricx_score": 9.484320640563965, "metricx_qe_score": 10.777547836303711, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "pt", "output": "Por favor, verifique o código ou a configuração.", "metrics": {"bleu_score": 4.990049701936832, "chrf_score": 10.423445445238341, "xcomet_score": 0.1355782449245453, "xcomet_qe_score": 0.1312088668346405, "metricx_score": 8.60970687866211, "metricx_qe_score": 8.249256134033203, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "pt", "output": "Obrigado.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14589540660381317, "metricx_qe_score": 0.24346594512462616, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "pt", "output": "Olá, meu nome é Safa Ferrari.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 22.444763054165758, "xcomet_score": 0.4581083655357361, "xcomet_qe_score": 0.5666201114654541, "metricx_score": 7.135134696960449, "metricx_qe_score": 6.074005126953125, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "pt", "output": "E eu representarei nosso artigo, \"Enriquecimento de dados tabulares com poucos exemplos usando arquiteturas de transformadores ajustadas\".", "metrics": {"bleu_score": 13.260140044654037, "chrf_score": 65.1977441346752, "xcomet_score": 0.7224834561347961, "xcomet_qe_score": 0.7274373769760132, "metricx_score": 9.604159355163574, "metricx_qe_score": 8.2327299118042, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "pt", "output": "Um cientista de dados analisa dados e se concentra principalmente na manipulação das características existentes dos dados.", "metrics": {"bleu_score": 52.2173699316905, "chrf_score": 85.80091027850446, "xcomet_score": 0.9997681379318237, "xcomet_qe_score": 1.0, "metricx_score": 1.227818250656128, "metricx_qe_score": 0.9607298970222473, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "pt", "output": "Mas, às vezes, essas funcionalidades são limitadas.", "metrics": {"bleu_score": 22.957488466614326, "chrf_score": 46.37949886511608, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.13017524778842926, "metricx_qe_score": 0.0, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "pt", "output": "A geração de recursos usando outra fonte de dados pode adicionar informações substanciais.", "metrics": {"bleu_score": 42.57110866884422, "chrf_score": 67.70381803954969, "xcomet_score": 0.8882614374160767, "xcomet_qe_score": 0.8995776176452637, "metricx_score": 3.6022250652313232, "metricx_qe_score": 3.5784807205200195, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "pt", "output": "Nosso objetivo de pesquisa é o enriquecimento automático de dados tabulares usando fontes externas de texto livre.", "metrics": {"bleu_score": 35.973870394187934, "chrf_score": 82.71310676491098, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.4614765644073486, "metricx_qe_score": 1.4246076345443726, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "pt", "output": "Suponha que temos um conjunto de dados tabulares e uma base de conhecimento.", "metrics": {"bleu_score": 69.97522298221911, "chrf_score": 88.92637257314419, "xcomet_score": 0.8967338800430298, "xcomet_qe_score": 0.9431560039520264, "metricx_score": 3.915160894393921, "metricx_qe_score": 2.22221302986145, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "pt", "output": "Precisamos de um processo automático que envolva a vinculação de entidades e a análise de texto para extrair novos recursos do texto livre da base de conhecimento.", "metrics": {"bleu_score": 57.83469454651139, "chrf_score": 76.36720818965567, "xcomet_score": 0.9172403216362, "xcomet_qe_score": 0.9302853941917419, "metricx_score": 2.184504985809326, "metricx_qe_score": 2.3116252422332764, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "pt", "output": "Nosso framework FAST é exatamente esse processo automático.", "metrics": {"bleu_score": 52.562405949030286, "chrf_score": 66.61175144317087, "xcomet_score": 0.8298028707504272, "xcomet_qe_score": 0.877557635307312, "metricx_score": 7.28917121887207, "metricx_qe_score": 7.105867862701416, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos dar um exemplo. Em um conjunto de dados alimentado no FAST.", "metrics": {"bleu_score": 32.55964126200301, "chrf_score": 75.27993842627583, "xcomet_score": 0.7646969556808472, "xcomet_qe_score": 0.725716233253479, "metricx_score": 6.613308906555176, "metricx_qe_score": 7.957879066467285, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "pt", "output": "Neste exemplo, o conjunto de dados é o conjunto de dados da universidade.", "metrics": {"bleu_score": 58.282339541526554, "chrf_score": 78.13455351546317, "xcomet_score": 0.996381402015686, "xcomet_qe_score": 0.9883792400360107, "metricx_score": 0.5522135496139526, "metricx_qe_score": 0.9164296388626099, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "pt", "output": "Quando o objetivo é classificar universidades em universidades de baixo e alto escalão.", "metrics": {"bleu_score": 33.48313657991786, "chrf_score": 69.85727155664499, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.678884983062744, "metricx_qe_score": 2.4039385318756104, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "pt", "output": "Como base de conhecimento, usamos a Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4150935411453247, "metricx_qe_score": 0.3402955234050751, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "pt", "output": "A primeira fase do FACE é a vinculação de entidades.", "metrics": {"bleu_score": 25.965358893403383, "chrf_score": 48.24755047308667, "xcomet_score": 0.7201493978500366, "xcomet_qe_score": 0.7326614856719971, "metricx_score": 8.262516975402832, "metricx_qe_score": 10.081526756286621, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "pt", "output": "quando cada entidade, neste exemplo, o nome da universidade, é vinculada a uma entidade dentro da base de conhecimento.", "metrics": {"bleu_score": 78.4851834939063, "chrf_score": 89.63248867689838, "xcomet_score": 0.9764856100082397, "xcomet_qe_score": 0.9691447019577026, "metricx_score": 1.0505707263946533, "metricx_qe_score": 1.57247793674469, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "pt", "output": "O texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.", "metrics": {"bleu_score": 88.17122476287477, "chrf_score": 97.57610935167037, "xcomet_score": 0.9992872476577759, "xcomet_qe_score": 0.995367169380188, "metricx_score": 1.0650415420532227, "metricx_qe_score": 1.7978917360305786, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "pt", "output": "Neste exemplo, o texto é o resumo da página da Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9991861581802368, "xcomet_qe_score": 0.9947096109390259, "metricx_score": 0.4545915424823761, "metricx_qe_score": 0.5933488607406616, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "pt", "output": "Agora, precisamos gerar ou extrair recursos do texto recuperado.", "metrics": {"bleu_score": 39.59377364332708, "chrf_score": 69.77652619299289, "xcomet_score": 0.874126672744751, "xcomet_qe_score": 0.8692214488983154, "metricx_score": 1.7795344591140747, "metricx_qe_score": 1.5012686252593994, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, precisamos de uma fase de extração de recursos que inclua análise de texto.", "metrics": {"bleu_score": 34.46073377034663, "chrf_score": 65.3753288968041, "xcomet_score": 0.8756394386291504, "xcomet_qe_score": 0.8859739899635315, "metricx_score": 3.386631727218628, "metricx_qe_score": 3.2853844165802, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "pt", "output": "Esta é a principal novidade deste artigo e eu vou aprofundar o assunto nas próximas apresentações.", "metrics": {"bleu_score": 30.864558739875022, "chrf_score": 54.11162533760454, "xcomet_score": 0.9874182939529419, "xcomet_qe_score": 0.9723232984542847, "metricx_score": 1.374944806098938, "metricx_qe_score": 0.8617093563079834, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "pt", "output": "Após a fase de extração de recursos, há uma fase de geração de recursos, quando usamos os recursos extraídos para gerar um pequeno número de novos recursos.", "metrics": {"bleu_score": 48.465254338121596, "chrf_score": 56.67308858112003, "xcomet_score": 0.6441197395324707, "xcomet_qe_score": 0.672127366065979, "metricx_score": 3.6877188682556152, "metricx_qe_score": 2.4392762184143066, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "pt", "output": "Primeiro, gere recursos no número de classes do conjunto de dados original.", "metrics": {"bleu_score": 70.8339753228812, "chrf_score": 75.46862360217915, "xcomet_score": 0.8400307893753052, "xcomet_qe_score": 0.7853624820709229, "metricx_score": 4.602723598480225, "metricx_qe_score": 7.586198806762695, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "pt", "output": "Neste exemplo, o conjunto de dados original tem duas classes.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.1638288497924805, "metricx_qe_score": 3.1495063304901123, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "pt", "output": "Então, o FAST gera duas novas características.", "metrics": {"bleu_score": 59.694917920196445, "chrf_score": 84.55434659210506, "xcomet_score": 0.8325656652450562, "xcomet_qe_score": 0.8417074084281921, "metricx_score": 5.960147857666016, "metricx_qe_score": 7.758612155914307, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "pt", "output": "Mas se o conjunto de dados tiver cinco classes, primeiro gere cinco novos recursos.", "metrics": {"bleu_score": 57.30452052531605, "chrf_score": 62.73018362678423, "xcomet_score": 0.776902437210083, "xcomet_qe_score": 0.8163919448852539, "metricx_score": 9.171627044677734, "metricx_qe_score": 10.59173583984375, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "pt", "output": "Cada característica representa a probabilidade de cada classe.", "metrics": {"bleu_score": 59.694917920196445, "chrf_score": 88.61352237016342, "xcomet_score": 0.9723166227340698, "xcomet_qe_score": 0.9629209637641907, "metricx_score": 1.004165530204773, "metricx_qe_score": 1.9671485424041748, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "pt", "output": "Para analisar o texto, utilizamos o estado da arte atual de análise de texto, que são modelos de linguagem baseados em transformadores, como BERT, XLNet, etc.", "metrics": {"bleu_score": 54.82970629055102, "chrf_score": 77.04732180345444, "xcomet_score": 0.9571510553359985, "xcomet_qe_score": 0.9637147188186646, "metricx_score": 1.73521888256073, "metricx_qe_score": 2.0192008018493652, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "pt", "output": "Mas é improvável que possamos treinar um modelo de linguagem usando os conjuntos de dados de entrada.", "metrics": {"bleu_score": 53.948230957280764, "chrf_score": 83.51454628015752, "xcomet_score": 0.9871636629104614, "xcomet_qe_score": 0.9811533689498901, "metricx_score": 2.0615549087524414, "metricx_qe_score": 2.8030378818511963, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, uma abordagem ingênua seria um ajuste fino para a tarefa-alvo.", "metrics": {"bleu_score": 22.131477988685884, "chrf_score": 63.84056769660923, "xcomet_score": 0.7934718132019043, "xcomet_qe_score": 0.710349440574646, "metricx_score": 2.046327590942383, "metricx_qe_score": 4.689529895782471, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "pt", "output": "Na fase de extração de recursos, podemos baixar um modelo de linguagem pré-treinado, ajustar o modelo de linguagem para o conjunto de dados de destino.", "metrics": {"bleu_score": 47.789906643606336, "chrf_score": 68.54666847626504, "xcomet_score": 0.7898189425468445, "xcomet_qe_score": 0.8103750944137573, "metricx_score": 3.1571133136749268, "metricx_qe_score": 2.4028091430664062, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "pt", "output": "Neste exemplo, para ajustar o modelo de linguagem para classificar o texto em classes, abstrair em classes baixa ou alta.", "metrics": {"bleu_score": 40.057751713010575, "chrf_score": 74.6962591424363, "xcomet_score": 0.6234727501869202, "xcomet_qe_score": 0.6694896221160889, "metricx_score": 6.383948802947998, "metricx_qe_score": 5.806229591369629, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "pt", "output": "Receba a saída do modelo de linguagem, que é a probabilidade de cada classe, e use como novos recursos.", "metrics": {"bleu_score": 61.39776196756082, "chrf_score": 72.98735594366677, "xcomet_score": 0.9489408731460571, "xcomet_qe_score": 0.8701999187469482, "metricx_score": 2.3220505714416504, "metricx_qe_score": 3.008253812789917, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "pt", "output": "O problema com essa abordagem é que o conjunto de dados pode ter poucas entidades distintas.", "metrics": {"bleu_score": 32.65636313274063, "chrf_score": 71.5819797801301, "xcomet_score": 0.8836932182312012, "xcomet_qe_score": 0.9130584597587585, "metricx_score": 2.5943965911865234, "metricx_qe_score": 3.3490304946899414, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "pt", "output": "Em nosso experimento, quase metade dos conjuntos de dados continha menos de 400 amostras, e o menor conjunto de dados continha 35 amostras em seu conjunto de treinamento inicial.", "metrics": {"bleu_score": 39.296476509212795, "chrf_score": 66.53018661986282, "xcomet_score": 0.9684591293334961, "xcomet_qe_score": 0.9636844396591187, "metricx_score": 1.0845789909362793, "metricx_qe_score": 1.0302764177322388, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, ajustar um modelo de linguagem a este conjunto de dados será ineficaz.", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 84.09332356009504, "xcomet_score": 0.9953792095184326, "xcomet_qe_score": 0.995608925819397, "metricx_score": 1.0955750942230225, "metricx_qe_score": 1.8370774984359741, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "pt", "output": "Mas podemos usar o conhecimento prévio sobre conjuntos de dados pré-analisados.", "metrics": {"bleu_score": 73.48889200874659, "chrf_score": 95.81998373030916, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7223302721977234, "metricx_qe_score": 0.8299049139022827, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "pt", "output": "Como aplicamos o FAST em múltiplos conjuntos de dados, podemos usar os n-1 conjuntos de dados para obter informações sobre os n-1 conjuntos de dados e usar essas informações quando analisarmos o n-ésimo conjunto de dados.", "metrics": {"bleu_score": 26.20021720625395, "chrf_score": 67.14732805494204, "xcomet_score": 0.7374669313430786, "xcomet_qe_score": 0.7376660108566284, "metricx_score": 4.978643894195557, "metricx_qe_score": 5.143989562988281, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "pt", "output": "O que sugerimos é adicionar outra fase de ajuste fino.", "metrics": {"bleu_score": 77.72460244048297, "chrf_score": 89.31917135706651, "xcomet_score": 0.9141839742660522, "xcomet_qe_score": 0.841532826423645, "metricx_score": 0.7814561128616333, "metricx_qe_score": 0.962009847164154, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "pt", "output": "uma fase preliminar de ajuste fino multitarefa.", "metrics": {"bleu_score": 84.08964152537145, "chrf_score": 97.39746893630078, "xcomet_score": 0.9738520383834839, "xcomet_qe_score": 0.9335678815841675, "metricx_score": 0.8024696707725525, "metricx_qe_score": 2.0833852291107178, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "pt", "output": "Quando você sintoniza o modelo de linguagem em conjuntos de dados N-1,", "metrics": {"bleu_score": 24.79427735122722, "chrf_score": 61.656648725615526, "xcomet_score": 0.7178642749786377, "xcomet_qe_score": 0.7727394700050354, "metricx_score": 6.8725175857543945, "metricx_qe_score": 6.635898590087891, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "pt", "output": "Em seguida, executamos outra fase de ajuste fino, que é o ajuste fino da tarefa-alvo, quando ajustamos o modelo de linguagem no conjunto de dados da tarefa-alvo.", "metrics": {"bleu_score": 28.627506005060948, "chrf_score": 63.3951480249324, "xcomet_score": 0.7206199169158936, "xcomet_qe_score": 0.6922152638435364, "metricx_score": 4.456025123596191, "metricx_qe_score": 5.499614715576172, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "pt", "output": "O estado da arte no ajuste fino multitarefa é chamado de MT-DNN.", "metrics": {"bleu_score": 8.130850857597444, "chrf_score": 49.01849524907354, "xcomet_score": 0.9441509246826172, "xcomet_qe_score": 0.929261326789856, "metricx_score": 4.918393135070801, "metricx_qe_score": 4.045252323150635, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "pt", "output": "No MT-DNN, o MT-DNN mantém cabeças no número de tarefas no conjunto de treinamento.", "metrics": {"bleu_score": 52.664038784792666, "chrf_score": 84.95745353585662, "xcomet_score": 0.5961558222770691, "xcomet_qe_score": 0.6415917277336121, "metricx_score": 11.413488388061523, "metricx_qe_score": 12.170631408691406, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "pt", "output": "Neste exemplo, há quatro tarefas no conjunto de treinamento, então a rede neural mantém quatro cabeças, como você pode ver na imagem.", "metrics": {"bleu_score": 58.05399561362192, "chrf_score": 76.74541513445133, "xcomet_score": 0.8422908782958984, "xcomet_qe_score": 0.9447376132011414, "metricx_score": 1.437936782836914, "metricx_qe_score": 1.5517951250076294, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "pt", "output": "E ele amostra um lote aleatório do conjunto de treinamento.", "metrics": {"bleu_score": 80.70557274927978, "chrf_score": 96.79746381920403, "xcomet_score": 0.9385656118392944, "xcomet_qe_score": 0.9389989376068115, "metricx_score": 2.3718466758728027, "metricx_qe_score": 3.1890206336975098, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "pt", "output": "E se o lote de execução pertence a uma tarefa de classificação de sentença única, ele executa passagens direta e reversa através da primeira cabeça.", "metrics": {"bleu_score": 11.858027506348229, "chrf_score": 45.48360795048112, "xcomet_score": 0.5101450681686401, "xcomet_qe_score": 0.6270663142204285, "metricx_score": 8.517046928405762, "metricx_qe_score": 7.380083084106445, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "pt", "output": "E se o lote aleatório pertence a uma tarefa de classificação por pares, sua atitude é lançada e passa por trás da última cabeça.", "metrics": {"bleu_score": 21.317916490399057, "chrf_score": 48.35057059391975, "xcomet_score": 0.6474931836128235, "xcomet_qe_score": 0.5800449848175049, "metricx_score": 10.963194847106934, "metricx_qe_score": 13.071391105651855, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "pt", "output": "No nosso cenário, o conjunto de dados do Tableau varia o número de classes.", "metrics": {"bleu_score": 33.64932442330151, "chrf_score": 66.58655137127354, "xcomet_score": 0.9250205755233765, "xcomet_qe_score": 0.9164523482322693, "metricx_score": 6.3487868309021, "metricx_qe_score": 6.1588592529296875, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "pt", "output": "Existem muitas tarefas.", "metrics": {"bleu_score": 59.460355750136046, "chrf_score": 79.0345830078829, "xcomet_score": 0.9972704648971558, "xcomet_qe_score": 0.9825527667999268, "metricx_score": 1.1234115362167358, "metricx_qe_score": 0.9988012313842773, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "pt", "output": "A rede neural mantém o número de classes, cabeçalhos, camadas de saída.", "metrics": {"bleu_score": 62.628449627654696, "chrf_score": 77.73475363777567, "xcomet_score": 0.8506405353546143, "xcomet_qe_score": 0.8258776664733887, "metricx_score": 4.659914016723633, "metricx_qe_score": 4.651221752166748, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "pt", "output": "Além disso, o DNA vazio precisa inicializar novas cabeças para um novo conjunto de dados com uma nova tarefa.", "metrics": {"bleu_score": 53.627217165241866, "chrf_score": 67.65448603962444, "xcomet_score": 0.5145108699798584, "xcomet_qe_score": 0.5312049984931946, "metricx_score": 12.55276870727539, "metricx_qe_score": 13.281071662902832, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "pt", "output": "Em nossa abordagem, chamada de ajuste fino de reformulação de tarefa, em vez de manter múltiplas cabeças, reformulamos cada conjunto de dados em um problema de classificação de sentença por sentença, que é uma tarefa de duas classes.", "metrics": {"bleu_score": 44.653864555859094, "chrf_score": 77.20714046720352, "xcomet_score": 0.5859414339065552, "xcomet_qe_score": 0.541454017162323, "metricx_score": 5.902695178985596, "metricx_qe_score": 6.2047905921936035, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos ver um exemplo.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.12355342507362366, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui está o nosso conjunto de dados de entrada, que consiste em entidades, recursos, texto e classes.", "metrics": {"bleu_score": 72.42447986095323, "chrf_score": 80.45415200531002, "xcomet_score": 0.8992892503738403, "xcomet_qe_score": 0.8949066996574402, "metricx_score": 2.670304775238037, "metricx_qe_score": 3.9520440101623535, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "pt", "output": "E reformularemos a tarefa de classificar o texto em baixo e alto para classificar o texto, o resumo e a classe em verdadeiro ou falso.", "metrics": {"bleu_score": 43.217006636770996, "chrf_score": 74.35370777448911, "xcomet_score": 0.8114790916442871, "xcomet_qe_score": 0.7916766405105591, "metricx_score": 3.543337345123291, "metricx_qe_score": 3.9411633014678955, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "pt", "output": "Em outras palavras, treinamos o modelo de linguagem para classificar um resumo e uma classe, se o resumo pertence à classe ou não.", "metrics": {"bleu_score": 69.55593167147791, "chrf_score": 90.45987319328121, "xcomet_score": 0.6766854524612427, "xcomet_qe_score": 0.4612888693809509, "metricx_score": 4.636031150817871, "metricx_qe_score": 6.099449634552002, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "pt", "output": "Portanto, o vetor de rótulos no caso do XGBoost sempre consiste em duas classes.", "metrics": {"bleu_score": 33.15796151992084, "chrf_score": 64.45022173845538, "xcomet_score": 0.8541109561920166, "xcomet_qe_score": 0.8727268576622009, "metricx_score": 5.290839672088623, "metricx_qe_score": 8.734570503234863, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "pt", "output": "Este é o algoritmo para nossa abordagem de ajuste fino reformulada.", "metrics": {"bleu_score": 50.16513759455242, "chrf_score": 85.4203729333374, "xcomet_score": 0.9626537561416626, "xcomet_qe_score": 0.9761641025543213, "metricx_score": 2.8432018756866455, "metricx_qe_score": 3.563960075378418, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "pt", "output": "Vamos ver o quadro completo.", "metrics": {"bleu_score": 6.916271812933183, "chrf_score": 33.43104665539895, "xcomet_score": 0.969420313835144, "xcomet_qe_score": 0.9871234893798828, "metricx_score": 3.393125295639038, "metricx_qe_score": 2.4833450317382812, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "pt", "output": "O conjunto de dados foi inserido no FAST.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 48.65189658077998, "xcomet_score": 0.6491042375564575, "xcomet_qe_score": 0.7599176168441772, "metricx_score": 6.769144058227539, "metricx_qe_score": 6.909165859222412, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "pt", "output": "Então, uma fase de ligação de entidades de execução rápida.", "metrics": {"bleu_score": 7.495553473355845, "chrf_score": 33.31200401535108, "xcomet_score": 0.763283371925354, "xcomet_qe_score": 0.7579317092895508, "metricx_score": 13.280057907104492, "metricx_qe_score": 13.426380157470703, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "pt", "output": "Ele extrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.", "metrics": {"bleu_score": 89.14703664390797, "chrf_score": 98.05720161400383, "xcomet_score": 0.9672228097915649, "xcomet_qe_score": 0.9354344010353088, "metricx_score": 1.4402004480361938, "metricx_qe_score": 2.426567792892456, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "pt", "output": "Em seguida, reformula a tarefa em tarefas de classificação de sentenças.", "metrics": {"bleu_score": 13.485078167116281, "chrf_score": 58.53167744107262, "xcomet_score": 0.847870945930481, "xcomet_qe_score": 0.8629615306854248, "metricx_score": 7.508660316467285, "metricx_qe_score": 7.366657257080078, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "pt", "output": "Aplique o modelo de linguagem à nova tarefa e forneça a probabilidade de cada classe.", "metrics": {"bleu_score": 57.56799653136483, "chrf_score": 73.72360321581144, "xcomet_score": 0.5991097092628479, "xcomet_qe_score": 0.536344051361084, "metricx_score": 3.307283401489258, "metricx_qe_score": 4.1371846199035645, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "pt", "output": "Observe que o modelo de linguagem já foi ajustado para N-1 conjuntos de dados usando um ajuste multitarefa preliminar.", "metrics": {"bleu_score": 39.962332754792115, "chrf_score": 68.4442756276902, "xcomet_score": 0.8448300361633301, "xcomet_qe_score": 0.7958415746688843, "metricx_score": 4.954013824462891, "metricx_qe_score": 4.584923267364502, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "pt", "output": "Em seguida, utilizamos o vetor de saída do modelo de linguagem como uma nova característica gerada no número de classes.", "metrics": {"bleu_score": 58.77038209148268, "chrf_score": 74.7256211780966, "xcomet_score": 0.9480212926864624, "xcomet_qe_score": 0.889532744884491, "metricx_score": 4.532835006713867, "metricx_qe_score": 7.77245569229126, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "pt", "output": "Para avaliar nosso framework, utilizamos um conjunto de dados de classificação tabular de 17, que variam em tamanho, recursos, equilíbrio, domínio e desempenho inicial.", "metrics": {"bleu_score": 44.76006614955163, "chrf_score": 67.56913290152414, "xcomet_score": 0.6013096570968628, "xcomet_qe_score": 0.7014328837394714, "metricx_score": 6.97231912612915, "metricx_qe_score": 6.6502299308776855, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "pt", "output": "E como base de conhecimento, usamos a Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6525752544403076, "metricx_qe_score": 0.56973797082901, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "pt", "output": "Projetamos nosso experimento como uma avaliação de exclusão de um, quando treinamos o FAST em 16 conjuntos de dados e o aplicamos ao 17º conjunto de dados.", "metrics": {"bleu_score": 24.245467021757097, "chrf_score": 53.01031570053113, "xcomet_score": 0.7266073226928711, "xcomet_qe_score": 0.7220853567123413, "metricx_score": 5.427329063415527, "metricx_qe_score": 5.664514541625977, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "pt", "output": "Também dividimos cada conjunto de dados em quatro partes e aplicamos a validação cruzada de quatro partes.", "metrics": {"bleu_score": 72.76817202342096, "chrf_score": 84.68251098061518, "xcomet_score": 0.8991978168487549, "xcomet_qe_score": 0.9543144702911377, "metricx_score": 3.190049886703491, "metricx_qe_score": 3.73626971244812, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "pt", "output": "Em seguida, geramos a nova característica e as avaliamos usando cinco classificadores de avaliação.", "metrics": {"bleu_score": 47.92365811426397, "chrf_score": 81.74967728469362, "xcomet_score": 0.9525994062423706, "xcomet_qe_score": 0.91961669921875, "metricx_score": 3.2248494625091553, "metricx_qe_score": 5.040326118469238, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "pt", "output": "Em nosso experimento, utilizamos uma arquitetura baseada em BERT.", "metrics": {"bleu_score": 7.574347133041985, "chrf_score": 42.509529744716765, "xcomet_score": 0.9824448823928833, "xcomet_qe_score": 0.9928004741668701, "metricx_score": 1.9477667808532715, "metricx_qe_score": 0.8729602694511414, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "pt", "output": "Aqui estão os resultados do nosso experimento.", "metrics": {"bleu_score": 32.260135189272866, "chrf_score": 56.31909204442126, "xcomet_score": 0.9898999929428101, "xcomet_qe_score": 0.9886748790740967, "metricx_score": 0.34101882576942444, "metricx_qe_score": 0.09031536430120468, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "pt", "output": "Podemos ver que comparamos nosso framework com o ajuste fino do conjunto de dados de destino, ajuste fino da tarefa de destino e ajuste fino preliminar do MT-DNN.", "metrics": {"bleu_score": 30.37643089519313, "chrf_score": 66.20712856544807, "xcomet_score": 0.8777217268943787, "xcomet_qe_score": 0.8967524766921997, "metricx_score": 5.077803134918213, "metricx_qe_score": 4.835637092590332, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "pt", "output": "E nosso ajuste fino reformulado alcançou o melhor resultado, o melhor desempenho.", "metrics": {"bleu_score": 66.46817937381975, "chrf_score": 92.25873485855546, "xcomet_score": 0.955430269241333, "xcomet_qe_score": 0.89842289686203, "metricx_score": 0.872135579586029, "metricx_qe_score": 1.1609138250350952, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "pt", "output": "Embora a MT-DNN tenha alcançado uma melhora de 2% em relação ao ajuste fino do conjunto de dados de destino,", "metrics": {"bleu_score": 50.1310627231278, "chrf_score": 66.59918855011189, "xcomet_score": 0.7780141830444336, "xcomet_qe_score": 0.73476243019104, "metricx_score": 3.6022441387176514, "metricx_qe_score": 4.040872097015381, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "pt", "output": "Nossa abordagem alcançou uma melhora de 6%.", "metrics": {"bleu_score": 16.14682615668325, "chrf_score": 64.83839834794155, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.1846578121185303, "metricx_qe_score": 1.2543476819992065, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "pt", "output": "Quando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MT-DNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.", "metrics": {"bleu_score": 91.57103753711765, "chrf_score": 98.07975955403369, "xcomet_score": 0.965391993522644, "xcomet_qe_score": 0.9305071830749512, "metricx_score": 4.173403739929199, "metricx_qe_score": 4.824728012084961, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "pt", "output": "Mas nosso desempenho aumentou 11% em comparação com o ajuste fino da tarefa-alvo.", "metrics": {"bleu_score": 24.92926698409002, "chrf_score": 56.12939666696424, "xcomet_score": 0.8886963129043579, "xcomet_qe_score": 0.8955467939376831, "metricx_score": 3.7412948608398438, "metricx_qe_score": 4.010712146759033, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "pt", "output": "Para a soma, o FaST permite o enriquecimento de poucos tiros a partir de 35 amostras em nosso experimento.", "metrics": {"bleu_score": 41.77393822296787, "chrf_score": 58.62358466846538, "xcomet_score": 0.5544326305389404, "xcomet_qe_score": 0.4581514894962311, "metricx_score": 9.067619323730469, "metricx_qe_score": 9.592159271240234, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "pt", "output": "Ele usa uma arquitetura para todos os conjuntos de tarefas.", "metrics": {"bleu_score": 17.423472443716534, "chrf_score": 69.75477705330721, "xcomet_score": 0.8568862676620483, "xcomet_qe_score": 0.8284398317337036, "metricx_score": 4.507905006408691, "metricx_qe_score": 5.434542655944824, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "pt", "output": "E ele mantém a cabeça do modelo.", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 57.435995164256035, "xcomet_score": 0.8014741539955139, "xcomet_qe_score": 0.828023374080658, "metricx_score": 6.213772773742676, "metricx_qe_score": 7.367697238922119, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "pt", "output": "Mas ele adiciona uma fase de reformulação.", "metrics": {"bleu_score": 54.10822690539397, "chrf_score": 67.85345603263981, "xcomet_score": 0.9910048246383667, "xcomet_qe_score": 0.9807368516921997, "metricx_score": 1.4115983247756958, "metricx_qe_score": 2.2189722061157227, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "pt", "output": "Ele aumentou o conjunto de dados de treinamento e adicionou um valor-alvo com significado semântico, para que pudéssemos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação de sentenças.", "metrics": {"bleu_score": 42.37986574150216, "chrf_score": 72.84795188444228, "xcomet_score": 0.7362223863601685, "xcomet_qe_score": 0.6475566625595093, "metricx_score": 2.963479518890381, "metricx_qe_score": 3.695382595062256, "linguapy_score": [0, "PORTUGUESE"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "pt", "output": "Obrigado.", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14589540660381317, "metricx_qe_score": 0.24346594512462616, "linguapy_score": [0, "PORTUGUESE"]}}
