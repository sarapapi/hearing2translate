{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo everyone,\nHeute werde ich unsere Forschungsarbeit vorstellen: \"Lernen, kreativ zu denken - Problemlösung mit Netzwerken als komplexes Verständnis von Regionen\".", "metrics": {"bleu_score": 15.04843536148922, "chrf_score": 45.16236074619909, "xcomet_score": 0.6189794540405273, "xcomet_qe_score": 0.6446163654327393, "metricx_score": 8.113633155822754, "metricx_qe_score": 8.774775505065918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Melinda aus dem AirLab von Biden und dies ist eine gemeinsame Arbeit mit Cheyenne vom University of Texas in Austin und Wayne von S U DD.", "metrics": {"bleu_score": 38.49194813833404, "chrf_score": 60.98268673670139, "xcomet_score": 0.2580755949020386, "xcomet_qe_score": 0.26521173119544983, "metricx_score": 21.147851943969727, "metricx_qe_score": 19.147119522094727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Reasoning sprechen.", "metrics": {"bleu_score": 74.19446627365011, "chrf_score": 77.37811447822722, "xcomet_score": 0.9394338130950928, "xcomet_qe_score": 0.9400126934051514, "metricx_score": 3.225599527359009, "metricx_qe_score": 2.504528760910034, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind einige Beispiele, in denen die multiplen Schritte der Rechnung hilfreich sind.", "metrics": {"bleu_score": 3.4585921141027356, "chrf_score": 29.669030330430964, "xcomet_score": 0.8682237863540649, "xcomet_qe_score": 0.9659514427185059, "metricx_score": 5.494543552398682, "metricx_qe_score": 4.7507123947143555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Wert stammt aus der Papiere, auf der die Probanden angewiesen wurden, das mathematische Problem in einem Future-Learning-Szenario zu lösen.", "metrics": {"bleu_score": 9.849349468888725, "chrf_score": 42.719328644542735, "xcomet_score": 0.5147793292999268, "xcomet_qe_score": 0.6860806941986084, "metricx_score": 7.250165939331055, "metricx_qe_score": 5.970616340637207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Also kann man auf der rechten Seite des Netpens sehen, wenn wir einige Beispiele mit nur Korrektur und Antworten geben, werden wir möglicherweise nicht in der Lage sein, die richtigen Antworten zu erhalten.", "metrics": {"bleu_score": 7.299453257591888, "chrf_score": 51.87891266862661, "xcomet_score": 0.7624759078025818, "xcomet_qe_score": 0.7594360709190369, "metricx_score": 8.032919883728027, "metricx_qe_score": 7.80136775970459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir einige genauere Beschreibung geben, kann das Modell die vorhergesagte Beschreibung vorhersagen und auch hier die korrekte Vorhersage treffen.", "metrics": {"bleu_score": 6.214678332525692, "chrf_score": 47.36341714357369, "xcomet_score": 0.8428019285202026, "xcomet_qe_score": 0.858654260635376, "metricx_score": 3.23527455329895, "metricx_qe_score": 2.6408281326293945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist gut, wenn man interpretierbare multi-stufige Verarbeitung als Ausgabe hat.", "metrics": {"bleu_score": 9.30514025247622, "chrf_score": 41.8029085088248, "xcomet_score": 0.9579746723175049, "xcomet_qe_score": 0.9805903434753418, "metricx_score": 3.637479305267334, "metricx_qe_score": 1.8263514041900635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Und wir denken auch, dass das Mathematikproblem eine strengere Anwendung zur Bewertung solcher Ratschläge ist. Fähigkeiten.", "metrics": {"bleu_score": 14.576846149722611, "chrf_score": 49.64065250706598, "xcomet_score": 0.6514460444450378, "xcomet_qe_score": 0.6878871917724609, "metricx_score": 14.131877899169922, "metricx_qe_score": 12.710209846496582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Also hier in unserem Problemsetup geben wir uns an, gegebenenfalls diese Frage zu lösen und die numerischen Antworten zu erhalten.", "metrics": {"bleu_score": 21.79301929852717, "chrf_score": 62.27842178951606, "xcomet_score": 0.7668105959892273, "xcomet_qe_score": 0.7215591669082642, "metricx_score": 5.609457015991211, "metricx_qe_score": 5.6648125648498535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datenbanken erhalten wir auch die mathematische Formel, was zu diesem bestimmten Antwort führt.", "metrics": {"bleu_score": 19.286624099885103, "chrf_score": 62.00071081058215, "xcomet_score": 0.9272860884666443, "xcomet_qe_score": 0.9324902296066284, "metricx_score": 4.806276321411133, "metricx_qe_score": 5.324358940124512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Also gelten bestimmte Annahmen als in früheren Arbeiten.", "metrics": {"bleu_score": 26.432408210372945, "chrf_score": 67.86665621610257, "xcomet_score": 0.9761193990707397, "xcomet_qe_score": 0.9741326570510864, "metricx_score": 5.002615451812744, "metricx_qe_score": 2.0697855949401855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Präzision der Quantitäten unbekannt ist.", "metrics": {"bleu_score": 53.44445934790542, "chrf_score": 62.593571164916675, "xcomet_score": 0.8559149503707886, "xcomet_qe_score": 0.8788880109786987, "metricx_score": 5.462665557861328, "metricx_qe_score": 4.9902849197387695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir berücksichtigen nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentialiation.", "metrics": {"bleu_score": 72.97627709554281, "chrf_score": 85.32802036757174, "xcomet_score": 0.9774107933044434, "xcomet_qe_score": 0.9798866510391235, "metricx_score": 1.5031287670135498, "metricx_qe_score": 1.1806942224502563, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können kommutative Operatoren tatsächlich aus diesen grundlegenden Operatoren decomponiert werden.", "metrics": {"bleu_score": 15.133218633429316, "chrf_score": 61.05285725756487, "xcomet_score": 0.9709789156913757, "xcomet_qe_score": 0.9822238087654114, "metricx_score": 4.495632171630859, "metricx_qe_score": 3.438800811767578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Die vorherige Arbeit in der Mathematik-Problem lösen kann tatsächlich in zwei Arten von Modellen unterteilt werden: sequentiell und sequentiell zu Baum-Modell.", "metrics": {"bleu_score": 2.4623373672221804, "chrf_score": 35.544246123451806, "xcomet_score": 0.86224365234375, "xcomet_qe_score": 0.8403433561325073, "metricx_score": 6.504210472106934, "metricx_qe_score": 6.318171501159668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle sequenz-zu-sequenz-Modelle konvertieren die Ausdrücke in eine spezifische Sequenz für die Erzeugung.", "metrics": {"bleu_score": 31.40228119437427, "chrf_score": 60.52614112049478, "xcomet_score": 0.91534423828125, "xcomet_qe_score": 0.9036697149276733, "metricx_score": 2.006812572479248, "metricx_qe_score": 1.4878661632537842, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist recht einfach zu implementieren und kann auf viele verschiedene komplizierte Probleme generalisiert werden.", "metrics": {"bleu_score": 44.77118844014732, "chrf_score": 75.03606290541954, "xcomet_score": 0.9965624809265137, "xcomet_qe_score": 0.9811549782752991, "metricx_score": 0.16485127806663513, "metricx_qe_score": 0.294178307056427, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachteile der Leistung sind tatsächlich im Allgemeinen nicht besser als das Strukturmodell und es fehlt an Interpretierbarkeit für Vorhersagen.", "metrics": {"bleu_score": 21.119032358562848, "chrf_score": 60.60136394078776, "xcomet_score": 0.9321072101593018, "xcomet_qe_score": 0.9380961060523987, "metricx_score": 5.940587997436523, "metricx_qe_score": 6.421443462371826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "\"但实际上，这个方向仍然很受欢迎，因为Transformer模型。\"", "metrics": {"bleu_score": 0.0, "chrf_score": 12.687404088674894, "xcomet_score": 0.7502197027206421, "xcomet_qe_score": 0.6948116421699524, "metricx_score": 4.426749229431152, "metricx_qe_score": 5.236963748931885, "linguapy_score": [1, "CHINESE"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In tree-basierten Modellen strukturieren wir diese Ausdrücke tatsächlich in einem Baumform und folgen einer vorbestimmten Reihenfolge in der Tree-Generierung.", "metrics": {"bleu_score": 27.065739132597326, "chrf_score": 63.50151688956357, "xcomet_score": 0.8565568327903748, "xcomet_qe_score": 0.9087666273117065, "metricx_score": 7.581364154815674, "metricx_qe_score": 6.37506628036499, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Also generieren wir hier weiterhin die Operatoren, bis wir die leafs erreichen, die die Quoten sind.", "metrics": {"bleu_score": 25.39868777670523, "chrf_score": 54.021699519082375, "xcomet_score": 0.8440563678741455, "xcomet_qe_score": 0.7867602705955505, "metricx_score": 7.257447242736816, "metricx_qe_score": 7.3775835037231445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Also hier das Beste ist, dass es uns tatsächlich diese binäre Baumstruktur gibt und es ist um, aber tatsächlich ist es quite counterintuitive, weil wir erst den Operator generieren und dann am Ende die Quantitäten.", "metrics": {"bleu_score": 18.8796429159276, "chrf_score": 53.85832241777189, "xcomet_score": 0.7410397529602051, "xcomet_qe_score": 0.7110360264778137, "metricx_score": 8.95583724975586, "metricx_qe_score": 8.827601432800293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Und das zweite ist, dass es auch einige repetitive Rechnungen enthält.", "metrics": {"bleu_score": 7.347053125977879, "chrf_score": 41.18645240315791, "xcomet_score": 0.9177292585372925, "xcomet_qe_score": 0.949743926525116, "metricx_score": 4.1868767738342285, "metricx_qe_score": 1.5800790786743164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Also hier, wenn wir diesen Ausdruck betrachten, wird 'a mal drei plus drei' tatsächlich zweimal generiert, aber in Wirklichkeit sollten wir die Ergebnisse wieder verwenden.", "metrics": {"bleu_score": 19.91148803162056, "chrf_score": 66.59024254227155, "xcomet_score": 0.9065001010894775, "xcomet_qe_score": 0.9074942469596863, "metricx_score": 3.306727409362793, "metricx_qe_score": 3.0108728408813477, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Vorschlag ist es unser Ziel, diese Probleme in Schritten zu lösen und auf verständliche Weise.", "metrics": {"bleu_score": 7.761035889722027, "chrf_score": 40.57148012562457, "xcomet_score": 0.9878703355789185, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.1564244031906128, "metricx_qe_score": 0.9253911972045898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Also kann man hier im zweiten Schritt zum Beispiel diese Divisoren erhalten, die ist twenty seven.", "metrics": {"bleu_score": 24.62395302527262, "chrf_score": 55.94676569298645, "xcomet_score": 0.8989248275756836, "xcomet_qe_score": 0.9097024202346802, "metricx_score": 6.419221878051758, "metricx_qe_score": 5.217600345611572, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückverweisen, um relevante Inhalte zu finden.", "metrics": {"bleu_score": 57.11023016171072, "chrf_score": 81.207020913416, "xcomet_score": 0.9841257333755493, "xcomet_qe_score": 0.9780357480049133, "metricx_score": 0.5902469158172607, "metricx_qe_score": 0.46894532442092896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "In diesen Schritten erhalten wir die Divisoren.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 80.62737893689558, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9920222759246826, "metricx_qe_score": 0.7619975209236145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Also und dann ist der dritte Schritt, in dem wir tatsächlich die Quotienten erhalten.", "metrics": {"bleu_score": 3.9779457777453793, "chrf_score": 50.38321215741357, "xcomet_score": 0.9518783092498779, "xcomet_qe_score": 0.9494993090629578, "metricx_score": 1.6994606256484985, "metricx_qe_score": 2.1667792797088623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse aus dem zweiten Schritt verwenden und dann das Ergebnis des vierten Schritts erhalten und schließlich die Dividende erhalten.", "metrics": {"bleu_score": 36.72404084841361, "chrf_score": 76.05471214307418, "xcomet_score": 0.9762285947799683, "xcomet_qe_score": 0.9688959717750549, "metricx_score": 1.5445404052734375, "metricx_qe_score": 2.4773571491241455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Also generieren wir tatsächlich die ganze Ausdrucks direkt, anstatt einzelne Operatoren oder Quantitäten zu generieren.", "metrics": {"bleu_score": 2.8378637222629375, "chrf_score": 42.091804806979454, "xcomet_score": 0.9476093053817749, "xcomet_qe_score": 0.9593348503112793, "metricx_score": 3.3258755207061768, "metricx_qe_score": 3.701711893081665, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dies macht den Prozess genauer.", "metrics": {"bleu_score": 30.213753973567677, "chrf_score": 52.95516583539063, "xcomet_score": 0.9947330951690674, "xcomet_qe_score": 0.9794038534164429, "metricx_score": 0.3046821653842926, "metricx_qe_score": 0.8406790494918823, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir zunächst mit einer Reihe von Quantitäten, die in den Fragen präsentiert werden, und auch einige Konstanten als unsere Initialwerte einbeziehen.", "metrics": {"bleu_score": 44.39174418630949, "chrf_score": 61.96136897044037, "xcomet_score": 0.9752672910690308, "xcomet_qe_score": 0.9583393335342407, "metricx_score": 2.1617939472198486, "metricx_qe_score": 2.9361724853515625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Also wird die Ausdrücke durch E i, j, o p dargestellt.", "metrics": {"bleu_score": 21.142141714303076, "chrf_score": 51.071894954271954, "xcomet_score": 0.9335755109786987, "xcomet_qe_score": 0.9266501665115356, "metricx_score": 3.0261898040771484, "metricx_qe_score": 3.753209352493286, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "的操作是从QI到QJ，而且这种表达式实际上是直接的。", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.5483992099761963, "xcomet_qe_score": 0.638850212097168, "metricx_score": 5.943052768707275, "metricx_qe_score": 5.302577972412109, "linguapy_score": [1, "CHINESE"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Also haben wir hier Subtraktion umgekehrt, um die entgegengesetzte Richtung zu repräsentieren.", "metrics": {"bleu_score": 11.710329038356216, "chrf_score": 44.52752252042445, "xcomet_score": 0.9444844126701355, "xcomet_qe_score": 0.9000041484832764, "metricx_score": 2.9174084663391113, "metricx_qe_score": 2.7635037899017334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist quite ähnlich zu einer Relativierung.", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 31.73120731643268, "xcomet_score": 0.8282473087310791, "xcomet_qe_score": 0.7626380920410156, "metricx_score": 7.8149824142456055, "metricx_qe_score": 5.418242931365967, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formalen deduktiven System gilt: At der Zeitstufe t wir wenden den Operator zwischen qi und qj an und erhalten dann diese neue Ausdrücke.", "metrics": {"bleu_score": 23.628926386260385, "chrf_score": 64.36010845506685, "xcomet_score": 0.9237298965454102, "xcomet_qe_score": 0.9368433952331543, "metricx_score": 7.547463417053223, "metricx_qe_score": 7.430630683898926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben es zu den nächsten Daten hinzugefügt, um eine neue Menge zu werden.", "metrics": {"bleu_score": 33.34477432809603, "chrf_score": 51.283141148767754, "xcomet_score": 0.9240615367889404, "xcomet_qe_score": 0.8833096623420715, "metricx_score": 4.972325325012207, "metricx_qe_score": 3.47489857673645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Vorschlag visualisiert tatsächlich die Entwicklung der Zustände, bei denen wir die Ausdrücke zu aktuellen Zuständen hinzufügen.", "metrics": {"bleu_score": 6.809398432036521, "chrf_score": 50.35527115980616, "xcomet_score": 0.8821077346801758, "xcomet_qe_score": 0.8643346428871155, "metricx_score": 4.153604507446289, "metricx_qe_score": 3.9636640548706055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst einen prätrainierten Sprachmodellkern, der Brötchensprachen oder Roboterhaut sein kann, und dann codieren wir die Sätze ein und erhalten diese Quantitätsrepräsentationen.", "metrics": {"bleu_score": 23.29812158705793, "chrf_score": 60.28216935484547, "xcomet_score": 0.755440354347229, "xcomet_qe_score": 0.7404459714889526, "metricx_score": 7.876727104187012, "metricx_qe_score": 8.54129695892334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Also, sobald wir die Quantifizierungen erhalten, können wir anfangen, zu inferieren.", "metrics": {"bleu_score": 11.633270842295033, "chrf_score": 40.468035192381365, "xcomet_score": 0.9817513227462769, "xcomet_qe_score": 0.9979302883148193, "metricx_score": 2.2930960655212402, "metricx_qe_score": 2.194913625717163, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für die Verwendung von Q1, um die Rekursion für Q1 dividiert durch Q2 und dann mal Q4 zu erhalten.", "metrics": {"bleu_score": 26.686028599747853, "chrf_score": 57.08039339778948, "xcomet_score": 0.8327631950378418, "xcomet_qe_score": 0.8534921407699585, "metricx_score": 9.136421203613281, "metricx_qe_score": 7.4043426513671875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst erhalten wir die Paare Darstellung, was im Grunde genommen nur die Kombination zwischen q1 und q2 ist, und dann wird eine vordergründige Netzwerk angewendet, die durch den Operator parametrisiert ist.", "metrics": {"bleu_score": 30.051033893614576, "chrf_score": 67.0895948872011, "xcomet_score": 0.7592563033103943, "xcomet_qe_score": 0.7222848534584045, "metricx_score": 8.975533485412598, "metricx_qe_score": 8.759977340698242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und dann schließlich erhalten wir die Ausdrucksform Q1 geteilt durch Q.", "metrics": {"bleu_score": 9.302496318704556, "chrf_score": 62.60032351977938, "xcomet_score": 0.8746652603149414, "xcomet_qe_score": 0.8931140899658203, "metricx_score": 4.878061294555664, "metricx_qe_score": 4.364582538604736, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis könnte man in der inkrementalen Phase tatsächlich auch falsche Ausdrücke oder inkorrekte Ausdrücke erhalten.", "metrics": {"bleu_score": 7.732130225986882, "chrf_score": 48.86939024980922, "xcomet_score": 0.9825664758682251, "xcomet_qe_score": 0.9756829738616943, "metricx_score": 1.4090869426727295, "metricx_qe_score": 1.7583032846450806, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Also gilt: Die Anzahl der Operatoren ist gleich drei mal der Anzahl der Operatoren.", "metrics": {"bleu_score": 23.961829057131983, "chrf_score": 43.88650917743039, "xcomet_score": 0.8369798064231873, "xcomet_qe_score": 0.7810062170028687, "metricx_score": 9.535030364990234, "metricx_qe_score": 8.931804656982422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Die nice Sache hier ist, dass wir leicht Konditionen hinzufügen können, um diese Suche zu steuern. Diese Suche.", "metrics": {"bleu_score": 28.479942163807365, "chrf_score": 49.94760267856323, "xcomet_score": 0.7608988881111145, "xcomet_qe_score": 0.8229568004608154, "metricx_score": 5.603648662567139, "metricx_qe_score": 5.07298469543457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Für Beispiel, wenn diese Ausdrucks nicht erlaubt ist, können wir einfach diesen Ausdruck in unserem Suchraum entfernen.", "metrics": {"bleu_score": 38.27673535697133, "chrf_score": 73.03102082666929, "xcomet_score": 0.9250575304031372, "xcomet_qe_score": 0.9171227216720581, "metricx_score": 4.618844032287598, "metricx_qe_score": 4.845695495605469, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "In der zweiten Schritt tun wir das gleiche, aber der einzige Unterschied ist, dass wir eine weitere Menge von Dingen tun.", "metrics": {"bleu_score": 40.28998029112095, "chrf_score": 68.881067615414, "xcomet_score": 0.793104350566864, "xcomet_qe_score": 0.7916170358657837, "metricx_score": 7.159346103668213, "metricx_qe_score": 6.3332929611206055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Menge stammt aus der vorherigen Berechnung dieser Ausdrücke.", "metrics": {"bleu_score": 18.575057999133595, "chrf_score": 58.509745315088146, "xcomet_score": 0.9897950887680054, "xcomet_qe_score": 0.9894850254058838, "metricx_score": 1.5595121383666992, "metricx_qe_score": 2.4998819828033447, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Also können wir endlich diese finale Ausdrücke aufteilen.", "metrics": {"bleu_score": 4.848169255678505, "chrf_score": 36.157698701462806, "xcomet_score": 0.8145264387130737, "xcomet_qe_score": 0.7934161424636841, "metricx_score": 6.174349308013916, "metricx_qe_score": 8.301000595092773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Die Anzahl der möglichen Ausdrücke ist von dem vorherigen Schritt unterschiedlich.", "metrics": {"bleu_score": 6.682025998431122, "chrf_score": 52.684953040379824, "xcomet_score": 0.9621809720993042, "xcomet_qe_score": 0.9420976638793945, "metricx_score": 3.2352614402770996, "metricx_qe_score": 4.24119234085083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "So machen solche Unterschiede es schwierig, den Baum zu durchsuchen, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten ungleich ist.", "metrics": {"bleu_score": 34.19372521950972, "chrf_score": 64.05607971292098, "xcomet_score": 0.8132264018058777, "xcomet_qe_score": 0.8365186452865601, "metricx_score": 4.314689636230469, "metricx_qe_score": 3.8872365951538086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsverfahren ist ähnlich wie das Training eines sequenz zu sequenz-Modells, bei dem wir die Fehler minimieren, jedes Mal beim Durchlaufen der Schritte.", "metrics": {"bleu_score": 12.920725243713852, "chrf_score": 60.337986663270726, "xcomet_score": 0.8483331203460693, "xcomet_qe_score": 0.8089483976364136, "metricx_score": 4.856895446777344, "metricx_qe_score": 3.838947296142578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch diese Tafel, um zu representieren, wann wir den generativen Prozess beenden sollten.", "metrics": {"bleu_score": 17.7528972829604, "chrf_score": 57.98450421148592, "xcomet_score": 0.826332688331604, "xcomet_qe_score": 0.8665242195129395, "metricx_score": 4.883640289306641, "metricx_qe_score": 5.502020359039307, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall ist der Raum anders als in einer sequentiellen Sequenz, da der Raum bei jedem Mal unterschiedlich ist, während in einem traditionellen sequentiellen Modell die Anzahl der Wörter festgelegt ist.", "metrics": {"bleu_score": 13.82453242569562, "chrf_score": 51.62933102374622, "xcomet_score": 0.9658360481262207, "xcomet_qe_score": 0.9371339082717896, "metricx_score": 3.368809700012207, "metricx_qe_score": 4.516176700592041, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht es auch, bestimmte Kontraindikationen von vornherein zu verhindern.", "metrics": {"bleu_score": 12.35622127262679, "chrf_score": 29.480735993842867, "xcomet_score": 0.9380370378494263, "xcomet_qe_score": 0.947201132774353, "metricx_score": 2.212963819503784, "metricx_qe_score": 2.7691633701324463, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente auf den häufig verwendeten Datenbanken für mathematische Probleme durch, wie z.B. MySQL, PostgreSQL, MongoDB und SQLite.", "metrics": {"bleu_score": 8.234891424657139, "chrf_score": 53.158907889647, "xcomet_score": 0.7007321119308472, "xcomet_qe_score": 0.8565127849578857, "metricx_score": 6.341521739959717, "metricx_qe_score": 4.88773775100708, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier sind wir mit dem Ergebnis, verglichen mit den vorherigen besten Ansätzen.", "metrics": {"bleu_score": 11.114924776032012, "chrf_score": 47.18611570099504, "xcomet_score": 0.949353039264679, "xcomet_qe_score": 0.910743236541748, "metricx_score": 2.522575616836548, "metricx_qe_score": 2.768378973007202, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unser best-performing Webserver ist Robeta.", "metrics": {"bleu_score": 8.170609724417774, "chrf_score": 16.870214668458956, "xcomet_score": 0.44233450293540955, "xcomet_qe_score": 0.6496012210845947, "metricx_score": 8.012651443481445, "metricx_qe_score": 7.890522480010986, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir Beamsuche nicht. Im Gegensatz dazu werden bei anderen Ansätzen Beamsuche verwendet.", "metrics": {"bleu_score": 5.045777123948043, "chrf_score": 51.80071013438118, "xcomet_score": 0.882246732711792, "xcomet_qe_score": 0.9308445453643799, "metricx_score": 2.1092355251312256, "metricx_qe_score": 1.8054583072662354, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Also sind die besten Ansätze in der Regel ein Baummodell.", "metrics": {"bleu_score": 24.808415001701817, "chrf_score": 45.70044337488547, "xcomet_score": 0.9846798181533813, "xcomet_qe_score": 0.9953752756118774, "metricx_score": 0.4993579685688019, "metricx_qe_score": 0.31732475757598877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Der Sprecher sagt: 'Insgesamt kann unser Rechner die Verarbeitung dieser tree-based-Modell erheblich beschleunigen.'", "metrics": {"bleu_score": 2.908317710573757, "chrf_score": 33.38317368288609, "xcomet_score": 0.2998267114162445, "xcomet_qe_score": 0.2029966413974762, "metricx_score": 4.582818984985352, "metricx_qe_score": 3.831432342529297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absolute Anzahl auf MathQa oder SWAM nicht wirklich hoch ist.", "metrics": {"bleu_score": 42.08598069524091, "chrf_score": 68.22291367191085, "xcomet_score": 0.9407958984375, "xcomet_qe_score": 0.9306426048278809, "metricx_score": 1.1485508680343628, "metricx_qe_score": 1.1776922941207886, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Also sollten wir die Ergebnisse weiter untersuchen.", "metrics": {"bleu_score": 21.573652645054953, "chrf_score": 60.52366153311386, "xcomet_score": 0.9896726608276367, "xcomet_qe_score": 0.9842419624328613, "metricx_score": 1.4524401426315308, "metricx_qe_score": 2.1410775184631348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Swamp und dieses Datenset ist herausfordernd, weil der Autor versucht hat, something manually zu addieren, um das NLP-Modell zu verwirren, indem er beispielsweise unangemessene Informationen hinzufügt und zusätzliche Quoten.", "metrics": {"bleu_score": 34.27570806305577, "chrf_score": 57.972616889308945, "xcomet_score": 0.6438966989517212, "xcomet_qe_score": 0.6810480952262878, "metricx_score": 16.293392181396484, "metricx_qe_score": 16.448970794677734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Vorhersage finden wir, dass einige der intermediären Werte tatsächlich negativ sind.", "metrics": {"bleu_score": 29.13055375496153, "chrf_score": 58.620949542033316, "xcomet_score": 0.9846630096435547, "xcomet_qe_score": 0.9923163652420044, "metricx_score": 1.0466539859771729, "metricx_qe_score": 0.9279828667640686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel werden in diesen Fragen gefragt, wie viele Äpfel hat Drake?", "metrics": {"bleu_score": 27.392758081541032, "chrf_score": 61.656477816654274, "xcomet_score": 0.8237000703811646, "xcomet_qe_score": 0.8044333457946777, "metricx_score": 4.718241214752197, "metricx_qe_score": 4.244235992431641, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie zum Beispiel siebzehn fewer pictures und Stephen hat acht Bilder, was völlig irrelevant ist.", "metrics": {"bleu_score": 54.89938756679379, "chrf_score": 76.50868630543981, "xcomet_score": 0.8691004514694214, "xcomet_qe_score": 0.864662230014801, "metricx_score": 9.05293083190918, "metricx_qe_score": 9.633976936340332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Also produziert unser Modell einige Vorhersagen wie diese, die negative Werte erzeugen.", "metrics": {"bleu_score": 37.59663529467017, "chrf_score": 65.62116369067265, "xcomet_score": 0.9766751527786255, "xcomet_qe_score": 0.958366334438324, "metricx_score": 0.7754756212234497, "metricx_qe_score": 0.783221423625946, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese beiden Ausdrücke beobachtet.", "metrics": {"bleu_score": 12.337170820562472, "chrf_score": 37.45375896678608, "xcomet_score": 0.6525212526321411, "xcomet_qe_score": 0.8638011813163757, "metricx_score": 4.160698413848877, "metricx_qe_score": 8.916892051696777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Also können wir tatsächlich diesen Suchraum einschränken, indem wir negative Ergebnisse entfernen, damit wir die Antwort korrekt machen können.", "metrics": {"bleu_score": 20.53204727071094, "chrf_score": 64.57967969960816, "xcomet_score": 0.9369549751281738, "xcomet_qe_score": 0.8381870985031128, "metricx_score": 2.0810623168945312, "metricx_qe_score": 2.670349597930908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Also verbessert sich dieser Konstrukt tatsächlich quite a lot für einige Modelle.", "metrics": {"bleu_score": 8.893584607712837, "chrf_score": 35.880331500867655, "xcomet_score": 0.8271245956420898, "xcomet_qe_score": 0.8942294120788574, "metricx_score": 9.172358512878418, "metricx_qe_score": 7.508527755737305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel für Vögel verbessern wir sie um sieben Punkte und dann für das robotergestützte Modell tatsächlich um zwei Punkte.", "metrics": {"bleu_score": 11.744506415971863, "chrf_score": 40.57395541702838, "xcomet_score": 0.6889440417289734, "xcomet_qe_score": 0.6989712119102478, "metricx_score": 10.02750015258789, "metricx_qe_score": 9.92028522491455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besserer Sprachmodell hat eine bessere Sprachverständnisfähigkeit, sodass der Wert hier oben für Roboter höher ist und niedriger für menschen.", "metrics": {"bleu_score": 7.1153576636023255, "chrf_score": 64.12925696114354, "xcomet_score": 0.7964245676994324, "xcomet_qe_score": 0.7709645628929138, "metricx_score": 5.436809062957764, "metricx_qe_score": 4.22796106338501, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Und wir versuchen auch, die Schwierigkeit hinter diesem zu analysieren.", "metrics": {"bleu_score": 29.167552921712726, "chrf_score": 67.27051826866278, "xcomet_score": 0.8533326983451843, "xcomet_qe_score": 0.8380154371261597, "metricx_score": 4.849609851837158, "metricx_qe_score": 4.860466957092285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der nicht verwendeten Menge als relevante Information hier betrachtet werden kann.", "metrics": {"bleu_score": 54.68017145144114, "chrf_score": 76.88136805660865, "xcomet_score": 0.8949771523475647, "xcomet_qe_score": 0.8868476152420044, "metricx_score": 7.334278583526611, "metricx_qe_score": 8.369383811950684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel können wir sehen, dass die Menge der nicht verwendeten Qualitäten bei den Swamptests am größten ist.", "metrics": {"bleu_score": 8.138452527768058, "chrf_score": 29.321777827827937, "xcomet_score": 0.7917962074279785, "xcomet_qe_score": 0.7769588232040405, "metricx_score": 5.344079971313477, "metricx_qe_score": 5.828380584716797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung.", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 95.153554655332, "xcomet_score": 0.9975186586380005, "xcomet_qe_score": 0.9953868389129639, "metricx_score": 0.17540127038955688, "metricx_qe_score": 0.28346192836761475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Samples ohne Verwendung von Quantitäten ist die Gesamtleistung tatsächlich höher als die Leistung.", "metrics": {"bleu_score": 15.065202446392847, "chrf_score": 53.817901839252634, "xcomet_score": 0.6709426641464233, "xcomet_qe_score": 0.5882710218429565, "metricx_score": 8.922957420349121, "metricx_qe_score": 9.35964584350586, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben ist die Qualität ohne Verwendung von Quoten tatsächlich viel schlechter als die der anderen.", "metrics": {"bleu_score": 26.801651563557787, "chrf_score": 52.669270807026244, "xcomet_score": 0.7580152750015259, "xcomet_qe_score": 0.7651086449623108, "metricx_score": 4.999515056610107, "metricx_qe_score": 6.227294921875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Leistung für MWP S: Wir haben nicht allzu viele Fallstudien, deshalb ignoriere ich diesen Teil einfach.", "metrics": {"bleu_score": 28.339296176052862, "chrf_score": 51.89297107521666, "xcomet_score": 0.7797788977622986, "xcomet_qe_score": 0.7565770149230957, "metricx_score": 4.56435489654541, "metricx_qe_score": 5.157742500305176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Also möchte ich Ihnen letztendlich die Verständlichkeit durch einen Beispiel zeigen, indem ich eine Crasheschutz-Prüfung anwende.", "metrics": {"bleu_score": 2.8265205879007453, "chrf_score": 27.018890449234796, "xcomet_score": 0.7419398427009583, "xcomet_qe_score": 0.8265236020088196, "metricx_score": 6.357238292694092, "metricx_qe_score": 6.106545925140381, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Also hier macht unser Modell tatsächlich eine falsche Vorhersage beim ersten Schritt.", "metrics": {"bleu_score": 35.74046404361828, "chrf_score": 87.58867726302861, "xcomet_score": 0.9770916700363159, "xcomet_qe_score": 0.9484221339225769, "metricx_score": 0.3740077018737793, "metricx_qe_score": 0.5355964303016663, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können also diese Ausdrücke tatsächlich mit der hier stehenden Sätze korrelieren.", "metrics": {"bleu_score": 10.647403801936504, "chrf_score": 58.29526126881605, "xcomet_score": 0.9661484360694885, "xcomet_qe_score": 0.9693382382392883, "metricx_score": 1.8121609687805176, "metricx_qe_score": 1.0841586589813232, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken daher, dass diese Senzen möglicherweise das Modell in eine falsche Vorhersage führen könnten.", "metrics": {"bleu_score": 8.233514927922947, "chrf_score": 54.70484380938828, "xcomet_score": 0.9432041049003601, "xcomet_qe_score": 0.9468787908554077, "metricx_score": 3.31184720993042, "metricx_qe_score": 1.7776594161987305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Also hier drucke ich noch einmal eine andere 35, macht das Modell, macht das Modell glauben, es sollte eine additiv operated sein.", "metrics": {"bleu_score": 4.320304869998879, "chrf_score": 34.70961204372815, "xcomet_score": 0.486102819442749, "xcomet_qe_score": 0.46886545419692993, "metricx_score": 13.984067916870117, "metricx_qe_score": 13.575138092041016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Also versuchen wir, die Sätze zu überarbeiten, um so etwas wie die Anzahl der reifen Bäume sind um etwa fiftieth geringer als die Apfelbäume zu sagen.", "metrics": {"bleu_score": 7.334959170370916, "chrf_score": 42.4014855819209, "xcomet_score": 0.7310444116592407, "xcomet_qe_score": 0.7518495321273804, "metricx_score": 14.055643081665039, "metricx_qe_score": 13.35606575012207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir machen es, um eine genauere Semantik zu übermitteln, damit das Modell die korrekte Vorhersage treffen kann.", "metrics": {"bleu_score": 8.430319854586646, "chrf_score": 48.868913097840725, "xcomet_score": 0.9599319696426392, "xcomet_qe_score": 0.9490355849266052, "metricx_score": 1.5308952331542969, "metricx_qe_score": 1.5494952201843262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Studie zeigt, wie interpretierbare Vorhersagen uns helfen, das Verhalten des Modells zu verstehen.", "metrics": {"bleu_score": 18.842393723950345, "chrf_score": 70.06307888372235, "xcomet_score": 0.9724700450897217, "xcomet_qe_score": 0.9618144035339355, "metricx_score": 1.4551140069961548, "metricx_qe_score": 1.385036587715149, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Also umfassend zu unserem Arbeitswerk. Also zuerst ist unser Modell tatsächlich ziemlich effizient.", "metrics": {"bleu_score": 40.016016019225006, "chrf_score": 65.75367844924791, "xcomet_score": 0.9238817095756531, "xcomet_qe_score": 0.9015403985977173, "metricx_score": 5.142775058746338, "metricx_qe_score": 4.797088623046875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir sind in der Lage, ein unvergleichliches Lösungsschema bereitzustellen.", "metrics": {"bleu_score": 43.36189090348677, "chrf_score": 45.44429962721176, "xcomet_score": 0.9184010624885559, "xcomet_qe_score": 0.9735630750656128, "metricx_score": 1.707688570022583, "metricx_qe_score": 2.385282278060913, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht vorherige Kenntnisse als Konstante integrieren, was die Leistung verbessern kann.", "metrics": {"bleu_score": 7.473868453555444, "chrf_score": 36.37773593449275, "xcomet_score": 0.9915565252304077, "xcomet_qe_score": 0.9879515171051025, "metricx_score": 1.752579927444458, "metricx_qe_score": 1.2321652173995972, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Die letzte Sache ist, dass die unterliegende Mechanik nicht nur auf Netzwerkproblemlösungstests anwendbar ist, sondern auch auf andere Tests, die mehrstufige Verarbeitung erfordern.", "metrics": {"bleu_score": 8.777339797465444, "chrf_score": 49.61621683159566, "xcomet_score": 0.9574916362762451, "xcomet_qe_score": 0.9748002290725708, "metricx_score": 2.459522008895874, "metricx_qe_score": 1.692105770111084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 18.03958201806172, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherbedarf相当 hoch sein.", "metrics": {"bleu_score": 78.09325628873462, "chrf_score": 82.11544882388363, "xcomet_score": 0.9065384864807129, "xcomet_qe_score": 0.958346962928772, "metricx_score": 0.5340757369995117, "metricx_qe_score": 0.5383468866348267, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Sache ist, dass die Wahrscheinlichkeitsverteilung an verschiedenen Zeitpunkten ungleich ist, sodass die Anwendung von Suchalgorithmen auch eine Herausforderung darstellt.", "metrics": {"bleu_score": 2.6459536968224975, "chrf_score": 44.81246759075463, "xcomet_score": 0.9626609086990356, "xcomet_qe_score": 0.9717568159103394, "metricx_score": 1.834747076034546, "metricx_qe_score": 1.786940097808838, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Also ist dies das Ende des Vortrags und ich begrüße Fragen.", "metrics": {"bleu_score": 10.93705719052346, "chrf_score": 32.289548566665225, "xcomet_score": 0.9150072336196899, "xcomet_qe_score": 0.9057514667510986, "metricx_score": 2.192064046859741, "metricx_qe_score": 1.4984145164489746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Mein Name ist Antoine und ich bin von der Universität Maastricht.", "metrics": {"bleu_score": 77.4403141014203, "chrf_score": 92.21577416896909, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10292574763298035, "metricx_qe_score": 0.09224346280097961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein gemeinsames Werk mit Jerry präsentieren, das über ein neues Datensatz für den statischen Artikelabzug handelt.", "metrics": {"bleu_score": 6.317540230731247, "chrf_score": 44.958937672759205, "xcomet_score": 0.7777385711669922, "xcomet_qe_score": 0.802132248878479, "metricx_score": 3.742673873901367, "metricx_qe_score": 3.238891124725342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtliche Angelegenheiten sind ein integraler Bestandteil des Lebens vieler Menschen.", "metrics": {"bleu_score": 51.93071778680675, "chrf_score": 73.78101035181317, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4498419165611267, "metricx_qe_score": 0.27269768714904785, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Die Mehrheit der Bürger hat jedoch wenig bis keine Kenntnis über ihre Rechte und grundlegenden rechtlichen Verfahren.", "metrics": {"bleu_score": 22.250253290431033, "chrf_score": 65.3578476285751, "xcomet_score": 0.9985010623931885, "xcomet_qe_score": 0.9994922876358032, "metricx_score": 0.35327231884002686, "metricx_qe_score": 0.5623337626457214, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Infolgedessen sind viele verletzte Bürger, die sich nicht leisten können, die teure Hilfe eines Rechtsanwalts zu bezahlen, ungeschützt oder sogar ausgebeutet.", "metrics": {"bleu_score": 20.672177376975434, "chrf_score": 46.014281112429515, "xcomet_score": 0.9178903698921204, "xcomet_qe_score": 0.9544598460197449, "metricx_score": 2.7498674392700195, "metricx_qe_score": 1.5358606576919556, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Werk oder die Arbeit zielt darauf ab, den Unterschied zwischen Menschen und dem Computer zu überbrücken, indem sie ein effektives Retrievalssystem für gesetzliche Artikel entwickelt.", "metrics": {"bleu_score": 28.190471507804133, "chrf_score": 68.85043479961158, "xcomet_score": 0.8647934198379517, "xcomet_qe_score": 0.8392003178596497, "metricx_score": 3.5086846351623535, "metricx_qe_score": 4.601376056671143, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen, professionellen, juristischen Hilfe-Dienst für unqualifizierte Menschen bieten.", "metrics": {"bleu_score": 34.234749558690204, "chrf_score": 70.64139590999957, "xcomet_score": 0.962968111038208, "xcomet_qe_score": 0.9797578454017639, "metricx_score": 0.9718643426895142, "metricx_qe_score": 0.7624139189720154, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns auf den Hauptbeitrag dieses Werks konzentrieren, beschreiben wir zunächst das Problem der gesetzlichen Artikelretraktion.", "metrics": {"bleu_score": 19.469940719627616, "chrf_score": 59.21195390665408, "xcomet_score": 0.8609490990638733, "xcomet_qe_score": 0.8926309943199158, "metricx_score": 3.2872231006622314, "metricx_qe_score": 2.921687602996826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ich gegen die berufliche Vertraulichkeit verstoße, was riskiere ich?", "metrics": {"bleu_score": 4.7525582267211846, "chrf_score": 27.606318622561542, "xcomet_score": 0.4846401810646057, "xcomet_qe_score": 0.8692760467529297, "metricx_score": 1.571026086807251, "metricx_qe_score": 1.6272352933883667, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetzeswerk zu entfernen.", "metrics": {"bleu_score": 20.789290034925113, "chrf_score": 51.42704549436503, "xcomet_score": 0.8527534008026123, "xcomet_qe_score": 0.8553063869476318, "metricx_score": 5.41090726852417, "metricx_qe_score": 5.670981407165527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsaustausch zwischen den tribes ist mit seinen eigenen Herausforderungen verbunden.", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 47.43658458988465, "xcomet_score": 0.8603342175483704, "xcomet_qe_score": 0.8508914709091187, "metricx_score": 4.8765339851379395, "metricx_qe_score": 5.156551361083984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Erstens beschäftigt es sich mit zwei Arten von Sprachen.", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 61.21464378680732, "xcomet_score": 0.9373613595962524, "xcomet_qe_score": 0.9412536025047302, "metricx_score": 0.1608111411333084, "metricx_qe_score": 0.23440663516521454, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "\"Common natural language for questions and complex legal language for statutes.\"", "metrics": {"bleu_score": 2.4617934274488045, "chrf_score": 15.544853179647925, "xcomet_score": 0.9346396923065186, "xcomet_qe_score": 0.9702761173248291, "metricx_score": 16.298429489135742, "metricx_qe_score": 18.18822479248047, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Unterschied in der Sprachverteilung macht es schwieriger für ein System, gleiche Kandidaten zu finden, da sie indirekt erfordert, dass es ein内재liches Interpretationssystem gibt, das in der Lage ist, eine natürliche Frage in eine rechtliche Frage umzuwandeln, die mit der Terminologie von Gesetzen übereinstimmt.", "metrics": {"bleu_score": 27.04273900685645, "chrf_score": 69.9341330388205, "xcomet_score": 0.8015393018722534, "xcomet_qe_score": 0.7650861740112305, "metricx_score": 5.070483207702637, "metricx_qe_score": 4.151399612426758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus ist das Gesetz nicht ein unabhängiges Werkzeug, das als vollständiger Informationsquelle behandelt werden kann, wie zum Beispiel Nachrichten oder Rezepte.", "metrics": {"bleu_score": 12.04485753758003, "chrf_score": 52.753973966996966, "xcomet_score": 0.9504989385604858, "xcomet_qe_score": 0.9345217347145081, "metricx_score": 3.755378007888794, "metricx_qe_score": 3.271909236907959, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen ist es eine strukturierte Sammlung von rechtlichen Vorschriften, die ihre gesamte Bedeutung nur dann haben, wenn sie im Gesamtkontext betrachtet werden, zusammen mit zusätzlichen Informationen aus benachbarten Artikeln, den Feldern und Unterfeldern, denen sie gehören, und ihrem Platz in der Gesetzgebung.", "metrics": {"bleu_score": 11.045105509508653, "chrf_score": 55.948396709510774, "xcomet_score": 0.9723579287528992, "xcomet_qe_score": 0.9735999703407288, "metricx_score": 0.6401827335357666, "metricx_qe_score": 0.6277303695678711, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Letztendlich sind es formelle Artikel, die in kleinen Absätzen behandelt werden, was üblicherweise der typische Erweiterungseinheit in大部分 Extraktionsarbeiten entspricht.", "metrics": {"bleu_score": 7.645949399477267, "chrf_score": 38.68012137057294, "xcomet_score": 0.616257905960083, "xcomet_qe_score": 0.6475461721420288, "metricx_score": 10.59867000579834, "metricx_qe_score": 8.60948657989502, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Seiten lang sein können.", "metrics": {"bleu_score": 40.52587697205425, "chrf_score": 52.809790764544694, "xcomet_score": 0.9993205070495605, "xcomet_qe_score": 1.0, "metricx_score": 0.8597356677055359, "metricx_qe_score": 0.7167233824729919, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben zu einem großen Interesse an vielen rechtlichen Themen geführt, wie z.B. rechtliches Urteilshaben oder automatisierte Vertragsgespräche.", "metrics": {"bleu_score": 16.140877838057012, "chrf_score": 49.99751365135294, "xcomet_score": 0.8330256938934326, "xcomet_qe_score": 0.8357981443405151, "metricx_score": 5.374872207641602, "metricx_qe_score": 5.533667087554932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die rechtliche Ersetzung ist bislang hauptsächlich unberührt geblieben, aufgrund mangelnder hochwertiger, etikettierter Datensätze.", "metrics": {"bleu_score": 4.7898920568856385, "chrf_score": 41.38457259801457, "xcomet_score": 0.739800214767456, "xcomet_qe_score": 0.7682890295982361, "metricx_score": 4.937593460083008, "metricx_qe_score": 4.960323810577393, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Werk präsentieren wir ein neues französisches native Datenset zum Studium der Frage, ob ein Retrieval-Modell die Effizienz und Zuverlässigkeit von rechtsexperten für die Aufgabe der strafrechtlichen Artikelrecherche approximate kann.", "metrics": {"bleu_score": 8.250401506822344, "chrf_score": 46.35372814251654, "xcomet_score": 0.7254219651222229, "xcomet_qe_score": 0.6423095464706421, "metricx_score": 8.663473129272461, "metricx_qe_score": 8.836047172546387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Die belgische Artikel 39 Absatz 2 Sätze 1 und 2 besteht aus mehr als 1100 Artikeln.", "metrics": {"bleu_score": 8.915848000621141, "chrf_score": 26.258985590813786, "xcomet_score": 0.1429295390844345, "xcomet_qe_score": 0.15368348360061646, "metricx_score": 18.958763122558594, "metricx_qe_score": 19.37384033203125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen ein breites Spektrum an Themen - von Familie und Wohnung bis hin zu Arbeit und Sozialversicherung.", "metrics": {"bleu_score": 34.34317738548994, "chrf_score": 63.41870458234718, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.607720136642456, "metricx_qe_score": 0.6496073007583618, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einer Sammlung von mehr als 22.000 Artikeln versehen.", "metrics": {"bleu_score": 51.06181696768391, "chrf_score": 64.68545311933487, "xcomet_score": 0.8681478500366211, "xcomet_qe_score": 0.9453171491622925, "metricx_score": 3.983830451965332, "metricx_qe_score": 4.622663974761963, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Die belgische K往外流。Lassen Sie uns jetzt darüber sprechen, wie wir diese Datensätze gesammelt haben.", "metrics": {"bleu_score": 33.64932442330151, "chrf_score": 73.71197207966546, "xcomet_score": 0.33993905782699585, "xcomet_qe_score": 0.2597215175628662, "metricx_score": 9.09354305267334, "metricx_qe_score": 12.491575241088867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir angefangen, eine große Sammlung von Lehrschriften zu kompilieren.", "metrics": {"bleu_score": 13.065113298388567, "chrf_score": 39.38859610740266, "xcomet_score": 0.9800857901573181, "xcomet_qe_score": 0.98716801404953, "metricx_score": 3.0066840648651123, "metricx_qe_score": 3.13141131401062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben dreißig zwei öffentlich zugängliche belgische Gesetze untersucht und alle ihre Artikel sowie die entsprechenden Abschnittsüberschriften extrahiert.", "metrics": {"bleu_score": 43.59493824807389, "chrf_score": 80.83055452178951, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5965266823768616, "metricx_qe_score": 0.5651661157608032, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Referenzen zu relevanten Statuten.", "metrics": {"bleu_score": 23.708987804092644, "chrf_score": 42.261902601026236, "xcomet_score": 0.9881705045700073, "xcomet_qe_score": 1.0, "metricx_score": 1.4157650470733643, "metricx_qe_score": 0.5665167570114136, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Um dies zu tun, arbeiten wir mit einer belgischen Rechtsfirma zusammen, die jedes Jahr etwa 4000 E-Mails von belgischen Bürgerinnen und Bürgern erhält, die Rat bei persönlichen oder rechtlichen Fragen suchen.", "metrics": {"bleu_score": 34.42087651652725, "chrf_score": 66.3602608242782, "xcomet_score": 0.9886109232902527, "xcomet_qe_score": 1.0, "metricx_score": 0.6451818346977234, "metricx_qe_score": 0.38125815987586975, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich genug, um Zugang zu ihren Websites zu erhalten, auf denen ihr Team erfahrener Juristen belgische häufigste rechtliche Fragen beantwortet.", "metrics": {"bleu_score": 41.72618870344869, "chrf_score": 56.62338578456644, "xcomet_score": 0.9135911464691162, "xcomet_qe_score": 0.9075460433959961, "metricx_score": 4.097814559936523, "metricx_qe_score": 3.3513190746307373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben tausende von Fragen gesammelt, die mit Kategorien, Unterkategorien und relevanten Gesetzen mit legalen Referenzen annotiert wurden.", "metrics": {"bleu_score": 26.153117750218023, "chrf_score": 65.55242149758573, "xcomet_score": 0.9806758165359497, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.5492615699768066, "metricx_qe_score": 1.8113733530044556, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Letztendlich haben wir die rechtlichen Referenzen überprüft und ausgewählt, die Fragen enthielten, deren Referenzen nicht in einem der Gesetze lagen, die wir berücksichtigt haben.", "metrics": {"bleu_score": 21.651956746181053, "chrf_score": 56.12473159082329, "xcomet_score": 0.8752074241638184, "xcomet_qe_score": 0.8717136979103088, "metricx_score": 6.081477165222168, "metricx_qe_score": 5.451762676239014, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die restlichen Referenzen wurden abgeglichen und in die entsprechenden Artikel-IDs von Okapi umgewandelt.", "metrics": {"bleu_score": 32.57566281011689, "chrf_score": 61.40641634056805, "xcomet_score": 0.9284489750862122, "xcomet_qe_score": 0.928709089756012, "metricx_score": 3.1970744132995605, "metricx_qe_score": 3.776822090148926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir kamen schließlich zu einer Gesamtzahl von 1108 Fragen, die sorgfältig mit den ID's der relevanten Artikel versehen wurden.", "metrics": {"bleu_score": 9.41665329981294, "chrf_score": 43.27440692111564, "xcomet_score": 0.9474833011627197, "xcomet_qe_score": 0.9268856644630432, "metricx_score": 3.4265847206115723, "metricx_qe_score": 7.363234996795654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "In addition, each question comes with a main category and a concatenation of subcategories.", "metrics": {"bleu_score": 2.445593937240363, "chrf_score": 19.78776826891362, "xcomet_score": 0.976622462272644, "xcomet_qe_score": 1.0, "metricx_score": 22.776611328125, "metricx_qe_score": 24.11787986755371, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Jeder Artikel enthält die Kombination seiner nachfolgenden Headings in der Struktur des Dokuments.", "metrics": {"bleu_score": 7.141816289329644, "chrf_score": 30.01371255327659, "xcomet_score": 0.9515608549118042, "xcomet_qe_score": 0.9601210355758667, "metricx_score": 4.696632385253906, "metricx_qe_score": 5.292027473449707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Externe Information wird in der aktuellen Arbeit nicht verwendet, könnte aber für zukünftige Forschungen zu rechtlicher Informationsgewinnung oder -klassifizierung von Interesse sein.", "metrics": {"bleu_score": 21.515824939972177, "chrf_score": 54.86294393259805, "xcomet_score": 0.9266052842140198, "xcomet_qe_score": 0.9442435503005981, "metricx_score": 1.8780348300933838, "metricx_qe_score": 1.817179799079895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Lass uns einige Merkmale von Datensätzen betrachten.", "metrics": {"bleu_score": 19.493995755254467, "chrf_score": 47.43720632651502, "xcomet_score": 0.9682407379150391, "xcomet_qe_score": 0.974138081073761, "metricx_score": 2.8452329635620117, "metricx_qe_score": 0.6268815994262695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen sind zwischen fünf und vierzig Wörtern lang mit einem Durchschnitt von vierzehn Wörtern.", "metrics": {"bleu_score": 36.61432823178966, "chrf_score": 61.84098465032663, "xcomet_score": 0.9851102828979492, "xcomet_qe_score": 0.9868687391281128, "metricx_score": 0.8085618615150452, "metricx_qe_score": 1.0244946479797363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger mit einer durchschnittlichen Länge von siebzig sieben Wörtern mit einer Vielzahl von.", "metrics": {"bleu_score": 22.609182032261533, "chrf_score": 55.5714051642131, "xcomet_score": 0.7749027013778687, "xcomet_qe_score": 0.7757702469825745, "metricx_score": 12.904170036315918, "metricx_qe_score": 12.570636749267578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Zwei davon überschreiten eine Tonne.", "metrics": {"bleu_score": 4.167251645138561, "chrf_score": 12.330207897666924, "xcomet_score": 0.1980619728565216, "xcomet_qe_score": 0.1427546739578247, "metricx_score": 7.187735080718994, "metricx_qe_score": 12.790145874023438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasst die Frage eine breite Palette von Themen, wovon etwa eighty five Prozent davon sich auf Familie, Wohnen, Geld oder Gerechtigkeit beziehen.", "metrics": {"bleu_score": 13.532713716527189, "chrf_score": 50.51629139921414, "xcomet_score": 0.9243017435073853, "xcomet_qe_score": 0.9418637752532959, "metricx_score": 5.03419303894043, "metricx_qe_score": 5.196447849273682, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Die restlichen 15% betreffen either soziale Sicherheit, Ausländer oder Arbeit.", "metrics": {"bleu_score": 59.230330720232516, "chrf_score": 78.9748304476697, "xcomet_score": 0.9762303233146667, "xcomet_qe_score": 0.9942417144775391, "metricx_score": 2.026129961013794, "metricx_qe_score": 0.6068280935287476, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr divers, da sie aus dreißig zwei verschiedenen belgischen Gesetzen stammen, die einen großen Teil illegaler Themen abdecken.", "metrics": {"bleu_score": 31.961036230236623, "chrf_score": 66.01874347947351, "xcomet_score": 0.8696067333221436, "xcomet_qe_score": 0.8910635709762573, "metricx_score": 6.157908916473389, "metricx_qe_score": 6.097285747528076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Die Gesamtzahl der Artikel, die von jedem dieser belgischen Briefmarken gesammelt wurden, ist hier nicht angegeben.", "metrics": {"bleu_score": 23.83041256525615, "chrf_score": 62.685551655308636, "xcomet_score": 0.5754048228263855, "xcomet_qe_score": 0.614224374294281, "metricx_score": 9.533767700195312, "metricx_qe_score": 6.879636287689209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den 22.336 Artikeln sind nur 16.12 als relevant für mindestens ein Thema bezeichnet worden.", "metrics": {"bleu_score": 18.928624746011366, "chrf_score": 55.04600165580597, "xcomet_score": 0.8847361207008362, "xcomet_qe_score": 0.874017059803009, "metricx_score": 1.9727915525436401, "metricx_qe_score": 1.688706398010254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragestellung in den Datensätzen lautet: 'Etwa eighty percent dieser zitierten Artikel stammen aus dem Bürgerlichen Gesetzbuch, Strafgesetzbuch, Strafverfahrensrecht oder Strafbefehlsgesetz.'", "metrics": {"bleu_score": 12.789533377801794, "chrf_score": 50.17006405654351, "xcomet_score": 0.4958486557006836, "xcomet_qe_score": 0.6382302045822144, "metricx_score": 9.868969917297363, "metricx_qe_score": 8.5712890625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit haben achtzehn von dreißig zwei Kodes weniger als fünf Artikel erwähnt, die relevant für mindestens eine Frage sind.", "metrics": {"bleu_score": 27.151607333166954, "chrf_score": 56.68357178221892, "xcomet_score": 0.8968122005462646, "xcomet_qe_score": 0.8868693709373474, "metricx_score": 4.134936332702637, "metricx_qe_score": 3.4382705688476562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Umstand kann durch die Tatsache erklärt werden, dass diese Gesetze weniger auf Individuen und ihre Sorgen ausgerichtet sind.", "metrics": {"bleu_score": 9.560408787521254, "chrf_score": 50.844276873134966, "xcomet_score": 0.99564528465271, "xcomet_qe_score": 0.9866161942481995, "metricx_score": 1.4536479711532593, "metricx_qe_score": 0.9896095395088196, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt beträgt die durchschnittliche Anzahl der Zitate für diese zitierten Artikel zwei, und weniger als 25% davon sind.", "metrics": {"bleu_score": 26.68330018500054, "chrf_score": 55.21562874305126, "xcomet_score": 0.782512903213501, "xcomet_qe_score": 0.7727322578430176, "metricx_score": 10.057892799377441, "metricx_qe_score": 9.321600914001465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datenbanken haben wir mehrere Abrechnungswege für die Abholung einschließlich lexikaler und dichter Architektur getestet.", "metrics": {"bleu_score": 10.35158390396198, "chrf_score": 42.83979372944937, "xcomet_score": 0.7307488918304443, "xcomet_qe_score": 0.760496973991394, "metricx_score": 12.572607040405273, "metricx_qe_score": 13.107349395751953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Gibt ein Lexikum in einem Artikel eine Note für das Querartikelpaar durch Berechnung der Summe über die Gewichte jedes dieser Terme in diesem Artikel.", "metrics": {"bleu_score": 6.578567802484727, "chrf_score": 35.13974210436951, "xcomet_score": 0.7379209995269775, "xcomet_qe_score": 0.7956403493881226, "metricx_score": 9.882316589355469, "metricx_qe_score": 8.096020698547363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standardtfidf- und bM-25-Rankingfunktionen.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 69.57884541264696, "xcomet_score": 0.8991551995277405, "xcomet_qe_score": 0.8776732683181763, "metricx_score": 2.4178507328033447, "metricx_qe_score": 3.1159074306488037, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Die Hauptprobleme mit diesen Ansätzen sind, dass sie nur Artikel zurückziehen können, die Schlüsselwörter enthalten, die in der Suchanfrage vorhanden sind.", "metrics": {"bleu_score": 49.124158433111575, "chrf_score": 74.76691809353903, "xcomet_score": 0.9694686532020569, "xcomet_qe_score": 0.9694673418998718, "metricx_score": 3.1677420139312744, "metricx_qe_score": 3.0727715492248535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neural-basierten Architektur, die semantische Beziehungen zwischen Suchanfragen und Artikeln erfassen kann.", "metrics": {"bleu_score": 75.22135016840222, "chrf_score": 93.89359393922726, "xcomet_score": 0.9599013328552246, "xcomet_qe_score": 0.9717234969139099, "metricx_score": 0.9634929895401001, "metricx_qe_score": 0.33498653769493103, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein BERT-Modell, das Suchfragen und Artikel in dense Vektordarstellungen mappa und berechnet eine Relevanzskala zwischen einem Suchwort-Artikel-Paar durch die Ähnlichkeit ihrer Eingebettungen.", "metrics": {"bleu_score": 13.07929141289792, "chrf_score": 61.840971218638316, "xcomet_score": 0.7895978689193726, "xcomet_qe_score": 0.9131608605384827, "metricx_score": 6.783520698547363, "metricx_qe_score": 6.675168991088867, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Verkettungen resultieren in der Regel aus einer Pooling-Operation auf dem Ausgang des Wortverkettungsmusters.", "metrics": {"bleu_score": 50.31747626530137, "chrf_score": 71.54687357080138, "xcomet_score": 0.8741328120231628, "xcomet_qe_score": 0.8637375831604004, "metricx_score": 4.973736763000488, "metricx_qe_score": 4.162327289581299, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit von Siamesischen Befehlshörern in einer Zer肖-Evaluierungsserie, was bedeutet, dass vortrainierte Modellvorlagen ohne weitere Feinjustierung direkt angewendet werden.", "metrics": {"bleu_score": 16.94882562383832, "chrf_score": 51.24821430055187, "xcomet_score": 0.786522626876831, "xcomet_qe_score": 0.7937904596328735, "metricx_score": 6.974255084991455, "metricx_qe_score": 6.817353248596191, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Kontextunabhängigen Texten-Empfängern, namely Word2Vec und FastText sowie Kontextabhängigen Eingebetteten Modellen, namely Roberta und insbesondere Camembert, das ein französisches RoBERTa-Modell ist.", "metrics": {"bleu_score": 10.109765416598174, "chrf_score": 65.94883822941264, "xcomet_score": 0.7745692729949951, "xcomet_qe_score": 0.807813286781311, "metricx_score": 4.854269504547119, "metricx_qe_score": 4.195812702178955, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus trainieren wir unseren eigenen CommonBird-basierten Modell, das ohne Querübersetzungen auskommt.", "metrics": {"bleu_score": 16.51207069202994, "chrf_score": 49.80352510091, "xcomet_score": 0.5682436227798462, "xcomet_qe_score": 0.6871541738510132, "metricx_score": 8.56119441986084, "metricx_qe_score": 6.423408508300781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "On oder Datensätze beachten Sie, dass wir für das Training mit den beiden Geschmacksrichtungen von Bianco experimentieren.", "metrics": {"bleu_score": 27.854685173648893, "chrf_score": 58.45477156041736, "xcomet_score": 0.42303892970085144, "xcomet_qe_score": 0.3863585293292999, "metricx_score": 12.9137544631958, "metricx_qe_score": 14.137084007263184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das einen einzigartigen Wortembindungsmodell verwendet, das die Quer- und Artikel zu einem gemeinsamen, gemeinsamen Dichtevektorraum abbildet, und Tesseract, das zwei unabhängige Wortembindungsmodelle verwendet, um die Quer- und Artikel getrennt in verschiedene Eingebettete Räume einzufangen.", "metrics": {"bleu_score": 19.80947966046687, "chrf_score": 63.231307076890445, "xcomet_score": 0.4369426965713501, "xcomet_qe_score": 0.47358179092407227, "metricx_score": 9.176640510559082, "metricx_qe_score": 8.035292625427246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben mit Mean-Max und CLS-Verfahren sowie Dot Product und Cosine für Berechnungen von Ähnlichkeiten experimentiert.", "metrics": {"bleu_score": 5.922398310212425, "chrf_score": 49.18827004616247, "xcomet_score": 0.6758284568786621, "xcomet_qe_score": 0.7994095087051392, "metricx_score": 6.393134117126465, "metricx_qe_score": 5.157896995544434, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse unserer Baseline-Testreihe auf dem Testset sind hier.", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 64.10169610861726, "xcomet_score": 0.9433388710021973, "xcomet_qe_score": 0.9427455067634583, "metricx_score": 0.8973318338394165, "metricx_qe_score": 1.0710198879241943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den lexicalen Methoden oben wurden die siamesischen Bambusquader in einer Zerlegung mit null Schritten im Mittel und fein abgestimmten Bambusquader unter Berücksichtigung der kulturellen Sensibilität übersetzt.", "metrics": {"bleu_score": 3.889818545474848, "chrf_score": 42.54923589602243, "xcomet_score": 0.5849413871765137, "xcomet_qe_score": 0.6097548007965088, "metricx_score": 20.42751693725586, "metricx_qe_score": 20.864500045776367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt hat sich der Fine-Tune-Basscode in Bezug auf alle anderen Basenlines deutlich bewährt.", "metrics": {"bleu_score": 7.474875887495341, "chrf_score": 48.008493218418394, "xcomet_score": 0.774390697479248, "xcomet_qe_score": 0.7773064374923706, "metricx_score": 5.765384197235107, "metricx_qe_score": 6.3371782302856445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das dicker Modell verbessert sich gegenüber seiner Siamese-Variante auf Rückzug bei 100, aber performed similarly on the other metrics.", "metrics": {"bleu_score": 8.95165248130093, "chrf_score": 43.25297235477415, "xcomet_score": 0.4262535572052002, "xcomet_qe_score": 0.47996941208839417, "metricx_score": 19.22996711730957, "metricx_qe_score": 18.458011627197266, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl B.M.25 die Trainingsdaten von Bianco deutlich unterboten hat, zeigt seine Leistung, dass es immer noch eine starke Grundlage für den domain spezifischen Retrieval darstellt.", "metrics": {"bleu_score": 12.26029504520199, "chrf_score": 49.869537736001696, "xcomet_score": 0.7501442432403564, "xcomet_qe_score": 0.8027143478393555, "metricx_score": 6.7673773765563965, "metricx_qe_score": 7.374661445617676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "In Bezug auf die Zero-Shot-Evaluierung von Siamesischen Zwergen fanden wir, dass die direkte Verwendung der Eingebettungen eines vor trainierten Käfermodells ohne Optimierung für die Informationsoptimierung eine schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt.", "metrics": {"bleu_score": 44.148054804289515, "chrf_score": 72.08106184327505, "xcomet_score": 0.6057652831077576, "xcomet_qe_score": 0.5676947236061096, "metricx_score": 9.349607467651367, "metricx_qe_score": 9.037680625915527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir beobachtet, dass der word2vec-basierte BERT signifikant besser abschneidet als der foveal- und bird-basierte Modell, was darauf hinweist, dass maybe prätrainierte Wort-Ebene Eingaben für die Aufgabe besser geeignet sind als Charakter-Ebene oder Subwort-Ebene Eingaben, wenn sie aus dem Boxen verwendet werden.", "metrics": {"bleu_score": 15.506492764786808, "chrf_score": 57.66575320386842, "xcomet_score": 0.3917069137096405, "xcomet_qe_score": 0.4877990782260895, "metricx_score": 11.242361068725586, "metricx_qe_score": 10.364596366882324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl diese Ergebnisse voraussichtlich groß sind, deuten sie auf Möglichkeiten zur Verbesserung hin, verglichen mit einem erfahrenen Experten, der schließlich alle relevanten Artikel zu jeder Frage erhalten und damit perfekte Noten erhält.", "metrics": {"bleu_score": 20.30308308934382, "chrf_score": 52.9960176166988, "xcomet_score": 0.8929542303085327, "xcomet_qe_score": 0.8862755298614502, "metricx_score": 6.124999046325684, "metricx_qe_score": 6.124942779541016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns abschließen, indem wir zwei Einschränkungen von Datensätzen besprechen.", "metrics": {"bleu_score": 6.837203339116283, "chrf_score": 50.7269153149955, "xcomet_score": 0.9842575788497925, "xcomet_qe_score": 0.9763016104698181, "metricx_score": 4.476300239562988, "metricx_qe_score": 2.360407590866089, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Die Sammlung des Artikels beschränkt sich auf diejenigen Artikel, die aus den 32 betrachteten belgischen Gesetzen stammen, was nicht den gesamten belgischen Rechtskreis abdeckt, da fehlende Artikel aus Dekreten, Directiven und Verordnungen sind.", "metrics": {"bleu_score": 13.610902668776577, "chrf_score": 59.28480928894011, "xcomet_score": 0.8337727785110474, "xcomet_qe_score": 0.850600004196167, "metricx_score": 5.558791160583496, "metricx_qe_score": 5.04571008682251, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Referenzen zu diesen uncollected Artikeln ignoriert, was dazu führt, dass einige Fragestellungen nur mit einem Bruchteil des ursprünglichen Zahlen von relevanten Artikeln beantwortet werden können.", "metrics": {"bleu_score": 19.654670486002182, "chrf_score": 56.37945661342649, "xcomet_score": 0.8841820955276489, "xcomet_qe_score": 0.8927110433578491, "metricx_score": 5.836528778076172, "metricx_qe_score": 5.664881229400635, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationenverlust bedeutet, dass die in den verbleibenden relevanten Artikeln enthaltenen Antworten möglicherweise unvollständig sind, obwohl sie immer noch vollständig angemessen sind.", "metrics": {"bleu_score": 21.14214776985805, "chrf_score": 62.96777907328476, "xcomet_score": 0.9697626829147339, "xcomet_qe_score": 0.9335277080535889, "metricx_score": 1.5614358186721802, "metricx_qe_score": 1.371239185333252, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen mit Gesetzen allein beantwortet werden können.", "metrics": {"bleu_score": 74.5887820160771, "chrf_score": 95.38581891413504, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.06662534177303314, "metricx_qe_score": 0.11332423985004425, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: 'Kann ich meine Mieter verklagen, wenn sie zu viel Lärm machen?'", "metrics": {"bleu_score": 56.82854869630478, "chrf_score": 77.49772193173168, "xcomet_score": 0.9104695320129395, "xcomet_qe_score": 0.9201692342758179, "metricx_score": 1.5263490676879883, "metricx_qe_score": 1.0829650163650513, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Keine spezifische Lautstärke Schwellenwert, bei dem die Evakuierung verpflichtend ist.", "metrics": {"bleu_score": 3.500469699279811, "chrf_score": 20.505334492333297, "xcomet_score": 0.7593486905097961, "xcomet_qe_score": 0.934984028339386, "metricx_score": 8.368815422058105, "metricx_qe_score": 7.829283237457275, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter sich wahrscheinlich eher auf das Gesetz verlassen und Vorschriften finden, die ähnlich zur aktuellen Situation sind.", "metrics": {"bleu_score": 22.93784819843181, "chrf_score": 64.30720553504595, "xcomet_score": 0.8513197302818298, "xcomet_qe_score": 0.8980677127838135, "metricx_score": 3.762678623199463, "metricx_qe_score": 3.0648913383483887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Mieter zwei Parteien pro Woche bis zu zehn.", "metrics": {"bleu_score": 16.1805547365076, "chrf_score": 51.575099277309775, "xcomet_score": 0.7430956959724426, "xcomet_qe_score": 0.7393018007278442, "metricx_score": 14.276006698608398, "metricx_qe_score": 14.922407150268555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser geeignet als andere für die rechtliche Artikel-Extraktionsaufgabe, und das Gebiet der weniger geeigneten bleibt noch zu bestimmen.", "metrics": {"bleu_score": 14.07469240968721, "chrf_score": 48.648702053562744, "xcomet_score": 0.9403642416000366, "xcomet_qe_score": 0.9035009145736694, "metricx_score": 2.8297855854034424, "metricx_qe_score": 3.3780508041381836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unser Werk Interesse an der Entwicklung von praktischen und zuverlässigen Modellen für den Erhalt von Statistiken weckt.", "metrics": {"bleu_score": 25.376192011638008, "chrf_score": 60.407481047643195, "xcomet_score": 0.859489917755127, "xcomet_qe_score": 0.8584843873977661, "metricx_score": 6.775364398956299, "metricx_qe_score": 5.986074924468994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann dazu beitragen, den Zugang zu Justiz zu verbessern.", "metrics": {"bleu_score": 46.15415465297943, "chrf_score": 74.15813198270457, "xcomet_score": 0.9828016757965088, "xcomet_qe_score": 1.0, "metricx_score": 1.3436146974563599, "metricx_qe_score": 1.8354588747024536, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können Ihre Papiere, die Tatsachen und Code folgender Links überprüfen. Vielen Dank.", "metrics": {"bleu_score": 10.992148055152452, "chrf_score": 39.59476900214372, "xcomet_score": 0.7481287717819214, "xcomet_qe_score": 0.7709609270095825, "metricx_score": 11.675554275512695, "metricx_qe_score": 10.687336921691895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo,\nwir sind froh, unsere Arbeit zu präsentieren, die sich auf \"Vowels - A Task-Independent Benchmark\" konzentriert, eine Aufgabe für die Überprüfung von Visionen und Sprachmodellen mit spezifischen linguistischen Phänomenen.\nVielen Dank!", "metrics": {"bleu_score": 10.868081257715552, "chrf_score": 49.54882530006801, "xcomet_score": 0.7909315824508667, "xcomet_qe_score": 0.8437467217445374, "metricx_score": 7.548371315002441, "metricx_qe_score": 6.945276737213135, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Wieso haben wir bei der Einstellung dieses Benchmarks Schwierigkeiten gehabt?", "metrics": {"bleu_score": 7.574347133041985, "chrf_score": 35.12073312154694, "xcomet_score": 0.8437131643295288, "xcomet_qe_score": 0.8293888568878174, "metricx_score": 5.082495212554932, "metricx_qe_score": 2.378085136413574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "Well, in den letzten Jahren haben wir eine Explosion von transformatorbasierten Visionen und Sprachmodellen gesehen, die auf großen Mengen an Bild-Text-Paaren trainiert wurden.", "metrics": {"bleu_score": 33.442605320946306, "chrf_score": 67.90077575584792, "xcomet_score": 0.9337950348854065, "xcomet_qe_score": 0.9497510194778442, "metricx_score": 5.426671504974365, "metricx_qe_score": 4.621370792388916, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jeder dieser Modelle treibt den Staat des Kunstes auf visuellen Aufgaben wie Frage-Antworten auf, visuelle Common Sense-Reasoning, Bildernahme und Phrasengründung an.", "metrics": {"bleu_score": 9.251737997876598, "chrf_score": 39.439299797011806, "xcomet_score": 0.5905360579490662, "xcomet_qe_score": 0.6172482967376709, "metricx_score": 13.875636100769043, "metricx_qe_score": 12.924918174743652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Die Genauigkeiten dieser Aufgaben-spezifischen Benchmarks steigen stetig an.", "metrics": {"bleu_score": 2.3469435106238055, "chrf_score": 51.77563398272, "xcomet_score": 0.9808964729309082, "xcomet_qe_score": 0.9757239818572998, "metricx_score": 2.173398494720459, "metricx_qe_score": 3.352857828140259, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir tatsächlich, was die Modelle tatsächlich gelernt haben?", "metrics": {"bleu_score": 73.48889200874659, "chrf_score": 90.60624240376144, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7504125237464905, "metricx_qe_score": 1.106797695159912, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Ein Seh- und Sprachtransformer ist verstanden, wenn beim Zuordnen eines hohen Punktes für dieses Bild und dieser Sätze eine Übereinstimmung besteht.", "metrics": {"bleu_score": 17.059573701616795, "chrf_score": 58.808638924806, "xcomet_score": 0.7201825380325317, "xcomet_qe_score": 0.7035446763038635, "metricx_score": 7.633739471435547, "metricx_qe_score": 6.356825351715088, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "In der unteren Tabelle für diesen Eintrag.", "metrics": {"bleu_score": 0.0, "chrf_score": 15.5200618311902, "xcomet_score": 0.165388822555542, "xcomet_qe_score": 0.2357218861579895, "metricx_score": 7.146142482757568, "metricx_qe_score": 7.191356182098389, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Sind Vision- und Sprachmodelle auf das Richtige fokussiert?", "metrics": {"bleu_score": 17.0653267718276, "chrf_score": 39.939369915011845, "xcomet_score": 0.9315561056137085, "xcomet_qe_score": 0.9379537105560303, "metricx_score": 2.4195332527160645, "metricx_qe_score": 1.6783645153045654, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie sie in früheren Arbeiten gezeigt wurden?", "metrics": {"bleu_score": 37.0304683381906, "chrf_score": 74.7020182172442, "xcomet_score": 0.9824657440185547, "xcomet_qe_score": 1.0, "metricx_score": 0.3689274787902832, "metricx_qe_score": 0.30982154607772827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf dieses Aspekt zu werfen, schlagen wir eine task agnostische Richtung vor und einführen von Werten, die die Empfindlichkeit von Vision- und Sprachmodellen gegenüber bestimmten linguistischen Phänomenen testen, die sowohl die Linguistik als auch die visuellen Modifikationen betreffen.", "metrics": {"bleu_score": 25.680343457530977, "chrf_score": 58.7772729965512, "xcomet_score": 0.7211722135543823, "xcomet_qe_score": 0.7146052122116089, "metricx_score": 8.884328842163086, "metricx_qe_score": 7.999875068664551, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir beziehen uns auf das Bestehen, die Anzahl der Pluralität, die räumlichen Beziehungen, die Handlungen und die Referenzen an Entitäten.", "metrics": {"bleu_score": 6.19245064140527, "chrf_score": 51.75488083961678, "xcomet_score": 0.8623888492584229, "xcomet_qe_score": 0.8792898654937744, "metricx_score": 4.508638858795166, "metricx_qe_score": 3.9113519191741943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision und Sprachmodelle diese Phänomene erfasst haben?", "metrics": {"bleu_score": 18.010019776510696, "chrf_score": 57.09035903869795, "xcomet_score": 0.9784106016159058, "xcomet_qe_score": 0.969023585319519, "metricx_score": 2.229104995727539, "metricx_qe_score": 2.705169200897217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "\"Vom Foiling, einem zuvor für Vision- und Sprachmodelle nur für Nomenphrasen verwendeten Methoden, ausgehend von Ravi Shekhar und seinen Co-Autoren und uns in früheren Arbeiten.\"", "metrics": {"bleu_score": 18.58098589457432, "chrf_score": 50.2028382154712, "xcomet_score": 0.6460795402526855, "xcomet_qe_score": 0.6192774772644043, "metricx_score": 8.676108360290527, "metricx_qe_score": 9.96484088897705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foilung bedeutet im Grunde, dass wir die Überschrift eines Bildes nehmen und durch Veränderungen der Überschrift zu einem Foil machen, indem wir sie so ändern, dass sie das Bild nicht mehr beschreibt.", "metrics": {"bleu_score": 48.0309687584463, "chrf_score": 68.58000717016223, "xcomet_score": 0.8803560137748718, "xcomet_qe_score": 0.9475916624069214, "metricx_score": 8.438175201416016, "metricx_qe_score": 6.994456768035889, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Wir machen diese Wortänderungen, indem wir uns auf sechs spezifische Stücke konzentrieren, wie Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitätsbezug, wobei jedes Stück aus einem oder mehr Instrumenten bestehen kann. Im Falle von mehr als einem interessanten Weg zur Erstellung von foil-Beispielen haben wir.", "metrics": {"bleu_score": 30.531727087265473, "chrf_score": 62.54487230410184, "xcomet_score": 0.5563207864761353, "xcomet_qe_score": 0.5455618500709534, "metricx_score": 9.304279327392578, "metricx_qe_score": 8.388818740844727, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel hat der Actionsatz zwei Instrumente: eines, bei dem der Action-Verb durch einen anderen Action ersetzt wird, und eines, bei dem die Akkusative durch eine andere ersetzt werden.", "metrics": {"bleu_score": 38.57305563018101, "chrf_score": 56.38846308789385, "xcomet_score": 0.5408156514167786, "xcomet_qe_score": 0.5638349652290344, "metricx_score": 10.761996269226074, "metricx_qe_score": 9.865779876708984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Co-Referenz sind auch Teile, die mehr als ein Instrument haben.", "metrics": {"bleu_score": 77.4403141014203, "chrf_score": 83.31773896880968, "xcomet_score": 0.7951681017875671, "xcomet_qe_score": 0.8288320899009705, "metricx_score": 4.6121954917907715, "metricx_qe_score": 4.698324203491211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung dieser Foliensätze erfolgt dadurch, dass wir sicherstellen, dass sie die Bildbeschreibung nicht beschreiben, dass sie grammatisch korrekt und andererseits gültige Sätze sind.", "metrics": {"bleu_score": 27.668736912821892, "chrf_score": 58.51704432137495, "xcomet_score": 0.8151949048042297, "xcomet_qe_score": 0.9295110702514648, "metricx_score": 4.7590532302856445, "metricx_qe_score": 4.386952877044678, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist nicht einfach zu tun, da ein fehlendes Caption möglicherweise weniger wahrscheinlich ist als der ursprüngliche Caption.", "metrics": {"bleu_score": 16.586105071157164, "chrf_score": 48.31157301737705, "xcomet_score": 0.7923831939697266, "xcomet_qe_score": 0.8699273467063904, "metricx_score": 4.9806084632873535, "metricx_qe_score": 3.1751298904418945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es statistisch unwahrscheinlicher, dass Pflanzen einen Menschen schneiden als umgekehrt. Große Visionen und Sprachmodelle könnten dies aufgreifen.", "metrics": {"bleu_score": 24.475571240671872, "chrf_score": 57.68824732235136, "xcomet_score": 0.955896258354187, "xcomet_qe_score": 0.9386221170425415, "metricx_score": 5.1306867599487305, "metricx_qe_score": 4.294747352600098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um gültige Folienscheine zu erhalten, müssen wir Maßnahmen ergreifen.", "metrics": {"bleu_score": 9.00746750211399, "chrf_score": 38.314441137536775, "xcomet_score": 0.8697516322135925, "xcomet_qe_score": 0.9082716107368469, "metricx_score": 3.116203546524048, "metricx_qe_score": 2.2499096393585205, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwenden wir starke Sprachmodelle, um Vorschläge für eine Stimme zu unterbreiten.", "metrics": {"bleu_score": 27.824623288353134, "chrf_score": 50.869180966984764, "xcomet_score": 0.8345683217048645, "xcomet_qe_score": 0.826755940914154, "metricx_score": 5.737117290496826, "metricx_qe_score": 6.069751739501953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir Natural Language Inference oder kürzlich NLI, um Fehlerteile auszuwählen, die immer noch das Bild beschreiben könnten, da bei der Erstellung von Fehlern sicherstellen müssen, dass sie das Bild beschreiben.", "metrics": {"bleu_score": 19.76023657259005, "chrf_score": 52.86327837957917, "xcomet_score": 0.7270284295082092, "xcomet_qe_score": 0.7611254453659058, "metricx_score": 7.865995407104492, "metricx_qe_score": 7.349048614501953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, verwenden wir eine natürliche Sprachverarbeitung mit folgendem Rationale.", "metrics": {"bleu_score": 27.444201848360166, "chrf_score": 58.09735311647316, "xcomet_score": 0.9684134721755981, "xcomet_qe_score": 0.9708629846572876, "metricx_score": 2.2914369106292725, "metricx_qe_score": 2.5553014278411865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als Prämisse und dessen Übersetzung als dessen enthaltene Hypothese.", "metrics": {"bleu_score": 30.329987166688387, "chrf_score": 55.46765116661303, "xcomet_score": 0.9649434089660645, "xcomet_qe_score": 0.9900439381599426, "metricx_score": 1.4188107252120972, "metricx_qe_score": 0.8810669183731079, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In addition, we consider the caption to be the premise and the foil is its hypothesis.", "metrics": {"bleu_score": 2.1476912089159055, "chrf_score": 18.06661253883431, "xcomet_score": 0.8047457933425903, "xcomet_qe_score": 0.9914631843566895, "metricx_score": 24.716184616088867, "metricx_qe_score": 24.68431282043457, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell das foil vorhersagt, sich zu widersetzen oder neutral zu sein gegenüber dem Caption, nehmen wir dies als Indikator für ein valides foil.", "metrics": {"bleu_score": 9.018037817565661, "chrf_score": 45.283800759916595, "xcomet_score": 0.6363641619682312, "xcomet_qe_score": 0.7131728529930115, "metricx_score": 8.995591163635254, "metricx_qe_score": 8.16757583618164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI das foil vorhersagt, das durch den Slogan entstehen wird, kann es kein gutes foil sein, da durch Translativität es eine wahrheitsgetreue Beschreibung des Bildes geben wird und wir diese Fälschungen auswählen werden.", "metrics": {"bleu_score": 11.318741602028203, "chrf_score": 50.69303459922915, "xcomet_score": 0.5504075288772583, "xcomet_qe_score": 0.5598196983337402, "metricx_score": 9.856056213378906, "metricx_qe_score": 9.596420288085938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Vorgang ist nicht perfekt, er ist nur ein Indikator für einen gültigen Ton.", "metrics": {"bleu_score": 23.578316044531807, "chrf_score": 49.70397534591008, "xcomet_score": 0.852751612663269, "xcomet_qe_score": 0.8670119643211365, "metricx_score": 5.9853620529174805, "metricx_qe_score": 4.819651126861572, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Erzeugung von validen Daten人类 annotatoren, um die verwendeten Daten zu überprüfen.", "metrics": {"bleu_score": 26.469022722208067, "chrf_score": 48.300579242080005, "xcomet_score": 0.7135666608810425, "xcomet_qe_score": 0.889998197555542, "metricx_score": 6.499705791473389, "metricx_qe_score": 6.786962985992432, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Filterung und der menschlichen Bewertung haben wir so viele Testbeispiele wie in diesem Tabelle beschrieben.", "metrics": {"bleu_score": 16.78889985606835, "chrf_score": 61.390420236156196, "xcomet_score": 0.9776466488838196, "xcomet_qe_score": 0.9813722968101501, "metricx_score": 1.9155319929122925, "metricx_qe_score": 1.970461130142212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "NLP-Valves liefert keine Schulungsinformationen, sondern nur Testdaten.", "metrics": {"bleu_score": 19.696640745654683, "chrf_score": 44.674668247030304, "xcomet_score": 0.8266686201095581, "xcomet_qe_score": 0.8585792779922485, "metricx_score": 4.08602237701416, "metricx_qe_score": 4.428670406341553, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich um eine zero-Shot-Testing-Benutzerbewertung handelt, die nur bestehende Fähigkeiten von Vision- und Sprachmodellen nutzt, nachdem sie vorher trainiert wurden, ist sie darauf ausgelegt, diese zu nutzen.", "metrics": {"bleu_score": 10.726279796055946, "chrf_score": 55.2988778477326, "xcomet_score": 0.8338742256164551, "xcomet_qe_score": 0.8359450697898865, "metricx_score": 4.242952823638916, "metricx_qe_score": 3.3625831604003906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Fine-tuning würde nur ermöglichen, dass Modelle Artefakte oder statistische Biases in den Daten ausnutzen könnten.", "metrics": {"bleu_score": 19.238225665491054, "chrf_score": 59.93617948724742, "xcomet_score": 0.9513365030288696, "xcomet_qe_score": 0.9596567749977112, "metricx_score": 3.4074480533599854, "metricx_qe_score": 3.047682046890259, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Kürzungen machen.", "metrics": {"bleu_score": 29.89950354998137, "chrf_score": 59.630494720724755, "xcomet_score": 0.9516656398773193, "xcomet_qe_score": 0.9102979898452759, "metricx_score": 3.3966257572174072, "metricx_qe_score": 2.427495002746582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, interessieren wir uns dafür, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vorbildung haben.", "metrics": {"bleu_score": 18.22986851602933, "chrf_score": 57.12666260163981, "xcomet_score": 0.960760235786438, "xcomet_qe_score": 0.9669955372810364, "metricx_score": 2.3178181648254395, "metricx_qe_score": 1.571115255355835, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Visionen- und Sprachmodellen auf Vokalen, nämlich mit Clip, AlexMert, Vilbert, Vilbert12in1 und VisualBERT.", "metrics": {"bleu_score": 22.08028914540057, "chrf_score": 60.684905643633016, "xcomet_score": 0.7049479484558105, "xcomet_qe_score": 0.7055069804191589, "metricx_score": 6.507266521453857, "metricx_qe_score": 6.635904788970947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren in Überschriften und Texten sowie die Qualität der erzeugten Übersetzungen.", "metrics": {"bleu_score": 34.29547961820059, "chrf_score": 67.05402914947616, "xcomet_score": 0.9275350570678711, "xcomet_qe_score": 0.9440352916717529, "metricx_score": 3.5591137409210205, "metricx_qe_score": 3.3514528274536133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht ist für dieses Video eher relevant, dass wir unsere primitivere Metrik zeigen werden, die Paarweise Genauigkeit, die misst, ob der Bild-Satz-Abgleichsgrad für das richtige Bildtextpaar größer ist als für sein fehlendes Paar.", "metrics": {"bleu_score": 19.439771859469815, "chrf_score": 57.43615926288792, "xcomet_score": 0.8471214771270752, "xcomet_qe_score": 0.8349214792251587, "metricx_score": 4.60263204574585, "metricx_qe_score": 1.9279942512512207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Für weitere Metriken und Ergebnisse darüber, schauen Sie in unserem Paper vorbei.", "metrics": {"bleu_score": 26.58483576665878, "chrf_score": 77.11357853887037, "xcomet_score": 0.9788621664047241, "xcomet_qe_score": 0.9646118879318237, "metricx_score": 1.3554803133010864, "metricx_qe_score": 2.9354255199432373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit pairwize-Genauigkeit sind hier dargestellt und sie entsprechen den Ergebnissen, die wir von anderen Metriken erhalten haben. Es ist so, dass das beste Null-Shot-Performances durch Vilbert erreicht wird, gefolgt von Vilbert-AlexMert-Clip und schließlich VisualBERT.", "metrics": {"bleu_score": 25.884667252188937, "chrf_score": 57.1138373286115, "xcomet_score": 0.5978845357894897, "xcomet_qe_score": 0.6232585310935974, "metricx_score": 9.95210075378418, "metricx_qe_score": 8.416820526123047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die auf individuelle Objekte wie das Vorhandensein und Nomenphrasen ausgerichtet sind, fast von Wilberts 'zehn in eins' gelöst werden, was zeigt, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren.", "metrics": {"bleu_score": 46.858912371495826, "chrf_score": 60.40807840142879, "xcomet_score": 0.810789167881012, "xcomet_qe_score": 0.879727840423584, "metricx_score": 5.944908142089844, "metricx_qe_score": 5.3308424949646, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "metrics": {"bleu_score": 2.719665272174911, "chrf_score": 15.597695686390006, "xcomet_score": 0.9719628095626831, "xcomet_qe_score": 0.9896148443222046, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Wir sehen anhand der Vielzahl von Zählinstrumenten, dass Visionssysteme und Sprachmodelle Schwierigkeiten haben, Referenzen zu einzelnen oder mehreren Objekten in einem Bild zu unterscheiden oder sie zu zählen.", "metrics": {"bleu_score": 29.9597896427608, "chrf_score": 65.33430976984303, "xcomet_score": 0.8751829266548157, "xcomet_qe_score": 0.8800210952758789, "metricx_score": 1.6492620706558228, "metricx_qe_score": 1.450149416923523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehungspunkte zeigen, dass sie Schwierigkeiten haben, einen benannten räumlichen Zusammenhang zwischen Objekten in einem Bild korrekt zu kategorisieren.", "metrics": {"bleu_score": 39.080227521872686, "chrf_score": 59.99369976121815, "xcomet_score": 0.9179028868675232, "xcomet_qe_score": 0.8960028290748596, "metricx_score": 1.1442457437515259, "metricx_qe_score": 1.2343149185180664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und die Teilnehmer zu identifizieren, selbst wenn sie durch plausibilitätsbeeinflussende Faktoren unterstützt werden, wie wir es in dem Abschnitt über Handlungen sehen.", "metrics": {"bleu_score": 57.045529828848274, "chrf_score": 81.40252646827687, "xcomet_score": 0.9651789665222168, "xcomet_qe_score": 0.9068925380706787, "metricx_score": 1.301019310951233, "metricx_qe_score": 1.89726722240448, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Von dem Co-Referenz-Piece finden wir heraus, dass es schwierig für Vision- und Sprachmodelle ist, mehrere Referenzen zu derselben Sache in einem Bild mithilfe von Pronomen zu verfolgen.", "metrics": {"bleu_score": 8.384179702790084, "chrf_score": 45.33614844082249, "xcomet_score": 0.8025888204574585, "xcomet_qe_score": 0.8063993453979492, "metricx_score": 5.975302696228027, "metricx_qe_score": 5.463883876800537, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Sanitätshüter und weil es ein interessantes Experiment ist, haben wir auch zwei textbasierte Modelle mithilfe von GPT-1 und GPT-2 bewertet, um zu prüfen, ob Wörter lösbar sind, indem wir die Perplexität der korrekten und fehlenden Übersetzungen berechnen und dann das Eingabewort mit der niedrigsten Perplexität vorausgesagt. Kein Bild hier!", "metrics": {"bleu_score": 25.283476582500043, "chrf_score": 51.250877431230876, "xcomet_score": 0.5679483413696289, "xcomet_qe_score": 0.5489681959152222, "metricx_score": 9.637316703796387, "metricx_qe_score": 8.74606704711914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Perplexität für das foil höher ist, nehmen wir dies als Indikation dafür, dass der gefaltete Caption möglicherweise von der Plausibilitätsbiase oder anderen sprachlichen Biases betroffen ist.", "metrics": {"bleu_score": 12.399375453827925, "chrf_score": 47.97205916533048, "xcomet_score": 0.6342620849609375, "xcomet_qe_score": 0.719507098197937, "metricx_score": 9.126144409179688, "metricx_qe_score": 7.505221843719482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Es ist interessant zu sehen, dass in einigen Fällen textbasierte GPMT-Modelle die Plausibilität der Welt besser als visuelle und Sprachmodell erfasst haben.", "metrics": {"bleu_score": 48.6038452578111, "chrf_score": 74.63118914429388, "xcomet_score": 0.9628541469573975, "xcomet_qe_score": 0.9534441232681274, "metricx_score": 2.3735647201538086, "metricx_qe_score": 1.5361671447753906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Also zusammenfassend: Vals ist ein Maßstab, der die Länge von linguistischen Konstrukten verwendet, um die Gemeinschaft zu helfen, die Vision und Sprachmodelle durch harte Überprüfung ihrer visuellen Grounding-Fähigkeiten zu verbessern.", "metrics": {"bleu_score": 10.365611305435394, "chrf_score": 49.75304371361289, "xcomet_score": 0.664339005947113, "xcomet_qe_score": 0.7205440998077393, "metricx_score": 9.295570373535156, "metricx_qe_score": 8.879119873046875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente haben gezeigt, dass Visionssysteme und Sprachmodelle benannte Objekte in Bildern gut identifizieren können, wie das Beispiel des 'Existenz' Abschnitts zeigt, aber Schwierigkeiten haben, ihre Abhängigkeit von den visuellen Indikatoren in Szenen zu begründen und ihre Beziehungen darzustellen, wenn sie dazu gezwungen sind, sich an ästhetische Indikatoren anzupassen.", "metrics": {"bleu_score": 14.28632684126682, "chrf_score": 64.62386754778396, "xcomet_score": 0.9111013412475586, "xcomet_qe_score": 0.9309316873550415, "metricx_score": 5.510361194610596, "metricx_qe_score": 5.616702556610107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir würden uns sehr freuen, wenn die Community Vals für die Messung von Fortschritten bei der Sprachgrundierung mit Visionen und Sprachmodellen verwenden würde.", "metrics": {"bleu_score": 9.429254736980939, "chrf_score": 47.96049578251227, "xcomet_score": 0.8354336619377136, "xcomet_qe_score": 0.8285625576972961, "metricx_score": 4.558675289154053, "metricx_qe_score": 4.998388290405273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und sogar mehr: Valves konnten als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach der Schulung oder Optimierung geprüft werden konnten, um zu sehen, ob ein Datensatz den Modellen hilft, sich auf irgendeine Weise zu verbessern, die durch Valves getestet wird.", "metrics": {"bleu_score": 30.437940244489106, "chrf_score": 54.42671812261975, "xcomet_score": 0.8059428930282593, "xcomet_qe_score": 0.8235713243484497, "metricx_score": 8.293135643005371, "metricx_qe_score": 7.8526153564453125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, sollten Sie das GitHub-Repository überprüfen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren.", "metrics": {"bleu_score": 39.96534939223408, "chrf_score": 56.190966247285836, "xcomet_score": 0.9798928499221802, "xcomet_qe_score": 0.979751467704773, "metricx_score": 1.6622531414031982, "metricx_qe_score": 2.34448504447937, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Mein Name ist Camisera und ich bin Student an der Universität Tokio.", "metrics": {"bleu_score": 20.333448190047886, "chrf_score": 60.431408092717284, "xcomet_score": 0.797722578048706, "xcomet_qe_score": 0.793337345123291, "metricx_score": 5.464282035827637, "metricx_qe_score": 5.413681507110596, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ist es wirklich schon so spät?", "metrics": {"bleu_score": 0.0, "chrf_score": 4.708568841032858, "xcomet_score": 0.1418979912996292, "xcomet_qe_score": 0.12641507387161255, "metricx_score": 21.615480422973633, "metricx_qe_score": 24.996082305908203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ist es wirklich schon so spät? \n\n(Note: \"Ist es wirklich schon so spät?\" is the correct translation of \"Is it really that late already?\" in German. The word \"spät\" means \"late\" in German.)", "metrics": {"bleu_score": 0.9798555761147508, "chrf_score": 13.68492174976083, "xcomet_score": 0.1593245267868042, "xcomet_qe_score": 0.15645667910575867, "metricx_score": 2.7888641357421875, "metricx_qe_score": 4.795392990112305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "\"Zunächst werde ich die automatische Registrierung einführen, an der wir in dieser Forschung arbeiten.\"", "metrics": {"bleu_score": 65.40585844910977, "chrf_score": 68.79674065481593, "xcomet_score": 0.8043555021286011, "xcomet_qe_score": 0.7962055206298828, "metricx_score": 6.34590482711792, "metricx_qe_score": 5.939449310302734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Release Note ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Version eines Software-Produkts verbreitet werden.", "metrics": {"bleu_score": 72.54330631437158, "chrf_score": 77.92034209306473, "xcomet_score": 0.950100302696228, "xcomet_qe_score": 0.9817095994949341, "metricx_score": 2.1199941635131836, "metricx_qe_score": 1.6730982065200806, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Ein Bild zeigt die Reihenfolge der Noten für den belgischen Zweig.", "metrics": {"bleu_score": 8.516593018819643, "chrf_score": 23.045924492664625, "xcomet_score": 0.1316719502210617, "xcomet_qe_score": 0.13337601721286774, "metricx_score": 22.039234161376953, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Die JRE-Sammlung spielt in der Entwicklung von Open-Source-Projekten eine wichtige Rolle, ist aber zeitintensiv bei der Erstellung von Manuskripten.", "metrics": {"bleu_score": 15.362208233245513, "chrf_score": 51.27953986306498, "xcomet_score": 0.7580974698066711, "xcomet_qe_score": 0.7456192374229431, "metricx_score": 13.50791072845459, "metricx_qe_score": 9.437984466552734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, automatisch hochwertige Notizen zu generieren.", "metrics": {"bleu_score": 30.06454569052614, "chrf_score": 54.717473477893975, "xcomet_score": 0.9382102489471436, "xcomet_qe_score": 0.9445886611938477, "metricx_score": 1.8184785842895508, "metricx_qe_score": 1.575670599937439, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mich auf zwei frühere Forschungen zu automatischer Erkennung von Dauer beziehen.", "metrics": {"bleu_score": 8.889175589171739, "chrf_score": 45.33737211087637, "xcomet_score": 0.8142961263656616, "xcomet_qe_score": 0.8299446105957031, "metricx_score": 6.699711799621582, "metricx_qe_score": 5.365661144256592, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens \"Algebra\", das im Jahr 2040 entwickelt wurde.", "metrics": {"bleu_score": 19.345299022826193, "chrf_score": 40.64916265248472, "xcomet_score": 0.4719240665435791, "xcomet_qe_score": 0.7168660163879395, "metricx_score": 16.271921157836914, "metricx_qe_score": 16.46434783935547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es nimmt einen regelbasierten Ansatz, zum Beispiel indem es den Änderungsextrakt verwendet, um Kernunterschiede, Änderungen an der Syntax und Dokumentänderungen zwischen Versionen zu extrahieren und schließlich diese zu kombinieren.", "metrics": {"bleu_score": 24.84833212997411, "chrf_score": 65.6597950898121, "xcomet_score": 0.9408077001571655, "xcomet_qe_score": 0.9319106340408325, "metricx_score": 1.7121336460113525, "metricx_qe_score": 1.901832103729248, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das auffälligste Merkmal dieses Systems ist der 'Issue-Extraktor' in der rechten oben.", "metrics": {"bleu_score": 23.566578558703185, "chrf_score": 56.45413938894417, "xcomet_score": 0.7963494062423706, "xcomet_qe_score": 0.8859683275222778, "metricx_score": 6.157951354980469, "metricx_qe_score": 5.791636943817139, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dies muss zu Jeroth dem Ausführer des Systems gehören und kann nur auf Projekte angewendet werden, die Jeroth verwenden.", "metrics": {"bleu_score": 44.980624668364484, "chrf_score": 58.69801444076317, "xcomet_score": 0.6989078521728516, "xcomet_qe_score": 0.685375452041626, "metricx_score": 14.402005195617676, "metricx_qe_score": 14.012035369873047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Andernfalls kann es für viele Projekte auf GitLab nicht verwendet werden.", "metrics": {"bleu_score": 25.42761993800977, "chrf_score": 61.43779709828602, "xcomet_score": 0.912047266960144, "xcomet_qe_score": 0.9172850251197815, "metricx_score": 4.152392864227295, "metricx_qe_score": 3.059225559234619, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite ist 'Graefe', die im Jahr 2000 angekündigt wurde.", "metrics": {"bleu_score": 16.59038701421971, "chrf_score": 48.955078615511994, "xcomet_score": 0.39766353368759155, "xcomet_qe_score": 0.6470213532447815, "metricx_score": 15.656082153320312, "metricx_qe_score": 13.239522933959961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "2020 ist ein Jahr auf der Internet-Plattform und kann als Podcast abonniert werden.", "metrics": {"bleu_score": 8.493098745313148, "chrf_score": 40.74513195493487, "xcomet_score": 0.164199560880661, "xcomet_qe_score": 0.17351940274238586, "metricx_score": 13.718761444091797, "metricx_qe_score": 15.167412757873535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System hat ein einfaches laufendes Textklassifizierungsmuster und gibt eine von fünf Rubriken aus, die Merkmale oder Fehlerbehebungen für jede Eingabe-Commsendung darstellen.", "metrics": {"bleu_score": 29.098631923997853, "chrf_score": 52.74391167967043, "xcomet_score": 0.8077523708343506, "xcomet_qe_score": 0.8236919641494751, "metricx_score": 5.6350626945495605, "metricx_qe_score": 5.174395561218262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Die Grafik ist ein Beispiel für eine Verwendung, die einen korrekten oder fehlerhaften Code darstellt.", "metrics": {"bleu_score": 6.019608768705656, "chrf_score": 29.208781069729866, "xcomet_score": 0.901141881942749, "xcomet_qe_score": 0.9216712117195129, "metricx_score": 2.2706003189086914, "metricx_qe_score": 2.3863375186920166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Graf's Trainingsdaten sind sehr klein, etwa fünf Zehntausend, und werden in den unten beschriebenen Experimenten gezeigt.", "metrics": {"bleu_score": 54.852921912798244, "chrf_score": 70.15876373929386, "xcomet_score": 0.7628805637359619, "xcomet_qe_score": 0.7623292207717896, "metricx_score": 6.143969535827637, "metricx_qe_score": 6.9434027671813965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Textklassifikationsmodells ist nicht hoch.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26596003770828247, "metricx_qe_score": 0.4735175371170044, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit begrenzter Anwendbarkeit und knapperen Datenressourcen.", "metrics": {"bleu_score": 7.042958208384708, "chrf_score": 60.02202022866481, "xcomet_score": 0.9686849117279053, "xcomet_qe_score": 0.9810351729393005, "metricx_score": 0.5822006464004517, "metricx_qe_score": 0.3525591492652893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Publikation löst diese beiden Probleme und generiert automatisch hochwertige Listen.", "metrics": {"bleu_score": 10.135943830402923, "chrf_score": 48.452457339128415, "xcomet_score": 0.8345392942428589, "xcomet_qe_score": 0.8352339267730713, "metricx_score": 5.25189208984375, "metricx_qe_score": 5.162578582763672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Mit einem begrenzten Rechenprogramm schlagen wir vor, einen hochwertigen Casio-Summiervorgang zu verwenden, der nur Eingaben über eine dedizierte Nachrichtenfunktion erhält.", "metrics": {"bleu_score": 5.856458233275369, "chrf_score": 39.39562851824802, "xcomet_score": 0.7208925485610962, "xcomet_qe_score": 0.6266454458236694, "metricx_score": 12.748651504516602, "metricx_qe_score": 12.717857360839844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Dieses vorgeschlagene Verfahren kann für alle Winkeln verwendet werden.", "metrics": {"bleu_score": 24.70315512339778, "chrf_score": 54.378304954406076, "xcomet_score": 0.7051064372062683, "xcomet_qe_score": 0.7794052958488464, "metricx_score": 7.439335346221924, "metricx_qe_score": 7.924623489379883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Zum zweiten Problem von mangelhaften Ressourcen bauen wir unsere Datenbank aus öffentlichen Git-Depot-Datenbanken auf, indem wir Daten durch die Verwendung der Git-API korrigieren.", "metrics": {"bleu_score": 1.8394069675790383, "chrf_score": 36.201297196955565, "xcomet_score": 0.7215279936790466, "xcomet_qe_score": 0.7085555791854858, "metricx_score": 11.742045402526855, "metricx_qe_score": 10.540173530578613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Nächst werde ich beschreiben, wie sie es gemacht haben.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 44.67774346627906, "xcomet_score": 0.8832037448883057, "xcomet_qe_score": 0.8726301193237305, "metricx_score": 4.165856838226318, "metricx_qe_score": 4.888720512390137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel für Daten.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 81.3052385800557, "xcomet_score": 0.9865502119064331, "xcomet_qe_score": 0.9950288534164429, "metricx_score": 0.11113797873258591, "metricx_qe_score": 0.3509396016597748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist eine Commit-Meldung und die rechte Seite ist ein Rezessnotizen.", "metrics": {"bleu_score": 11.325857976105244, "chrf_score": 40.60364868231474, "xcomet_score": 0.741254448890686, "xcomet_qe_score": 0.730241060256958, "metricx_score": 6.16143798828125, "metricx_qe_score": 6.41911506652832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Zahlen werden als Verbesserungen der Fähigkeiten usw. bezeichnet.", "metrics": {"bleu_score": 11.208466750961147, "chrf_score": 38.89215160281713, "xcomet_score": 0.8068752288818359, "xcomet_qe_score": 0.7904819250106812, "metricx_score": 9.061434745788574, "metricx_qe_score": 7.88250732421875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die den Eingang von Nachrichten als Eingabe und das Ausgabe der ausgewählten Notizen als Ergebnis hat.", "metrics": {"bleu_score": 29.81792160679168, "chrf_score": 52.299862399189024, "xcomet_score": 0.8329238891601562, "xcomet_qe_score": 0.847885251045227, "metricx_score": 5.755758285522461, "metricx_qe_score": 4.5653252601623535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassungsaufgabe betrachtet werden.", "metrics": {"bleu_score": 51.54486831107658, "chrf_score": 88.85357201061939, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.04171179234981537, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vorgegebene vier Räder mit Merkmalen, Verbesserungen, Reparaturen, Abdeckungen, Verkleidungen und Bremsenwechseln.", "metrics": {"bleu_score": 11.014703317346848, "chrf_score": 37.08592046479134, "xcomet_score": 0.611609935760498, "xcomet_qe_score": 0.5156623125076294, "metricx_score": 18.566001892089844, "metricx_qe_score": 17.513643264770508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Dies basierte auf vorherigen Recherchen und anderen Faktoren.", "metrics": {"bleu_score": 12.929367642051732, "chrf_score": 35.89551988793674, "xcomet_score": 0.980216383934021, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.536759376525879, "metricx_qe_score": 1.1042640209197998, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Noten auf der unteren rechten Seite sind extrahiert und nicht auf der linken unteren Seite zu finden.", "metrics": {"bleu_score": 2.6643211213888947, "chrf_score": 34.210700498027116, "xcomet_score": 0.825098991394043, "xcomet_qe_score": 0.8578758239746094, "metricx_score": 6.0877604484558105, "metricx_qe_score": 6.843575954437256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "那时候，有必要检测出在浴缸里设置的四个阀门。", "metrics": {"bleu_score": 0.0, "chrf_score": 0.0, "xcomet_score": 0.18277284502983093, "xcomet_qe_score": 0.48196184635162354, "metricx_score": 9.004366874694824, "metricx_qe_score": 6.386404991149902, "linguapy_score": [1, "CHINESE"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Vorbehalte sind nicht immer mit jeder Republik konsistent.", "metrics": {"bleu_score": 18.36028134946796, "chrf_score": 47.3752771062197, "xcomet_score": 0.6142736673355103, "xcomet_qe_score": 0.5867974758148193, "metricx_score": 10.242243766784668, "metricx_qe_score": 9.168700218200684, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel kann die Arbeitslosigkeit zu einer Zunahme von Armut und sozialer Ausgrenzung führen usw.", "metrics": {"bleu_score": 2.908317710573757, "chrf_score": 20.009551386249314, "xcomet_score": 0.13498851656913757, "xcomet_qe_score": 0.13273832201957703, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben für jede dieser phonologischen Variation eine Vokabelliste mit etwa 300 Studienworten vorbereitet.", "metrics": {"bleu_score": 15.310245441182436, "chrf_score": 49.28088340169457, "xcomet_score": 0.9194610118865967, "xcomet_qe_score": 0.9414676427841187, "metricx_score": 5.849889755249023, "metricx_qe_score": 6.835722923278809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die wahrnehmbaren Klänge in einem Text zu erkennen und den Text nachfolgender wahrnehmbarer Sätze zu korrigieren.", "metrics": {"bleu_score": 4.8438253172160035, "chrf_score": 22.82271030572411, "xcomet_score": 0.12896986305713654, "xcomet_qe_score": 0.13074345886707306, "metricx_score": 19.723291397094727, "metricx_qe_score": 8.312888145446777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Nächster ist eine Communi-Message.", "metrics": {"bleu_score": 10.400597689005304, "chrf_score": 37.740191920188146, "xcomet_score": 0.7117525339126587, "xcomet_qe_score": 0.7654343843460083, "metricx_score": 8.641929626464844, "metricx_qe_score": 8.053511619567871, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Commitment messages are not tied to each branch.", "metrics": {"bleu_score": 4.767707020457095, "chrf_score": 17.40479575516325, "xcomet_score": 0.8874815106391907, "xcomet_qe_score": 0.9835938215255737, "metricx_score": 9.838615417480469, "metricx_qe_score": 7.865765571594238, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Die in der Abbildung gezeigte Situation ist die folgende: Wenn der aktuelle Trend 2,5 bis 19 beträgt, benötigen wir eine Korrektur.", "metrics": {"bleu_score": 3.664448474169163, "chrf_score": 30.17045242221871, "xcomet_score": 0.6525166034698486, "xcomet_qe_score": 0.23149771988391876, "metricx_score": 6.571715354919434, "metricx_qe_score": 9.968999862670898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Vergleiche die vorherige Version (2.5 bis 18) und füge es hinzu. Das ist ein bisschen kompliziert und reicht nicht aus, um nur eine Liste von Reduzierungen zu erstellen. Vergleiche auch die vorherige und nachfolgende Version.", "metrics": {"bleu_score": 13.856514146716284, "chrf_score": 44.81908462971778, "xcomet_score": 0.43513190746307373, "xcomet_qe_score": 0.18151159584522247, "metricx_score": 18.92730140686035, "metricx_qe_score": 16.111291885375977, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine hygienische Matching-Regel entwickelt, um die vorherigen und nächsten Versionen zu erhalten.", "metrics": {"bleu_score": 15.917012694603715, "chrf_score": 50.43716087285121, "xcomet_score": 0.8030699491500854, "xcomet_qe_score": 0.7965928912162781, "metricx_score": 4.429798603057861, "metricx_qe_score": 3.9265403747558594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Sie sitzt auf der Nase.", "metrics": {"bleu_score": 8.116697886877475, "chrf_score": 12.758673445119593, "xcomet_score": 0.11894163489341736, "xcomet_qe_score": 0.09812584519386292, "metricx_score": 8.034384727478027, "metricx_qe_score": 11.855670928955078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt sieben thousand two hundred thirty乳房间.", "metrics": {"bleu_score": 4.278179264606695, "chrf_score": 16.950370662020084, "xcomet_score": 0.13536925613880157, "xcomet_qe_score": 0.14906708896160126, "metricx_score": 25.0, "metricx_qe_score": 25.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Die durchschnittliche Anzahl an Release-Notizen beträgt sechsunddreißig, was für eine Sammlung von Übungen recht hoch ist.", "metrics": {"bleu_score": 29.550432371218758, "chrf_score": 46.65356604877037, "xcomet_score": 0.7591210007667542, "xcomet_qe_score": 0.7524690628051758, "metricx_score": 6.001723289489746, "metricx_qe_score": 5.4856276512146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Die Anzahl der einzigartigen Symbole ist recht hoch: acht Millionen, acht Millionen und dreißigtausend. Das ist ...", "metrics": {"bleu_score": 7.645949399477267, "chrf_score": 44.17820322779234, "xcomet_score": 0.5535290837287903, "xcomet_qe_score": 0.7499507069587708, "metricx_score": 8.387312889099121, "metricx_qe_score": 7.055669784545898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "\"aufgrund der großen Anzahl einzigartiger Klassen und Methodennamen, die im Repository gefunden werden.\"", "metrics": {"bleu_score": 6.019608768705656, "chrf_score": 45.10430265394899, "xcomet_score": 0.9631189107894897, "xcomet_qe_score": 0.979438066482544, "metricx_score": 1.1874058246612549, "metricx_qe_score": 1.195300817489624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Das nächste ist die Erklärung des vorgeschlagenen Verfahrens.", "metrics": {"bleu_score": 5.669791110976001, "chrf_score": 38.218234752740244, "xcomet_score": 0.9687778353691101, "xcomet_qe_score": 0.9533248543739319, "metricx_score": 0.1734205186367035, "metricx_qe_score": 0.1699332743883133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Der klassische extraktrische und abstrakte Zusammenfassungsmodell besteht aus zwei Neuronenmodulen.", "metrics": {"bleu_score": 21.648693746244412, "chrf_score": 59.60137133426435, "xcomet_score": 0.8408591747283936, "xcomet_qe_score": 0.8438756465911865, "metricx_score": 4.002780437469482, "metricx_qe_score": 3.6250205039978027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "In English: \nA classifier using a bar or called a bar chart on the generator using bars.\n\nIn German:\nEin Klassifizierer, der mit einer Bar oder als Bar-Chart auf dem Generator unter Verwendung von Balken verwendet wird.", "metrics": {"bleu_score": 1.3058944351862714, "chrf_score": 36.47439971404884, "xcomet_score": 0.20428422093391418, "xcomet_qe_score": 0.21708662807941437, "metricx_score": 6.13090181350708, "metricx_qe_score": 7.1876115798950195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Erster: 'CAS nutzt eine Klassifizierung, um jeden Commit-Meldung in fünf Klassen zu unterteilen: Features, Verbesserungen, Bugfixes, Erweiterungen und Sonstiges.'", "metrics": {"bleu_score": 8.230975040504823, "chrf_score": 38.49649165874347, "xcomet_score": 0.6784387826919556, "xcomet_qe_score": 0.7165396809577942, "metricx_score": 5.672394275665283, "metricx_qe_score": 5.55160665512085, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die übermittelten Nachrichten werden als 'Sonstige' oder 'Gelöscht' kategorisiert.", "metrics": {"bleu_score": 5.934202609760488, "chrf_score": 42.07030774904009, "xcomet_score": 0.9633122682571411, "xcomet_qe_score": 0.9626961946487427, "metricx_score": 2.445913076400757, "metricx_qe_score": 2.253971815109253, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Siehe auch: Generieren Sie eine Ressourcen-Notiz für jede Klasse unabhängig voneinander und geben Sie diese an den Benutzer zurück.", "metrics": {"bleu_score": 9.846107951428584, "chrf_score": 38.77533365946211, "xcomet_score": 0.1528332531452179, "xcomet_qe_score": 0.15329208970069885, "metricx_score": 4.8358330726623535, "metricx_qe_score": 5.131079196929932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Aufgabe sind die direkten Korrespondenzen zwischen Commit-Mails und Lesern nicht bekannt.", "metrics": {"bleu_score": 62.98129992394241, "chrf_score": 72.79229739605906, "xcomet_score": 0.8372687101364136, "xcomet_qe_score": 0.7508244514465332, "metricx_score": 5.664928436279297, "metricx_qe_score": 6.244643211364746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Therefore, to train the class fire, class fire, we assign those roles to each input command message using the first ten characters of each command message.", "metrics": {"bleu_score": 1.4763939041893883, "chrf_score": 18.320936716430655, "xcomet_score": 0.3251461386680603, "xcomet_qe_score": 0.566287100315094, "metricx_score": 18.63264274597168, "metricx_qe_score": 16.407974243164062, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben die Klassifizierung der inkonsistenten Schätzungen durch zwei definierte Methoden modelliert.", "metrics": {"bleu_score": 16.90062198556585, "chrf_score": 43.72150557302287, "xcomet_score": 0.8129727840423584, "xcomet_qe_score": 0.769374668598175, "metricx_score": 4.679995059967041, "metricx_qe_score": 5.846715450286865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir 'CJ-Single' nennen, besteht aus einem einzelnen S2-S2-Netzwerk und generiert eine einzelne long-distance-RNA-Tagsatz. Es gibt eine Kombination von Eingangskommunikations-Messungen.", "metrics": {"bleu_score": 34.59894910015056, "chrf_score": 50.12148715186434, "xcomet_score": 0.2853175103664398, "xcomet_qe_score": 0.46475011110305786, "metricx_score": 17.630416870117188, "metricx_qe_score": 14.769308090209961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der externe Text kann in段落 aufgeteilt werden, die auf spezielle Klassifikationsmerkmale basieren.", "metrics": {"bleu_score": 3.2399023551226187, "chrf_score": 27.957943736796427, "xcomet_score": 0.7424553632736206, "xcomet_qe_score": 0.7833800911903381, "metricx_score": 5.09665584564209, "metricx_qe_score": 3.9173409938812256, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir als Shear-Methode bezeichnen, besteht aus vier verschiedenen Skalensegmenten-Netzwerken,每种对应于一个基类。", "metrics": {"bleu_score": 33.60073369884098, "chrf_score": 48.66530817176275, "xcomet_score": 0.6609982848167419, "xcomet_qe_score": 0.6420632600784302, "metricx_score": 8.313820838928223, "metricx_qe_score": 8.189488410949707, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, lass uns Spans experiment machen.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 28.333629100003506, "xcomet_score": 0.5140998959541321, "xcomet_qe_score": 0.8207798004150391, "metricx_score": 8.361186027526855, "metricx_qe_score": 6.650933265686035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen: Cheers, Singlet, Marche, Glittering und Previous Study Group.", "metrics": {"bleu_score": 22.634051112223126, "chrf_score": 48.688556997310414, "xcomet_score": 0.4836662709712982, "xcomet_qe_score": 0.4341283440589905, "metricx_score": 19.321313858032227, "metricx_qe_score": 18.82149887084961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "In einigen Fällen kann die Abweichung nicht als Ausdruck in Prozenten angegeben werden.", "metrics": {"bleu_score": 6.033104985460151, "chrf_score": 33.10011251152707, "xcomet_score": 0.1401994228363037, "xcomet_qe_score": 0.1436082422733307, "metricx_score": 14.191405296325684, "metricx_qe_score": 7.1525750160217285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze in einer bestimmten Textabschnitts zu bestimmen, werden diese mit Leerzeichen kombiniert und als eine lange Sache behandelt.", "metrics": {"bleu_score": 37.57154576765614, "chrf_score": 70.23812315485145, "xcomet_score": 0.9438831806182861, "xcomet_qe_score": 0.9482706785202026, "metricx_score": 4.420681476593018, "metricx_qe_score": 4.424529075622559, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Der Blue ist panaritidisch, wenn das System einen kurzen Satz ausgibt.", "metrics": {"bleu_score": 66.52049901111006, "chrf_score": 66.32916419060415, "xcomet_score": 0.7991724014282227, "xcomet_qe_score": 0.7433210611343384, "metricx_score": 8.647923469543457, "metricx_qe_score": 10.22295093536377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Wert ist der Vorhersage für die Effizienz und die Leistungsfähigkeit in den Ergebnissen der Experimente.", "metrics": {"bleu_score": 5.439330544349821, "chrf_score": 30.219263851986266, "xcomet_score": 0.1966586709022522, "xcomet_qe_score": 0.35123324394226074, "metricx_score": 12.605224609375, "metricx_qe_score": 14.410531044006348, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich müssen wir auch eine Spezifizität charakterisieren, weil Rot und Blau nicht gezeichnet werden können, wenn die Noten der Leese leer sind.", "metrics": {"bleu_score": 22.542577626536843, "chrf_score": 55.72693339651625, "xcomet_score": 0.7774859666824341, "xcomet_qe_score": 0.8079851865768433, "metricx_score": 9.388142585754395, "metricx_qe_score": 7.964380741119385, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifizität bedeutet, dass das Modell in Fällen, in denen die Regeln als leer angenommen werden, leere Strings ausgibt.", "metrics": {"bleu_score": 47.21348165832945, "chrf_score": 58.45046803503019, "xcomet_score": 0.9307997226715088, "xcomet_qe_score": 0.9926612377166748, "metricx_score": 4.525204181671143, "metricx_qe_score": 4.43683385848999, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse.", "metrics": {"bleu_score": 42.72870063962342, "chrf_score": 48.96283815298874, "xcomet_score": 0.9982582330703735, "xcomet_qe_score": 0.9951757192611694, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da das Dayset auch E-Mails enthält, etc., werden wir es auch im sauberen Dayset verarbeiten, indem wir diese ausschließen.", "metrics": {"bleu_score": 4.705244978975818, "chrf_score": 37.833401752667655, "xcomet_score": 0.7558080554008484, "xcomet_qe_score": 0.7568596601486206, "metricx_score": 12.067755699157715, "metricx_qe_score": 12.036360740661621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "CS und GS erzielten Rote Punkte, die mehr als zehn Punkte über den Basenlinien lagen.", "metrics": {"bleu_score": 46.36645919987621, "chrf_score": 56.94636302698808, "xcomet_score": 0.6355652213096619, "xcomet_qe_score": 0.6774717569351196, "metricx_score": 8.988540649414062, "metricx_qe_score": 11.300163269042969, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "insbesondere beim Koreanischen Testset war der Querschnittsbereich zwischen dem vorgeschlagenen Methoden und den Basissätzen größer als zwanzig Punkte.", "metrics": {"bleu_score": 10.142823159709938, "chrf_score": 58.13959422972711, "xcomet_score": 0.6475881338119507, "xcomet_qe_score": 0.6114785671234131, "metricx_score": 11.899947166442871, "metricx_qe_score": 12.391741752624512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse deuten darauf hin, dass Schmerzen und Schmerzen erheblich beeinflusst werden.", "metrics": {"bleu_score": 8.889175589171739, "chrf_score": 35.03640221835471, "xcomet_score": 0.48707932233810425, "xcomet_qe_score": 0.7323106527328491, "metricx_score": 10.465631484985352, "metricx_qe_score": 11.725071907043457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "CS hat bessere鲁棒性指标 als GS, was darauf hindeutet, dass die Kombination eines Klassifizierers und eines Generators bei der Schulung von Klassifizierern mit Supervision effektiv ist.", "metrics": {"bleu_score": 38.694317759010325, "chrf_score": 58.88388692196983, "xcomet_score": 0.3226628005504608, "xcomet_qe_score": 0.43006858229637146, "metricx_score": 10.949176788330078, "metricx_qe_score": 11.419105529785156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Überdeckung von C-S ist in der Regel richtig, da der Klassifizierer sich auf die Verarbeitung relevanten Commit-Messages für jede Klasse konzentrieren kann.", "metrics": {"bleu_score": 22.599865452149242, "chrf_score": 50.384055711053975, "xcomet_score": 0.7173159122467041, "xcomet_qe_score": 0.734569251537323, "metricx_score": 7.720958709716797, "metricx_qe_score": 7.774465560913086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie ist viel eher geneigt, in höheren Lagen zu leben als wenn sie allein wäre.", "metrics": {"bleu_score": 2.719665272174911, "chrf_score": 17.51029177145783, "xcomet_score": 0.12911024689674377, "xcomet_qe_score": 0.12253706157207489, "metricx_score": 25.0, "metricx_qe_score": 19.934720993041992, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Es wird vorgeschlagen, dass es auch effektiv ist, unabhängig voneinander entwickelte unterschiedliche präzise Zusammenfassungsmodelle für jede Klasse von Notizen zu erstellen.", "metrics": {"bleu_score": 33.08274705943025, "chrf_score": 68.64657629181939, "xcomet_score": 0.903179407119751, "xcomet_qe_score": 0.888498067855835, "metricx_score": 3.122138261795044, "metricx_qe_score": 3.0348641872406006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hieron und Aeneas.", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 13.3035803689658, "xcomet_score": 0.11387097835540771, "xcomet_qe_score": 0.07624556869268417, "metricx_score": 13.463113784790039, "metricx_qe_score": 23.928668975830078, "linguapy_score": [1, "SPANISH"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Sehr häufig sind die Methoden der Shesha tendenziell kürzer als menschliche Referenzsentenzen.", "metrics": {"bleu_score": 7.347053125977879, "chrf_score": 62.485956773856344, "xcomet_score": 0.7426447868347168, "xcomet_qe_score": 0.7403892278671265, "metricx_score": 11.188692092895508, "metricx_qe_score": 12.13302230834961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In dem Video auf der rechten Seite hat die referentielle Sätze drei oder vier Satzzeilen, während Shears nur einen hat.", "metrics": {"bleu_score": 9.364337313929381, "chrf_score": 44.03955087540904, "xcomet_score": 0.6339468359947205, "xcomet_qe_score": 0.5838937759399414, "metricx_score": 9.6472806930542, "metricx_qe_score": 9.534760475158691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Die Gründe für diesen geringeren Widerstand sind, dass in den Trainingsdaten nur etwa dreißig Prozent der Sätze enthalten sind, die im Features-Label und vierzig Prozent im Improvements-Label vorliegen.", "metrics": {"bleu_score": 20.03509454750005, "chrf_score": 42.99562361235581, "xcomet_score": 0.7455077171325684, "xcomet_qe_score": 0.8746953010559082, "metricx_score": 6.744846343994141, "metricx_qe_score": 5.751010894775391, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können C#-Methoden ohne zusätzliche Informationen keine genauen Venn-Zahlen generieren.", "metrics": {"bleu_score": 36.6192636299943, "chrf_score": 74.20740525604275, "xcomet_score": 0.7312994003295898, "xcomet_qe_score": 0.6984380483627319, "metricx_score": 11.518705368041992, "metricx_qe_score": 7.097017288208008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für einen sehr mächtigen Commit-Mails, dessen Zusammenfassung ohne Berücksichtigung des entsprechenden Perlgastes oder Themas nicht generiert werden kann.", "metrics": {"bleu_score": 27.144278093478135, "chrf_score": 51.27362001245581, "xcomet_score": 0.6964885592460632, "xcomet_qe_score": 0.6857497096061707, "metricx_score": 10.794650077819824, "metricx_qe_score": 9.643295288085938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Die folgende Beispiel zeigt, dass die beiden commit-Meldungen in dem Eingabeisatz miteinander verknüpft sind und zusammen in einer Sätze就应该这样做。", "metrics": {"bleu_score": 22.998067193883283, "chrf_score": 44.894187946707724, "xcomet_score": 0.6811476945877075, "xcomet_qe_score": 0.7349527478218079, "metricx_score": 11.910469055175781, "metricx_qe_score": 11.069188117980957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Abschließend:", "metrics": {"bleu_score": 0.0, "chrf_score": 3.4831922153418424, "xcomet_score": 0.9829944372177124, "xcomet_qe_score": 1.0, "metricx_score": 0.6943221688270569, "metricx_qe_score": 0.26415568590164185, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine neue Datenbank für die automatisierte Verarbeitung von Daten erstellt.", "metrics": {"bleu_score": 11.121234698968381, "chrf_score": 54.03766431962723, "xcomet_score": 0.9785417318344116, "xcomet_qe_score": 0.9798856973648071, "metricx_score": 2.252448320388794, "metricx_qe_score": 2.621009349822998, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe des Einlegens von Commit-Meldungen und der Zusammenfassung davon, so dass sie für alle in Englisch geschriebenen Projekte anwendbar sind, wurde auch definiert.", "metrics": {"bleu_score": 8.248720006399612, "chrf_score": 59.10197023279628, "xcomet_score": 0.9340416193008423, "xcomet_qe_score": 0.9365856647491455, "metricx_score": 1.892585039138794, "metricx_qe_score": 1.8535737991333008, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente haben gezeigt, dass das vorgeschlagene Verfahren bei gleicher oder sogar höherer Abdeckung leiser ist als die Basislinien.", "metrics": {"bleu_score": 6.7602298845717375, "chrf_score": 48.23121220415216, "xcomet_score": 0.7977436780929565, "xcomet_qe_score": 0.8994430303573608, "metricx_score": 2.2208824157714844, "metricx_qe_score": 2.6823534965515137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte überprüfen Sie Ihre Wörter oder Fragen auf dem Tisch.", "metrics": {"bleu_score": 5.300156689756295, "chrf_score": 20.69606167118838, "xcomet_score": 0.11535875499248505, "xcomet_qe_score": 0.10844006389379501, "metricx_score": 10.175743103027344, "metricx_qe_score": 16.648569107055664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank!", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.017602328211069107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo! Mein Name ist Afarai.", "metrics": {"bleu_score": 55.780028607687655, "chrf_score": 68.8213104600177, "xcomet_score": 0.7485524415969849, "xcomet_qe_score": 0.7178557515144348, "metricx_score": 5.166316986083984, "metricx_qe_score": 5.5890936851501465, "linguapy_score": [1, "YORUBA"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Paper werden wir die Verwendung von Unit-Transformern für Tabellen-Daten-Enrichment vorstellen.", "metrics": {"bleu_score": 3.4857116957065437, "chrf_score": 38.05395562221251, "xcomet_score": 0.7790654897689819, "xcomet_qe_score": 0.7742601633071899, "metricx_score": 6.266903877258301, "metricx_qe_score": 7.956427574157715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Wissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der vorhandenen Features der Daten.", "metrics": {"bleu_score": 62.628449627654696, "chrf_score": 77.56573645896576, "xcomet_score": 0.9768591523170471, "xcomet_qe_score": 0.9810123443603516, "metricx_score": 2.2033839225769043, "metricx_qe_score": 2.416278123855591, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind diese Funktionen eingeschränkt.", "metrics": {"bleu_score": 64.34588841607616, "chrf_score": 77.23728006526383, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09981583058834076, "metricx_qe_score": 0.053570352494716644, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Generierung von Merkmalen mit Hilfe eines anderen Datenquells oder der Erweiterung von Substanzinformationen.", "metrics": {"bleu_score": 6.754312828675707, "chrf_score": 45.83851439711997, "xcomet_score": 0.8292850255966187, "xcomet_qe_score": 0.8913841843605042, "metricx_score": 8.707648277282715, "metricx_qe_score": 7.331152439117432, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsauftrag besteht darin, automatisches Tabellen- oder Datenverdopplern mit Hilfe von externen Quellen wie Freitexten zu erreichen.", "metrics": {"bleu_score": 5.0912128230977505, "chrf_score": 52.53609437879027, "xcomet_score": 0.8862849473953247, "xcomet_qe_score": 0.9205598831176758, "metricx_score": 6.2847394943237305, "metricx_qe_score": 6.041673183441162, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, wir haben eine tabellarische Datenbank und eine Wissensbasis.", "metrics": {"bleu_score": 46.92470064105599, "chrf_score": 79.83594772140128, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.47677648067474365, "metricx_qe_score": 0.5233802795410156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der inkrementales Linking und Textanalyse umfasst, um neue Merkmale aus der Wissensbasis freier Texte zu extrahieren.", "metrics": {"bleu_score": 36.59626379517192, "chrf_score": 68.20341531600658, "xcomet_score": 0.8432716131210327, "xcomet_qe_score": 0.8513703346252441, "metricx_score": 3.924901008605957, "metricx_qe_score": 3.37363600730896, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Leitfaden basiert genau auf diesem automatischen Prozess.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 50.966186343518885, "xcomet_score": 0.8697946071624756, "xcomet_qe_score": 0.8400173187255859, "metricx_score": 4.825867176055908, "metricx_qe_score": 4.215919494628906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Also seien wir bei einem Beispiel: In anderen Datensätzen werden sie in 'fast' geführt.", "metrics": {"bleu_score": 3.435448519978226, "chrf_score": 32.43157214604581, "xcomet_score": 0.752589225769043, "xcomet_qe_score": 0.6670880317687988, "metricx_score": 10.5784273147583, "metricx_qe_score": 11.95328426361084, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist das Datenset 'University Data Set'.", "metrics": {"bleu_score": 27.77619034011791, "chrf_score": 55.97802456340071, "xcomet_score": 0.9787430763244629, "xcomet_qe_score": 0.9725316762924194, "metricx_score": 1.9669866561889648, "metricx_qe_score": 1.3606946468353271, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Seine Zielsetzung ist die Einstufung von Universitäten in niedrig排名-Universitäten und Hochschulen mit hohem Rang.", "metrics": {"bleu_score": 6.917184228205472, "chrf_score": 41.46095126403704, "xcomet_score": 0.8629721403121948, "xcomet_qe_score": 0.8562066555023193, "metricx_score": 2.4866251945495605, "metricx_qe_score": 3.119370222091675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden Wikipedia als Wissensbasis.", "metrics": {"bleu_score": 11.478744233307168, "chrf_score": 72.26529360720536, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase der ersten Stufe ist die Entitätslinkung.", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 43.39246788645592, "xcomet_score": 0.8619328737258911, "xcomet_qe_score": 0.8526014089584351, "metricx_score": 1.7735264301300049, "metricx_qe_score": 2.8662827014923096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Name der Universität mit einer Entität in der Wissensbasis verknüpft.", "metrics": {"bleu_score": 32.65420870993383, "chrf_score": 73.17762466828353, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3903811573982239, "metricx_qe_score": 0.6287959218025208, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Die Texte der Entitäten in der Wissensbasis werden extrahiert und zu dem Datensatz hinzugefügt.", "metrics": {"bleu_score": 24.601372576927535, "chrf_score": 76.19079170583213, "xcomet_score": 0.998923659324646, "xcomet_qe_score": 0.9893550276756287, "metricx_score": 0.48811018466949463, "metricx_qe_score": 0.667072057723999, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text die Wikipedia-Seite 'Abstrakt'.", "metrics": {"bleu_score": 50.26587270045526, "chrf_score": 76.65065248306266, "xcomet_score": 0.9442503452301025, "xcomet_qe_score": 0.9556202292442322, "metricx_score": 2.990142822265625, "metricx_qe_score": 3.716890573501587, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Fall müssen wir Features aus dem empfangenen Text generieren oder extrahieren.", "metrics": {"bleu_score": 34.078064670813475, "chrf_score": 65.2860795545983, "xcomet_score": 0.9576200246810913, "xcomet_qe_score": 0.9547597169876099, "metricx_score": 2.3235464096069336, "metricx_qe_score": 1.6888097524642944, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen eine FeatureExtraktionPhase, die Textanalyse umfasst.", "metrics": {"bleu_score": 6.443030905386945, "chrf_score": 38.02578878452472, "xcomet_score": 0.9271609783172607, "xcomet_qe_score": 0.9363003373146057, "metricx_score": 5.17104959487915, "metricx_qe_score": 4.837745666503906, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist die Hauptsache dieses Papers, und ich werde in den nächsten Folien tiefer in sie eintauchen.", "metrics": {"bleu_score": 15.593439508212386, "chrf_score": 47.89089145299534, "xcomet_score": 0.8340330719947815, "xcomet_qe_score": 0.8338165879249573, "metricx_score": 3.3487260341644287, "metricx_qe_score": 4.861319541931152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Feature-Extraktionsphase gibt es eine Phase der Feature-Generierung, in der wir die extrahierten Features verwenden, um eine kleine Anzahl von neuen Funktionen zu generieren.", "metrics": {"bleu_score": 41.882168504198276, "chrf_score": 65.46622339225185, "xcomet_score": 0.9700385928153992, "xcomet_qe_score": 0.9943153858184814, "metricx_score": 1.528598666191101, "metricx_qe_score": 0.7013871669769287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Erstelle in der Anzahl der Klassen des ursprünglichen Datensatzes 'features'.", "metrics": {"bleu_score": 58.27355625822051, "chrf_score": 62.48341104825757, "xcomet_score": 0.8811919689178467, "xcomet_qe_score": 0.8920023441314697, "metricx_score": 6.415713310241699, "metricx_qe_score": 6.370181083679199, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat das ursprüngliche Datenset zwei Klassen.", "metrics": {"bleu_score": 39.281465090051285, "chrf_score": 82.58909585193098, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.05607153847813606, "metricx_qe_score": 0.24292829632759094, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also erstelle zwei neue Funktionen.", "metrics": {"bleu_score": 43.01250851313264, "chrf_score": 55.07139279209594, "xcomet_score": 0.8638017177581787, "xcomet_qe_score": 0.8735310435295105, "metricx_score": 4.05942964553833, "metricx_qe_score": 3.7860779762268066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn das Datenset fünf Klassen hat, erstelle五 neue Merkmale.", "metrics": {"bleu_score": 20.544097977075833, "chrf_score": 35.07974995070045, "xcomet_score": 0.842121958732605, "xcomet_qe_score": 0.8635667562484741, "metricx_score": 5.025208950042725, "metricx_qe_score": 5.059014797210693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Eigenschaft repräsentiert die Wahrscheinlichkeit für jede Klasse.", "metrics": {"bleu_score": 43.44371253135793, "chrf_score": 65.6097909447073, "xcomet_score": 0.9979524612426758, "xcomet_qe_score": 1.0, "metricx_score": 0.8377842903137207, "metricx_qe_score": 0.7834119200706482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Art des Textanalyse, die aus transformierenden Sprachmodellen wie BERT, GPT, XNOR und anderen sind.", "metrics": {"bleu_score": 44.76006614955163, "chrf_score": 71.91292866381468, "xcomet_score": 0.7792288064956665, "xcomet_qe_score": 0.7893193960189819, "metricx_score": 6.313443183898926, "metricx_qe_score": 6.000336647033691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir einen Sprachmodell trainieren können, indem wir die Eingabedaten verwenden.", "metrics": {"bleu_score": 18.71015823041062, "chrf_score": 60.531672265695576, "xcomet_score": 0.971057653427124, "xcomet_qe_score": 0.9672108292579651, "metricx_score": 1.2897204160690308, "metricx_qe_score": 1.3100472688674927, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wäre das Zielgeräte-Feinjustieren.", "metrics": {"bleu_score": 17.112717058426785, "chrf_score": 36.77436480129789, "xcomet_score": 0.9517484307289124, "xcomet_qe_score": 0.9583708047866821, "metricx_score": 4.737302780151367, "metricx_qe_score": 4.059483528137207, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der künftigen Extraktionsphase können wir ein personalisiertes Sprachmodell herunterladen und die Sprachmodelle über das Zielsetzwerk fine-tunen.", "metrics": {"bleu_score": 8.189273015718468, "chrf_score": 52.74519564706086, "xcomet_score": 0.7754911184310913, "xcomet_qe_score": 0.7720096111297607, "metricx_score": 6.506602764129639, "metricx_qe_score": 5.669766902923584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel soll der Sprachmodell angepasst werden, um Texte in Klassen zu klassifizieren - abstrakt oder konkreter.", "metrics": {"bleu_score": 6.618730066429364, "chrf_score": 42.61160976207643, "xcomet_score": 0.8383193016052246, "xcomet_qe_score": 0.8291521668434143, "metricx_score": 4.638331413269043, "metricx_qe_score": 5.2354350090026855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "GermanTranslation: \n\"Erhalten Sie den Ausdruck des Sprachmodells, der die Wahrscheinlichkeit für jede Klasse darstellt, und verwenden Sie ihn als neue Merkmale.\"", "metrics": {"bleu_score": 37.030468338190616, "chrf_score": 70.7323262839889, "xcomet_score": 0.8498349189758301, "xcomet_qe_score": 0.8430224061012268, "metricx_score": 4.0801005363464355, "metricx_qe_score": 3.2663207054138184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Die Problematik mit diesem Ansatz ist, dass Datensätze möglicherweise nur wenige distincte Individuen haben.", "metrics": {"bleu_score": 46.47585110517453, "chrf_score": 60.07678470083615, "xcomet_score": 0.8882172107696533, "xcomet_qe_score": 0.8950077295303345, "metricx_score": 4.144904136657715, "metricx_qe_score": 3.0342321395874023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthalten fast die Hälfte der Datensätze weniger als 400 Samples und das kleinste Datenset enthält sogar 35 Samples in seinem Trainingsset.", "metrics": {"bleu_score": 36.443025672882484, "chrf_score": 67.46135667841718, "xcomet_score": 0.9699716567993164, "xcomet_qe_score": 0.9652712345123291, "metricx_score": 3.7977848052978516, "metricx_qe_score": 2.479360580444336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "So wird die Feinabstimmung eines Sprachmodells über ein Datensatz ineffektiv sein.", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 68.67432574544033, "xcomet_score": 0.9524185657501221, "xcomet_qe_score": 0.94910728931427, "metricx_score": 2.0610456466674805, "metricx_qe_score": 1.6949095726013184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können vorheriges Wissen über vorge分析daten verwenden.", "metrics": {"bleu_score": 16.14682615668325, "chrf_score": 41.50600813145228, "xcomet_score": 0.8591846227645874, "xcomet_qe_score": 0.8494654893875122, "metricx_score": 0.9470294713973999, "metricx_qe_score": 0.9472883939743042, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Weil 'fast' über mehrere Datensätze angewendet wird, können wir die n - 1-Datensätze verwenden, um Informationen über die n - 1-Daten sets zu sammeln und diese Informationen bei der Analyse des n. Datensatzes zu verwenden.", "metrics": {"bleu_score": 21.54680201305972, "chrf_score": 62.761377213894264, "xcomet_score": 0.6683690547943115, "xcomet_qe_score": 0.6822378635406494, "metricx_score": 4.9044694900512695, "metricx_qe_score": 5.028637886047363, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen ist, eine weitere Fine-Tuning-Phase hinzuzufügen.", "metrics": {"bleu_score": 19.64073254502565, "chrf_score": 61.70156108662138, "xcomet_score": 0.9521775245666504, "xcomet_qe_score": 0.9478136301040649, "metricx_score": 4.336655616760254, "metricx_qe_score": 4.11184549331665, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Ein vorläufiges multitasking-Feinjustierungsphase.", "metrics": {"bleu_score": 9.688464563433238, "chrf_score": 52.23838134807758, "xcomet_score": 0.9283682107925415, "xcomet_qe_score": 0.931735098361969, "metricx_score": 3.721567153930664, "metricx_qe_score": 4.774586200714111, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie im Sprachmodell über N-Means-Daten sets arbeiten.", "metrics": {"bleu_score": 4.540013809283726, "chrf_score": 32.47420672147881, "xcomet_score": 0.8369287252426147, "xcomet_qe_score": 0.8541344404220581, "metricx_score": 7.756405353546143, "metricx_qe_score": 7.681118011474609, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Und dann führen wir eine weitere Fine-Tuning-Phase durch, bei der das Zielmodell über das 25. Zieldatenset fine-tuned wird.", "metrics": {"bleu_score": 12.367773313159153, "chrf_score": 40.242485749850665, "xcomet_score": 0.8358168601989746, "xcomet_qe_score": 0.8573293685913086, "metricx_score": 9.13153076171875, "metricx_qe_score": 7.873310565948486, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der Staat der Kunst in Multitasking, multitasking, feinjustierte called Empty DNA.", "metrics": {"bleu_score": 2.8398387225677895, "chrf_score": 27.258288528381907, "xcomet_score": 0.40631598234176636, "xcomet_qe_score": 0.5772444009780884, "metricx_score": 18.571067810058594, "metricx_qe_score": 19.228988647460938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In einem leeren DNA-Molekül bleibt die Anzahl der Aufgaben im Trainingsset unverändert.", "metrics": {"bleu_score": 12.097786402359946, "chrf_score": 43.012129066011966, "xcomet_score": 0.4135657250881195, "xcomet_qe_score": 0.4788951873779297, "metricx_score": 10.452033996582031, "metricx_qe_score": 6.815573692321777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es in der Trainingsmenge vier Aufgaben. Also leerer DNA und vier Heads, wie Sie auf dem Bild sehen können.", "metrics": {"bleu_score": 47.79289657345159, "chrf_score": 59.03869571626393, "xcomet_score": 0.6952713131904602, "xcomet_qe_score": 0.6954782009124756, "metricx_score": 9.164100646972656, "metricx_qe_score": 9.927292823791504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Es sampelt eine zufällige Version aus der Ausbildungsmenge.", "metrics": {"bleu_score": 6.033504141761816, "chrf_score": 20.188737762711188, "xcomet_score": 0.6792415380477905, "xcomet_qe_score": 0.694008469581604, "metricx_score": 6.099394798278809, "metricx_qe_score": 5.765372276306152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Einzelbatch einem bestimmten Beispiel wie z.B. der Singel-Selbstklassifizierungsaufgabe entspricht, wird er vorwärts und rückwärts durchlaufen lassen, um den ersten Head zu erreichen.", "metrics": {"bleu_score": 1.943043650185126, "chrf_score": 37.63025540316286, "xcomet_score": 0.6259641647338867, "xcomet_qe_score": 0.7206129431724548, "metricx_score": 10.82717227935791, "metricx_qe_score": 9.009847640991211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der zufällige Batch zu einer Paarweiser Rangfolge gehört, ändert sich seine Attitüde auf einen vorwärtsgerichteten und rückwärts gerichteten Weg durch das letzte Element.", "metrics": {"bleu_score": 3.802351022611669, "chrf_score": 33.21524138234125, "xcomet_score": 0.7834288477897644, "xcomet_qe_score": 0.8509865999221802, "metricx_score": 6.576869964599609, "metricx_qe_score": 5.642220973968506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario sind Tabellen-Datenbanken umfangreicher als die Anzahl der Klassen.", "metrics": {"bleu_score": 30.66148710292676, "chrf_score": 55.536982350615496, "xcomet_score": 0.8420360088348389, "xcomet_qe_score": 0.8348429203033447, "metricx_score": 7.846207618713379, "metricx_qe_score": 8.605792045593262, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Also gibt es viele Aufgaben.", "metrics": {"bleu_score": 32.46679154750991, "chrf_score": 65.43677210153183, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.11517974734306335, "metricx_qe_score": 0.4500460624694824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Vereinzelte DNS-Verbindungen haben eine begrenzte Anzahl von Klassen, Höhen und Ausgabel层.", "metrics": {"bleu_score": 22.242469397936766, "chrf_score": 41.689075179379046, "xcomet_score": 0.28743642568588257, "xcomet_qe_score": 0.3950783312320709, "metricx_score": 12.08244800567627, "metricx_qe_score": 10.551565170288086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Die Erweiterung erfordert es, zunächst eine neue Tabelle mit neuen Aufgaben für das neue Datenset zu erstellen.", "metrics": {"bleu_score": 3.0272532566104675, "chrf_score": 34.05276964636869, "xcomet_score": 0.833358883857727, "xcomet_qe_score": 0.9223800897598267, "metricx_score": 2.8074374198913574, "metricx_qe_score": 3.932220220565796, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der Task Reformulation Fine Tuning genannt wird, besteht darin, dass wir bei unserem Ansatz anstatt mehrere Headsets zu halten, jedes Datenset in ein Satz pro Klassifikationsproblem reformulieren. Das sind zwei Klassen Aufgaben.", "metrics": {"bleu_score": 18.244169087429608, "chrf_score": 58.18601914656624, "xcomet_score": 0.6783286333084106, "xcomet_qe_score": 0.7631898522377014, "metricx_score": 11.364899635314941, "metricx_qe_score": 8.886348724365234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Also lasst uns ein Beispiel sehen.", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 50.865040830607136, "xcomet_score": 0.9612133502960205, "xcomet_qe_score": 0.9620589017868042, "metricx_score": 1.1651170253753662, "metricx_qe_score": 0.6413676142692566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Unser Input-Daten set besteht aus Entitäten mit Merkmalen, Texten und Klassen.", "metrics": {"bleu_score": 7.387561680614721, "chrf_score": 43.28879372817039, "xcomet_score": 0.9539144039154053, "xcomet_qe_score": 0.9699251651763916, "metricx_score": 3.2824435234069824, "metricx_qe_score": 1.9627773761749268, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Die Aufgabe besteht darin, den Text in low und high zu kategorisieren, um die Abstrakte und Klasse in true oder false zu unterteilen.", "metrics": {"bleu_score": 3.793569371738633, "chrf_score": 28.955372643376432, "xcomet_score": 0.6745852828025818, "xcomet_qe_score": 0.8423641324043274, "metricx_score": 7.281620025634766, "metricx_qe_score": 5.724652290344238, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten trainieren wir das Sprachmodell, um eine abstrakte Klasse zu kategorisieren. Wenn ein Abstraktum zur Klasse gehört oder nicht.", "metrics": {"bleu_score": 16.863758031987462, "chrf_score": 48.14973579225672, "xcomet_score": 0.648848295211792, "xcomet_qe_score": 0.5125183463096619, "metricx_score": 6.360922336578369, "metricx_qe_score": 7.6161112785339355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Also bleibt der Labelvektor im Fall von Zik in immer dieselben zwei Klassen.", "metrics": {"bleu_score": 6.734395444347337, "chrf_score": 37.636141243441685, "xcomet_score": 0.7933638095855713, "xcomet_qe_score": 0.7908064126968384, "metricx_score": 6.12220573425293, "metricx_qe_score": 6.384109020233154, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Dies ist der Algorithmus für unseren finiten, formulierten Fine-Tuning-Ansatz.", "metrics": {"bleu_score": 38.16330911371339, "chrf_score": 67.13082085336055, "xcomet_score": 0.8049004077911377, "xcomet_qe_score": 0.8359070420265198, "metricx_score": 5.844176769256592, "metricx_qe_score": 5.499940395355225, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Also sehen wir uns das volle Framework an.", "metrics": {"bleu_score": 13.485111859503691, "chrf_score": 26.52075236917217, "xcomet_score": 0.9591060280799866, "xcomet_qe_score": 0.9528416395187378, "metricx_score": 1.2721545696258545, "metricx_qe_score": 0.46308597922325134, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Ein Datensatz wird sehr schnell in die erste Ebene geschrieben.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 39.6123791870988, "xcomet_score": 0.4802052080631256, "xcomet_qe_score": 0.6516702175140381, "metricx_score": 6.358927249908447, "metricx_qe_score": 6.398318290710449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann kommt die schnell ausgeführte Entitätslinkungsfase.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 27.847580428527703, "xcomet_score": 0.9229867458343506, "xcomet_qe_score": 0.9247422814369202, "metricx_score": 4.300343990325928, "metricx_qe_score": 5.5594987869262695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Wikipedia-Seite abstrahieren.", "metrics": {"bleu_score": 0.0, "chrf_score": 25.603758206601817, "xcomet_score": 0.1734791249036789, "xcomet_qe_score": 0.14475670456886292, "metricx_score": 7.5580291748046875, "metricx_qe_score": 6.409511566162109, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann formulieren sie die Aufgabe in eine SQL-Sentence mit der Klassifizierungsaufgabe.", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 53.116602335802774, "xcomet_score": 0.8363709449768066, "xcomet_qe_score": 0.8438776731491089, "metricx_score": 7.63576078414917, "metricx_qe_score": 6.458578109741211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Angewendetes Sprachmodell auf die neue Aufgabe und Ausgabe der Wahrscheinlichkeit für jede Klasse.", "metrics": {"bleu_score": 35.00482776497398, "chrf_score": 72.46249814056014, "xcomet_score": 0.9409430623054504, "xcomet_qe_score": 0.9380485415458679, "metricx_score": 3.896580934524536, "metricx_qe_score": 3.5975706577301025, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Ein Hinweis darauf, dass das Sprachmodell bereits über N - 1 Datensätze mit einem vorläufigen multitasking fine-tuning optimiert wurde.", "metrics": {"bleu_score": 12.58220555845937, "chrf_score": 47.741953233151946, "xcomet_score": 0.8202716708183289, "xcomet_qe_score": 0.8239288330078125, "metricx_score": 5.5464277267456055, "metricx_qe_score": 5.051644802093506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgangssensor des Sprachmodells als eine neu generierte Eigenschaft in der Anzahl der Klassen.", "metrics": {"bleu_score": 66.7278568794606, "chrf_score": 79.88934158122022, "xcomet_score": 0.845320463180542, "xcomet_qe_score": 0.8376901149749756, "metricx_score": 5.579433441162109, "metricx_qe_score": 5.9667510986328125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Framework zu evaluieren, verwenden wir eine 17-Tabellen-Klassifikationssatz, der Größe variiert und Features wie Balance, Domäne und Initialleistung enthält.", "metrics": {"bleu_score": 8.040993409646841, "chrf_score": 37.93264352886935, "xcomet_score": 0.8886784315109253, "xcomet_qe_score": 0.8642632961273193, "metricx_score": 5.853298187255859, "metricx_qe_score": 4.631551742553711, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Wissensweg verwenden wir Wikipedia.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 68.94988437881993, "xcomet_score": 0.8992471694946289, "xcomet_qe_score": 0.9114192128181458, "metricx_score": 3.3552706241607666, "metricx_qe_score": 3.657663106918335, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Unser Experiment wurde so gestaltet, dass wir bei der Überprüfung von mehr als 16 Datensätzen schnell vorgehen und ihn auf den 17. Datensatz anwenden.", "metrics": {"bleu_score": 26.57251941599823, "chrf_score": 48.25435267809411, "xcomet_score": 0.7210546135902405, "xcomet_qe_score": 0.6795633435249329, "metricx_score": 6.483238697052002, "metricx_qe_score": 6.660195827484131, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datenzelle in vier Falsche Fäden auf und führen eine Quervalidierung durch.", "metrics": {"bleu_score": 8.225964699966557, "chrf_score": 42.595152375277614, "xcomet_score": 0.7752867937088013, "xcomet_qe_score": 0.7418099641799927, "metricx_score": 9.37630558013916, "metricx_qe_score": 9.174485206604004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir ein neues Feature und evaluieren es using five evaluation classifiers.", "metrics": {"bleu_score": 12.011055432195764, "chrf_score": 41.96467123828596, "xcomet_score": 0.9427141547203064, "xcomet_qe_score": 0.9727312326431274, "metricx_score": 12.803412437438965, "metricx_qe_score": 13.296391487121582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserer experimentell basierten, belt-basierten Architektur.", "metrics": {"bleu_score": 16.784459625186194, "chrf_score": 61.497490364437, "xcomet_score": 0.8119767904281616, "xcomet_qe_score": 0.843657374382019, "metricx_score": 12.265089988708496, "metricx_qe_score": 7.421511650085449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse unserer Experimente sind hier.", "metrics": {"bleu_score": 27.77619034011791, "chrf_score": 80.5141506457296, "xcomet_score": 0.9945375919342041, "xcomet_qe_score": 0.9884932041168213, "metricx_score": 0.0, "metricx_qe_score": 0.016110263764858246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Siehe, dass wir unseren Rahmenwerk mit einem Ziel-Daten集 vergleichen, feinjustieren, das Ziel-Aufgabenfeinjustieren und eine leere DNA-Präliminariefeinjustierung.", "metrics": {"bleu_score": 11.43269358142632, "chrf_score": 39.14019404222148, "xcomet_score": 0.48164471983909607, "xcomet_qe_score": 0.568663477897644, "metricx_score": 17.24173355102539, "metricx_qe_score": 14.43407917022705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Unser Team hat eine fein abgestimmte Formel entwickelt, um das beste Ergebnis und die beste Leistung zu erzielen.", "metrics": {"bleu_score": 30.143352515082135, "chrf_score": 58.20565188603671, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0191549062728882, "metricx_qe_score": 1.4277279376983643, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während das leere DNA zwei Prozent gegenüber dem Ziel-Datenbank-Feinjustieren verbessert hat.", "metrics": {"bleu_score": 8.054496384843702, "chrf_score": 41.58885867008789, "xcomet_score": 0.6296651363372803, "xcomet_qe_score": 0.6190457940101624, "metricx_score": 10.68117618560791, "metricx_qe_score": 12.200039863586426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Poach erreichte eine Verbesserung von sechs Prozent.", "metrics": {"bleu_score": 33.471898740037666, "chrf_score": 62.00344001113489, "xcomet_score": 0.8438698053359985, "xcomet_qe_score": 0.8216042518615723, "metricx_score": 7.165152072906494, "metricx_qe_score": 7.5042405128479, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "When we look at the small data set, we can see that the performance of MTD decreases and the improvement of the preliminary multitask fine-tuning phase decreases to one point five percent.", "metrics": {"bleu_score": 1.2944532586971997, "chrf_score": 21.01170267956358, "xcomet_score": 0.7439099550247192, "xcomet_qe_score": 0.7555173635482788, "metricx_score": 14.433757781982422, "metricx_qe_score": 9.702147483825684, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "'Unser Leistungsniveau hat sich um elf Prozent gegenüber dem Zielauftrag 'Fine-tuning' erhöht.'", "metrics": {"bleu_score": 5.852284798798958, "chrf_score": 31.73178587141447, "xcomet_score": 0.9326798915863037, "xcomet_qe_score": 0.9754718542098999, "metricx_score": 4.962809085845947, "metricx_qe_score": 3.485910177230835, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für Saling arbeitet 'Fast' als Enzym, das die Verstoffwechselung von Fett zu Kohlenhydraten beschleunigt.", "metrics": {"bleu_score": 3.21858262703621, "chrf_score": 15.504311057200034, "xcomet_score": 0.11111761629581451, "xcomet_qe_score": 0.10847078263759613, "metricx_score": 23.896467208862305, "metricx_qe_score": 24.359018325805664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben, Datensätze.", "metrics": {"bleu_score": 70.71067811865478, "chrf_score": 90.0929663869274, "xcomet_score": 0.9819139242172241, "xcomet_qe_score": 0.9792402982711792, "metricx_score": 0.6101759076118469, "metricx_qe_score": 1.068135142326355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und es hält den Kopf des Modells fest.", "metrics": {"bleu_score": 14.923729480049115, "chrf_score": 48.14460270889752, "xcomet_score": 0.8470722436904907, "xcomet_qe_score": 0.8924514055252075, "metricx_score": 3.6050281524658203, "metricx_qe_score": 3.3845374584198, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Formulierung hinzu.", "metrics": {"bleu_score": 48.892302243490086, "chrf_score": 64.92804923091808, "xcomet_score": 0.8715407848358154, "xcomet_qe_score": 0.8563467860221863, "metricx_score": 6.500548362731934, "metricx_qe_score": 6.610191345214844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Die Vergrößerung der Trainingsdaten erfordert eine Zielwerte mit semantischem Sinn, damit wir sie in das Sprachmodell einfügen und es für die Sätzeperkennungsprobleme verwenden können.", "metrics": {"bleu_score": 13.171730318749777, "chrf_score": 50.21261349934461, "xcomet_score": 0.8833909630775452, "xcomet_qe_score": 0.861653208732605, "metricx_score": 5.460888385772705, "metricx_qe_score": 4.444922924041748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank!", "metrics": {"bleu_score": 0.0, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.017602328211069107, "linguapy_score": [0, "GERMAN"]}}
