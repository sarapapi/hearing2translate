{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous. Aujourd'hui, je vais présenter notre travail de recherche, Apprendre à raisonner déductivement, la résolution de problèmes métaphoriques en tant qu'extraction de raisonnement complexe."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je suis Alan du laboratoire d'intelligence artificielle de Baidu et ceci est un travail conjoint avec Jiri de l'Université du Texas à Austin et Weilu de SUTD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, j'aimerais parler de notre motivation pour raisonner."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Voici quelques exemples où le raisonnement en plusieurs étapes est utile."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Cette figure est tirée de l'article où ils ont effectué un prompt pour résoudre le problème de MathWorld dans un scénario d'apprentissage par quelques exemples."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Sur le côté de la main, nous pouvons voir que si nous donnons des exemples avec juste des questions et des réponses, nous ne pourrons peut-être pas obtenir les bonnes réponses."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous donnons une description plus raisonnée, le modèle est capable de prédire la description raisonnée et de faire également une prédiction correcte ici."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Il est donc bon d'avoir un raisonnement multi-étapes interprétable en sortie."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons également que les problèmes de mathématiques sont une application directe pour évaluer de telles capacités de raisonnement."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre configuration de problème, nous devons résoudre cette question et obtenir les réponses numériques, étant donné les questions."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Dans nos ensembles de données, on nous donne également l'expression mathématique qui conduit à cette réponse particulière."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Certaines hypothèses s'appliquent également comme dans les travaux précédents."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que la précision des quantités est connue."}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Nous n'envisageons que les opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentiation."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les opérateurs complexes peuvent en fait être décomposés en ces opérateurs de base."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Les travaux antérieurs sur la résolution de problèmes mathématiques peuvent en fait être classés en deux catégories : séquence à séquence et séquence à arbre."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles traditionnels de séquence à séquence convertissent l'expression en une séquence spécifique pour la génération."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Il est assez facile à mettre en œuvre et peut être généralisé à de nombreux problèmes différents et complexes."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les inconvénients de la performance ne sont généralement pas meilleurs que ceux du modèle structurel, et ils manquent d'interprétabilité pour la prédiction."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en fait, cette direction est toujours assez populaire grâce au modèle de transformateur."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Dans les modèles basés sur les arbres, nous structurons en fait ces expressions sous forme d'arbre et suivons un parcours préfixe lors de la génération de l'arbre."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous continuons à générer les opérateurs jusqu'à ce que nous atteignions les feuilles, qui sont les quantités."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, le bon côté est qu'il nous donne en fait cette structure d'arbre binaire, mais en fait, c'est assez contre-intuitif, car nous générons d'abord l'opérateur, puis à la fin, nous générons les quantités."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième chose est qu'il contient également certains calculs répétitifs."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, si nous regardons cette expression, 8 fois 3 plus 3 est en fait généré deux fois. Mais en fait, nous devrions réutiliser les résultats."}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre approche proposée, nous voulons résoudre ces problèmes de manière progressive et interprétable."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, ici, à la deuxième étape, nous pouvons obtenir ce diviseur, qui est 27."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons également nous référer aux questions originales pour trouver les contenus pertinents."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les diviseurs."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "À cette troisième étape, nous obtenons en fait le quotient."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, et après ces trois étapes, nous pouvons en fait réutiliser les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape, et enfin obtenir les dividendes."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous générons en fait toute l'expression directement, plutôt que de générer un seul opérateur ou quantité."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "Cela rend donc le processus plus précis."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre système déductif, nous commençons par un ensemble de quantités présentées dans les questions, ainsi que certaines constantes comme point de départ."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "L'expression est représentée par EIJOP."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "Nous effectuons l'opérateur de Qi à Qj, et une telle expression est en fait dirigée."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également une soustraction inverse ici pour représenter la direction opposée."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "Cela ressemble beaucoup à l'extraction de relations."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Dans un système déductif formel, à l'étape t, nous appliquons l'opérateur entre la paire QI et QJ, puis nous obtenons ces nouvelles expressions."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "Nous l'ajoutons aux États suivants pour en faire une nouvelle quantité."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Ces diapositives visualisent en fait l'évolution des états, où nous continuons à ajouter des expressions aux états actuels."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Dans nos implémentations de modèles, nous utilisons d'abord un modèle de langage pré-entraîné, qui peut être BERT ou RoBERTa, puis nous codons une phrase, et nous obtenons ces représentations quantitatives."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Une fois que nous avons obtenu les représentations quantitatives, nous pouvons commencer à faire des inférences."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de Q1 pour obtenir la représentation de Q1 divisé par Q2 puis multiplié par Q3."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous obtenons la représentation de la paire, qui est essentiellement la concaténation entre Q1 et Q2, puis nous appliquons un réseau feedforward, qui est paramétré par l'opérateur."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous obtenons la représentation de l'expression Q1/Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en fait, en pratique, lors de la phase d'inférence, nous pourrions obtenir une expression incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, toutes les expressions possibles sont égales à trois fois le nombre d'opérateurs."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "L'avantage ici est que nous pouvons facilement ajouter des contraintes pour contrôler cet espace de recherche."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement supprimer cette expression dans notre espace de recherche."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "À la deuxième étape, nous faisons la même chose, mais la seule différence est qu'il y a une quantité supplémentaire."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "Cette quantité provient de l'expression calculée précédemment."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc finalement obtenir cette expression finale Q."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pouvons également voir que le nombre de toutes les expressions possibles est différent de l'étape précédente."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "De telles différences rendent difficile l'application de la recherche de faisceau, car la distribution de probabilité entre ces deux étapes est déséquilibrée."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "La procédure d'entraînement est similaire à celle d'un modèle de séquence à séquence, où nous optimisons la perte à chaque instant."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également ce tau pour représenter le moment où nous devons mettre fin à ce processus de génération."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, l'espace est différent d'une séquence à l'autre, car l'espace est différent à chaque fois, alors que dans le modèle traditionnel de séquence à séquence, il s'agit du nombre de mots du vocabulaire."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Cela nous permet également d'imposer certaines contraintes à partir de connaissances antérieures."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc mené des expériences sur les ensembles de données de problèmes mathématiques couramment utilisés, à savoir MATH, Math23K, MathQA et SWAMP."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Nous présentons ici brièvement les résultats comparés aux meilleures approches précédentes."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Notre variante la plus performante est Roberta Detective Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "En fait, nous n'utilisons pas de recherche de faisceau, contrairement aux approches objectives utilisant la recherche de faisceau."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord. Les meilleures approches sont souvent basées sur les arbres."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, notre raisonneur est capable de surpasser de manière significative ce modèle basé sur les arbres."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons voir que le nombre absolu sur MathQA ou SWM n'est pas vraiment élevé."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc poursuivi l'étude des résultats sur"}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "SWAMP, et cet ensemble de données est difficile car l'auteur a tenté d'ajouter manuellement des éléments pour tromper le modèle de traitement automatique du langage naturel, comme des informations sur l'environnement et des quantités supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre prédiction, nous avons trouvé que certaines des valeurs intermédiaires sont en fait négatives."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans ces questions, nous demandons combien de pommes a Drake."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons des informations supplémentaires, comme le fait que 17 lancers ont été effectués et que Stephen en a réussi 8, ce qui est totalement sans importance."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Notre modèle fait donc des prédictions comme celle-ci, qui produit des valeurs négatives."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons observé ces deux expressions"}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc limiter cet espace de recherche en supprimant les résultats négatifs, afin de pouvoir donner la bonne réponse."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons en outre que cette contrainte améliore considérablement certains modèles."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour les oiseaux, nous avons amélioré de 7 points, et pour le modèle basé sur le robot, nous avons en fait amélioré de 2 points."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Un meilleur modèle linguistique a une meilleure capacité de compréhension linguistique, de sorte que le nombre ici est plus élevé pour Roberta et plus bas pour BERT."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également tenté d'analyser les difficultés inhérentes à cette situation."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que le nombre de quantités inutilisées peut être considéré comme une information non pertinente ici."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous pouvons voir que nous avons le pourcentage d'échantillons que nous n'utilisons pas de quantités, et l'ensemble de données SWAMP a la plus grande proportion."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Nous présentons également ici les performances globales."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "Pour les échantillons sans quantités utilisées, les performances globales sont en fait supérieures aux performances globales."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "Mais avec ces échantillons qui ont une quantité inutilisée, c'est en fait bien pire que la quantité inutilisée."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce qui est des performances, nous n'avons pas beaucoup de cas de décès pour le MPSW, donc je vais ignorer cette partie."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous voulons montrer l'interprétabilité à travers un exemple de prédiction de crash."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, notre modèle fait en fait une mauvaise prédiction à la première étape."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc en fait corréler cette expression avec la phrase ici, d'accord ?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons que cette phrase pourrait induire le modèle en erreur et le conduire à une prédiction incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, planter un autre 35 fait penser au modèle qu'il devrait s'agir d'un opérateur d'addition."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc essayé de réviser la phrase pour qu'elle ressemble à ceci : « le nombre de poiriers est inférieur de 55 % à celui des pommiers. »"}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Nous le faisons pour transmettre une sémantique plus précise, afin que le modèle puisse faire des prédictions correctes."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Cette étude montre comment les prédictions interprétables nous aident à comprendre le comportement du modèle."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure notre travail, notre modèle est en fait assez efficace."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "Nous sommes en mesure de fournir une procédure de résolution interprétable."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons facilement incorporer certaines connaissances préalables sous forme de contraintes, ce qui peut aider à améliorer les performances."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, le mécanisme sous-jacent ne s'applique pas seulement aux tâches de résolution de problèmes mathématiques, mais aussi à d'autres tâches nécessitant un raisonnement en plusieurs étapes."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons aussi certaines limitations."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "Si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose, comme mentionné, c'est que, comme la distribution des probabilités est déséquilibrée à différents moments, il est également assez difficile d'appliquer une recherche de faisceau."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Voici la fin de la conférence et les questions sont les bienvenues. Merci."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je suis de l'Université de Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter mon travail conjoint avec Jerry, qui porte sur un nouveau jeu de données pour la récupération d'articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions juridiques font partie intégrante de la vie de nombreuses personnes."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et les procédures juridiques fondamentales."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent pas se permettre l'assistance coûteuse d'un expert juridique se retrouvent sans protection ou, pire encore, exploités."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler le fossé entre les personnes et la loi en développant un système de récupération efficace pour les articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "Un tel système pourrait fournir un service d'aide juridique professionnel gratuit pour les humains non qualifiés."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de nous plonger dans la contribution principale de ce travail, décrivons d'abord le problème de la récupération d'articles statutaires."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Si vous violez le secret professionnel, quels risques courez-vous ?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est nécessaire pour extraire tous les articles législatifs pertinents d'un grand corpus de législation."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche de récupération d'informations comporte son propre ensemble de défis."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, il traite de deux types de langues."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "Langage naturel courant pour les questions et langage juridique complexe pour les statuts."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans les distributions linguistiques rend plus difficile pour un système de retrouver des candidats pertinents, car elle nécessite indirectement un système d'interprétation inhérent qui peut traduire une question naturelle en une question juridique qui correspond à la terminologie des statuts."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, la loi statutaire n'est pas une pile d'articles indépendants qui peuvent être traités comme une source d'information complète en soi, comme les nouvelles ou les recettes, par exemple."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, il s'agit d'une collection structurée de dispositions juridiques qui n'ont un sens global que lorsqu'elles sont considérées dans leur contexte global, c'est-à-dire avec les informations supplémentaires de leurs articles voisins, des domaines et sous-domaines auxquels elles appartiennent, et de leur place dans la structure de la loi."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles statutaires ne sont pas de petits paragraphes, qui sont généralement l'unité de récupération typique dans la plupart des travaux de récupération."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit ici de documents longs pouvant aller jusqu'à 6 000 mots."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les récents progrès en PLN ont suscité un grand intérêt pour de nombreuses tâches juridiques, telles que la prédiction des jugements juridiques ou la révision automatique des contrats."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Mais l'extraction d'articles statutaires est restée principalement intacte en raison du manque de grands ensembles de données étiquetées de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce travail, nous présentons un nouveau jeu de données centré sur le citoyen et en langue française pour étudier si un modèle de récupération peut approcher l'efficacité et la fiabilité d'un expert juridique pour la tâche de récupération d'articles législatifs."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "L'ensemble de données de récupération d'articles de loi belges comprend plus de 1 100 lois."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions couvrent une large gamme de sujets, allant de la famille, du logement, de l'argent, au travail et à la sécurité sociale."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun d'entre eux a été étiqueté par un juriste expérimenté avec des références aux articles pertinents d'un corpus de plus de 22 600 articles."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Parlons maintenant de la manière dont nous avons collecté ces ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons commencé par compiler un grand corpus d'articles juridiques."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné 32 codes belges disponibles publiquement et extrait tous leurs articles ainsi que les en-têtes de section correspondants."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons ensuite rassemblé des questions juridiques avec des références aux statuts pertinents."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous avons fait équipe avec un cabinet d'avocats belge qui reçoit chaque année environ 4 000 courriels de citoyens belges demandant des conseils sur une question juridique personnelle."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'accéder à leurs sites web, où leur équipe d'avocats expérimentés traite les questions juridiques les plus courantes en Belgique."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons recueilli des milliers de questions, annotées avec des catégories, des sous-catégories et des références juridiques aux statuts pertinents."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons analysé les références juridiques et filtré les questions dont les références n'étaient pas des articles de l'un des codes de loi que nous avons pris en compte."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été mises en correspondance et converties en identifiants d'articles correspondants d'AlloCiné."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons finalement abouti à 1 108 questions, chacune soigneusement étiquetée avec les idées des articles pertinents de Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question est accompagnée d'une catégorie principale et d'une concaténation de sous-catégories."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "Et chaque article est suivi de la concaténation de son titre dans la structure de la loi."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Ces informations supplémentaires ne sont pas utilisées dans le présent travail, mais pourraient intéresser les recherches futures sur la récupération d'informations juridiques ou la classification de textes juridiques."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons quelques caractéristiques de nos ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions font entre 5 et 44 mots de long, avec une médiane de 14 mots."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont beaucoup plus longs, avec une longueur médiane de 77 mots, avec 140 000 mots."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "Deux d'entre eux dépassent 1 000 m."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "Comme mentionné précédemment, la question couvre une large gamme de sujets, dont environ 85 % concernent la famille, le logement, l'argent ou la justice."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "Les 15 % restants concernent soit la sécurité sociale, soit les étrangers, soit le travail."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très diversifiés, car ils proviennent de 32 codes belges différents qui couvrent un grand nombre de sujets juridiques."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles collectés pour chacun de ces codes belges."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Sur les 22 633 articles, seuls 1 612 sont considérés comme pertinents pour au moins un des 100 sujets."}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "Dans les ensembles de données, environ 80 % des articles cités proviennent du Code civil, du Code judiciaire, du Code de procédure pénale ou du Code pénal."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant ce temps, 18 des 32 codes ont moins de 5 articles mentionnés comme pertinents pour au moins une question."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Ce qui peut s'expliquer par le fait que le code de justice focusse moins sur les individus et leurs préoccupations."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "En général, le nombre médian de citations pour ces articles cités est de 2, et moins de 25 % d'entre eux ont été cités plus de 10 fois."}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "À l'aide de nos ensembles de données, nous avons évalué plusieurs approches de récupération, y compris les architectures lexicales et denses."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné une requête et un article, un modèle lexical attribue un score à la paire requête-article en calculant la somme, sur les termes de la requête, des poids de chacun de ces termes dans cet article."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons expérimenté avec les fonctions de classement standard TF-IDF et BM25."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème de ces approches est qu'elles ne peuvent récupérer que les articles contenant les mots-clés présents dans la requête."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons une architecture basée sur un réseau neuronal qui peut capturer la relation sémantique entre les requêtes et les articles."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle B-encoder qui cartographie les requêtes et les articles dans des représentations vectorielles denses, et nous calculons un score de pertinence entre une paire requête-article par la similarité de leurs intégrations."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces intégrations résultent généralement d'une opération de mise en commun de la sortie d'un modèle d'intégration de mots."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous avons étudié l'efficacité des encodeurs Siamois B dans un cadre d'évaluation sans apprentissage, ce qui signifie que les modèles d'intégration de mots pré-entraînés sont appliqués tels quels, sans aucun réglage fin supplémentaire."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons expérimenté avec des encodeurs de texte indépendants du contexte, à savoir Word2Vec et FastText, et des modèles d'intégration dépendants du contexte, à savoir RoBERTa et plus spécifiquement CamemBERT, qui est un modèle RoBERTa en français."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous avons formé notre propre modèle basé sur CamemBERT, au-delà des codeurs."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "Sur tous les ensembles de données. Notez que pour l'entraînement, nous avons expérimenté avec les deux variantes de l'architecture BiANN."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamese, qui utilise un modèle d'intégration de mots unique qui cartographie la requête et l'article ensemble dans un espace vectoriel dense partagé, et Two-Tower, qui utilise deux modèles d'intégration de mots indépendants qui codent la requête et l'article séparément dans des espaces d'intégration différents."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons expérimenté avec la moyenne, le max et le pooling CLS, ainsi qu'avec le produit scalaire et le cosinus pour calculer les similarités."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre ligne de base sur l'ensemble de test."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "Avec les méthodes lexicales ci-dessus, les encodeurs B Siamese évalués dans un cadre sans tir dans le milieu, et les encodeurs B ajustés en dessous."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, le décodeur B fine-tuned surpasse de loin tous les autres modèles de référence."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle à deux tours améliore le rappel à 100 de sa variante siamoise, mais affiche des performances similaires sur les autres métriques."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que BM25 soit nettement moins performant que le modèle BERT entraîné, ses performances indiquent qu'il s'agit toujours d'une référence solide pour la récupération spécifique à un domaine."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation à tir unique de l'encodeur Siamese, nous constatons que l'utilisation directe des intégrations d'un modèle CamemBERT pré-entraîné sans optimisation pour la tâche de récupération d'informations donne de mauvais résultats, ce qui est conforme aux résultats précédents."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous avons constaté que le décodeur de BERT basé sur Word2Vec surpasse de manière significative le modèle basé sur FastText et BERT, ce qui suggère que les intégrations de niveau de mot pré-entraînées sont peut-être plus appropriées pour la tâche que les intégrations de niveau de caractère ou de sous-mot lorsqu'elles sont utilisées telles quelles."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteurs, ces résultats suggèrent une marge d'amélioration considérable par rapport à un expert chevronné qui peut éventuellement retrouver tous les articles pertinents pour n'importe quelle question et obtenir ainsi des scores parfaits."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Concluons en discutant de deux limitations de nos ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, le corpus d'articles est limité à ceux collectés à partir des 32 codes belges considérés, ce qui ne couvre pas l'ensemble du droit belge, car les articles des décrets, directives et ordonnances sont absents."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Lors de la construction de l'ensemble de données, toutes les références à ces articles non collectés sont ignorées, ce qui pose la question de savoir pourquoi il ne reste qu'une fraction du nombre initial d'articles pertinents."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'information implique que la réponse contenue dans les articles pertinents restants pourrait être incomplète, bien qu'elle soit toujours totalement appropriée."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous devons noter que toutes les questions juridiques ne peuvent pas être résolues par les statuts seuls."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question « Puis-je expulser mes locataires s’ils font trop de bruit »"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "Il n'existe peut-être pas de réponse détaillée dans la loi qui quantifie un seuil de bruit spécifique à partir duquel une expulsion est autorisée."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, le propriétaire foncier devrait probablement s'appuyer davantage sur la jurisprudence et trouver des précédents similaires à sa situation actuelle."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le locataire fait deux parties par semaine jusqu'à 20 h."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "Certaines questions sont donc mieux adaptées que d'autres à la tâche de récupération d'articles statutaires, et le domaine des moins adaptées reste à déterminer."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que ce travail suscitera l'intérêt pour le développement de modèles de récupération d'articles législatifs pratiques et fiables."}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut aider à améliorer l'accès à la justice pour tous."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre article, notre ensemble de données et notre code aux liens suivants. Merci."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, nous sommes heureux de vous présenter notre travail sur VALSE, un benchmark indépendant des tâches, conçu pour tester les modèles de vision et de langage avec des phénomènes linguistiques spécifiques."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi nous sommes-nous donné la peine de mettre en place ce benchmark ?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Eh bien, au cours des dernières années, nous avons assisté à une explosion de modèles de vision et de langage basés sur des transformateurs, pré-entraînés sur de grandes quantités de paires d'images et de textes."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun de ces modèles fait progresser l'état de l'art dans les tâches de vision et de langage, telles que la réponse à des questions visuelles, le raisonnement visuel de bon sens, la récupération d'images, l'ancrage de phrases."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons reçu un message. Les taux de réussite de ces benchmarks spécifiques à la tâche augmentent régulièrement."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous vraiment ce que les modèles ont appris ?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Que comprend un transformateur de vision et de langage lorsqu'il attribue un score élevé à cette image et à cette phrase pour les faire correspondre ?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "Et le score le plus bas pour celui-ci."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur les bonnes choses ?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Ou se concentrent-ils sur les biais, comme le montrent les travaux précédents ?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour mieux éclairer cet aspect, nous proposons une direction plus indépendante de la tâche et introduisons VALSE, qui teste la sensibilité des modèles de vision et de langage à des phénomènes linguistiques spécifiques qui affectent à la fois les modalités linguistiques et visuelles."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la coréférence d'entités."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment pouvons-nous tester si les modèles de vision et de langage ont capturé ce phénomène ?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "par FOILing, une méthode appliquée précédemment aux modèles de vision et de langage uniquement pour les syntagmes nominaux par Ravi Shekhar et ses collaborateurs, et au comptage par nous dans un travail précédent."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le « foiling » consiste essentiellement à prendre la légende d'une image et à produire un « foil » en modifiant la légende de manière à ce qu'elle ne décrive plus l'image."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Nous réalisons ces modifications de phrases en nous concentrant sur six éléments spécifiques, tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la coréférence d'entités, chaque élément pouvant être constitué d'un ou de plusieurs instruments, au cas où nous aurions trouvé plus d'une manière intéressante de créer des instances de leurres."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas de la pièce sur les actions, nous avons deux instruments, l'un dans lequel le verbe d'action est remplacé par une action différente et l'autre dans lequel les actants sont échangés."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la coréférence sont également des éléments qui comportent plus d'un instrument."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Nous créons ces leurres en nous assurant qu'ils ne décrivent pas l'image, qu'ils sont des phrases grammaticalement correctes et valides."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Cela n'est pas facile à faire car une légende erronée peut être moins probable que la légende originale."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien qu'il ne soit pas impossible que des plantes coupent un homme, il est statistiquement moins probable que des plantes coupent un homme qu'un homme coupe des plantes, et les grands modèles de vision et de langage pourraient s'en rendre compte."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Nous devons donc agir pour obtenir des résultats valides."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous utilisons des modèles linguistiques puissants pour proposer des feuilles."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence en langage naturel, ou NLI, pour filtrer les leurres qui pourraient encore décrire l'image, car lors de la construction des leurres, nous devons nous assurer qu'ils ne décrivent pas l'image."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester cela automatiquement, nous appliquons l'inférence en langage naturel avec le raisonnement suivant."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons une image comme étant la prémisse et sa légende comme son hypothèse sous-jacente."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous considérons la légende comme étant la prémisse et le leurre comme son hypothèse."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit que le FOIL est en contradiction ou neutre par rapport à la légende, nous considérons cela comme un indicateur d'un FOIL valide."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si un NLI prédit que le leurre est impliqué par la légende, il ne peut pas être un bon leurre, car par transitivité, il donnera une description véridique de l'image, et nous filtrons ces leurres."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette procédure n'est pas parfaite. Elle n'est qu'un indicateur de la validité des feuilles."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que troisième mesure pour générer des FOI valides, nous avons donc recours à des annotateurs humains pour valider les données utilisées dans VALSE."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Après filtrage et évaluation humaine, nous disposons d'autant d'instances de test que celles décrites dans ce tableau."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que VALSE ne fournit aucune donnée d'entraînement, mais uniquement des données de test."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit d'un benchmark de test à zéro tir, conçu pour exploiter les capacités existantes des modèles de vision et de langage après le pré-entraînement."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "Le réglage fin ne permettrait aux modèles que d'exploiter les artefacts ou les biais statistiques des données."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme nous l'avons dit, nous nous intéressons à évaluer les capacités des modèles de vision et de langage après le pré-entraînement."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons expérimenté avec cinq modèles de vision et de langage sur VALSE, à savoir CLIP, ALIGN, ViLBERT, ViLBERT 12-in-1 et VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos métriques d’évaluation les plus importantes sont l’exactitude des modèles à classer les paires d’images et de phrases en légendes et en leurres."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Peut-être plus pertinent pour cette vidéo, nous allons présenter notre métrique plus permissive, la précision par paires, qui mesure si le score d'alignement image-phrase est plus élevé pour la paire image-texte correcte que pour sa paire trompeuse."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "Pour plus de métriques et de résultats, consultez notre article."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats avec la précision par paires sont présentés ici et sont cohérents avec les résultats que nous avons obtenus à partir des autres métriques. Le meilleur résultat en tir zéro est obtenu par VilBERT 12 en 1, suivi de VilBERT, AlexMERT, CLIP et enfin VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est remarquable de constater que les instruments centrés sur les objets individuels comme l'existence et les groupes nominaux sont presque résolus par Wilbert 12 en 1, ce qui met en évidence le fait que les modèles sont capables d'identifier les objets nommés et leur présence dans les images."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos paramètres de contournement adverses."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons, grâce aux instruments de comptage et de pluralité, que les modèles de vision et de langage ont du mal à distinguer les références à un seul objet ou à plusieurs objets, ou à les compter sur une image."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "L'étude de la relation montre qu'ils ont des difficultés à classer correctement une relation spatiale nommée entre des objets sur une image."}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont également du mal à distinguer les actions et à identifier leurs participants, même lorsqu’ils sont soutenus par des biais de plausibilité, comme nous le voyons dans l’article sur les actions."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'article sur la coréférence, nous découvrons que le suivi de plusieurs références au même objet dans une image à l'aide de pronoms est également difficile pour les modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "Pour vérifier la cohérence et parce que c'est une expérience intéressante, nous avons également évalué deux modèles basés uniquement sur le texte, GPT-1 et GPT-2, afin de déterminer si VALSE peut être résolu par ces modèles unimodaux en calculant la perplexité des légendes correctes et incorrectes (aucune image ici) et en prédisant l'entrée avec la perplexité la plus faible."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "Si la perplexité est plus élevée pour le leurre, nous considérons cela comme une indication que la légende truquée peut souffrir d'un biais de plausibilité ou d'autres biais linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Il est intéressant de constater que dans certains cas, les modèles GPT basés uniquement sur le texte ont mieux capturé la plausibilité du monde que les modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "Pour résumer, VALSE est un benchmark qui utilise le prisme des constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant rigoureusement leurs capacités de mise en correspondance visuelle."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que les modèles de vision et de langage identifient bien les objets nommés en leur présence dans les images, comme le montre l'article sur l'existence, mais ont du mal à ancrer leur interdépendance et leurs relations dans les scènes visuelles lorsqu'ils sont contraints de respecter les indicateurs linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser VALSE pour mesurer les progrès réalisés en matière d'ancrage linguistique avec les modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, VALSE pourrait être utilisé comme une évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou l'ajustement afin de voir si un ensemble de données aide les modèles à s'améliorer sur l'un des aspects testés par VALSE."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si vous êtes intéressé, consultez les données de Vals sur GitHub et si vous avez des questions, n'hésitez pas à nous contacter."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kamezawa, de l'Université de Tokyo."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter un article intitulé « RnR : un grand ensemble de données pour la génération automatique de résumés de journaux de validation »."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "J'ai de l'expérience dans ce domaine."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais vous présenter la génération automatique de résumés sur laquelle nous travaillons dans le cadre de cette recherche."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de version sont un document technique qui résume les modifications distribuées avec chaque version d'un produit logiciel."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'image montre les notes de version pour la version 2.6."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Ces notes jouent un rôle important dans le développement open source, mais elles sont chronophages à préparer manuellement."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Il serait donc très utile de pouvoir générer automatiquement des notes de version de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais me référer à deux recherches antérieures sur la génération automatique de résumés."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé Arena, sorti en 2014."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il adopte une approche basée sur des règles, par exemple en utilisant l'extracteur de modifications pour extraire les différences de code, les modifications de bibliothèque et les modifications de documentation à partir des différences entre les versions, puis en les combinant."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus notable de ce système est l'extracteur de fiches dans le coin supérieur droit."}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "Il doit être lié à JIRA, le système de suivi des problèmes, et ne peut être appliqué qu'aux projets utilisant JIRA."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, il ne peut pas être utilisé pour de nombreux projets sur GitHub."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "Le deuxième est le deuil. Cette entrée a été annoncée en 2013."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "Il est disponible sur Internet et peut être stocké par une personne."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système dispose d'un modèle de classification de texte basé sur l'apprentissage simple et produit l'une des cinq étiquettes, telles que « fonctionnalités » ou « correctifs », pour chaque message de validation d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un exemple d'utilisation qui renvoie une liste de correctifs de bogues."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données d'entraînement de Quora sont assez réduites, environ 5 000, et seront présentées dans les expériences décrites ci-dessous."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "Les performances du modèle de croisement de texte ne sont pas élevées."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il y a des problèmes de portée limitée et de ressources de données rares."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des notes de publication de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le problème de l'applicabilité limitée, nous proposons une méthode de résumé de classe de haute qualité utilisant uniquement le message de validation en tant qu'entrée."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour toutes les bases de données en anglais."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème de ressources limitées, nous avons créé un ensemble de données R et SUMO composé d'environ 82 000 éléments de données en collectant des données à partir de dépôts GitHub publics à l'aide de l'API GitHub."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris notre ensemble."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de données."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche est le message de validation et le côté droit est les notes de version."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de publication sont étiquetées comme des améliorations, des corrections, etc."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons mis en place une tâche qui prend les messages de validation en entrée et produit les nœuds de base."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de résumé."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédéfini quatre labels : fonctionnalités, améliorations, corrections de bugs, duplications, suppressions et modifications de rupture."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Celles-ci ont été établies sur la base de recherches antérieures et d'autres faits."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de bas de page de la partie inférieure droite sont extraites des notes de bas de page présentées dans la partie inférieure gauche."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce stade, il est nécessaire de détecter les quatre pièges qui ont été installés à l'avance."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les labels ne sont pas toujours cohérents avec chaque dépôt."}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le niveau d'amélioration comprend les améliorations, les améliorations, les optimisations, etc."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste de vocabulaire ou d’étiquettes d’étude pour chacune de ces variations de notation."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-le pour détecter les classes de notes de version et corriger le texte du reste qui suit en tant que phrase de notes de version pour la classe."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, un message de commit."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de validation ne sont pas liés à chaque version."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme indiqué sur l'image ci-dessous, si la version actuelle est la 2.5.19, nous devons identifier"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "Qualifiez la version de la version précédente (2.5.18) et obtenez sa profondeur. C'est un peu fastidieux et il ne suffit pas de simplement obtenir une liste de versions et de regarder avant et après."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons créé une règle de correspondance heuristique pour obtenir les versions précédentes et suivantes."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "C'est ainsi que vous vous en sortez."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "À la fin, 7 200 dépôts."}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de jetons de nœud de sortie est de 63, ce qui est assez élevé pour une tâche de résumé."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "Le nombre de jetons uniques est également assez élevé, à 830 000."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "En raison du grand nombre de noms de classes et de méthodes uniques présents dans la bibliothèque."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais maintenant expliquer la méthode proposée."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé extractif et abstrait classe par classe se compose de deux modules neuronaux."}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "Un classificateur utilisant BERT ou CodeBERT et un générateur utilisant BART."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, CAS utilise un classificateur pour classer chaque message de validation dans cinq classes de notes de publication, à savoir les fonctionnalités, les implémentations, les corrections de bugs, les suppressions et autres."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de validation sont classés comme « autres » ou rejetés."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Le CAS applique ensuite le générateur aux quatre documents de base indépendamment et génère une note de lecture pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages de validation et les raisons ne sont pas connues."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Pour entraîner le classificateur, nous avons attribué des étiquettes pseudo à chaque message de validation d'entrée en utilisant les 10 premiers caractères de chaque message de validation."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons les résumés abstraits par classe de notre approche par deux méthodes différentes."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons « CAS simple », se compose d'un seul réseau de séquence à séquence et génère un seul texte de note long, donné par la concaténation des messages de validation d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte de sortie peut être divisé en segments de classe en fonction de symboles de fin de point spécifiques à la classe."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons « CS Match », consiste en quatre réseaux différents de type « sec2sec », chacun correspondant à l'une des classes de nœuds de sortie."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, laissez-moi expliquer l'expérience."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées : CES, CES simple, CES multiple, Plassering et l'étude précédente de Griff."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation, dans certains cas, les notes sont données en plusieurs phrases."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Comme il est difficile de calculer le nombre de phrases, les zéros sont combinés avec des espaces et traités comme une seule longue phrase."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "Le bleu est pénalisé lorsque le système produit une phrase courte."}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité entraîne une valeur de bleu plus faible dans les résultats de l'expérience décrite ci-dessous."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous avons également calculé la spécificité, car le rouge et le bleu ne peuvent pas être calculés si les notes de publication sont vides."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une spécificité élevée signifie que le modèle produit correctement des textes vides dans les cas où les nœuds de référence supposent qu'ils sont vides."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Comme l’ensemble de données contient des adresses électroniques, des valeurs de hachage, etc., nous avons également évalué l’ensemble de données nettoyé, qui les exclut."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Les scores ROUGE de CAS et de CAS sont supérieurs de plus de 10 points à ceux des lignes de base."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur l'ensemble de test propre, l'écart de score entre la méthode proposée et la référence a bondi à plus de 20 points."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent que le CES et le CES sont significativement efficaces."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "Le CAS a obtenu un meilleur score de F1 que le CAS, ce qui suggère que la combinaison d'un classificateur et d'un générateur est efficace et que l'entraînement du classificateur à l'aide de données synthétiques est efficace."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "Une couverture élevée de CAS peut être obtenue probablement parce que le classificateur peut se concentrer sur la sélection de messages de validation pertinents pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Le CAS multithreadé a tendance à avoir un taux d'erreur plus élevé que le CAS monothreadé."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "ce qui suggère qu'il est également efficace de développer indépendamment différents modèles d'abstraction de résumé pour chaque classe de notes de publication."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "L'analyse des erreurs."}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes CS ont tendance à produire des phrases plus courtes que les phrases de référence humaine."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Sur la figure de droite, la phrase de référence comporte trois ou quatre phrases, tandis que la phrase de l’USAS n’en comporte qu’une seule."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette réticence du modèle est que, dans les données d'entraînement, seules 33 % des phrases sont présentes dans l'étiquette des caractéristiques et 40 % dans l'étiquette des améliorations."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes CS ne peuvent pas générer de nœuds de base précis sans informations supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple du haut à droite est un exemple de message de validation très désordonné, et la phrase complète ne peut pas être générée sans référence à la demande ou au problème correspondant."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous montre que les deux messages de validation dans l'entrée sont liés et doivent être combinés en une seule phrase, mais il ne parvient pas à le faire."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, un conclure."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons créé un nouveau jeu de données pour l'obturation automatique des racines."}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également pour mission de rédiger des messages de validation et de les résumer de manière à ce qu'ils soient applicables à tous les projets rédigés en anglais."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Notre expérience montre que la méthode proposée génère moins de bruit et de notes de base à une couverture plus élevée que les méthodes de référence."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez vérifier les codes ou désactiver le blocage."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Safa Ferrari."}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter notre article « Enrichissement de données tabulaires à partir de quelques exemples à l'aide d'architectures de transformateurs ajustées »."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Un scientifique analyse les données et se concentre principalement sur la manipulation des caractéristiques existantes des données."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "Mais parfois, ces fonctionnalités sont limitées."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération de fonctionnalités à partir d'une autre source de données peut ajouter des informations substantielles."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique des données tabulaires à l'aide de sources externes de texte libre."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons que nous ayons un ensemble de données tabulaires et une base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique qui implique le lien d'entité et l'analyse de texte pour extraire de nouvelles caractéristiques à partir du texte libre de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre FAST est exactement ce processus automatique."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Prenons un exemple. Dans les ensembles de données fournis à FAST."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données est l'ensemble de données des universités."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque son objectif est de classer les universités en universités de faible rang et en universités de haut rang."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que base de connaissances, nous utilisons Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase de FACE est le lien d'entité."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque chaque entité, dans cet exemple le nom de l'université, est liée à une entité au sein de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte des entités de la base de connaissances est extrait et ajouté à l'ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est le résumé de la page Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Nous devons maintenant générer ou extraire des caractéristiques du texte récupéré."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc besoin d'une phase d'extraction de caractéristiques qui inclut l'analyse de texte."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "C'est la principale nouveauté de cet article, et je vais en parler en détail dans les diapositives suivantes."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des caractéristiques, il y a une phase de génération de caractéristiques, au cours de laquelle nous utilisons les caractéristiques extraites pour générer un petit nombre de nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez des caractéristiques dans le nombre de classes de l'ensemble de données d'origine."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données d'origine comporte deux classes."}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "FAST génère donc deux nouveaux traits."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si l'ensemble de données comporte cinq classes, il faut d'abord générer cinq nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité de chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état actuel de l'art de l'analyse textuelle, à savoir les modèles de langage basés sur des transformateurs tels que BERT, XLNet, etc."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "Mais il est peu probable que nous puissions former un modèle linguistique à l'aide des ensembles de données d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Une approche naïve consisterait à effectuer un réglage fin pour la tâche cible."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Lors de la phase d'extraction de caractéristiques, nous pouvons télécharger un modèle de langage pré-entraîné, puis affiner le modèle de langage sur l'ensemble de données cible."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, pour ajuster le modèle de langage afin de classer le texte en classes, abstraire en classes, faible ou élevé."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "Recevez la sortie du modèle linguistique, qui est la probabilité de chaque classe, et utilisez-la comme nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que les ensembles de données peuvent avoir peu d'étiquettes d'entités distinctes."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, près de la moitié des ensembles de données contenaient moins de 400 échantillons, et le plus petit ensemble de données contenait 35 échantillons dans son ensemble d'entraînement initial."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "L'ajustement d'un modèle linguistique sur cet ensemble de données serait donc inefficace."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons utiliser des connaissances antérieures sur des ensembles de données préanalysés."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Puisque nous appliquons FAST à plusieurs ensembles de données, nous pouvons utiliser les n-1 ensembles de données pour recueillir des informations sur les n-1 ensembles de données et utiliser ces informations lorsque nous analysons le nème ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Ce que nous suggérons, c'est d'ajouter une autre phase de réglage fin."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "une phase préliminaire d'ajustement fin multitâche."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque vous affinez un modèle linguistique sur des ensembles de données N-1,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Nous procédons ensuite à une autre phase de micro-adaptation, qui est une micro-adaptation de la tâche cible, lorsque nous micro-adaptons le modèle linguistique sur le n-ième ensemble de données cible."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "L'état de l'art en matière d'ajustement fin multitâche s'appelle l'ajustement fin multitâche."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "Dans MT-DNN, MT-DNN maintient des têtes dans le nombre de tâches de l'ensemble d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, il y a quatre tâches dans l'ensemble d'apprentissage, donc le DNN vide maintient quatre têtes, comme vous pouvez le voir sur l'image."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "Il échantillonne ensuite un lot aléatoire de l'ensemble d'apprentissage."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "Si le lot de données appartient à une tâche de classification de phrases, il exécute un passage avant et arrière à travers la première tête."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Si le lot aléatoire appartient à une tâche de classement par paires, son attitude est de passer par le dernier en avant et en arrière."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, le jeu de données de Tableau varie en fonction du nombre de classes."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a donc de nombreuses tâches."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "Le nombre de classes de sortie (têtes) d'un réseau de neurones profond (DNN) est maintenu."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, mT5 doit initialiser de nouvelles têtes pour un nouvel ensemble de données avec une nouvelle tâche."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche, appelée « raffinement de la reformulation des tâches », consiste à reformuler chaque ensemble de données en un problème de classification par phrase, qui est une tâche à deux classes."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons un exemple."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre ensemble de données d'entrée, qui se compose d'entités, de caractéristiques, de texte et de classes."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Nous allons reformuler la tâche de classification du texte en « bas » et « élevé » pour classer le texte, le résumé et la classe en « vrai » ou « faux »."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous avons formé le modèle linguistique pour classer les résumés et les classes afin de déterminer si le résumé appartient à la classe ou non."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Le vecteur d'étiquettes dans le cas de X reste donc toujours composé de deux classes."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Voici l'algorithme de notre approche de réglage fin nouvellement formulée."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons donc le cadre complet."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "L'ensemble de données est ensuite chargé dans FAST."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, une phase d'exécution rapide de l'entité de liaison."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "Il extrait le texte de la base de connaissances, qui dans cet exemple est le résumé de la page Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "Il reformule ensuite la tâche en une tâche de classification de phrases."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "Appliquez le modèle linguistique à la nouvelle tâche et produisez la probabilité de chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que le modèle linguistique a déjà été ajusté sur le jeu de données n-1 à l'aide d'un ajustement multitâche préliminaire."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons ensuite le vecteur de sortie du modèle linguistique comme nouvelle fonction générée dans le nombre de classes."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification tabulaire de 17 éléments, qui varient en termes de taille, de caractéristiques, d'équilibre, de domaine et de performance initiale."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que base de connaissances, nous utilisons Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons conçu notre expérience comme une évaluation de type « leave-one-out » : nous avons formé FAST sur 16 ensembles de données, puis nous l'avons appliqué au 17e ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également divisé chaque ensemble de données en quatre plis et appliqué une validation croisée à quatre plis."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Nous générons ensuite la nouvelle fonction et l'évaluons à l'aide de cinq classifieurs d'évaluation."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons une architecture basée sur BERT dans notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez voir que nous comparons notre cadre à l'ajustement fin de l'ensemble de données cible, à l'ajustement fin de la tâche cible et à l'ajustement fin préliminaire du réseau de neurones profond."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "Et notre reformulation de l'ajustement fin a obtenu le meilleur résultat, la meilleure performance."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "Alors que MT-DNN a obtenu une amélioration de 2 % par rapport à l'ajustement fin sur l'ensemble de données cible,"}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche a permis une amélioration de 6 %."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous examinons le petit ensemble de données, nous pouvons voir que les performances de l'MT-DNN diminuent et que l'amélioration de la phase de réglage fin multitâche préliminaire diminue à 1,5 %."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "Mais notre performance a augmenté de 11 % par rapport à l'ajustement fin de la tâche cible."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le calcul de la somme, FAST permet un enrichissement à faible échantillonnage à partir de 35 échantillons dans notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une seule architecture pour toutes les tâches et tous les ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "Et il garde la tête du modèle."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "Mais il ajoute une phase de reformulation."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "Il augmente l'ensemble d'apprentissage et ses besoins d'une valeur cible avec une signification sémantique, afin que nous puissions l'alimenter dans le modèle de langage et l'utiliser dans le problème de classification de phrases."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci."}
