{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, gostaria de falar sobre a nossa motivação para o raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mostramos aqui exemplos em que o raciocínio em vários passos é útil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É bom ter raciocínio interpretável multietapas como saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, certas suposições também se aplicam como no trabalho anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que a precisão das quantidades é conhecida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que também contém alguns cálculos repetitivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nestes passos obtemos os divisores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então neste terceiro passo nós conseguimos obter o quociente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Certo. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto torna o processo mais preciso.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, a expressão é representada por e i j o p.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Onde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, também temos a subtração com palavras aqui para representar a direção oposta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é bastante semelhante a relation extraction.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionamo-la ao próximo estado para se tornar uma nova quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim que obtemos as representações de quantidade, podemos começar a fazer inferência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, toda a expressão possível é igual a três vezes o número de operadores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, esta quantidade vem da expressão calculada anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então podemos finalmente obter esta expressão final q_3 vezes q_4.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também usamos este tau para representar quando devemos encerrar este processo de geração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também nos permite impor certas restrições do conhecimento anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Muito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, investigamos ainda mais os resultados no SVAMP.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso modelo faz alguma previsão como esta que está a produzir valores negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E observamos que estas duas expressões realmente têm classificações semelhantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, descobrimos ainda que esta restrição melhora muito para alguns modelos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também mostramos o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podemos realmente correlacionar esta expressão com a frase aqui. Certo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E somos capazes de fornecer um procedimento de resolução interpretável.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também temos certas limitações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Questões legais são parte integrante da vida de muitas pessoas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Todo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Antes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, lida com dois tipos de linguagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Linguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, há documentos longos que podem chegar a seis mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos agora falar sobre como recolhemos este conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Considerámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reunimos perguntas legais com referências a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Recolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Acabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vejamos algumas características do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O mais longo sendo até cinco mil setecentos e noventa palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o número total de artigos recolhidos de cada um destes códigos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos as funções de classificação TF-IDF e BM25 padrão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Observe que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o resultado da nossa linha de base nos conjuntos de teste.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos concluir discutindo duas limitações do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Durante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isso pode ajudar a melhorar o acesso à justiça para todos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Porque é que nos esforçámos para estabelecer este termo de comparação?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Bem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas sabemos o que os modelos realmente aprenderam?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a pontuação baixa para esta?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os modelos de linguagem e visão concentram-se na coisa certa?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou concentram-se em preconceitos como mostrado pelo trabalho anterior?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas como testamos se os modelos de linguagem e visão capturaram este fenómeno?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ao frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Frustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Contagem e correferência também são peças que possuem mais de um instrumento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para obter frustrações válidas, devemos agir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Duas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Talvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para mais métricas e resultados sobre eles, veja o nosso artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Gostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou explicar nesta ordem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro é um sistema chamado ARENA lançado em 2014.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A característica mais notável deste sistema é o extrator de problemas no canto superior direito.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Que deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por outras palavras, não pode ser usado para muitos projetos no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo é Glyph, anunciado recentemente em 2020.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Está disponível na internet e pode ser instalado através do pip.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O desempenho do modelo de text classification não é alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Apresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este método proposto pode ser usado para todos os repositórios em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, vou descrever o nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está um exemplo de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento são rotuladas como melhorias ou correções, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Configurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto pode ser considerado como uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Temos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes foram definidos com base em pesquisas anteriores e outros fatores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas os rótulos nem sempre são consistentes com cada repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Preparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, temos uma mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação não estão vinculadas a cada lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos uma regra de correspondência heurística para obter as versões anterior e seguinte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Análise do conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, explicarei o método proposto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um classificador que usa BERT ou CodeBERT e um gerador que usa BART.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação classificadas como outras são descartadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós modelamos a abordagem de abstractive summarization por dois métodos diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "OK, deixe-me explicar as experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Foram comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O BLEU é penalizado quando o sistema emite uma frase curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes resultados indicam que CEAS e CAS são significativamente afetados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está uma análise de erro.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, uma conclusão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos um novo conjunto de dados para geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem consultar o nosso conjunto de dados no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá. Chamo-me Asaf Harari.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, por vezes, estas características são limitadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A geração de características que usa outra fonte de dados pode adicionar informação substancial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "o nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Suponhamos que temos um conjunto de dados tabular e uma base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Precisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa estrutura FeSTE é exatamente esse processo automático.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo num conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados é um conjunto de dados universitário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A primeira fase do FeSTE é entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o texto é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Agora, precisamos de gerar ou extrair características do texto recuperado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, precisamos da fase de extração de características que inclui análise de texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Após a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro gere características no número de classes do conjunto de dados original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados original tem duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, o FeSTE gera duas novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada característica representa a probabilidade para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Receba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que nós sugerimos é adicionar outra fase de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma fase preliminar de ajuste fino multitarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando se afina o modelo de linguagem sobre n menos um conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A última geração em ajuste fino de multitarefa chamado MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E amostra um lote aleatório do conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso cenário, os conjuntos de dados tabulares variam no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Há muitas tarefas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN manteve número de classes, cabeçalhos, camadas de saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o vetor de rótulo neste caso consiste sempre em duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este é o algoritmo para a nossa abordagem de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, vamos ver a estrutura completa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então o FeSTE executa a fase de entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Extrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reformulou a tarefa numa tarefa de sentence classification par a par.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Projetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos na nossa base de experiências da arquitetura básica do BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados para as nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem alcançou uma melhoria de seis por cento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usa uma arquitetura para todas as tarefas e conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E mantém o cabeçalho do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas acrescenta uma fase de reformulação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, gostaria de falar sobre a nossa motivação para o raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mostramos aqui exemplos em que o raciocínio em vários passos é útil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É bom ter raciocínio interpretável multietapas como saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, certas suposições também se aplicam como no trabalho anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que a precisão das quantidades é conhecida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que também contém alguns cálculos repetitivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nestes passos obtemos os divisores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então neste terceiro passo nós conseguimos obter o quociente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Certo. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto torna o processo mais preciso.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, a expressão é representada por e i j o p.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Onde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, também temos a subtração com palavras aqui para representar a direção oposta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é bastante semelhante a relation extraction.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionamo-la ao próximo estado para se tornar uma nova quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim que obtemos as representações de quantidade, podemos começar a fazer inferência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, toda a expressão possível é igual a três vezes o número de operadores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, esta quantidade vem da expressão calculada anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então podemos finalmente obter esta expressão final q_3 vezes q_4.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também usamos este tau para representar quando devemos encerrar este processo de geração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também nos permite impor certas restrições do conhecimento anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Muito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, investigamos ainda mais os resultados no SVAMP.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso modelo faz alguma previsão como esta que está a produzir valores negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E observamos que estas duas expressões realmente têm classificações semelhantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, descobrimos ainda que esta restrição melhora muito para alguns modelos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também mostramos o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podemos realmente correlacionar esta expressão com a frase aqui. Certo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E somos capazes de fornecer um procedimento de resolução interpretável.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também temos certas limitações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Questões legais são parte integrante da vida de muitas pessoas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Todo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Antes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, lida com dois tipos de linguagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Linguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, há documentos longos que podem chegar a seis mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos agora falar sobre como recolhemos este conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Considerámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reunimos perguntas legais com referências a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Recolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Acabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vejamos algumas características do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O mais longo sendo até cinco mil setecentos e noventa palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o número total de artigos recolhidos de cada um destes códigos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos as funções de classificação TF-IDF e BM25 padrão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Observe que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o resultado da nossa linha de base nos conjuntos de teste.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos concluir discutindo duas limitações do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Durante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isso pode ajudar a melhorar o acesso à justiça para todos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Porque é que nos esforçámos para estabelecer este termo de comparação?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Bem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas sabemos o que os modelos realmente aprenderam?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a pontuação baixa para esta?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os modelos de linguagem e visão concentram-se na coisa certa?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou concentram-se em preconceitos como mostrado pelo trabalho anterior?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas como testamos se os modelos de linguagem e visão capturaram este fenómeno?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ao frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Frustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Contagem e correferência também são peças que possuem mais de um instrumento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para obter frustrações válidas, devemos agir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Duas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Talvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para mais métricas e resultados sobre eles, veja o nosso artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Gostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou explicar nesta ordem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro é um sistema chamado ARENA lançado em 2014.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A característica mais notável deste sistema é o extrator de problemas no canto superior direito.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Que deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por outras palavras, não pode ser usado para muitos projetos no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo é Glyph, anunciado recentemente em 2020.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Está disponível na internet e pode ser instalado através do pip.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O desempenho do modelo de text classification não é alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Apresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este método proposto pode ser usado para todos os repositórios em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, vou descrever o nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está um exemplo de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento são rotuladas como melhorias ou correções, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Configurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto pode ser considerado como uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Temos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes foram definidos com base em pesquisas anteriores e outros fatores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas os rótulos nem sempre são consistentes com cada repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Preparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, temos uma mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação não estão vinculadas a cada lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos uma regra de correspondência heurística para obter as versões anterior e seguinte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Análise do conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, explicarei o método proposto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um classificador que usa BERT ou CodeBERT e um gerador que usa BART.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação classificadas como outras são descartadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós modelamos a abordagem de abstractive summarization por dois métodos diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "OK, deixe-me explicar as experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Foram comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O BLEU é penalizado quando o sistema emite uma frase curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes resultados indicam que CEAS e CAS são significativamente afetados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está uma análise de erro.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, uma conclusão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos um novo conjunto de dados para geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem consultar o nosso conjunto de dados no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá. Chamo-me Asaf Harari.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, por vezes, estas características são limitadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A geração de características que usa outra fonte de dados pode adicionar informação substancial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "o nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Suponhamos que temos um conjunto de dados tabular e uma base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Precisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa estrutura FeSTE é exatamente esse processo automático.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo num conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados é um conjunto de dados universitário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A primeira fase do FeSTE é entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o texto é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Agora, precisamos de gerar ou extrair características do texto recuperado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, precisamos da fase de extração de características que inclui análise de texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Após a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro gere características no número de classes do conjunto de dados original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados original tem duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, o FeSTE gera duas novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada característica representa a probabilidade para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Receba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que nós sugerimos é adicionar outra fase de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma fase preliminar de ajuste fino multitarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando se afina o modelo de linguagem sobre n menos um conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A última geração em ajuste fino de multitarefa chamado MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E amostra um lote aleatório do conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso cenário, os conjuntos de dados tabulares variam no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Há muitas tarefas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN manteve número de classes, cabeçalhos, camadas de saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o vetor de rótulo neste caso consiste sempre em duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este é o algoritmo para a nossa abordagem de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, vamos ver a estrutura completa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então o FeSTE executa a fase de entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Extrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reformulou a tarefa numa tarefa de sentence classification par a par.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Projetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos na nossa base de experiências da arquitetura básica do BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados para as nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem alcançou uma melhoria de seis por cento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usa uma arquitetura para todas as tarefas e conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E mantém o cabeçalho do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas acrescenta uma fase de reformulação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, gostaria de falar sobre a nossa motivação para o raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mostramos aqui exemplos em que o raciocínio em vários passos é útil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É bom ter raciocínio interpretável multietapas como saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, certas suposições também se aplicam como no trabalho anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que a precisão das quantidades é conhecida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que também contém alguns cálculos repetitivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nestes passos obtemos os divisores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então neste terceiro passo nós conseguimos obter o quociente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Certo. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto torna o processo mais preciso.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, a expressão é representada por e i j o p.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Onde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, também temos a subtração com palavras aqui para representar a direção oposta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é bastante semelhante a relation extraction.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionamo-la ao próximo estado para se tornar uma nova quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim que obtemos as representações de quantidade, podemos começar a fazer inferência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, toda a expressão possível é igual a três vezes o número de operadores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, esta quantidade vem da expressão calculada anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então podemos finalmente obter esta expressão final q_3 vezes q_4.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também usamos este tau para representar quando devemos encerrar este processo de geração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também nos permite impor certas restrições do conhecimento anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Muito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, investigamos ainda mais os resultados no SVAMP.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso modelo faz alguma previsão como esta que está a produzir valores negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E observamos que estas duas expressões realmente têm classificações semelhantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, descobrimos ainda que esta restrição melhora muito para alguns modelos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também mostramos o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podemos realmente correlacionar esta expressão com a frase aqui. Certo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E somos capazes de fornecer um procedimento de resolução interpretável.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também temos certas limitações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Questões legais são parte integrante da vida de muitas pessoas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Todo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Antes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, lida com dois tipos de linguagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Linguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, há documentos longos que podem chegar a seis mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos agora falar sobre como recolhemos este conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Considerámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reunimos perguntas legais com referências a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Recolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Acabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vejamos algumas características do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O mais longo sendo até cinco mil setecentos e noventa palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o número total de artigos recolhidos de cada um destes códigos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos as funções de classificação TF-IDF e BM25 padrão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Observe que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o resultado da nossa linha de base nos conjuntos de teste.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos concluir discutindo duas limitações do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Durante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isso pode ajudar a melhorar o acesso à justiça para todos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Porque é que nos esforçámos para estabelecer este termo de comparação?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Bem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas sabemos o que os modelos realmente aprenderam?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a pontuação baixa para esta?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os modelos de linguagem e visão concentram-se na coisa certa?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou concentram-se em preconceitos como mostrado pelo trabalho anterior?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas como testamos se os modelos de linguagem e visão capturaram este fenómeno?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ao frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Frustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Contagem e correferência também são peças que possuem mais de um instrumento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para obter frustrações válidas, devemos agir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Duas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Talvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para mais métricas e resultados sobre eles, veja o nosso artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Gostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou explicar nesta ordem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro é um sistema chamado ARENA lançado em 2014.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A característica mais notável deste sistema é o extrator de problemas no canto superior direito.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Que deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por outras palavras, não pode ser usado para muitos projetos no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo é Glyph, anunciado recentemente em 2020.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Está disponível na internet e pode ser instalado através do pip.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O desempenho do modelo de text classification não é alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Apresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este método proposto pode ser usado para todos os repositórios em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, vou descrever o nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está um exemplo de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento são rotuladas como melhorias ou correções, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Configurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto pode ser considerado como uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Temos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes foram definidos com base em pesquisas anteriores e outros fatores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas os rótulos nem sempre são consistentes com cada repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Preparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, temos uma mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação não estão vinculadas a cada lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos uma regra de correspondência heurística para obter as versões anterior e seguinte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Análise do conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, explicarei o método proposto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um classificador que usa BERT ou CodeBERT e um gerador que usa BART.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação classificadas como outras são descartadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós modelamos a abordagem de abstractive summarization por dois métodos diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "OK, deixe-me explicar as experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Foram comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O BLEU é penalizado quando o sistema emite uma frase curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes resultados indicam que CEAS e CAS são significativamente afetados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está uma análise de erro.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, uma conclusão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos um novo conjunto de dados para geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem consultar o nosso conjunto de dados no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá. Chamo-me Asaf Harari.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, por vezes, estas características são limitadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A geração de características que usa outra fonte de dados pode adicionar informação substancial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "o nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Suponhamos que temos um conjunto de dados tabular e uma base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Precisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa estrutura FeSTE é exatamente esse processo automático.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo num conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados é um conjunto de dados universitário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A primeira fase do FeSTE é entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o texto é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Agora, precisamos de gerar ou extrair características do texto recuperado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, precisamos da fase de extração de características que inclui análise de texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Após a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro gere características no número de classes do conjunto de dados original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados original tem duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, o FeSTE gera duas novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada característica representa a probabilidade para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Receba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que nós sugerimos é adicionar outra fase de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma fase preliminar de ajuste fino multitarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando se afina o modelo de linguagem sobre n menos um conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A última geração em ajuste fino de multitarefa chamado MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E amostra um lote aleatório do conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso cenário, os conjuntos de dados tabulares variam no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Há muitas tarefas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN manteve número de classes, cabeçalhos, camadas de saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o vetor de rótulo neste caso consiste sempre em duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este é o algoritmo para a nossa abordagem de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, vamos ver a estrutura completa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então o FeSTE executa a fase de entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Extrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reformulou a tarefa numa tarefa de sentence classification par a par.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Projetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos na nossa base de experiências da arquitetura básica do BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados para as nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem alcançou uma melhoria de seis por cento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usa uma arquitetura para todas as tarefas e conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E mantém o cabeçalho do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas acrescenta uma fase de reformulação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.\nSou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.\nPrimeiro, gostaria de falar sobre a nossa motivação para o raciocínio.\nMostramos aqui exemplos em que o raciocínio em vários passos é útil.\nEste número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.\nEntão, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.\nMas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.\nÉ bom ter raciocínio interpretável multietapas como saída.\nE também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.\nAqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.\nAssim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.\nAssim, certas suposições também se aplicam como no trabalho anterior.\nAssumimos que a precisão das quantidades é conhecida.\nE consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.\nAlém disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.\nAssim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.\nAssim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.\nE é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.\nMas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.\nMas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.\nEntão, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.\nEntão, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.\nO que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.\nE a segunda coisa é que também contém alguns cálculos repetitivos.\nAqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.\nEntão, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.\nEntão por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.\nE também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.\nE nestes passos obtemos os divisores.\nE então neste terceiro passo nós conseguimos obter o quociente.\nCerto. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.\nEntão, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.\nIsto torna o processo mais preciso.\nNo nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.\nAssim, a expressão é representada por e i j o p.\nOnde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.\nEntão, também temos a subtração com palavras aqui para representar a direção oposta.\nIsto é bastante semelhante a relation extraction.\nAssim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.\nAdicionamo-la ao próximo estado para se tornar uma nova quantidade.\nÉ possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.\nNas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.\nAssim que obtemos as representações de quantidade, podemos começar a fazer inferência.\nAqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.\nPrimeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.\nE então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.\nMas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.\nAqui, toda a expressão possível é igual a três vezes o número de operadores.\nO que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.\nPor exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.\nEntão, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.\nPortanto, esta quantidade vem da expressão calculada anterior.\nEntão podemos finalmente obter esta expressão final q_3 vezes q_4.\nE também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.\nEntão, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.\nAssim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.\nE aqui também usamos este tau para representar quando devemos encerrar este processo de geração.\nE aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.\nE também nos permite impor certas restrições do conhecimento anterior.\nAssim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.\nE aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.\nPortanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.\nE, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.\nMuito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.\nEntão, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.\nMas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.\nEntão, investigamos ainda mais os resultados no SVAMP.\nE este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.\nEntão, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.\nPor exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?\nMas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.\nO nosso modelo faz alguma previsão como esta que está a produzir valores negativos.\nE observamos que estas duas expressões realmente têm classificações semelhantes.\nEntão, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.\nEntão, descobrimos ainda que esta restrição melhora muito para alguns modelos.\nPor exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.\nUm melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.\nTambém tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.\nAssumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.\nEntão, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.\nE aqui também mostramos o desempenho geral.\nPara essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.\nMas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.\nPara MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.\nFinalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.\nAqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.\nPodemos realmente correlacionar esta expressão com a frase aqui. Certo.\nEntão, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.\nAqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.\nEntão tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.\nNós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.\nPortanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.\nEntão, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.\nE somos capazes de fornecer um procedimento de resolução interpretável.\nE podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.\nE a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.\nTambém temos certas limitações.\nSe tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.\nE a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.\nEste é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.\nVou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.\nQuestões legais são parte integrante da vida de muitas pessoas.\nMas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.\nComo resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.\nTodo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.\nTal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.\nAntes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.\nDada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?\nUm modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.\nEsta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.\nPrimeiro, lida com dois tipos de linguagem.\nLinguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.\nEsta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.\nAlém disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.\nEm vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.\nPor fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.\nAqui, há documentos longos que podem chegar a seis mil palavras.\nOs avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.\nMas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.\nNeste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.\nO nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.\nEstas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.\nCada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.\nVamos agora falar sobre como recolhemos este conjunto de dados.\nPrimeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.\nConsiderámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.\nEm seguida, reunimos perguntas legais com referências a estatutos relevantes.\nPara isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.\nTivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.\nRecolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.\nPor fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.\nAs referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.\nAcabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.\nAlém disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.\nE cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.\nEsta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.\nVejamos algumas características do nosso conjunto de dados.\nAs perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.\nOs artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.\nO mais longo sendo até cinco mil setecentos e noventa palavras.\nComo mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.\nEnquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.\nO artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.\nAqui está o número total de artigos recolhidos de cada um destes códigos belgas.\nDos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.\nE cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.\nEnquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.\nO que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.\nNo geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.\nUsando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.\nDada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.\nExperimentamos as funções de classificação TF-IDF e BM25 padrão.\nO principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.\nPara superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.\nUsamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.\nEstas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.\nPrimeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.\nNós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.\nAlém disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.\nObserve que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.\nO siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.\nNós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.\nAqui está o resultado da nossa linha de base nos conjuntos de teste.\nCom os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.\nNo geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.\nO modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.\nEmbora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.\nEm relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.\nAlém disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.\nEmbora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.\nVamos concluir discutindo duas limitações do nosso conjunto de dados.\nEm primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.\nDurante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.\nEsta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.\nEm segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.\nPor exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?\nPode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.\nEm vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.\nPor exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.\nConsequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.\nEsperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.\nIsso pode ajudar a melhorar o acesso à justiça para todos.\nPodem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.\nPorque é que nos esforçámos para estabelecer este termo de comparação?\nBem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.\nCada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.\nEntão, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.\nMas sabemos o que os modelos realmente aprenderam?\nO que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?\nE a pontuação baixa para esta?\nOs modelos de linguagem e visão concentram-se na coisa certa?\nOu concentram-se em preconceitos como mostrado pelo trabalho anterior?\nPara lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.\nTomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.\nMas como testamos se os modelos de linguagem e visão capturaram este fenómeno?\nAo frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.\nFrustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.\nE fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.\nPor exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.\nContagem e correferência também são peças que possuem mais de um instrumento.\nE nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.\nIsto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.\nPor exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.\nAssim, para obter frustrações válidas, devemos agir.\nPrimeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.\nEm segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.\nPara testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.\nConsideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.\nAlém disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.\nSe um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.\nSe uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.\nMas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.\nAssim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.\nAssim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.\nPode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.\nUma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.\nO ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.\nE todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.\nE, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.\nExperimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.\nDuas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.\nTalvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.\nPara mais métricas e resultados sobre eles, veja o nosso artigo.\nOs resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.\nÉ notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.\nNo entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.\nVemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.\nA peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.\nTambém têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.\nA partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.\nComo uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.\nSe a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.\nE é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.\nEntão, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.\nAs nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.\nGostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.\nE além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.\nSe houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.\nVou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.\nVou explicar nesta ordem.\nPrimeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.\nUma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.\nA imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.\nAs notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.\nAssim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.\nVou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.\nO primeiro é um sistema chamado ARENA lançado em 2014.\nÉ precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.\nA característica mais notável deste sistema é o extrator de problemas no canto superior direito.\nQue deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.\nPor outras palavras, não pode ser usado para muitos projetos no GitHub.\nO segundo é Glyph, anunciado recentemente em 2020.\nEstá disponível na internet e pode ser instalado através do pip.\nEste sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.\nEsta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.\nOs dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.\nO desempenho do modelo de text classification não é alto.\nApresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.\nO nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.\nCom um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.\nEste método proposto pode ser usado para todos os repositórios em inglês.\nPara o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.\nEm seguida, vou descrever o nosso conjunto de dados.\nAqui está um exemplo de dados.\nO lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.\nAs notas de lançamento são rotuladas como melhorias ou correções, etc.\nConfigurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.\nIsto pode ser considerado como uma tarefa de sumarização.\nTemos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.\nEstes foram definidos com base em pesquisas anteriores e outros fatores.\nA nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.\nNeste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.\nMas os rótulos nem sempre são consistentes com cada repositório.\nPor exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.\nPreparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.\nIsto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.\nEm seguida, temos uma mensagem de confirmação.\nAs mensagens de confirmação não estão vinculadas a cada lançamento.\nComo mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.\nIsto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.\nCriámos uma regra de correspondência heurística para obter as versões anterior e seguinte.\nAnálise do conjunto de dados.\nNo final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.\nAlém disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.\nAlém disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.\nIsto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.\nEm seguida, explicarei o método proposto.\nO extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.\nUm classificador que usa BERT ou CodeBERT e um gerador que usa BART.\nPrimeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.\nAs mensagens de confirmação classificadas como outras são descartadas.\nEm seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.\nNesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.\nAssim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.\nNós modelamos a abordagem de abstractive summarization por dois métodos diferentes.\nO primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.\nOs textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.\nO segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.\nOK, deixe-me explicar as experiências.\nForam comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.\nEm relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.\nComo é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.\nO BLEU é penalizado quando o sistema emite uma frase curta.\nEsta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.\nFinalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.\nUma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.\nAqui estão os resultados.\nComo o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.\nCEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.\nEm particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.\nEstes resultados indicam que CEAS e CAS são significativamente afetados.\nCEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.\nA alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.\nO CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.\nSugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.\nAqui está uma análise de erro.\nOs métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.\nNa figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.\nA razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.\nAlém disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.\nO exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.\nO exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.\nPor fim, uma conclusão.\nCriámos um novo conjunto de dados para geração automática de notas de lançamento.\nTambém formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.\nAs nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.\nPodem consultar o nosso conjunto de dados no GitHub.\nObrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "Olá. Chamo-me Asaf Harari.\nE vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.\nOs cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.\nMas, por vezes, estas características são limitadas.\nA geração de características que usa outra fonte de dados pode adicionar informação substancial.\no nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.\nSuponhamos que temos um conjunto de dados tabular e uma base de conhecimento.\nPrecisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.\nA nossa estrutura FeSTE é exatamente esse processo automático.\nVamos ver um exemplo num conjunto de dados alimentado no FeSTE.\nNeste exemplo, o conjunto de dados é um conjunto de dados universitário.\nQuando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.\nComo base de conhecimento, usamos a Wikipédia.\nA primeira fase do FeSTE é entity linking.\nQuando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.\nE o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.\nNeste exemplo, o texto é o resumo da página da Wikipédia.\nAgora, precisamos de gerar ou extrair características do texto recuperado.\nEntão, precisamos da fase de extração de características que inclui análise de texto.\nE esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.\nApós a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.\nPrimeiro gere características no número de classes do conjunto de dados original.\nNeste exemplo, o conjunto de dados original tem duas classes.\nEntão, o FeSTE gera duas novas características.\nMas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.\nCada característica representa a probabilidade para cada classe.\nPara analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.\nÉ, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.\nPortanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.\nAssim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.\nNeste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.\nReceba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.\nO problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.\nNa nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.\nEntão, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.\nMas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.\nAplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.\nO que nós sugerimos é adicionar outra fase de ajuste fino.\nUma fase preliminar de ajuste fino multitarefa.\nQuando se afina o modelo de linguagem sobre n menos um conjuntos de dados.\nE, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.\nA última geração em ajuste fino de multitarefa chamado MTDNN.\nO MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.\nNeste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.\nE amostra um lote aleatório do conjunto de treinamento.\nE se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.\nE se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.\nNo nosso cenário, os conjuntos de dados tabulares variam no número de classes.\nHá muitas tarefas.\nO MTDNN manteve número de classes, cabeçalhos, camadas de saída.\nAdicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.\nA nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.\nVamos ver um exemplo.\nAqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.\nE, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.\nOu, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.\nAssim, o vetor de rótulo neste caso consiste sempre em duas classes.\nE este é o algoritmo para a nossa abordagem de ajuste fino.\nEntão, vamos ver a estrutura completa.\nConjunto de dados alimentado no FeSTE.\nE então o FeSTE executa a fase de entity linking.\nExtrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.\nEm seguida, reformulou a tarefa numa tarefa de sentence classification par a par.\nAplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.\nE agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.\nEm seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.\nPara avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.\nE como base de conhecimento, usamos a Wikipédia.\nProjetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.\nTambém dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.\nEm seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.\nUsamos na nossa base de experiências da arquitetura básica do BERT.\nAqui estão os resultados para as nossas experiências.\nPode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.\nE o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.\nEnquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.\nA nossa abordagem alcançou uma melhoria de seis por cento.\nQuando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.\nMas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.\nPara resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.\nUsa uma arquitetura para todas as tarefas e conjuntos de dados.\nE mantém o cabeçalho do modelo.\nMas acrescenta uma fase de reformulação.\nAumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.\nObrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, gostaria de falar sobre a nossa motivação para o raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mostramos aqui exemplos em que o raciocínio em vários passos é útil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É bom ter raciocínio interpretável multietapas como saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, certas suposições também se aplicam como no trabalho anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que a precisão das quantidades é conhecida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que também contém alguns cálculos repetitivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nestes passos obtemos os divisores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então neste terceiro passo nós conseguimos obter o quociente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Certo. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto torna o processo mais preciso.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, a expressão é representada por e i j o p.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Onde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, também temos a subtração com palavras aqui para representar a direção oposta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é bastante semelhante a relation extraction.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionamo-la ao próximo estado para se tornar uma nova quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim que obtemos as representações de quantidade, podemos começar a fazer inferência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, toda a expressão possível é igual a três vezes o número de operadores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, esta quantidade vem da expressão calculada anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então podemos finalmente obter esta expressão final q_3 vezes q_4.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também usamos este tau para representar quando devemos encerrar este processo de geração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também nos permite impor certas restrições do conhecimento anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Muito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, investigamos ainda mais os resultados no SVAMP.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso modelo faz alguma previsão como esta que está a produzir valores negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E observamos que estas duas expressões realmente têm classificações semelhantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, descobrimos ainda que esta restrição melhora muito para alguns modelos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também mostramos o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podemos realmente correlacionar esta expressão com a frase aqui. Certo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E somos capazes de fornecer um procedimento de resolução interpretável.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também temos certas limitações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Questões legais são parte integrante da vida de muitas pessoas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Todo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Antes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, lida com dois tipos de linguagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Linguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, há documentos longos que podem chegar a seis mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos agora falar sobre como recolhemos este conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Considerámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reunimos perguntas legais com referências a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Recolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Acabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vejamos algumas características do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O mais longo sendo até cinco mil setecentos e noventa palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o número total de artigos recolhidos de cada um destes códigos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos as funções de classificação TF-IDF e BM25 padrão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Observe que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o resultado da nossa linha de base nos conjuntos de teste.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos concluir discutindo duas limitações do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Durante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isso pode ajudar a melhorar o acesso à justiça para todos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Porque é que nos esforçámos para estabelecer este termo de comparação?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Bem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas sabemos o que os modelos realmente aprenderam?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a pontuação baixa para esta?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os modelos de linguagem e visão concentram-se na coisa certa?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou concentram-se em preconceitos como mostrado pelo trabalho anterior?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas como testamos se os modelos de linguagem e visão capturaram este fenómeno?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ao frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Frustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Contagem e correferência também são peças que possuem mais de um instrumento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para obter frustrações válidas, devemos agir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Duas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Talvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para mais métricas e resultados sobre eles, veja o nosso artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Gostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou explicar nesta ordem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro é um sistema chamado ARENA lançado em 2014.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A característica mais notável deste sistema é o extrator de problemas no canto superior direito.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Que deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por outras palavras, não pode ser usado para muitos projetos no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo é Glyph, anunciado recentemente em 2020.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Está disponível na internet e pode ser instalado através do pip.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O desempenho do modelo de text classification não é alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Apresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este método proposto pode ser usado para todos os repositórios em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, vou descrever o nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está um exemplo de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento são rotuladas como melhorias ou correções, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Configurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto pode ser considerado como uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Temos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes foram definidos com base em pesquisas anteriores e outros fatores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas os rótulos nem sempre são consistentes com cada repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Preparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, temos uma mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação não estão vinculadas a cada lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos uma regra de correspondência heurística para obter as versões anterior e seguinte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Análise do conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, explicarei o método proposto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um classificador que usa BERT ou CodeBERT e um gerador que usa BART.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação classificadas como outras são descartadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós modelamos a abordagem de abstractive summarization por dois métodos diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "OK, deixe-me explicar as experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Foram comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O BLEU é penalizado quando o sistema emite uma frase curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes resultados indicam que CEAS e CAS são significativamente afetados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está uma análise de erro.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, uma conclusão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos um novo conjunto de dados para geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem consultar o nosso conjunto de dados no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá. Chamo-me Asaf Harari.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, por vezes, estas características são limitadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A geração de características que usa outra fonte de dados pode adicionar informação substancial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "o nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Suponhamos que temos um conjunto de dados tabular e uma base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Precisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa estrutura FeSTE é exatamente esse processo automático.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo num conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados é um conjunto de dados universitário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A primeira fase do FeSTE é entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o texto é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Agora, precisamos de gerar ou extrair características do texto recuperado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, precisamos da fase de extração de características que inclui análise de texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Após a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro gere características no número de classes do conjunto de dados original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados original tem duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, o FeSTE gera duas novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada característica representa a probabilidade para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Receba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que nós sugerimos é adicionar outra fase de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma fase preliminar de ajuste fino multitarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando se afina o modelo de linguagem sobre n menos um conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A última geração em ajuste fino de multitarefa chamado MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E amostra um lote aleatório do conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso cenário, os conjuntos de dados tabulares variam no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Há muitas tarefas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN manteve número de classes, cabeçalhos, camadas de saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o vetor de rótulo neste caso consiste sempre em duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este é o algoritmo para a nossa abordagem de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, vamos ver a estrutura completa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então o FeSTE executa a fase de entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Extrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reformulou a tarefa numa tarefa de sentence classification par a par.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Projetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos na nossa base de experiências da arquitetura básica do BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados para as nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem alcançou uma melhoria de seis por cento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usa uma arquitetura para todas as tarefas e conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E mantém o cabeçalho do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas acrescenta uma fase de reformulação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "Olá. Chamo-me Asaf Harari.\nE vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.\nOs cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.\nMas, por vezes, estas características são limitadas.\nA geração de características que usa outra fonte de dados pode adicionar informação substancial.\no nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.\nSuponhamos que temos um conjunto de dados tabular e uma base de conhecimento.\nPrecisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.\nA nossa estrutura FeSTE é exatamente esse processo automático.\nVamos ver um exemplo num conjunto de dados alimentado no FeSTE.\nNeste exemplo, o conjunto de dados é um conjunto de dados universitário.\nQuando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.\nComo base de conhecimento, usamos a Wikipédia.\nA primeira fase do FeSTE é entity linking.\nQuando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.\nE o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.\nNeste exemplo, o texto é o resumo da página da Wikipédia.\nAgora, precisamos de gerar ou extrair características do texto recuperado.\nEntão, precisamos da fase de extração de características que inclui análise de texto.\nE esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.\nApós a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.\nPrimeiro gere características no número de classes do conjunto de dados original.\nNeste exemplo, o conjunto de dados original tem duas classes.\nEntão, o FeSTE gera duas novas características.\nMas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.\nCada característica representa a probabilidade para cada classe.\nPara analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.\nÉ, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.\nPortanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.\nAssim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.\nNeste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.\nReceba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.\nO problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.\nNa nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.\nEntão, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.\nMas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.\nAplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.\nO que nós sugerimos é adicionar outra fase de ajuste fino.\nUma fase preliminar de ajuste fino multitarefa.\nQuando se afina o modelo de linguagem sobre n menos um conjuntos de dados.\nE, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.\nA última geração em ajuste fino de multitarefa chamado MTDNN.\nO MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.\nNeste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.\nE amostra um lote aleatório do conjunto de treinamento.\nE se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.\nE se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.\nNo nosso cenário, os conjuntos de dados tabulares variam no número de classes.\nHá muitas tarefas.\nO MTDNN manteve número de classes, cabeçalhos, camadas de saída.\nAdicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.\nA nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.\nVamos ver um exemplo.\nAqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.\nE, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.\nOu, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.\nAssim, o vetor de rótulo neste caso consiste sempre em duas classes.\nE este é o algoritmo para a nossa abordagem de ajuste fino.\nEntão, vamos ver a estrutura completa.\nConjunto de dados alimentado no FeSTE.\nE então o FeSTE executa a fase de entity linking.\nExtrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.\nEm seguida, reformulou a tarefa numa tarefa de sentence classification par a par.\nAplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.\nE agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.\nEm seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.\nPara avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.\nE como base de conhecimento, usamos a Wikipédia.\nProjetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.\nTambém dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.\nEm seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.\nUsamos na nossa base de experiências da arquitetura básica do BERT.\nAqui estão os resultados para as nossas experiências.\nPode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.\nE o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.\nEnquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.\nA nossa abordagem alcançou uma melhoria de seis por cento.\nQuando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.\nMas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.\nPara resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.\nUsa uma arquitetura para todas as tarefas e conjuntos de dados.\nE mantém o cabeçalho do modelo.\nMas acrescenta uma fase de reformulação.\nAumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.\nObrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.\nSou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.\nPrimeiro, gostaria de falar sobre a nossa motivação para o raciocínio.\nMostramos aqui exemplos em que o raciocínio em vários passos é útil.\nEste número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.\nEntão, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.\nMas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.\nÉ bom ter raciocínio interpretável multietapas como saída.\nE também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.\nAqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.\nAssim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.\nAssim, certas suposições também se aplicam como no trabalho anterior.\nAssumimos que a precisão das quantidades é conhecida.\nE consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.\nAlém disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.\nAssim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.\nAssim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.\nE é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.\nMas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.\nMas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.\nEntão, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.\nEntão, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.\nO que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.\nE a segunda coisa é que também contém alguns cálculos repetitivos.\nAqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.\nEntão, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.\nEntão por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.\nE também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.\nE nestes passos obtemos os divisores.\nE então neste terceiro passo nós conseguimos obter o quociente.\nCerto. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.\nEntão, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.\nIsto torna o processo mais preciso.\nNo nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.\nAssim, a expressão é representada por e i j o p.\nOnde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.\nEntão, também temos a subtração com palavras aqui para representar a direção oposta.\nIsto é bastante semelhante a relation extraction.\nAssim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.\nAdicionamo-la ao próximo estado para se tornar uma nova quantidade.\nÉ possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.\nNas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.\nAssim que obtemos as representações de quantidade, podemos começar a fazer inferência.\nAqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.\nPrimeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.\nE então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.\nMas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.\nAqui, toda a expressão possível é igual a três vezes o número de operadores.\nO que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.\nPor exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.\nEntão, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.\nPortanto, esta quantidade vem da expressão calculada anterior.\nEntão podemos finalmente obter esta expressão final q_3 vezes q_4.\nE também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.\nEntão, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.\nAssim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.\nE aqui também usamos este tau para representar quando devemos encerrar este processo de geração.\nE aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.\nE também nos permite impor certas restrições do conhecimento anterior.\nAssim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.\nE aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.\nPortanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.\nE, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.\nMuito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.\nEntão, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.\nMas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.\nEntão, investigamos ainda mais os resultados no SVAMP.\nE este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.\nEntão, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.\nPor exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?\nMas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.\nO nosso modelo faz alguma previsão como esta que está a produzir valores negativos.\nE observamos que estas duas expressões realmente têm classificações semelhantes.\nEntão, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.\nEntão, descobrimos ainda que esta restrição melhora muito para alguns modelos.\nPor exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.\nUm melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.\nTambém tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.\nAssumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.\nEntão, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.\nE aqui também mostramos o desempenho geral.\nPara essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.\nMas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.\nPara MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.\nFinalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.\nAqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.\nPodemos realmente correlacionar esta expressão com a frase aqui. Certo.\nEntão, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.\nAqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.\nEntão tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.\nNós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.\nPortanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.\nEntão, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.\nE somos capazes de fornecer um procedimento de resolução interpretável.\nE podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.\nE a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.\nTambém temos certas limitações.\nSe tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.\nE a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.\nEste é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.\nVou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.\nQuestões legais são parte integrante da vida de muitas pessoas.\nMas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.\nComo resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.\nTodo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.\nTal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.\nAntes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.\nDada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?\nUm modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.\nEsta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.\nPrimeiro, lida com dois tipos de linguagem.\nLinguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.\nEsta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.\nAlém disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.\nEm vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.\nPor fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.\nAqui, há documentos longos que podem chegar a seis mil palavras.\nOs avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.\nMas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.\nNeste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.\nO nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.\nEstas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.\nCada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.\nVamos agora falar sobre como recolhemos este conjunto de dados.\nPrimeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.\nConsiderámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.\nEm seguida, reunimos perguntas legais com referências a estatutos relevantes.\nPara isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.\nTivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.\nRecolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.\nPor fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.\nAs referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.\nAcabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.\nAlém disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.\nE cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.\nEsta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.\nVejamos algumas características do nosso conjunto de dados.\nAs perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.\nOs artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.\nO mais longo sendo até cinco mil setecentos e noventa palavras.\nComo mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.\nEnquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.\nO artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.\nAqui está o número total de artigos recolhidos de cada um destes códigos belgas.\nDos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.\nE cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.\nEnquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.\nO que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.\nNo geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.\nUsando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.\nDada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.\nExperimentamos as funções de classificação TF-IDF e BM25 padrão.\nO principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.\nPara superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.\nUsamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.\nEstas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.\nPrimeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.\nNós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.\nAlém disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.\nObserve que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.\nO siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.\nNós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.\nAqui está o resultado da nossa linha de base nos conjuntos de teste.\nCom os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.\nNo geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.\nO modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.\nEmbora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.\nEm relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.\nAlém disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.\nEmbora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.\nVamos concluir discutindo duas limitações do nosso conjunto de dados.\nEm primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.\nDurante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.\nEsta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.\nEm segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.\nPor exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?\nPode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.\nEm vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.\nPor exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.\nConsequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.\nEsperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.\nIsso pode ajudar a melhorar o acesso à justiça para todos.\nPodem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.\nPorque é que nos esforçámos para estabelecer este termo de comparação?\nBem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.\nCada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.\nEntão, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.\nMas sabemos o que os modelos realmente aprenderam?\nO que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?\nE a pontuação baixa para esta?\nOs modelos de linguagem e visão concentram-se na coisa certa?\nOu concentram-se em preconceitos como mostrado pelo trabalho anterior?\nPara lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.\nTomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.\nMas como testamos se os modelos de linguagem e visão capturaram este fenómeno?\nAo frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.\nFrustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.\nE fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.\nPor exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.\nContagem e correferência também são peças que possuem mais de um instrumento.\nE nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.\nIsto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.\nPor exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.\nAssim, para obter frustrações válidas, devemos agir.\nPrimeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.\nEm segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.\nPara testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.\nConsideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.\nAlém disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.\nSe um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.\nSe uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.\nMas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.\nAssim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.\nAssim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.\nPode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.\nUma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.\nO ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.\nE todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.\nE, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.\nExperimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.\nDuas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.\nTalvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.\nPara mais métricas e resultados sobre eles, veja o nosso artigo.\nOs resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.\nÉ notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.\nNo entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.\nVemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.\nA peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.\nTambém têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.\nA partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.\nComo uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.\nSe a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.\nE é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.\nEntão, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.\nAs nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.\nGostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.\nE além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.\nSe houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.\nVou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.\nVou explicar nesta ordem.\nPrimeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.\nUma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.\nA imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.\nAs notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.\nAssim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.\nVou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.\nO primeiro é um sistema chamado ARENA lançado em 2014.\nÉ precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.\nA característica mais notável deste sistema é o extrator de problemas no canto superior direito.\nQue deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.\nPor outras palavras, não pode ser usado para muitos projetos no GitHub.\nO segundo é Glyph, anunciado recentemente em 2020.\nEstá disponível na internet e pode ser instalado através do pip.\nEste sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.\nEsta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.\nOs dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.\nO desempenho do modelo de text classification não é alto.\nApresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.\nO nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.\nCom um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.\nEste método proposto pode ser usado para todos os repositórios em inglês.\nPara o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.\nEm seguida, vou descrever o nosso conjunto de dados.\nAqui está um exemplo de dados.\nO lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.\nAs notas de lançamento são rotuladas como melhorias ou correções, etc.\nConfigurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.\nIsto pode ser considerado como uma tarefa de sumarização.\nTemos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.\nEstes foram definidos com base em pesquisas anteriores e outros fatores.\nA nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.\nNeste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.\nMas os rótulos nem sempre são consistentes com cada repositório.\nPor exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.\nPreparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.\nIsto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.\nEm seguida, temos uma mensagem de confirmação.\nAs mensagens de confirmação não estão vinculadas a cada lançamento.\nComo mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.\nIsto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.\nCriámos uma regra de correspondência heurística para obter as versões anterior e seguinte.\nAnálise do conjunto de dados.\nNo final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.\nAlém disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.\nAlém disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.\nIsto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.\nEm seguida, explicarei o método proposto.\nO extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.\nUm classificador que usa BERT ou CodeBERT e um gerador que usa BART.\nPrimeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.\nAs mensagens de confirmação classificadas como outras são descartadas.\nEm seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.\nNesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.\nAssim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.\nNós modelamos a abordagem de abstractive summarization por dois métodos diferentes.\nO primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.\nOs textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.\nO segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.\nOK, deixe-me explicar as experiências.\nForam comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.\nEm relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.\nComo é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.\nO BLEU é penalizado quando o sistema emite uma frase curta.\nEsta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.\nFinalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.\nUma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.\nAqui estão os resultados.\nComo o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.\nCEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.\nEm particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.\nEstes resultados indicam que CEAS e CAS são significativamente afetados.\nCEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.\nA alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.\nO CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.\nSugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.\nAqui está uma análise de erro.\nOs métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.\nNa figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.\nA razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.\nAlém disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.\nO exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.\nO exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.\nPor fim, uma conclusão.\nCriámos um novo conjunto de dados para geração automática de notas de lançamento.\nTambém formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.\nAs nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.\nPodem consultar o nosso conjunto de dados no GitHub.\nObrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, gostaria de falar sobre a nossa motivação para o raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mostramos aqui exemplos em que o raciocínio em vários passos é útil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É bom ter raciocínio interpretável multietapas como saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, certas suposições também se aplicam como no trabalho anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que a precisão das quantidades é conhecida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que também contém alguns cálculos repetitivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nestes passos obtemos os divisores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então neste terceiro passo nós conseguimos obter o quociente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Certo. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto torna o processo mais preciso.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, a expressão é representada por e i j o p.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Onde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, também temos a subtração com palavras aqui para representar a direção oposta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é bastante semelhante a relation extraction.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionamo-la ao próximo estado para se tornar uma nova quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim que obtemos as representações de quantidade, podemos começar a fazer inferência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, toda a expressão possível é igual a três vezes o número de operadores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, esta quantidade vem da expressão calculada anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então podemos finalmente obter esta expressão final q_3 vezes q_4.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também usamos este tau para representar quando devemos encerrar este processo de geração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também nos permite impor certas restrições do conhecimento anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Muito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, investigamos ainda mais os resultados no SVAMP.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso modelo faz alguma previsão como esta que está a produzir valores negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E observamos que estas duas expressões realmente têm classificações semelhantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, descobrimos ainda que esta restrição melhora muito para alguns modelos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também mostramos o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podemos realmente correlacionar esta expressão com a frase aqui. Certo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E somos capazes de fornecer um procedimento de resolução interpretável.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também temos certas limitações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Questões legais são parte integrante da vida de muitas pessoas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Todo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Antes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, lida com dois tipos de linguagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Linguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, há documentos longos que podem chegar a seis mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos agora falar sobre como recolhemos este conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Considerámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reunimos perguntas legais com referências a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Recolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Acabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vejamos algumas características do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O mais longo sendo até cinco mil setecentos e noventa palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o número total de artigos recolhidos de cada um destes códigos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos as funções de classificação TF-IDF e BM25 padrão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Observe que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o resultado da nossa linha de base nos conjuntos de teste.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos concluir discutindo duas limitações do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Durante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isso pode ajudar a melhorar o acesso à justiça para todos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Porque é que nos esforçámos para estabelecer este termo de comparação?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Bem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas sabemos o que os modelos realmente aprenderam?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a pontuação baixa para esta?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os modelos de linguagem e visão concentram-se na coisa certa?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou concentram-se em preconceitos como mostrado pelo trabalho anterior?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas como testamos se os modelos de linguagem e visão capturaram este fenómeno?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ao frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Frustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Contagem e correferência também são peças que possuem mais de um instrumento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para obter frustrações válidas, devemos agir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Duas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Talvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para mais métricas e resultados sobre eles, veja o nosso artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Gostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou explicar nesta ordem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro é um sistema chamado ARENA lançado em 2014.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A característica mais notável deste sistema é o extrator de problemas no canto superior direito.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Que deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por outras palavras, não pode ser usado para muitos projetos no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo é Glyph, anunciado recentemente em 2020.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Está disponível na internet e pode ser instalado através do pip.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O desempenho do modelo de text classification não é alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Apresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este método proposto pode ser usado para todos os repositórios em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, vou descrever o nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está um exemplo de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento são rotuladas como melhorias ou correções, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Configurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto pode ser considerado como uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Temos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes foram definidos com base em pesquisas anteriores e outros fatores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas os rótulos nem sempre são consistentes com cada repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Preparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, temos uma mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação não estão vinculadas a cada lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos uma regra de correspondência heurística para obter as versões anterior e seguinte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Análise do conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, explicarei o método proposto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um classificador que usa BERT ou CodeBERT e um gerador que usa BART.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação classificadas como outras são descartadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós modelamos a abordagem de abstractive summarization por dois métodos diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "OK, deixe-me explicar as experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Foram comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O BLEU é penalizado quando o sistema emite uma frase curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes resultados indicam que CEAS e CAS são significativamente afetados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está uma análise de erro.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, uma conclusão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos um novo conjunto de dados para geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem consultar o nosso conjunto de dados no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá. Chamo-me Asaf Harari.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, por vezes, estas características são limitadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A geração de características que usa outra fonte de dados pode adicionar informação substancial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "o nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Suponhamos que temos um conjunto de dados tabular e uma base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Precisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa estrutura FeSTE é exatamente esse processo automático.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo num conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados é um conjunto de dados universitário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A primeira fase do FeSTE é entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o texto é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Agora, precisamos de gerar ou extrair características do texto recuperado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, precisamos da fase de extração de características que inclui análise de texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Após a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro gere características no número de classes do conjunto de dados original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados original tem duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, o FeSTE gera duas novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada característica representa a probabilidade para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Receba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que nós sugerimos é adicionar outra fase de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma fase preliminar de ajuste fino multitarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando se afina o modelo de linguagem sobre n menos um conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A última geração em ajuste fino de multitarefa chamado MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E amostra um lote aleatório do conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso cenário, os conjuntos de dados tabulares variam no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Há muitas tarefas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN manteve número de classes, cabeçalhos, camadas de saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o vetor de rótulo neste caso consiste sempre em duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este é o algoritmo para a nossa abordagem de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, vamos ver a estrutura completa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então o FeSTE executa a fase de entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Extrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reformulou a tarefa numa tarefa de sentence classification par a par.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Projetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos na nossa base de experiências da arquitetura básica do BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados para as nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem alcançou uma melhoria de seis por cento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usa uma arquitetura para todas as tarefas e conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E mantém o cabeçalho do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas acrescenta uma fase de reformulação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "Olá. Chamo-me Asaf Harari.\nE vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.\nOs cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.\nMas, por vezes, estas características são limitadas.\nA geração de características que usa outra fonte de dados pode adicionar informação substancial.\no nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.\nSuponhamos que temos um conjunto de dados tabular e uma base de conhecimento.\nPrecisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.\nA nossa estrutura FeSTE é exatamente esse processo automático.\nVamos ver um exemplo num conjunto de dados alimentado no FeSTE.\nNeste exemplo, o conjunto de dados é um conjunto de dados universitário.\nQuando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.\nComo base de conhecimento, usamos a Wikipédia.\nA primeira fase do FeSTE é entity linking.\nQuando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.\nE o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.\nNeste exemplo, o texto é o resumo da página da Wikipédia.\nAgora, precisamos de gerar ou extrair características do texto recuperado.\nEntão, precisamos da fase de extração de características que inclui análise de texto.\nE esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.\nApós a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.\nPrimeiro gere características no número de classes do conjunto de dados original.\nNeste exemplo, o conjunto de dados original tem duas classes.\nEntão, o FeSTE gera duas novas características.\nMas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.\nCada característica representa a probabilidade para cada classe.\nPara analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.\nÉ, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.\nPortanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.\nAssim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.\nNeste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.\nReceba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.\nO problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.\nNa nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.\nEntão, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.\nMas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.\nAplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.\nO que nós sugerimos é adicionar outra fase de ajuste fino.\nUma fase preliminar de ajuste fino multitarefa.\nQuando se afina o modelo de linguagem sobre n menos um conjuntos de dados.\nE, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.\nA última geração em ajuste fino de multitarefa chamado MTDNN.\nO MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.\nNeste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.\nE amostra um lote aleatório do conjunto de treinamento.\nE se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.\nE se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.\nNo nosso cenário, os conjuntos de dados tabulares variam no número de classes.\nHá muitas tarefas.\nO MTDNN manteve número de classes, cabeçalhos, camadas de saída.\nAdicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.\nA nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.\nVamos ver um exemplo.\nAqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.\nE, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.\nOu, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.\nAssim, o vetor de rótulo neste caso consiste sempre em duas classes.\nE este é o algoritmo para a nossa abordagem de ajuste fino.\nEntão, vamos ver a estrutura completa.\nConjunto de dados alimentado no FeSTE.\nE então o FeSTE executa a fase de entity linking.\nExtrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.\nEm seguida, reformulou a tarefa numa tarefa de sentence classification par a par.\nAplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.\nE agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.\nEm seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.\nPara avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.\nE como base de conhecimento, usamos a Wikipédia.\nProjetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.\nTambém dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.\nEm seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.\nUsamos na nossa base de experiências da arquitetura básica do BERT.\nAqui estão os resultados para as nossas experiências.\nPode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.\nE o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.\nEnquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.\nA nossa abordagem alcançou uma melhoria de seis por cento.\nQuando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.\nMas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.\nPara resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.\nUsa uma arquitetura para todas as tarefas e conjuntos de dados.\nE mantém o cabeçalho do modelo.\nMas acrescenta uma fase de reformulação.\nAumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.\nObrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.\nSou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.\nPrimeiro, gostaria de falar sobre a nossa motivação para o raciocínio.\nMostramos aqui exemplos em que o raciocínio em vários passos é útil.\nEste número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.\nEntão, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.\nMas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.\nÉ bom ter raciocínio interpretável multietapas como saída.\nE também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.\nAqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.\nAssim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.\nAssim, certas suposições também se aplicam como no trabalho anterior.\nAssumimos que a precisão das quantidades é conhecida.\nE consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.\nAlém disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.\nAssim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.\nAssim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.\nE é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.\nMas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.\nMas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.\nEntão, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.\nEntão, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.\nO que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.\nE a segunda coisa é que também contém alguns cálculos repetitivos.\nAqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.\nEntão, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.\nEntão por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.\nE também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.\nE nestes passos obtemos os divisores.\nE então neste terceiro passo nós conseguimos obter o quociente.\nCerto. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.\nEntão, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.\nIsto torna o processo mais preciso.\nNo nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.\nAssim, a expressão é representada por e i j o p.\nOnde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.\nEntão, também temos a subtração com palavras aqui para representar a direção oposta.\nIsto é bastante semelhante a relation extraction.\nAssim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.\nAdicionamo-la ao próximo estado para se tornar uma nova quantidade.\nÉ possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.\nNas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.\nAssim que obtemos as representações de quantidade, podemos começar a fazer inferência.\nAqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.\nPrimeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.\nE então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.\nMas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.\nAqui, toda a expressão possível é igual a três vezes o número de operadores.\nO que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.\nPor exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.\nEntão, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.\nPortanto, esta quantidade vem da expressão calculada anterior.\nEntão podemos finalmente obter esta expressão final q_3 vezes q_4.\nE também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.\nEntão, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.\nAssim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.\nE aqui também usamos este tau para representar quando devemos encerrar este processo de geração.\nE aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.\nE também nos permite impor certas restrições do conhecimento anterior.\nAssim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.\nE aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.\nPortanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.\nE, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.\nMuito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.\nEntão, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.\nMas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.\nEntão, investigamos ainda mais os resultados no SVAMP.\nE este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.\nEntão, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.\nPor exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?\nMas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.\nO nosso modelo faz alguma previsão como esta que está a produzir valores negativos.\nE observamos que estas duas expressões realmente têm classificações semelhantes.\nEntão, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.\nEntão, descobrimos ainda que esta restrição melhora muito para alguns modelos.\nPor exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.\nUm melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.\nTambém tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.\nAssumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.\nEntão, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.\nE aqui também mostramos o desempenho geral.\nPara essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.\nMas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.\nPara MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.\nFinalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.\nAqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.\nPodemos realmente correlacionar esta expressão com a frase aqui. Certo.\nEntão, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.\nAqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.\nEntão tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.\nNós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.\nPortanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.\nEntão, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.\nE somos capazes de fornecer um procedimento de resolução interpretável.\nE podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.\nE a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.\nTambém temos certas limitações.\nSe tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.\nE a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.\nEste é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.\nVou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.\nQuestões legais são parte integrante da vida de muitas pessoas.\nMas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.\nComo resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.\nTodo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.\nTal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.\nAntes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.\nDada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?\nUm modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.\nEsta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.\nPrimeiro, lida com dois tipos de linguagem.\nLinguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.\nEsta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.\nAlém disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.\nEm vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.\nPor fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.\nAqui, há documentos longos que podem chegar a seis mil palavras.\nOs avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.\nMas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.\nNeste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.\nO nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.\nEstas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.\nCada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.\nVamos agora falar sobre como recolhemos este conjunto de dados.\nPrimeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.\nConsiderámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.\nEm seguida, reunimos perguntas legais com referências a estatutos relevantes.\nPara isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.\nTivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.\nRecolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.\nPor fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.\nAs referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.\nAcabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.\nAlém disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.\nE cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.\nEsta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.\nVejamos algumas características do nosso conjunto de dados.\nAs perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.\nOs artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.\nO mais longo sendo até cinco mil setecentos e noventa palavras.\nComo mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.\nEnquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.\nO artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.\nAqui está o número total de artigos recolhidos de cada um destes códigos belgas.\nDos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.\nE cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.\nEnquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.\nO que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.\nNo geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.\nUsando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.\nDada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.\nExperimentamos as funções de classificação TF-IDF e BM25 padrão.\nO principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.\nPara superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.\nUsamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.\nEstas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.\nPrimeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.\nNós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.\nAlém disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.\nObserve que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.\nO siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.\nNós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.\nAqui está o resultado da nossa linha de base nos conjuntos de teste.\nCom os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.\nNo geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.\nO modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.\nEmbora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.\nEm relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.\nAlém disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.\nEmbora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.\nVamos concluir discutindo duas limitações do nosso conjunto de dados.\nEm primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.\nDurante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.\nEsta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.\nEm segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.\nPor exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?\nPode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.\nEm vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.\nPor exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.\nConsequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.\nEsperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.\nIsso pode ajudar a melhorar o acesso à justiça para todos.\nPodem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.\nPorque é que nos esforçámos para estabelecer este termo de comparação?\nBem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.\nCada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.\nEntão, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.\nMas sabemos o que os modelos realmente aprenderam?\nO que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?\nE a pontuação baixa para esta?\nOs modelos de linguagem e visão concentram-se na coisa certa?\nOu concentram-se em preconceitos como mostrado pelo trabalho anterior?\nPara lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.\nTomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.\nMas como testamos se os modelos de linguagem e visão capturaram este fenómeno?\nAo frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.\nFrustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.\nE fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.\nPor exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.\nContagem e correferência também são peças que possuem mais de um instrumento.\nE nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.\nIsto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.\nPor exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.\nAssim, para obter frustrações válidas, devemos agir.\nPrimeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.\nEm segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.\nPara testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.\nConsideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.\nAlém disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.\nSe um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.\nSe uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.\nMas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.\nAssim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.\nAssim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.\nPode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.\nUma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.\nO ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.\nE todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.\nE, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.\nExperimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.\nDuas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.\nTalvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.\nPara mais métricas e resultados sobre eles, veja o nosso artigo.\nOs resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.\nÉ notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.\nNo entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.\nVemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.\nA peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.\nTambém têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.\nA partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.\nComo uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.\nSe a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.\nE é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.\nEntão, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.\nAs nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.\nGostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.\nE além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.\nSe houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.\nVou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.\nVou explicar nesta ordem.\nPrimeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.\nUma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.\nA imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.\nAs notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.\nAssim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.\nVou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.\nO primeiro é um sistema chamado ARENA lançado em 2014.\nÉ precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.\nA característica mais notável deste sistema é o extrator de problemas no canto superior direito.\nQue deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.\nPor outras palavras, não pode ser usado para muitos projetos no GitHub.\nO segundo é Glyph, anunciado recentemente em 2020.\nEstá disponível na internet e pode ser instalado através do pip.\nEste sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.\nEsta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.\nOs dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.\nO desempenho do modelo de text classification não é alto.\nApresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.\nO nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.\nCom um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.\nEste método proposto pode ser usado para todos os repositórios em inglês.\nPara o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.\nEm seguida, vou descrever o nosso conjunto de dados.\nAqui está um exemplo de dados.\nO lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.\nAs notas de lançamento são rotuladas como melhorias ou correções, etc.\nConfigurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.\nIsto pode ser considerado como uma tarefa de sumarização.\nTemos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.\nEstes foram definidos com base em pesquisas anteriores e outros fatores.\nA nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.\nNeste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.\nMas os rótulos nem sempre são consistentes com cada repositório.\nPor exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.\nPreparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.\nIsto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.\nEm seguida, temos uma mensagem de confirmação.\nAs mensagens de confirmação não estão vinculadas a cada lançamento.\nComo mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.\nIsto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.\nCriámos uma regra de correspondência heurística para obter as versões anterior e seguinte.\nAnálise do conjunto de dados.\nNo final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.\nAlém disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.\nAlém disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.\nIsto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.\nEm seguida, explicarei o método proposto.\nO extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.\nUm classificador que usa BERT ou CodeBERT e um gerador que usa BART.\nPrimeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.\nAs mensagens de confirmação classificadas como outras são descartadas.\nEm seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.\nNesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.\nAssim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.\nNós modelamos a abordagem de abstractive summarization por dois métodos diferentes.\nO primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.\nOs textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.\nO segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.\nOK, deixe-me explicar as experiências.\nForam comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.\nEm relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.\nComo é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.\nO BLEU é penalizado quando o sistema emite uma frase curta.\nEsta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.\nFinalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.\nUma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.\nAqui estão os resultados.\nComo o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.\nCEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.\nEm particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.\nEstes resultados indicam que CEAS e CAS são significativamente afetados.\nCEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.\nA alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.\nO CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.\nSugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.\nAqui está uma análise de erro.\nOs métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.\nNa figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.\nA razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.\nAlém disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.\nO exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.\nO exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.\nPor fim, uma conclusão.\nCriámos um novo conjunto de dados para geração automática de notas de lançamento.\nTambém formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.\nAs nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.\nPodem consultar o nosso conjunto de dados no GitHub.\nObrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, gostaria de falar sobre a nossa motivação para o raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mostramos aqui exemplos em que o raciocínio em vários passos é útil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É bom ter raciocínio interpretável multietapas como saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, certas suposições também se aplicam como no trabalho anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que a precisão das quantidades é conhecida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que também contém alguns cálculos repetitivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nestes passos obtemos os divisores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então neste terceiro passo nós conseguimos obter o quociente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Certo. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto torna o processo mais preciso.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, a expressão é representada por e i j o p.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Onde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, também temos a subtração com palavras aqui para representar a direção oposta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é bastante semelhante a relation extraction.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionamo-la ao próximo estado para se tornar uma nova quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim que obtemos as representações de quantidade, podemos começar a fazer inferência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, toda a expressão possível é igual a três vezes o número de operadores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, esta quantidade vem da expressão calculada anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então podemos finalmente obter esta expressão final q_3 vezes q_4.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também usamos este tau para representar quando devemos encerrar este processo de geração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também nos permite impor certas restrições do conhecimento anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Muito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, investigamos ainda mais os resultados no SVAMP.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso modelo faz alguma previsão como esta que está a produzir valores negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E observamos que estas duas expressões realmente têm classificações semelhantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, descobrimos ainda que esta restrição melhora muito para alguns modelos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também mostramos o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podemos realmente correlacionar esta expressão com a frase aqui. Certo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E somos capazes de fornecer um procedimento de resolução interpretável.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também temos certas limitações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Questões legais são parte integrante da vida de muitas pessoas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Todo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Antes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, lida com dois tipos de linguagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Linguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, há documentos longos que podem chegar a seis mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos agora falar sobre como recolhemos este conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Considerámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reunimos perguntas legais com referências a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Recolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Acabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vejamos algumas características do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O mais longo sendo até cinco mil setecentos e noventa palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o número total de artigos recolhidos de cada um destes códigos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos as funções de classificação TF-IDF e BM25 padrão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Observe que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o resultado da nossa linha de base nos conjuntos de teste.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos concluir discutindo duas limitações do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Durante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isso pode ajudar a melhorar o acesso à justiça para todos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Porque é que nos esforçámos para estabelecer este termo de comparação?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Bem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas sabemos o que os modelos realmente aprenderam?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a pontuação baixa para esta?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os modelos de linguagem e visão concentram-se na coisa certa?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou concentram-se em preconceitos como mostrado pelo trabalho anterior?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas como testamos se os modelos de linguagem e visão capturaram este fenómeno?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ao frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Frustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Contagem e correferência também são peças que possuem mais de um instrumento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para obter frustrações válidas, devemos agir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Duas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Talvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para mais métricas e resultados sobre eles, veja o nosso artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Gostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou explicar nesta ordem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro é um sistema chamado ARENA lançado em 2014.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A característica mais notável deste sistema é o extrator de problemas no canto superior direito.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Que deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por outras palavras, não pode ser usado para muitos projetos no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo é Glyph, anunciado recentemente em 2020.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Está disponível na internet e pode ser instalado através do pip.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O desempenho do modelo de text classification não é alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Apresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este método proposto pode ser usado para todos os repositórios em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, vou descrever o nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está um exemplo de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento são rotuladas como melhorias ou correções, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Configurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto pode ser considerado como uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Temos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes foram definidos com base em pesquisas anteriores e outros fatores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas os rótulos nem sempre são consistentes com cada repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Preparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, temos uma mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação não estão vinculadas a cada lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos uma regra de correspondência heurística para obter as versões anterior e seguinte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Análise do conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, explicarei o método proposto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um classificador que usa BERT ou CodeBERT e um gerador que usa BART.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação classificadas como outras são descartadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós modelamos a abordagem de abstractive summarization por dois métodos diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "OK, deixe-me explicar as experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Foram comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O BLEU é penalizado quando o sistema emite uma frase curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes resultados indicam que CEAS e CAS são significativamente afetados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está uma análise de erro.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, uma conclusão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos um novo conjunto de dados para geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem consultar o nosso conjunto de dados no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá. Chamo-me Asaf Harari.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, por vezes, estas características são limitadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A geração de características que usa outra fonte de dados pode adicionar informação substancial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "o nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Suponhamos que temos um conjunto de dados tabular e uma base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Precisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa estrutura FeSTE é exatamente esse processo automático.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo num conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados é um conjunto de dados universitário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A primeira fase do FeSTE é entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o texto é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Agora, precisamos de gerar ou extrair características do texto recuperado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, precisamos da fase de extração de características que inclui análise de texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Após a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro gere características no número de classes do conjunto de dados original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados original tem duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, o FeSTE gera duas novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada característica representa a probabilidade para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Receba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que nós sugerimos é adicionar outra fase de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma fase preliminar de ajuste fino multitarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando se afina o modelo de linguagem sobre n menos um conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A última geração em ajuste fino de multitarefa chamado MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E amostra um lote aleatório do conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso cenário, os conjuntos de dados tabulares variam no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Há muitas tarefas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN manteve número de classes, cabeçalhos, camadas de saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o vetor de rótulo neste caso consiste sempre em duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este é o algoritmo para a nossa abordagem de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, vamos ver a estrutura completa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então o FeSTE executa a fase de entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Extrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reformulou a tarefa numa tarefa de sentence classification par a par.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Projetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos na nossa base de experiências da arquitetura básica do BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados para as nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem alcançou uma melhoria de seis por cento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usa uma arquitetura para todas as tarefas e conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E mantém o cabeçalho do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas acrescenta uma fase de reformulação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "Olá. Chamo-me Asaf Harari.\nE vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.\nOs cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.\nMas, por vezes, estas características são limitadas.\nA geração de características que usa outra fonte de dados pode adicionar informação substancial.\no nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.\nSuponhamos que temos um conjunto de dados tabular e uma base de conhecimento.\nPrecisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.\nA nossa estrutura FeSTE é exatamente esse processo automático.\nVamos ver um exemplo num conjunto de dados alimentado no FeSTE.\nNeste exemplo, o conjunto de dados é um conjunto de dados universitário.\nQuando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.\nComo base de conhecimento, usamos a Wikipédia.\nA primeira fase do FeSTE é entity linking.\nQuando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.\nE o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.\nNeste exemplo, o texto é o resumo da página da Wikipédia.\nAgora, precisamos de gerar ou extrair características do texto recuperado.\nEntão, precisamos da fase de extração de características que inclui análise de texto.\nE esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.\nApós a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.\nPrimeiro gere características no número de classes do conjunto de dados original.\nNeste exemplo, o conjunto de dados original tem duas classes.\nEntão, o FeSTE gera duas novas características.\nMas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.\nCada característica representa a probabilidade para cada classe.\nPara analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.\nÉ, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.\nPortanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.\nAssim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.\nNeste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.\nReceba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.\nO problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.\nNa nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.\nEntão, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.\nMas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.\nAplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.\nO que nós sugerimos é adicionar outra fase de ajuste fino.\nUma fase preliminar de ajuste fino multitarefa.\nQuando se afina o modelo de linguagem sobre n menos um conjuntos de dados.\nE, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.\nA última geração em ajuste fino de multitarefa chamado MTDNN.\nO MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.\nNeste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.\nE amostra um lote aleatório do conjunto de treinamento.\nE se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.\nE se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.\nNo nosso cenário, os conjuntos de dados tabulares variam no número de classes.\nHá muitas tarefas.\nO MTDNN manteve número de classes, cabeçalhos, camadas de saída.\nAdicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.\nA nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.\nVamos ver um exemplo.\nAqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.\nE, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.\nOu, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.\nAssim, o vetor de rótulo neste caso consiste sempre em duas classes.\nE este é o algoritmo para a nossa abordagem de ajuste fino.\nEntão, vamos ver a estrutura completa.\nConjunto de dados alimentado no FeSTE.\nE então o FeSTE executa a fase de entity linking.\nExtrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.\nEm seguida, reformulou a tarefa numa tarefa de sentence classification par a par.\nAplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.\nE agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.\nEm seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.\nPara avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.\nE como base de conhecimento, usamos a Wikipédia.\nProjetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.\nTambém dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.\nEm seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.\nUsamos na nossa base de experiências da arquitetura básica do BERT.\nAqui estão os resultados para as nossas experiências.\nPode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.\nE o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.\nEnquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.\nA nossa abordagem alcançou uma melhoria de seis por cento.\nQuando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.\nMas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.\nPara resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.\nUsa uma arquitetura para todas as tarefas e conjuntos de dados.\nE mantém o cabeçalho do modelo.\nMas acrescenta uma fase de reformulação.\nAumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.\nObrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.\nSou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.\nPrimeiro, gostaria de falar sobre a nossa motivação para o raciocínio.\nMostramos aqui exemplos em que o raciocínio em vários passos é útil.\nEste número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.\nEntão, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.\nMas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.\nÉ bom ter raciocínio interpretável multietapas como saída.\nE também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.\nAqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.\nAssim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.\nAssim, certas suposições também se aplicam como no trabalho anterior.\nAssumimos que a precisão das quantidades é conhecida.\nE consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.\nAlém disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.\nAssim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.\nAssim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.\nE é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.\nMas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.\nMas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.\nEntão, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.\nEntão, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.\nO que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.\nE a segunda coisa é que também contém alguns cálculos repetitivos.\nAqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.\nEntão, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.\nEntão por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.\nE também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.\nE nestes passos obtemos os divisores.\nE então neste terceiro passo nós conseguimos obter o quociente.\nCerto. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.\nEntão, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.\nIsto torna o processo mais preciso.\nNo nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.\nAssim, a expressão é representada por e i j o p.\nOnde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.\nEntão, também temos a subtração com palavras aqui para representar a direção oposta.\nIsto é bastante semelhante a relation extraction.\nAssim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.\nAdicionamo-la ao próximo estado para se tornar uma nova quantidade.\nÉ possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.\nNas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.\nAssim que obtemos as representações de quantidade, podemos começar a fazer inferência.\nAqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.\nPrimeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.\nE então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.\nMas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.\nAqui, toda a expressão possível é igual a três vezes o número de operadores.\nO que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.\nPor exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.\nEntão, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.\nPortanto, esta quantidade vem da expressão calculada anterior.\nEntão podemos finalmente obter esta expressão final q_3 vezes q_4.\nE também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.\nEntão, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.\nAssim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.\nE aqui também usamos este tau para representar quando devemos encerrar este processo de geração.\nE aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.\nE também nos permite impor certas restrições do conhecimento anterior.\nAssim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.\nE aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.\nPortanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.\nE, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.\nMuito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.\nEntão, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.\nMas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.\nEntão, investigamos ainda mais os resultados no SVAMP.\nE este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.\nEntão, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.\nPor exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?\nMas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.\nO nosso modelo faz alguma previsão como esta que está a produzir valores negativos.\nE observamos que estas duas expressões realmente têm classificações semelhantes.\nEntão, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.\nEntão, descobrimos ainda que esta restrição melhora muito para alguns modelos.\nPor exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.\nUm melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.\nTambém tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.\nAssumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.\nEntão, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.\nE aqui também mostramos o desempenho geral.\nPara essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.\nMas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.\nPara MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.\nFinalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.\nAqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.\nPodemos realmente correlacionar esta expressão com a frase aqui. Certo.\nEntão, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.\nAqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.\nEntão tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.\nNós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.\nPortanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.\nEntão, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.\nE somos capazes de fornecer um procedimento de resolução interpretável.\nE podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.\nE a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.\nTambém temos certas limitações.\nSe tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.\nE a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.\nEste é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.\nVou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.\nQuestões legais são parte integrante da vida de muitas pessoas.\nMas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.\nComo resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.\nTodo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.\nTal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.\nAntes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.\nDada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?\nUm modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.\nEsta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.\nPrimeiro, lida com dois tipos de linguagem.\nLinguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.\nEsta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.\nAlém disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.\nEm vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.\nPor fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.\nAqui, há documentos longos que podem chegar a seis mil palavras.\nOs avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.\nMas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.\nNeste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.\nO nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.\nEstas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.\nCada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.\nVamos agora falar sobre como recolhemos este conjunto de dados.\nPrimeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.\nConsiderámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.\nEm seguida, reunimos perguntas legais com referências a estatutos relevantes.\nPara isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.\nTivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.\nRecolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.\nPor fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.\nAs referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.\nAcabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.\nAlém disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.\nE cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.\nEsta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.\nVejamos algumas características do nosso conjunto de dados.\nAs perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.\nOs artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.\nO mais longo sendo até cinco mil setecentos e noventa palavras.\nComo mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.\nEnquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.\nO artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.\nAqui está o número total de artigos recolhidos de cada um destes códigos belgas.\nDos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.\nE cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.\nEnquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.\nO que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.\nNo geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.\nUsando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.\nDada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.\nExperimentamos as funções de classificação TF-IDF e BM25 padrão.\nO principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.\nPara superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.\nUsamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.\nEstas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.\nPrimeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.\nNós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.\nAlém disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.\nObserve que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.\nO siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.\nNós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.\nAqui está o resultado da nossa linha de base nos conjuntos de teste.\nCom os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.\nNo geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.\nO modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.\nEmbora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.\nEm relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.\nAlém disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.\nEmbora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.\nVamos concluir discutindo duas limitações do nosso conjunto de dados.\nEm primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.\nDurante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.\nEsta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.\nEm segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.\nPor exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?\nPode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.\nEm vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.\nPor exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.\nConsequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.\nEsperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.\nIsso pode ajudar a melhorar o acesso à justiça para todos.\nPodem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.\nPorque é que nos esforçámos para estabelecer este termo de comparação?\nBem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.\nCada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.\nEntão, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.\nMas sabemos o que os modelos realmente aprenderam?\nO que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?\nE a pontuação baixa para esta?\nOs modelos de linguagem e visão concentram-se na coisa certa?\nOu concentram-se em preconceitos como mostrado pelo trabalho anterior?\nPara lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.\nTomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.\nMas como testamos se os modelos de linguagem e visão capturaram este fenómeno?\nAo frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.\nFrustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.\nE fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.\nPor exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.\nContagem e correferência também são peças que possuem mais de um instrumento.\nE nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.\nIsto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.\nPor exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.\nAssim, para obter frustrações válidas, devemos agir.\nPrimeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.\nEm segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.\nPara testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.\nConsideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.\nAlém disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.\nSe um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.\nSe uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.\nMas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.\nAssim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.\nAssim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.\nPode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.\nUma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.\nO ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.\nE todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.\nE, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.\nExperimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.\nDuas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.\nTalvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.\nPara mais métricas e resultados sobre eles, veja o nosso artigo.\nOs resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.\nÉ notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.\nNo entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.\nVemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.\nA peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.\nTambém têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.\nA partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.\nComo uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.\nSe a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.\nE é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.\nEntão, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.\nAs nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.\nGostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.\nE além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.\nSe houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.\nVou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.\nVou explicar nesta ordem.\nPrimeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.\nUma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.\nA imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.\nAs notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.\nAssim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.\nVou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.\nO primeiro é um sistema chamado ARENA lançado em 2014.\nÉ precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.\nA característica mais notável deste sistema é o extrator de problemas no canto superior direito.\nQue deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.\nPor outras palavras, não pode ser usado para muitos projetos no GitHub.\nO segundo é Glyph, anunciado recentemente em 2020.\nEstá disponível na internet e pode ser instalado através do pip.\nEste sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.\nEsta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.\nOs dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.\nO desempenho do modelo de text classification não é alto.\nApresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.\nO nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.\nCom um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.\nEste método proposto pode ser usado para todos os repositórios em inglês.\nPara o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.\nEm seguida, vou descrever o nosso conjunto de dados.\nAqui está um exemplo de dados.\nO lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.\nAs notas de lançamento são rotuladas como melhorias ou correções, etc.\nConfigurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.\nIsto pode ser considerado como uma tarefa de sumarização.\nTemos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.\nEstes foram definidos com base em pesquisas anteriores e outros fatores.\nA nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.\nNeste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.\nMas os rótulos nem sempre são consistentes com cada repositório.\nPor exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.\nPreparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.\nIsto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.\nEm seguida, temos uma mensagem de confirmação.\nAs mensagens de confirmação não estão vinculadas a cada lançamento.\nComo mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.\nIsto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.\nCriámos uma regra de correspondência heurística para obter as versões anterior e seguinte.\nAnálise do conjunto de dados.\nNo final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.\nAlém disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.\nAlém disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.\nIsto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.\nEm seguida, explicarei o método proposto.\nO extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.\nUm classificador que usa BERT ou CodeBERT e um gerador que usa BART.\nPrimeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.\nAs mensagens de confirmação classificadas como outras são descartadas.\nEm seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.\nNesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.\nAssim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.\nNós modelamos a abordagem de abstractive summarization por dois métodos diferentes.\nO primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.\nOs textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.\nO segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.\nOK, deixe-me explicar as experiências.\nForam comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.\nEm relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.\nComo é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.\nO BLEU é penalizado quando o sistema emite uma frase curta.\nEsta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.\nFinalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.\nUma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.\nAqui estão os resultados.\nComo o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.\nCEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.\nEm particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.\nEstes resultados indicam que CEAS e CAS são significativamente afetados.\nCEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.\nA alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.\nO CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.\nSugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.\nAqui está uma análise de erro.\nOs métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.\nNa figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.\nA razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.\nAlém disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.\nO exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.\nO exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.\nPor fim, uma conclusão.\nCriámos um novo conjunto de dados para geração automática de notas de lançamento.\nTambém formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.\nAs nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.\nPodem consultar o nosso conjunto de dados no GitHub.\nObrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 0, "src_audio": "/acl6060/audio/en/0.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": null, "sample_id": 1, "src_audio": "/acl6060/audio/en/1.wav", "src_ref": "I'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 2, "src_audio": "/acl6060/audio/en/2.wav", "src_ref": "First, I'd like to talk about our motivation for reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, gostaria de falar sobre a nossa motivação para o raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 3, "src_audio": "/acl6060/audio/en/3.wav", "src_ref": "So here we show an examples where multi-step reasoning is helpful.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mostramos aqui exemplos em que o raciocínio em vários passos é útil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 4, "src_audio": "/acl6060/audio/en/4.wav", "src_ref": "So this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 5, "src_audio": "/acl6060/audio/en/5.wav", "src_ref": "So on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 6, "src_audio": "/acl6060/audio/en/6.wav", "src_ref": "But if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 7, "src_audio": "/acl6060/audio/en/7.wav", "src_ref": "So it is good to have interpretable multi-step reasoning as output.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É bom ter raciocínio interpretável multietapas como saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 8, "src_audio": "/acl6060/audio/en/8.wav", "src_ref": "And we also think math word problem is a straightforward application to evaluate such reasoning abilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 9, "src_audio": "/acl6060/audio/en/9.wav", "src_ref": "So, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 10, "src_audio": "/acl6060/audio/en/10.wav", "src_ref": "So in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 11, "src_audio": "/acl6060/audio/en/11.wav", "src_ref": "So, certain assumptions ah also apply as in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, certas suposições também se aplicam como no trabalho anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 12, "src_audio": "/acl6060/audio/en/12.wav", "src_ref": "We assume the precision of quantities are known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que a precisão das quantidades é conhecida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 13, "src_audio": "/acl6060/audio/en/13.wav", "src_ref": "And we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 14, "src_audio": "/acl6060/audio/en/14.wav", "src_ref": "Furthermore, complicated operators can be actually decomposed into these basic operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 15, "src_audio": "/acl6060/audio/en/15.wav", "src_ref": "So, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 16, "src_audio": "/acl6060/audio/en/16.wav", "src_ref": "So, traditional sequence to sequence model convert the expression to a specific sequence for generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 17, "src_audio": "/acl6060/audio/en/17.wav", "src_ref": "And it is pretty easy to implement and it can generalize to many different complicated problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 18, "src_audio": "/acl6060/audio/en/18.wav", "src_ref": "But the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 19, "src_audio": "/acl6060/audio/en/19.wav", "src_ref": "But actually this direction is still quite popular because of um the transformer model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 20, "src_audio": "/acl6060/audio/en/20.wav", "src_ref": "So, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 21, "src_audio": "/acl6060/audio/en/21.wav", "src_ref": "So here we keep generating the operators until we reach the leaves, which are the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 22, "src_audio": "/acl6060/audio/en/22.wav", "src_ref": "So here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 23, "src_audio": "/acl6060/audio/en/23.wav", "src_ref": "And the second thing is that it also contains some repetitive computations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que também contém alguns cálculos repetitivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 24, "src_audio": "/acl6060/audio/en/24.wav", "src_ref": "So here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 25, "src_audio": "/acl6060/audio/en/25.wav", "src_ref": "So, in our proposed approach we want to solve those problems in a step by step and interpretable manners.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 26, "src_audio": "/acl6060/audio/en/26.wav", "src_ref": "So for example, here in the second step, ah we can obtain these divisors which is twenty seven.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 27, "src_audio": "/acl6060/audio/en/27.wav", "src_ref": "And we can also refer back to the original questions to find the relevant contents.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 28, "src_audio": "/acl6060/audio/en/28.wav", "src_ref": "And in these steps we obtain the divisors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nestes passos obtemos os divisores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 29, "src_audio": "/acl6060/audio/en/29.wav", "src_ref": "So, ah and then at this third step we actually get the quotient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então neste terceiro passo nós conseguimos obter o quociente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 30, "src_audio": "/acl6060/audio/en/30.wav", "src_ref": "Alright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Certo. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 31, "src_audio": "/acl6060/audio/en/31.wav", "src_ref": "So, here we actually generate the whole expression directly rather than generating a single operators or quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 32, "src_audio": "/acl6060/audio/en/32.wav", "src_ref": "So this makes the process more accurate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto torna o processo mais preciso.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 33, "src_audio": "/acl6060/audio/en/33.wav", "src_ref": "So, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 34, "src_audio": "/acl6060/audio/en/34.wav", "src_ref": "So, the expression is represented by e i j o p.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, a expressão é representada por e i j o p.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 35, "src_audio": "/acl6060/audio/en/35.wav", "src_ref": "Where we perform operator from q_i to q_j, and such expression is actually directed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Onde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 36, "src_audio": "/acl6060/audio/en/36.wav", "src_ref": "So, we also have subtraction with words here to represent the opposite direction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, também temos a subtração com palavras aqui para representar a direção oposta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 37, "src_audio": "/acl6060/audio/en/37.wav", "src_ref": "This is quite similar to relation extraction.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é bastante semelhante a relation extraction.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 38, "src_audio": "/acl6060/audio/en/38.wav", "src_ref": "So in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 39, "src_audio": "/acl6060/audio/en/39.wav", "src_ref": "We add it to the next state to become a new quantity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionamo-la ao próximo estado para se tornar uma nova quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 40, "src_audio": "/acl6060/audio/en/40.wav", "src_ref": "So, these slides actually visualize the evolution of the state where we keep adding expression to the current state.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 41, "src_audio": "/acl6060/audio/en/41.wav", "src_ref": "So in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 42, "src_audio": "/acl6060/audio/en/42.wav", "src_ref": "So, once we get the quantity representations, we can start to do inference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim que obtemos as representações de quantidade, podemos começar a fazer inferência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 43, "src_audio": "/acl6060/audio/en/43.wav", "src_ref": "Here we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 44, "src_audio": "/acl6060/audio/en/44.wav", "src_ref": "First we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 45, "src_audio": "/acl6060/audio/en/45.wav", "src_ref": "And then finally we obtain the expression representation q_1 divided by q_2.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 46, "src_audio": "/acl6060/audio/en/46.wav", "src_ref": "But in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 47, "src_audio": "/acl6060/audio/en/47.wav", "src_ref": "So, here all the possible expression is equals to three times the number of operators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, toda a expressão possível é igual a três vezes o número de operadores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 48, "src_audio": "/acl6060/audio/en/48.wav", "src_ref": "So the nice thing here is that we can easily add constraints to control this search this search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 49, "src_audio": "/acl6060/audio/en/49.wav", "src_ref": "For example, if this expression is not allowed, we can simply remove this expression in our search space.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 50, "src_audio": "/acl6060/audio/en/50.wav", "src_ref": "So in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 51, "src_audio": "/acl6060/audio/en/51.wav", "src_ref": "So this quantity come from the previous calculated expression.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, esta quantidade vem da expressão calculada anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 52, "src_audio": "/acl6060/audio/en/52.wav", "src_ref": "So finally we can obtain this final expression q_3 times q_4.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então podemos finalmente obter esta expressão final q_3 vezes q_4.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 53, "src_audio": "/acl6060/audio/en/53.wav", "src_ref": "And we can also see the number of all the possible ah expression is different from the previous step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 54, "src_audio": "/acl6060/audio/en/54.wav", "src_ref": "So, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 55, "src_audio": "/acl6060/audio/en/55.wav", "src_ref": "So the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 56, "src_audio": "/acl6060/audio/en/56.wav", "src_ref": "And here we also use this tau to represent when we should terminate this generation process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também usamos este tau para representar quando devemos encerrar este processo de geração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 57, "src_audio": "/acl6060/audio/en/57.wav", "src_ref": "And here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 58, "src_audio": "/acl6060/audio/en/58.wav", "src_ref": "And it also allows us to impose certain constraints from prior from prior knowledge.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E também nos permite impor certas restrições do conhecimento anterior.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 59, "src_audio": "/acl6060/audio/en/59.wav", "src_ref": "So we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 60, "src_audio": "/acl6060/audio/en/60.wav", "src_ref": "And here we briefly show the results compared with the previous best approaches.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 61, "src_audio": "/acl6060/audio/en/61.wav", "src_ref": "So our best performing variant is Roberta-DeductiveReasoner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 62, "src_audio": "/acl6060/audio/en/62.wav", "src_ref": "And in fact we do not use beam search, in contrast all previous approaches are using beam search.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 63, "src_audio": "/acl6060/audio/en/63.wav", "src_ref": "All right. So, the best approaches are often tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Muito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 64, "src_audio": "/acl6060/audio/en/64.wav", "src_ref": "So, overall our reasoner is able to significantl significantly outperform this tree based model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 65, "src_audio": "/acl6060/audio/en/65.wav", "src_ref": "But we can see the absolute numbers on MathQA or SVAMP are not really high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 66, "src_audio": "/acl6060/audio/en/66.wav", "src_ref": "So we further investigate the results on SVAMP.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, investigamos ainda mais os resultados no SVAMP.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 67, "src_audio": "/acl6060/audio/en/67.wav", "src_ref": "And this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 68, "src_audio": "/acl6060/audio/en/68.wav", "src_ref": "So, in our prediction we find some of the intermediate values are actually negatives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 69, "src_audio": "/acl6060/audio/en/69.wav", "src_ref": "For example, um, in these questions we are asking how many apples does Jake have?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 70, "src_audio": "/acl6060/audio/en/70.wav", "src_ref": "But we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 71, "src_audio": "/acl6060/audio/en/71.wav", "src_ref": "So, our model makes some prediction like this which is producing negative values.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso modelo faz alguma previsão como esta que está a produzir valores negativos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 72, "src_audio": "/acl6060/audio/en/72.wav", "src_ref": "And we observe these two expressions actually have similar scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E observamos que estas duas expressões realmente têm classificações semelhantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 73, "src_audio": "/acl6060/audio/en/73.wav", "src_ref": "So, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 74, "src_audio": "/acl6060/audio/en/74.wav", "src_ref": "So um we further find such constraint actually improves quite a lot for some models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, descobrimos ainda que esta restrição melhora muito para alguns modelos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 75, "src_audio": "/acl6060/audio/en/75.wav", "src_ref": "For example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 76, "src_audio": "/acl6060/audio/en/76.wav", "src_ref": "So better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 77, "src_audio": "/acl6060/audio/en/77.wav", "src_ref": "And we also try to analyze the difficulty behind these behind all these datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 78, "src_audio": "/acl6060/audio/en/78.wav", "src_ref": "We assume the number of unused quantities can be regarded as irrelevant information here.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 79, "src_audio": "/acl6060/audio/en/79.wav", "src_ref": "So ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 80, "src_audio": "/acl6060/audio/en/80.wav", "src_ref": "And here we also show the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E aqui também mostramos o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 81, "src_audio": "/acl6060/audio/en/81.wav", "src_ref": "For those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 82, "src_audio": "/acl6060/audio/en/82.wav", "src_ref": "But with those samples that with unused quantity is actually way worse than the, worse than the overall performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 83, "src_audio": "/acl6060/audio/en/83.wav", "src_ref": "For MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 84, "src_audio": "/acl6060/audio/en/84.wav", "src_ref": "So, finally we want to show the interpretability through a question perturbation example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 85, "src_audio": "/acl6060/audio/en/85.wav", "src_ref": "So here our model actually makes a wrong prediction at the first step.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 86, "src_audio": "/acl6060/audio/en/86.wav", "src_ref": "So, we can actually correlate this expression with the sentence here. Alright.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podemos realmente correlacionar esta expressão com a frase aqui. Certo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 87, "src_audio": "/acl6060/audio/en/87.wav", "src_ref": "So, we think this sentence might be misleading the model to an incorrect predictions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 88, "src_audio": "/acl6060/audio/en/88.wav", "src_ref": "So here planting another thirty five makes the model makes the model think it should be an addition operator.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 89, "src_audio": "/acl6060/audio/en/89.wav", "src_ref": "So we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 90, "src_audio": "/acl6060/audio/en/90.wav", "src_ref": "So, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 91, "src_audio": "/acl6060/audio/en/91.wav", "src_ref": "So, this study shows how the interpretable predictions help us understand the model behavior.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 92, "src_audio": "/acl6060/audio/en/92.wav", "src_ref": "So to conclude our work, so first our model is actually pretty efficient.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 93, "src_audio": "/acl6060/audio/en/93.wav", "src_ref": "And we are able to provide interpretable solving procedure.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E somos capazes de fornecer um procedimento de resolução interpretável.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 94, "src_audio": "/acl6060/audio/en/94.wav", "src_ref": "And we can easily incorporate some prior knowledge as constraint which can help improve the performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 95, "src_audio": "/acl6060/audio/en/95.wav", "src_ref": "And the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 96, "src_audio": "/acl6060/audio/en/96.wav", "src_ref": "We also have certain limitations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também temos certas limitações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 97, "src_audio": "/acl6060/audio/en/97.wav", "src_ref": "Ah, if we have a large number of operators or constants, the memory consumption could be pretty high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 98, "src_audio": "/acl6060/audio/en/98.wav", "src_ref": "And the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 99, "src_audio": "/acl6060/audio/en/99.wav", "src_ref": "So this is the end of the talk, and questions are welcomed. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 100, "src_audio": "/acl6060/audio/en/100.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 101, "src_audio": "/acl6060/audio/en/101.wav", "src_ref": "I will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 102, "src_audio": "/acl6060/audio/en/102.wav", "src_ref": "Legal issues are an integral part of many people's lives.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Questões legais são parte integrante da vida de muitas pessoas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 103, "src_audio": "/acl6060/audio/en/103.wav", "src_ref": "But the majority of citizens have little to know knowledge about their rights and fundamental legal processes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 104, "src_audio": "/acl6060/audio/en/104.wav", "src_ref": "As a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 105, "src_audio": "/acl6060/audio/en/105.wav", "src_ref": "All work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Todo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 106, "src_audio": "/acl6060/audio/en/106.wav", "src_ref": "Such a system could provide a free professional legal help service for unskilled humans.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 107, "src_audio": "/acl6060/audio/en/107.wav", "src_ref": "Before diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Antes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 108, "src_audio": "/acl6060/audio/en/108.wav", "src_ref": "Given a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 109, "src_audio": "/acl6060/audio/en/109.wav", "src_ref": "A model is required to retrieve all relevant statutory articles from a large body of legislation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 110, "src_audio": "/acl6060/audio/en/110.wav", "src_ref": "This information retrieval task comes with its own set of challenges.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 111, "src_audio": "/acl6060/audio/en/111.wav", "src_ref": "First, it deals with two types of language.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, lida com dois tipos de linguagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 112, "src_audio": "/acl6060/audio/en/112.wav", "src_ref": "Common natural language for the questions and complex legal language for the statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Linguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 113, "src_audio": "/acl6060/audio/en/113.wav", "src_ref": "This difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 114, "src_audio": "/acl6060/audio/en/114.wav", "src_ref": "Besides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 115, "src_audio": "/acl6060/audio/en/115.wav", "src_ref": "Instead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 116, "src_audio": "/acl6060/audio/en/116.wav", "src_ref": "Lastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 117, "src_audio": "/acl6060/audio/en/117.wav", "src_ref": "Here, there are long documents that may be up to six thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui, há documentos longos que podem chegar a seis mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 118, "src_audio": "/acl6060/audio/en/118.wav", "src_ref": "The recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 119, "src_audio": "/acl6060/audio/en/119.wav", "src_ref": "But statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 120, "src_audio": "/acl6060/audio/en/120.wav", "src_ref": "In this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 121, "src_audio": "/acl6060/audio/en/121.wav", "src_ref": "Our Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 122, "src_audio": "/acl6060/audio/en/122.wav", "src_ref": "These questions cover a wide range of topics from family, housing, money, to work and social security.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 123, "src_audio": "/acl6060/audio/en/123.wav", "src_ref": "Each of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 124, "src_audio": "/acl6060/audio/en/124.wav", "src_ref": "Let's now talk about how we collected this dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos agora falar sobre como recolhemos este conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 125, "src_audio": "/acl6060/audio/en/125.wav", "src_ref": "First, we started by compiling a large corpus of legal articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 126, "src_audio": "/acl6060/audio/en/126.wav", "src_ref": "We considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Considerámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 127, "src_audio": "/acl6060/audio/en/127.wav", "src_ref": "Then we gathered legal questions with references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reunimos perguntas legais com referências a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 128, "src_audio": "/acl6060/audio/en/128.wav", "src_ref": "To do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 129, "src_audio": "/acl6060/audio/en/129.wav", "src_ref": "We were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 130, "src_audio": "/acl6060/audio/en/130.wav", "src_ref": "We collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Recolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 131, "src_audio": "/acl6060/audio/en/131.wav", "src_ref": "Lastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 132, "src_audio": "/acl6060/audio/en/132.wav", "src_ref": "The remaining references were matched and converted to the corresponding article ids from our corpus.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 133, "src_audio": "/acl6060/audio/en/133.wav", "src_ref": "We eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Acabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 134, "src_audio": "/acl6060/audio/en/134.wav", "src_ref": "In addition, each question comes with the main category and a concatenation of subcategories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 135, "src_audio": "/acl6060/audio/en/135.wav", "src_ref": "And each articles comes with a concatenation of the subsequence heading in the structure of the law.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 136, "src_audio": "/acl6060/audio/en/136.wav", "src_ref": "This extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 137, "src_audio": "/acl6060/audio/en/137.wav", "src_ref": "Let's look at some characteristic of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vejamos algumas características do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 138, "src_audio": "/acl6060/audio/en/138.wav", "src_ref": "The questions are between five and forty four words long with a median of fourteen words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 139, "src_audio": "/acl6060/audio/en/139.wav", "src_ref": "The articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 140, "src_audio": "/acl6060/audio/en/140.wav", "src_ref": "The lengthiest one being up to five thousand seven hundred and ninety words.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O mais longo sendo até cinco mil setecentos e noventa palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 141, "src_audio": "/acl6060/audio/en/141.wav", "src_ref": "As previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 142, "src_audio": "/acl6060/audio/en/142.wav", "src_ref": "While the remaining fifteen percent concern either social security, foreigners or work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 143, "src_audio": "/acl6060/audio/en/143.wav", "src_ref": "The article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 144, "src_audio": "/acl6060/audio/en/144.wav", "src_ref": "Here's the total number of articles collected from each of these Belgian codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o número total de artigos recolhidos de cada um destes códigos belgas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 145, "src_audio": "/acl6060/audio/en/145.wav", "src_ref": "Out of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 146, "src_audio": "/acl6060/audio/en/146.wav", "src_ref": "And around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 147, "src_audio": "/acl6060/audio/en/147.wav", "src_ref": "Meanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 148, "src_audio": "/acl6060/audio/en/148.wav", "src_ref": "Which can be explained by the fact that those codes focused less on individuals and their concerns.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 149, "src_audio": "/acl6060/audio/en/149.wav", "src_ref": "Overall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 150, "src_audio": "/acl6060/audio/en/150.wav", "src_ref": "Using all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 151, "src_audio": "/acl6060/audio/en/151.wav", "src_ref": "Given a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Dada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 152, "src_audio": "/acl6060/audio/en/152.wav", "src_ref": "We experiment with the standard TF-IDF and BM25 ranking functions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos as funções de classificação TF-IDF e BM25 padrão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 153, "src_audio": "/acl6060/audio/en/153.wav", "src_ref": "The main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 154, "src_audio": "/acl6060/audio/en/154.wav", "src_ref": "To overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 155, "src_audio": "/acl6060/audio/en/155.wav", "src_ref": "We use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 156, "src_audio": "/acl6060/audio/en/156.wav", "src_ref": "These embeddings typically result from a pooling operation on the output of a word embedding model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 157, "src_audio": "/acl6060/audio/en/157.wav", "src_ref": "First, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 158, "src_audio": "/acl6060/audio/en/158.wav", "src_ref": "We experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 159, "src_audio": "/acl6060/audio/en/159.wav", "src_ref": "Additionally, we train our own CamemBERT based model ah bi-encoders on our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 160, "src_audio": "/acl6060/audio/en/160.wav", "src_ref": "Note that for training, we experiment with the two flavors of the bi-encoder architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Observe que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 161, "src_audio": "/acl6060/audio/en/161.wav", "src_ref": "Siamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 162, "src_audio": "/acl6060/audio/en/162.wav", "src_ref": "We experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 163, "src_audio": "/acl6060/audio/en/163.wav", "src_ref": "Here are the result of our baseline on the test sets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o resultado da nossa linha de base nos conjuntos de teste.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 164, "src_audio": "/acl6060/audio/en/164.wav", "src_ref": "With the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 165, "src_audio": "/acl6060/audio/en/165.wav", "src_ref": "Overall, the finetuned bi-encoder significantly outperforms all the other baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 166, "src_audio": "/acl6060/audio/en/166.wav", "src_ref": "The two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 167, "src_audio": "/acl6060/audio/en/167.wav", "src_ref": "Although BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 168, "src_audio": "/acl6060/audio/en/168.wav", "src_ref": "Regarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 169, "src_audio": "/acl6060/audio/en/169.wav", "src_ref": "Furthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 170, "src_audio": "/acl6060/audio/en/170.wav", "src_ref": "Although promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Embora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 171, "src_audio": "/acl6060/audio/en/171.wav", "src_ref": "Let's conclude by discussing two limitations of our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos concluir discutindo duas limitações do nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 172, "src_audio": "/acl6060/audio/en/172.wav", "src_ref": "First, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 173, "src_audio": "/acl6060/audio/en/173.wav", "src_ref": "During the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Durante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 174, "src_audio": "/acl6060/audio/en/174.wav", "src_ref": "This information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 175, "src_audio": "/acl6060/audio/en/175.wav", "src_ref": "Second, we should note that not all legal questions can be answered with statutes alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 176, "src_audio": "/acl6060/audio/en/176.wav", "src_ref": "For instance, the question, can I evict my tenants if they make too much noise?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 177, "src_audio": "/acl6060/audio/en/177.wav", "src_ref": "Might not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 178, "src_audio": "/acl6060/audio/en/178.wav", "src_ref": "Instead, the landlord should probably rely more on case law and find precedents similar to their current situation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 179, "src_audio": "/acl6060/audio/en/179.wav", "src_ref": "For example, the tenants makes two parties a week until two AM.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 180, "src_audio": "/acl6060/audio/en/180.wav", "src_ref": "Hence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 181, "src_audio": "/acl6060/audio/en/181.wav", "src_ref": "We hope that our work sparks interest in developing practical and reliable statutory article retrieval models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 182, "src_audio": "/acl6060/audio/en/182.wav", "src_ref": "That can help improve access to justice for all.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isso pode ajudar a melhorar o acesso à justiça para todos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 183, "src_audio": "/acl6060/audio/en/183.wav", "src_ref": "You can check out our paper, dataset and code at the following links. Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 184, "src_audio": "/acl6060/audio/en/184.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 185, "src_audio": "/acl6060/audio/en/185.wav", "src_ref": "Why did we do the trouble in setting up this benchmark?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Porque é que nos esforçámos para estabelecer este termo de comparação?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 186, "src_audio": "/acl6060/audio/en/186.wav", "src_ref": "Well, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Bem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 187, "src_audio": "/acl6060/audio/en/187.wav", "src_ref": "Each one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 188, "src_audio": "/acl6060/audio/en/188.wav", "src_ref": "So we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 189, "src_audio": "/acl6060/audio/en/189.wav", "src_ref": "But do we know what the models have actually learned?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas sabemos o que os modelos realmente aprenderam?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 190, "src_audio": "/acl6060/audio/en/190.wav", "src_ref": "What is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 191, "src_audio": "/acl6060/audio/en/191.wav", "src_ref": "And the low score for this one?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E a pontuação baixa para esta?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 192, "src_audio": "/acl6060/audio/en/192.wav", "src_ref": "Do vision and language models focus on the right thing?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os modelos de linguagem e visão concentram-se na coisa certa?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 193, "src_audio": "/acl6060/audio/en/193.wav", "src_ref": "Or do they focus on biases as shown by previous work?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou concentram-se em preconceitos como mostrado pelo trabalho anterior?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 194, "src_audio": "/acl6060/audio/en/194.wav", "src_ref": "To shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 195, "src_audio": "/acl6060/audio/en/195.wav", "src_ref": "We target existence, plurality, counting, spatial relations, actions and entity coreference.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Tomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 196, "src_audio": "/acl6060/audio/en/196.wav", "src_ref": "But how do we test whether the vision and language models have captured this phenomena?", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas como testamos se os modelos de linguagem e visão capturaram este fenómeno?", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 197, "src_audio": "/acl6060/audio/en/197.wav", "src_ref": "By foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ao frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 198, "src_audio": "/acl6060/audio/en/198.wav", "src_ref": "Foiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Frustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 199, "src_audio": "/acl6060/audio/en/199.wav", "src_ref": "And we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 200, "src_audio": "/acl6060/audio/en/200.wav", "src_ref": "For example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 201, "src_audio": "/acl6060/audio/en/201.wav", "src_ref": "Counting and coreference also are pieces that have more than one instrument.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Contagem e correferência também são peças que possuem mais de um instrumento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 202, "src_audio": "/acl6060/audio/en/202.wav", "src_ref": "And we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 203, "src_audio": "/acl6060/audio/en/203.wav", "src_ref": "This is not easy to do because a foiled caption may be less likely than the original caption.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 204, "src_audio": "/acl6060/audio/en/204.wav", "src_ref": "For example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 205, "src_audio": "/acl6060/audio/en/205.wav", "src_ref": "Therefore, to obtain valid foils, we must take action.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para obter frustrações válidas, devemos agir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 206, "src_audio": "/acl6060/audio/en/206.wav", "src_ref": "First, we make use of strong language models to propose foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 207, "src_audio": "/acl6060/audio/en/207.wav", "src_ref": "Second, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 208, "src_audio": "/acl6060/audio/en/208.wav", "src_ref": "To test this automatically, we apply natural language inference with the following rationale.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 209, "src_audio": "/acl6060/audio/en/209.wav", "src_ref": "We consider an image to be the premise and its caption its entailed hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Consideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 210, "src_audio": "/acl6060/audio/en/210.wav", "src_ref": "In addition, we consider the caption to be the premise, and the foil is its hypothesis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 211, "src_audio": "/acl6060/audio/en/211.wav", "src_ref": "If an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 212, "src_audio": "/acl6060/audio/en/212.wav", "src_ref": "If an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 213, "src_audio": "/acl6060/audio/en/213.wav", "src_ref": "But this procedure is not perfect, it is just an indicator for valid foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 214, "src_audio": "/acl6060/audio/en/214.wav", "src_ref": "Therefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 215, "src_audio": "/acl6060/audio/en/215.wav", "src_ref": "So, after filtering and human evaluation, we have as many test instances as described in this table.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 216, "src_audio": "/acl6060/audio/en/216.wav", "src_ref": "Note that VALSE does not deliver any training data but only test data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 217, "src_audio": "/acl6060/audio/en/217.wav", "src_ref": "Since it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 218, "src_audio": "/acl6060/audio/en/218.wav", "src_ref": "Finetuning would only enable models to exploit artifacts or statistical biases in the data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 219, "src_audio": "/acl6060/audio/en/219.wav", "src_ref": "And we all know that these models like to cheat and take shortcuts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 220, "src_audio": "/acl6060/audio/en/220.wav", "src_ref": "And as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 221, "src_audio": "/acl6060/audio/en/221.wav", "src_ref": "We experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Experimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 222, "src_audio": "/acl6060/audio/en/222.wav", "src_ref": "Two of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Duas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 223, "src_audio": "/acl6060/audio/en/223.wav", "src_ref": "Perhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Talvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 224, "src_audio": "/acl6060/audio/en/224.wav", "src_ref": "For more metrics and results on them, do check out our paper.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para mais métricas e resultados sobre eles, veja o nosso artigo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 225, "src_audio": "/acl6060/audio/en/225.wav", "src_ref": "The results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 226, "src_audio": "/acl6060/audio/en/226.wav", "src_ref": "It's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 227, "src_audio": "/acl6060/audio/en/227.wav", "src_ref": "However, none of the remaining pieces can be reliably solved in our adversarial foiling settings.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 228, "src_audio": "/acl6060/audio/en/228.wav", "src_ref": "We see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 229, "src_audio": "/acl6060/audio/en/229.wav", "src_ref": "The relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 230, "src_audio": "/acl6060/audio/en/230.wav", "src_ref": "They also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 231, "src_audio": "/acl6060/audio/en/231.wav", "src_ref": "From the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 232, "src_audio": "/acl6060/audio/en/232.wav", "src_ref": "As a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 233, "src_audio": "/acl6060/audio/en/233.wav", "src_ref": "If the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 234, "src_audio": "/acl6060/audio/en/234.wav", "src_ref": "And it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 235, "src_audio": "/acl6060/audio/en/235.wav", "src_ref": "So to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 236, "src_audio": "/acl6060/audio/en/236.wav", "src_ref": "Our experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 237, "src_audio": "/acl6060/audio/en/237.wav", "src_ref": "We would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Gostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 238, "src_audio": "/acl6060/audio/en/238.wav", "src_ref": "And even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 239, "src_audio": "/acl6060/audio/en/239.wav", "src_ref": "If you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Se houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 240, "src_audio": "/acl6060/audio/en/240.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 241, "src_audio": "/acl6060/audio/en/241.wav", "src_ref": "I'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 242, "src_audio": "/acl6060/audio/en/242.wav", "src_ref": "I'll be explaining in this order.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou explicar nesta ordem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 243, "src_audio": "/acl6060/audio/en/243.wav", "src_ref": "First, I will introduce automatic release note generation that we are working on in this research.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 244, "src_audio": "/acl6060/audio/en/244.wav", "src_ref": "A release note is a technical document that summarizes the changes distributed with each release of a software product.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 245, "src_audio": "/acl6060/audio/en/245.wav", "src_ref": "The image shows a release note for version two point six point four of the vuejs library.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 246, "src_audio": "/acl6060/audio/en/246.wav", "src_ref": "Release notes play an important role in open source development but they're time consuming to prepare manually.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 247, "src_audio": "/acl6060/audio/en/247.wav", "src_ref": "Therefore, it would be very useful to be able to automatically generate high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 248, "src_audio": "/acl6060/audio/en/248.wav", "src_ref": "I will defer to two previous researches on automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 249, "src_audio": "/acl6060/audio/en/249.wav", "src_ref": "The first is a system called ARENA released in twenty fourteen.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro é um sistema chamado ARENA lançado em 2014.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 250, "src_audio": "/acl6060/audio/en/250.wav", "src_ref": "It takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 251, "src_audio": "/acl6060/audio/en/251.wav", "src_ref": "The most notable feature of this system is the issue extractor in the upper right corner.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A característica mais notável deste sistema é o extrator de problemas no canto superior direito.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 252, "src_audio": "/acl6060/audio/en/252.wav", "src_ref": "Which must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Que deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 253, "src_audio": "/acl6060/audio/en/253.wav", "src_ref": "In other words, it cannot be used for many projects on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por outras palavras, não pode ser usado para muitos projetos no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 254, "src_audio": "/acl6060/audio/en/254.wav", "src_ref": "The second is Glyph, recently announced in twenty twenty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo é Glyph, anunciado recentemente em 2020.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 255, "src_audio": "/acl6060/audio/en/255.wav", "src_ref": "It is available on the internet and can be installed via pip.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Está disponível na internet e pode ser instalado através do pip.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 256, "src_audio": "/acl6060/audio/en/256.wav", "src_ref": "This system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 257, "src_audio": "/acl6060/audio/en/257.wav", "src_ref": "This image is a sample usage that returns a corrective or bug fixes label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 258, "src_audio": "/acl6060/audio/en/258.wav", "src_ref": "Glyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 259, "src_audio": "/acl6060/audio/en/259.wav", "src_ref": "The performance of the text classification model is not high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O desempenho do modelo de text classification não é alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 260, "src_audio": "/acl6060/audio/en/260.wav", "src_ref": "I present two related researches, but their problems are limited applicability and scarce data resources.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Apresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 261, "src_audio": "/acl6060/audio/en/261.wav", "src_ref": "Our paper solves these two problems and automatically generates high quality release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 262, "src_audio": "/acl6060/audio/en/262.wav", "src_ref": "With a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Com um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 263, "src_audio": "/acl6060/audio/en/263.wav", "src_ref": "This proposed method can be used for all English repositories.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Este método proposto pode ser usado para todos os repositórios em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 264, "src_audio": "/acl6060/audio/en/264.wav", "src_ref": "For the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 265, "src_audio": "/acl6060/audio/en/265.wav", "src_ref": "Next, I'll describe our dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, vou descrever o nosso conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 266, "src_audio": "/acl6060/audio/en/266.wav", "src_ref": "Here is an example of data.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está um exemplo de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 267, "src_audio": "/acl6060/audio/en/267.wav", "src_ref": "The left side is a commit message and the right side is the release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 268, "src_audio": "/acl6060/audio/en/268.wav", "src_ref": "Release notes are labeled as improvements or fixes, etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As notas de lançamento são rotuladas como melhorias ou correções, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 269, "src_audio": "/acl6060/audio/en/269.wav", "src_ref": "We have set up a task that takes the commit messages as input and outputs a labeled release notes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Configurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 270, "src_audio": "/acl6060/audio/en/270.wav", "src_ref": "This can be regarded as a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto pode ser considerado como uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 271, "src_audio": "/acl6060/audio/en/271.wav", "src_ref": "We have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Temos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 272, "src_audio": "/acl6060/audio/en/272.wav", "src_ref": "These were set based on previous research and other factors.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes foram definidos com base em pesquisas anteriores e outros fatores.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 273, "src_audio": "/acl6060/audio/en/273.wav", "src_ref": "The release note on the bottom right is extracted from the release note on the bottom left.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 274, "src_audio": "/acl6060/audio/en/274.wav", "src_ref": "At this time, it is necessary to detect the four labels that have been set up in advance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 275, "src_audio": "/acl6060/audio/en/275.wav", "src_ref": "But the labels are not always consistent with each repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas os rótulos nem sempre são consistentes com cada repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 276, "src_audio": "/acl6060/audio/en/276.wav", "src_ref": "For example, the improvements label includes improvements, enhancements, optimizations, and so on.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 277, "src_audio": "/acl6060/audio/en/277.wav", "src_ref": "We prepared a vocabulary list of about thirty labels for each of these notational variations.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Preparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 278, "src_audio": "/acl6060/audio/en/278.wav", "src_ref": "This is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 279, "src_audio": "/acl6060/audio/en/279.wav", "src_ref": "Next is a commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, temos uma mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 280, "src_audio": "/acl6060/audio/en/280.wav", "src_ref": "Commit messages are not tied to each release.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação não estão vinculadas a cada lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 281, "src_audio": "/acl6060/audio/en/281.wav", "src_ref": "As shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 282, "src_audio": "/acl6060/audio/en/282.wav", "src_ref": "This is a bit tedious and it is not enough to just get a list of releases and look at the before and after.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 283, "src_audio": "/acl6060/audio/en/283.wav", "src_ref": "We created a heuristic matching rule to get the previous and next versions.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos uma regra de correspondência heurística para obter as versões anterior e seguinte.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 284, "src_audio": "/acl6060/audio/en/284.wav", "src_ref": "Dataset analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Análise do conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 285, "src_audio": "/acl6060/audio/en/285.wav", "src_ref": "In the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 286, "src_audio": "/acl6060/audio/en/286.wav", "src_ref": "Also, the average number of release notes tokens is sixty three, which is quite high for a summarization task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 287, "src_audio": "/acl6060/audio/en/287.wav", "src_ref": "Also, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 288, "src_audio": "/acl6060/audio/en/288.wav", "src_ref": "This is due to the large number of unique class or method names found in the repository.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Isto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 289, "src_audio": "/acl6060/audio/en/289.wav", "src_ref": "Next, I will explain the proposed method.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, explicarei o método proposto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 290, "src_audio": "/acl6060/audio/en/290.wav", "src_ref": "The classwise extractive then abstractive summarization model consists of two neural modules.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 291, "src_audio": "/acl6060/audio/en/291.wav", "src_ref": "A classifier using BERT or CodeBERT and a generator using BART.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Um classificador que usa BERT ou CodeBERT e um gerador que usa BART.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 292, "src_audio": "/acl6060/audio/en/292.wav", "src_ref": "First, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 293, "src_audio": "/acl6060/audio/en/293.wav", "src_ref": "The commit messages classified as other are discarded.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As mensagens de confirmação classificadas como outras são descartadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 294, "src_audio": "/acl6060/audio/en/294.wav", "src_ref": "Then CEAS applies the generator to the four labeled documents independently and generates release notes for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 295, "src_audio": "/acl6060/audio/en/295.wav", "src_ref": "In this task, the direct correspondences between commit messages and release notes are not known.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 296, "src_audio": "/acl6060/audio/en/296.wav", "src_ref": "Therefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 297, "src_audio": "/acl6060/audio/en/297.wav", "src_ref": "We modeled the classwise abstractive summarization approach by two different methods.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Nós modelamos a abordagem de abstractive summarization por dois métodos diferentes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 298, "src_audio": "/acl6060/audio/en/298.wav", "src_ref": "The first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 299, "src_audio": "/acl6060/audio/en/299.wav", "src_ref": "The output texts can be divided into classwise segments based on special class-specific endpoint symbols.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 300, "src_audio": "/acl6060/audio/en/300.wav", "src_ref": "The second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 301, "src_audio": "/acl6060/audio/en/301.wav", "src_ref": "Okay, let me explain the experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "OK, deixe-me explicar as experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 302, "src_audio": "/acl6060/audio/en/302.wav", "src_ref": "Five methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Foram comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 303, "src_audio": "/acl6060/audio/en/303.wav", "src_ref": "Regarding evaluation, in some cases, release notes are output in multiple sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 304, "src_audio": "/acl6060/audio/en/304.wav", "src_ref": "Since it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 305, "src_audio": "/acl6060/audio/en/305.wav", "src_ref": "The BLEU is penalized when the system outputs a short sentence.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O BLEU é penalizado quando o sistema emite uma frase curta.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 306, "src_audio": "/acl6060/audio/en/306.wav", "src_ref": "This penalty results in a lower BLEU value in the experiment results described next.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Esta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 307, "src_audio": "/acl6060/audio/en/307.wav", "src_ref": "Finally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Finalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 308, "src_audio": "/acl6060/audio/en/308.wav", "src_ref": "A higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 309, "src_audio": "/acl6060/audio/en/309.wav", "src_ref": "Here are the results.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 310, "src_audio": "/acl6060/audio/en/310.wav", "src_ref": "Since the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 311, "src_audio": "/acl6060/audio/en/311.wav", "src_ref": "CEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 312, "src_audio": "/acl6060/audio/en/312.wav", "src_ref": "In particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 313, "src_audio": "/acl6060/audio/en/313.wav", "src_ref": "These results indicate that CEAS and CAS are significantly affected.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Estes resultados indicam que CEAS e CAS são significativamente afetados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 314, "src_audio": "/acl6060/audio/en/314.wav", "src_ref": "CEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "CEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 315, "src_audio": "/acl6060/audio/en/315.wav", "src_ref": "High coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 316, "src_audio": "/acl6060/audio/en/316.wav", "src_ref": "CAS-Multi tended to yield higher ROUGE-L than CAS-Single.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 317, "src_audio": "/acl6060/audio/en/317.wav", "src_ref": "Suggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Sugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 318, "src_audio": "/acl6060/audio/en/318.wav", "src_ref": "Here are an error analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está uma análise de erro.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 319, "src_audio": "/acl6060/audio/en/319.wav", "src_ref": "CAS methods tend to output shorter sentences than human reference sentences.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 320, "src_audio": "/acl6060/audio/en/320.wav", "src_ref": "In the figure on the right, the reference sentence has three or four sentences, while CAS has only one.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 321, "src_audio": "/acl6060/audio/en/321.wav", "src_ref": "The reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 322, "src_audio": "/acl6060/audio/en/322.wav", "src_ref": "Furthermore, CAS methods cannot generate accurate release notes without additional information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Além disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 323, "src_audio": "/acl6060/audio/en/323.wav", "src_ref": "The top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 324, "src_audio": "/acl6060/audio/en/324.wav", "src_ref": "The example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 325, "src_audio": "/acl6060/audio/en/325.wav", "src_ref": "Finally, a conclusion.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Por fim, uma conclusão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 326, "src_audio": "/acl6060/audio/en/326.wav", "src_ref": "We have built a new dataset for automatic release note generation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Criámos um novo conjunto de dados para geração automática de notas de lançamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 327, "src_audio": "/acl6060/audio/en/327.wav", "src_ref": "We have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 328, "src_audio": "/acl6060/audio/en/328.wav", "src_ref": "Our experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "As nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 329, "src_audio": "/acl6060/audio/en/329.wav", "src_ref": "Please check out our dataset on GitHub.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Podem consultar o nosso conjunto de dados no GitHub.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 330, "src_audio": "/acl6060/audio/en/330.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 331, "src_audio": "/acl6060/audio/en/331.wav", "src_ref": "Hello. My name is Asaf Harari.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Olá. Chamo-me Asaf Harari.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 332, "src_audio": "/acl6060/audio/en/332.wav", "src_ref": "And I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 333, "src_audio": "/acl6060/audio/en/333.wav", "src_ref": "Data scientists analyze data and mainly focus on the manipulating the data's existing features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Os cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 334, "src_audio": "/acl6060/audio/en/334.wav", "src_ref": "But sometimes, these features are limited.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas, por vezes, estas características são limitadas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 335, "src_audio": "/acl6060/audio/en/335.wav", "src_ref": "Feature generation using another data source may add substantial information.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A geração de características que usa outra fonte de dados pode adicionar informação substancial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 336, "src_audio": "/acl6060/audio/en/336.wav", "src_ref": "Our research goal is automatic tabular data enrichment using external sources' free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "o nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 337, "src_audio": "/acl6060/audio/en/337.wav", "src_ref": "Assume we have a tabular dataset and a knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Suponhamos que temos um conjunto de dados tabular e uma base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 338, "src_audio": "/acl6060/audio/en/338.wav", "src_ref": "We need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Precisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 339, "src_audio": "/acl6060/audio/en/339.wav", "src_ref": "Our framework FeSTE is exactly this automatic process.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa estrutura FeSTE é exatamente esse processo automático.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 340, "src_audio": "/acl6060/audio/en/340.wav", "src_ref": "So let's see an example in a dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo num conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 341, "src_audio": "/acl6060/audio/en/341.wav", "src_ref": "In this example, the dataset is university dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados é um conjunto de dados universitário.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 342, "src_audio": "/acl6060/audio/en/342.wav", "src_ref": "When its goal is to classify universities into low ranking universities and high-ranking universities.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 343, "src_audio": "/acl6060/audio/en/343.wav", "src_ref": "As knowledge base, we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 344, "src_audio": "/acl6060/audio/en/344.wav", "src_ref": "The first phase of FeSTE is entity linking.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A primeira fase do FeSTE é entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 345, "src_audio": "/acl6060/audio/en/345.wav", "src_ref": "When each entity, in this example the university name, is linked to an entity within the knowledge base.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 346, "src_audio": "/acl6060/audio/en/346.wav", "src_ref": "And and the text of the entities of the knowledge base is extracted and added to the dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 347, "src_audio": "/acl6060/audio/en/347.wav", "src_ref": "In this example, the text is the Wikipedia page's abstract.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o texto é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 348, "src_audio": "/acl6060/audio/en/348.wav", "src_ref": "Now, we need to generate or extract features from the retrieved text.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Agora, precisamos de gerar ou extrair características do texto recuperado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 349, "src_audio": "/acl6060/audio/en/349.wav", "src_ref": "So, we need to ah feature extraction phase ah which includes text analysis.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, precisamos da fase de extração de características que inclui análise de texto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 350, "src_audio": "/acl6060/audio/en/350.wav", "src_ref": "And this is the main novelty of this paper and I will deep dive into it in the next slides.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 351, "src_audio": "/acl6060/audio/en/351.wav", "src_ref": "After the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Após a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 352, "src_audio": "/acl6060/audio/en/352.wav", "src_ref": "First generate ah features in the number of classes of the original dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Primeiro gere características no número de classes do conjunto de dados original.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 353, "src_audio": "/acl6060/audio/en/353.wav", "src_ref": "In this example, the original dataset has two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, o conjunto de dados original tem duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 354, "src_audio": "/acl6060/audio/en/354.wav", "src_ref": "So, FeSTE generates two new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, o FeSTE gera duas novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 355, "src_audio": "/acl6060/audio/en/355.wav", "src_ref": "But if the dataset has five classes, FeSTE generates five new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 356, "src_audio": "/acl6060/audio/en/356.wav", "src_ref": "Each feature represents the likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Cada característica representa a probabilidade para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 357, "src_audio": "/acl6060/audio/en/357.wav", "src_ref": "To analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 358, "src_audio": "/acl6060/audio/en/358.wav", "src_ref": "It is but it is not likely that we can train language models using the input datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "É, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 359, "src_audio": "/acl6060/audio/en/359.wav", "src_ref": "So a naive approach will be ah target task finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Portanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 360, "src_audio": "/acl6060/audio/en/360.wav", "src_ref": "So, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 361, "src_audio": "/acl6060/audio/en/361.wav", "src_ref": "In this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 362, "src_audio": "/acl6060/audio/en/362.wav", "src_ref": "Receive the language model output, which is the likelihood for each class and use as new features.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Receba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 363, "src_audio": "/acl6060/audio/en/363.wav", "src_ref": "The problem with this approach is datasets may have few distinct entities / texts.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 364, "src_audio": "/acl6060/audio/en/364.wav", "src_ref": "In our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Na nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 365, "src_audio": "/acl6060/audio/en/365.wav", "src_ref": "So to finetune a language model over ah this dataset will be ineffective.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 366, "src_audio": "/acl6060/audio/en/366.wav", "src_ref": "But we can use prior knowledge about pre-analyzed datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 367, "src_audio": "/acl6060/audio/en/367.wav", "src_ref": "Because FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 368, "src_audio": "/acl6060/audio/en/368.wav", "src_ref": "What we, what we suggest is to add, to add another finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O que nós sugerimos é adicionar outra fase de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 369, "src_audio": "/acl6060/audio/en/369.wav", "src_ref": "A preliminary multitask finetuning phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Uma fase preliminar de ajuste fino multitarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 370, "src_audio": "/acl6060/audio/en/370.wav", "src_ref": "When you finetune the language model over the n minus one datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando se afina o modelo de linguagem sobre n menos um conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 371, "src_audio": "/acl6060/audio/en/371.wav", "src_ref": "And, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 372, "src_audio": "/acl6060/audio/en/372.wav", "src_ref": "The state-of-the-art in multitask ah multitask finetuning called MTDNN.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A última geração em ajuste fino de multitarefa chamado MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 373, "src_audio": "/acl6060/audio/en/373.wav", "src_ref": "In MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 374, "src_audio": "/acl6060/audio/en/374.wav", "src_ref": "So, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Neste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 375, "src_audio": "/acl6060/audio/en/375.wav", "src_ref": "And it samples a random batch from ah from the training set.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E amostra um lote aleatório do conjunto de treinamento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 376, "src_audio": "/acl6060/audio/en/376.wav", "src_ref": "And if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 377, "src_audio": "/acl6060/audio/en/377.wav", "src_ref": "And if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 378, "src_audio": "/acl6060/audio/en/378.wav", "src_ref": "In our scenario, ah tabular datasets vary in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "No nosso cenário, os conjuntos de dados tabulares variam no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 379, "src_audio": "/acl6060/audio/en/379.wav", "src_ref": "So there are many tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Há muitas tarefas.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 380, "src_audio": "/acl6060/audio/en/380.wav", "src_ref": "MTDNN maintained number of classes, heads, output layers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "O MTDNN manteve número de classes, cabeçalhos, camadas de saída.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 381, "src_audio": "/acl6060/audio/en/381.wav", "src_ref": "And the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Adicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 382, "src_audio": "/acl6060/audio/en/382.wav", "src_ref": "Our approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 383, "src_audio": "/acl6060/audio/en/383.wav", "src_ref": "So let's see an example.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Vamos ver um exemplo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 384, "src_audio": "/acl6060/audio/en/384.wav", "src_ref": "Here is the our input dataset which consists of entities, features, text and classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 385, "src_audio": "/acl6060/audio/en/385.wav", "src_ref": "And, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 386, "src_audio": "/acl6060/audio/en/386.wav", "src_ref": "Or in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Ou, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 387, "src_audio": "/acl6060/audio/en/387.wav", "src_ref": "So the label vector in this case stays always ah which consists always with two classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Assim, o vetor de rótulo neste caso consiste sempre em duas classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 388, "src_audio": "/acl6060/audio/en/388.wav", "src_ref": "And this is the ah algorithm for our fine, reformulated finetuning approach.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E este é o algoritmo para a nossa abordagem de ajuste fino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 389, "src_audio": "/acl6060/audio/en/389.wav", "src_ref": "So let's see the full framework.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Então, vamos ver a estrutura completa.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 390, "src_audio": "/acl6060/audio/en/390.wav", "src_ref": "Dataset fed into FeSTE.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Conjunto de dados alimentado no FeSTE.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 391, "src_audio": "/acl6060/audio/en/391.wav", "src_ref": "And then ah FeSTE executes entity linking phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E então o FeSTE executa a fase de entity linking.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 392, "src_audio": "/acl6060/audio/en/392.wav", "src_ref": "It ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Extrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 393, "src_audio": "/acl6060/audio/en/393.wav", "src_ref": "Then it reformulated the task into a pairwise sentence classification task.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, reformulou a tarefa numa tarefa de sentence classification par a par.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 394, "src_audio": "/acl6060/audio/en/394.wav", "src_ref": "Applied the language model to the new task and the output likelihood for each class.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 395, "src_audio": "/acl6060/audio/en/395.wav", "src_ref": "And now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 396, "src_audio": "/acl6060/audio/en/396.wav", "src_ref": "Then we use the output vector of the language model as a newly generated feature in the number of classes.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 397, "src_audio": "/acl6060/audio/en/397.wav", "src_ref": "To evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 398, "src_audio": "/acl6060/audio/en/398.wav", "src_ref": "And as knowledge base we use Wikipedia.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E como base de conhecimento, usamos a Wikipédia.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 399, "src_audio": "/acl6060/audio/en/399.wav", "src_ref": "We design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Projetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 400, "src_audio": "/acl6060/audio/en/400.wav", "src_ref": "We also, we also split each dataset into four folds and apply four folds cross validation.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Também dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 401, "src_audio": "/acl6060/audio/en/401.wav", "src_ref": "Then, we generate the new features and evaluate them using five evaluation classifiers.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Em seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 402, "src_audio": "/acl6060/audio/en/402.wav", "src_ref": "We use in our experiments base BERT base architecture.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usamos na nossa base de experiências da arquitetura básica do BERT.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 403, "src_audio": "/acl6060/audio/en/403.wav", "src_ref": "Here are the results for our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aqui estão os resultados para as nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 404, "src_audio": "/acl6060/audio/en/404.wav", "src_ref": "You can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Pode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 405, "src_audio": "/acl6060/audio/en/405.wav", "src_ref": "And our reformulated finetuning achieves the best result, the best performance.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 406, "src_audio": "/acl6060/audio/en/406.wav", "src_ref": "While MTDNN achieved two percent improvement over the target dataset finetuning.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Enquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 407, "src_audio": "/acl6060/audio/en/407.wav", "src_ref": "Our approach achieved six percent improvement.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "A nossa abordagem alcançou uma melhoria de seis por cento.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 408, "src_audio": "/acl6060/audio/en/408.wav", "src_ref": "When we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Quando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 409, "src_audio": "/acl6060/audio/en/409.wav", "src_ref": "But our performance increased to eleven percent compared to the target task finetuning alone.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 410, "src_audio": "/acl6060/audio/en/410.wav", "src_ref": "For summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Para resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 411, "src_audio": "/acl6060/audio/en/411.wav", "src_ref": "It uses one architecture for all tasks and datasets.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Usa uma arquitetura para todas as tarefas e conjuntos de dados.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 412, "src_audio": "/acl6060/audio/en/412.wav", "src_ref": "And it keeps the head of ah of the model.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "E mantém o cabeçalho do modelo.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 413, "src_audio": "/acl6060/audio/en/413.wav", "src_ref": "But it adds reformulation phase.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Mas acrescenta uma fase de reformulação.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 414, "src_audio": "/acl6060/audio/en/414.wav", "src_ref": "It augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Aumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 415, "src_audio": "/acl6060/audio/en/415.wav", "src_ref": "Thank you.", "src_lang": "en", "benchmark_metadata": {"context": "short", "dataset_type": "longform", "subset": "eval"}, "tgt_ref": "Obrigado.", "tgt_lang": "pt"}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.111", "sample_id": 416, "src_audio": "/acl6060/audio/en/416.wav", "src_ref": "Hello. My name is Asaf Harari.\nAnd I will present our paper, Few-Shot Tabular Data Enrichment Using Fine-Tuned Transformers Architectures.\nData scientists analyze data and mainly focus on the manipulating the data's existing features.\nBut sometimes, these features are limited.\nFeature generation using another data source may add substantial information.\nOur research goal is automatic tabular data enrichment using external sources' free text.\nAssume we have a tabular dataset and a knowledge base.\nWe need an automatic process which involves entity linking and text analysis to extract new features from the knowledge base's free text.\nOur framework FeSTE is exactly this automatic process.\nSo let's see an example in a dataset fed into FeSTE.\nIn this example, the dataset is university dataset.\nWhen its goal is to classify universities into low ranking universities and high-ranking universities.\nAs knowledge base, we use Wikipedia.\nThe first phase of FeSTE is entity linking.\nWhen each entity, in this example the university name, is linked to an entity within the knowledge base.\nAnd and the text of the entities of the knowledge base is extracted and added to the dataset.\nIn this example, the text is the Wikipedia page's abstract.\nNow, we need to generate or extract features from the retrieved text.\nSo, we need to ah feature extraction phase ah which includes text analysis.\nAnd this is the main novelty of this paper and I will deep dive into it in the next slides.\nAfter the feature extraction phase, there is a feature generation phase when we use the extracted features to generate a small number of new features.\nFirst generate ah features in the number of classes of the original dataset.\nIn this example, the original dataset has two classes.\nSo, FeSTE generates two new features.\nBut if the dataset has five classes, FeSTE generates five new features.\nEach feature represents the likelihood for each class.\nTo analyze the text, we use the current state-of-the-art of text analysis, which are transformer based language models as BERT, GPT,  XLNet and etc.\nIt is but it is not likely that we can train language models using the input datasets.\nSo a naive approach will be ah target task finetuning.\nSo, in the feature extraction phase, we can download pretrained language models, finetune the language model over the target dataset.\nIn this example to finetune the language model, to classify ah to classify text into classes, abstract into classes, low or high.\nReceive the language model output, which is the likelihood for each class and use as new features.\nThe problem with this approach is datasets may have few distinct entities / texts.\nIn our experiment, almost half of the datasets contain less than four hundred samples and the smallest dataset contain thirty five samples in its, in a training set.\nSo to finetune a language model over ah this dataset will be ineffective.\nBut we can use prior knowledge about pre-analyzed datasets.\nBecause FeSTE, we apply FeSTE over a multiple dataset, we can use the n minus one datasets to gather information about the n minus one datasets, and use this information when we analyze the nth dataset.\nWhat we, what we suggest is to add, to add another finetuning phase.\nA preliminary multitask finetuning phase.\nWhen you finetune the language model over the n minus one datasets.\nAnd, then we execute another finetuning phase which is a target task finetuning, when you fine when we finetune the language model over the nth target dataset.\nThe state-of-the-art in multitask ah multitask finetuning called MTDNN.\nIn MTDNN, MTDNN maintains ah heads in the number of tasks in the training set.\nSo, in this example there are four tasks in the training set, so MTDNN maintain four heads as you can see at the image.\nAnd it samples a random batch from ah from the training set.\nAnd if they random batch belongs to a, for example single sentence classification task, it executes forward and backward paths through the first head.\nAnd if the random batch belongs to pairwise ranking task, it executes forward and backward path through the last head.\nIn our scenario, ah tabular datasets vary in the number of classes.\nSo there are many tasks.\nMTDNN maintained number of classes, heads, output layers.\nAnd the additional, additionally MTDNN needs to initialize new heads for a new dataset with a new task.\nOur approach, called task reformulation finetuning is, in our approach task reformulation finetuning, instead of maintaining multiple heads, we reformulate each dataset into a sentence per classification problem, which is two classes' tasks.\nSo let's see an example.\nHere is the our input dataset which consists of entities, features, text and classes.\nAnd, we reformulate the task from a classifying the text into low or high to classify the text, the abstract and the class into true or false.\nOr in other words, we trained the language model to classify an abstract and class ah to abstract and class ah, if the abstract belongs to the class or not.\nSo the label vector in this case stays always ah which consists always with two classes.\nAnd this is the ah algorithm for our fine, reformulated finetuning approach.\nSo let's see the full framework.\nDataset fed into FeSTE.\nAnd then ah FeSTE executes entity linking phase.\nIt ah it extracts the text from the knowledge base, which in this example is the abstract of the Wikipedia page.\nThen it reformulated the task into a pairwise sentence classification task.\nApplied the language model to the new task and the output likelihood for each class.\nAnd now that the language model is already finetuned over n minus one dataset using a preliminary multitask finetuning.\nThen we use the output vector of the language model as a newly generated feature in the number of classes.\nTo evaluate our framework, we use ah seventeen tabular classification datasets which vary in size, features, balance, domain and initial performance.\nAnd as knowledge base we use Wikipedia.\nWe design our experiment as leave one out ah evaluation where we train FeSTe over sixteen datasets and apply it to the seventeenth dataset.\nWe also, we also split each dataset into four folds and apply four folds cross validation.\nThen, we generate the new features and evaluate them using five evaluation classifiers.\nWe use in our experiments base BERT base architecture.\nHere are the results for our experiments.\nYou can see that we compare our our framework to target dataset finetuning, target task finetuning, and a MTDNN preliminary finetuning.\nAnd our reformulated finetuning achieves the best result, the best performance.\nWhile MTDNN achieved two percent improvement over the target dataset finetuning.\nOur approach achieved six percent improvement.\nWhen we look on the small ah dataset, we can see that the performance of MTDNN decreases and the improvement of the prelim, the preliminary multitask finetuning phase decreases to one point five percent.\nBut our performance increased to eleven percent compared to the target task finetuning alone.\nFor summing, FeSTE enables few shot enrichment from thirty five samples in our experiments.\nIt uses one architecture for all tasks and datasets.\nAnd it keeps the head of ah of the model.\nBut it adds reformulation phase.\nIt augments the train set and it needs a target value with semantic meaning so we can feed it into the language model and use it in the sentence pair classification problem.\nThank you.", "tgt_ref": "Olá. Chamo-me Asaf Harari.\nE vou apresentar o nosso artigo, Enriquecimento tabular de dados em poucos disparos que usam arquiteturas de transformadores com ajuste fino.\nOs cientistas de dados analisam dados e concentram-se principalmente na manipulação das características existentes dos dados.\nMas, por vezes, estas características são limitadas.\nA geração de características que usa outra fonte de dados pode adicionar informação substancial.\no nosso objetivo de pesquisa é o enriquecimento de dados tabular automático usando texto livre de fontes externas.\nSuponhamos que temos um conjunto de dados tabular e uma base de conhecimento.\nPrecisamos de um processo automático que envolva entity linking e análise de texto para extrair novas características do texto livre da base de conhecimento.\nA nossa estrutura FeSTE é exatamente esse processo automático.\nVamos ver um exemplo num conjunto de dados alimentado no FeSTE.\nNeste exemplo, o conjunto de dados é um conjunto de dados universitário.\nQuando o seu objetivo é classificar as universidades em universidades de baixo escalão e universidades de alto escalão.\nComo base de conhecimento, usamos a Wikipédia.\nA primeira fase do FeSTE é entity linking.\nQuando cada entidade, neste exemplo, o nome da universidade, está vinculado a uma entidade dentro da base de conhecimento.\nE o texto das entidades da base de conhecimento é extraído e adicionado ao conjunto de dados.\nNeste exemplo, o texto é o resumo da página da Wikipédia.\nAgora, precisamos de gerar ou extrair características do texto recuperado.\nEntão, precisamos da fase de extração de características que inclui análise de texto.\nE esta é a principal novidade deste artigo, e eu vou mergulhar a fundo nele nos próximos diapositivos.\nApós a fase de extração do características, há uma fase de geração de características quando usamos as características extraídas para gerar um pequeno número de novas características.\nPrimeiro gere características no número de classes do conjunto de dados original.\nNeste exemplo, o conjunto de dados original tem duas classes.\nEntão, o FeSTE gera duas novas características.\nMas se o conjunto de dados tiver cinco classes, o FeSTE gera cinco novas características.\nCada característica representa a probabilidade para cada classe.\nPara analisar o texto, usamos análise de texto de última geração, que são modelos de linguagem baseados em transformadores como BERT, GPT, XLNet, etc.\nÉ, mas não é provável que possamos treinar modelos de linguagem usando os conjuntos de dados de entrada.\nPortanto, uma abordagem ingénua será o ajuste fino da tarefa de destino.\nAssim, na fase de extração de características, podemos transferir modelos de linguagem pré-treinada, ajustar o modelo de linguagem sobre o conjunto de dados de destino.\nNeste exemplo para ajustar o modelo de linguagem, para classificar texto em classes, resumo em classes, baixo ou alto.\nReceba a saída do modelo de linguagem, que é a probabilidade para cada classe e use como novas características.\nO problema com esta abordagem é que o conjuntos de dados pode ter algumas entidades/textos distintos.\nNa nossa experiência, quase metade dos conjuntos de dados contém menos de quatrocentas amostras e o menor conjunto de dados contém trinta e cinco amostras num conjunto de treinamento.\nEntão, ajustar um modelo de linguagem sobre este conjunto de dados será ineficaz.\nMas podemos usar conhecimento prévio sobre conjuntos de dados pré-analisados.\nAplicamos o FeSTE sobre um conjunto de dados múltiplo, podemos usar n menos um conjuntos de dados para recolher informações sobre n menos um conjuntos de dados e usar esta informação quando analisamos o enésimo conjunto de dados.\nO que nós sugerimos é adicionar outra fase de ajuste fino.\nUma fase preliminar de ajuste fino multitarefa.\nQuando se afina o modelo de linguagem sobre n menos um conjuntos de dados.\nE, em seguida, executamos outra fase de ajuste fino que é um ajuste fino de tarefa de destino, quando se faz o ajuste fino do modelo de linguagem sobre o enésimo conjunto de dados de destino.\nA última geração em ajuste fino de multitarefa chamado MTDNN.\nO MTDNN mantém cabeçalhos no número de tarefas no conjunto de treinamento.\nNeste exemplo, há quatro tarefas no conjunto de treinamento, então o MTDNN mantenha quatro cabeçalhos como se pode ver na imagem.\nE amostra um lote aleatório do conjunto de treinamento.\nE se o lote aleatório pertence a, por exemplo, uma única tarefa sentence classification, executa percursos para frente e para trás através do primeiro cabeçalho.\nE se o lote aleatório pertence à classificação de tarefa de par a par, executa o percurso para frente e para trás através do último cabeçalho.\nNo nosso cenário, os conjuntos de dados tabulares variam no número de classes.\nHá muitas tarefas.\nO MTDNN manteve número de classes, cabeçalhos, camadas de saída.\nAdicionalmente, o MTDNN precisa de inicializar novos cabeçalhos para um novo conjunto de dados com uma nova tarefa.\nA nossa abordagem, chamada ajuste fino de reformulação de tarefas, é, em vez de manter várias cabeças, reformulamos cada conjunto de dados numa frase por problema de classificação, que são tarefas de duas classes.\nVamos ver um exemplo.\nAqui está o nosso conjunto de dados de entrada que consiste em entidades, características, texto e classes.\nE, reformulamos a tarefa de uma classificação do texto em baixa ou alta para classificar o texto, o resumo e a classe em verdadeira ou falsa.\nOu, em outras palavras, treinámos o modelo de linguagem para classificar um resumo e uma classe e se o resumo pertence à classe ou não.\nAssim, o vetor de rótulo neste caso consiste sempre em duas classes.\nE este é o algoritmo para a nossa abordagem de ajuste fino.\nEntão, vamos ver a estrutura completa.\nConjunto de dados alimentado no FeSTE.\nE então o FeSTE executa a fase de entity linking.\nExtrai o texto da base de conhecimento, que neste exemplo é o resumo da página da Wikipédia.\nEm seguida, reformulou a tarefa numa tarefa de sentence classification par a par.\nAplicou o modelo de linguagem à nova tarefa e a probabilidade de saída para cada classe.\nE agora que o modelo de linguagem já está ajustado sobre n menos um conjunto de dados usando um ajuste fino multitarefa preliminar.\nEm seguida, usamos o vetor de saída do modelo de linguagem como um recurso recém gerado no número de classes.\nPara avaliar a nossa estrutura, usamos dezessete conjuntos de dados de classificação tabulares que variam em tamanho, características, equilíbrio, domínio e desempenho inicial.\nE como base de conhecimento, usamos a Wikipédia.\nProjetamos a nossa experiência como uma avaliação de deixar um de fora, onde treinamos o FeSTe ao longo de dezasseis conjuntos de dados e aplicamo-lo ao décimo sétimo conjunto de dados.\nTambém dividimos cada conjunto de dados em quatro dobras e aplicamos a validação cruzada de quatro dobras.\nEm seguida, geramos as novas características e os avaliamo-las usando cinco classificadores de avaliação.\nUsamos na nossa base de experiências da arquitetura básica do BERT.\nAqui estão os resultados para as nossas experiências.\nPode ver-se que comparamos a nossa estrutura com ajuste fino de conjunto de dados de destino e ajuste fino preliminar de um MTDNN.\nE o nosso ajuste fino reformulado alcança o melhor resultado, o melhor desempenho.\nEnquanto que o MTDNN alcançou 2% de melhoria em relação ao ajuste fino do conjunto de dados de destino.\nA nossa abordagem alcançou uma melhoria de seis por cento.\nQuando olhamos para o pequeno conjunto de dados, podemos ver que o desempenho do MTDNN diminui e a melhoria da fase de ajuste fino multitarefa preliminar diminui para 1,5%.\nMas o nosso desempenho aumentou para onze por cento comparado com o ajuste fino da tarefa de destino sozinho.\nPara resumir, o FeSTE permite o enriquecimento de poucos tiros a partir de trinta e cinco amostras nas nossas experiências.\nUsa uma arquitetura para todas as tarefas e conjuntos de dados.\nE mantém o cabeçalho do modelo.\nMas acrescenta uma fase de reformulação.\nAumenta o conjunto de treino e precisa de um valor de destino com significado semântico para que possamos alimentá-lo no modelo de linguagem e usá-lo no problema de classificação do sentence pair.\nObrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.410", "sample_id": 417, "src_audio": "/acl6060/audio/en/417.wav", "src_ref": "Hi everyone. Today I'm going to present our research work Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction.\nI'm Allan from ByteDance AI Lab, and this is a joint work with Jierui Li from the University of Texas at Austin and Wei Lu from SUTD.\nFirst, I'd like to talk about our motivation for reasoning.\nSo here we show an examples where multi-step reasoning is helpful.\nSo this figure is taken from the PaLM paper where they perform prompting to solve the network problem in the few shot learning scenario.\nSo on the left hand side, we can see if we give some examples with just question and answers, we might not be able to obtain the correct answers.\nBut if we give some more reasoning description, the model is able to predict the reasoning description and also make a correct prediction here.\nSo it is good to have interpretable multi-step reasoning as output.\nAnd we also think math word problem is a straightforward application to evaluate such reasoning abilities.\nSo, here in our problem setup, given the questions we need to solve this question and obtain the numerical answers.\nSo in our datasets we are also given the mathematical expression which leads to the ah to this particular answer as well.\nSo, certain assumptions ah also apply as in previous work.\nWe assume the precision of quantities are known.\nAnd we only consider basic operators such as addition, subtractions, multiplication, division, and exponential.\nFurthermore, complicated operators can be actually decomposed into these basic operators.\nSo, previous work in math word problem solving ah actually can ah be categorized into sequence to sequence and sequence to tree model.\nSo, traditional sequence to sequence model convert the expression to a specific sequence for generation.\nAnd it is pretty easy to implement and it can generalize to many different complicated problem.\nBut the drawbacks are the performance is actually generally not better than the structured model and its lack of interpretability for prediction.\nBut actually this direction is still quite popular because of um the transformer model.\nSo, in tree based models, we actually structure these expressions in the tree form and follow a preordered traversal in tree generations.\nSo here we keep generating the operators until we reach the leaves, which are the quantities.\nSo here the good thing is that it actually gives us this binary tree structure, and it is um but actually it is quite counterintuitive because we generate the operator first and then at the end we generate the quantities.\nAnd the second thing is that it also contains some repetitive computations.\nSo here if we look at this expression, eight times three plus three is actually generated twice, but in fact we should reuse the results.\nSo, in our proposed approach we want to solve those problems in a step by step and interpretable manners.\nSo for example, here in the second step, ah we can obtain these divisors which is twenty seven.\nAnd we can also refer back to the original questions to find the relevant contents.\nAnd in these steps we obtain the divisors.\nSo, ah and then at this third step we actually get the quotient.\nAlright. And after these three steps, we can actually reuse the results from the second step, and then get the ah results of the fourth step, and then finally we can obtain the dividends.\nSo, here we actually generate the whole expression directly rather than generating a single operators or quantities.\nSo this makes the process more accurate.\nSo, in our deductive system, we first start with a bunch of quantities presented in the questions and also including some constant as our initial state ah initial state.\nSo, the expression is represented by e i j o p.\nWhere we perform operator from q_i to q_j, and such expression is actually directed.\nSo, we also have subtraction with words here to represent the opposite direction.\nThis is quite similar to relation extraction.\nSo in a formal deductive system, at a time step t, we apply the operator between the q_i and q_j pair, and then we obtain this new expression.\nWe add it to the next state to become a new quantity.\nSo, these slides actually visualize the evolution of the state where we keep adding expression to the current state.\nSo in our model implementations, we first use a pretrained language model which can be BERTs or Robertas and then we encode the sentence and then we obtain these quantity representations.\nSo, once we get the quantity representations, we can start to do inference.\nHere we show an example of q_1 to obtain the representation for q_2 divided by q_2 and then times q_3.\nFirst we get the ah pair representation, which is basically just the concatenation between q_1 and q_2, and then we apply a feedforward network which is parameterized by the operator.\nAnd then finally we obtain the expression representation q_1 divided by q_2.\nBut in fact, in practice, in the inference stage, we might ah be able to get the incorrect expression as well.\nSo, here all the possible expression is equals to three times the number of operators.\nSo the nice thing here is that we can easily add constraints to control this search this search space.\nFor example, if this expression is not allowed, we can simply remove this expression in our search space.\nSo in the second step, we do the same thing, but the only difference is that we ah the only difference is one more quantities.\nSo this quantity come from the previous calculated expression.\nSo finally we can obtain this final expression q_3 times q_4.\nAnd we can also see the number of all the possible ah expression is different from the previous step.\nSo, ah such difference make it hard to apply beam search because the probability distribution between these two steps is unbalanced.\nSo the training procedure is similar to training a sequence to sequence model where we optimize the loss at each time step.\nAnd here we also use this tau to represent when we should terminate this generation process.\nAnd here the space is different from sequence to sequence because the space is different at each time step while in traditional sequence to sequence model this is the number of vocabulary.\nAnd it also allows us to impose certain constraints from prior from prior knowledge.\nSo we conduct experiments on the commonly used math word problem datasets, MAWPS, Math23K,  MathQA and SVAMP.\nAnd here we briefly show the results compared with the previous best approaches.\nSo our best performing variant is Roberta-DeductiveReasoner.\nAnd in fact we do not use beam search, in contrast all previous approaches are using beam search.\nAll right. So, the best approaches are often tree based model.\nSo, overall our reasoner is able to significantl significantly outperform this tree based model.\nBut we can see the absolute numbers on MathQA or SVAMP are not really high.\nSo we further investigate the results on SVAMP.\nAnd this dataset is challenging because the author tried to manually ah adding something to confuse the NLP model like such as adding irrelevant information and extra quantities.\nSo, in our prediction we find some of the intermediate values are actually negatives.\nFor example, um, in these questions we are asking how many apples does Jake have?\nBut we have some extra information like seventeen fewer pictures, and Steven has eight pictures, which is totally irrelevant.\nSo, our model makes some prediction like this which is producing negative values.\nAnd we observe these two expressions actually have similar scores.\nSo, we can actually limit this search space by removing those results that are negatives so that we can make the ah make the answer correct.\nSo um we further find such constraint actually improves quite a lot for some models.\nFor example, for BERT, we improve seven points and then for the Roberta base model we actually improved two points.\nSo better language model has better language understanding abilities so that the number here is higher for Roberta and lower for BERT.\nAnd we also try to analyze the difficulty behind these behind all these datasets.\nWe assume the number of unused quantities can be regarded as irrelevant information here.\nSo ah here we can see that ah,we have the the percentage of samples with unused quantities, and the SVAMP dataset has the largest portion.\nAnd here we also show the overall performance.\nFor those samples without unused quantities, so the overall performance is actually higher than the, the performance is actually higher than the overall performance.\nBut with those samples that with unused quantity is actually way worse than the, worse than the overall performance.\nFor MAWPS, we don't we don't really have ah too many test cases, so I just ignore this part.\nSo, finally we want to show the interpretability through a question perturbation example.\nSo here our model actually makes a wrong prediction at the first step.\nSo, we can actually correlate this expression with the sentence here. Alright.\nSo, we think this sentence might be misleading the model to an incorrect predictions.\nSo here planting another thirty five makes the model makes the model think it should be an addition operator.\nSo we try to revise the sentence to be something like the number of pear trees are thirty five fewer than the apple trees.\nSo, we make it to convey more accurate semantics such that the model is able to make um the prediction correct.\nSo, this study shows how the interpretable predictions help us understand the model behavior.\nSo to conclude our work, so first our model is actually pretty efficient.\nAnd we are able to provide interpretable solving procedure.\nAnd we can easily incorporate some prior knowledge as constraint which can help improve the performance.\nAnd the last thing is that the underlying mechanism does not only apply to network problem solving tasks but also other tasks that involve multi step reasoning.\nWe also have certain limitations.\nAh, if we have a large number of operators or constants, the memory consumption could be pretty high.\nAnd the second thing is that, as mentioned, because the probability distribution is unbalanced between different time steps, so it's also pretty challenging to apply beam search strategy.\nSo this is the end of the talk, and questions are welcomed. Thank you.", "tgt_ref": "Olá a todos. Hoje vou apresentar o nosso trabalho de pesquisa Aprendizagem para raciocinar dedutivamente: resolução de math word problem como relation extraction complexas.\nSou o Allan do ByteDance IA Lab, e este é um trabalho conjunto com Jierui Li, da Universidade do Texas em Austin, e Wei Lu, da SUTD.\nPrimeiro, gostaria de falar sobre a nossa motivação para o raciocínio.\nMostramos aqui exemplos em que o raciocínio em vários passos é útil.\nEste número é retirado do artigo PaLM, onde eles realizam solicitações para resolver o problema da rede no cenário de aprendizagem curta.\nEntão, no lado esquerdo, podemos ver que, se dermos alguns exemplos com apenas pergunta e respostas, podemos não conseguir obter as respostas corretas.\nMas se dermos uma descrição de raciocínio, o modelo é capaz de prever a descrição de raciocínio e também fazer uma previsão correta aqui.\nÉ bom ter raciocínio interpretável multietapas como saída.\nE também achamos que math world problem é uma aplicação direta para avaliar tais capacidades de raciocínio.\nAqui na nossa configuração de problema, damos as perguntas de precisamos para resolver essa pergunta e obter as respostas numéricas.\nAssim, nos nossos conjuntos de dados, também recebemos a expressão matemática que leva a essa resposta em particular.\nAssim, certas suposições também se aplicam como no trabalho anterior.\nAssumimos que a precisão das quantidades é conhecida.\nE consideramos apenas operadores básicos como adição, subtração, multiplicação, divisão e exponencial.\nAlém disso, os operadores complicados podem ser realmente decompostos nestes operadores básicos.\nAssim, o trabalho anterior em resolução de math word problem pode realmente ser categorizado em sequência para sequência e sequência para modelo de árvore.\nAssim, o modelo tradicional de sequência para sequência converte a expressão para uma sequência para geração específica.\nE é muito fácil de implementar e pode generalizar para muitos problemas complicados diferentes.\nMas as desvantagens são que o desempenho geralmente não é melhor do que o modelo estruturado e a sua falta de interpretabilidade para previsão.\nMas, na verdade, esta direção ainda é bastante popular por causa do modelo transformador.\nEntão, em modelos baseados em árvore, nós realmente estruturamos estas expressões na forma de árvore e seguimos uma travessia preordenada em gerações de árvores.\nEntão, aqui continuamos a gerar os operadores até chegarmos às folhas, que são as quantidades.\nO que é bom aqui é que realmente nos dá esta estrutura de árvore binária, e é, mas na verdade é bastante contraintuitivo porque geramos o operador primeiro e depois, no final, geramos as quantidades.\nE a segunda coisa é que também contém alguns cálculos repetitivos.\nAqui, se olharmos para esta expressão, oito vezes três mais três é realmente gerado duas vezes, mas na verdade devemos reutilizar os resultados.\nEntão, na nossa abordagem proposta, queremos resolver estes problemas passo a passo e de formas interpretáveis.\nEntão por exemplo, aqui no segundo passo, podemos obter estes divisores, vinte e sete.\nE também podemos consultar de novo as perguntas originais para encontrar os conteúdos relevantes.\nE nestes passos obtemos os divisores.\nE então neste terceiro passo nós conseguimos obter o quociente.\nCerto. E após estes três passos, podemos mesmo reutilizar os resultados do segundo passo e, em seguida, obter os resultados do quarto passo e, finalmente, conseguimos obter os dividendos.\nEntão, aqui geramos toda a expressão diretamente em vez de gerar um único operador ou quantidades.\nIsto torna o processo mais preciso.\nNo nosso sistema dedutivo, primeiro começamos com algumas quantidades apresentadas nas perguntas e também incluímos alguma constante como o nosso estado inicial.\nAssim, a expressão é representada por e i j o p.\nOnde realizamos o operador de q_i a q_j, e tal expressão é realmente direcionada.\nEntão, também temos a subtração com palavras aqui para representar a direção oposta.\nIsto é bastante semelhante a relation extraction.\nAssim, num sistema dedutivo formal, num passo de tempo t, aplicamos o operador entre o par q_i e q_j, e então obtemos esta nova expressão.\nAdicionamo-la ao próximo estado para se tornar uma nova quantidade.\nÉ possível visualizar nestes diapositivos a evolução do estado em que continuamos a adicionar expressão ao estado atual.\nNas nossas implementações de modelo, primeiro usamos um modelo de linguagem pré-treinada que pode ser BERTs ou Robertas e depois codificamos a frase e então obtemos estas representações de quantidades.\nAssim que obtemos as representações de quantidade, podemos começar a fazer inferência.\nAqui mostramos um exemplo de q_1 para obter a representação para q_2 dividida por q_2 e depois vezes q_3.\nPrimeiro obtemos a representação de par, que é basicamente apenas a concatenação entre q_1 e q_2, e então aplicamos uma rede de controlo por antecipação que é parametrizada pelo operador.\nE então, finalmente, obtemos a representação da expressão q_1 dividida por q_2.\nMas, de facto, na prática, na fase de inferência, podemos ser capazes de obter também a expressão incorreta.\nAqui, toda a expressão possível é igual a três vezes o número de operadores.\nO que é bom aqui é que podemos facilmente adicionar restrições para controlar este espaço de pesquisa.\nPor exemplo, se esta expressão não for permitida, podemos simplesmente remover esta expressão no nosso espaço de pesquisa.\nEntão, no segundo passo, fazemos a mesma coisa, mas a única diferença é que a única diferença é mais uma quantidade.\nPortanto, esta quantidade vem da expressão calculada anterior.\nEntão podemos finalmente obter esta expressão final q_3 vezes q_4.\nE também podemos ver que o número de todas as expressões possíveis é diferente do passo anterior.\nEntão, tal diferença torna difícil aplicar beam search porque a distribuição de probabilidade entre estes dois passos é desequilibrada.\nAssim, o procedimento de treinamento é semelhante ao treinamento de um modelo de sequência a sequência, onde otimizamos a perda em cada passo de tempo.\nE aqui também usamos este tau para representar quando devemos encerrar este processo de geração.\nE aqui o espaço é diferente de sequência a sequência porque o espaço é diferente em cada passo de tempo, enquanto que no modelo tradicional de sequência a sequência, este é o número de vocabulário.\nE também nos permite impor certas restrições do conhecimento anterior.\nAssim, realizamos experiências nos conjuntos de dados de math word problems, MAWPS, Math23K, MathQA e SVAMP tipicamente usados.\nE aqui mostramos brevemente os resultados comparados com as melhores abordagens anteriores.\nPortanto, a nossa variante com melhor desempenho é Roberta-DeductiveReasoner.\nE, na verdade, não usamos beam search, em contraste, todas as abordagens anteriores estão a usar beam search.\nMuito bem. Assim, as melhores abordagens são muitas vezes baseadas no modelo em árvore.\nEntão, no geral, o nosso raciocinador é capaz de superar significativamente este modelo baseado em árvore.\nMas podemos ver que os números absolutos no MathQA ou SVAMP não são muito altos.\nEntão, investigamos ainda mais os resultados no SVAMP.\nE este conjunto de dados é desafiador porque o autor tentou manualmente adicionar algo para confundir o modelo NLP, como adicionar informações irrelevantes e quantidades extra.\nEntão, na nossa previsão, descobrimos que alguns dos valores intermediários são realmente negativos.\nPor exemplo, nestas perguntas, perguntamos quantas maçãs tem o Jake?\nMas temos algumas informação extra, como dezassete fotografias a menos, e o Steven tem oito fotografias, o que é totalmente irrelevante.\nO nosso modelo faz alguma previsão como esta que está a produzir valores negativos.\nE observamos que estas duas expressões realmente têm classificações semelhantes.\nEntão, podemos realmente limitar este espaço de pesquisa removendo os resultados negativos para que possamos criar uma resposta correta.\nEntão, descobrimos ainda que esta restrição melhora muito para alguns modelos.\nPor exemplo, para BERT, melhoramos sete pontos e depois, para o modelo básico do Roberta, na verdade melhoramos dois pontos.\nUm melhor modelo de linguagem tem melhores capacidades de language understanding para que o número aqui seja maior para o Roberta e menor para o BERT.\nTambém tentamos analisar a dificuldade entre estes por trás de todos estes conjuntos de dados.\nAssumimos que o número de quantidades não utilizadas pode ser considerado informação irrelevante aqui.\nEntão, aqui podemos ver que temos a percentagem de amostras com quantidades não utilizadas, e o conjunto de dados SVAMP tem a maior porção.\nE aqui também mostramos o desempenho geral.\nPara essas amostras sem quantidades não utilizadas, o desempenho é maior do que o desempenho geral.\nMas com essas amostras com quantidades não utilizadas é realmente muito pior do que o desempenho geral.\nPara MAWPS, nós não temos muitos casos de teste, então eu simplesmente ignoro esta parte.\nFinalmente, queremos mostrar a interpretabilidade através de um exemplo de perturbação de pergunta.\nAqui, o nosso modelo, na verdade, faz uma previsão errada no primeiro passo.\nPodemos realmente correlacionar esta expressão com a frase aqui. Certo.\nEntão, achamos que esta frase pode estar a enganar o modelo para previsões incorretas.\nAqui, plantar mais trinta e cinco faz o modelo pensar que deveria ser um operador de adição.\nEntão tentamos rever a frase para ser algo como o número de pereiras são trinta e cinco menos do que as macieiras.\nNós fazemos isto para transmitir uma semântica mais precisa, de modo a que o modelo seja capaz de fazer a previsão correta.\nPortanto, este estudo mostra como as previsões interpretáveis nos ajudam a perceber o comportamento do modelo.\nEntão, para concluir o nosso trabalho, primeiro, o nosso modelo é realmente muito eficiente.\nE somos capazes de fornecer um procedimento de resolução interpretável.\nE podemos facilmente incorporar algum conhecimento prévio como restrição que pode ajudar a melhorar o desempenho.\nE a última coisa é que o mecanismo subjacente não se aplica apenas a tarefas de resolução de problemas de rede, mas também a outras tarefas que envolvem raciocínio de vários passos.\nTambém temos certas limitações.\nSe tivermos um grande número de operadores ou constantes, o consumo de memória pode ser bastante alto.\nE a segunda coisa é que, como mencionado, porque a distribuição de probabilidade é desequilibrada entre diferentes passos de tempo, também é bastante desafiador aplicar a estratégia de beam search.\nEste é o fim da palestra, e perguntas são bem-vindas. Obrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.468", "sample_id": 418, "src_audio": "/acl6060/audio/en/418.wav", "src_ref": "Hi, my name is Antoine and I'm from Maastricht University.\nI will be presenting my joint work with Jerry which is about a New Dataset for Statutory Article Retrieval.\nLegal issues are an integral part of many people's lives.\nBut the majority of citizens have little to know knowledge about their rights and fundamental legal processes.\nAs a result, many vulnerable citizens who cannot afford the costly assistance of a legal expert are left unprotected or, worst, exploited.\nAll work aims to bridge the gap between people and the law by developing an effective retrieval system for statutory articles.\nSuch a system could provide a free professional legal help service for unskilled humans.\nBefore diving into the main contribution of this work, let's first describe the problem of statutory article retrieval.\nGiven a simple question on a legal matter such as, what do I risk if I violate professional confidentiality?\nA model is required to retrieve all relevant statutory articles from a large body of legislation.\nThis information retrieval task comes with its own set of challenges.\nFirst, it deals with two types of language.\nCommon natural language for the questions and complex legal language for the statutes.\nThis difference in language distributions makes it harder for a system to retrieve relevant candidates, as it indirectly requires an inherent interpretation system that can translate a natural question to a legal question that matches the terminology of statutes.\nBesides, statutory law is not a stack of independent articles that can be treated as a complete source of information on their own, unlike news or recipes, for example.\nInstead, it's a structured collection of legal provisions that have a whole meaning only when considered in the overall context, that is, together with the supplementary information from the neighboring articles, the fields and subfields they belong to, and their place in the structure of the law.\nLastly, statutory articles aren't small paragraphs which usually is the typical retrieval unit in most retrieval works.\nHere, there are long documents that may be up to six thousand words.\nThe recent advances in NLP have sparked huge interest in many legal tasks, such as legal judgment prediction or automated contact contract review.\nBut statutory article retrieval has remained mainly untouched due to the lack of large and high quality labeled datasets.\nIn this work, we present a new French native citizen-centric dataset to study whether retrieval models can approximate the efficiency and reliability of a legal expert for the task of statutory article retrieval.\nOur Belgian statutory article retrieval dataset BSARD consists of more than one thousand one hundred legal questions posed by Belgian citizens.\nThese questions cover a wide range of topics from family, housing, money, to work and social security.\nEach of them has been labeled by experienced jurists with references to relevant articles from a corpus of more than twenty-two thousand six hundred legal articles from Belgian codes of law.\nLet's now talk about how we collected this dataset.\nFirst, we started by compiling a large corpus of legal articles.\nWe considered thirty two publicly available Belgian codes and extracted all the articles as well as the corresponding section headings.\nThen we gathered legal questions with references to relevant statutes.\nTo do so, we partner with the Belgian law firm that receives each year around four thousand emails from Belgian citizens who ask for advice on a personal legal issue.\nWe were lucky enough to get access to their websites, where their team of experienced jurists addresses Belgians' most common legal issues.\nWe collected thousands of questions annotated with categories, subcategories and legal references to relevant statutes.\nLastly, we passed the legal references and filtered out the questions whose references were not articles in one of the codes of law we considered.\nThe remaining references were matched and converted to the corresponding article ids from our corpus.\nWe eventually ended up with one thousand one hundred and eight questions, each carefully labeled with the ids of the relevant articles from our large corpus of twenty two thousands and six hundred thirty three statutory articles.\nIn addition, each question comes with the main category and a concatenation of subcategories.\nAnd each articles comes with a concatenation of the subsequence heading in the structure of the law.\nThis extra information is not used in the present work, but might be of interest for future research on legal information retrieval or legal text classification.\nLet's look at some characteristic of our dataset.\nThe questions are between five and forty four words long with a median of fourteen words.\nThe articles are much longer with a median length of seventy seven words, with one hundred and forty two of them exceeding one thousand words.\nThe lengthiest one being up to five thousand seven hundred and ninety words.\nAs previously mentioned, the questions cover a wide range of topics, with around eighty five percent of them being either about family, housing, money or justice.\nWhile the remaining fifteen percent concern either social security, foreigners or work.\nThe article are also very diverse as they come from thirty two different Belgian codes that cover a large number of legal topics.\nHere's the total number of articles collected from each of these Belgian codes.\nOut of the twenty two thousand six hundred and thirty three articles, only one thousand six hundred and twelve are referred to as relevant to at least one question in the dataset.\nAnd around eighty percent of these cited articles come from either the civil code, judicial codes, criminal investigation codes or penal codes.\nMeanwhile, eighteen out of thirty two codes have less than five articles mentioned as relevant to at least one question.\nWhich can be explained by the fact that those codes focused less on individuals and their concerns.\nOverall, the median number of citations for these cited articles is two, and less than twenty-five percent of them are cited more than five times.\nUsing all datasets, we benchmarked several retrieval approaches, including lexical and dense architecture.\nGiven a query and an article, a lexical model assigns a score to the query article pair by computing the sum over the query terms of the weights of each of these terms in that article.\nWe experiment with the standard TF-IDF and BM25 ranking functions.\nThe main problem with these approaches is that they can only retrieve articles that contain keywords present in the query.\nTo overcome this limitation, we experiment with a neural based architecture that can capture semantic relationships between queries and article.\nWe use a bi-encoder model that maps queries and articles into dense vector representations and calculate a relevance score between a query article pair by the similarity of their embeddings.\nThese embeddings typically result from a pooling operation on the output of a word embedding model.\nFirst, we study the effectiveness of Siamese bi-encoders in a zero shot evaluation setup, meaning that pretrained word embedding models are applied out-of-the-box without any additional finetuning.\nWe experiment with context independent text encoder, namely word2vec and fastText, and context dependent embedding models, namely Roberta and more specifically CamemBERT which is a French Roberta model.\nAdditionally, we train our own CamemBERT based model ah bi-encoders on our dataset.\nNote that for training, we experiment with the two flavors of the bi-encoder architecture.\nSiamese, which uses a unique word embedding model that maps the query and article together in a shared dense vector space, and two-tower, which uses two independent word embedding models that encode the query and article separately into different embedding spaces.\nWe experiment with mean, max and CLS pooling as well as product and cosine for computing similarities.\nHere are the result of our baseline on the test sets.\nWith the lexical methods above, the Siamese bi-encoders evaluated in a zero shot setup in the middle, and the finetuned bi-encoders below.\nOverall, the finetuned bi-encoder significantly outperforms all the other baselines.\nThe two-tower model improves over its Siamese variants on recall at one hundred, but performs similarly on the other metrics.\nAlthough BM25 underperformed the trained bi-encoder significantly, its performance indicated that it's still a strong baseline for domain specific retrieval.\nRegarding the zero shot evaluation of Siamese bi-encoder, we find that directly using the embeddings of a pretrained CamemBERT model without optimizing for the information retrieval task gives poor results, which is consistent with previous findings.\nFurthermore, we observe that the word2vec based bi-encoder significantly outperformed the fastText and BERT based models, suggesting that maybe pretrained word level embeddings are more appropriate for the task than character level or subword level embeddings when used out of the box.\nAlthough promising, these results suggest ample opportunity for improvement compared to a skilled legal expert who can eventually retrieve all relevant articles to any question and thus get perfect scores.\nLet's conclude by discussing two limitations of our dataset.\nFirst, the corpus of article is limited to those collected from the thirty two considered Belgian codes, which does not cover the entire Belgian law as articles from decrees, directives and ordinances are missing.\nDuring the dataset construction, all references to these uncollected articles are ignored, which causes some questions to end up with only a fraction of the initial number of relevant articles.\nThis information thus implies that the answer contained in the remaining relevant articles might be incomplete, although it's still completely appropriate.\nSecond, we should note that not all legal questions can be answered with statutes alone.\nFor instance, the question, can I evict my tenants if they make too much noise?\nMight not have a detailed answer within statutory law that quantifies a specific noise threshold at which eviction is allowed.\nInstead, the landlord should probably rely more on case law and find precedents similar to their current situation.\nFor example, the tenants makes two parties a week until two AM.\nHence, some question are better suited than others to the statutory article retrieval task, and the domain of the less suitable ones remains to be determined.\nWe hope that our work sparks interest in developing practical and reliable statutory article retrieval models.\nThat can help improve access to justice for all.\nYou can check out our paper, dataset and code at the following links. Thank you.", "tgt_ref": "Olá, o meu nome é Antoine e sou da Universidade de Maastricht.\nVou apresentar o meu trabalho conjunto com o Jerry, sobre um Novo conjunto de dados para recuperação de artigos estatutários.\nQuestões legais são parte integrante da vida de muitas pessoas.\nMas a maioria dos cidadãos tem pouco a nenhum conhecimento sobre os seus direitos e processos legais fundamentais.\nComo resultado, muitos cidadãos vulneráveis que não podem pagar a assistência dispendiosa de um especialista jurídico são deixados desprotegidos ou, pior, explorados.\nTodo o trabalho visa colmatar a lacuna entre as pessoas e a lei através do desenvolvimento de um sistema de recuperação eficaz para artigos estatutários.\nTal sistema poderia fornecer um serviço de ajuda jurídica profissional gratuito para humanos não qualificados.\nAntes de mergulhar na principal contribuição deste trabalho, vamos primeiro descrever o problema da recuperação de artigos estatutários.\nDada uma simples pergunta sobre uma questão legal, como, o que arrisco se violar o sigilo profissional?\nUm modelo é necessário para recuperar todos os artigos estatutários relevantes de um corpo grande de legislação.\nEsta tarefa de recuperação de informações vem com o seu próprio conjunto de desafios.\nPrimeiro, lida com dois tipos de linguagem.\nLinguagem natural comum para as perguntas e linguagem jurídica complexa para os estatutos.\nEsta diferença nas distribuições de idioma torna mais difícil para um sistema recuperar candidatos relevantes, pois requer indiretamente um sistema de interpretação inerente que possa traduzir uma pergunta natural para uma pergunta legal que corresponda à terminologia dos estatutos.\nAlém disso, a lei estatutária não é uma pilha de artigos independentes que podem ser tratados como uma fonte completa de informações por conta própria, ao contrário de notícias ou receitas, por exemplo.\nEm vez disso, é uma coleção estruturada de disposições legais que têm todo um significado apenas quando consideradas no contexto geral, ou seja, juntamente com as informações suplementares dos artigos vizinhos, os campos e subcampos aos quais pertencem e seu lugar na estrutura da lei.\nPor fim, os artigos estatutários não são parágrafos pequenos, que geralmente são a unidade típica de recuperação na maioria dos trabalhos de recuperação.\nAqui, há documentos longos que podem chegar a seis mil palavras.\nOs avanços recentes em NLP despertaram um enorme interesse em muitas tarefas legais, como previsão de julgamentos legais ou revisão automatizada de contratos de contacto.\nMas a recuperação de artigos estatutários permaneceu praticamente intocada devido à falta de conjuntos de dados rotulados grandes de alta qualidade.\nNeste trabalho, apresentamos um novo conjunto de dados centrado no cidadão nativo francês para estudar se modelos de recuperação se podem aproximar à eficiência e fiabilidade de um especialista jurídico para a tarefa de recuperação de artigos estatutários.\nO nosso conjunto de dados BSARD de recuperação de artigos estatutários belga consiste em mais de mil e cem perguntas legais feitas por cidadãos belgas.\nEstas perguntas abrangem uma ampla gama de tópicos, desde família, alojamento, dinheiro, trabalho e segurança social.\nCada um deles foi rotulado por juristas experientes com referências a artigos relevantes de um corpus linguístico de mais de vinte e dois mil e seiscentos artigos jurídicos de códigos de direito belgas.\nVamos agora falar sobre como recolhemos este conjunto de dados.\nPrimeiro, começámos por compilar um grande corpus linguístico de artigos jurídicos.\nConsiderámos trinta e dois códigos belgas publicamente disponíveis e extraímos todos os artigos, bem como os títulos das secções correspondentes.\nEm seguida, reunimos perguntas legais com referências a estatutos relevantes.\nPara isso, fazemos parceria com o escritório de advocacia belga que recebe anualmente cerca de quatro mil e-mails de cidadãos belgas que pedem conselhos para uma questão jurídica pessoal.\nTivemos a sorte de ter acesso aos seus sites, onde a sua equipa de juristas experientes aborda as questões jurídicas mais comuns dos belgas.\nRecolhemos milhares de perguntas anotadas com categorias, subcategorias e referências legais a estatutos relevantes.\nPor fim, passámos as referências legais e filtrámos as perguntas cujas referências não eram artigos em um dos códigos de direito que considerámos.\nAs referências restantes foram combinadas e convertidas para os identificadores do artigo correspondente do nosso corpus linguístico.\nAcabámos com mil cento e oito perguntas, cada uma cuidadosamente rotulada com os identificadores dos artigos relevantes do nosso grande corpus linguístico de vinte e dois mil e seiscentos e trinta e três artigos estatutários.\nAlém disso, cada pergunta vem com a categoria principal e uma concatenação de subcategorias.\nE cada artigo vem com uma concatenação do título de subsequência na estrutura da lei.\nEsta informação extra não é usada no presente trabalho, mas pode ser de interesse para futuras pesquisas sobre recuperação de informação legal ou classificação de texto legal.\nVejamos algumas características do nosso conjunto de dados.\nAs perguntas têm entre cinco e quarenta e quatro palavras de comprimento com uma mediana de catorze palavras.\nOs artigos são muito mais longos, com um comprimento médio de setenta e sete palavras, com cento e quarenta e dois deles excedendo as mil palavras.\nO mais longo sendo até cinco mil setecentos e noventa palavras.\nComo mencionado anteriormente, as perguntas abrangem uma ampla gama de tópicos, com cerca de oitenta e cinco por cento deles sendo sobre família, alojamento, dinheiro ou justiça.\nEnquanto os restantes quinze por cento dizem respeito a segurança social, estrangeiros ou trabalho.\nO artigo também é muito diversificado, pois vêm de trinta e dois códigos belgas diferentes que cobrem um grande número de tópicos legais.\nAqui está o número total de artigos recolhidos de cada um destes códigos belgas.\nDos vinte e dois mil seiscentos e trinta e três artigos, apenas mil seiscentos e doze são referidos como relevantes para pelo menos uma pergunta no conjunto de dados.\nE cerca de oitenta por cento destes artigos citados vêm do código civil, códigos judiciais, códigos de investigação criminal ou códigos penais.\nEnquanto isso, dezoito dos trinta e dois códigos têm menos de cinco artigos mencionados como relevantes para pelo menos uma pergunta.\nO que pode ser explicado pelo facto de que esses códigos se concentraram menos em indivíduos e nas suas preocupações.\nNo geral, o número mediano de citações para estes artigos citados é de dois, e menos de vinte e cinco por cento deles são citados mais de cinco vezes.\nUsando todos os conjuntos de dados, comparámos várias abordagens de recuperação, incluindo arquitetura lexical e densa.\nDada uma consulta e um artigo, um modelo lexical atribui uma pontuação ao par de artigos de consulta calculando a soma sobre os termos de consulta dos pesos de cada um desses termos nesse artigo.\nExperimentamos as funções de classificação TF-IDF e BM25 padrão.\nO principal problema com estas abordagens é que só podem recuperar artigos que contenham palavras-chave presentes na consulta.\nPara superar esta limitação, experimentamos uma arquitetura de base neural que pode capturar relações semânticas entre consultas e o artigo.\nUsamos um modelo bi-codificador que mapeia consultas e artigos em representações de vetor densas e calcula uma pontuação de relevância entre um par de artigos de consulta pela similaridade das suas integrações.\nEstas integrações normalmente resultam de uma operação de acumulação na saída de um modelo de integrações de palavras.\nPrimeiro, estudamos a eficácia dos bi-codificadores siameses numa configuração de avaliação de tiro zero, num significado de que os modelos pré-treinados de integração de palavras são aplicados como estão sem qualquer ajuste fino adicional.\nNós experimentamos com um codificador de texto de contexto independente, ou seja, word2vec e fastText, e modelos de integração de contexto dependentes, ou seja Roberta e mais especificamente CamemBERT que é um modelo francês do Roberta.\nAlém disso, treinamos nosso próprio CamemBERT com base num modelo de bi-codificadores no nosso conjunto de dados.\nObserve que para treinamento, experimentamos os dois sabores da arquitetura de bi-codificador.\nO siamês, que usa um modelo de integração de palavras exclusivo que mapeia a consulta e o artigo juntos num espaço de vetor compartilhado denso, e duas torres, que usa dois modelos de integração de palavras independentes que codificam a consulta e o artigo separadamente em diferentes espaços de integração.\nNós experimentamos com acumulação CLS média e máxima, bem como produto e cosseno para semelhanças de computação.\nAqui está o resultado da nossa linha de base nos conjuntos de teste.\nCom os métodos lexicais acima, os bi-codificadores siameses avaliados numa configuração de tiro zero no meio e os bi-codificadores afinados abaixo.\nNo geral, o bi-codificador ajustado supera significativamente todas as outras linhas de referência.\nO modelo de duas torres melhora em relação às suas variantes siamesas na recuperação em cem, mas tem um desempenho semelhante nas outras métricas.\nEmbora o BM25 tenha tido um desempenho inferior ao do bi-codificador treinado significativamente, o seu desempenho indicou que ainda é uma linha de referência forte para recuperação específica de domínio.\nEm relação à avaliação de tiro zero do bi-codificador siamês, descobrimos que usar diretamente as integrações de um modelo CamemBERT pré-treinado sem otimizar para a tarefa recuperação de informações dá resultados maus, o que é consistente com os resultados anteriores.\nAlém disso, observamos que o bi- codificador baseado em word2vec superou significativamente os modelos baseados em fastText e BERT, sugerindo que talvez as integrações ao nível da palavra pré-treinada seja mais apropriado para a tarefa do que o nível de caractere ou integrações ao nível de subpalavra quando usado como está.\nEmbora promissores, estes resultados sugerem uma ampla oportunidade para melhoria comparado com um especialista jurídico qualificado que pode eventualmente recuperar todos os artigos relevantes para qualquer pergunta e, assim, obter pontuações perfeitas.\nVamos concluir discutindo duas limitações do nosso conjunto de dados.\nEm primeiro lugar, o corpus linguístico de artigos limita-se aos recolhidos a partir dos trinta e dois códigos belgas considerados, o que não abrange toda a lei belga, uma vez que faltam artigos de decretos, diretivas e portarias.\nDurante a construção do conjunto de dados, todas as referências a estes artigos não recolhidos são ignoradas, o que faz com que algumas perguntas acabem com apenas uma fração do número inicial de artigos relevantes.\nEsta informação, portanto, implica que a resposta contida nos artigos relevantes restantes pode estar incompleta, embora seja completamente apropriada.\nEm segundo lugar, devemos notar que não se pode responder a todas as perguntas legais apenas com estatutos.\nPor exemplo, a pergunta, posso despejar os meus inquilinos se fizerem muito barulho?\nPode não ter uma resposta detalhada dentro da lei estatutária que quantifique um limite de ruído específico a partir do qual o despejo é permitido.\nEm vez disso, o proprietário provavelmente deve confiar mais na jurisprudência e encontrar precedentes semelhantes à sua situação atual.\nPor exemplo, os inquilinos fazem duas festas por semana até às duas da manhã.\nConsequentemente, algumas perguntas são mais adequadas do que outras para a tarefa de recuperação de artigos estatutários, e o domínio das menos adequadas continua indeterminado.\nEsperamos que o nosso trabalho desperte interesse no desenvolvimento de modelos de recuperação de artigos estatutários práticos e fiáveis.\nIsso pode ajudar a melhorar o acesso à justiça para todos.\nPodem ver o nosso artigo, conjunto de dados e código nos links a seguir. Obrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.567", "sample_id": 419, "src_audio": "/acl6060/audio/en/419.wav", "src_ref": "Hello, we are happy to present our work on VALSE; a Task-Independent Benchmark meant for testing vision and language models with specific linguistic phenomena.\nWhy did we do the trouble in setting up this benchmark?\nWell, during the last years, we have seen an explosion of transformer based vision and language models pretrained on large amounts of image text pairs.\nEach one of these models pushes state-of-the-art on vision and language tasks such as visual question answering, visual common sense reasoning, image retrieval, phrase grounding.\nSo we got a message, the accuracies on these tasks and specific benchmarks are increasing steadily.\nBut do we know what the models have actually learned?\nWhat is it that a vision and language transformer understood when assigning a high score for this image and this sentence to match?\nAnd the low score for this one?\nDo vision and language models focus on the right thing?\nOr do they focus on biases as shown by previous work?\nTo shed more light on this aspect, we propose a more task agnostic direction and introduce VALSE that tests the sensitivity of vision and language models to specific linguistic phenomena that affect both the linguistic and the visual modalities.\nWe target existence, plurality, counting, spatial relations, actions and entity coreference.\nBut how do we test whether the vision and language models have captured this phenomena?\nBy foiling a method previously applied for vision and language models only for noun phrases by Ravi Shekhar and collaborators, and on counting by us in previous work.\nFoiling basically means that we take the caption of an image and produce a foil by altering the caption such that it does not describe the image anymore.\nAnd we do these phrase alterations by focusing on six specific pieces such as existence, plurality, counting, spatial relations, actions and entity coreference, where each piece can consist of one or more instruments, in case we found more than one interesting way to create foil instances.\nFor example, in the case of the actions piece, we have two instruments, one in which the action verb is changed with a different action, and one in which actants are swapped.\nCounting and coreference also are pieces that have more than one instrument.\nAnd we create these foils by making sure that they fail to describe the image, that they are grammatical, and otherwise valid sentences.\nThis is not easy to do because a foiled caption may be less likely than the original caption.\nFor example, though it's not impossible, it is statistically less likely for plants to cut a man than a man to cut plants, and large vision and language models could pick up on this.\nTherefore, to obtain valid foils, we must take action.\nFirst, we make use of strong language models to propose foils.\nSecond, we use natural language inference or short NLI to filter out foils that could be still describing the image, since when constructing foils we need to ensure that they fail to describe the image.\nTo test this automatically, we apply natural language inference with the following rationale.\nWe consider an image to be the premise and its caption its entailed hypothesis.\nIn addition, we consider the caption to be the premise, and the foil is its hypothesis.\nIf an NLI model predicts the foil to contradict or to be neutral with respect to the caption, we take this as an indicator of a valid foil.\nIf an NLI predicts the foil to be entailed by the caption, it cannot be a good foil, since by transitivity it will give a truthful description of the image, and we filter these foils out.\nBut this procedure is not perfect, it is just an indicator for valid foils.\nTherefore, as a third measure for generating valid foils, we employ human annotators to validate the data used in VALSE.\nSo, after filtering and human evaluation, we have as many test instances as described in this table.\nNote that VALSE does not deliver any training data but only test data.\nSince it is a zero shot testing benchmark only, it is designed to leverage the existing capabilities of vision and language models after pretraining.\nFinetuning would only enable models to exploit artifacts or statistical biases in the data.\nAnd we all know that these models like to cheat and take shortcuts.\nAnd as we said, we are interested in assessing what capabilities the vision and language models have after pretraining.\nWe experiment with five vision and language models on VALSE, namely with CLIP, LXMert, ViLBERT, ViLBERT twelve in one, and VisualBERT.\nTwo of our most important evaluation metrics are the accuracy of the models in classifying image sentence pairs into captions and foils.\nPerhaps more relevant for this video, we will showcase our more permissive metric, the pairwise accuracy, which measures whether the image sentence alignment score is greater for the correct image text pair than for its foiled pair.\nFor more metrics and results on them, do check out our paper.\nThe results with pairwise accuracy are shown here and they are consistent with the results we got from the other metrics is that the best zero shot performance is achieved by ViLBERT twelve in one, followed by ViLBERT, LXMert, CLIP, and finally VisualBERT.\nIt's notable how instruments centered on the individual objects like existence and noun phrases are almost solved by ViLBERT twelve in one, highlighting that models are capable of identifying named objects and their presence in images.\nHowever, none of the remaining pieces can be reliably solved in our adversarial foiling settings.\nWe see from the plurality and counting instruments that vision and language models have trouble distinguishing references to single versus multiple objects, or counting them in an image.\nThe relation piece shows that they have difficulties in correctly classifying a named spatial relation between objects in an image.\nThey also have trouble distinguishing actions and identifying their participants, even if supported by plausibility biases as we see in the actions piece.\nFrom the coreference piece, we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models.\nAs a sanity check, and because it's an interesting experiment, we also benchmark two text only models, GPT one and GPT two, to assess whether VALSE is solvable by these unimodal models by computing the perplexity of the correct and the foiled caption, no image here, and predicting the entry with the lowest perplexity.\nIf the perplexity is higher for the foil, we take this as an indication that the foiled caption may suffer from plausibility bias or other linguistic biases.\nAnd it's interesting to see that in some cases, the text only GPT models have captured the plausibility of the world better than the vision and language models.\nSo to sum up, VALSE is a benchmark that uses the lens of linguistic constructs to help the community improve vision and language models by hard testing their visual grounding capabilities.\nOur experiments show that vision and language models identify named objects and their presence in images well, as shown by the existence piece, but struggle to ground their interdependence and relationships in visual scenes when forced to respect linguistic indicators.\nWe would really like to encourage the community to use VALSE for measuring progress towards language grounding with vision and language models.\nAnd even more, VALSE could be used as an indirect assessment of datasets, as models could be evaluated before and after training or finetuning to see whether a dataset helps models improve on any of the aspects tested by VALSE.\nIf you're interested, do check out the VALSE data on GitHub, and if you have any questions do not hesitate to contact us.", "tgt_ref": "Olá, estamos felizes em apresentar nosso trabalho em VALSE; um termo de comparação independente de tarefas feito para testar a visão e modelos de linguagem com fenómenos linguísticos específicos.\nPorque é que nos esforçámos para estabelecer este termo de comparação?\nBem, durante os últimos anos, vimos uma explosão de visão baseada em transformadores e modelos de linguagem pré-treinados em grandes quantidades de pares imagem-texto.\nCada um destes modelos impulsiona a última geração em tarefas de visão e idioma, como visual question answering, raciocínio visual de sentido comum, recuperação de imagem, embasamento de frases.\nEntão, recebemos uma mensagem, as precisões nestas tarefas e termos de comparação específicos estão a aumentar de forma constante.\nMas sabemos o que os modelos realmente aprenderam?\nO que é que um transformador de visão e idioma compreendeu ao atribuir uma pontuação alta para esta imagem e esta frase para combinar?\nE a pontuação baixa para esta?\nOs modelos de linguagem e visão concentram-se na coisa certa?\nOu concentram-se em preconceitos como mostrado pelo trabalho anterior?\nPara lançar mais luz sobre este aspecto, propomos uma direção mais agnóstica à tarefa e introduzimos o VALSE, que testa a sensibilidade de modelos de linguagem e visão a fenómenos linguísticos específicos que afetam as modalidades linguísticas e visuais.\nTomámos como alvo a existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade.\nMas como testamos se os modelos de linguagem e visão capturaram este fenómeno?\nAo frustrar um método anteriormente aplicado para modelos de linguagem e visão apenas para frases com substantivos de Ravi Shekhar e colaboradores, e na contagem por nós em trabalhos anteriores.\nFrustar basicamente significa que pegamos na legenda de uma imagem e produzimos um frustração que altera a legenda de modo a que deixe de descrever a imagem.\nE fazemos estas alterações na frase concentrando-nos em seis peças específicas, como existência, pluralidade, contagem, relações espaciais, ações e correferência de entidade, onde cada peça pode consistir em um ou mais instrumentos, caso encontremos mais de uma forma interessante de criar instâncias de frustação.\nPor exemplo, no caso da peça de ações, temos dois instrumentos, um em que o verbo de ação é alterado com uma ação diferente e um em que os actantes são trocados.\nContagem e correferência também são peças que possuem mais de um instrumento.\nE nós criámos estas frustação, certificando-se de que não descrevem a imagem, mas que são frases válidas gramaticalmente e de outras formas.\nIsto não é fácil de fazer porque uma legenda frustrada pode ser menos provável do que a legenda original.\nPor exemplo, embora não seja impossível, é estatisticamente menos provável que as plantas cortem um homem do que um homem corte plantas, e modelos de linguagem e visão grandes podem captar isto.\nAssim, para obter frustrações válidas, devemos agir.\nPrimeiro, fazemos uso de modelos de linguagem fortes para propor frustrações.\nEm segundo lugar, usamos natural language inference ou NLI curtas para filtrar frustrações que ainda podem estar a descrevendo a imagem, já que ao construir frustrações precisamos de garantir que não descrevem a imagem.\nPara testar isto automaticamente, aplicamos natural language inference com o seguinte raciocínio.\nConsideramos uma imagem como a premissa e a sua legenda como a sua hipótese implicada.\nAlém disso, consideramos a legenda como a premissa, e a frustração é a sua hipótese.\nSe um modelo NLI prevê que a frustração contradiga ou seja neutra em relação à legenda, tomamos isto como um indicador de uma frustação válida.\nSe uma NLI prevê que a frustração seja implicada pela legenda, não pode ser uma boa frustração, uma vez que, por transitividade, dará uma descrição verdadeira da imagem, e filtramos estas frustrações.\nMas este procedimento não é perfeito, é apenas um indicador para frustrações válidas.\nAssim, como uma terceira medida para gerar frustrações válidas, empregamos anotadores humanos para validar os dados usados no VALSE.\nAssim, após a filtragem e avaliação humana, temos tantas instâncias de teste como descrito nesta tabela.\nPode observar-se que o VALSE não fornece nenhuns dados de treinamento, apenas testa dados.\nUma vez que é apenas um termo de comparação de teste de tiro zero, é projetado para alavancar as capacidades existentes de modelos de linguagem e visão após pré-treinamento.\nO ajuste fino só permitiria aos modelos explorar artefatos ou preconceitos estatísticos nos dados.\nE todos nós sabemos que estes modelos gostam de fazer batota e usar atalhos.\nE, como dissemos, estamos interessados em avaliar quais as capacidades de modelos de linguagem e visão têm após o pré-treinamento.\nExperimentamos cinco modelos de linguagem e visão no VALSE, ou seja com CLIP, LXMert, ViLBERT, ViLBERT doze em um e VisualBERT.\nDuas das nossas mais importantes métricas de avaliação são a precisão dos modelos para classificar pares de imagem-frase em legendas e frustrações.\nTalvez mais relevante para este vídeo, mostraremos a nossa métrica mais permissiva, a precisão par a par, que mede se a pontuação de alinhamento de frases-imagem é maior para o par imagem-texto correto do que para o seu par frustrado.\nPara mais métricas e resultados sobre eles, veja o nosso artigo.\nOs resultados com precisão par a par são mostrados aqui e são consistentes com os resultados que obtivemos das outras métricas é que o melhor desempenho de tiro zero é alcançado pelo ViLBERT doze em um, seguido pelo ViLBERT, LXMert, CLIP e, finalmente, VisualBERT.\nÉ notável como instrumentos centrados em objetos individuais como existência e frases com substantivo são quase resolvidos pelo ViLBERT doze em um, destacando que modelos são capazes de identificar objetos nomeados e a sua presença em imagens.\nNo entanto, nenhuma das peças restantes pode ser resolvida de forma fiável nas nossas configurações de frustração adversárias.\nVemos a partir da pluralidade e dos instrumentos de contagem que os modelos de linguagem e visão têm dificuldade em distinguir referências a objetos únicos contra múltiplos, ou contá-los numa imagem.\nA peça de relação mostra que têm dificuldades em classificar corretamente uma relação espacial nomeada entre objetos numa imagem.\nTambém têm dificuldade em distinguir ações e identificar os seus participantes, mesmo que apoiados por preconceitos de plausibilidade como vemos na peça de ações.\nA partir da peça de correferência, descobrimos que traçar várias referências ao mesmo objeto numa imagem usando pronomes também é difícil para modelos de linguagem e visão.\nComo uma verificação de sanidade, e porque é uma experiência interessante, também comparamos dois modelos apenas de texto, GPT um e GPT dois, para avaliar se o VALSE é solucionável por estes modelos unimodais calculando a perplexidade da legenda correta e frustrada, sem imagem aqui, e prevendo a entrada com a menor perplexidade.\nSe a perplexidade é maior para a frustração, tomamos isto como uma indicação de que a legenda frustrada pode sofrer de preconceitos linguísticos de plausibilidade.\nE é interessante ver que, em alguns casos, os modelos GPT apenas com texto capturaram a plausibilidade do mundo melhor do que os modelos de linguagem e visão.\nEntão, para resumir, o VALSE é uma referência que usa a lente de construções linguísticas para ajudar a comunidade a melhorar modelos de linguagem e visão testando duramente as suas capacidades embasamento visuais.\nAs nossas experiências mostram que os modelos de linguagem e visão identificam bem os objetos nomeados e sua presença nas imagens, como mostra a peça de existência, mas lutam para fundamentar a sua interdependência e relações em cenas visuais quando forçados a respeitar indicadores linguísticos.\nGostaríamos muito de encorajar a comunidade a usar o VALSE para medir o progresso em direção a embasamento de idioma com modelos de linguagem e visão.\nE além disso, o VALSE poderia ser usado como uma avaliação indireta de conjuntos de dados, já que os modelos poderiam ser avaliados antes e depois do treinamento ou ajuste fino para ver se um conjunto de dados ajuda os modelos a melhorar em qualquer um dos aspectos testados pelo VALSE.\nSe houver interesse, os dados do VALSE podem ser vistos no GitHub e, se houverem perguntas, não hesitem em contactar-nos.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
{"dataset_id": "acl_6060", "doc_id": "2022.acl-long.597", "sample_id": 420, "src_audio": "/acl6060/audio/en/420.wav", "src_ref": "Hello, my name is Kamezawa from the University of Tokyo.\nI'll be presenting a paper entitled RNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Logs Summarization.\nI'll be explaining in this order.\nFirst, I will introduce automatic release note generation that we are working on in this research.\nA release note is a technical document that summarizes the changes distributed with each release of a software product.\nThe image shows a release note for version two point six point four of the vuejs library.\nRelease notes play an important role in open source development but they're time consuming to prepare manually.\nTherefore, it would be very useful to be able to automatically generate high quality release notes.\nI will defer to two previous researches on automatic release note generation.\nThe first is a system called ARENA released in twenty fourteen.\nIt takes a rule-based approach, for example using the change extractor to extract all differences, library changes and document changes from the differences between releases, and finally combining them.\nThe most notable feature of this system is the issue extractor in the upper right corner.\nWhich must be left to Jira, the issue tracker system, and can only be applied to projects that use Jira.\nIn other words, it cannot be used for many projects on GitHub.\nThe second is Glyph, recently announced in twenty twenty.\nIt is available on the internet and can be installed via pip.\nThis system has a simple learning based text classification model and outputs one of five labels such as features or bug fixes for each input commit message.\nThis image is a sample usage that returns a corrective or bug fixes label.\nGlyph's training data is fairly small, about five thousand, and will be shown in the experiments described below.\nThe performance of the text classification model is not high.\nI present two related researches, but their problems are limited applicability and scarce data resources.\nOur paper solves these two problems and automatically generates high quality release notes.\nWith a limited applicability problem, we propose a high quality classwise summarization method using only commit messages as input.\nThis proposed method can be used for all English repositories.\nFor the second problem of scarce data resources, we built our RNSum dataset consisting of about eighty two thousand pieces of data by collecting data from public GitHub repositories using the GitHub API.\nNext, I'll describe our dataset.\nHere is an example of data.\nThe left side is a commit message and the right side is the release notes.\nRelease notes are labeled as improvements or fixes, etc.\nWe have set up a task that takes the commit messages as input and outputs a labeled release notes.\nThis can be regarded as a summarization task.\nWe have predefined four labels: features, improvements, bug fixes, deprecations removals and breaking changes.\nThese were set based on previous research and other factors.\nThe release note on the bottom right is extracted from the release note on the bottom left.\nAt this time, it is necessary to detect the four labels that have been set up in advance.\nBut the labels are not always consistent with each repository.\nFor example, the improvements label includes improvements, enhancements, optimizations, and so on.\nWe prepared a vocabulary list of about thirty labels for each of these notational variations.\nThis is to detect the release note class, and collects the text of the release that follows as the release note sentence for the class.\nNext is a commit message.\nCommit messages are not tied to each release.\nAs shown in the image below, if the current release is version two point five to nineteen, we need to identify the previous release version two point five to eighteen and get a diff.\nThis is a bit tedious and it is not enough to just get a list of releases and look at the before and after.\nWe created a heuristic matching rule to get the previous and next versions.\nDataset analysis.\nIn the end, seven thousand two hundred repositories and eighty two thousand pieces of data were collected.\nAlso, the average number of release notes tokens is sixty three, which is quite high for a summarization task.\nAlso, the number of unique tokens is quite large at eight thousand eight hundred thirty thousand.\nThis is due to the large number of unique class or method names found in the repository.\nNext, I will explain the proposed method.\nThe classwise extractive then abstractive summarization model consists of two neural modules.\nA classifier using BERT or CodeBERT and a generator using BART.\nFirst, CEAS uses a classifier to classify each commit message into five release notes classes, which use improvements, bug fixes, deprecations, plus an other.\nThe commit messages classified as other are discarded.\nThen CEAS applies the generator to the four labeled documents independently and generates release notes for each class.\nIn this task, the direct correspondences between commit messages and release notes are not known.\nTherefore, to train the classifier, that's why we reassigned surveys to each input commit message using the first ten characters of each commit message.\nWe modeled the classwise abstractive summarization approach by two different methods.\nThe first model, which we call CAS-Single, consists of a single six to six network and generates a single release note text give a concatenation of input commit messages.\nThe output texts can be divided into classwise segments based on special class-specific endpoint symbols.\nThe second method, method, which we call CAS-Multi, consists of four different seq2seq networks, each of which correspond to one of the fixed release note classes.\nOkay, let me explain the experiments.\nFive methods were compared: CEAS, CAS-Single, CAS-Multi, Clustering, and previous study, Glyph.\nRegarding evaluation, in some cases, release notes are output in multiple sentences.\nSince it is difficult to calculate the number of sentences as they are, they are combined with spaces and treated as one long sentence.\nThe BLEU is penalized when the system outputs a short sentence.\nThis penalty results in a lower BLEU value in the experiment results described next.\nFinally, we also calculate the specificity because ROUGE and BLEU cannot be calculated if the release notes are empty.\nA higher specificity means that the model correctly outputs an empty text in cases where the release notes assume empty.\nHere are the results.\nSince the dataset contains e-mail addresses, hashed values, etc, we also evaluated the cleaned dataset, which excludes them.\nCEAS and CAS achieved ROUGE-L scores more than ten points higher than the baselines.\nIn particular, on the clean test set, the score gap between the proposed method and the baselines jumped to more than twenty points.\nThese results indicate that CEAS and CAS are significantly affected.\nCEAS got a better ROUGE-L score than CAS suggesting that combining a classifier and a generator is effective on training the classifier using pseudo labels.\nHigh coverage of CEAS can be achieved probably because the classifier can focus on selecting relevant commit messages for each class.\nCAS-Multi tended to yield higher ROUGE-L than CAS-Single.\nSuggesting that it is also effective to independently develop differently abstractive summarization models for each release note class.\nHere are an error analysis.\nCAS methods tend to output shorter sentences than human reference sentences.\nIn the figure on the right, the reference sentence has three or four sentences, while CAS has only one.\nThe reason for this model's reluctance is that in training data, only thirty three percent of the sentences are present in the features label and forty percent in the improvements label.\nFurthermore, CAS methods cannot generate accurate release notes without additional information.\nThe top example on the right is an example of a very messy commit message, and the complete sentence cannot be generated without reference to the corresponding progress or issue.\nThe example below shows that the two commit messages in the input are related and should be combined into one sentence, but it fails to do so.\nFinally, a conclusion.\nWe have built a new dataset for automatic release note generation.\nWe have also formulated a task of entering commit messages and summarizing them so that it is applicable to all projects written in English.\nOur experiments show that the proposed method generates less noisy release notes at higher coverage than the baselines.\nPlease check out our dataset on GitHub.\nThank you.", "tgt_ref": "Olá, o meu nome é Kamezawa da Universidade de Tóquio.\nVou apresentar um artigo intitulado RNSum: um conjunto de dados de grande escala para geração automática de notas de lançamento através de sumarização de registos de confirmação.\nVou explicar nesta ordem.\nPrimeiro, apresentarei a geração automática de notas de lançamento em que estamos a trabalhar nesta pesquisa.\nUma nota de lançamento é um documento técnico que resume as mudanças distribuídas com cada lançamento de um produto de software.\nA imagem mostra uma nota de lançamento para a versão 2.6.4 da biblioteca vuejs.\nAs notas de lançamento desempenham um papel importante no desenvolvimento de código aberto, mas consomem tempo ao serem preparadas manualmente.\nAssim, seria muito útil ser capaz de gerar notas de lançamento de alta qualidade automaticamente.\nVou referir-me a duas pesquisas anteriores sobre a geração automática de notas de lançamento.\nO primeiro é um sistema chamado ARENA lançado em 2014.\nÉ precisa uma abordagem baseada em regras, por exemplo, usando o extrator de alterações para extrair todas as diferenças, alterações de biblioteca e alterações de documento das diferenças entre versões e, finalmente, combiná-las.\nA característica mais notável deste sistema é o extrator de problemas no canto superior direito.\nQue deve ser deixado para o Jira, o sistema monitorizador de problemas, e só pode ser aplicado a projetos que usam o Jira.\nPor outras palavras, não pode ser usado para muitos projetos no GitHub.\nO segundo é Glyph, anunciado recentemente em 2020.\nEstá disponível na internet e pode ser instalado através do pip.\nEste sistema tem uma aprendizagem simples baseada num modelo de classificação de texto e cria um de cinco rótulos, como características ou correções de erros para cada mensagem de confirmação de entrada.\nEsta imagem é uma amostra de uso que devolve um rótulo corretivo ou de correções de erros.\nOs dados de treinamento do Glyph são bastante pequenos, cerca de cinco mil, e serão mostrados nas experiências descritas abaixo.\nO desempenho do modelo de text classification não é alto.\nApresento duas pesquisas relacionadas, mas os seus problemas são de aplicabilidade limitada e escassos recursos de dados.\nO nosso artigo resolve estes dois problemas e gera notas de lançamento de alta qualidade automaticamente.\nCom um problema de aplicabilidade limitada, nós propomos um método de sumarização em termos de classe de alta qualidade usando apenas mensagens de confirmação como entrada.\nEste método proposto pode ser usado para todos os repositórios em inglês.\nPara o segundo problema de recursos de dados escassos, construímos o nosso conjunto de dados RNSum consistindo em cerca de oitenta e dois mil dados recolhendo dados de repositórios públicos do GitHub usando o API do GitHub.\nEm seguida, vou descrever o nosso conjunto de dados.\nAqui está um exemplo de dados.\nO lado esquerdo é uma mensagem de confirmação e o lado direito são as notas de lançamento.\nAs notas de lançamento são rotuladas como melhorias ou correções, etc.\nConfigurámos uma tarefa que usa as mensagens de confirmação como entrada e cria notas de lançamento rotuladas.\nIsto pode ser considerado como uma tarefa de sumarização.\nTemos quatro rótulos predefinidos: características, melhorias, correções de erros, remoções de desaprovações e alterações de interrupção.\nEstes foram definidos com base em pesquisas anteriores e outros fatores.\nA nota de lançamento no canto inferior direito é extraída da nota de lançamento no canto inferior esquerdo.\nNeste momento, é necessário detetar os quatro rótulos que foram configurados com antecedência.\nMas os rótulos nem sempre são consistentes com cada repositório.\nPor exemplo, o rótulo de melhorias inclui melhorias, aperfeiçoamentos, otimizações e assim por diante.\nPreparamos uma lista de vocabulário de cerca de trinta rótulos para cada uma dessas variações notacionais.\nIsto serve para detetar a classe de notas de lançamento e recolhe o texto da versão que se segue como a frase da nota de lançamento para a classe.\nEm seguida, temos uma mensagem de confirmação.\nAs mensagens de confirmação não estão vinculadas a cada lançamento.\nComo mostrado na imagem abaixo, se o lançamento atual é a versão 2.5.19, precisamos identificar a versão anterior 2.5.18 do lançamento e obter um diferencial.\nIsto é um pouco monótono e não é suficiente obter apenas uma lista de lançamentos e olhar para o antes e o depois.\nCriámos uma regra de correspondência heurística para obter as versões anterior e seguinte.\nAnálise do conjunto de dados.\nNo final, foram recolhidos sete mil e duzentos repositórios e oitenta e dois mil peças de dados.\nAlém disso, o número médio de tokens de notas de lançamento é sessenta e três, o que é bastante alto para uma tarefa de sumarização.\nAlém disso, o número de tokens únicos é bastante grande, oito mil oitocentos e trinta mil.\nIsto deve-se ao grande número de nomes de classe única ou método encontrados no repositório.\nEm seguida, explicarei o método proposto.\nO extrativo em termos de classe, seguido do modelo de abstractive summarization consiste em dois módulos neurais.\nUm classificador que usa BERT ou CodeBERT e um gerador que usa BART.\nPrimeiro, o CEAS usa um classificador para classificar cada mensagem de confirmação em cinco classes de notas de lançamento, que usam melhorias, correções de bugs, desaprovações e outros.\nAs mensagens de confirmação classificadas como outras são descartadas.\nEm seguida, o CEAS aplica o gerador aos quatro documentos rotulados de forma independente e gera notas de lançamento para cada classe.\nNesta tarefa, as correspondências diretas entre mensagens de confirmação e as notas de lançamento não são conhecidas.\nAssim, para treinar o classificador, é por isso que reatribuímos pesquisas para cada mensagem de confirmação na entrada usando os primeiros dez caracteres de casa mensagem de confirmação.\nNós modelamos a abordagem de abstractive summarization por dois métodos diferentes.\nO primeiro modelo, a que chamamos CAS-Single, consiste numa única rede de seis a seis e gera um único texto de nota de lançamento dá uma concatenação de mensagens de confirmação de entrada.\nOs textos de saída podem ser divididos em segmentos de classe com base em símbolos de ponto de extremidade específicos de classe especiais.\nO segundo método, a que chamamos CAS-Multi, consiste em quatro redes diferentes seq2seq, cada uma das quais corresponde a uma das classes de notas de lançamento fixas.\nOK, deixe-me explicar as experiências.\nForam comparados cinco métodos: CEAS, CAS-Single, CAS-Multi, Clustering e o estudo anterior, Glyph.\nEm relação à avaliação, em alguns casos, as notas de versão são emitidas em várias frases.\nComo é difícil calcular o número de frases como elas são, são combinadas com espaços e tratadas como uma frase longa.\nO BLEU é penalizado quando o sistema emite uma frase curta.\nEsta penalidade resulta num valor BLEU menor nos resultados do experiência descritos a seguir.\nFinalmente, também calculamos a especificidade porque ROUGE e BLEU não podem ser calculados se as notas de lançamento estiverem vazias.\nUma maior especificidade significa que o modelo cria corretamente um texto vazio nos casos em que as notas de lançamento assumem vazio.\nAqui estão os resultados.\nComo o conjunto de dados contém endereços de e-mail, valores em hash, etc., também avaliamos o conjunto de dados limpo, o que os exclui.\nCEAS e CAS alcançaram pontuações ROUGE-L mais de dez pontos acima das linhas de referência.\nEm particular, no conjunto de testes limpo, a diferença de pontuação entre o método proposto e as linhas de referência saltou para mais de vinte pontos.\nEstes resultados indicam que CEAS e CAS são significativamente afetados.\nCEAS obteve uma pontuação ROUGE-L melhor do que CAS, sugerindo que a combinação de um classificador e um gerador é eficaz para treinar o classificador usando rótulos pseudo.\nA alta cobertura do CEAS pode ser alcançada provavelmente porque o classificador pode concentrar-se na seleção de mensagens de confirmação relevantes para cada classe.\nO CAS-Multi tinha tendência para produzir mais ROUGE-L do que o CAS-Single.\nSugerindo que também é eficaz desenvolver de forma independente modelos abstractive summarization para cada classe de nota de lançamento.\nAqui está uma análise de erro.\nOs métodos CAS têm tendência para produzir frases mais curtas do que frases de referência humanas.\nNa figura à direita, a frase de referência tem três ou quatro frases, enquanto que o CAS tem apenas uma.\nA razão para a relutância deste modelo é que em dados de treinamento, apenas trinta e três por cento das frases estão presentes no rótulo de características e quarenta por cento no rótulo de melhorias.\nAlém disso, os métodos CAS não podem gerar notas de lançamento precisas sem informações adicionais.\nO exemplo superior à direita é um exemplo de uma mensagem de confirmação muito confusa, e a frase completa não pode ser gerada sem referência ao progresso ou problema correspondente.\nO exemplo abaixo mostra que as duas mensagens de confirmação na entrada estão relacionadas e devem ser combinadas numa frase, mas não o faz.\nPor fim, uma conclusão.\nCriámos um novo conjunto de dados para geração automática de notas de lançamento.\nTambém formulámos uma tarefa para inserir mensagens de confirmação e resumi-las para que seja aplicável a todos os projetos escritos em inglês.\nAs nossas experiências mostram que o método proposto gera notas de lançamento menos ruidosas em maior cobertura do que as linhas de referência.\nPodem consultar o nosso conjunto de dados no GitHub.\nObrigado.", "src_lang": "en", "tgt_lang": "pt", "benchmark_metadata": {"context": "long", "dataset_type": "longform", "subset": "eval"}}
