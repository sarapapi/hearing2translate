{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous. Aujourd'hui, je vais vous présenter notre travail de recherche apprendre à raisonner deductivement, résolution de problèmes de mathématiques en tant que réaction complexe d'extraction."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je suis Alan de Biden's AI Lab et je travaille en collaboration avec Thierry de l'université du Texas à Austin et Wayloo de SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je voudrais parler de notre motivation pour raisonner."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous montrons des exemples où le raisonnement à plusieurs étapes est utile."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Ce chiffre provient du papier PALM où ils ont effectué des promptings pour résoudre le problème de la méthode dans un scénario d'apprentissage de tirs de combustible."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, du côté du net, nous pouvons voir que si nous donnons des exemples avec seulement des questions et des réponses, nous ne pourrons peut-être pas obtenir les bonnes réponses."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous donnons une description plus raisonnable, le modèle est capable de prédire la description raisonnable et de faire une prédiction correcte ici."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Il est donc bon d'avoir une résolution interprétable à plusieurs étapes."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons également que le problème de la méthode est une application directe pour évaluer ces capacités de raisonnement."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre configuration de problème, compte tenu des questions, nous devons résoudre cette question et obtenir les réponses numériques."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos ensembles de données, on nous donne également l'expression mathématique qui conduit également à cette réponse particulière."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, certaines hypothèses s'appliquent également comme dans les travaux précédents."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que la précision des quantités est connue,"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que des opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentielle."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, des opérateurs compliqués peuvent en fait être décomposés en ces opérateurs de base."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le travail précédent dans la résolution de problèmes méthodiques peut en fait être classé en séquence à séquence et en séquence à arbre."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le modèle de séquence traditionnel convertit l'expression en une séquence spécifique pour la génération."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est assez facile à mettre en œuvre et peut être généralisé à de nombreux problèmes compliqués."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les inconvénients sont que la performance n'est en fait généralement pas meilleure que le modèle structuré et qu'il manque d'interprétation pour la prédiction."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en fait, cette direction est encore assez populaire parce que le transformer modèle."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans les modèles basés sur un arbre, nous structurons en fait ces expressions sous forme d'arbre et suivons une traversée préordonnée dans trois générations."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous continuons à générer les opérateurs jusqu'à ce que nous atteignions les LIFF qui sont les quantités."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Le bon côté, c'est qu'il nous donne en fait cette structure d'arbre binaire, mais en réalité, c'est assez contraire à l'intuitivité car nous générons d'abord l'opérateur, puis à la fin, nous générons les quantités."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose, c'est qu'il contient également des calculs répétitifs."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, si nous regardons cette expression, huit fois trois plus trois est en fait générée deux fois. Mais en fait, nous devrions réutiliser les résultats"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre approche proposée, nous souhaitons donc résoudre ces problèmes de manière étape par étape et interprétable."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, ici, dans la deuxième étape, nous pouvons obtenir ce diviseur, qui est vingt-sept."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons également nous référer à l'original pour trouver le contenu pertinent."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les diviseurs."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Et puis, à cette troisième étape, nous obtenons réellement le quotient."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord. Et après ces trois étapes, nous pouvons réutiliser les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape. Et enfin, nous pouvons obtenir les dividendes."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, nous générons en fait l'expression entière directement plutôt que de générer des opérateurs ou des quantités individuels."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "Cela rend le processus plus précis."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre système déductif, nous commençons d'abord par un ensemble de quantités présentées dans les questions et nous incluons également une constante comme état initial."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "L'expression est donc représentée par EIJOP."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "Là où nous effectuons des opérateurs de Qi à Qj, et cette expression est en fait dirigée."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, nous avons également des subtractions versus ici pour représenter la direction opposée."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "C'est assez similaire à l'extraction de radiation."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans un système déductif formel, à l'étape temporelle t, nous appliquons l'opérateur entre le couple Qi et Qj, puis nous obtenons ces nouvelles expressions."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "Nous l'ajoutons à l'état suivant pour devenir une nouvelle quantité."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Ces diapositives visualisent donc en fait l'évolution des états, où nous continuons à ajouter des expressions aux états actuels."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos implémentations de modèle, nous utilisons d'abord un modèle de langue pré-entraînée qui peut être des oiseaux ou des robots, puis nous codons la phrase et obtenons ces représentations de quantité."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Une fois que nous avons obtenu les représentations de quantité, nous pouvons commencer à faire des inférences."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous montrons un exemple de Q1 pour obtenir la représentation de Q1. Ils seront divisés par Q2, puis multipliés par Q4."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous obtenons la représentation de la paire, qui est essentiellement la concaténation entre Q1 et Q2. Ensuite, nous appliquons un réseau de feedforward, qui est paramétrifié par l'opérateur."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, nous obtenons la représentation de l'expression Q1 divisée par Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en pratique, à l'étape de l'influence, nous pourrions également être en mesure d'obtenir l'expression incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, toutes les expressions possibles sont égales à trois fois le nombre d'opérateurs."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "Le bon côté ici, c'est que nous pouvons facilement ajouter des contraintes pour contrôler ce espace de recherche."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement la supprimer de notre espace de recherche."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans la deuxième étape, nous faisons la même chose, mais la seule différence est qu'il y a une quantité de plus."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "Cette quantité provient de l'expression calculée précédemment."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous pouvons obtenir cette expression finale Q3."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "Quatre fois Q quatre. Et nous pouvons également voir que le nombre de toutes les expressions possibles est différent de l'étape précédente."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "Ces différences rendent donc difficile l'application de la recherche par faisceau car la répartition des probabilités entre ces deux étapes est déséquilibrée."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "La procédure d'entraînement est donc similaire à l'entraînement d'un modèle de séquence à séquence où nous optimisons la perte à chaque étape temporelle."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également cette tau pour représenter quand nous devrions mettre fin à ce processus de génération."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent de séquence à séquence car l'espace est différent à chaque fois que, dans le modèle traditionnel de séquence à séquence, c'est le nombre de vocabulaire."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela nous permet également d'imposer certaines contraintes à partir de connaissances préalables."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc effectué des expériences sur les ensembles de données de problèmes de méthodes couramment utilisés, MAWPS, Math twenty three K, Math QA et SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici brièvement les résultats par rapport aux meilleures approches précédentes."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Notre meilleure variante est donc Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "En fait, nous n'utilisons pas BeamSearch, par opposition aux approches évidentes utilisant BeamSearch."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, les meilleures approches sont souvent un modèle basé sur trois arbres."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, notre raisonnement est donc capable de surpasser de manière significative ce modèle basé sur l'arbre."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons voir que le nombre absolu sur MathQA ou SWAM n'est pas vraiment élevé."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc étudié les résultats sur la page."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "Et cet ensemble de données est difficile car l'auteur a tenté d'ajouter manuellement quelque chose pour confondre le modèle NLP, comme ajouter des informations irrelevantes et des quantités supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans notre prédiction, nous constatons que certaines des intermédiaires sont en fait négatives."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans ces questions, nous demandons combien de pommes Jake possède."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons des informations supplémentaires, comme dix-sept présentations de combustible et Stephen en a huit, ce qui est totalement sans importance."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Notre modèle fait donc des prédictions comme celle-ci, qui produisent des valeurs négatives."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous observons ces deux expressions."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc en fait limiter cet espace de recherche en supprimant les résultats négatifs afin de pouvoir donner une bonne réponse."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons donc que cette contrainte améliore en fait considérablement certains modèles."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour les oiseaux, nous avons amélioré de sept points, puis pour le modèle basé sur Roberta, nous avons en fait amélioré de deux points."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, un meilleur modèle de langue a une meilleure capacité à comprendre la langue, de sorte que le nombre ici est plus élevé pour Roberta et plus faible pour Bertha."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également essayé d'analyser les difficultés qui se cachent derrière ce BPP."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que le nombre de quantités inutilisées peut être considéré comme une information sans importance ici."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous pouvons voir que nous avons le pourcentage d'échantillons avec des quantités inutilisées et que le jeu de données SWAMP contient la plus grande partie."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons également les performances globales."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ces échantillons sans quantités inutilisées, la performance globale est en fait supérieure à celle de la performance globale."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "Mais avec ces échantillons, avec une quantité inutilisée, c'est en fait bien pire que la quantité."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "Pour MAWPS, nous n'avons pas vraiment beaucoup de cas de bureau, donc je n'ignore pas cette partie."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous voulons montrer l'interprétation à travers un exemple de participation à la question."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait en fait une prédiction erronée à la première étape."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc en fait corréler cette expression à la phrase ici, d'accord?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons donc que cette phrase pourrait dérober un modèle de prédiction incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, en plantant un autre trente-cinq, le modèle pense qu'il devrait s'agir d'opérateurs d'addition."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc essayé de réviser la phrase pour qu'elle soit quelque chose comme le nombre d'arbres de poireaux est de cinq fois moins que celui des pommiers."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Nous le faisons donc pour transmettre une sémantique plus précise, de sorte que le modèle soit capable de faire la prédiction correcte."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Cette étude montre donc comment les prédictions interprétables nous aident à comprendre le comportement du modèle."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure notre travail, notre modèle est en fait assez efficace."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "et nous sommes en mesure de fournir une procédure de résolution interprétable."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pouvons facilement incorporer une certaine connaissance préalable comme constraint, ce qui peut aider à améliorer la performance."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et la dernière chose est que le mécanisme sous-jacent ne s'applique pas seulement aux tâches de résolution de problèmes de réseau, mais aussi à d'autres tâches qui impliquent un raisonnement à plusieurs étapes."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons également certaines limites."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "Si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose, comme mentionné, c'est que la distribution de probabilité est déséquilibrée à différents étapes temporelles, il est donc également assez difficile d'appliquer des recherches de faisceau."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "C'est la fin de la discussion et les questions sont les bienvenues. Merci."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je suis de l'université de Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter mon travail de John avec Jerry, qui concerne un nouveau ensemble de données pour la récupération d'articles statutaires."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions juridiques font partie intégrante de la vie de beaucoup de gens."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et leurs procédures juridiques fondamentales."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent pas afforder l'assistance costlière d'un expert sont laissés unprotection ou, worse, exploités."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler le fossé entre les gens et la loi en développant un système de récupération efficace pour les articles statutaires."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "Un tel système pourrait fournir un service d'aide juridique gratuit et professionnel aux humains non qualifiés."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de plonger dans la principale contribution de ce travail, décrivons d'abord le problème de la récupération d'articles statutaires."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Si une simple question sur une question juridique, comme : Que risque-je si je viole la confidentialité professionnelle?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est nécessaire pour retrouver tous les articles statutaires pertinents d'un grand ensemble de législation."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche de récupération d'informations s'accompagne de ses propres défis."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, il traite de deux types de langue."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "langage naturel commun pour les questions et langage juridique complexe pour les statuts."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans les distributions linguistiques rend plus difficile pour un système de récupérer les candidats pertinents, car elle nécessite indirectement un système d'interprétation inhérent qui peut traduire une question naturelle en une question juridique qui correspond à la terminologie des lois."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le droit statutaire n'est pas un tas d'articles indépendants qui peuvent être considérés comme une source d'information complète à part entière, comme les nouvelles ou les recettes, par exemple."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Enstead, c'est une collection structurée de dispositions légales qui ont une entière signification uniquement lorsqu'elles sont considérées dans leur contexte global, c'est-à-dire avec les informations supplémentaires provenant des articles adjacents, les domaines et sous domaines à qui elles appartiennent, et leur place dans la structure de la loi."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Lastly, les statutes articles sont en small paragraph, qui est généralement la type de retrieval unit dans la plupart des travaux de retrieval."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, il y a des documents longs qui peuvent durer jusqu'à six minutes."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les récentes avancées en matière de NLP ont suscité un énorme intérêt pour de nombreuses tâches juridiques, telles que la prédiction de jugements judiciaires ou la révision automatique des contrats."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la récupération d'articles statutaires est restée majoritairement intacte en raison du manque de données étiquetées de grande qualité et de grande envergure."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette étude, nous présentons un nouveau ensemble de données centré sur les citoyens français pour étudier si le modèle de récupération peut approximer l'efficacité et la fiabilité d'un expert juridique pour la tâche de récupération d'articles statutaires."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "Our Belgian statutory article retrieval dates consiste à plus de mille un litres."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions couvrent un large éventail de sujets, de la famille, du logement, de l'argent, au travail et à la sécurité sociale."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun d'entre eux a été labellé par expérimentés juristes avec références à relevant articles de plus de vingt deux mille six cents."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Belgique codes de la loi. Let's now talk about how we collected these data sets."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous avons commencé par compiler un grand corpus d'articles légaux."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné trente deux codes belges publicly disponibles et extrait tous leurs articles ainsi que les titres de section correspondants."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons ensuite rassemblé des questions juridiques en référence aux lois pertinentes."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous nous associons à un cabinet d'avocats belge qui reçoit chaque année environ quatre mille e-mails de citoyens belges qui demandent des conseils sur une question juridique personnelle."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance de nous accéder à leurs websites, où leur team de juristes expérimentés traite des questions de la Belgique les plus courantes."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons collecté des milliers de questions annotées avec des catégories, des sous catégories et des références juridiques à des statuts pertinents."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Lastly, nous passons les références juridiques et filtrons les questions dont les références ne sont pas des articles dans l'un des codes de loi que nous avons examinés."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été associées et converties aux identifiants d'article correspondants de notre corpus."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons finalement obtenu mille cent huit questions, chacune soigneusement labellée avec les ID des articles pertinents de la publication."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question est accompagnée d'une catégorie principale et d'une concaténation de sous-catégories."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "Et chaque article est accompagné d'une concaténation de leur titre suivant dans la structure de la loi."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Cette information supplémentaire n'est pas utilisée dans le travail présent, mais pourrait être intéressante pour future recherche sur la retrieval des informations juridiques ou la classification des textes."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons quelques caractéristiques de notre ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "La question est entre cinq et quarante quatre mots long, avec une médiane de quarante words."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont beaucoup plus longs, avec une longueur médiane de soixante sept mots, avec une longueur de cent quarante grammes."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "deux d'entre eux exceivant un million."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "Comme mentionné précédemment, la question couvre un large éventail de sujets, avec environ quatre-vingt-quinze pour cent d'entre eux concernant la famille, le logement, l'argent ou la justice."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que les quinze pour cent restants concernent soit la sécurité sociale, les étrangers ou le travail."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers, as ils proviennent de trente deux différents codes belges qui couvrent un large nombre de topics."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles collectés de chaque code belge."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Out de les vingt deux mille six cent trente trois articles, seulement un mille six cent douze sont referrés à as relevant à atteindre le point."}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "une question dans les données. Et environ quatre-vingts pour cent de ces articles cités proviennent de la Civil Code, de la Code judiciaire, de la Code d'investigation pénale ou de la Code pénale."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant ce temps, dix-huit codes sur trente-deux contiennent moins de cinq articles mentionnés comme étant pertinents à au moins une question."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Ce qui peut être expliqué par le fait que ces codes se concentrent moins sur les individus et leurs préoccupations."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "Overall, le médian de citation pour ces cités articles est deux, et moins de vingt cinq pour cent d'entre eux sont des"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos datasets, nous avons testé plusieurs approches de récupération, notamment la lexical et l'architecture dense."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "Si une requête est donnée dans un article, un modèle lexical attribue une note à la paire article requête en calculant la somme des poids de chacun de ces termes dans cet article sur les termes de requête."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec les fonctions de classement standard TFIDF et BM twenty five."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que des articles contenant des mots-clés présents dans la requête."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons une architecture basée sur des neurones qui peut capturer la relation sémantique entre les requêtes et les articles."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle BEAncoder qui mape des requêtes et des articles en représentations vectorielles denses et calcule un score pertinent entre une paire d'articles de requête en fonction de la similitude de leurs embeddings."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces embeddings sont généralement le résultat d'une opération de pooling sur la sortie d'un modèle d'embedding de mots."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous étudions l'efficacité des biancodeurs siamés dans un système d'évaluation à zéro tir, ce qui signifie que les modèles d'embellage pré-trainwood sont appliqués hors de la boîte sans aucune réglage supplémentaire."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec des encodeurs de texte indépendants du contexte, à savoir Word2Vec et FastText, et des modèles d'intégration dépendants du contexte, à savoir Roberta et plus précisément Camembert, qui est un modèle français Roberta."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous traînons notre propre modèle Camembert basé sur le modèle."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "sur tous les sets de données. Notez que pour la formation, nous expérimentons les deux flavors de l'architecture Bianco."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamese, qui utilise un modèle de word embedding unique qui mappe la query et l'article ensemble dans un espace vectoriel dense partagé, et Tutor, qui utilise deux modèles de word embedding indépendants qui encodent la query et l'article séparément dans deux spaces de embedding différents."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec le pooling de moyenne, de maximum et de CLS, ainsi que le produit scalaire et le cosinus pour les similitudes informatiques."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre ligne de base sur les ensembles de test."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "Avec les méthodes lexicales ci-dessus, les encodeurs B siamés évalués dans un ensemble de tirs zéro au milieu, et les encodeurs B finement ajustés ci-dessous."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, les cores Biancore bien ajustées surpassent de manière significative toutes les autres lignes de basse."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de deux tours s'améliore par rapport à sa variante siamese sur Recallat one hundred, mais se comporte de manière similaire sur les autres indicateurs."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que BM vingt cinq ait sous-performé de manière significative au train Biancode, ses performances indiquent qu'il reste une solide base pour le retrieu spécifique du domaine."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "Concernant l'évaluation Zero Shot du Biancodeur siaméen, nous constatons que l'utilisation directe des embeddings d'un modèle Kamembert préentraîné sans optimiser la tâche de récupération d'informations donne de mauvais résultats, ce qui est conforme aux conclusions précédentes."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous avons constaté que le Biancodeur basé sur WordTuvec a considérablement surpassé le modèle basé sur Vastex et Bird, ce qui suggère que peut-être les embeddings au niveau de la parole pré-entraînée sont plus appropriés pour cette tâche que les embeddings au niveau de caractère ou au niveau de sous-ord lorsqu'ils sont utilisés dès le départ."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteurs, ces résultats suggèrent de nombreuses possibilités d'amélioration par rapport à un expert juridique qualifié qui peut éventuellement récupérer tous les articles pertinents à n'importe quelle question et ainsi obtenir des scores parfaits."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Concluons en discutant de deux limitations de tous les ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, le corpus des articles est limité à ceux recueillis des trente-deux codes belges considérés, qui ne couvrent pas l'ensemble de la loi belge, car les articles des décrets, des directives et des ordonnances manquent."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Lors de la construction du dataset, toutes les références à ces articles non collectés sont ignorées, ce qui cause une question de finir avec une fraction de leur nombre initial d'articles pertinents."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'informations implique que la réponse contenue dans les articles restants pertinents pourrait être incomplète, bien qu'elle soit toujours complètement appropriée."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, il convient de noter que toutes les questions juridiques ne peuvent être répondues que par des statuts."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question : Puis-je expulser mes locataires s'ils font trop de bruit?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "Il ne peut pas avoir une réponse détaillée dans la loi statutique qui quantifie un seuil de bruit spécifique auquel l'expulsion est autorisée."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, le propriétaire devrait probablement se fier davantage à la jurisprudence et trouver des précédents similaires à leur situation actuelle."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le tenant fait deux parties par week jusqu'à deux heures."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, certaines questions sont mieux adaptées que d'autres à la tâche de récupération d'articles statutaires, et le domaine des moins appropriées restera à être déterminé."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que tout ce travail suscite l'intérêt pour le développement de modèles de récupération d'articles statutaires pratiques et fiables,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut aider à améliorer l'accès à la justice pour tous."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre papier, DATSET et CODE à l'environnement. Merci."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, nous sommes heureux de présenter notre travail sur Vowls, un benchmark indépendant de tâches destiné à tester des modèles de vision et de langage avec des phénomènes linguistiques spécifiques."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi avons-nous fait le travail de mettre en place ce point de référence?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Eh bien, au cours des dernières années, nous avons vu une explosion de modèles de vision et de langage basés sur des transformateurs pré-entraînés sur de grandes quantités de paires d'images texte."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun de ces modèles pousse les tâches de pointe sur la vision et le langage telles que la réponse aux questions visuelles, la raison de bon sens visuel, la récupération d'images, la fondation des phrases."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc reçu un message. Les précisions de ces références spécifiques à la tâche augmentent régulièrement."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous ce que les modèles ont réellement appris?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce qu'un transformateur de vision et de langage a compris en attribuant un score élevé à cette image et à cette phrase pour correspondre?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "Et le score le plus bas pour celui-ci."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur la bonne chose?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Ou se concentrent-ils sur les préjugés, comme le montrent les travaux précédents?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour éclairer davantage cet aspect, nous proposons une direction plus indépendante des tâches et introduisons des valves qui testent la sensibilité des modèles visuels et de langage à des phénomènes linguistiques spécifiques qui affectent à la fois les modalités linguistiques et visuelles."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous visons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la co-référence d'entité."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment vérifier si les modèles de vision et de langage ont capturé ces phénomènes?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "par le foiling, une méthode précédemment appliquée pour les modèles de vision et de langue, seulement pour les phrases nominales par Ravi Shakar et ses collaborateurs, et sur le comptage par nous dans le travail précédent."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le foiling signifie essentiellement que nous prenons la légende d'une image et produisons un foil en modifiant la légende de telle sorte qu'elle ne décrit plus l'image."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Nous apportons ces modifications de phrases en nous concentrant sur six éléments spécifiques tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la co-référence d'entités, où chaque élément peut être composé d'un ou plusieurs instruments, au cas où nous aurions trouvé plus d'une façon intéressante de créer des instances de FOIL."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas de la pièce des actions, nous avons deux instruments, l'un dans lequel le verbe d'action est changé avec une action différente et l'autre dans lequel les actants sont échangés."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la co-référence sont également des pièces qui ont plus d'un instrument."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous créons ces défauts en veillant à ce qu'ils ne décrivent pas l'image, qu'ils soient des phrases grammaticales et autres valides."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas facile à faire car une légende défectueuse peut être moins probable que la légende originale."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien que ce ne soit pas impossible, statistiquement, il est moins probable que des plantes coupent un homme qu'un homme coupent des plantes, et les modèles de grande vision et de langage pourraient le détecter."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des feuilles valides, nous devons agir."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous utilisons des modèles de langage solides pour proposer des FOILS."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence du langage naturel ou NLI pour filtrer les feuilles qui pourraient encore décrire l'image, car lorsque nous construisons des feuilles, nous devons nous assurer qu'elles ne décrivent pas l'image."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester cela automatiquement, nous appliquons l'inférence du langage naturel avec la logique suivante."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons une image comme la prémisse et son titre comme l'hypothèse implicite."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "En addition, nous considérons que la caption est la premisse et que le foil est sa hypothèse."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit que le FOIL contredit ou est neutre par rapport à la légende, nous considérons cela comme un indicateur d'un FOIL valide."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si une NLI prédit que la feuille de surface est impliquée par la légende, elle ne peut pas être une bonne feuille de surface, car elle donnera une description fidèle de l'image par transitivité et nous filtrons ces feuilles."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette procédure n'est pas parfaite. Elle est juste une indication pour validifier."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, en tant que troisième mesure pour générer des foils valides, nous utilisons des annotateurs humains pour valider les données utilisées dans les valves."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, après le filtrage et l'évaluation humaine, nous avons autant d'instances de test que décrit dans ce tableau."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que VALS ne fournit aucune donnée d'entraînement, mais seulement des données de test."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "Puisqu'il s'agit uniquement d'un benchmark de test de tir zéro, il est conçu pour tirer parti des capacités existantes des modèles de vision et de langage après la pré-entraînement."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "Le réglage précis ne permettrait que des modèles d'exploiter des artefacts ou des biais statistiques dans les données."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme nous l'avons dit, nous sommes intéressés par l'évaluation des capacités des modèles de vision et de langage après la pré-entraînement."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons cinq modèles de vision et de langage sur les voyelles, à savoir CLIP, AlexMert, Wilbert, Wilbert Kelvin I et VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos métriques d'évaluation les plus importantes sont l'exactitude des modèles pour classer les paires de phrases d'images en titres et en foils."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Plus pertinente pour cette vidéo, nous présenterons notre métrique plus permissive, l'exactitude par paires, qui mesure si le score d'alignement de la phrase d'image est supérieur pour la paire de texte d'image correcte que pour sa paire de FOIL."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "Pour plus de métriques et de résultats à leur sujet, consultez notre article"}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats avec une précision par paires sont présentés ici et sont cohérents avec les résultats que nous avons obtenus des autres métriques. Le meilleur résultat de tirs à zéro est obtenu par Wilbert douze en un, suivi de Wilbert, Alex Mert, Clip et enfin VisualBird."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est remarquable de noter que les instruments centrés sur des objets individuels comme l'existence et les phrases nominales sont presque résolus par Wilbert douze en un, soulignant que les modèles sont capables d'identifier les objets nommés et leur présence dans les images."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos réglages de foiling adversaire."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons, grâce à la pluralité des instruments de comptage, que les modèles visuels et linguistiques ont du mal à distinguer les références à des objets individuels par rapport à plusieurs objets ou à les compter dans une image."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "La relation P montre qu'ils ont des difficultés à classer correctement une relation spatiale nommée entre les objets dans une image,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont également du mal à distinguer les actions et à identifier leurs participants, même si elles sont étayées par des préjugés de plausibilité, comme nous le voyons dans la partie sur les actions."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la partie de la co-référence, nous constatons que le fait de retracer plusieurs références au même objet dans une image en utilisant des pronoms est également difficile pour les modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "En guise de vérification de la santé mentale et parce que c'est une expérience intéressante, nous avons également testé deux modèles de texte seulement, GPT un et GPT deux, pour évaluer si Valve est résolu par ces modèles unimodaux en calculant la perplexité de la légende correcte et défaillante, sans image ici, et en prédisant l'entrée avec la plus faible perplexité."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "Si la perplexité est plus élevée pour le FOIL, nous considérons cela comme un signe que la légende FOIL peut souffrir d'un biais de plausibilité ou d'autres biais linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est intéressant de voir que dans certains cas, les modèles GPT de texte ont capturé la plausibilité du monde mieux que les modèles vision et language."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, VALS est un référencement qui utilise le prisme des constructions linguistiques pour aider la communauté à améliorer les modèles visuels et linguistiques en testant rigoureusement leurs capacités de fondation visuelle."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que les modèles visuels et de langage identifient bien les objets nommés et leur présence dans les images, comme le montre l'existence, mais ont du mal à établir leur interdépendance et leurs relations dans les scènes visuelles lorsqu'ils sont contraints de respecter les indicateurs linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser Vals pour mesurer les progrès vers la base linguistique avec des modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "Et, de plus, Valve pourrait être utilisé comme évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou le finissement pour voir si un ensemble de données aide les modèles à améliorer l'un des aspects testés par Valve."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si cela vous intéresse, consultez les données de Vault sur GitHub et si vous avez des questions, n'hésitez pas à nous contacter."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kamisara, de l'université de Tokyo."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter un papier entitled RNSAM, un large scale de la set pour automatique risque de duration de la comitologie."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais expliquer dans cet ordre."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais vous présenter la génération automatique de risques sur laquelle nous travaillons dans cette recherche."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "ReleaseNote est un document technique qui résume les modifications apportées à chaque version d'un produit logiciel."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'image montre les notes de risque pour Bosch deux point six."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Usage S library. Ces notes prennent un important rôle en open source développement, mais elles sont consommées à préparer manuellement."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Il serait donc très utile de pouvoir générer automatiquement des notes de libération de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais faire référence à deux recherches précédentes sur la génération automatique de fissures."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé Arena, produit en 2014."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il prend une approche basée sur les rules, par exemple, en utilisant le changer extracteur pour extraire les différences, les changements de librerie et les changements de documents des différences entre les releases, et finalement en combinant les différences."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus notable de ce système est l'extracteur de l'émission dans le coin supérieur droit,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "Il doit être lié à zéro pour évaluer l'écosystème et ne peut être appliqué qu'aux projets qui utilisent zéro."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "ensemble. En d'autres termes, il ne peut pas être utilisé pour de nombreux projets sur GitHub."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "Le second est Grief. Il est annoncé en vingt minutes."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "2020. Il est disponible sur Internet et peut être stocké via PIP."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système dispose d'un modèle de classification de texte simple basé sur le rangement et de sorties formant cinq graphiques telles que des fonctionnalités ou des corrections d'erreurs pour chaque message de comité d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un échantillon utilisé qui retient un échantillon de correction ou de correction des erreurs."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données de training de Graves sont relativement faibles, environ cinq mille, et seront présentées dans les expériences décrites ci-dessous."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "La performance du modèle de classification statistique n'est pas élevée."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il y a des problèmes de limitées applicabilités et de scarce ressources de données."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des notes de libération de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le programme d'applicabilité limitée, nous proposons une méthode de résumé classifié de haute qualité en utilisant uniquement le message de comité comme input."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour tous les dépôts en anglais."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème de ressources scarces, nous avons construit un RNSAMDSET consistant de quatre-vingt-deux mille pièces de données en collectant des données provenant de réponses publiques GitHub utilisant l'API GitHub."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris notre décès."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de données."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche est le message du comité et le côté droit est la note de liquidation."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de la liste sont louables comme des améliorations, des officiels, etc."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons configuré une tâche qui prend les messages du comité en entrée et sort les notes de plaisance révélées."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de résumé."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédefinie quatre éléments de fonctionnalité, amélioration, correction des erreurs, suppression, suppression et modification des freins."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces données étaient basées sur des recherches antérieures et d'autres facteurs."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de release en bas à droite sont extraites des notes de release en bas à gauche."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce moment-là, il est nécessaire de détecter les quatre débris qui ont été installés à l'avance."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "mais les livres ne sont pas toujours cohérents avec chaque liberté,"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, les moteurs d'amélioration de la taille augmentent les améliorations, les améliorations, les optimisations, etc."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste vocabulaire d'environ trente numéros pour chacune de ces variations notationnelles."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez le texte de la race note crusque et correct le texte de la race note crusque."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, il y a un message de comité."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages du comité ne sont pas liés à chaque voix."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme on le voit dans l'image below, si le current risque est deux point cinq deux neuf, nous devons identifier"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "modifie la version de la version précédente et obtient un diff. C'est un peu tedious et il ne suffit pas de simplement obtenir une liste de versions et de regarder les versions avant et après."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Il a créé une heuristique correspondant à vous pour obtenir les concours précédents et suivants."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Dès que le hors de la rue s'est arrêté."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "En fin de compte, sept mille deux cents repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de jetons de produits n'est pas de soixante-trois, ce qui est assez élevé pour une tâche de résolution."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "L'autre, le nombre de tokens uniques est très large à huit mille huit cent trente mille."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "due au large nombre de classe et de méthodes n'auront été trouvées dans le répertoire."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je vais expliquer la méthode proposée."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé transversal, extractif et abstractif est composé de deux modules neuronaux"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "un classificateur utilisant BOT ou un code BOT et un générateur utilisant BOT."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, GEAS utilise un classificateur pour classer chaque message de comité en cinq classes de notes de recherche : fonctionnalités, améliorations, corrections d'erreurs, duplications, plus et autres."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages du comité classés comme autres sont rejetés."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, GAS applique le générateur indépendamment aux quatre documents de routeur et génère un nœud de risque pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages de commit et les notes de lecture ne sont pas connues."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classificateur, nous attribuons des pseudobus à chaque message de commande d'entrée en utilisant les dix premiers caractères de chaque message de commande."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons l'approche de la somme d'obstruction transversale par deux méthodes différentes."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier module, que nous appelons GIS Single, est composé d'un seul réseau SECT et génère un seul texte long, donnant un potentiel de messages de commutation d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte de sortie peut être divisé en segments croisés en fonction de symboles de point de fin spécifiques de la croix."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons CSMarch, se compose de quatre réseaux sec-to-sec différents, chacun correspondant à l'une des classes de nœuds de la liste."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, ça fait l'expérience de Span."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées : CAS, CAS unique, CAS intelligent, Rosselling et le résumé de l'étude précédente."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'ablation, dans certains cas, ces notes sont produites en multiples sentences."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Puisqu'il est difficile de calculer le nombre de phrases à zéro, elles sont combinées avec des espaces et traitées comme une seule phrase longue."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "Le bureau est pénaire lorsque le système produit une brève phrase"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité entraîne une baisse du volume de la boisson dans les résultats expérimentaux décrits en suivant."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous corroguons également la spécificité car le rouge et le bleu ne peuvent pas être corrogués si les notes de RISE sont vides."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une spécificité élevée signifie que les outputs de la propriété modèle sont emptis, tactis, dans les cas où les résultats sont assumés emptis."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Puisque le dataset contient des adresses d'email, des barrières, etc, nous avons également élargi le client dataset, qui exclut les"}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a atteint des scores de l'air de Rouge de plus de dix points supérieurs aux lignes de base."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur le Green test, le score gap entre la proposée méthode et la base en jumped à plus de vingt points."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent qu'elle est et qu'elle est significativement efficace."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "GAS a obtenu un meilleur score de Rouge FS que GAS, suggérant que combiner un classifier et un générateur est efficace sur la formation du classifier en utilisant des pseudo-régaux."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "La coverage de la GAS peut être atteinte probablement parce que le classifier peut se concentrer sur la sélection de messages de commande pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a tendance à manger plus souvent que lorsqu'elle est célibataire."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "suggérant qu'il est également efficace de développer de manière indépendante différents modèles de résumé de votre perspective pour chaque classe de nœud."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "Héroïne et Eronas."}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes Xi's ont tendance à produire des phrases plus courtes que les phrases de référence humaines."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure sur la droite, la différence de la sentence a trois ou quatre sentences, while SUS a seulement un."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette réticence modèle est que dans les données d'entraînement, seulement 33 % des phrases sont présentes dans le ruban des caractéristiques et 40 % dans le ruban des améliorations."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes de CES ne peuvent pas générer de nœuds de risque précis sans des informations supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut sur la droite est un exemple de message très messie, et la phrase complète ne peut pas être générée sans référence à la requête ou à l'issue correspondante."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous montre que les deux messages de comité dans l'entrée sont liés et devraient être combinés en une seule phrase, mais cela ne le fait pas."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, une conclusion."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons créé un nouveau jeu de données pour la génération automatique de pisteaux,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également formé la tâche d'entrer les messages de commande et de les résumer de manière à ce qu'ils s'appliquent à tous les projets écrits en anglais."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que la méthode proposée générée par le basso n'est pas à une couverture plus élevée que les bassoirs."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez consulter notre application de tests de réserve."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Safarari,"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter notre article, Few Short Tabular Data Enrichment Using Fine Tuning Transformers Architectures."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Les scientifiques des données analysent les données et se concentrent principalement sur la manipulation des caractéristiques existantes des données."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "Mais parfois, ses caractéristiques sont limitées."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération de fonctionnalités à l'aide d'une autre source de données peut ajouter des informations importantes."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique des données tabulaires à l'aide de textes libres d'origine externe."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons que nous disposions d'un ensemble de données tabulaire et d'une base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique qui implique le lien entre entités et l'analyse de texte pour extraire de nouvelles caractéristiques du texte libre de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre est exactement ce processus automatique."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Prenons un exemple. Dans les ensembles de données, ils sont introduits dans FAST."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données est un ensemble de données universitaires."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque son objectif est de classer les universités en universités à faible classement et universités à haut classement."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que base de connaissances, nous utilisons Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase de FEST est la liaison d'entités."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque chaque entité, dans cet exemple, le nom de l'université est lié à une entité au sein de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "et le texte des entités de la base de connaissances est extrait et ajouté au dataset."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est l'abstract de la page Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Maintenant, nous devons générer ou extraire des caractéristiques du texte récupéré."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc besoin d'une phase d'extraction de caractéristiques qui comprend l'analyse du texte."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est la principale nouveauté de cet article, et je vais y approfondir dans les prochaines diapositives."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des caractéristiques, il y a une phase de génération de caractéristiques, lorsque nous utilisons les caractéristiques extraites pour générer un petit nombre de nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez des caractéristiques dans le nombre de classes du jeu de données original."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données d'origine comporte deux classes"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, générez deux nouvelles fonctionnalités."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si l'ensemble de données comporte cinq classes, générez d'abord cinq nouvelles fonctionnalités."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état actuel de l'analyse du texte, qui est un modèle de langage basé sur des transformateurs, comme Baird, GPT, XNET, etc."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "Mais il est peu probable que nous puissions entraîner un modèle de langue à l'aide des ensembles de données d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Une approche naïve consistera donc à affiner la tâche cible."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans la phase d'extraction de caractéristiques, nous pouvons télécharger le modèle de langue parentraîné, affiner le modèle de langue sur le jeu de données cible."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, pour affiner le modèle de langue, classifier le texte en classes, l'abstract en classes, bas ou haut."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "Recevez la sortie du modèle de langue, qui est la probabilité pour chaque classe, et utilisez-la comme nouvelles fonctionnalités."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que les ensembles de données peuvent avoir peu d'entités distinctes."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, près de la moitié des ensembles de données contiennent moins de quatre cents échantillons et le plus petit ensemble de données contient trente-cinq échantillons dans son ensemble d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, affiner un modèle de langue sur cet ensemble de données sera inefficace."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons utiliser des connaissances préalables sur les ensembles de données préanalysées."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Puisque nous appliquons le FAST sur plusieurs ensembles de données, nous pouvons utiliser les ensembles de données n pour recueillir des informations sur les ensembles de données n et utiliser ces informations lorsque nous analysons l'ens dataset."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce que nous suggérons? Tout d'abord, une autre phase de fine-tuning."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "une phase de finition préliminaire multitask."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque vous trouvez le modèle de langue sur n moins un ensemble de données,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous exécutons une autre phase de finesse, qui est une finesse des tâches cibles lorsque nous finissons le modèle de langue sur le ensemble de données cible n."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "Le réglage à la dernière minute en matière de multitâche appelé MTDNN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "Dans le DNN vide, le DNN vide maintient un nombre de têtes dans le nombre de tâches dans le jeu d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, il y a donc quatre tâches dans le jeu d'entraînement. Donc, le DNN vide et le maintien de quatre têtes, comme vous pouvez le voir sur l'image."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "Et il échantillonne un lot aléatoire du jeu d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot de rendez-vous appartient à, par exemple, des tâches de classification de Sing et Selton, il exécute des passages en avant et en arrière à travers la première tête."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot aléatoire appartient à une tâche de classement paires, il est autorisé à passer en arrière et en arrière à travers la dernière tête."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, une tableau de données verifie le nombre de classes."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a donc de nombreuses tâches."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "Le DNN vide maintient le nombre de têtes de classes, couches de sortie."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, MTDNN doit initialiser de nouvelles têtes pour un nouveau ensemble de données avec une nouvelle tâche."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche appelée réglage de la réformulation des tâches consiste à réformuler chaque ensemble de données en une phrase par problème de classification, qui est composée de deux classes de tâches."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons donc un exemple."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre ensemble de données d'entrée qui consiste en entités, caractéristiques, texte et classes."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Nous reformulons la tâche de classer le texte en bas et haut pour classer le texte, l'abstract et la classe en vrai ou faux."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous avons formé le modèle de langage pour classer les abstracts et les classes, pour voir si les abstracts appartiennent à la classe ou non."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le vecteur étiquette, dans ce cas, reste toujours composé de deux classes."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici l'algorithme de notre approche de réglage précis formulée."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons donc le cadre complet."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "et dataset fade into fast."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "puis une phase de liaison d'entité exécutive rapide."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "Il extrait le texte de la base de connaissances, qui dans cet exemple est l'abstracte de la page Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "puis il réformulait la tâche en une tâche de classification de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de péri"}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "appliquez le modèle de langue à la nouvelle tâche et à la probabilité de sortie pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que le modèle de langue est déjà ajusté sur un ensemble de données n-1 en utilisant un ajustement préliminaire multitask."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons ensuite le vecteur de sortie du modèle de langue comme caractéristique nouvellement générée dans le nombre de classes."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification tabulaire de dix-sept, qui varie en taille, caractéristiques, équilibre, domaine et performance initiale."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme base de connaissances, nous utilisons Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation de laissée de côté, lorsque nous entraînons rapidement sur seize ensembles de données et les appliquons au dix-septième ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "Nous divisons également chaque ensemble de données en quatre fausses et appliquons une validation croisée des fausses."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous générons la nouvelle fonctionnalité et l'évaluons à l'aide de cinq classificateurs d'évaluation."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons une architecture basée sur la construction dans notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez voir que nous comparons notre cadre à la fine-tuning du jeu de données cible, la fine-tuning des tâches cible et la fine-tuning préliminaire du DNN vide."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "Et notre formulation a été très utile pour obtenir le meilleur résultat, la meilleure performance."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que MTDN a réalisé une amélioration de 2 % par rapport à la fine réglage du jeu de données cible."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "Notre poche a réalisé une amélioration de six pour cent."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque nous examinons le petit ensemble de données, nous constatons que la performance du DNN vide diminue et que l'amélioration de la phase de fine-tune multitask diminue à 1,5 %."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "Mais notre performance a augmenté de 11 % par rapport à la tâche cible, en faisant des ajustements."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le summum, FAST permet d'enrichir quelques prises de vue à partir de trente-cinq échantillons de notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une seule architecture pour tous les ensembles de données de tâches."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "Et il garde la tête du modèle."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "Mais il ajoute trois phases de formulation."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "Il s'agit d'augmenter l'ensemble de formation et il a besoin d'une valeur cible avec un sens sémantique, afin de pouvoir l'intégrer au modèle de langue et l'utiliser dans le problème de classification des paire de phrases."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci."}
{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous. Aujourd'hui, je vais vous présenter notre travail de recherche apprendre à raisonner deductivement, résolution de problèmes de mathématiques en tant que réaction complexe d'extraction."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je suis Alan de Biden's AI Lab et je travaille en collaboration avec Thierry de l'université du Texas à Austin et Wayloo de SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je voudrais parler de notre motivation pour raisonner."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous montrons des exemples où le raisonnement à plusieurs étapes est utile."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Ce chiffre provient du papier PALM où ils ont effectué des promptings pour résoudre le problème de la méthode dans un scénario d'apprentissage de tirs de combustible."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, du côté du net, nous pouvons voir que si nous donnons des exemples avec seulement des questions et des réponses, nous ne pourrons peut-être pas obtenir les bonnes réponses."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous donnons une description plus raisonnable, le modèle est capable de prédire la description raisonnable et de faire une prédiction correcte ici."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Il est donc bon d'avoir une résolution interprétable à plusieurs étapes."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons également que le problème de la méthode est une application directe pour évaluer ces capacités de raisonnement."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre configuration de problème, compte tenu des questions, nous devons résoudre cette question et obtenir les réponses numériques."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos ensembles de données, on nous donne également l'expression mathématique qui conduit également à cette réponse particulière."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, certaines hypothèses s'appliquent également comme dans les travaux précédents."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que la précision des quantités est connue,"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que des opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentielle."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, des opérateurs compliqués peuvent en fait être décomposés en ces opérateurs de base."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le travail précédent dans la résolution de problèmes méthodiques peut en fait être classé en séquence à séquence et en séquence à arbre."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le modèle de séquence traditionnel convertit l'expression en une séquence spécifique pour la génération."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est assez facile à mettre en œuvre et peut être généralisé à de nombreux problèmes compliqués."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les inconvénients sont que la performance n'est en fait généralement pas meilleure que le modèle structuré et qu'il manque d'interprétation pour la prédiction."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en fait, cette direction est encore assez populaire parce que le transformer modèle."}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans les modèles basés sur un arbre, nous structurons en fait ces expressions sous forme d'arbre et suivons une traversée préordonnée dans trois générations."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, nous continuons à générer les opérateurs jusqu'à ce que nous atteignions les LIFF qui sont les quantités."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Le bon côté, c'est qu'il nous donne en fait cette structure d'arbre binaire, mais en réalité, c'est assez contraire à l'intuitivité car nous générons d'abord l'opérateur, puis à la fin, nous générons les quantités."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose, c'est qu'il contient également des calculs répétitifs."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, si nous regardons cette expression, huit fois trois plus trois est en fait générée deux fois. Mais en fait, nous devrions réutiliser les résultats"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre approche proposée, nous souhaitons donc résoudre ces problèmes de manière étape par étape et interprétable."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, ici, dans la deuxième étape, nous pouvons obtenir ce diviseur, qui est vingt-sept."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons également nous référer à l'original pour trouver le contenu pertinent."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous obtenons les diviseurs."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Et puis, à cette troisième étape, nous obtenons réellement le quotient."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord. Et après ces trois étapes, nous pouvons réutiliser les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape. Et enfin, nous pouvons obtenir les dividendes."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, nous générons en fait l'expression entière directement plutôt que de générer des opérateurs ou des quantités individuels."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "Cela rend le processus plus précis."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans notre système déductif, nous commençons d'abord par un ensemble de quantités présentées dans les questions et nous incluons également une constante comme état initial."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "L'expression est donc représentée par EIJOP."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "Là où nous effectuons des opérateurs de Qi à Qj, et cette expression est en fait dirigée."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, nous avons également des subtractions versus ici pour représenter la direction opposée."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "C'est assez similaire à l'extraction de radiation."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans un système déductif formel, à l'étape temporelle t, nous appliquons l'opérateur entre le couple Qi et Qj, puis nous obtenons ces nouvelles expressions."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "Nous l'ajoutons à l'état suivant pour devenir une nouvelle quantité."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Ces diapositives visualisent donc en fait l'évolution des états, où nous continuons à ajouter des expressions aux états actuels."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans nos implémentations de modèle, nous utilisons d'abord un modèle de langue pré-entraînée qui peut être des oiseaux ou des robots, puis nous codons la phrase et obtenons ces représentations de quantité."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Une fois que nous avons obtenu les représentations de quantité, nous pouvons commencer à faire des inférences."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous montrons un exemple de Q1 pour obtenir la représentation de Q1. Ils seront divisés par Q2, puis multipliés par Q4."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous obtenons la représentation de la paire, qui est essentiellement la concaténation entre Q1 et Q2. Ensuite, nous appliquons un réseau de feedforward, qui est paramétrifié par l'opérateur."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et enfin, nous obtenons la représentation de l'expression Q1 divisée par Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en pratique, à l'étape de l'influence, nous pourrions également être en mesure d'obtenir l'expression incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, toutes les expressions possibles sont égales à trois fois le nombre d'opérateurs."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "Le bon côté ici, c'est que nous pouvons facilement ajouter des contraintes pour contrôler ce espace de recherche."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement la supprimer de notre espace de recherche."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans la deuxième étape, nous faisons la même chose, mais la seule différence est qu'il y a une quantité de plus."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "Cette quantité provient de l'expression calculée précédemment."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous pouvons obtenir cette expression finale Q3."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "Quatre fois Q quatre. Et nous pouvons également voir que le nombre de toutes les expressions possibles est différent de l'étape précédente."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "Ces différences rendent donc difficile l'application de la recherche par faisceau car la répartition des probabilités entre ces deux étapes est déséquilibrée."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "La procédure d'entraînement est donc similaire à l'entraînement d'un modèle de séquence à séquence où nous optimisons la perte à chaque étape temporelle."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons également cette tau pour représenter quand nous devrions mettre fin à ce processus de génération."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent de séquence à séquence car l'espace est différent à chaque fois que, dans le modèle traditionnel de séquence à séquence, c'est le nombre de vocabulaire."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et cela nous permet également d'imposer certaines contraintes à partir de connaissances préalables."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc effectué des expériences sur les ensembles de données de problèmes de méthodes couramment utilisés, MAWPS, Math twenty three K, Math QA et SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici brièvement les résultats par rapport aux meilleures approches précédentes."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Notre meilleure variante est donc Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "En fait, nous n'utilisons pas BeamSearch, par opposition aux approches évidentes utilisant BeamSearch."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, les meilleures approches sont souvent un modèle basé sur trois arbres."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, notre raisonnement est donc capable de surpasser de manière significative ce modèle basé sur l'arbre."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons voir que le nombre absolu sur MathQA ou SWAM n'est pas vraiment élevé."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc étudié les résultats sur la page."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "Et cet ensemble de données est difficile car l'auteur a tenté d'ajouter manuellement quelque chose pour confondre le modèle NLP, comme ajouter des informations irrelevantes et des quantités supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans notre prédiction, nous constatons que certaines des intermédiaires sont en fait négatives."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans ces questions, nous demandons combien de pommes Jake possède."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons des informations supplémentaires, comme dix-sept présentations de combustible et Stephen en a huit, ce qui est totalement sans importance."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Notre modèle fait donc des prédictions comme celle-ci, qui produisent des valeurs négatives."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous observons ces deux expressions."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc en fait limiter cet espace de recherche en supprimant les résultats négatifs afin de pouvoir donner une bonne réponse."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons donc que cette contrainte améliore en fait considérablement certains modèles."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour les oiseaux, nous avons amélioré de sept points, puis pour le modèle basé sur Roberta, nous avons en fait amélioré de deux points."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, un meilleur modèle de langue a une meilleure capacité à comprendre la langue, de sorte que le nombre ici est plus élevé pour Roberta et plus faible pour Bertha."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également essayé d'analyser les difficultés qui se cachent derrière ce BPP."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que le nombre de quantités inutilisées peut être considéré comme une information sans importance ici."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous pouvons voir que nous avons le pourcentage d'échantillons avec des quantités inutilisées et que le jeu de données SWAMP contient la plus grande partie."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons également les performances globales."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ces échantillons sans quantités inutilisées, la performance globale est en fait supérieure à celle de la performance globale."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "Mais avec ces échantillons, avec une quantité inutilisée, c'est en fait bien pire que la quantité."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "Pour MAWPS, nous n'avons pas vraiment beaucoup de cas de bureau, donc je n'ignore pas cette partie."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous voulons montrer l'interprétation à travers un exemple de participation à la question."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, notre modèle fait en fait une prédiction erronée à la première étape."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pouvons donc en fait corréler cette expression à la phrase ici, d'accord?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Nous pensons donc que cette phrase pourrait dérober un modèle de prédiction incorrecte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, ici, en plantant un autre trente-cinq, le modèle pense qu'il devrait s'agir d'opérateurs d'addition."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc essayé de réviser la phrase pour qu'elle soit quelque chose comme le nombre d'arbres de poireaux est de cinq fois moins que celui des pommiers."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Nous le faisons donc pour transmettre une sémantique plus précise, de sorte que le modèle soit capable de faire la prédiction correcte."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Cette étude montre donc comment les prédictions interprétables nous aident à comprendre le comportement du modèle."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Pour conclure notre travail, notre modèle est en fait assez efficace."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "et nous sommes en mesure de fournir une procédure de résolution interprétable."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pouvons facilement incorporer une certaine connaissance préalable comme constraint, ce qui peut aider à améliorer la performance."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et la dernière chose est que le mécanisme sous-jacent ne s'applique pas seulement aux tâches de résolution de problèmes de réseau, mais aussi à d'autres tâches qui impliquent un raisonnement à plusieurs étapes."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons également certaines limites."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "Si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose, comme mentionné, c'est que la distribution de probabilité est déséquilibrée à différents étapes temporelles, il est donc également assez difficile d'appliquer des recherches de faisceau."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "C'est la fin de la discussion et les questions sont les bienvenues. Merci."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Antoine et je suis de l'université de Maastricht."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter mon travail de John avec Jerry, qui concerne un nouveau ensemble de données pour la récupération d'articles statutaires."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions juridiques font partie intégrante de la vie de beaucoup de gens."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et leurs procédures juridiques fondamentales."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent pas afforder l'assistance costlière d'un expert sont laissés unprotection ou, worse, exploités."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler le fossé entre les gens et la loi en développant un système de récupération efficace pour les articles statutaires."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "Un tel système pourrait fournir un service d'aide juridique gratuit et professionnel aux humains non qualifiés."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de plonger dans la principale contribution de ce travail, décrivons d'abord le problème de la récupération d'articles statutaires."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Si une simple question sur une question juridique, comme : Que risque-je si je viole la confidentialité professionnelle?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est nécessaire pour retrouver tous les articles statutaires pertinents d'un grand ensemble de législation."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche de récupération d'informations s'accompagne de ses propres défis."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, il traite de deux types de langue."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "langage naturel commun pour les questions et langage juridique complexe pour les statuts."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "Cette différence dans les distributions linguistiques rend plus difficile pour un système de récupérer les candidats pertinents, car elle nécessite indirectement un système d'interprétation inhérent qui peut traduire une question naturelle en une question juridique qui correspond à la terminologie des lois."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le droit statutaire n'est pas un tas d'articles indépendants qui peuvent être considérés comme une source d'information complète à part entière, comme les nouvelles ou les recettes, par exemple."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "Enstead, c'est une collection structurée de dispositions légales qui ont une entière signification uniquement lorsqu'elles sont considérées dans leur contexte global, c'est-à-dire avec les informations supplémentaires provenant des articles adjacents, les domaines et sous domaines à qui elles appartiennent, et leur place dans la structure de la loi."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Lastly, les statutes articles sont en small paragraph, qui est généralement la type de retrieval unit dans la plupart des travaux de retrieval."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, il y a des documents longs qui peuvent durer jusqu'à six minutes."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les récentes avancées en matière de NLP ont suscité un énorme intérêt pour de nombreuses tâches juridiques, telles que la prédiction de jugements judiciaires ou la révision automatique des contrats."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la récupération d'articles statutaires est restée majoritairement intacte en raison du manque de données étiquetées de grande qualité et de grande envergure."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette étude, nous présentons un nouveau ensemble de données centré sur les citoyens français pour étudier si le modèle de récupération peut approximer l'efficacité et la fiabilité d'un expert juridique pour la tâche de récupération d'articles statutaires."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "Our Belgian statutory article retrieval dates consiste à plus de mille un litres."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions couvrent un large éventail de sujets, de la famille, du logement, de l'argent, au travail et à la sécurité sociale."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun d'entre eux a été labellé par expérimentés juristes avec références à relevant articles de plus de vingt deux mille six cents."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "Belgique codes de la loi. Let's now talk about how we collected these data sets."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous avons commencé par compiler un grand corpus d'articles légaux."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné trente deux codes belges publicly disponibles et extrait tous leurs articles ainsi que les titres de section correspondants."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons ensuite rassemblé des questions juridiques en référence aux lois pertinentes."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous nous associons à un cabinet d'avocats belge qui reçoit chaque année environ quatre mille e-mails de citoyens belges qui demandent des conseils sur une question juridique personnelle."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance de nous accéder à leurs websites, où leur team de juristes expérimentés traite des questions de la Belgique les plus courantes."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons collecté des milliers de questions annotées avec des catégories, des sous catégories et des références juridiques à des statuts pertinents."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "Lastly, nous passons les références juridiques et filtrons les questions dont les références ne sont pas des articles dans l'un des codes de loi que nous avons examinés."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été associées et converties aux identifiants d'article correspondants de notre corpus."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons finalement obtenu mille cent huit questions, chacune soigneusement labellée avec les ID des articles pertinents de la publication."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, chaque question est accompagnée d'une catégorie principale et d'une concaténation de sous-catégories."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "Et chaque article est accompagné d'une concaténation de leur titre suivant dans la structure de la loi."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Cette information supplémentaire n'est pas utilisée dans le travail présent, mais pourrait être intéressante pour future recherche sur la retrieval des informations juridiques ou la classification des textes."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Examinons quelques caractéristiques de notre ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "La question est entre cinq et quarante quatre mots long, avec une médiane de quarante words."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont beaucoup plus longs, avec une longueur médiane de soixante sept mots, avec une longueur de cent quarante grammes."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "deux d'entre eux exceivant un million."}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "Comme mentionné précédemment, la question couvre un large éventail de sujets, avec environ quatre-vingt-quinze pour cent d'entre eux concernant la famille, le logement, l'argent ou la justice."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que les quinze pour cent restants concernent soit la sécurité sociale, les étrangers ou le travail."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers, as ils proviennent de trente deux différents codes belges qui couvrent un large nombre de topics."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles collectés de chaque code belge."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Out de les vingt deux mille six cent trente trois articles, seulement un mille six cent douze sont referrés à as relevant à atteindre le point."}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "une question dans les données. Et environ quatre-vingts pour cent de ces articles cités proviennent de la Civil Code, de la Code judiciaire, de la Code d'investigation pénale ou de la Code pénale."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant ce temps, dix-huit codes sur trente-deux contiennent moins de cinq articles mentionnés comme étant pertinents à au moins une question."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Ce qui peut être expliqué par le fait que ces codes se concentrent moins sur les individus et leurs préoccupations."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "Overall, le médian de citation pour ces cités articles est deux, et moins de vingt cinq pour cent d'entre eux sont des"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos datasets, nous avons testé plusieurs approches de récupération, notamment la lexical et l'architecture dense."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "Si une requête est donnée dans un article, un modèle lexical attribue une note à la paire article requête en calculant la somme des poids de chacun de ces termes dans cet article sur les termes de requête."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec les fonctions de classement standard TFIDF et BM twenty five."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le principal problème avec ces approches est qu'elles ne peuvent récupérer que des articles contenant des mots-clés présents dans la requête."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons une architecture basée sur des neurones qui peut capturer la relation sémantique entre les requêtes et les articles."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle BEAncoder qui mape des requêtes et des articles en représentations vectorielles denses et calcule un score pertinent entre une paire d'articles de requête en fonction de la similitude de leurs embeddings."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces embeddings sont généralement le résultat d'une opération de pooling sur la sortie d'un modèle d'embedding de mots."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous étudions l'efficacité des biancodeurs siamés dans un système d'évaluation à zéro tir, ce qui signifie que les modèles d'embellage pré-trainwood sont appliqués hors de la boîte sans aucune réglage supplémentaire."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec des encodeurs de texte indépendants du contexte, à savoir Word2Vec et FastText, et des modèles d'intégration dépendants du contexte, à savoir Roberta et plus précisément Camembert, qui est un modèle français Roberta."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous traînons notre propre modèle Camembert basé sur le modèle."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "sur tous les sets de données. Notez que pour la formation, nous expérimentons les deux flavors de l'architecture Bianco."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamese, qui utilise un modèle de word embedding unique qui mappe la query et l'article ensemble dans un espace vectoriel dense partagé, et Tutor, qui utilise deux modèles de word embedding indépendants qui encodent la query et l'article séparément dans deux spaces de embedding différents."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec le pooling de moyenne, de maximum et de CLS, ainsi que le produit scalaire et le cosinus pour les similitudes informatiques."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre ligne de base sur les ensembles de test."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "Avec les méthodes lexicales ci-dessus, les encodeurs B siamés évalués dans un ensemble de tirs zéro au milieu, et les encodeurs B finement ajustés ci-dessous."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, les cores Biancore bien ajustées surpassent de manière significative toutes les autres lignes de basse."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de deux tours s'améliore par rapport à sa variante siamese sur Recallat one hundred, mais se comporte de manière similaire sur les autres indicateurs."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que BM vingt cinq ait sous-performé de manière significative au train Biancode, ses performances indiquent qu'il reste une solide base pour le retrieu spécifique du domaine."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "Concernant l'évaluation Zero Shot du Biancodeur siaméen, nous constatons que l'utilisation directe des embeddings d'un modèle Kamembert préentraîné sans optimiser la tâche de récupération d'informations donne de mauvais résultats, ce qui est conforme aux conclusions précédentes."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous avons constaté que le Biancodeur basé sur WordTuvec a considérablement surpassé le modèle basé sur Vastex et Bird, ce qui suggère que peut-être les embeddings au niveau de la parole pré-entraînée sont plus appropriés pour cette tâche que les embeddings au niveau de caractère ou au niveau de sous-ord lorsqu'ils sont utilisés dès le départ."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que prometteurs, ces résultats suggèrent de nombreuses possibilités d'amélioration par rapport à un expert juridique qualifié qui peut éventuellement récupérer tous les articles pertinents à n'importe quelle question et ainsi obtenir des scores parfaits."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Concluons en discutant de deux limitations de tous les ensembles de données."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, le corpus des articles est limité à ceux recueillis des trente-deux codes belges considérés, qui ne couvrent pas l'ensemble de la loi belge, car les articles des décrets, des directives et des ordonnances manquent."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Lors de la construction du dataset, toutes les références à ces articles non collectés sont ignorées, ce qui cause une question de finir avec une fraction de leur nombre initial d'articles pertinents."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'informations implique que la réponse contenue dans les articles restants pertinents pourrait être incomplète, bien qu'elle soit toujours complètement appropriée."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, il convient de noter que toutes les questions juridiques ne peuvent être répondues que par des statuts."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question : Puis-je expulser mes locataires s'ils font trop de bruit?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "Il ne peut pas avoir une réponse détaillée dans la loi statutique qui quantifie un seuil de bruit spécifique auquel l'expulsion est autorisée."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, le propriétaire devrait probablement se fier davantage à la jurisprudence et trouver des précédents similaires à leur situation actuelle."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le tenant fait deux parties par week jusqu'à deux heures."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, certaines questions sont mieux adaptées que d'autres à la tâche de récupération d'articles statutaires, et le domaine des moins appropriées restera à être déterminé."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que tout ce travail suscite l'intérêt pour le développement de modèles de récupération d'articles statutaires pratiques et fiables,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut aider à améliorer l'accès à la justice pour tous."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre papier, DATSET et CODE à l'environnement. Merci."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, nous sommes heureux de présenter notre travail sur Vowls, un benchmark indépendant de tâches destiné à tester des modèles de vision et de langage avec des phénomènes linguistiques spécifiques."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi avons-nous fait le travail de mettre en place ce point de référence?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Eh bien, au cours des dernières années, nous avons vu une explosion de modèles de vision et de langage basés sur des transformateurs pré-entraînés sur de grandes quantités de paires d'images texte."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chacun de ces modèles pousse les tâches de pointe sur la vision et le langage telles que la réponse aux questions visuelles, la raison de bon sens visuel, la récupération d'images, la fondation des phrases."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc reçu un message. Les précisions de ces références spécifiques à la tâche augmentent régulièrement."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous ce que les modèles ont réellement appris?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce qu'un transformateur de vision et de langage a compris en attribuant un score élevé à cette image et à cette phrase pour correspondre?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "Et le score le plus bas pour celui-ci."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur la bonne chose?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Ou se concentrent-ils sur les préjugés, comme le montrent les travaux précédents?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour éclairer davantage cet aspect, nous proposons une direction plus indépendante des tâches et introduisons des valves qui testent la sensibilité des modèles visuels et de langage à des phénomènes linguistiques spécifiques qui affectent à la fois les modalités linguistiques et visuelles."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous visons l'existence, la pluralité, le comptage, les relations spatiales, les actions et la co-référence d'entité."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment vérifier si les modèles de vision et de langage ont capturé ces phénomènes?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "par le foiling, une méthode précédemment appliquée pour les modèles de vision et de langue, seulement pour les phrases nominales par Ravi Shakar et ses collaborateurs, et sur le comptage par nous dans le travail précédent."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Le foiling signifie essentiellement que nous prenons la légende d'une image et produisons un foil en modifiant la légende de telle sorte qu'elle ne décrit plus l'image."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "Nous apportons ces modifications de phrases en nous concentrant sur six éléments spécifiques tels que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la co-référence d'entités, où chaque élément peut être composé d'un ou plusieurs instruments, au cas où nous aurions trouvé plus d'une façon intéressante de créer des instances de FOIL."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas de la pièce des actions, nous avons deux instruments, l'un dans lequel le verbe d'action est changé avec une action différente et l'autre dans lequel les actants sont échangés."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la co-référence sont également des pièces qui ont plus d'un instrument."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous créons ces défauts en veillant à ce qu'ils ne décrivent pas l'image, qu'ils soient des phrases grammaticales et autres valides."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas facile à faire car une légende défectueuse peut être moins probable que la légende originale."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien que ce ne soit pas impossible, statistiquement, il est moins probable que des plantes coupent un homme qu'un homme coupent des plantes, et les modèles de grande vision et de langage pourraient le détecter."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des feuilles valides, nous devons agir."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, nous utilisons des modèles de langage solides pour proposer des FOILS."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons l'inférence du langage naturel ou NLI pour filtrer les feuilles qui pourraient encore décrire l'image, car lorsque nous construisons des feuilles, nous devons nous assurer qu'elles ne décrivent pas l'image."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester cela automatiquement, nous appliquons l'inférence du langage naturel avec la logique suivante."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons une image comme la prémisse et son titre comme l'hypothèse implicite."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "En addition, nous considérons que la caption est la premisse et que le foil est sa hypothèse."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit que le FOIL contredit ou est neutre par rapport à la légende, nous considérons cela comme un indicateur d'un FOIL valide."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si une NLI prédit que la feuille de surface est impliquée par la légende, elle ne peut pas être une bonne feuille de surface, car elle donnera une description fidèle de l'image par transitivité et nous filtrons ces feuilles."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette procédure n'est pas parfaite. Elle est juste une indication pour validifier."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, en tant que troisième mesure pour générer des foils valides, nous utilisons des annotateurs humains pour valider les données utilisées dans les valves."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, après le filtrage et l'évaluation humaine, nous avons autant d'instances de test que décrit dans ce tableau."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que VALS ne fournit aucune donnée d'entraînement, mais seulement des données de test."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "Puisqu'il s'agit uniquement d'un benchmark de test de tir zéro, il est conçu pour tirer parti des capacités existantes des modèles de vision et de langage après la pré-entraînement."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "Le réglage précis ne permettrait que des modèles d'exploiter des artefacts ou des biais statistiques dans les données."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme nous l'avons dit, nous sommes intéressés par l'évaluation des capacités des modèles de vision et de langage après la pré-entraînement."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons cinq modèles de vision et de langage sur les voyelles, à savoir CLIP, AlexMert, Wilbert, Wilbert Kelvin I et VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos métriques d'évaluation les plus importantes sont l'exactitude des modèles pour classer les paires de phrases d'images en titres et en foils."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "Plus pertinente pour cette vidéo, nous présenterons notre métrique plus permissive, l'exactitude par paires, qui mesure si le score d'alignement de la phrase d'image est supérieur pour la paire de texte d'image correcte que pour sa paire de FOIL."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "Pour plus de métriques et de résultats à leur sujet, consultez notre article"}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats avec une précision par paires sont présentés ici et sont cohérents avec les résultats que nous avons obtenus des autres métriques. Le meilleur résultat de tirs à zéro est obtenu par Wilbert douze en un, suivi de Wilbert, Alex Mert, Clip et enfin VisualBird."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est remarquable de noter que les instruments centrés sur des objets individuels comme l'existence et les phrases nominales sont presque résolus par Wilbert douze en un, soulignant que les modèles sont capables d'identifier les objets nommés et leur présence dans les images."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos réglages de foiling adversaire."}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "Nous constatons, grâce à la pluralité des instruments de comptage, que les modèles visuels et linguistiques ont du mal à distinguer les références à des objets individuels par rapport à plusieurs objets ou à les compter dans une image."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "La relation P montre qu'ils ont des difficultés à classer correctement une relation spatiale nommée entre les objets dans une image,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont également du mal à distinguer les actions et à identifier leurs participants, même si elles sont étayées par des préjugés de plausibilité, comme nous le voyons dans la partie sur les actions."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la partie de la co-référence, nous constatons que le fait de retracer plusieurs références au même objet dans une image en utilisant des pronoms est également difficile pour les modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "En guise de vérification de la santé mentale et parce que c'est une expérience intéressante, nous avons également testé deux modèles de texte seulement, GPT un et GPT deux, pour évaluer si Valve est résolu par ces modèles unimodaux en calculant la perplexité de la légende correcte et défaillante, sans image ici, et en prédisant l'entrée avec la plus faible perplexité."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "Si la perplexité est plus élevée pour le FOIL, nous considérons cela comme un signe que la légende FOIL peut souffrir d'un biais de plausibilité ou d'autres biais linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et il est intéressant de voir que dans certains cas, les modèles GPT de texte ont capturé la plausibilité du monde mieux que les modèles vision et language."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "En résumé, VALS est un référencement qui utilise le prisme des constructions linguistiques pour aider la communauté à améliorer les modèles visuels et linguistiques en testant rigoureusement leurs capacités de fondation visuelle."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que les modèles visuels et de langage identifient bien les objets nommés et leur présence dans les images, comme le montre l'existence, mais ont du mal à établir leur interdépendance et leurs relations dans les scènes visuelles lorsqu'ils sont contraints de respecter les indicateurs linguistiques."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions vraiment encourager la communauté à utiliser Vals pour mesurer les progrès vers la base linguistique avec des modèles de vision et de langage."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "Et, de plus, Valve pourrait être utilisé comme évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après l'entraînement ou le finissement pour voir si un ensemble de données aide les modèles à améliorer l'un des aspects testés par Valve."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si cela vous intéresse, consultez les données de Vault sur GitHub et si vous avez des questions, n'hésitez pas à nous contacter."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Kamisara, de l'université de Tokyo."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter un papier entitled RNSAM, un large scale de la set pour automatique risque de duration de la comitologie."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais expliquer dans cet ordre."}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais vous présenter la génération automatique de risques sur laquelle nous travaillons dans cette recherche."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "ReleaseNote est un document technique qui résume les modifications apportées à chaque version d'un produit logiciel."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "L'image montre les notes de risque pour Bosch deux point six."}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Usage S library. Ces notes prennent un important rôle en open source développement, mais elles sont consommées à préparer manuellement."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Il serait donc très utile de pouvoir générer automatiquement des notes de libération de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais faire référence à deux recherches précédentes sur la génération automatique de fissures."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé Arena, produit en 2014."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il prend une approche basée sur les rules, par exemple, en utilisant le changer extracteur pour extraire les différences, les changements de librerie et les changements de documents des différences entre les releases, et finalement en combinant les différences."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus notable de ce système est l'extracteur de l'émission dans le coin supérieur droit,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "Il doit être lié à zéro pour évaluer l'écosystème et ne peut être appliqué qu'aux projets qui utilisent zéro."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "ensemble. En d'autres termes, il ne peut pas être utilisé pour de nombreux projets sur GitHub."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "Le second est Grief. Il est annoncé en vingt minutes."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "2020. Il est disponible sur Internet et peut être stocké via PIP."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système dispose d'un modèle de classification de texte simple basé sur le rangement et de sorties formant cinq graphiques telles que des fonctionnalités ou des corrections d'erreurs pour chaque message de comité d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est un échantillon utilisé qui retient un échantillon de correction ou de correction des erreurs."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données de training de Graves sont relativement faibles, environ cinq mille, et seront présentées dans les expériences décrites ci-dessous."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "La performance du modèle de classification statistique n'est pas élevée."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il y a des problèmes de limitées applicabilités et de scarce ressources de données."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des notes de libération de haute qualité."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le programme d'applicabilité limitée, nous proposons une méthode de résumé classifié de haute qualité en utilisant uniquement le message de comité comme input."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour tous les dépôts en anglais."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le deuxième problème de ressources scarces, nous avons construit un RNSAMDSET consistant de quatre-vingt-deux mille pièces de données en collectant des données provenant de réponses publiques GitHub utilisant l'API GitHub."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je décris notre décès."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de données."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche est le message du comité et le côté droit est la note de liquidation."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de la liste sont louables comme des améliorations, des officiels, etc."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons configuré une tâche qui prend les messages du comité en entrée et sort les notes de plaisance révélées."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de résumé."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédefinie quatre éléments de fonctionnalité, amélioration, correction des erreurs, suppression, suppression et modification des freins."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces données étaient basées sur des recherches antérieures et d'autres facteurs."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "Les notes de release en bas à droite sont extraites des notes de release en bas à gauche."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce moment-là, il est nécessaire de détecter les quatre débris qui ont été installés à l'avance."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "mais les livres ne sont pas toujours cohérents avec chaque liberté,"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, les moteurs d'amélioration de la taille augmentent les améliorations, les améliorations, les optimisations, etc."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste vocabulaire d'environ trente numéros pour chacune de ces variations notationnelles."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez le texte de la race note crusque et correct le texte de la race note crusque."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, il y a un message de comité."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages du comité ne sont pas liés à chaque voix."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme on le voit dans l'image below, si le current risque est deux point cinq deux neuf, nous devons identifier"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "modifie la version de la version précédente et obtient un diff. C'est un peu tedious et il ne suffit pas de simplement obtenir une liste de versions et de regarder les versions avant et après."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Il a créé une heuristique correspondant à vous pour obtenir les concours précédents et suivants."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Dès que le hors de la rue s'est arrêté."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "En fin de compte, sept mille deux cents repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, le nombre moyen de jetons de produits n'est pas de soixante-trois, ce qui est assez élevé pour une tâche de résolution."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "L'autre, le nombre de tokens uniques est très large à huit mille huit cent trente mille."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "due au large nombre de classe et de méthodes n'auront été trouvées dans le répertoire."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je vais expliquer la méthode proposée."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé transversal, extractif et abstractif est composé de deux modules neuronaux"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "un classificateur utilisant BOT ou un code BOT et un générateur utilisant BOT."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, GEAS utilise un classificateur pour classer chaque message de comité en cinq classes de notes de recherche : fonctionnalités, améliorations, corrections d'erreurs, duplications, plus et autres."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages du comité classés comme autres sont rejetés."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, GAS applique le générateur indépendamment aux quatre documents de routeur et génère un nœud de risque pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages de commit et les notes de lecture ne sont pas connues."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour entraîner le classificateur, nous attribuons des pseudobus à chaque message de commande d'entrée en utilisant les dix premiers caractères de chaque message de commande."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons l'approche de la somme d'obstruction transversale par deux méthodes différentes."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier module, que nous appelons GIS Single, est composé d'un seul réseau SECT et génère un seul texte long, donnant un potentiel de messages de commutation d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Le texte de sortie peut être divisé en segments croisés en fonction de symboles de point de fin spécifiques de la croix."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La deuxième méthode, que nous appelons CSMarch, se compose de quatre réseaux sec-to-sec différents, chacun correspondant à l'une des classes de nœuds de la liste."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "D'accord, ça fait l'expérience de Span."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été comparées : CAS, CAS unique, CAS intelligent, Rosselling et le résumé de l'étude précédente."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'ablation, dans certains cas, ces notes sont produites en multiples sentences."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Puisqu'il est difficile de calculer le nombre de phrases à zéro, elles sont combinées avec des espaces et traitées comme une seule phrase longue."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "Le bureau est pénaire lorsque le système produit une brève phrase"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité entraîne une baisse du volume de la boisson dans les résultats expérimentaux décrits en suivant."}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous corroguons également la spécificité car le rouge et le bleu ne peuvent pas être corrogués si les notes de RISE sont vides."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une spécificité élevée signifie que les outputs de la propriété modèle sont emptis, tactis, dans les cas où les résultats sont assumés emptis."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Puisque le dataset contient des adresses d'email, des barrières, etc, nous avons également élargi le client dataset, qui exclut les"}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a atteint des scores de l'air de Rouge de plus de dix points supérieurs aux lignes de base."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur le Green test, le score gap entre la proposée méthode et la base en jumped à plus de vingt points."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent qu'elle est et qu'elle est significativement efficace."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "GAS a obtenu un meilleur score de Rouge FS que GAS, suggérant que combiner un classifier et un générateur est efficace sur la formation du classifier en utilisant des pseudo-régaux."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "La coverage de la GAS peut être atteinte probablement parce que le classifier peut se concentrer sur la sélection de messages de commande pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a tendance à manger plus souvent que lorsqu'elle est célibataire."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "suggérant qu'il est également efficace de développer de manière indépendante différents modèles de résumé de votre perspective pour chaque classe de nœud."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "Héroïne et Eronas."}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes Xi's ont tendance à produire des phrases plus courtes que les phrases de référence humaines."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure sur la droite, la différence de la sentence a trois ou quatre sentences, while SUS a seulement un."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette réticence modèle est que dans les données d'entraînement, seulement 33 % des phrases sont présentes dans le ruban des caractéristiques et 40 % dans le ruban des améliorations."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, les méthodes de CES ne peuvent pas générer de nœuds de risque précis sans des informations supplémentaires."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple en haut sur la droite est un exemple de message très messie, et la phrase complète ne peut pas être générée sans référence à la requête ou à l'issue correspondante."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous montre que les deux messages de comité dans l'entrée sont liés et devraient être combinés en une seule phrase, mais cela ne le fait pas."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, une conclusion."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons créé un nouveau jeu de données pour la génération automatique de pisteaux,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également formé la tâche d'entrer les messages de commande et de les résumer de manière à ce qu'ils s'appliquent à tous les projets écrits en anglais."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences montrent que la méthode proposée générée par le basso n'est pas à une couverture plus élevée que les bassoirs."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez consulter notre application de tests de réserve."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour, je m'appelle Safarari,"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter notre article, Few Short Tabular Data Enrichment Using Fine Tuning Transformers Architectures."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Les scientifiques des données analysent les données et se concentrent principalement sur la manipulation des caractéristiques existantes des données."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "Mais parfois, ses caractéristiques sont limitées."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération de fonctionnalités à l'aide d'une autre source de données peut ajouter des informations importantes."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique des données tabulaires à l'aide de textes libres d'origine externe."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons que nous disposions d'un ensemble de données tabulaire et d'une base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique qui implique le lien entre entités et l'analyse de texte pour extraire de nouvelles caractéristiques du texte libre de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre cadre est exactement ce processus automatique."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Prenons un exemple. Dans les ensembles de données, ils sont introduits dans FAST."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données est un ensemble de données universitaires."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque son objectif est de classer les universités en universités à faible classement et universités à haut classement."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que base de connaissances, nous utilisons Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase de FEST est la liaison d'entités."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque chaque entité, dans cet exemple, le nom de l'université est lié à une entité au sein de la base de connaissances."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "et le texte des entités de la base de connaissances est extrait et ajouté au dataset."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est l'abstract de la page Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Maintenant, nous devons générer ou extraire des caractéristiques du texte récupéré."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons donc besoin d'une phase d'extraction de caractéristiques qui comprend l'analyse du texte."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est la principale nouveauté de cet article, et je vais y approfondir dans les prochaines diapositives."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction des caractéristiques, il y a une phase de génération de caractéristiques, lorsque nous utilisons les caractéristiques extraites pour générer un petit nombre de nouvelles caractéristiques."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, générez des caractéristiques dans le nombre de classes du jeu de données original."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, l'ensemble de données d'origine comporte deux classes"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, générez deux nouvelles fonctionnalités."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si l'ensemble de données comporte cinq classes, générez d'abord cinq nouvelles fonctionnalités."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état actuel de l'analyse du texte, qui est un modèle de langage basé sur des transformateurs, comme Baird, GPT, XNET, etc."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "Mais il est peu probable que nous puissions entraîner un modèle de langue à l'aide des ensembles de données d'entrée."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Une approche naïve consistera donc à affiner la tâche cible."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, dans la phase d'extraction de caractéristiques, nous pouvons télécharger le modèle de langue parentraîné, affiner le modèle de langue sur le jeu de données cible."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, pour affiner le modèle de langue, classifier le texte en classes, l'abstract en classes, bas ou haut."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "Recevez la sortie du modèle de langue, qui est la probabilité pour chaque classe, et utilisez-la comme nouvelles fonctionnalités."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que les ensembles de données peuvent avoir peu d'entités distinctes."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, près de la moitié des ensembles de données contiennent moins de quatre cents échantillons et le plus petit ensemble de données contient trente-cinq échantillons dans son ensemble d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, affiner un modèle de langue sur cet ensemble de données sera inefficace."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous pouvons utiliser des connaissances préalables sur les ensembles de données préanalysées."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Puisque nous appliquons le FAST sur plusieurs ensembles de données, nous pouvons utiliser les ensembles de données n pour recueillir des informations sur les ensembles de données n et utiliser ces informations lorsque nous analysons l'ens dataset."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce que nous suggérons? Tout d'abord, une autre phase de fine-tuning."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "une phase de finition préliminaire multitask."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "Lorsque vous trouvez le modèle de langue sur n moins un ensemble de données,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous exécutons une autre phase de finesse, qui est une finesse des tâches cibles lorsque nous finissons le modèle de langue sur le ensemble de données cible n."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "Le réglage à la dernière minute en matière de multitâche appelé MTDNN."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "Dans le DNN vide, le DNN vide maintient un nombre de têtes dans le nombre de tâches dans le jeu d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, il y a donc quatre tâches dans le jeu d'entraînement. Donc, le DNN vide et le maintien de quatre têtes, comme vous pouvez le voir sur l'image."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "Et il échantillonne un lot aléatoire du jeu d'entraînement."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot de rendez-vous appartient à, par exemple, des tâches de classification de Sing et Selton, il exécute des passages en avant et en arrière à travers la première tête."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le lot aléatoire appartient à une tâche de classement paires, il est autorisé à passer en arrière et en arrière à travers la dernière tête."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, une tableau de données verifie le nombre de classes."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Il y a donc de nombreuses tâches."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "Le DNN vide maintient le nombre de têtes de classes, couches de sortie."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, MTDNN doit initialiser de nouvelles têtes pour un nouveau ensemble de données avec une nouvelle tâche."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Notre approche appelée réglage de la réformulation des tâches consiste à réformuler chaque ensemble de données en une phrase par problème de classification, qui est composée de deux classes de tâches."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons donc un exemple."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre ensemble de données d'entrée qui consiste en entités, caractéristiques, texte et classes."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "Nous reformulons la tâche de classer le texte en bas et haut pour classer le texte, l'abstract et la classe en vrai ou faux."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous avons formé le modèle de langage pour classer les abstracts et les classes, pour voir si les abstracts appartiennent à la classe ou non."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Ainsi, le vecteur étiquette, dans ce cas, reste toujours composé de deux classes."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et voici l'algorithme de notre approche de réglage précis formulée."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Voyons donc le cadre complet."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "et dataset fade into fast."}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "puis une phase de liaison d'entité exécutive rapide."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "Il extrait le texte de la base de connaissances, qui dans cet exemple est l'abstracte de la page Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "puis il réformulait la tâche en une tâche de classification de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de période de péri"}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "appliquez le modèle de langue à la nouvelle tâche et à la probabilité de sortie pour chaque classe."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que le modèle de langue est déjà ajusté sur un ensemble de données n-1 en utilisant un ajustement préliminaire multitask."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons ensuite le vecteur de sortie du modèle de langue comme caractéristique nouvellement générée dans le nombre de classes."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification tabulaire de dix-sept, qui varie en taille, caractéristiques, équilibre, domaine et performance initiale."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme base de connaissances, nous utilisons Wikipédia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation de laissée de côté, lorsque nous entraînons rapidement sur seize ensembles de données et les appliquons au dix-septième ensemble de données."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "Nous divisons également chaque ensemble de données en quatre fausses et appliquons une validation croisée des fausses."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous générons la nouvelle fonctionnalité et l'évaluons à l'aide de cinq classificateurs d'évaluation."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons une architecture basée sur la construction dans notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez voir que nous comparons notre cadre à la fine-tuning du jeu de données cible, la fine-tuning des tâches cible et la fine-tuning préliminaire du DNN vide."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "Et notre formulation a été très utile pour obtenir le meilleur résultat, la meilleure performance."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "tandis que MTDN a réalisé une amélioration de 2 % par rapport à la fine réglage du jeu de données cible."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "Notre poche a réalisé une amélioration de six pour cent."}
