{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle. Heute werde ich unsere Forschungsarbeit Lernen zu reisen deduktiv, Methodenproblemlösung als komplexe Rasen-Extraktion vorstellen.", "metrics": {"bleu_score": 23.40531991799294, "chrf_score": 51.50284416884564, "xcomet_score": 0.6749078631401062, "xcomet_qe_score": 0.6301181316375732, "metricx_score": 15.96241569519043, "metricx_qe_score": 17.772624969482422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD.", "metrics": {"bleu_score": 46.67769522668045, "chrf_score": 69.16680839988824, "xcomet_score": 0.5411026477813721, "xcomet_qe_score": 0.5387531518936157, "metricx_score": 10.58348274230957, "metricx_qe_score": 10.611810684204102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen.", "metrics": {"bleu_score": 74.19446627365011, "chrf_score": 80.89316601602657, "xcomet_score": 0.9814042448997498, "xcomet_qe_score": 0.9854676723480225, "metricx_score": 1.536429524421692, "metricx_qe_score": 0.7237764596939087, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist.", "metrics": {"bleu_score": 16.21599014882373, "chrf_score": 55.986797401068664, "xcomet_score": 0.986242949962616, "xcomet_qe_score": 0.9959239959716797, "metricx_score": 0.2947690188884735, "metricx_qe_score": 0.27105236053466797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Zahl stammt aus dem POWN-Papier, in dem sie Anweisungen zur Lösung des Methodenproblems in einem Fluch-Learning-Szenario ausführen.", "metrics": {"bleu_score": 18.38063849674274, "chrf_score": 43.90060961732117, "xcomet_score": 0.5106722116470337, "xcomet_qe_score": 0.5772057771682739, "metricx_score": 9.476139068603516, "metricx_qe_score": 8.310115814208984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite können wir sehen, dass wir, wenn wir einige Beispiele nur mit Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten.", "metrics": {"bleu_score": 13.521024592529315, "chrf_score": 62.018411537696785, "xcomet_score": 0.9534322619438171, "xcomet_qe_score": 0.9441317319869995, "metricx_score": 0.8523635864257812, "metricx_qe_score": 0.6585074663162231, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch noch mehr Beschreibungen geben, kann das Modell die Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen.", "metrics": {"bleu_score": 11.988116174987852, "chrf_score": 50.89092891573581, "xcomet_score": 0.9636056423187256, "xcomet_qe_score": 0.9880129098892212, "metricx_score": 1.0449776649475098, "metricx_qe_score": 1.3012950420379639, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, als Ausgabe interpretierbares Mehrstufenrechnungsverfahren zu haben.", "metrics": {"bleu_score": 36.964463979752836, "chrf_score": 52.70647644049301, "xcomet_score": 0.9294009208679199, "xcomet_qe_score": 0.9881535768508911, "metricx_score": 2.5026116371154785, "metricx_qe_score": 1.1355204582214355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken auch, dass ein Methodenproblem eine einfache Anwendung zur Bewertung solcher Argumentationsfähigkeiten ist.", "metrics": {"bleu_score": 28.572802657788227, "chrf_score": 66.06564069017516, "xcomet_score": 0.895656943321228, "xcomet_qe_score": 0.8913193345069885, "metricx_score": 4.4041748046875, "metricx_qe_score": 3.9236092567443848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier müssen wir also in unserer Problemkonfiguration, angesichts der Fragen, diese Frage lösen und die numerischen Antworten erhalten.", "metrics": {"bleu_score": 51.0032342952127, "chrf_score": 80.56739218545277, "xcomet_score": 0.9767025709152222, "xcomet_qe_score": 0.9492864012718201, "metricx_score": 1.8035794496536255, "metricx_qe_score": 1.8432435989379883, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser besonderen Antwort führt.", "metrics": {"bleu_score": 17.01668259220275, "chrf_score": 67.45407045898762, "xcomet_score": 0.9646607637405396, "xcomet_qe_score": 0.9651163816452026, "metricx_score": 2.0401761531829834, "metricx_qe_score": 3.1308774948120117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten.", "metrics": {"bleu_score": 55.70438815301074, "chrf_score": 77.83370476158633, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.9207534193992615, "metricx_qe_score": 1.0926321744918823, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Größen bekannt ist", "metrics": {"bleu_score": 70.76618839098694, "chrf_score": 85.92033113996305, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.15982186794281, "metricx_qe_score": 0.5769716501235962, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential.", "metrics": {"bleu_score": 88.43946454355333, "chrf_score": 93.2282436226332, "xcomet_score": 0.9847314357757568, "xcomet_qe_score": 0.9869264364242554, "metricx_score": 0.6797162294387817, "metricx_qe_score": 1.0274807214736938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren aufgeteilt werden.", "metrics": {"bleu_score": 37.06866381788036, "chrf_score": 73.07077390524638, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4693734049797058, "metricx_qe_score": 0.4419320225715637, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Eine frühere Arbeit im Lösungsproblem der Methode kann also tatsächlich in Sequenz- und Baummodell kategorisiert werden.", "metrics": {"bleu_score": 3.2342452920962157, "chrf_score": 33.987540456465446, "xcomet_score": 0.8216445446014404, "xcomet_qe_score": 0.819953441619873, "metricx_score": 5.785401344299316, "metricx_qe_score": 6.132246494293213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenzmodelle konvertieren den Ausdruck also in eine bestimmte Sequenz für die Generierung.", "metrics": {"bleu_score": 22.0189498013509, "chrf_score": 56.87161044420888, "xcomet_score": 0.9755889177322388, "xcomet_qe_score": 0.9637478590011597, "metricx_score": 0.8348733186721802, "metricx_qe_score": 1.2119022607803345, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ziemlich einfach umzusetzen und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden.", "metrics": {"bleu_score": 57.11023016171072, "chrf_score": 80.5297488996929, "xcomet_score": 0.9988404512405396, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.08073097467422485, "metricx_qe_score": 0.107516810297966, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil ist, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell und es fehlt an Interpretabilität für die Vorhersage.", "metrics": {"bleu_score": 37.26650196278939, "chrf_score": 58.31213596050291, "xcomet_score": 0.9708361625671387, "xcomet_qe_score": 0.9908900260925293, "metricx_score": 0.6578744053840637, "metricx_qe_score": 0.9093519449234009, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Direction noch ziemlich populär, weil der Transformermodell", "metrics": {"bleu_score": 20.624574461560556, "chrf_score": 53.992028866375605, "xcomet_score": 0.806096076965332, "xcomet_qe_score": 0.8195706605911255, "metricx_score": 7.317325592041016, "metricx_qe_score": 7.276336669921875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen.", "metrics": {"bleu_score": 43.819512537676886, "chrf_score": 82.88444955587553, "xcomet_score": 0.8944991827011108, "xcomet_qe_score": 0.8668993711471558, "metricx_score": 2.8597841262817383, "metricx_qe_score": 2.081411600112915, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also die Operatoren weiter, bis wir die Lifts erreichen, die die Größen sind.", "metrics": {"bleu_score": 27.21737536178887, "chrf_score": 54.586980205133784, "xcomet_score": 0.8050793409347534, "xcomet_qe_score": 0.7877659797668457, "metricx_score": 7.458070755004883, "metricx_qe_score": 9.091975212097168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt, aber es ist eigentlich ganz entgegengesetzt, weil wir zuerst den Operator generieren und dann am Ende die Größen generieren.", "metrics": {"bleu_score": 34.36622031501779, "chrf_score": 61.185187196902326, "xcomet_score": 0.867566704750061, "xcomet_qe_score": 0.8362190127372742, "metricx_score": 3.4656574726104736, "metricx_qe_score": 3.8825018405914307, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens enthält es auch einige wiederholte Berechnungen.", "metrics": {"bleu_score": 14.575161396875705, "chrf_score": 60.739866159705095, "xcomet_score": 0.925826907157898, "xcomet_qe_score": 0.9381299614906311, "metricx_score": 0.5349371433258057, "metricx_qe_score": 0.36274242401123047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck hier ansehen, wird acht mal drei plus drei tatsächlich zweimal erzeugt. Aber tatsächlich sollten wir die Ergebnisse verwenden", "metrics": {"bleu_score": 32.892676518285576, "chrf_score": 64.13343767400616, "xcomet_score": 0.9595848321914673, "xcomet_qe_score": 0.9484028816223145, "metricx_score": 1.093297004699707, "metricx_qe_score": 0.929481029510498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und in interpretierbaren Methoden lösen.", "metrics": {"bleu_score": 22.250253290431033, "chrf_score": 65.72073177151024, "xcomet_score": 0.9883997440338135, "xcomet_qe_score": 0.9900038242340088, "metricx_score": 0.9685032367706299, "metricx_qe_score": 0.7371940016746521, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diesen Teiler erhalten, der 27 ist.", "metrics": {"bleu_score": 21.81916573942327, "chrf_score": 71.83284320965679, "xcomet_score": 0.871004581451416, "xcomet_qe_score": 0.9110492467880249, "metricx_score": 0.8599472641944885, "metricx_qe_score": 1.1113450527191162, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden.", "metrics": {"bleu_score": 68.65065103648593, "chrf_score": 90.5122326795875, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.1980559229850769, "metricx_qe_score": 0.23076917231082916, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler.", "metrics": {"bleu_score": 72.59795291154772, "chrf_score": 95.55813636296386, "xcomet_score": 0.9975470304489136, "xcomet_qe_score": 0.9964474439620972, "metricx_score": 0.46138083934783936, "metricx_qe_score": 1.0272918939590454, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir bei diesem dritten Schritt tatsächlich den Quotienten.", "metrics": {"bleu_score": 25.470553981698203, "chrf_score": 74.44156883194914, "xcomet_score": 0.9878969192504883, "xcomet_qe_score": 0.979393482208252, "metricx_score": 1.0448079109191895, "metricx_qe_score": 1.5607749223709106, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Okay. Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schritts tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten.", "metrics": {"bleu_score": 55.83294517400156, "chrf_score": 88.53870352243992, "xcomet_score": 0.9911160469055176, "xcomet_qe_score": 0.9930182695388794, "metricx_score": 1.1032804250717163, "metricx_qe_score": 1.6527013778686523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren.", "metrics": {"bleu_score": 5.653041175801492, "chrf_score": 50.460870459718436, "xcomet_score": 0.996963620185852, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7588018178939819, "metricx_qe_score": 0.7142263650894165, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird der Prozess genauer.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9916499853134155, "xcomet_qe_score": 0.9766815900802612, "metricx_score": 0.29923000931739807, "metricx_qe_score": 0.5827406048774719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als unser Anfangszustand ein.", "metrics": {"bleu_score": 53.707566707346565, "chrf_score": 78.02209504410507, "xcomet_score": 0.9492254853248596, "xcomet_qe_score": 0.9496089220046997, "metricx_score": 1.58820378780365, "metricx_qe_score": 1.997148871421814, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt.", "metrics": {"bleu_score": 36.06452879987793, "chrf_score": 80.28357106983552, "xcomet_score": 0.9844173192977905, "xcomet_qe_score": 0.9895853400230408, "metricx_score": 1.127659559249878, "metricx_qe_score": 2.294699192047119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Operatoren von QY bis QJ aus, und dieser Ausdruck ist tatsächlich gerichtet.", "metrics": {"bleu_score": 31.70242597818534, "chrf_score": 70.15043774946675, "xcomet_score": 0.8271743059158325, "xcomet_qe_score": 0.8645950555801392, "metricx_score": 4.7750396728515625, "metricx_qe_score": 4.452342987060547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "So, wir haben hier auch Subtraction-Wert, um die entgegengesetzte Richtung zu repräsentieren.", "metrics": {"bleu_score": 12.94214832447352, "chrf_score": 40.657942836534474, "xcomet_score": 0.8560657501220703, "xcomet_qe_score": 0.9038268327713013, "metricx_score": 6.27510929107666, "metricx_qe_score": 6.402536392211914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie bei der Strahlungsauffnahme.", "metrics": {"bleu_score": 6.742555929751843, "chrf_score": 30.034831342083802, "xcomet_score": 0.8088911771774292, "xcomet_qe_score": 0.8095588684082031, "metricx_score": 6.111241817474365, "metricx_qe_score": 5.078085899353027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diese neuen Ausdrücke.", "metrics": {"bleu_score": 17.7112472745327, "chrf_score": 60.33142515694993, "xcomet_score": 0.9283764362335205, "xcomet_qe_score": 0.8878461122512817, "metricx_score": 2.1812288761138916, "metricx_qe_score": 3.7007222175598145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es in den nächsten Zustand hinzu, um eine neue Menge zu werden.", "metrics": {"bleu_score": 56.76721706387804, "chrf_score": 74.64199430348219, "xcomet_score": 0.9594885110855103, "xcomet_qe_score": 0.9679067134857178, "metricx_score": 2.103252649307251, "metricx_qe_score": 1.7310878038406372, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folien visualisieren also tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zuständen immer wieder Ausdrücke hinzufügen.", "metrics": {"bleu_score": 11.369306152454815, "chrf_score": 59.785253929250516, "xcomet_score": 0.9841200113296509, "xcomet_qe_score": 0.9299314618110657, "metricx_score": 0.6665880680084229, "metricx_qe_score": 1.0572700500488281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Sprachmodell, das Vögel oder Robetts sein kann, und dann kodieren wir den Satz und erhalten diese Mengenrepräsentationen.", "metrics": {"bleu_score": 45.291802336749825, "chrf_score": 70.4388619823663, "xcomet_score": 0.7839599847793579, "xcomet_qe_score": 0.7264185547828674, "metricx_score": 7.170917987823486, "metricx_qe_score": 9.738343238830566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengen darstellen, können wir mit der Schlussfolgerung beginnen.", "metrics": {"bleu_score": 48.41524713034602, "chrf_score": 73.06810661650074, "xcomet_score": 0.958452582359314, "xcomet_qe_score": 0.9769740700721741, "metricx_score": 1.030377984046936, "metricx_qe_score": 0.8859612941741943, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q4 multipliziert wird.", "metrics": {"bleu_score": 30.883128948485865, "chrf_score": 67.86765362632642, "xcomet_score": 0.8948050737380981, "xcomet_qe_score": 0.9074167013168335, "metricx_score": 9.423433303833008, "metricx_qe_score": 8.026630401611328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Anweisung, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist. Dann wenden wir ein Fit-Forward-Netzwerk an, das vom Operator parametriert wird.", "metrics": {"bleu_score": 23.55271045759526, "chrf_score": 61.316005445558815, "xcomet_score": 0.7010967135429382, "xcomet_qe_score": 0.7109089493751526, "metricx_score": 5.034732818603516, "metricx_qe_score": 5.364349842071533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksrepräsentation Q1 geteilt durch Q2.", "metrics": {"bleu_score": 8.001467044102561, "chrf_score": 58.078129147119405, "xcomet_score": 0.9884779453277588, "xcomet_qe_score": 0.9803186655044556, "metricx_score": 0.7220244407653809, "metricx_qe_score": 0.8349495530128479, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Schlussfolgerung möglicherweise auch den falschen Ausdruck erhalten.", "metrics": {"bleu_score": 74.47819789879651, "chrf_score": 79.16303454809423, "xcomet_score": 0.9976706504821777, "xcomet_qe_score": 0.9906032085418701, "metricx_score": 1.6395790576934814, "metricx_qe_score": 2.132498025894165, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier entspricht also jeder möglichen Ausdruck dreimal so viel wie die Anzahl der Operatoren.", "metrics": {"bleu_score": 18.92240568795936, "chrf_score": 51.55461109396406, "xcomet_score": 0.9704679250717163, "xcomet_qe_score": 0.9740684032440186, "metricx_score": 4.018435001373291, "metricx_qe_score": 3.9023895263671875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern.", "metrics": {"bleu_score": 89.15993127600096, "chrf_score": 87.40069207547113, "xcomet_score": 0.9903877973556519, "xcomet_qe_score": 0.9839985370635986, "metricx_score": 0.7308709621429443, "metricx_qe_score": 0.8081192970275879, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchbereich entfernen.", "metrics": {"bleu_score": 38.17666460451127, "chrf_score": 69.18299752039427, "xcomet_score": 0.9843226671218872, "xcomet_qe_score": 1.0, "metricx_score": 0.4919506907463074, "metricx_qe_score": 0.7104009389877319, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir noch eine Menge mehr haben.", "metrics": {"bleu_score": 87.25129388059685, "chrf_score": 94.83810647869069, "xcomet_score": 0.9747592210769653, "xcomet_qe_score": 0.9410364627838135, "metricx_score": 2.5670900344848633, "metricx_qe_score": 4.347785472869873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe stammt aus dem vorherigen berechneten Ausdruck.", "metrics": {"bleu_score": 56.481980977130846, "chrf_score": 78.21299487829872, "xcomet_score": 0.9894788265228271, "xcomet_qe_score": 0.9800119996070862, "metricx_score": 1.3620316982269287, "metricx_qe_score": 2.39326548576355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir diesen letzten Ausdruck Q3 erhalten.", "metrics": {"bleu_score": 6.856346714060815, "chrf_score": 53.559262910477386, "xcomet_score": 0.8591343760490417, "xcomet_qe_score": 0.8685371279716492, "metricx_score": 7.762936115264893, "metricx_qe_score": 11.395795822143555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke von dem vorherigen Schritt unterschiedlich ist.", "metrics": {"bleu_score": 63.4192268377597, "chrf_score": 81.21279706964354, "xcomet_score": 0.9783830642700195, "xcomet_qe_score": 0.9579473733901978, "metricx_score": 2.3260889053344727, "metricx_qe_score": 3.4470913410186768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede machen es schwierig, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist.", "metrics": {"bleu_score": 36.073547169156235, "chrf_score": 63.45615096284837, "xcomet_score": 0.8884471654891968, "xcomet_qe_score": 0.8862094879150391, "metricx_score": 3.888925552368164, "metricx_qe_score": 4.6280646324157715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsmethode ist ähnlich wie bei der Schulung eines Sequenzmodells, bei dem wir den Verlust bei jedem Zeitschritt optimieren.", "metrics": {"bleu_score": 51.46906560381766, "chrf_score": 65.52852829888039, "xcomet_score": 0.9548478126525879, "xcomet_qe_score": 0.9571447372436523, "metricx_score": 1.3250654935836792, "metricx_qe_score": 2.603891134262085, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch diese Tao, um darzustellen, wann wir diesen Generierungsprozess beenden sollten.", "metrics": {"bleu_score": 65.40585844910977, "chrf_score": 86.83258384387122, "xcomet_score": 0.8708329796791077, "xcomet_qe_score": 0.8567243814468384, "metricx_score": 3.6639962196350098, "metricx_qe_score": 3.8804569244384766, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz anders, weil der Raum bei jedem Zeitpunkt anders ist, während es im traditionellen Sequenz- zu-Sequenz-Modell die Anzahl des Wortschatzes ist.", "metrics": {"bleu_score": 43.217450122697905, "chrf_score": 74.12767345187761, "xcomet_score": 0.9372576475143433, "xcomet_qe_score": 0.8849196434020996, "metricx_score": 2.2386157512664795, "metricx_qe_score": 2.9717864990234375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht es uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen zu verhängen.", "metrics": {"bleu_score": 18.20705281109213, "chrf_score": 50.891265332281776, "xcomet_score": 0.9729835987091064, "xcomet_qe_score": 0.9641116857528687, "metricx_score": 0.7896671891212463, "metricx_qe_score": 1.0785188674926758, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen also Experimente mit den häufig verwendeten Method-Problem-Datensätzen durch, MAWPS, Math23K, MathQA und SWAM.", "metrics": {"bleu_score": 49.372436277491104, "chrf_score": 67.2155642172253, "xcomet_score": 0.7967276573181152, "xcomet_qe_score": 0.8037093877792358, "metricx_score": 5.021219253540039, "metricx_qe_score": 5.4184489250183105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen.", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 89.65762009027497, "xcomet_score": 0.9826195240020752, "xcomet_qe_score": 0.9405105113983154, "metricx_score": 0.1904527097940445, "metricx_qe_score": 0.421423077583313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Variante ist also Roberta Dedative Reasoner.", "metrics": {"bleu_score": 20.164945583740657, "chrf_score": 63.9041175452618, "xcomet_score": 0.969239354133606, "xcomet_qe_score": 0.973747730255127, "metricx_score": 1.082547664642334, "metricx_qe_score": 1.9205034971237183, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir BeamSearch nicht, im Gegensatz zu offensichtlichen Ansätzen mit BeamSearch.", "metrics": {"bleu_score": 15.064134787973595, "chrf_score": 57.289747005828715, "xcomet_score": 0.9498482942581177, "xcomet_qe_score": 0.8460195064544678, "metricx_score": 4.081188201904297, "metricx_qe_score": 3.3602640628814697, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Okay, die besten Ansätze sind oft ein Baumbasiertes Modell.", "metrics": {"bleu_score": 17.242221289766626, "chrf_score": 59.63024141717249, "xcomet_score": 0.9728389978408813, "xcomet_qe_score": 0.9872888922691345, "metricx_score": 0.5576933026313782, "metricx_qe_score": 0.45352813601493835, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Vernunft also dieses Baumbasierungsmodell deutlich übertreffen.", "metrics": {"bleu_score": 6.061512325492642, "chrf_score": 43.33436174227452, "xcomet_score": 0.7844446897506714, "xcomet_qe_score": 0.7434931993484497, "metricx_score": 5.945489883422852, "metricx_qe_score": 3.568376302719116, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MatQuery oder SWAM nicht wirklich hoch sind.", "metrics": {"bleu_score": 66.54377827941899, "chrf_score": 79.0397097427659, "xcomet_score": 0.8322863578796387, "xcomet_qe_score": 0.8162553310394287, "metricx_score": 2.294023036956787, "metricx_qe_score": 2.0883450508117676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse weiter.", "metrics": {"bleu_score": 14.723282228934908, "chrf_score": 54.73983873930044, "xcomet_score": 0.9746352434158325, "xcomet_qe_score": 0.9660305976867676, "metricx_score": 0.9896937012672424, "metricx_qe_score": 1.4955278635025024, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist eine Herausforderung, weil der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. irrelevante Informationen und zusätzliche Mengen hinzuzufügen.", "metrics": {"bleu_score": 68.62716120112705, "chrf_score": 87.63458603972292, "xcomet_score": 0.9403753280639648, "xcomet_qe_score": 0.9449719190597534, "metricx_score": 1.0147875547409058, "metricx_qe_score": 1.1471457481384277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Also, in unserer Vorhersage finden wir, dass einige der intermediären Werte tatsächlich negativ sind.", "metrics": {"bleu_score": 23.693055763743093, "chrf_score": 57.899410416537634, "xcomet_score": 0.9961183071136475, "xcomet_qe_score": 0.9974676370620728, "metricx_score": 1.187645435333252, "metricx_qe_score": 1.2179932594299316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat.", "metrics": {"bleu_score": 53.36129799268556, "chrf_score": 72.9200239299847, "xcomet_score": 0.9995771646499634, "xcomet_qe_score": 0.9972515106201172, "metricx_score": 0.665325403213501, "metricx_qe_score": 1.0680568218231201, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Pitchs und Stephen hat acht Pitchs, was völlig irrelevant ist.", "metrics": {"bleu_score": 48.23588086672041, "chrf_score": 73.0343441983581, "xcomet_score": 0.7886362075805664, "xcomet_qe_score": 0.7989926338195801, "metricx_score": 6.666820526123047, "metricx_qe_score": 6.288867473602295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt.", "metrics": {"bleu_score": 47.163812845557715, "chrf_score": 76.40311291183929, "xcomet_score": 0.983458399772644, "xcomet_qe_score": 0.9717435836791992, "metricx_score": 0.6164632439613342, "metricx_qe_score": 0.7936659455299377, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke.", "metrics": {"bleu_score": 11.147892272337163, "chrf_score": 33.87680096462581, "xcomet_score": 0.7297190427780151, "xcomet_qe_score": 0.8604840636253357, "metricx_score": 6.011697769165039, "metricx_qe_score": 13.461858749389648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse als negativ entfernen, damit wir die Antwort richtig machen können.", "metrics": {"bleu_score": 17.569374699826113, "chrf_score": 69.23478799244849, "xcomet_score": 0.9216958284378052, "xcomet_qe_score": 0.8144686222076416, "metricx_score": 2.8869264125823975, "metricx_qe_score": 2.9406609535217285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert.", "metrics": {"bleu_score": 54.20662441541858, "chrf_score": 67.04859956942606, "xcomet_score": 0.98409104347229, "xcomet_qe_score": 0.9691487550735474, "metricx_score": 1.2443279027938843, "metricx_qe_score": 1.2154340744018555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert und bei dem Roberta-Basemodell tatsächlich zwei Punkte verbessert.", "metrics": {"bleu_score": 22.923168930216754, "chrf_score": 64.04862417578953, "xcomet_score": 0.8039360046386719, "xcomet_qe_score": 0.8057708740234375, "metricx_score": 10.500574111938477, "metricx_qe_score": 9.17062759399414, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat also bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Bert niedriger ist.", "metrics": {"bleu_score": 60.65340911201771, "chrf_score": 81.75378911702465, "xcomet_score": 0.9998496770858765, "xcomet_qe_score": 1.0, "metricx_score": 0.5577476024627686, "metricx_qe_score": 0.9439879655838013, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren.", "metrics": {"bleu_score": 40.17682558797496, "chrf_score": 68.4717897329591, "xcomet_score": 0.7763559818267822, "xcomet_qe_score": 0.7386771440505981, "metricx_score": 5.086433410644531, "metricx_qe_score": 7.315237998962402, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information angesehen werden kann.", "metrics": {"bleu_score": 79.12619863720215, "chrf_score": 87.06357167795058, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2532813847064972, "metricx_qe_score": 0.3384082615375519, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der ungenutzten Mengen haben und der SWAMP-Datensatz den größten Teil enthält.", "metrics": {"bleu_score": 30.605489748861324, "chrf_score": 66.94404424515707, "xcomet_score": 0.9535649418830872, "xcomet_qe_score": 0.9485882520675659, "metricx_score": 2.054572820663452, "metricx_qe_score": 2.4237165451049805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung.", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 95.153554655332, "xcomet_score": 0.9975186586380005, "xcomet_qe_score": 0.9953868389129639, "metricx_score": 0.17540127038955688, "metricx_qe_score": 0.28346192836761475, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen ist die Gesamtleistung tatsächlich höher als die Gesamtleistung.", "metrics": {"bleu_score": 57.02822264405544, "chrf_score": 75.73745658524284, "xcomet_score": 0.8043622970581055, "xcomet_qe_score": 0.6431232690811157, "metricx_score": 3.904196262359619, "metricx_qe_score": 5.960141181945801, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlimmer ist als die, äh, viel schlimmer als.", "metrics": {"bleu_score": 13.566979610140004, "chrf_score": 52.172625660075624, "xcomet_score": 0.8774046897888184, "xcomet_qe_score": 0.86769700050354, "metricx_score": 11.95778751373291, "metricx_qe_score": 12.342180252075195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für MAWPS haben wir nicht wirklich viele Desk-Cases, also ignoriere ich diesen Teil einfach.", "metrics": {"bleu_score": 74.47819789879651, "chrf_score": 81.37568396964687, "xcomet_score": 0.878989577293396, "xcomet_qe_score": 0.8383238315582275, "metricx_score": 3.7374186515808105, "metricx_qe_score": 4.164152145385742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretationsfähigkeit durch ein Beispiel für die Zusammenstoßpartizierung zeigen.", "metrics": {"bleu_score": 9.238430210261097, "chrf_score": 48.17118925042962, "xcomet_score": 0.835361897945404, "xcomet_qe_score": 0.8464998602867126, "metricx_score": 6.130422592163086, "metricx_qe_score": 5.105709552764893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also tatsächlich eine falsche Vorhersage im ersten Schritt.", "metrics": {"bleu_score": 68.71280435782894, "chrf_score": 86.47645976696444, "xcomet_score": 0.990764856338501, "xcomet_qe_score": 0.9795717000961304, "metricx_score": 0.39116501808166504, "metricx_qe_score": 0.4954703450202942, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren, oder?", "metrics": {"bleu_score": 75.77395672414198, "chrf_score": 90.97148603534116, "xcomet_score": 0.9999788999557495, "xcomet_qe_score": 0.9998624324798584, "metricx_score": 0.9259734153747559, "metricx_qe_score": 0.799877405166626, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben also, dass dieser Satz das Modell in eine falsche Vorhersage führen könnte.", "metrics": {"bleu_score": 42.311785416105785, "chrf_score": 67.53786050362861, "xcomet_score": 0.9697215557098389, "xcomet_qe_score": 0.9662671089172363, "metricx_score": 0.9351934194564819, "metricx_qe_score": 0.7803514003753662, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man hier also noch 35 plant, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte.", "metrics": {"bleu_score": 9.849349468888725, "chrf_score": 40.108946653802896, "xcomet_score": 0.8339099884033203, "xcomet_qe_score": 0.7324355840682983, "metricx_score": 5.767863750457764, "metricx_qe_score": 3.354818820953369, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu ändern, dass er so aussieht wie die Anzahl der Birnenfäden fünfundfünfzig weniger ist als die Apfelbäume.", "metrics": {"bleu_score": 15.441675910887072, "chrf_score": 56.9219115841474, "xcomet_score": 0.861557126045227, "xcomet_qe_score": 0.8606848120689392, "metricx_score": 13.177986145019531, "metricx_qe_score": 12.819868087768555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen es also so, dass es genauere Semantik vermittelt, damit das Modell die Vorhersage richtig machen kann.", "metrics": {"bleu_score": 9.666038999671365, "chrf_score": 48.68077147486035, "xcomet_score": 0.9506624937057495, "xcomet_qe_score": 0.9256950616836548, "metricx_score": 1.2086814641952515, "metricx_qe_score": 1.3782907724380493, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen.", "metrics": {"bleu_score": 54.44444966666223, "chrf_score": 86.20673516181925, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.47664502263069153, "metricx_qe_score": 0.6502724885940552, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell eigentlich ziemlich effizient.", "metrics": {"bleu_score": 36.049080429833154, "chrf_score": 74.61098560965692, "xcomet_score": 0.997116208076477, "xcomet_qe_score": 0.9678579568862915, "metricx_score": 0.718780517578125, "metricx_qe_score": 0.8830163478851318, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können eine interpretierbare Lösungsmethode bereitstellen.", "metrics": {"bleu_score": 3.7954847898457067, "chrf_score": 39.871949296810506, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2914818525314331, "metricx_qe_score": 0.2640162706375122, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige vorherige Kenntnisse als Konstrakt einbeziehen, was uns helfen kann, die Leistung zu verbessern.", "metrics": {"bleu_score": 8.638804535733374, "chrf_score": 46.58837712323739, "xcomet_score": 0.9686673879623413, "xcomet_qe_score": 0.9697449803352356, "metricx_score": 3.6152093410491943, "metricx_qe_score": 3.8295531272888184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur für Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch für andere Aufgaben, die mehrtretende Argumentation beinhalten.", "metrics": {"bleu_score": 34.79159475128446, "chrf_score": 65.45370328273353, "xcomet_score": 0.9391567707061768, "xcomet_qe_score": 0.9354265928268433, "metricx_score": 2.1852543354034424, "metricx_qe_score": 2.1305148601531982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 18.03958201806172, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4435056149959564, "metricx_qe_score": 0.46961158514022827, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung in verschiedenen Zeitzonen unbalanciert ist, daher ist es auch ziemlich schwierig, Beam-Suche anzuwenden.", "metrics": {"bleu_score": 4.807547001959649, "chrf_score": 47.281740598861425, "xcomet_score": 0.8770859837532043, "xcomet_qe_score": 0.8894186019897461, "metricx_score": 4.580848217010498, "metricx_qe_score": 4.7643280029296875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also das Ende des Vortrags und Fragen sind willkommen. Vielen Dank.", "metrics": {"bleu_score": 15.934326838673732, "chrf_score": 48.46195260351017, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4070357382297516, "metricx_qe_score": 0.2971506714820862, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Maastricht University.", "metrics": {"bleu_score": 58.84191416232741, "chrf_score": 76.65922419923122, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2487911581993103, "metricx_qe_score": 0.10448111593723297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein Johannes Werk mit Jerry vorstellen, das sich mit einem neuen Datensatz für die Abholung von gesetzlichen Artikeln befasst.", "metrics": {"bleu_score": 17.855149299161596, "chrf_score": 52.35120712826159, "xcomet_score": 0.8591204881668091, "xcomet_qe_score": 0.8069272041320801, "metricx_score": 10.64129638671875, "metricx_qe_score": 9.8592529296875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein wesentlicher Bestandteil des Lebens vieler Menschen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat wenig oder kein Wissen über ihre Rechte und grundlegenden Rechtsverfahren.", "metrics": {"bleu_score": 42.254876310519364, "chrf_score": 70.69331286766712, "xcomet_score": 0.9993624687194824, "xcomet_qe_score": 1.0, "metricx_score": 0.39269357919692993, "metricx_qe_score": 0.4587463438510895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Ergebnis sind viele vulnerable Bürger, die sich nicht die kostbare Assistance eines Legal Experts erwarten können, unprotegt oder worstens, exploitiert.", "metrics": {"bleu_score": 12.066117639596522, "chrf_score": 32.95358679712256, "xcomet_score": 0.8822271227836609, "xcomet_qe_score": 0.9251782298088074, "metricx_score": 13.416223526000977, "metricx_qe_score": 9.971001625061035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Lücke zwischen Menschen und dem Gesetz zu schließen, indem wir ein effektives Rückholsystem für gesetzliche Artikel entwickeln.", "metrics": {"bleu_score": 41.790821900460315, "chrf_score": 66.50196285632266, "xcomet_score": 0.9525216817855835, "xcomet_qe_score": 0.9052947759628296, "metricx_score": 1.5714194774627686, "metricx_qe_score": 0.748677134513855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte für unqualifizierte Menschen einen kostenlosen professionellen Rechtshilfenservice bieten.", "metrics": {"bleu_score": 30.57690288450511, "chrf_score": 75.84635578032444, "xcomet_score": 0.9705953598022461, "xcomet_qe_score": 0.9927171468734741, "metricx_score": 0.6170272827148438, "metricx_qe_score": 0.48733794689178467, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem der statutarischen Artikelabholung.", "metrics": {"bleu_score": 31.42665434344144, "chrf_score": 63.37230033418837, "xcomet_score": 0.8590691089630127, "xcomet_qe_score": 0.8889737725257874, "metricx_score": 5.3613972663879395, "metricx_qe_score": 3.2549123764038086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ich eine einfache Frage zu einem rechtlichen Thema stelle, wie zum Beispiel: Was mache ich, wenn ich die professionelle Vertraulichkeit verletze?", "metrics": {"bleu_score": 14.965975078050626, "chrf_score": 47.01873179400416, "xcomet_score": 0.9509152173995972, "xcomet_qe_score": 0.914699912071228, "metricx_score": 4.5376434326171875, "metricx_qe_score": 3.8838319778442383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetz zu erfassen.", "metrics": {"bleu_score": 20.789290034925113, "chrf_score": 49.528974363724856, "xcomet_score": 0.9714971780776978, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.018237352371216, "metricx_qe_score": 1.1585683822631836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe zur Informationserfassung bringt eine ganze Reihe von Herausforderungen mit sich.", "metrics": {"bleu_score": 44.08231875586728, "chrf_score": 72.41605650595613, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.48902595043182373, "metricx_qe_score": 0.21398422122001648, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst geht es um zwei Sprachtypen.", "metrics": {"bleu_score": 10.175282441454787, "chrf_score": 31.518313563389405, "xcomet_score": 0.9990803003311157, "xcomet_qe_score": 0.9940214157104492, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "für die Fragen eine gängige natürliche Sprache und für die Statuten eine komplexe rechtliche Sprache.", "metrics": {"bleu_score": 14.980800232509305, "chrf_score": 55.172662978804254, "xcomet_score": 0.9653434753417969, "xcomet_qe_score": 0.9656959772109985, "metricx_score": 1.7378818988800049, "metricx_qe_score": 1.0395948886871338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in den Sprachverteilungen machen es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die mit der Terminologie der Gesetze entspricht.", "metrics": {"bleu_score": 81.48395787418856, "chrf_score": 94.16443456492367, "xcomet_score": 0.951311469078064, "xcomet_qe_score": 0.9237390756607056, "metricx_score": 1.7175456285476685, "metricx_qe_score": 1.3603514432907104, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das gesetzliche Recht kein Stapel unabhängiger Artikel, die als vollständige Informationsquelle an sich behandelt werden können, wie zum Beispiel Nachrichten oder Rezepte.", "metrics": {"bleu_score": 29.504864876582374, "chrf_score": 68.11497400946277, "xcomet_score": 0.9674498438835144, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.6533410549163818, "metricx_qe_score": 1.0789077281951904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Insted ist es eine Strukturkollektion von legalen Provisionen, die nur in der allgemeinen Kontext betrachtet sind, zusammen mit den zusätzlichen Informationen aus den neighbouring Artikeln, den Feldern und Subfeldern, zu denen sie gehören, und ihrer Platz in der Struktur des Gesetzes.", "metrics": {"bleu_score": 9.77798169499108, "chrf_score": 44.43908553364634, "xcomet_score": 0.4446326494216919, "xcomet_qe_score": 0.5743907690048218, "metricx_score": 17.16754722595215, "metricx_qe_score": 14.689922332763672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, statutory Articles RN small paragraph, was usuell die typische Retrieval Unit in Most Retrieval Works ist.", "metrics": {"bleu_score": 4.356766657846935, "chrf_score": 26.72426718051805, "xcomet_score": 0.4212157130241394, "xcomet_qe_score": 0.6223356127738953, "metricx_score": 20.152421951293945, "metricx_qe_score": 18.618896484375, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Jahre dauern können.", "metrics": {"bleu_score": 40.818511424237265, "chrf_score": 53.37226059067219, "xcomet_score": 0.8206316232681274, "xcomet_qe_score": 0.8247852921485901, "metricx_score": 12.502873420715332, "metricx_qe_score": 13.864418029785156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich NLP haben großes Interesse an vielen rechtlichen Aufgaben wie der Vorhersage von Rechtsentscheidungen oder der automatisierten Überprüfung von Vertragsverträgen weckt.", "metrics": {"bleu_score": 39.968279787810694, "chrf_score": 72.7150426414791, "xcomet_score": 0.9700304865837097, "xcomet_qe_score": 0.9589686393737793, "metricx_score": 1.0977226495742798, "metricx_qe_score": 1.2167755365371704, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabholung ist jedoch aufgrund des Mangels an großen und hochwertigen gekennzeichneten Datensätzen größtenteils unberührt geblieben.", "metrics": {"bleu_score": 31.688916239214326, "chrf_score": 56.32276508206638, "xcomet_score": 0.8663316965103149, "xcomet_qe_score": 0.8741229772567749, "metricx_score": 4.825144290924072, "metricx_qe_score": 3.702840805053711, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir ein neues französisches, zentrales, zentrales Datenkett, um zu untersuchen, ob ein Rückholmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten für die Aufgabe der Statutorienartikelrückholung nähern kann.", "metrics": {"bleu_score": 17.415761553219877, "chrf_score": 53.56063782548336, "xcomet_score": 0.6525304317474365, "xcomet_qe_score": 0.6928983330726624, "metricx_score": 12.788432121276855, "metricx_qe_score": 11.022191047668457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Our Belgian Statutory Article Retrieval Data Sets consist von mehr als einem Jahrzehnt Liter.", "metrics": {"bleu_score": 3.1743251572381714, "chrf_score": 19.602466397393243, "xcomet_score": 0.23089507222175598, "xcomet_qe_score": 0.5187681913375854, "metricx_score": 24.965167999267578, "metricx_qe_score": 24.373003005981445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnraum, Geld bis hin zu Arbeit und Sozialversicherung.", "metrics": {"bleu_score": 37.97100712132707, "chrf_score": 59.73465139657156, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3013668954372406, "metricx_qe_score": 0.11081445217132568, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen hat von erfahrenen Juristen mit Referenzen zu relevanten Artikeln aus einem Corpus von mehr als twenty zwei Tausend sechshundert.", "metrics": {"bleu_score": 17.011219398374337, "chrf_score": 50.50823408926458, "xcomet_score": 0.6692209243774414, "xcomet_qe_score": 0.7863742113113403, "metricx_score": 14.264535903930664, "metricx_qe_score": 15.007833480834961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Codes of Law. Lassen Sie uns nun über die Erstellung dieser Datsätze sprechen.", "metrics": {"bleu_score": 16.94357181593088, "chrf_score": 42.84408682998297, "xcomet_score": 0.3061532974243164, "xcomet_qe_score": 0.2685996890068054, "metricx_score": 12.463595390319824, "metricx_qe_score": 14.347186088562012, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir mit der Zusammenstellung eines großen Korpus an rechtlichen Artikeln begonnen.", "metrics": {"bleu_score": 13.912311644176565, "chrf_score": 59.45528818979471, "xcomet_score": 0.999789834022522, "xcomet_qe_score": 0.989833414554596, "metricx_score": 0.2183150351047516, "metricx_qe_score": 0.30868542194366455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich verfügbare Belgische Codes und alle Artikel sowie die entsprechenden Abschnittshebungen entnommen.", "metrics": {"bleu_score": 44.05136963304349, "chrf_score": 56.05047918418522, "xcomet_score": 0.827355146408081, "xcomet_qe_score": 0.8226908445358276, "metricx_score": 5.685217380523682, "metricx_qe_score": 4.004554748535156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf relevante Gesetze.", "metrics": {"bleu_score": 46.65904311461236, "chrf_score": 61.41642355332066, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3132973313331604, "metricx_qe_score": 0.2885987162590027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten.", "metrics": {"bleu_score": 64.97559154222685, "chrf_score": 78.67578236488436, "xcomet_score": 0.9983940124511719, "xcomet_qe_score": 1.0, "metricx_score": 0.1264541894197464, "metricx_qe_score": 0.21154549717903137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich, auf ihre Websites zuzugreifen, wo ihr Team von erfahrenen Juristen Belgien's am häufigsten rechtlichen Probleme behandelt.", "metrics": {"bleu_score": 6.374832623269345, "chrf_score": 44.991631293570535, "xcomet_score": 0.9266501665115356, "xcomet_qe_score": 0.9135284423828125, "metricx_score": 1.2611688375473022, "metricx_qe_score": 1.1209497451782227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen zusammengestellt, mit Kategorien, Subkategorien und rechtlichen Verweisen auf relevante Statuten.", "metrics": {"bleu_score": 30.928520903947533, "chrf_score": 59.276109036065925, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7797550559043884, "metricx_qe_score": 0.572742223739624, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, wir passten die legalen Referenzen und filterten die Fragen aus, die Referenzen nicht Artikel in einem der Codes of Law wirkten.", "metrics": {"bleu_score": 8.586092130733784, "chrf_score": 27.794256253716416, "xcomet_score": 0.5957298278808594, "xcomet_qe_score": 0.6830876469612122, "metricx_score": 14.333870887756348, "metricx_qe_score": 13.503127098083496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Verweise wurden in die entsprechenden Artikel-IDs aus O Corpus abgestimmt und umgewandelt.", "metrics": {"bleu_score": 30.934588294313713, "chrf_score": 54.2792938259705, "xcomet_score": 0.9369245767593384, "xcomet_qe_score": 0.925318717956543, "metricx_score": 5.620779514312744, "metricx_qe_score": 5.090725898742676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.108 Fragen, jeder sorgfältig mit den IDs der relevanten Artikel aus dem Buch.", "metrics": {"bleu_score": 30.491854911466543, "chrf_score": 49.21225868301159, "xcomet_score": 0.688458263874054, "xcomet_qe_score": 0.6933411359786987, "metricx_score": 8.799903869628906, "metricx_qe_score": 13.301911354064941, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich enthält jede Frage eine Hauptkategorie und eine Konkatenation von Unterkategorien.", "metrics": {"bleu_score": 58.33510584342546, "chrf_score": 71.07981184015847, "xcomet_score": 0.9581558704376221, "xcomet_qe_score": 0.9474607706069946, "metricx_score": 1.3972971439361572, "metricx_qe_score": 0.9411666393280029, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel kommt mit einer Konkatenation ihrer nachfolgenden Überschriften in der Struktur des Gesetzes.", "metrics": {"bleu_score": 10.82597837309053, "chrf_score": 50.0976818603163, "xcomet_score": 0.9336916208267212, "xcomet_qe_score": 0.9135510921478271, "metricx_score": 4.103768825531006, "metricx_qe_score": 4.084705352783203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzliche Information wird nicht in der Präsentation verwendet, aber sie könnte für zukünftige Research auf Legal Information Retrieval oder Legaltext Classification interessant sein.", "metrics": {"bleu_score": 5.603240270747239, "chrf_score": 46.95188798491659, "xcomet_score": 0.8987488746643066, "xcomet_qe_score": 0.9222826957702637, "metricx_score": 6.897402763366699, "metricx_qe_score": 5.665501594543457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale unserer Datensätze an.", "metrics": {"bleu_score": 51.33450480401705, "chrf_score": 79.12152600161083, "xcomet_score": 0.9981184005737305, "xcomet_qe_score": 1.0, "metricx_score": 0.08073697239160538, "metricx_qe_score": 0.08605223894119263, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Frage ist zwischen fünf und vierundvierzig Wort lang, mit einem Median von vierzig Wort.", "metrics": {"bleu_score": 22.637359354764463, "chrf_score": 49.12005984846522, "xcomet_score": 0.8817247748374939, "xcomet_qe_score": 0.9571183919906616, "metricx_score": 8.31457233428955, "metricx_qe_score": 5.77714729309082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer medianen Länge von sechzig sieben Wörtern, mit 140 Gramm.", "metrics": {"bleu_score": 12.820245744744291, "chrf_score": 41.1527374154187, "xcomet_score": 0.5664102435112, "xcomet_qe_score": 0.5459225177764893, "metricx_score": 13.700643539428711, "metricx_qe_score": 16.575881958007812, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei von ihnen, die eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr", "metrics": {"bleu_score": 2.177002209903929, "chrf_score": 12.944781580832865, "xcomet_score": 0.14610795676708221, "xcomet_qe_score": 0.14582905173301697, "metricx_score": 19.347448348999023, "metricx_qe_score": 20.558828353881836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine Vielzahl von Themen, von denen etwa 85 % entweder über Familie, Wohnraum, Geld oder Gerechtigkeit betraf.", "metrics": {"bleu_score": 10.248656832135978, "chrf_score": 49.363983884848004, "xcomet_score": 0.9163382053375244, "xcomet_qe_score": 0.9182398319244385, "metricx_score": 3.1969361305236816, "metricx_qe_score": 2.94680118560791, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Während die restlichen fünfzehn Prozent entweder mit der Sozialversicherung, Ausländern oder Arbeit zu tun haben.", "metrics": {"bleu_score": 6.256118460580956, "chrf_score": 54.486009281451956, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.1842366456985474, "metricx_qe_score": 0.6182213425636292, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr diverse, da sie aus dreißig zwei verschiedenen Belgischen Codes kommen, die eine große Anzahl von illegalen Themen abdecken.", "metrics": {"bleu_score": 34.75656119148122, "chrf_score": 58.96132720994499, "xcomet_score": 0.7991318702697754, "xcomet_qe_score": 0.8242580890655518, "metricx_score": 8.958362579345703, "metricx_qe_score": 7.451976776123047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel aus jedem dieser belgischen Codes.", "metrics": {"bleu_score": 35.96008497520192, "chrf_score": 53.69013954696852, "xcomet_score": 0.9773925542831421, "xcomet_qe_score": 1.0, "metricx_score": 3.0941505432128906, "metricx_qe_score": 2.4575722217559814, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Aus den twenty two thousand six hundred thirty three Artikeln, nur eintausend sechs hundred twelve sind als relevant zu at least einem", "metrics": {"bleu_score": 4.141141330484801, "chrf_score": 29.61565512970004, "xcomet_score": 0.6897472143173218, "xcomet_qe_score": 0.8135076761245728, "metricx_score": 19.832008361816406, "metricx_qe_score": 20.147781372070312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "nur eine Frage in den Daten sätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafverfolgungsgesetz.", "metrics": {"bleu_score": 18.52972751417938, "chrf_score": 51.57937013619854, "xcomet_score": 0.2542054057121277, "xcomet_qe_score": 0.38626357913017273, "metricx_score": 11.501693725585938, "metricx_qe_score": 12.892720222473145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen enthalten achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden.", "metrics": {"bleu_score": 34.53064989552127, "chrf_score": 60.69581813012282, "xcomet_score": 0.9582452774047852, "xcomet_qe_score": 0.9757745862007141, "metricx_score": 2.4342310428619385, "metricx_qe_score": 1.7929102182388306, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann durch die Tatsache erklärt werden, dass diese Codes weniger auf Einzelpersonen und ihre Anliegen fokussieren.", "metrics": {"bleu_score": 10.975762213309226, "chrf_score": 45.784081428752, "xcomet_score": 0.9819101691246033, "xcomet_qe_score": 0.9865762591362, "metricx_score": 4.415182113647461, "metricx_qe_score": 3.2928853034973145, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünf Prozent von ihnen sind in der", "metrics": {"bleu_score": 15.867077366552559, "chrf_score": 40.768643562323845, "xcomet_score": 0.2625156044960022, "xcomet_qe_score": 0.5497974157333374, "metricx_score": 19.26835823059082, "metricx_qe_score": 15.721713066101074, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen benchmarken wir verschiedene Rückholmethoden, einschließlich lexikalischer und denser Architektur.", "metrics": {"bleu_score": 15.895657318041236, "chrf_score": 54.39554661621607, "xcomet_score": 0.938667356967926, "xcomet_qe_score": 0.8977645039558411, "metricx_score": 2.349987268447876, "metricx_qe_score": 3.004730701446533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrageartikelpaar eine Punktzahl zu, indem es die Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfragezeiten berechnet.", "metrics": {"bleu_score": 52.74419476494788, "chrf_score": 75.45723289440942, "xcomet_score": 0.880144476890564, "xcomet_qe_score": 0.876102089881897, "metricx_score": 4.372537612915039, "metricx_qe_score": 3.919670343399048, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM-25-Rankingfunktionen.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 75.38886031355452, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9985291957855225, "metricx_qe_score": 1.4380638599395752, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten.", "metrics": {"bleu_score": 51.3463583213731, "chrf_score": 78.68300882076775, "xcomet_score": 0.9642143249511719, "xcomet_qe_score": 0.9594448804855347, "metricx_score": 1.3089779615402222, "metricx_qe_score": 0.8937552571296692, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann.", "metrics": {"bleu_score": 87.87419089273847, "chrf_score": 94.0489601912323, "xcomet_score": 0.9998520612716675, "xcomet_qe_score": 0.9999477863311768, "metricx_score": 0.4494284987449646, "metricx_qe_score": 0.3703739643096924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert und eine relevante Punktzahl zwischen einem Abfrage-Artikelpaar anhand der Ähnlichkeit ihrer Eingebettungen berechnet.", "metrics": {"bleu_score": 34.61631665891904, "chrf_score": 74.39161475097758, "xcomet_score": 0.8000051975250244, "xcomet_qe_score": 0.8016875982284546, "metricx_score": 4.404580116271973, "metricx_qe_score": 4.607856750488281, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Einbettungsmodells.", "metrics": {"bleu_score": 13.46216659120865, "chrf_score": 65.36540383288597, "xcomet_score": 0.9198237657546997, "xcomet_qe_score": 0.8908716440200806, "metricx_score": 3.113664388656616, "metricx_qe_score": 3.0518693923950195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit siamesischer Biancoder in einer Nullschussbewertung, was bedeutet, dass vorgebildete Word-Embedding-Modelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden.", "metrics": {"bleu_score": 17.846877279661648, "chrf_score": 53.609531688941836, "xcomet_score": 0.8433307409286499, "xcomet_qe_score": 0.7092852592468262, "metricx_score": 5.195127487182617, "metricx_qe_score": 4.735837936401367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, und kontextunabhängigen Einbettungsmodellen, nämlich Roberta und genauer gesagt Camembert, das ein französisches Roberta-Modell ist.", "metrics": {"bleu_score": 13.834368456410951, "chrf_score": 70.27481219524674, "xcomet_score": 0.8839197158813477, "xcomet_qe_score": 0.9617897868156433, "metricx_score": 3.6797547340393066, "metricx_qe_score": 2.037158489227295, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes Camembert-basiertes Modell. Beyond quoters.", "metrics": {"bleu_score": 13.741214343226053, "chrf_score": 41.913054578410694, "xcomet_score": 0.7532779574394226, "xcomet_qe_score": 0.7653360962867737, "metricx_score": 10.338109016418457, "metricx_qe_score": 12.982501983642578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beispiele auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Flavors der Bianco architektur experimentieren.", "metrics": {"bleu_score": 30.09429889037876, "chrf_score": 67.47695460610876, "xcomet_score": 0.5831239819526672, "xcomet_qe_score": 0.6181331872940063, "metricx_score": 13.581748962402344, "metricx_qe_score": 13.368804931640625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Query und den Artikel in einem gemeinsamen Densivektorraum mappiert, und Tutor, das zwei unabhängige Word-Embedding-Modelle verwendet, die die Query und den Artikel separat in zwei verschiedene Embedding-Spaces codieren.", "metrics": {"bleu_score": 31.823562179732587, "chrf_score": 57.634931207640335, "xcomet_score": 0.693622350692749, "xcomet_qe_score": 0.6825092434883118, "metricx_score": 7.670272350311279, "metricx_qe_score": 9.45722484588623, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit dem Pooling von Mittel, Max und CLS sowie mit dem Punktprodukt und dem Kosinus für die Rechengelähnungen.", "metrics": {"bleu_score": 13.871452725344989, "chrf_score": 55.6323068406291, "xcomet_score": 0.6768176555633545, "xcomet_qe_score": 0.7594611644744873, "metricx_score": 7.514424800872803, "metricx_qe_score": 7.727290153503418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Ausgangslinie auf den Testsätzen.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 81.97179057768953, "xcomet_score": 0.8857712745666504, "xcomet_qe_score": 0.8061846494674683, "metricx_score": 2.7335784435272217, "metricx_qe_score": 4.386214256286621, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Dann mit den lexikalischen Methoden oben, den Siamese-B-Encodern, die in einer Null-Schuss-Einrichtung evaluiert wurden, und den fein abgestimmten B-Encodern unten.", "metrics": {"bleu_score": 6.8146790862039905, "chrf_score": 51.13380660645891, "xcomet_score": 0.7493047714233398, "xcomet_qe_score": 0.6519596576690674, "metricx_score": 6.472739219665527, "metricx_qe_score": 6.05906343460083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchore alle anderen Basslinien deutlich.", "metrics": {"bleu_score": 11.731175160263996, "chrf_score": 63.25995418571385, "xcomet_score": 0.7642766237258911, "xcomet_qe_score": 0.7664473056793213, "metricx_score": 6.572929859161377, "metricx_qe_score": 6.783105373382568, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two Tower Modell verbessert sich gegenüber seiner Siamese-Variante auf Recallat one hundred, aber es funktioniert ähnlich bei den anderen Metriken.", "metrics": {"bleu_score": 17.059573701616795, "chrf_score": 60.385338842273775, "xcomet_score": 0.6338993310928345, "xcomet_qe_score": 0.6263275742530823, "metricx_score": 7.847984790802002, "metricx_qe_score": 7.393246650695801, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five den trainierten Biancode erheblich unterlegen hat, zeigt seine Leistung, dass es immer noch eine starke Grundlage für Domain Specific Retrieval ist.", "metrics": {"bleu_score": 16.497440012799224, "chrf_score": 48.28323490848283, "xcomet_score": 0.7438697814941406, "xcomet_qe_score": 0.7690967321395874, "metricx_score": 8.443126678466797, "metricx_qe_score": 7.982354640960693, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Was die Nullschussbewertung des siamesischen Biancoders betrifft, stellen wir fest, dass die direkte Verwendung der Eingebettungen eines vorgebildeten Kamembert-Modells ohne Optimierung für die Informationsabholungsaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt.", "metrics": {"bleu_score": 53.86366368831865, "chrf_score": 72.75539159118745, "xcomet_score": 0.7387277483940125, "xcomet_qe_score": 0.7459055185317993, "metricx_score": 4.970860481262207, "metricx_qe_score": 3.04130482673645, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir festgestellt, dass der Word-Tuec-basierte Biancoder den Vastex- und Vogelbasierten Modell deutlich übertrifft, was darauf hindeutet, dass möglicherweise vor-train-Word-Level-Embeddings für die Aufgabe besser geeignet sind als Charakter- oder Unterword-Level-Embeddings, wenn sie von vorn verwendet werden.", "metrics": {"bleu_score": 28.315637089283598, "chrf_score": 56.7309271290746, "xcomet_score": 0.34832310676574707, "xcomet_qe_score": 0.3606896698474884, "metricx_score": 17.18301773071289, "metricx_qe_score": 15.835213661193848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Möglichkeiten für Verbesserungen im Vergleich zu einem geschickten Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann.", "metrics": {"bleu_score": 31.872519756132593, "chrf_score": 65.14005392011471, "xcomet_score": 0.9998713731765747, "xcomet_qe_score": 1.0, "metricx_score": 0.5971353054046631, "metricx_qe_score": 0.39116767048835754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns mit zwei Einschränkungen aller Datensätze abschließen.", "metrics": {"bleu_score": 9.287528999566801, "chrf_score": 49.3093991850115, "xcomet_score": 0.9560278654098511, "xcomet_qe_score": 0.9431362152099609, "metricx_score": 6.829432487487793, "metricx_qe_score": 4.466310501098633, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf die aus den 32 belgischen Gesetzen gezogenen beschränkt, die nicht das gesamte belgische Gesetz abdecken, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen.", "metrics": {"bleu_score": 42.56737846773503, "chrf_score": 70.50519613507855, "xcomet_score": 0.9308384656906128, "xcomet_qe_score": 0.9172719120979309, "metricx_score": 3.39497709274292, "metricx_qe_score": 3.120191812515259, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Referenzen zu diesen ungesammelten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl relevanten Artikeln erhalten.", "metrics": {"bleu_score": 28.61438789384231, "chrf_score": 61.679097637074165, "xcomet_score": 0.9373260140419006, "xcomet_qe_score": 0.9600399732589722, "metricx_score": 2.0033116340637207, "metricx_qe_score": 1.5524547100067139, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsloss impliziert, dass die Antwort in den verbleibenden relevanten Artikeln unvollständig sein könnte, obwohl sie immer noch vollständig angemessen ist.", "metrics": {"bleu_score": 38.90150368910117, "chrf_score": 74.29887149950021, "xcomet_score": 0.884712278842926, "xcomet_qe_score": 0.862317681312561, "metricx_score": 3.2303643226623535, "metricx_qe_score": 4.130620002746582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.111781045794487, "metricx_qe_score": 0.16189205646514893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Kann ich meine Mieter vertreiben, wenn sie zu viel Lärm machen?", "metrics": {"bleu_score": 57.030171725674585, "chrf_score": 76.32455518379896, "xcomet_score": 0.9998271465301514, "xcomet_qe_score": 0.9988764524459839, "metricx_score": 0.3151014745235443, "metricx_qe_score": 0.24529340863227844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Might not have a detaillierte Antwort innerhalb des gesetzlichen Gesetzes, das eine spezifische Noise-Threshold quantifiziert, bei der Räumung zulässig ist.", "metrics": {"bleu_score": 13.929083599454664, "chrf_score": 44.29201737657576, "xcomet_score": 0.5578869581222534, "xcomet_qe_score": 0.6113486289978027, "metricx_score": 15.336101531982422, "metricx_qe_score": 16.04705810546875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich mehr auf die Rechtsprechung vertrauen und Präzedenzfälle finden, die ähnlich zu ihrer aktuellen Situation sind.", "metrics": {"bleu_score": 28.461430654409302, "chrf_score": 72.19741626443664, "xcomet_score": 0.9873918294906616, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.6159895062446594, "metricx_qe_score": 0.41744446754455566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Tenant zwei Parties pro Woche und tut es.", "metrics": {"bleu_score": 8.953363688807181, "chrf_score": 39.2952470506415, "xcomet_score": 0.8192132115364075, "xcomet_qe_score": 0.73445063829422, "metricx_score": 12.17687702178955, "metricx_qe_score": 13.347423553466797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser als andere für die gesetzliche Artikel-Retrieval-Tasche geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen.", "metrics": {"bleu_score": 23.430072687678056, "chrf_score": 55.819191199600894, "xcomet_score": 0.809341311454773, "xcomet_qe_score": 0.7918623685836792, "metricx_score": 6.04911994934082, "metricx_qe_score": 5.7360992431640625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass all diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur Berechnung von gesetzlichen Artikeln weckt,", "metrics": {"bleu_score": 51.84989152196749, "chrf_score": 74.83617782566517, "xcomet_score": 0.8548610210418701, "xcomet_qe_score": 0.8328565359115601, "metricx_score": 4.398179531097412, "metricx_qe_score": 3.7656280994415283, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern.", "metrics": {"bleu_score": 91.93227152249175, "chrf_score": 94.685406447034, "xcomet_score": 0.9811796545982361, "xcomet_qe_score": 1.0, "metricx_score": 0.591306209564209, "metricx_qe_score": 0.3152727484703064, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Papier, Datset und Code unter den folgenden Links sehen. Vielen Dank.", "metrics": {"bleu_score": 21.57127321078917, "chrf_score": 58.54147525693244, "xcomet_score": 0.858016848564148, "xcomet_qe_score": 0.89958655834198, "metricx_score": 5.938584327697754, "metricx_qe_score": 4.167646884918213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorzustellen, einem unabhängigen Benchmark, der für die Testung von Vision- und Sprachmodellen mit bestimmten sprachlichen Phänomenen gedacht ist.", "metrics": {"bleu_score": 26.667088566593787, "chrf_score": 57.81630156664953, "xcomet_score": 0.7561835050582886, "xcomet_qe_score": 0.7813700437545776, "metricx_score": 4.312676906585693, "metricx_qe_score": 5.455072402954102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark festzulegen?", "metrics": {"bleu_score": 82.651681837938, "chrf_score": 80.38630974144311, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.32537293434143066, "metricx_qe_score": 0.2666904926300049, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformer-basierten Vision- und Sprachmodellen gesehen, die auf große Mengen an Bild-Textpaaren vorgebildet wurden.", "metrics": {"bleu_score": 33.379285320159624, "chrf_score": 66.4690879576001, "xcomet_score": 0.9556179046630859, "xcomet_qe_score": 0.9266349077224731, "metricx_score": 2.7823314666748047, "metricx_qe_score": 2.9802987575531006, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle drängt die Moderne in der Vision und Sprachaufgaben wie der Antwort auf visuelle Fragen, der visuellen Sinnesreasoning, der Bildherstellung und der Phrase-Grundung voran.", "metrics": {"bleu_score": 6.996703938075385, "chrf_score": 43.22210754706924, "xcomet_score": 0.6413124799728394, "xcomet_qe_score": 0.6372884511947632, "metricx_score": 10.358681678771973, "metricx_qe_score": 10.253867149353027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Nachricht erhalten. Die Genauigkeit dieser für die Aufgabe spezifischen Benchmarks steigt stetig.", "metrics": {"bleu_score": 12.151974811408735, "chrf_score": 68.45133660357344, "xcomet_score": 0.9864119291305542, "xcomet_qe_score": 0.9703723192214966, "metricx_score": 1.2042820453643799, "metricx_qe_score": 1.5025991201400757, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5102907419204712, "metricx_qe_score": 0.9778188467025757, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprachtransformer verstanden, als er diesem Bild und diesem Satz eine hohe Punktzahl zugewiesen hat, um es zu vereinbaren?", "metrics": {"bleu_score": 16.91896235111172, "chrf_score": 67.159698557499, "xcomet_score": 0.8179185390472412, "xcomet_qe_score": 0.8283472061157227, "metricx_score": 3.8477230072021484, "metricx_qe_score": 4.527521133422852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und der niedrige Punkt für diesen.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 48.13594515318653, "xcomet_score": 0.9152822494506836, "xcomet_qe_score": 0.9228225946426392, "metricx_score": 1.9398683309555054, "metricx_qe_score": 2.18253755569458, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?", "metrics": {"bleu_score": 20.90067144241745, "chrf_score": 60.27342618027498, "xcomet_score": 0.937651515007019, "xcomet_qe_score": 0.9570304155349731, "metricx_score": 1.4751598834991455, "metricx_qe_score": 0.4880390465259552, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie durch frühere Arbeiten gezeigt?", "metrics": {"bleu_score": 32.79475209724913, "chrf_score": 60.25426421758663, "xcomet_score": 0.9800937175750732, "xcomet_qe_score": 1.0, "metricx_score": 0.6111229658126831, "metricx_qe_score": 0.3809245824813843, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf diesen Aspekt zu werfen, schlagen wir eine tauschfreundlichere Richtung vor und führen VALS ein, das die Empfindlichkeit von Seh- und Sprachmodellen auf spezifische sprachliche Phänomene testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen.", "metrics": {"bleu_score": 60.638286758390784, "chrf_score": 77.58408121128699, "xcomet_score": 0.755540132522583, "xcomet_qe_score": 0.8046247959136963, "metricx_score": 5.478695869445801, "metricx_qe_score": 6.293959140777588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Vielfalt, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenzen ab.", "metrics": {"bleu_score": 54.11927503805856, "chrf_score": 69.6632527575247, "xcomet_score": 0.979097843170166, "xcomet_qe_score": 0.9833896160125732, "metricx_score": 1.407855749130249, "metricx_qe_score": 1.725205421447754, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen festgehalten haben?", "metrics": {"bleu_score": 25.470014226549075, "chrf_score": 53.76933835362032, "xcomet_score": 0.9838738441467285, "xcomet_qe_score": 0.9872679710388184, "metricx_score": 2.147519588470459, "metricx_qe_score": 0.7878751158714294, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor nur für Vision und Sprachmodelle von Ravi Shakar und seinen Mitarbeitern für Nomenphrasen angewendet wurde, und bei der Zählung von uns in früheren Arbeiten.", "metrics": {"bleu_score": 15.31305080006172, "chrf_score": 56.45959154952306, "xcomet_score": 0.6863709092140198, "xcomet_qe_score": 0.7944066524505615, "metricx_score": 5.65807580947876, "metricx_qe_score": 6.192378997802734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde, dass wir den Bildunterschrift eines Bildes nehmen und einen Foil erzeugen, indem wir den Unterschrift so verändern, dass er das Bild nicht mehr beschreibt.", "metrics": {"bleu_score": 50.79560247431461, "chrf_score": 68.99809551505058, "xcomet_score": 0.712786853313446, "xcomet_qe_score": 0.8649534583091736, "metricx_score": 7.714567184448242, "metricx_qe_score": 5.894965171813965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Wir ändern diese Phrase, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenz, wobei jedes Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, FOIL-Instanzen zu erstellen.", "metrics": {"bleu_score": 56.42185078203061, "chrf_score": 74.23225281076029, "xcomet_score": 0.8681907653808594, "xcomet_qe_score": 0.924911618232727, "metricx_score": 2.2390081882476807, "metricx_qe_score": 2.49796986579895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir im Fall des Aktionsstücks zwei Instrumente, eines, bei dem das Aktionsverb mit einer anderen Aktion geändert wird, und eines, bei dem die Spielzeuge ausgetauscht werden.", "metrics": {"bleu_score": 53.69557049919316, "chrf_score": 62.479517643131075, "xcomet_score": 0.782133936882019, "xcomet_qe_score": 0.661467432975769, "metricx_score": 9.422497749328613, "metricx_qe_score": 8.979730606079102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Ko-Referenzen sind auch Stücke, die mehr als ein Instrument haben.", "metrics": {"bleu_score": 57.57575636202256, "chrf_score": 70.29613583225184, "xcomet_score": 0.8746821880340576, "xcomet_qe_score": 0.879081130027771, "metricx_score": 3.9928081035614014, "metricx_qe_score": 3.933391571044922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schaffen diese Fehler, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererseits gültige Sätze sind.", "metrics": {"bleu_score": 52.83247772499191, "chrf_score": 65.79263721275098, "xcomet_score": 0.935880184173584, "xcomet_qe_score": 0.9653462767601013, "metricx_score": 3.659087896347046, "metricx_qe_score": 3.7799618244171143, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach, da eine fehlerhafte Beschreibung weniger wahrscheinlich sein kann als die ursprüngliche Beschreibung.", "metrics": {"bleu_score": 22.0294066346937, "chrf_score": 59.847331247213695, "xcomet_score": 0.9730410575866699, "xcomet_qe_score": 0.9865380525588989, "metricx_score": 1.0512547492980957, "metricx_qe_score": 0.8603147268295288, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es zwar nicht unmöglich, statistisch gesehen ist es weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann Pflanzen schneiden, und große Vision- und Sprachmodelle könnten dies aufgreifen.", "metrics": {"bleu_score": 25.597161701112118, "chrf_score": 66.91507405145592, "xcomet_score": 0.9102611541748047, "xcomet_qe_score": 0.9090164303779602, "metricx_score": 4.14935827255249, "metricx_qe_score": 3.615534782409668, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um gültige Folien zu erhalten, müssen wir daher Maßnahmen ergreifen.", "metrics": {"bleu_score": 8.91376552139813, "chrf_score": 38.578047913111064, "xcomet_score": 0.8997146487236023, "xcomet_qe_score": 0.9363779425621033, "metricx_score": 2.4536614418029785, "metricx_qe_score": 1.2772939205169678, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir starke Sprachmodelle, um FOILs vorzuschlagen.", "metrics": {"bleu_score": 58.14307369682194, "chrf_score": 67.37635539415918, "xcomet_score": 0.8979828357696533, "xcomet_qe_score": 0.8766951560974121, "metricx_score": 3.620567798614502, "metricx_qe_score": 3.3924455642700195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir die Inferenz durch natürliche Sprache oder kurz NLI, um Folien zu filtern, die das Bild noch beschreiben könnten, da wir bei der Konstruktion von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben.", "metrics": {"bleu_score": 53.84404781457109, "chrf_score": 76.62265828990705, "xcomet_score": 0.746366024017334, "xcomet_qe_score": 0.8407917618751526, "metricx_score": 5.644924640655518, "metricx_qe_score": 3.865727186203003, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir eine Schlussfolgerung aus natürlicher Sprache mit der folgenden Begründung an.", "metrics": {"bleu_score": 53.09354663044073, "chrf_score": 69.95225710419113, "xcomet_score": 0.9974220991134644, "xcomet_qe_score": 0.9878330230712891, "metricx_score": 1.6489238739013672, "metricx_qe_score": 0.97169429063797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Beschriftung als die damit verbundene Hypothese.", "metrics": {"bleu_score": 76.70387248467661, "chrf_score": 82.34885367566889, "xcomet_score": 0.9998939037322998, "xcomet_qe_score": 0.9993104934692383, "metricx_score": 0.2751620411872864, "metricx_qe_score": 0.2713712453842163, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In addition, wir betrachten die Kaption als die Premise und die FOIL als ihre Hypothese.", "metrics": {"bleu_score": 19.345299022826186, "chrf_score": 40.811001647132464, "xcomet_score": 0.4700871407985687, "xcomet_qe_score": 0.7669479846954346, "metricx_score": 8.251925468444824, "metricx_qe_score": 7.679128170013428, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell die FOIL als widersprechend oder neutral gegenüber dem Untertitel vorhersagt, nehmen wir dies als Indikator für eine gültige FOIL.", "metrics": {"bleu_score": 16.641949185944824, "chrf_score": 48.979718002446035, "xcomet_score": 0.721297562122345, "xcomet_qe_score": 0.7804070711135864, "metricx_score": 5.134280681610107, "metricx_qe_score": 3.139145612716675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Folie durch den Untertitel enthalten ist, kann es keine gute Folie sein, da sie durch Transitivität eine wahrhaftige Beschreibung des Bildes liefert und wir diese Folien ausfiltern.", "metrics": {"bleu_score": 47.1554172375178, "chrf_score": 60.22607414267248, "xcomet_score": 0.6820354461669922, "xcomet_qe_score": 0.7459830641746521, "metricx_score": 3.8974339962005615, "metricx_qe_score": 3.293330192565918, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Prozedere ist nicht perfekt. Es ist nur ein Indikator für valide Foil.", "metrics": {"bleu_score": 19.56475149792291, "chrf_score": 42.382453748293074, "xcomet_score": 0.8356159925460815, "xcomet_qe_score": 0.8604563474655151, "metricx_score": 5.997078895568848, "metricx_qe_score": 5.109023094177246, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Erstellung gültiger FOILs menschliche Annotatoren, um die in Valse verwendeten Daten zu validieren.", "metrics": {"bleu_score": 45.00713667765254, "chrf_score": 69.24006783957822, "xcomet_score": 0.929293155670166, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.942647933959961, "metricx_qe_score": 2.8552730083465576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir also so viele Testfälle wie in dieser Tabelle beschrieben.", "metrics": {"bleu_score": 65.35194995338728, "chrf_score": 77.2447133881458, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.863872766494751, "metricx_qe_score": 0.7803686857223511, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten.", "metrics": {"bleu_score": 28.025542898280413, "chrf_score": 81.78857772591213, "xcomet_score": 0.9688535928726196, "xcomet_qe_score": 0.9927035570144653, "metricx_score": 0.4330703616142273, "metricx_qe_score": 0.8924462795257568, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um einen Benchmark für Null-Schuss-Tests handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vorausbildung nutzt.", "metrics": {"bleu_score": 47.209241370742745, "chrf_score": 69.07085986923144, "xcomet_score": 0.825871467590332, "xcomet_qe_score": 0.8716428875923157, "metricx_score": 3.28236722946167, "metricx_qe_score": 4.520754337310791, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Die Feinabstimmung würde es den Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen.", "metrics": {"bleu_score": 83.94327083733333, "chrf_score": 89.37304727917113, "xcomet_score": 0.9919897317886353, "xcomet_qe_score": 0.9947028160095215, "metricx_score": 0.34541529417037964, "metricx_qe_score": 0.3227079212665558, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nutzen.", "metrics": {"bleu_score": 32.55964126200301, "chrf_score": 68.11454010420653, "xcomet_score": 0.994429349899292, "xcomet_qe_score": 0.9989796876907349, "metricx_score": 0.5656729936599731, "metricx_qe_score": 0.6740055084228516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vorausbildung haben.", "metrics": {"bleu_score": 19.28576545653752, "chrf_score": 59.519286589672305, "xcomet_score": 0.9729781150817871, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 1.4264262914657593, "metricx_qe_score": 1.2057727575302124, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen auf Vowels, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin I und VisualBERT.", "metrics": {"bleu_score": 33.78892373468243, "chrf_score": 62.23172497223574, "xcomet_score": 0.556437611579895, "xcomet_qe_score": 0.518257737159729, "metricx_score": 6.479284286499023, "metricx_qe_score": 6.384301662445068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bilder-Satzpaaren in Untertitel und FOILs.", "metrics": {"bleu_score": 41.2295470431275, "chrf_score": 61.04691546357115, "xcomet_score": 0.8727771639823914, "xcomet_qe_score": 0.8745120763778687, "metricx_score": 3.4691667556762695, "metricx_qe_score": 3.052098035812378, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht ist für dieses Video relevanter, dass wir unsere permissivere Metrik, die Paargenauigkeit, präsentieren, die misst, ob der Ausrichtungswert des Bildesatzes für das korrekte Textpaar des Bildes höher ist als für das fehlerhafte Paar.", "metrics": {"bleu_score": 19.494801320323692, "chrf_score": 55.78563750543076, "xcomet_score": 0.847081184387207, "xcomet_qe_score": 0.8491345643997192, "metricx_score": 2.0271592140197754, "metricx_qe_score": 2.2375924587249756, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Metriken und Ergebnisse zu diesen Ergebnissen finden Sie in unserer Arbeit.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 72.69177085158765, "xcomet_score": 0.9674638509750366, "xcomet_qe_score": 0.9433743953704834, "metricx_score": 1.7824245691299438, "metricx_qe_score": 2.310990333557129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit Paar-Präzision sind hier gezeigt und entsprechen den Ergebnissen, die wir aus den anderen Metriken erhalten haben. Die beste Leistung bei Nullschüssen wird von Wilbert zwölf in einem, gefolgt von Wilbert, LXMert, Clip und schließlich VisualBird erreicht.", "metrics": {"bleu_score": 20.139171742413726, "chrf_score": 56.2264292892386, "xcomet_score": 0.514572262763977, "xcomet_qe_score": 0.5249951481819153, "metricx_score": 8.699220657348633, "metricx_qe_score": 7.81168794631958, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert Twelve in One fast gelöst werden, wobei er hervorhebt, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren.", "metrics": {"bleu_score": 55.220601914360635, "chrf_score": 71.14457043590988, "xcomet_score": 0.7640768885612488, "xcomet_qe_score": 0.6785810589790344, "metricx_score": 4.699469566345215, "metricx_qe_score": 4.459653854370117, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann in unseren Adversarial Foiling-Einstellungen keine der verbleibenden Teile zuverlässig gelöst werden", "metrics": {"bleu_score": 20.953980708003318, "chrf_score": 59.01116500002169, "xcomet_score": 0.8371217250823975, "xcomet_qe_score": 0.8343689441680908, "metricx_score": 1.7737377882003784, "metricx_qe_score": 1.6043870449066162, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäten und Zählungsinstrumenten sehen wir, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen.", "metrics": {"bleu_score": 71.26809516383486, "chrf_score": 85.5495546323331, "xcomet_score": 0.942151665687561, "xcomet_qe_score": 0.8356202840805054, "metricx_score": 2.008349657058716, "metricx_qe_score": 2.3539867401123047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren,", "metrics": {"bleu_score": 57.70362357478205, "chrf_score": 72.45319341499791, "xcomet_score": 0.8557186126708984, "xcomet_qe_score": 0.8347682952880859, "metricx_score": 3.697047233581543, "metricx_qe_score": 3.59826922416687, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Aktionen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie durch plausibel Vorurteile unterstützt werden, wie wir im Aktionsteil sehen.", "metrics": {"bleu_score": 53.991235460113415, "chrf_score": 70.87278555081208, "xcomet_score": 0.8533157110214233, "xcomet_qe_score": 0.8832628726959229, "metricx_score": 3.7894954681396484, "metricx_qe_score": 3.2046568393707275, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Bereich erfahren wir, dass es für Vision- und Sprachmodelle ebenfalls schwierig ist, mehrere Referenzen auf das gleiche Objekt in einem Bild mit Pronomen zu verfolgen.", "metrics": {"bleu_score": 12.64203703898735, "chrf_score": 50.724643182033724, "xcomet_score": 0.9023610949516296, "xcomet_qe_score": 0.8831861019134521, "metricx_score": 3.2084267139434814, "metricx_qe_score": 3.4374210834503174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Verstandskontrolle und weil es ein interessantes Experiment ist, haben wir auch zwei Textmodelle, GPT eins und GPT zwei, benchmarkt, um zu beurteilen, ob Valse durch diese Einmodalmodelle gelöst werden kann, indem wir die Verwirrung der richtigen und der fehlgeschlagenen Beschriftung berechnen und den Eintrag mit der geringsten Verwirrung vorhersagen.", "metrics": {"bleu_score": 23.331485114614456, "chrf_score": 51.16864426840171, "xcomet_score": 0.7611198425292969, "xcomet_qe_score": 0.7902347445487976, "metricx_score": 5.819832801818848, "metricx_qe_score": 5.415518760681152, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die FOIL höher ist, nehmen wir dies als Hinweis darauf, dass die FOIL-Beschriftung unter einer plausibilen Voreingenommenheit oder anderen sprachlichen Voreingenommenheiten leidet.", "metrics": {"bleu_score": 13.547277341758472, "chrf_score": 46.80029983129196, "xcomet_score": 0.7275965213775635, "xcomet_qe_score": 0.7005345225334167, "metricx_score": 7.565669059753418, "metricx_qe_score": 5.784390449523926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die Text nur GPT Modelle die Plausibilität der Welt besser erfassen haben als die Vision und Language Modelle.", "metrics": {"bleu_score": 47.689559976337705, "chrf_score": 71.73051067385403, "xcomet_score": 0.8261486291885376, "xcomet_qe_score": 0.876244068145752, "metricx_score": 7.251726150512695, "metricx_qe_score": 6.4801249504089355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALS ein Benchmark ist, der die Linse der sprachlichen Konstruktionen nutzt, um der Community bei der Verbesserung von Seh- und Sprachmodellen zu helfen, indem sie ihre visuellen Grundlagefähigkeiten hart testet.", "metrics": {"bleu_score": 42.407646773944236, "chrf_score": 66.07320464143356, "xcomet_score": 0.8716446161270142, "xcomet_qe_score": 0.9295735359191895, "metricx_score": 4.887662887573242, "metricx_qe_score": 5.072301387786865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu begründen, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren.", "metrics": {"bleu_score": 66.46636447461488, "chrf_score": 81.32679503506273, "xcomet_score": 0.9109614491462708, "xcomet_qe_score": 0.8898153305053711, "metricx_score": 2.9025185108184814, "metricx_qe_score": 2.6590914726257324, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich ermutigen, VALS zur Messung des Fortschritts hin zur Sprachbasis mit Vision und Sprachmodellen zu verwenden.", "metrics": {"bleu_score": 27.039317946553588, "chrf_score": 67.9433367644118, "xcomet_score": 0.9029144644737244, "xcomet_qe_score": 0.9150348901748657, "metricx_score": 4.920778751373291, "metricx_qe_score": 5.0213751792907715, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, VALS könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von VALS getesteten Aspekte hilft.", "metrics": {"bleu_score": 51.55089182862425, "chrf_score": 72.89398552294128, "xcomet_score": 0.9729731678962708, "xcomet_qe_score": 0.978485107421875, "metricx_score": 0.5716334581375122, "metricx_qe_score": 0.5937699675559998, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, sollten Sie sich die Walls-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren.", "metrics": {"bleu_score": 46.27590631131124, "chrf_score": 69.2779506667768, "xcomet_score": 0.8767817616462708, "xcomet_qe_score": 0.8784022331237793, "metricx_score": 4.793943405151367, "metricx_qe_score": 5.032374382019043, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizura von der Universität Tokio.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 85.90010292854612, "xcomet_score": 0.8645148277282715, "xcomet_qe_score": 0.91205233335495, "metricx_score": 2.0298497676849365, "metricx_qe_score": 1.0224183797836304, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde eine Papier entitelt RNSAM, ein Large Scale DSET für automatische Risikogrammierung beim Commitologizieren präsentieren.", "metrics": {"bleu_score": 4.023854200837977, "chrf_score": 28.68059661970152, "xcomet_score": 0.6199290752410889, "xcomet_qe_score": 0.6556020975112915, "metricx_score": 13.543465614318848, "metricx_qe_score": 15.163990020751953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären", "metrics": {"bleu_score": 43.29820146406896, "chrf_score": 85.6859213126352, "xcomet_score": 0.9804357290267944, "xcomet_qe_score": 0.9768197536468506, "metricx_score": 0.4799310266971588, "metricx_qe_score": 0.8654665946960449, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikogenerierung vorstellen, an der wir in dieser Forschung arbeiten.", "metrics": {"bleu_score": 71.9548353625319, "chrf_score": 79.57353811929666, "xcomet_score": 0.7581674456596375, "xcomet_qe_score": 0.7736640572547913, "metricx_score": 7.358946800231934, "metricx_qe_score": 5.640221118927002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNote ist ein technisches Dokument, das die bei jeder Veröffentlichung eines Softwareprodukts zusammenfasst.", "metrics": {"bleu_score": 31.898741882585618, "chrf_score": 56.880319872902795, "xcomet_score": 0.7309894561767578, "xcomet_qe_score": 0.6944110989570618, "metricx_score": 8.174102783203125, "metricx_qe_score": 7.51803731918335, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Restnoten für Bosch 2.6", "metrics": {"bleu_score": 15.181939159382823, "chrf_score": 24.307160911267108, "xcomet_score": 0.21148182451725006, "xcomet_qe_score": 0.19765949249267578, "metricx_score": 14.448304176330566, "metricx_qe_score": 22.562685012817383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "User Us Library These Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consuming, um manuell zu erstellen.", "metrics": {"bleu_score": 7.929026506841378, "chrf_score": 41.301685179714305, "xcomet_score": 0.5190500020980835, "xcomet_qe_score": 0.5087466239929199, "metricx_score": 18.809200286865234, "metricx_qe_score": 19.646493911743164, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, hochwertige Release-Noten automatisch zu erzeugen.", "metrics": {"bleu_score": 29.282980137146964, "chrf_score": 49.48389977577766, "xcomet_score": 0.993178129196167, "xcomet_qe_score": 0.9844765663146973, "metricx_score": 1.2427794933319092, "metricx_qe_score": 0.8050544261932373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Frischknotengenerierung verweisen.", "metrics": {"bleu_score": 12.320255516768906, "chrf_score": 59.05041721887583, "xcomet_score": 0.804276704788208, "xcomet_qe_score": 0.8013770580291748, "metricx_score": 6.5767388343811035, "metricx_qe_score": 5.468373775482178, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste System, das Arena erstellt wurde, wurde 2014 erstellt.", "metrics": {"bleu_score": 5.977325737924353, "chrf_score": 24.24088766241522, "xcomet_score": 0.8873231410980225, "xcomet_qe_score": 0.8405665159225464, "metricx_score": 7.492522239685059, "metricx_qe_score": 7.779673099517822, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert eine ruralbasierte Approach, zum Beispiel, indem man die Change Extractor verwendet, um Code differenzen, Bibliothekänder und Dokumentenänderungen von den differenzen zwischen Releases zu extrahieren, und schließlich kombinieren sie.", "metrics": {"bleu_score": 7.511251053510193, "chrf_score": 55.526186786518004, "xcomet_score": 0.5654106736183167, "xcomet_qe_score": 0.6481398344039917, "metricx_score": 16.02980613708496, "metricx_qe_score": 14.644018173217773, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das bemerkenswerteste Merkmal dieses Systems ist der Ausgaben-Extraktor in der oberen rechten Ecke,", "metrics": {"bleu_score": 44.534504264163466, "chrf_score": 68.59919757898543, "xcomet_score": 0.9343440532684326, "xcomet_qe_score": 0.8924262523651123, "metricx_score": 1.1398069858551025, "metricx_qe_score": 2.0149643421173096, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dieses muss mit dem Issues-Ökosystem verbunden sein und kann nur auf Projekte mit Null angewendet werden.", "metrics": {"bleu_score": 21.276310863176104, "chrf_score": 46.267820728648225, "xcomet_score": 0.5886179804801941, "xcomet_qe_score": 0.6103097200393677, "metricx_score": 13.746739387512207, "metricx_qe_score": 13.07121467590332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden.", "metrics": {"bleu_score": 58.56596027429396, "chrf_score": 87.83355213781319, "xcomet_score": 0.8732229471206665, "xcomet_qe_score": 0.8544350266456604, "metricx_score": 1.5768228769302368, "metricx_qe_score": 3.2770819664001465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist Grief. Dies entweder angesagt in 2014.", "metrics": {"bleu_score": 8.139165682360764, "chrf_score": 28.493978713893416, "xcomet_score": 0.1752816140651703, "xcomet_qe_score": 0.2769286036491394, "metricx_score": 18.89848518371582, "metricx_qe_score": 11.30698013305664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "2020. Es ist auf dem Internet verfügbar und kann via PIP gespeichert werden.", "metrics": {"bleu_score": 22.229849552064017, "chrf_score": 61.08225437568524, "xcomet_score": 0.7462169528007507, "xcomet_qe_score": 0.746465802192688, "metricx_score": 9.300413131713867, "metricx_qe_score": 6.960263252258301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches Textklassifizierungsmodell basierendes auf Lernen und Ausgaben aus fünf Labors, wie z. B. Funktionen oder Fehlerbehebungen, für jede Eingabe-Kommentarnachricht.", "metrics": {"bleu_score": 24.45874991538772, "chrf_score": 61.169107588526174, "xcomet_score": 0.7408525943756104, "xcomet_qe_score": 0.7569684386253357, "metricx_score": 9.397934913635254, "metricx_qe_score": 9.493619918823242, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Sample-User, das eine Korrektur für Fehlerkorrekturen erhält.", "metrics": {"bleu_score": 13.873271045271656, "chrf_score": 40.00500740781729, "xcomet_score": 0.6788672208786011, "xcomet_qe_score": 0.6441960334777832, "metricx_score": 8.598645210266113, "metricx_qe_score": 8.575394630432129, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingdaten sind sehr klein, etwa fünftausend, und werden in den Experimenten beschriebenen unten gezeigt.", "metrics": {"bleu_score": 28.763445389425833, "chrf_score": 65.29542939794064, "xcomet_score": 0.879939079284668, "xcomet_qe_score": 0.8749933242797852, "metricx_score": 6.014865875244141, "metricx_qe_score": 7.102064609527588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Kreuzschaltmodells ist nicht höher.", "metrics": {"bleu_score": 23.356898886410015, "chrf_score": 54.37519742865342, "xcomet_score": 0.9184908866882324, "xcomet_qe_score": 0.8585093021392822, "metricx_score": 5.421529293060303, "metricx_qe_score": 6.7683796882629395, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen.", "metrics": {"bleu_score": 8.002345513587947, "chrf_score": 61.25495583377509, "xcomet_score": 0.9839810132980347, "xcomet_qe_score": 0.9870116710662842, "metricx_score": 1.3270325660705566, "metricx_qe_score": 0.6275477409362793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier löst diese beiden Probleme und erzeugt automatisch hochwertige Freigabe-Noten.", "metrics": {"bleu_score": 25.670705659941795, "chrf_score": 60.06777016918584, "xcomet_score": 0.8088830709457397, "xcomet_qe_score": 0.8659015893936157, "metricx_score": 3.489234685897827, "metricx_qe_score": 2.1904139518737793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das begrenzte Anwendungsprogramm schlagen wir eine hochwertige Klassifizierungsmethode mit nur Kommentarmeldungen als Eingabe vor.", "metrics": {"bleu_score": 8.560693512989548, "chrf_score": 41.73061944935921, "xcomet_score": 0.8859319686889648, "xcomet_qe_score": 0.8390735387802124, "metricx_score": 6.613797664642334, "metricx_qe_score": 6.439456939697266, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Repositories verwendet werden.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.292210191488266, "metricx_qe_score": 0.5091390013694763, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der Skarbstaatressourcen haben wir eine RNSAM DSET konsistent mit etwa 82.000 Datenpunkten erstellt, indem wir Daten aus öffentlichen GitHub Repositories mit der GitHub API erstellen.", "metrics": {"bleu_score": 16.192487668354385, "chrf_score": 54.81378758619976, "xcomet_score": 0.7650055289268494, "xcomet_qe_score": 0.7592325210571289, "metricx_score": 11.881031036376953, "metricx_qe_score": 12.02031135559082, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unsere Daseinsetzung.", "metrics": {"bleu_score": 7.492442692259767, "chrf_score": 50.9118260758217, "xcomet_score": 0.8746144771575928, "xcomet_qe_score": 0.8692095279693604, "metricx_score": 5.149682521820068, "metricx_qe_score": 4.209080219268799, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten.", "metrics": {"bleu_score": 19.721218241637786, "chrf_score": 60.614263059545905, "xcomet_score": 0.9531964063644409, "xcomet_qe_score": 0.9582484364509583, "metricx_score": 0.32169288396835327, "metricx_qe_score": 0.6557445526123047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Nachricht des Komitees und die rechte Seite ist die Release-Note.", "metrics": {"bleu_score": 6.437165254072419, "chrf_score": 37.2010778382343, "xcomet_score": 0.9211947917938232, "xcomet_qe_score": 0.8709730505943298, "metricx_score": 4.921026706695557, "metricx_qe_score": 4.4305620193481445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Riesen sind als Verbesserungen, Verbesserungen, etc. gelobt.", "metrics": {"bleu_score": 23.462350320527996, "chrf_score": 42.34311679348026, "xcomet_score": 0.3482385277748108, "xcomet_qe_score": 0.2591114044189453, "metricx_score": 15.330699920654297, "metricx_qe_score": 16.317522048950195, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Kommentarnachrichten als Eingaben aufnimmt und die Raveled-Please-Notizen ausgibt.", "metrics": {"bleu_score": 43.37367531754813, "chrf_score": 58.44554487776249, "xcomet_score": 0.6836458444595337, "xcomet_qe_score": 0.6228920817375183, "metricx_score": 9.055990219116211, "metricx_qe_score": 8.758384704589844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassungsaufgabe angesehen werden.", "metrics": {"bleu_score": 27.890014303843827, "chrf_score": 66.95611082724527, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.02184990420937538, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Rubber, Funktionen, Verbesserungen, Fehlerbehebungen, Deprekationen, Entfernungen und Bremsänderungen vorgedefiniert.", "metrics": {"bleu_score": 33.49923255785667, "chrf_score": 60.21026840517286, "xcomet_score": 0.5944589376449585, "xcomet_qe_score": 0.626465916633606, "metricx_score": 16.17079734802246, "metricx_qe_score": 17.3189697265625, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden aufgrund früherer Forschung und anderer Faktoren festgelegt.", "metrics": {"bleu_score": 15.228763726734105, "chrf_score": 65.7997976700448, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08747155964374542, "metricx_qe_score": 0.16953018307685852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Rhythmus-Noten unten rechts werden aus den Rhythmus-Noten unten links abgezogen.", "metrics": {"bleu_score": 12.605968092174914, "chrf_score": 36.74213976348311, "xcomet_score": 0.7797129154205322, "xcomet_qe_score": 0.9442474246025085, "metricx_score": 6.375714302062988, "metricx_qe_score": 2.412931442260742, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Moment müssen die vier Schuttwerke, die im Voraus aufgestellt wurden, entdeckt werden.", "metrics": {"bleu_score": 25.772294506990857, "chrf_score": 55.98892292464745, "xcomet_score": 0.7954685091972351, "xcomet_qe_score": 0.778599202632904, "metricx_score": 7.424459934234619, "metricx_qe_score": 6.850994110107422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Lager sind nicht immer mit jeder Freiheit übereinstimmen", "metrics": {"bleu_score": 15.187207110382285, "chrf_score": 34.90384030428982, "xcomet_score": 0.6053958535194397, "xcomet_qe_score": 0.5906176567077637, "metricx_score": 8.469849586486816, "metricx_qe_score": 7.042261600494385, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, um Verbesserungen zu treffen, zu erhöhen, Verbesserungen, Verbesserungen, Optimierungen und so weiter.", "metrics": {"bleu_score": 26.529518334824456, "chrf_score": 61.685902060647855, "xcomet_score": 0.5204595923423767, "xcomet_qe_score": 0.6241966485977173, "metricx_score": 16.64788055419922, "metricx_qe_score": 18.31146240234375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabulärliste mit etwa 30 Numbers für jede dieser Rotationsvariationen erstellt.", "metrics": {"bleu_score": 26.332019392396344, "chrf_score": 62.123316579200285, "xcomet_score": 0.7278054356575012, "xcomet_qe_score": 0.8043904900550842, "metricx_score": 8.791613578796387, "metricx_qe_score": 10.102285385131836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Restnotkrasten zu erkennen und den Text der Restnotkrasten zu korrigieren.", "metrics": {"bleu_score": 4.665819907464467, "chrf_score": 22.084797229686124, "xcomet_score": 0.14835070073604584, "xcomet_qe_score": 0.13552875816822052, "metricx_score": 14.272387504577637, "metricx_qe_score": 9.503087997436523, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Komiteemeldung.", "metrics": {"bleu_score": 10.682175159905853, "chrf_score": 29.794310127762664, "xcomet_score": 0.9082239270210266, "xcomet_qe_score": 0.9315637946128845, "metricx_score": 5.043644905090332, "metricx_qe_score": 4.383716583251953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachrichten des Komitees sind nicht an jede Stimme gebunden.", "metrics": {"bleu_score": 17.542198478193427, "chrf_score": 48.57929928623042, "xcomet_score": 0.7140756845474243, "xcomet_qe_score": 0.7041932344436646, "metricx_score": 5.7219390869140625, "metricx_qe_score": 4.873945713043213, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der image below, wenn die aktuelle Realität Boson zwei Punkt fünf zwei neunzehn, müssen wir die IDECHTEN", "metrics": {"bleu_score": 6.023546525077816, "chrf_score": 27.18461990819639, "xcomet_score": 0.2092178910970688, "xcomet_qe_score": 0.4476088285446167, "metricx_score": 23.929672241210938, "metricx_qe_score": 23.453628540039062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "erfüllt die vorherige Version 2.5218 und erhält einen Tiff. Dies ist ein bisschen mühsam und es reicht nicht aus, nur eine Liste der Releases zu erhalten und sich die Vorher und Nachher anzusehen.", "metrics": {"bleu_score": 28.215396128745784, "chrf_score": 57.20222970267726, "xcomet_score": 0.48854896426200867, "xcomet_qe_score": 0.2572837471961975, "metricx_score": 13.8690824508667, "metricx_qe_score": 14.841413497924805, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine Heuristik, die mit Ihnen übereinstimmt, um die vorherigen und nächsten Schauspielzeiten zu erhalten.", "metrics": {"bleu_score": 9.629943614188138, "chrf_score": 43.3982817862624, "xcomet_score": 0.6521668434143066, "xcomet_qe_score": 0.63475501537323, "metricx_score": 11.3953218460083, "metricx_qe_score": 9.666778564453125, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind die Horses.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 12.44254216164827, "xcomet_score": 0.12343449145555496, "xcomet_qe_score": 0.09086182713508606, "metricx_score": 7.029128074645996, "metricx_qe_score": 11.35456371307373, "linguapy_score": [1, "AFRIKAANS"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "In der Hand, siebentausend zwei hundert Repositories", "metrics": {"bleu_score": 4.300847718252331, "chrf_score": 30.99826373797581, "xcomet_score": 0.18082661926746368, "xcomet_qe_score": 0.1666475236415863, "metricx_score": 21.241378784179688, "metricx_qe_score": 20.963376998901367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Token 63, was für eine Zusammenfassungsaufgabe ziemlich hoch ist.", "metrics": {"bleu_score": 48.06604068305993, "chrf_score": 71.21479449866088, "xcomet_score": 0.8789277076721191, "xcomet_qe_score": 0.963732123374939, "metricx_score": 3.3450722694396973, "metricx_qe_score": 2.5947115421295166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Nummer der Unique Tokens ist bei Roger at eight thousand eight hundred thirty thousand.", "metrics": {"bleu_score": 5.751391809950023, "chrf_score": 24.12518505706669, "xcomet_score": 0.711956262588501, "xcomet_qe_score": 0.7142471671104431, "metricx_score": 14.94591236114502, "metricx_qe_score": 11.813590049743652, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl von einzigartigen Kasten und Methoden im Repertory.", "metrics": {"bleu_score": 6.272848091762075, "chrf_score": 38.91103850905497, "xcomet_score": 0.770775556564331, "xcomet_qe_score": 0.798672080039978, "metricx_score": 8.413198471069336, "metricx_qe_score": 8.611305236816406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes erkläre ich die vorgeschlagene Methode.", "metrics": {"bleu_score": 33.764591090632756, "chrf_score": 65.81520524166675, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.03903842344880104, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Querschnitts-, Extraktions- und Abstruktionsmodell besteht aus zwei neuer Modulen", "metrics": {"bleu_score": 13.832283585102266, "chrf_score": 40.02661775244455, "xcomet_score": 0.6678214073181152, "xcomet_qe_score": 0.7549773454666138, "metricx_score": 4.997828483581543, "metricx_qe_score": 4.0934624671936035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifier mit Bot oder Code Bot und ein Generator mit Bot.", "metrics": {"bleu_score": 13.674406678232565, "chrf_score": 46.13112282223199, "xcomet_score": 0.6331063508987427, "xcomet_qe_score": 0.6624966263771057, "metricx_score": 10.354714393615723, "metricx_qe_score": 9.862481117248535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Klassifizierer, um jede Kommentarnachricht in fünf RESNOT-Klassen zu klassifizieren: Funktionen, Verbesserungen, Fehlerbehebungen, Duplizierungen und andere.", "metrics": {"bleu_score": 15.542549544776186, "chrf_score": 58.65476671627351, "xcomet_score": 0.669029951095581, "xcomet_qe_score": 0.668574333190918, "metricx_score": 7.508017539978027, "metricx_qe_score": 7.27005672454834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als anderer eingestuften Komitee-Nachrichten werden abgelehnt.", "metrics": {"bleu_score": 13.888095170058955, "chrf_score": 52.74631106730009, "xcomet_score": 0.7265368103981018, "xcomet_qe_score": 0.7435082793235779, "metricx_score": 5.121799945831299, "metricx_qe_score": 4.711184978485107, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GAS den Generator unabhängig auf die vier Rudder-Dokumente an und erzeugt für jede Klasse Risikonode.", "metrics": {"bleu_score": 17.102846954548706, "chrf_score": 52.56948877461042, "xcomet_score": 0.6043830513954163, "xcomet_qe_score": 0.61778324842453, "metricx_score": 12.934401512145996, "metricx_qe_score": 13.760366439819336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Übereinstimmungen zwischen Commit-Nachrichten und Lesemerkungen nicht bekannt.", "metrics": {"bleu_score": 43.748114312246464, "chrf_score": 68.96275423382427, "xcomet_score": 0.9519575834274292, "xcomet_qe_score": 0.8837037086486816, "metricx_score": 2.1884312629699707, "metricx_qe_score": 3.55076265335083, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifizierer zu trainieren, weisen wir jeder Eingabe-Commit-Nachricht Pseudorabben zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden.", "metrics": {"bleu_score": 27.33459421111296, "chrf_score": 64.25777582516598, "xcomet_score": 0.9152083396911621, "xcomet_qe_score": 0.9328683018684387, "metricx_score": 6.59580135345459, "metricx_qe_score": 6.266417503356934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Kreuzstreifen-Abstruktiv-Summersätze durch zwei verschiedene Methoden.", "metrics": {"bleu_score": 23.668206578270116, "chrf_score": 45.21861963578915, "xcomet_score": 0.8542428016662598, "xcomet_qe_score": 0.8501884341239929, "metricx_score": 9.658515930175781, "metricx_qe_score": 7.760385036468506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzigen SEC-Netzwerk und generiert einen einzigen Long-SNode-Text, der eine Kombination von Eingabe-Commit-Nachrichten liefert.", "metrics": {"bleu_score": 40.86010354525494, "chrf_score": 66.09363363371537, "xcomet_score": 0.5684828758239746, "xcomet_qe_score": 0.5424466133117676, "metricx_score": 11.618022918701172, "metricx_qe_score": 11.936394691467285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgangstext kann in Kreuzzeichen aufgeteilt werden, basierend auf speziellen Kreuz-Spezifischen Endpunkt-Symbolen.", "metrics": {"bleu_score": 3.4815016528590457, "chrf_score": 38.17243420697298, "xcomet_score": 0.795761227607727, "xcomet_qe_score": 0.7977925539016724, "metricx_score": 9.971556663513184, "metricx_qe_score": 8.812610626220703, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSMarch nennen, besteht aus vier verschiedenen SEC-to-SEC-Netzwerken, von denen jede einer der RES-Knotenklassen entspricht.", "metrics": {"bleu_score": 48.81873576627694, "chrf_score": 69.1630948140261, "xcomet_score": 0.5984008312225342, "xcomet_qe_score": 0.6035414934158325, "metricx_score": 10.01715087890625, "metricx_qe_score": 10.152763366699219, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das macht Spain's Experiment.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 28.046840246121068, "xcomet_score": 0.2660254240036011, "xcomet_qe_score": 0.40116316080093384, "metricx_score": 10.159089088439941, "metricx_qe_score": 10.633895874023438, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: CS, CS Single, CS Smart, Russelling und die vorherige Studienbeschreibung.", "metrics": {"bleu_score": 5.577144216540393, "chrf_score": 46.17795048274229, "xcomet_score": 0.6181114912033081, "xcomet_qe_score": 0.5756763815879822, "metricx_score": 12.225008010864258, "metricx_qe_score": 11.805715560913086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Abrissung sind in einigen Fällen diese Noten in mehreren Sätzen ausgeführt.", "metrics": {"bleu_score": 14.913001954344919, "chrf_score": 46.93168749499843, "xcomet_score": 0.7887320518493652, "xcomet_qe_score": 0.8224109411239624, "metricx_score": 9.533082008361816, "metricx_qe_score": 8.719610214233398, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt.", "metrics": {"bleu_score": 77.09002428237393, "chrf_score": 90.47656401175612, "xcomet_score": 0.876798689365387, "xcomet_qe_score": 0.8787704706192017, "metricx_score": 5.31808614730835, "metricx_qe_score": 6.5746684074401855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro ist penetrativ, wenn das System einen kurzen Satz ausgibt", "metrics": {"bleu_score": 56.41985990655355, "chrf_score": 61.83988458294585, "xcomet_score": 0.730949342250824, "xcomet_qe_score": 0.7268795967102051, "metricx_score": 13.445451736450195, "metricx_qe_score": 14.262231826782227, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Brauvolumen. In den als nächstes beschriebenen Experimentenergebnissen", "metrics": {"bleu_score": 12.571192676522521, "chrf_score": 46.966544542355415, "xcomet_score": 0.6231405138969421, "xcomet_qe_score": 0.7097833156585693, "metricx_score": 12.667922973632812, "metricx_qe_score": 12.553022384643555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erzeugen wir auch eine Spezifität, da Rouge und Brux nicht erzeugt werden können, wenn die Riesen-Knoten leer sind.", "metrics": {"bleu_score": 30.09429889037877, "chrf_score": 54.97451393373668, "xcomet_score": 0.7209169864654541, "xcomet_qe_score": 0.7218561768531799, "metricx_score": 13.903860092163086, "metricx_qe_score": 14.039729118347168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass die Modellprojekte ausgegeben sind, die in Fällen, in denen die Reasonals empfangen, empfindlich sind.", "metrics": {"bleu_score": 32.998954725277926, "chrf_score": 50.48053185381741, "xcomet_score": 0.31978124380111694, "xcomet_qe_score": 0.22679753601551056, "metricx_score": 20.53213119506836, "metricx_qe_score": 20.337764739990234, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse.", "metrics": {"bleu_score": 42.72870063962342, "chrf_score": 48.96283815298874, "xcomet_score": 0.9982582330703735, "xcomet_qe_score": 0.9951757192611694, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Daseit Emailadresse, Hashbarriers, etc. enthält, erweitern wir auch den Quint Daseit, der sie ausschließt.", "metrics": {"bleu_score": 15.088774045957564, "chrf_score": 40.971819053975395, "xcomet_score": 0.4793446362018585, "xcomet_qe_score": 0.48609045147895813, "metricx_score": 19.18514060974121, "metricx_qe_score": 16.613117218017578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat und sie hat Rouge Air-Punkte erreicht, die mehr als zehn Punkte höher waren als die Baselines.", "metrics": {"bleu_score": 26.104909033290696, "chrf_score": 46.82022156435715, "xcomet_score": 0.2995634078979492, "xcomet_qe_score": 0.13350360095500946, "metricx_score": 13.238702774047852, "metricx_qe_score": 15.90788459777832, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Green Test set, der Square Gap zwischen der proposierten Methode und der Basis jumped zu mehr als 20 Punkten.", "metrics": {"bleu_score": 6.19245064140527, "chrf_score": 40.60950313952772, "xcomet_score": 0.4986317455768585, "xcomet_qe_score": 0.5560775995254517, "metricx_score": 16.246164321899414, "metricx_qe_score": 15.31419849395752, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie und sie erfolgreich sind.", "metrics": {"bleu_score": 38.09694917244036, "chrf_score": 50.7038364369359, "xcomet_score": 0.138505220413208, "xcomet_qe_score": 0.15336613357067108, "metricx_score": 15.858105659484863, "metricx_qe_score": 19.33667755126953, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS hat eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Crossfire und eines Generators auf das Training des Crossfire-Systems mit Pseudobus effektiv ist.", "metrics": {"bleu_score": 26.49268590278449, "chrf_score": 53.526109530287144, "xcomet_score": 0.2832774519920349, "xcomet_qe_score": 0.31632137298583984, "metricx_score": 20.256128311157227, "metricx_qe_score": 19.913414001464844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, weil der Klassifizierer sich auf die relevanten Kommittentests für jeden Kurs konzentrieren kann.", "metrics": {"bleu_score": 31.746034938659623, "chrf_score": 65.44145949929873, "xcomet_score": 0.6663339138031006, "xcomet_qe_score": 0.6891931295394897, "metricx_score": 7.739039421081543, "metricx_qe_score": 6.943406581878662, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie isst in dieser Zeit viel höher als wenn sie ledig ist.", "metrics": {"bleu_score": 3.673526562988939, "chrf_score": 13.62884851851091, "xcomet_score": 0.11713042110204697, "xcomet_qe_score": 0.08886818587779999, "metricx_score": 24.336380004882812, "metricx_qe_score": 23.740230560302734, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es auch effektiv ist, für jede dieser Notengrasse unabhängig verschiedene Perspektivsummerisierungsmodelle zu entwickeln.", "metrics": {"bleu_score": 28.588519773722574, "chrf_score": 47.36178754042165, "xcomet_score": 0.7557336091995239, "xcomet_qe_score": 0.8380494117736816, "metricx_score": 7.572507381439209, "metricx_qe_score": 5.905895233154297, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hero und Eronasus", "metrics": {"bleu_score": 0.0, "chrf_score": 8.03700088318691, "xcomet_score": 0.21026548743247986, "xcomet_qe_score": 0.09466181695461273, "metricx_score": 11.358569145202637, "metricx_qe_score": 21.137041091918945, "linguapy_score": [1, "LITHUANIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xia's Methoden neigen dazu, kürzere Sätze als menschliche Referenz-Sätze zu erhalten.", "metrics": {"bleu_score": 9.238430210261097, "chrf_score": 59.262699747931315, "xcomet_score": 0.8255925178527832, "xcomet_qe_score": 0.8349565863609314, "metricx_score": 3.853210926055908, "metricx_qe_score": 6.749719142913818, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Figur auf der rechten Referenz hat drei oder vier Sätze, während CS nur eins hat.", "metrics": {"bleu_score": 11.488177632088458, "chrf_score": 45.61382574927329, "xcomet_score": 0.7285051941871643, "xcomet_qe_score": 0.7140488028526306, "metricx_score": 9.59936237335205, "metricx_qe_score": 8.884971618652344, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzugabe ist, dass in den Trainingsdaten nur 33 % der Sätze im Rabel Merkmale und 40 % im Rabel Verbesserungen vorhanden sind.", "metrics": {"bleu_score": 29.04110779624916, "chrf_score": 50.03272457080098, "xcomet_score": 0.6851596832275391, "xcomet_qe_score": 0.768298864364624, "metricx_score": 8.216413497924805, "metricx_qe_score": 7.7541327476501465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES Methoden ohne zusätzliche Informationen keine genauen Risikobewertungen erzeugen.", "metrics": {"bleu_score": 39.832871551569504, "chrf_score": 71.42932256412755, "xcomet_score": 0.8005627393722534, "xcomet_qe_score": 0.896253228187561, "metricx_score": 7.238461494445801, "metricx_qe_score": 5.90397310256958, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommentarmeldung, und die Kommentarfassung kann nicht generiert werden, ohne auf die entsprechende Peru-Request oder -Erstellung hinzugefügt.", "metrics": {"bleu_score": 32.59692157640202, "chrf_score": 50.69536845128751, "xcomet_score": 0.5948796272277832, "xcomet_qe_score": 0.5967445373535156, "metricx_score": 15.817474365234375, "metricx_qe_score": 13.430747985839844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das untenstehende Beispiel zeigt, dass die beiden Kommentarberichte im Eingaben miteinander verbunden sind und in einen Satz kombiniert werden sollten, aber dies geschieht nicht.", "metrics": {"bleu_score": 24.728515687112836, "chrf_score": 47.015595335482615, "xcomet_score": 0.8555080890655518, "xcomet_qe_score": 0.869038462638855, "metricx_score": 5.2750396728515625, "metricx_qe_score": 5.676469802856445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung.", "metrics": {"bleu_score": 9.688464563433238, "chrf_score": 7.9346982584858505, "xcomet_score": 0.9945788383483887, "xcomet_qe_score": 1.0, "metricx_score": 0.570763885974884, "metricx_qe_score": 0.05037352815270424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Personalgenerierung erstellt,", "metrics": {"bleu_score": 58.27355625822051, "chrf_score": 71.01196079833653, "xcomet_score": 0.7551684379577637, "xcomet_qe_score": 0.7559963464736938, "metricx_score": 10.228418350219727, "metricx_qe_score": 7.473443984985352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Kommentarmeldungen einzugeben und sie zusammenzufassen, sodass sie für alle Projekte auf Englisch anwendbar ist.", "metrics": {"bleu_score": 25.474392242715638, "chrf_score": 51.776635036135396, "xcomet_score": 0.8773609399795532, "xcomet_qe_score": 0.8592420816421509, "metricx_score": 3.5009522438049316, "metricx_qe_score": 4.179376602172852, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die Bassrate besser laut macht als die Bassrate.", "metrics": {"bleu_score": 41.22023501583932, "chrf_score": 50.76519054631663, "xcomet_score": 0.6935921311378479, "xcomet_qe_score": 0.7922650575637817, "metricx_score": 11.063618659973145, "metricx_qe_score": 13.584081649780273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte schauen Sie sich unsere Dessert-Audit-Tab an.", "metrics": {"bleu_score": 12.862534787413374, "chrf_score": 46.75483428674012, "xcomet_score": 0.4021378457546234, "xcomet_qe_score": 0.2224692702293396, "metricx_score": 6.844804286956787, "metricx_qe_score": 7.668722152709961, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 20.4664420548395, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.02491046115756035, "metricx_qe_score": 0.1274172067642212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist ein Safarari,", "metrics": {"bleu_score": 12.22307556087252, "chrf_score": 49.31439950025961, "xcomet_score": 0.7144095301628113, "xcomet_qe_score": 0.6643913984298706, "metricx_score": 10.512860298156738, "metricx_qe_score": 10.973207473754883, "linguapy_score": [1, "ROMANIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unsere Arbeit über die Anreicherung von Tabellen mit Hilfe von fein abgestimmten Transformatoren präsentieren.", "metrics": {"bleu_score": 2.5540496664715904, "chrf_score": 31.180659070180276, "xcomet_score": 0.9830282926559448, "xcomet_qe_score": 0.9791454076766968, "metricx_score": 3.6856884956359863, "metricx_qe_score": 3.778625965118408, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Merkmale der Daten.", "metrics": {"bleu_score": 76.70387248467661, "chrf_score": 87.35972419756955, "xcomet_score": 0.9997085332870483, "xcomet_qe_score": 1.0, "metricx_score": 0.3632175922393799, "metricx_qe_score": 0.40494126081466675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen begrenzt.", "metrics": {"bleu_score": 41.11336169005196, "chrf_score": 84.09978153399207, "xcomet_score": 0.9822602272033691, "xcomet_qe_score": 0.9808085560798645, "metricx_score": 0.22435833513736725, "metricx_qe_score": 0.2748662233352661, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Funktionen mit einer anderen Datenquelle kann erhebliche Informationen bieten.", "metrics": {"bleu_score": 23.566578558703185, "chrf_score": 59.410567640171266, "xcomet_score": 0.970352292060852, "xcomet_qe_score": 0.9602512121200562, "metricx_score": 0.8481608033180237, "metricx_qe_score": 1.0846755504608154, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung von Tabelldaten mit externen Quellen-Freitexten.", "metrics": {"bleu_score": 35.96008497520192, "chrf_score": 71.63553946508104, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.6621195673942566, "metricx_qe_score": 0.6121528744697571, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben eine Tabelldatensammlung und eine Wissensbasis.", "metrics": {"bleu_score": 30.66148710292676, "chrf_score": 58.74823346354145, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.41141200065612793, "metricx_qe_score": 0.41206884384155273, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Funktionen aus dem künstlichen Text der Wissensbasis zu extrahieren.", "metrics": {"bleu_score": 47.32072478339365, "chrf_score": 70.9298299369999, "xcomet_score": 0.7553173303604126, "xcomet_qe_score": 0.7122284173965454, "metricx_score": 7.537999153137207, "metricx_qe_score": 8.752447128295898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess.", "metrics": {"bleu_score": 62.401954419369176, "chrf_score": 84.75044971165464, "xcomet_score": 0.8918439149856567, "xcomet_qe_score": 0.888335645198822, "metricx_score": 3.8839259147644043, "metricx_qe_score": 4.871129512786865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel sehen. In einem Datensatz, der in FEST eingeführt wird.", "metrics": {"bleu_score": 14.463984658071604, "chrf_score": 53.1880744042553, "xcomet_score": 0.9338255524635315, "xcomet_qe_score": 0.8943592309951782, "metricx_score": 4.479485988616943, "metricx_qe_score": 3.968790054321289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist die Datenmenge Universitätsdatenmenge.", "metrics": {"bleu_score": 32.260135189272866, "chrf_score": 65.38203827004277, "xcomet_score": 0.9803561568260193, "xcomet_qe_score": 0.9757620096206665, "metricx_score": 0.8637650012969971, "metricx_qe_score": 0.820065975189209, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten zu unterteilen.", "metrics": {"bleu_score": 3.4585921141027365, "chrf_score": 43.697127043435565, "xcomet_score": 0.9764678478240967, "xcomet_qe_score": 1.0, "metricx_score": 0.607851505279541, "metricx_qe_score": 0.34761422872543335, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festes ist die Entitätsverknüpfung.", "metrics": {"bleu_score": 20.164945583740657, "chrf_score": 42.33726134189686, "xcomet_score": 0.7956360578536987, "xcomet_qe_score": 0.809151291847229, "metricx_score": 4.123542308807373, "metricx_qe_score": 4.628881931304932, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Einheit, in diesem Beispiel der Name der Universität, mit einer Einheit innerhalb der Wissensbasis verknüpft ist.", "metrics": {"bleu_score": 54.69200314562076, "chrf_score": 79.29103206876515, "xcomet_score": 0.8640899062156677, "xcomet_qe_score": 0.952814519405365, "metricx_score": 1.4147294759750366, "metricx_qe_score": 0.8569120168685913, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Knowledge-Basis wird extrahiert und in die Daten setzt.", "metrics": {"bleu_score": 17.678748653651848, "chrf_score": 57.20303973876405, "xcomet_score": 0.8249883055686951, "xcomet_qe_score": 0.8795196413993835, "metricx_score": 7.030519008636475, "metricx_qe_score": 6.411530494689941, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text der Abstrakt der Wikipedia-Seite.", "metrics": {"bleu_score": 58.77283725105324, "chrf_score": 84.82730179687263, "xcomet_score": 0.9879180788993835, "xcomet_qe_score": 0.9890912771224976, "metricx_score": 0.5078300833702087, "metricx_qe_score": 0.547862708568573, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Funktionen aus dem abgerufenen Text generieren oder extrahieren.", "metrics": {"bleu_score": 90.36020036098445, "chrf_score": 94.91448073675998, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.32671982049942017, "metricx_qe_score": 0.3977917730808258, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen also eine Funktionsaufnahmephase, die Textanalyse beinhaltet.", "metrics": {"bleu_score": 8.27951003977077, "chrf_score": 42.149426937942145, "xcomet_score": 0.9576568603515625, "xcomet_qe_score": 0.9323186874389648, "metricx_score": 4.803910732269287, "metricx_qe_score": 4.325207710266113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde mich in den nächsten Folien tiefer damit befassen.", "metrics": {"bleu_score": 10.657284485555579, "chrf_score": 44.78372805759204, "xcomet_score": 0.9524855613708496, "xcomet_qe_score": 0.9440417289733887, "metricx_score": 1.5007208585739136, "metricx_qe_score": 1.7696139812469482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Extraktionsphase der Merkmale gibt es eine Generierungsphase der Merkmale, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren.", "metrics": {"bleu_score": 40.35660856614614, "chrf_score": 56.70129644964354, "xcomet_score": 0.9513896703720093, "xcomet_qe_score": 0.9817698001861572, "metricx_score": 0.8026913404464722, "metricx_qe_score": 0.5626745223999023, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst generieren Sie Funktionen in der Anzahl der Klassen des ursprünglichen Datensatzes.", "metrics": {"bleu_score": 66.52049901111006, "chrf_score": 80.3814115354913, "xcomet_score": 0.9752501249313354, "xcomet_qe_score": 0.9515448808670044, "metricx_score": 1.246880292892456, "metricx_qe_score": 3.2892072200775146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen", "metrics": {"bleu_score": 89.483931681437, "chrf_score": 98.49752398086483, "xcomet_score": 0.998803973197937, "xcomet_qe_score": 0.9922256469726562, "metricx_score": 0.17233462631702423, "metricx_qe_score": 0.3795880675315857, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also, erstens zwei neue Funktionen.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 55.55032386797779, "xcomet_score": 0.9524015188217163, "xcomet_qe_score": 0.9390473365783691, "metricx_score": 2.7292821407318115, "metricx_qe_score": 4.742486953735352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Funktionen.", "metrics": {"bleu_score": 64.75445426291287, "chrf_score": 77.90131052373106, "xcomet_score": 0.9133902192115784, "xcomet_qe_score": 0.9345011711120605, "metricx_score": 5.025780200958252, "metricx_qe_score": 4.36533784866333, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Funktion stellt die Wahrscheinlichkeit für jede Klasse dar.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9983868598937988, "xcomet_qe_score": 0.9895145893096924, "metricx_score": 0.4900013208389282, "metricx_qe_score": 0.7916998863220215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, die sich auf Transformer basieren lassen, wie Baird, GPT, XLED und so weiter.", "metrics": {"bleu_score": 29.967090451591627, "chrf_score": 61.280742185819726, "xcomet_score": 0.6620998978614807, "xcomet_qe_score": 0.6754058599472046, "metricx_score": 7.186909198760986, "metricx_qe_score": 9.179692268371582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können.", "metrics": {"bleu_score": 24.601372576927535, "chrf_score": 55.634149757202366, "xcomet_score": 0.9896091222763062, "xcomet_qe_score": 0.985703706741333, "metricx_score": 1.2135157585144043, "metricx_qe_score": 1.2252578735351562, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe zur Feinabstimmung sein.", "metrics": {"bleu_score": 19.081654556856684, "chrf_score": 57.76912538622534, "xcomet_score": 0.9263441562652588, "xcomet_qe_score": 0.9620009660720825, "metricx_score": 2.9595720767974854, "metricx_qe_score": 3.4412691593170166, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Funktionsauffnahme können wir also ein Parent-Train-Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset verfeinern.", "metrics": {"bleu_score": 38.78964805488567, "chrf_score": 66.80552700371062, "xcomet_score": 0.8682878017425537, "xcomet_qe_score": 0.868034839630127, "metricx_score": 3.5424726009368896, "metricx_qe_score": 3.696488857269287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell verfeinert, um Text in Klassen zu klassifizieren, abstrakt in Klassen, niedrig oder hoch.", "metrics": {"bleu_score": 17.757983499689274, "chrf_score": 55.543297788619604, "xcomet_score": 0.8849579095840454, "xcomet_qe_score": 0.8422841429710388, "metricx_score": 3.744131565093994, "metricx_qe_score": 3.591128349304199, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse ist, und verwenden Sie sie als neue Funktionen.", "metrics": {"bleu_score": 65.6680744925114, "chrf_score": 80.86840679012658, "xcomet_score": 0.9087142944335938, "xcomet_qe_score": 0.9583205580711365, "metricx_score": 0.8126949071884155, "metricx_qe_score": 0.8414944410324097, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datenmengen möglicherweise wenige unterschiedliche Entitätsstapel haben.", "metrics": {"bleu_score": 44.581353773440114, "chrf_score": 73.98053835946781, "xcomet_score": 0.9592570066452026, "xcomet_qe_score": 0.9086679220199585, "metricx_score": 2.0873327255249023, "metricx_qe_score": 1.9563798904418945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Proben, und der kleinste Datensatz enthält fünfunddreißig Proben in seinem Trainings-Satz.", "metrics": {"bleu_score": 43.64460225519446, "chrf_score": 73.81014877035513, "xcomet_score": 0.9181286096572876, "xcomet_qe_score": 0.9154099225997925, "metricx_score": 1.1077543497085571, "metricx_qe_score": 1.5043327808380127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern.", "metrics": {"bleu_score": 12.35622127262679, "chrf_score": 45.6864332985765, "xcomet_score": 0.9957242012023926, "xcomet_qe_score": 0.9921504259109497, "metricx_score": 0.4795929491519928, "metricx_qe_score": 0.5472784638404846, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorherige Kenntnisse über voranalyseierte Datensätze nutzen.", "metrics": {"bleu_score": 24.70315512339778, "chrf_score": 72.48184537304184, "xcomet_score": 0.9810230731964111, "xcomet_qe_score": 0.9881771206855774, "metricx_score": 0.11918814480304718, "metricx_qe_score": 0.15891766548156738, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir den nth-Datensatz analysieren.", "metrics": {"bleu_score": 46.464990766349146, "chrf_score": 80.49761954354774, "xcomet_score": 0.6755894422531128, "xcomet_qe_score": 0.6840016841888428, "metricx_score": 4.376712799072266, "metricx_qe_score": 3.5359981060028076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sugest, ist die Hälfte der Fine Tuning Phase.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 16.505783815575366, "xcomet_score": 0.45728418231010437, "xcomet_qe_score": 0.6225225329399109, "metricx_score": 17.585407257080078, "metricx_qe_score": 14.350434303283691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Phase der Fine-Tuning-Multitask.", "metrics": {"bleu_score": 9.652434877402245, "chrf_score": 44.369539704076665, "xcomet_score": 0.9020479917526245, "xcomet_qe_score": 0.8687891960144043, "metricx_score": 5.825441837310791, "metricx_qe_score": 4.6786789894104, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über n minus eins Datensätze finden,", "metrics": {"bleu_score": 4.456882760699063, "chrf_score": 42.81880175661515, "xcomet_score": 0.7665672302246094, "xcomet_qe_score": 0.7592151761054993, "metricx_score": 8.59589672088623, "metricx_qe_score": 9.512457847595215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine weitere Feinabstimmungsphase durch, die eine Feinabstimmung der Zielaufgaben ist, wenn wir das Sprachmodell über den n-Tiel-Datensatz feinabstimmen.", "metrics": {"bleu_score": 70.33001921469473, "chrf_score": 83.66558360575863, "xcomet_score": 0.8346560001373291, "xcomet_qe_score": 0.7433739900588989, "metricx_score": 4.2580108642578125, "metricx_qe_score": 3.8672378063201904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der neueste Stand der Multitask-Fine-Tuning, der MTDNN genannt wird.", "metrics": {"bleu_score": 8.913765521398126, "chrf_score": 46.89722701194675, "xcomet_score": 0.9318940043449402, "xcomet_qe_score": 0.9320767521858215, "metricx_score": 4.943251132965088, "metricx_qe_score": 4.692646026611328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN hält MTDNN eine Anzahl von Aufgaben im Trainingsatz aufrecht.", "metrics": {"bleu_score": 6.8179839929677115, "chrf_score": 35.13159405626294, "xcomet_score": 0.6810630559921265, "xcomet_qe_score": 0.8286431431770325, "metricx_score": 6.794310569763184, "metricx_qe_score": 4.137360095977783, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainings-Set. Also leere DNN und halte vier Kopfhäupter, wie Sie auf dem Bild sehen können.", "metrics": {"bleu_score": 59.7713031281549, "chrf_score": 68.79918075289282, "xcomet_score": 0.7793456315994263, "xcomet_qe_score": 0.787073016166687, "metricx_score": 10.955241203308105, "metricx_qe_score": 9.786602020263672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es samplet eine zufällige Charge aus dem Trainingsset.", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 36.96211430513171, "xcomet_score": 0.905950665473938, "xcomet_qe_score": 0.8748857378959656, "metricx_score": 4.247941017150879, "metricx_qe_score": 3.553711414337158, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Run-Batch zu einer, zum Beispiel, Sing und Selton-Klassifizierungsaufgabe gehört, führt er einen Vorwärts- und Rückwärtspass durch den ersten Kopf aus.", "metrics": {"bleu_score": 9.615094003919301, "chrf_score": 51.18489051755959, "xcomet_score": 0.5394628643989563, "xcomet_qe_score": 0.602022647857666, "metricx_score": 9.558219909667969, "metricx_qe_score": 10.039294242858887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zu einer Paar-Ranking-Tasche gehört, wird sie durch den letzten Kopf weitergegeben und zurückgegeben.", "metrics": {"bleu_score": 5.237520761048587, "chrf_score": 29.16959010728135, "xcomet_score": 0.6056535840034485, "xcomet_qe_score": 0.6403613090515137, "metricx_score": 7.758810997009277, "metricx_qe_score": 7.163551330566406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario verifiziert eine Datenmenge-Tabelle die Anzahl der Klassen.", "metrics": {"bleu_score": 30.983802298041674, "chrf_score": 58.17827624675688, "xcomet_score": 0.8192577362060547, "xcomet_qe_score": 0.8360494375228882, "metricx_score": 4.048142433166504, "metricx_qe_score": 3.6207053661346436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.05911726504564285, "metricx_qe_score": 0.12243705987930298, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN hält die Anzahl der Klassen-Heads-Ausgaben-Schichten aufrecht.", "metrics": {"bleu_score": 3.983253478176822, "chrf_score": 28.307750403663746, "xcomet_score": 0.7813084125518799, "xcomet_qe_score": 0.8511111736297607, "metricx_score": 6.879890441894531, "metricx_qe_score": 7.092966556549072, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss MTDNN eine neue HEADS für einen neuen Datensatz mit einer neuen Aufgabe initialisieren.", "metrics": {"bleu_score": 70.85876411943929, "chrf_score": 82.43329136505305, "xcomet_score": 0.901775598526001, "xcomet_qe_score": 0.8768877387046814, "metricx_score": 4.5356879234313965, "metricx_qe_score": 5.304867744445801, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Task Reformulation Fine Tuning bezeichnet wird, besteht darin, dass wir in unserem Ansatz Task Reformation Fine Tuning statt mehrere Kopfgruppen zu behalten, jeden Datensatz in ein Satz pro Klassifizierungsproblem umformulieren, das zwei Klassen-Aufgaben ist.", "metrics": {"bleu_score": 21.31099604430212, "chrf_score": 62.63334321636672, "xcomet_score": 0.6409361362457275, "xcomet_qe_score": 0.7249100804328918, "metricx_score": 8.732345581054688, "metricx_qe_score": 8.633281707763672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also ein Beispiel sehen.", "metrics": {"bleu_score": 13.134549472120788, "chrf_score": 43.5696002694538, "xcomet_score": 0.9822450876235962, "xcomet_qe_score": 0.9828373193740845, "metricx_score": 0.7119780778884888, "metricx_qe_score": 0.6313139796257019, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Input-Datensatz, der von Entitäten, Funktionen, Text und Klassen besteht.", "metrics": {"bleu_score": 60.252688074129274, "chrf_score": 76.79999990267507, "xcomet_score": 0.9836969375610352, "xcomet_qe_score": 0.9812113046646118, "metricx_score": 1.8997843265533447, "metricx_qe_score": 1.7937781810760498, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zu der Klassifizierung des Textes, des Abstrakts und der Klasse in wahr oder falsch.", "metrics": {"bleu_score": 52.65106255150894, "chrf_score": 84.01258734459724, "xcomet_score": 0.9173793792724609, "xcomet_qe_score": 0.9272597432136536, "metricx_score": 1.7481274604797363, "metricx_qe_score": 2.4725687503814697, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, wir haben das Sprachmodell so trainiert, dass es abstrakt und in der Klasse klassifiziert, ob die Abstrakt-Klasse in der Klasse gehört oder nicht.", "metrics": {"bleu_score": 36.36200522541209, "chrf_score": 67.0187203654275, "xcomet_score": 0.6705152988433838, "xcomet_qe_score": 0.488253653049469, "metricx_score": 10.893021583557129, "metricx_qe_score": 10.518895149230957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Etikettvektor besteht in diesem Fall also immer aus zwei Klassen.", "metrics": {"bleu_score": 23.394539701283108, "chrf_score": 48.21263391357753, "xcomet_score": 0.9942306280136108, "xcomet_qe_score": 0.988111138343811, "metricx_score": 1.9859421253204346, "metricx_qe_score": 2.877591848373413, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren fertigen oder formulierten Feintuning-Ansatz.", "metrics": {"bleu_score": 34.48444257953326, "chrf_score": 65.06898676358345, "xcomet_score": 0.8557530641555786, "xcomet_qe_score": 0.8439071178436279, "metricx_score": 5.870461463928223, "metricx_qe_score": 6.5997819900512695, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also das vollständige Framework betrachten.", "metrics": {"bleu_score": 10.552670315936318, "chrf_score": 28.0755887847268, "xcomet_score": 0.975450873374939, "xcomet_qe_score": 1.0, "metricx_score": 0.8321741223335266, "metricx_qe_score": 0.31801092624664307, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und das set fade into fast", "metrics": {"bleu_score": 0.0, "chrf_score": 9.400958612314431, "xcomet_score": 0.1778413951396942, "xcomet_qe_score": 0.519209086894989, "metricx_score": 14.976766586303711, "metricx_qe_score": 14.153972625732422, "linguapy_score": [1, "SWEDISH"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Entity-Linking-Phase.", "metrics": {"bleu_score": 8.170609724417774, "chrf_score": 53.14328259592374, "xcomet_score": 0.8883309364318848, "xcomet_qe_score": 0.8822115659713745, "metricx_score": 4.877869606018066, "metricx_qe_score": 5.530518531799316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensbasis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9831864833831787, "xcomet_qe_score": 0.9467700719833374, "metricx_score": 1.2580218315124512, "metricx_qe_score": 1.4702454805374146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird die Aufgabe in eine Satz-Per-Classifikation-Tasche reformuliert.", "metrics": {"bleu_score": 26.449672174138467, "chrf_score": 54.30707185458101, "xcomet_score": 0.7580485343933105, "xcomet_qe_score": 0.7642979621887207, "metricx_score": 8.541301727294922, "metricx_qe_score": 7.872615814208984, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und die Ausgabenwahrscheinlichkeit für jede Klasse.", "metrics": {"bleu_score": 25.947507140745756, "chrf_score": 76.75658862606505, "xcomet_score": 0.925209641456604, "xcomet_qe_score": 0.8871338367462158, "metricx_score": 0.9281048774719238, "metricx_qe_score": 2.4774587154388428, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über n-1-Datensatz mit einer vorläufigen Multitask-Fine-Tuning verfeinert wurde.", "metrics": {"bleu_score": 16.61742929957894, "chrf_score": 58.080806240287544, "xcomet_score": 0.8033375144004822, "xcomet_qe_score": 0.750084638595581, "metricx_score": 5.638415813446045, "metricx_qe_score": 5.996222972869873, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu erstelltes Merkmal in der Anzahl der Klassen.", "metrics": {"bleu_score": 48.25893492910237, "chrf_score": 70.68621781918395, "xcomet_score": 0.9333317279815674, "xcomet_qe_score": 0.9142856597900391, "metricx_score": 1.108764886856079, "metricx_qe_score": 1.9004459381103516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Rahmenwerk zu bewerten, verwenden wir eine Datenmenge mit siebzehn Tabellen, die Größe, Merkmale, Balance, Bereich und anfängliche Leistung variieren.", "metrics": {"bleu_score": 5.594147299480393, "chrf_score": 35.45895479735608, "xcomet_score": 0.8761184811592102, "xcomet_qe_score": 0.8891918659210205, "metricx_score": 3.7878057956695557, "metricx_qe_score": 4.369904518127441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 95.4310132341269, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.02063114196062088, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unser Experiment als Live-Out-Evaluierung gestaltet, bei der wir schnell über sechzehn Datensätze trainieren und sie auf das siebzehnte Datenset anwenden.", "metrics": {"bleu_score": 10.414419091986518, "chrf_score": 52.893822039568484, "xcomet_score": 0.6755749583244324, "xcomet_qe_score": 0.722192645072937, "metricx_score": 6.196385860443115, "metricx_qe_score": 5.904324531555176, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datensatz in vier Fehler auf und wenden eine Falten-Cross-Validation an.", "metrics": {"bleu_score": 34.64226178936947, "chrf_score": 47.75734091085933, "xcomet_score": 0.7912290096282959, "xcomet_qe_score": 0.7623357772827148, "metricx_score": 10.155861854553223, "metricx_qe_score": 9.042542457580566, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Funktionen und bewerten sie mit fünf Bewertungs-Klassifikatoren.", "metrics": {"bleu_score": 84.23626743789745, "chrf_score": 81.92388605092582, "xcomet_score": 0.9965016841888428, "xcomet_qe_score": 0.9999806880950928, "metricx_score": 0.43360835313796997, "metricx_qe_score": 0.8884925246238708, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-Basis-Architektur.", "metrics": {"bleu_score": 19.493995755254467, "chrf_score": 69.91582826112078, "xcomet_score": 0.9996485710144043, "xcomet_qe_score": 1.0, "metricx_score": 0.42892053723335266, "metricx_qe_score": 0.6971045136451721, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 85.51131524815735, "xcomet_score": 0.9987486600875854, "xcomet_qe_score": 0.9999598264694214, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Rahmenwerk mit der Feinabstimmung des Zieldatensatzes, der Feinabstimmung der Zielaufgabe und der vorläufigen Feinabstimmung der MTDNN vergleichen.", "metrics": {"bleu_score": 52.08202637221089, "chrf_score": 83.40331134901218, "xcomet_score": 0.9719748497009277, "xcomet_qe_score": 0.960708498954773, "metricx_score": 1.7339410781860352, "metricx_qe_score": 1.4488309621810913, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere Formulierung ist ein Feintuning, das beste Ergebnis, die beste Leistung.", "metrics": {"bleu_score": 23.793665482062607, "chrf_score": 55.922418035757005, "xcomet_score": 0.9258921146392822, "xcomet_qe_score": 0.9126065969467163, "metricx_score": 7.069815158843994, "metricx_qe_score": 7.256374835968018, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2% gegenüber der Feinabstimmung des Zieldatensatzes erreichte.", "metrics": {"bleu_score": 30.79300751569293, "chrf_score": 77.24169938278862, "xcomet_score": 0.973564863204956, "xcomet_qe_score": 0.9851980805397034, "metricx_score": 0.5945246815681458, "metricx_qe_score": 1.15377938747406, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Poach hat eine Verbesserung um sechs Prozent erzielt.", "metrics": {"bleu_score": 10.274506536150966, "chrf_score": 49.976666471769335, "xcomet_score": 0.8493798971176147, "xcomet_qe_score": 0.8364808559417725, "metricx_score": 7.6271538734436035, "metricx_qe_score": 8.220807075500488, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Daten ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Feinabstimmung bei mehrere Aufgaben auf 1,5 Prozent abnimmt.", "metrics": {"bleu_score": 42.774464413593606, "chrf_score": 69.94854493839033, "xcomet_score": 0.9335155487060547, "xcomet_qe_score": 0.8617466688156128, "metricx_score": 2.2699079513549805, "metricx_qe_score": 3.1548588275909424, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung hat sich im Vergleich zu der Zielaufgabe, die allein mit der Feinabstimmung verbessert wurde, um elf Prozent zu verbessern.", "metrics": {"bleu_score": 9.00911347430732, "chrf_score": 60.776430228183365, "xcomet_score": 0.9561319351196289, "xcomet_qe_score": 0.9607750773429871, "metricx_score": 3.5758116245269775, "metricx_qe_score": 3.5002431869506836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Zusammenfassung ermöglicht Fast die Bereicherung von Fushot aus 35 Proben in unserem Experiment.", "metrics": {"bleu_score": 12.874330508144842, "chrf_score": 54.47721428558333, "xcomet_score": 0.7219856977462769, "xcomet_qe_score": 0.7074866890907288, "metricx_score": 11.804706573486328, "metricx_qe_score": 12.357681274414062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze.", "metrics": {"bleu_score": 55.0695314903184, "chrf_score": 90.0929663869274, "xcomet_score": 0.9807785749435425, "xcomet_qe_score": 0.9429309368133545, "metricx_score": 1.1379332542419434, "metricx_qe_score": 1.739567518234253, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells.", "metrics": {"bleu_score": 27.054113452696992, "chrf_score": 54.42421912540176, "xcomet_score": 0.798446536064148, "xcomet_qe_score": 0.8068912029266357, "metricx_score": 4.322042465209961, "metricx_qe_score": 5.432572841644287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulationsphase hinzu.", "metrics": {"bleu_score": 48.892302243490086, "chrf_score": 78.32830921384375, "xcomet_score": 0.9774839282035828, "xcomet_qe_score": 0.9655010104179382, "metricx_score": 1.8783448934555054, "metricx_qe_score": 1.0447611808776855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satzpaar-Klassifizierungsproblematik verwenden können.", "metrics": {"bleu_score": 62.56538561604213, "chrf_score": 81.70762660514002, "xcomet_score": 0.8637980222702026, "xcomet_qe_score": 0.8101247549057007, "metricx_score": 4.1765618324279785, "metricx_qe_score": 4.810375213623047, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 20.4664420548395, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.02491046115756035, "metricx_qe_score": 0.1274172067642212, "linguapy_score": [0, "GERMAN"]}}
