{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo zusammen. Heute werde ich unsere Forschungsarbeit „Lernen, deduktiv zu schließen: mathematisches Problemlösen als Extraktion komplexer Bereiche“ vorstellen.", "metrics": {"bleu_score": 33.46215683618005, "chrf_score": 55.174552894937555, "xcomet_score": 0.9160363674163818, "xcomet_qe_score": 0.913411021232605, "metricx_score": 2.6312553882598877, "metricx_qe_score": 2.6478431224823, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan vom Bayden's AI Lab und dies ist eine gemeinsame Arbeit mit Jerry von der University of Texas in Austin und Weilu von der SUTD.", "metrics": {"bleu_score": 48.58373853487032, "chrf_score": 73.58714063408314, "xcomet_score": 0.6729018092155457, "xcomet_qe_score": 0.6700947880744934, "metricx_score": 5.895283222198486, "metricx_qe_score": 5.172635555267334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen.", "metrics": {"bleu_score": 74.19446627365011, "chrf_score": 80.89316601602657, "xcomet_score": 0.9814042448997498, "xcomet_qe_score": 0.9854676723480225, "metricx_score": 1.536429524421692, "metricx_qe_score": 0.7237764596939087, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist.", "metrics": {"bleu_score": 16.21599014882373, "chrf_score": 55.986797401068664, "xcomet_score": 0.986242949962616, "xcomet_qe_score": 0.9959239959716797, "metricx_score": 0.2947690188884735, "metricx_qe_score": 0.27105236053466797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Abbildung stammt aus der Arbeit von Palm, in der sie Prompting einsetzen, um das mathematische Problem in einem Few-Shot-Lern-Szenario zu lösen.", "metrics": {"bleu_score": 21.427403687026292, "chrf_score": 66.54744983415253, "xcomet_score": 0.7862458229064941, "xcomet_qe_score": 0.7365421056747437, "metricx_score": 4.229744911193848, "metricx_qe_score": 4.790027618408203, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite können wir sehen, dass wir, wenn wir einige Beispiele mit nur Fragen und Antworten geben, möglicherweise nicht die richtigen Antworten erhalten.", "metrics": {"bleu_score": 19.59280139287725, "chrf_score": 63.40384663908719, "xcomet_score": 0.9640712141990662, "xcomet_qe_score": 0.9651310443878174, "metricx_score": 0.6587244868278503, "metricx_qe_score": 0.49524277448654175, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch eine etwas ausführlichere Begründung geben, kann das Modell die Begründung vorhersagen und auch hier eine korrekte Vorhersage treffen.", "metrics": {"bleu_score": 16.757352000247426, "chrf_score": 45.634977531506145, "xcomet_score": 0.9975043535232544, "xcomet_qe_score": 0.9967635869979858, "metricx_score": 0.9141442775726318, "metricx_qe_score": 0.760273814201355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, interpretierbares mehrstufiges Denken als Ausgabe zu haben.", "metrics": {"bleu_score": 36.883688707312125, "chrf_score": 57.71297982803978, "xcomet_score": 0.9684027433395386, "xcomet_qe_score": 0.9924466609954834, "metricx_score": 1.368630051612854, "metricx_qe_score": 1.1038901805877686, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir sind auch der Meinung, dass das MathWorld-Problem eine einfache Anwendung ist, um solche Denkfähigkeiten zu bewerten.", "metrics": {"bleu_score": 18.856152326562558, "chrf_score": 56.058612125920405, "xcomet_score": 0.8984975814819336, "xcomet_qe_score": 0.9124661087989807, "metricx_score": 4.243458271026611, "metricx_qe_score": 3.4034218788146973, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Problemaufbau müssen wir also bei den gegebenen Fragen diese Frage lösen und die numerischen Antworten erhalten.", "metrics": {"bleu_score": 59.08871032231054, "chrf_score": 78.07512336273933, "xcomet_score": 0.9853231906890869, "xcomet_qe_score": 0.9834052920341492, "metricx_score": 0.6334456205368042, "metricx_qe_score": 1.0262588262557983, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns auch der mathematische Ausdruck gegeben, der zu dieser bestimmten Antwort führt.", "metrics": {"bleu_score": 38.8905561152711, "chrf_score": 75.36768720778252, "xcomet_score": 0.9743032455444336, "xcomet_qe_score": 0.980651319026947, "metricx_score": 1.851338267326355, "metricx_qe_score": 3.033282995223999, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Bestimmte Annahmen gelten auch wie in früheren Arbeiten.", "metrics": {"bleu_score": 35.967895947086795, "chrf_score": 71.26510051943254, "xcomet_score": 0.9898253679275513, "xcomet_qe_score": 1.0, "metricx_score": 1.054714322090149, "metricx_qe_score": 1.250827670097351, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir nehmen an, dass die Genauigkeit der Mengen unbekannt ist.", "metrics": {"bleu_score": 44.462966469165124, "chrf_score": 71.92958193778215, "xcomet_score": 0.8657549023628235, "xcomet_qe_score": 0.86202073097229, "metricx_score": 4.750453472137451, "metricx_qe_score": 4.2941718101501465, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponentiation.", "metrics": {"bleu_score": 75.7637442126685, "chrf_score": 88.70212592409335, "xcomet_score": 0.950537383556366, "xcomet_qe_score": 0.9606033563613892, "metricx_score": 1.0560083389282227, "metricx_qe_score": 0.9698505401611328, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren zerlegt werden.", "metrics": {"bleu_score": 24.08856270485351, "chrf_score": 69.63888387207133, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3693346679210663, "metricx_qe_score": 0.3960431218147278, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Frühere Arbeiten zur mathematischen Problemlösung lassen sich tatsächlich in sequenzielle und sequenzielle Baummodelle einteilen.", "metrics": {"bleu_score": 7.735984567871263, "chrf_score": 46.902995495290774, "xcomet_score": 0.8674119710922241, "xcomet_qe_score": 0.8666446805000305, "metricx_score": 3.9786949157714844, "metricx_qe_score": 5.48612117767334, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenz-zu-Sequenz-Modelle wandeln den Ausdruck in eine bestimmte Sequenz für die Generierung um.", "metrics": {"bleu_score": 46.091613189209355, "chrf_score": 76.82234866843271, "xcomet_score": 0.9823542833328247, "xcomet_qe_score": 0.9328607320785522, "metricx_score": 0.4074362516403198, "metricx_qe_score": 0.6224039196968079, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ziemlich einfach zu implementieren und kann auf viele verschiedene komplizierte Probleme angewendet werden.", "metrics": {"bleu_score": 64.1386525898168, "chrf_score": 80.53145118955712, "xcomet_score": 0.9968968629837036, "xcomet_qe_score": 0.9879087209701538, "metricx_score": 0.2024717777967453, "metricx_qe_score": 0.3725321590900421, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachteile der Leistung sind jedoch im Allgemeinen nicht besser als bei dem Strukturmodell und es fehlt an Interpretierbarkeit für Vorhersagen.", "metrics": {"bleu_score": 22.35360330173221, "chrf_score": 63.40354988572272, "xcomet_score": 0.9411041736602783, "xcomet_qe_score": 0.9481351375579834, "metricx_score": 5.484588146209717, "metricx_qe_score": 5.697475910186768, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Diese Richtung ist jedoch aufgrund des Transformer-Modells immer noch sehr beliebt.", "metrics": {"bleu_score": 8.523278832198827, "chrf_score": 52.888654083234066, "xcomet_score": 0.992943525314331, "xcomet_qe_score": 0.9710997343063354, "metricx_score": 1.135043978691101, "metricx_qe_score": 1.595210075378418, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "Bei baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Präordertraversierung bei der Baumgenerierung.", "metrics": {"bleu_score": 41.180376356915765, "chrf_score": 71.4781709102958, "xcomet_score": 0.8963003158569336, "xcomet_qe_score": 0.892345666885376, "metricx_score": 2.15435791015625, "metricx_qe_score": 1.876439094543457, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir weiterhin die Operatoren, bis wir die Blätter erreichen, die die Mengen sind.", "metrics": {"bleu_score": 46.56684017696602, "chrf_score": 63.32991245156422, "xcomet_score": 0.9697611927986145, "xcomet_qe_score": 0.9604504704475403, "metricx_score": 1.0797514915466309, "metricx_qe_score": 1.954207420349121, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist das Gute, dass es uns tatsächlich diese Binärbaumstruktur gibt, aber es ist tatsächlich ziemlich gegenintuitiv, weil wir zuerst den Operator generieren und dann am Ende die Mengen.", "metrics": {"bleu_score": 32.596921576402, "chrf_score": 60.01723154444475, "xcomet_score": 0.9147406816482544, "xcomet_qe_score": 0.9058772325515747, "metricx_score": 2.639033794403076, "metricx_qe_score": 3.638129949569702, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Das zweite ist, dass es auch einige wiederholte Berechnungen enthält.", "metrics": {"bleu_score": 8.516593018819643, "chrf_score": 56.83429186498595, "xcomet_score": 0.9491372108459473, "xcomet_qe_score": 0.9772520065307617, "metricx_score": 0.7059602737426758, "metricx_qe_score": 0.46796438097953796, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns diesen Ausdruck ansehen, wird 8 mal 3 plus 3 tatsächlich zweimal erzeugt. Wir sollten jedoch die Ergebnisse wiederverwenden.", "metrics": {"bleu_score": 34.006760909293895, "chrf_score": 62.29769852342009, "xcomet_score": 0.9983969926834106, "xcomet_qe_score": 0.9963551759719849, "metricx_score": 0.360553503036499, "metricx_qe_score": 0.5827324986457825, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme schrittweise und interpretierbar lösen.", "metrics": {"bleu_score": 38.71551944619038, "chrf_score": 75.80935171254833, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.39517393708229065, "metricx_qe_score": 0.3752603828907013, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "So können wir zum Beispiel in Schritt zwei diesen Teiler erhalten, der 27 ist.", "metrics": {"bleu_score": 14.62806365365753, "chrf_score": 58.55822094250789, "xcomet_score": 0.8709793090820312, "xcomet_qe_score": 0.9064650535583496, "metricx_score": 0.9061622619628906, "metricx_qe_score": 1.130623459815979, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um die relevanten Inhalte zu finden.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.2288219928741455, "metricx_qe_score": 0.19367283582687378, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "In diesen Schritten erhalten wir die Teiler.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9997648000717163, "xcomet_qe_score": 0.9984711408615112, "metricx_score": 0.454661101102829, "metricx_qe_score": 1.0295369625091553, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir in diesem dritten Schritt tatsächlich den Quotienten.", "metrics": {"bleu_score": 35.93041119630842, "chrf_score": 78.14920374149271, "xcomet_score": 0.9972431659698486, "xcomet_qe_score": 0.9907289743423462, "metricx_score": 1.0759165287017822, "metricx_qe_score": 1.6355054378509521, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Alles klar. Und nach diesen drei Schritten können wir die Ergebnisse aus dem zweiten Schritt tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und schließlich können wir die Dividenden erhalten.", "metrics": {"bleu_score": 41.49616795062542, "chrf_score": 83.2137403218321, "xcomet_score": 0.9888207912445068, "xcomet_qe_score": 0.975402295589447, "metricx_score": 1.0912821292877197, "metricx_qe_score": 1.6279239654541016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier erzeugen wir tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Quantitäten zu erzeugen.", "metrics": {"bleu_score": 5.422832877388758, "chrf_score": 43.97166685627668, "xcomet_score": 0.9754398465156555, "xcomet_qe_score": 0.9732636213302612, "metricx_score": 0.8791293501853943, "metricx_qe_score": 0.9561573266983032, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Das macht den Prozess genauer.", "metrics": {"bleu_score": 30.213753973567677, "chrf_score": 53.38238387625975, "xcomet_score": 0.9950906038284302, "xcomet_qe_score": 0.977350115776062, "metricx_score": 0.31846505403518677, "metricx_qe_score": 0.9903241395950317, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir mit einer Reihe von Größen, die in den Fragen angegeben sind, und einigen Konstanten als Ausgangspunkt.", "metrics": {"bleu_score": 37.48334498776697, "chrf_score": 55.40028854722125, "xcomet_score": 0.9827888011932373, "xcomet_qe_score": 0.9748855829238892, "metricx_score": 1.4014766216278076, "metricx_qe_score": 1.6767295598983765, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt.", "metrics": {"bleu_score": 36.06452879987793, "chrf_score": 80.28357106983552, "xcomet_score": 0.9844173192977905, "xcomet_qe_score": 0.9895853400230408, "metricx_score": 1.127659559249878, "metricx_qe_score": 2.294699192047119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen einen Operator von QI nach QJ aus und ein solcher Ausdruck ist tatsächlich gerichtet.", "metrics": {"bleu_score": 11.071887991253549, "chrf_score": 62.54942001478725, "xcomet_score": 0.9437196254730225, "xcomet_qe_score": 0.9476289749145508, "metricx_score": 2.0129785537719727, "metricx_qe_score": 1.8097949028015137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben hier auch eine umgekehrte Subtraktion, um die entgegengesetzte Richtung darzustellen.", "metrics": {"bleu_score": 23.800153836413934, "chrf_score": 73.39946439198035, "xcomet_score": 0.978998064994812, "xcomet_qe_score": 0.9603822231292725, "metricx_score": 1.0610630512237549, "metricx_qe_score": 1.6973824501037598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie die Relationsextraktion.", "metrics": {"bleu_score": 7.267884212102741, "chrf_score": 42.3679063659331, "xcomet_score": 0.9993832111358643, "xcomet_qe_score": 0.9989855289459229, "metricx_score": 1.9776597023010254, "metricx_qe_score": 2.9239537715911865, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formalen deduktiven System wenden wir zum Zeitpunkt t den Operator auf das QI-QJ-Paar an und erhalten dann diese neuen Ausdrücke.", "metrics": {"bleu_score": 28.84708232647883, "chrf_score": 63.88069003373611, "xcomet_score": 0.9601510763168335, "xcomet_qe_score": 0.9561300277709961, "metricx_score": 1.486815094947815, "metricx_qe_score": 2.488570213317871, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es zu den nächsten Staaten hinzu, um eine neue Menge zu bilden.", "metrics": {"bleu_score": 43.33207865423753, "chrf_score": 60.44000642045181, "xcomet_score": 0.8805352449417114, "xcomet_qe_score": 0.8808268308639526, "metricx_score": 5.217087745666504, "metricx_qe_score": 2.022739887237549, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folie visualisiert tatsächlich die Entwicklung der Zustände, bei denen wir weiterhin Ausdrücke zu den aktuellen Zuständen hinzufügen.", "metrics": {"bleu_score": 6.632379583706114, "chrf_score": 52.388412221715775, "xcomet_score": 0.9774003028869629, "xcomet_qe_score": 0.9094813466072083, "metricx_score": 1.5165495872497559, "metricx_qe_score": 2.339195489883423, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vortrainiertes Sprachmodell, das BERT oder RoBERTa sein kann, und kodieren dann einen Satz, um diese quantitativen Darstellungen zu erhalten.", "metrics": {"bleu_score": 27.823042638325845, "chrf_score": 66.06289603775488, "xcomet_score": 0.9692489504814148, "xcomet_qe_score": 0.9489123821258545, "metricx_score": 0.8221049308776855, "metricx_qe_score": 0.7088977098464966, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir die quantitativen Darstellungen erhalten haben, können wir mit der Inferenz beginnen.", "metrics": {"bleu_score": 61.000344570143675, "chrf_score": 76.14275305572295, "xcomet_score": 0.9985803365707397, "xcomet_qe_score": 0.9967116117477417, "metricx_score": 0.6958228349685669, "metricx_qe_score": 1.199337124824524, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 durch Q2 geteilt und dann mit Q3 multipliziert zu erhalten.", "metrics": {"bleu_score": 32.04896054127566, "chrf_score": 71.36412637253142, "xcomet_score": 0.9527841806411743, "xcomet_qe_score": 0.9482941627502441, "metricx_score": 3.909290075302124, "metricx_qe_score": 4.995314121246338, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Darstellung, die im Grunde nur die Verkettung zwischen Q1 und Q2 ist, und dann wenden wir ein Feed-Forward-Netzwerk an, das durch den Operator parametrisiert ist.", "metrics": {"bleu_score": 58.24440455940564, "chrf_score": 87.03781797104442, "xcomet_score": 0.9170891046524048, "xcomet_qe_score": 0.8888091444969177, "metricx_score": 2.2882397174835205, "metricx_qe_score": 2.960766077041626, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erhalten wir die Ausdrucksdarstellung Q1/Q2.", "metrics": {"bleu_score": 6.550847048803501, "chrf_score": 57.417852473289535, "xcomet_score": 0.9717881679534912, "xcomet_qe_score": 0.971458911895752, "metricx_score": 1.0754683017730713, "metricx_qe_score": 1.2855169773101807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "In der Praxis können wir jedoch im Inferenzstadium auch einen falschen Ausdruck erhalten.", "metrics": {"bleu_score": 21.152545079560706, "chrf_score": 65.06611839272068, "xcomet_score": 0.9998346567153931, "xcomet_qe_score": 0.9989253282546997, "metricx_score": 0.8485286831855774, "metricx_qe_score": 1.6748102903366089, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist also jede mögliche Ausdrücke gleich der dreifachen Anzahl der Operatoren.", "metrics": {"bleu_score": 23.566578558703185, "chrf_score": 69.54679638095529, "xcomet_score": 0.9716053009033203, "xcomet_qe_score": 0.9733823537826538, "metricx_score": 3.047966480255127, "metricx_qe_score": 4.3068413734436035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu kontrollieren.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9924850463867188, "xcomet_qe_score": 0.9827297925949097, "metricx_score": 0.8107752799987793, "metricx_qe_score": 0.9124424457550049, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach aus unserem Suchraum entfernen.", "metrics": {"bleu_score": 60.3161203621801, "chrf_score": 81.67510234384292, "xcomet_score": 0.9959189891815186, "xcomet_qe_score": 0.9975526332855225, "metricx_score": 0.5890759229660034, "metricx_qe_score": 0.8914521932601929, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir dasselbe, nur dass wir diesmal eine zusätzliche Menge hinzufügen.", "metrics": {"bleu_score": 20.708304248442662, "chrf_score": 48.86971062440836, "xcomet_score": 0.9630852937698364, "xcomet_qe_score": 0.926967978477478, "metricx_score": 2.6416940689086914, "metricx_qe_score": 4.874173641204834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Menge stammt aus dem zuvor berechneten Ausdruck.", "metrics": {"bleu_score": 30.34691922392703, "chrf_score": 69.97373201919828, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.47827595472335815, "metricx_qe_score": 2.3371500968933105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir diesen endgültigen Ausdruck Q erhalten.", "metrics": {"bleu_score": 11.984004548101536, "chrf_score": 71.07673508717136, "xcomet_score": 0.8790936470031738, "xcomet_qe_score": 0.8678323030471802, "metricx_score": 7.893027305603027, "metricx_qe_score": 10.238727569580078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke anders ist als im vorherigen Schritt.", "metrics": {"bleu_score": 73.31765459202478, "chrf_score": 93.38422602751417, "xcomet_score": 0.9874875545501709, "xcomet_qe_score": 0.9545896649360657, "metricx_score": 1.5972998142242432, "metricx_qe_score": 2.6757240295410156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Ein solcher Unterschied macht es schwierig, eine Strahlensuche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unausgeglichen ist.", "metrics": {"bleu_score": 42.18752038739221, "chrf_score": 71.74950457519648, "xcomet_score": 0.9122397899627686, "xcomet_qe_score": 0.9301931262016296, "metricx_score": 1.5080875158309937, "metricx_qe_score": 1.7442054748535156, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Das Trainingsverfahren ist ähnlich wie das Training eines sequenziellen Modells, bei dem wir den Verlust zu jedem Zeitpunkt optimieren.", "metrics": {"bleu_score": 34.45778903767542, "chrf_score": 67.7264608302828, "xcomet_score": 0.9749116897583008, "xcomet_qe_score": 0.9671605825424194, "metricx_score": 0.6911033987998962, "metricx_qe_score": 1.578834891319275, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch dieses Tau, um darzustellen, wann wir diesen Generierungsprozess beenden sollten.", "metrics": {"bleu_score": 77.7811122305422, "chrf_score": 93.16890559489094, "xcomet_score": 0.9878531694412231, "xcomet_qe_score": 0.9760472774505615, "metricx_score": 0.8554815649986267, "metricx_qe_score": 1.2309409379959106, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist der Raum anders als bei Sequenz zu Sequenz, da der Raum bei jeder Zeitstufe anders ist, während es sich bei dem traditionellen Sequenz-zu-Sequenz-Modell um die Anzahl der Vokabeln handelt.", "metrics": {"bleu_score": 21.34405162675802, "chrf_score": 65.61332575060185, "xcomet_score": 0.9030709266662598, "xcomet_qe_score": 0.8115259408950806, "metricx_score": 2.184495449066162, "metricx_qe_score": 1.9394923448562622, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Es ermöglicht uns auch, bestimmte Einschränkungen aus Vorwissen zu erzwingen.", "metrics": {"bleu_score": 25.211936184349828, "chrf_score": 60.45797568322809, "xcomet_score": 0.9568219184875488, "xcomet_qe_score": 0.9392016530036926, "metricx_score": 1.4953161478042603, "metricx_qe_score": 2.01229190826416, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Experimente mit den gängigen mathematischen Problemdatensätzen MATH, MATH23K, MATHQA und SWAMP durch.", "metrics": {"bleu_score": 8.571745718075354, "chrf_score": 47.011721795797506, "xcomet_score": 0.8435331583023071, "xcomet_qe_score": 0.8786957263946533, "metricx_score": 5.667844772338867, "metricx_qe_score": 5.425041675567627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir kurz die Ergebnisse im Vergleich zu den bisher besten Ansätzen.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 91.51146496996535, "xcomet_score": 0.9913967847824097, "xcomet_qe_score": 0.976719856262207, "metricx_score": 0.18897739052772522, "metricx_qe_score": 0.26035961508750916, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere am besten funktionierende Variante ist Roberta Detektiv.", "metrics": {"bleu_score": 11.339582221952005, "chrf_score": 38.13305099585159, "xcomet_score": 0.8951400518417358, "xcomet_qe_score": 0.8694791793823242, "metricx_score": 4.269052505493164, "metricx_qe_score": 3.900538921356201, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir im Gegensatz zu anderen Ansätzen keine Beam-Suche.", "metrics": {"bleu_score": 9.152959627456559, "chrf_score": 52.99226150493341, "xcomet_score": 0.9297088384628296, "xcomet_qe_score": 0.9195059537887573, "metricx_score": 2.1040592193603516, "metricx_qe_score": 4.3034586906433105, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Also, die besten Ansätze sind oft baumgestützt.", "metrics": {"bleu_score": 16.89983564524027, "chrf_score": 42.55513711924776, "xcomet_score": 0.9511039853096008, "xcomet_qe_score": 0.9441975951194763, "metricx_score": 2.982358932495117, "metricx_qe_score": 2.665456533432007, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Grundsatzmodell dieses Baummodell deutlich übertreffen.", "metrics": {"bleu_score": 5.508583800214239, "chrf_score": 35.74689290836865, "xcomet_score": 0.8396354913711548, "xcomet_qe_score": 0.826378583908081, "metricx_score": 2.084477663040161, "metricx_qe_score": 1.3624070882797241, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MathQA oder SWAG nicht wirklich hoch sind.", "metrics": {"bleu_score": 68.99302125555486, "chrf_score": 85.03362866504594, "xcomet_score": 0.9401757717132568, "xcomet_qe_score": 0.9403014779090881, "metricx_score": 2.5972800254821777, "metricx_qe_score": 3.153289318084717, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse weiter auf", "metrics": {"bleu_score": 11.708995388048026, "chrf_score": 52.32141693781042, "xcomet_score": 0.7214614152908325, "xcomet_qe_score": 0.8145463466644287, "metricx_score": 4.071658611297607, "metricx_qe_score": 1.335111141204834, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "SWAMP und dieser Datensatz ist eine Herausforderung, da der Autor versucht hat, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. die Hinzufügung von Umgebungsinformationen und zusätzlichen Mengen.", "metrics": {"bleu_score": 64.13169901084213, "chrf_score": 81.93849240862279, "xcomet_score": 0.9250752925872803, "xcomet_qe_score": 0.9136885404586792, "metricx_score": 3.6126344203948975, "metricx_qe_score": 4.428590774536133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "In unserer Vorhersage haben wir festgestellt, dass einige der Zwischenwerte tatsächlich negativ sind.", "metrics": {"bleu_score": 38.70605144677149, "chrf_score": 76.47284818888745, "xcomet_score": 0.9968360662460327, "xcomet_qe_score": 0.991976261138916, "metricx_score": 0.32539424300193787, "metricx_qe_score": 0.4383816123008728, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "In diesen Fragen fragen wir zum Beispiel, wie viele Äpfel Drake hat.", "metrics": {"bleu_score": 23.03447207468007, "chrf_score": 62.894608063067416, "xcomet_score": 0.8422775864601135, "xcomet_qe_score": 0.8144106268882751, "metricx_score": 3.6828806400299072, "metricx_qe_score": 2.6739375591278076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen wie 17 Feldbilder und Stephen hatte 8 Bilder, was völlig irrelevant ist.", "metrics": {"bleu_score": 58.69740862506178, "chrf_score": 78.14091233982275, "xcomet_score": 0.8858983516693115, "xcomet_qe_score": 0.8730011582374573, "metricx_score": 5.201973915100098, "metricx_qe_score": 4.435524940490723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also Vorhersagen wie diese, die negative Werte erzeugen.", "metrics": {"bleu_score": 54.844980922047604, "chrf_score": 79.30386297209215, "xcomet_score": 0.9908307790756226, "xcomet_qe_score": 0.9766910076141357, "metricx_score": 0.4803025424480438, "metricx_qe_score": 0.5867586731910706, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben diese beiden Ausdrücke beobachtet.", "metrics": {"bleu_score": 12.337170820562472, "chrf_score": 37.45375896678608, "xcomet_score": 0.6525212526321411, "xcomet_qe_score": 0.8638011813163757, "metricx_score": 4.160698413848877, "metricx_qe_score": 8.916892051696777, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können also den Suchraum tatsächlich einschränken, indem wir die negativen Ergebnisse entfernen, sodass wir die Antwort korrekt machen können.", "metrics": {"bleu_score": 39.64513253420688, "chrf_score": 67.68057183082826, "xcomet_score": 0.9407095909118652, "xcomet_qe_score": 0.8504023551940918, "metricx_score": 1.8150742053985596, "metricx_qe_score": 2.6387276649475098, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen außerdem fest, dass eine solche Einschränkung die Leistung einiger Modelle erheblich verbessert.", "metrics": {"bleu_score": 24.74477295896412, "chrf_score": 52.2772644416124, "xcomet_score": 0.9842941761016846, "xcomet_qe_score": 0.974256157875061, "metricx_score": 0.6794754862785339, "metricx_qe_score": 0.5528147220611572, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert und beim roboterbasierten Modell tatsächlich zwei Punkte.", "metrics": {"bleu_score": 20.274322077705452, "chrf_score": 51.07737188549078, "xcomet_score": 0.7367380857467651, "xcomet_qe_score": 0.7375539541244507, "metricx_score": 10.155597686767578, "metricx_qe_score": 9.555392265319824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat eine bessere Sprachverständnisfähigkeit, sodass die Zahl hier für Roberta höher und für Bert niedriger ist.", "metrics": {"bleu_score": 34.00215619680846, "chrf_score": 73.50396682715407, "xcomet_score": 0.9993537664413452, "xcomet_qe_score": 1.0, "metricx_score": 0.6243383884429932, "metricx_qe_score": 1.1471967697143555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch versucht, die Schwierigkeiten hinter dieser Frage zu analysieren.", "metrics": {"bleu_score": 29.782017963590448, "chrf_score": 64.48077969019067, "xcomet_score": 0.8153091073036194, "xcomet_qe_score": 0.7981231212615967, "metricx_score": 3.5178258419036865, "metricx_qe_score": 5.5587005615234375, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der nicht genutzten Mengen hier als irrelevante Information betrachtet werden kann.", "metrics": {"bleu_score": 65.14613449066714, "chrf_score": 91.71419711300132, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.549547016620636, "metricx_qe_score": 0.5778229832649231, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir, dass wir den Prozentsatz der Proben haben, die wir mit Qualitäten ungenutzt haben, und der SWAMP-Datensatz hat den größten Anteil.", "metrics": {"bleu_score": 45.59274666224602, "chrf_score": 73.66752126834925, "xcomet_score": 0.8286505341529846, "xcomet_qe_score": 0.8291887044906616, "metricx_score": 6.733919143676758, "metricx_qe_score": 6.942882537841797, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir auch die Gesamtleistung.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9984831809997559, "xcomet_qe_score": 0.9979250431060791, "metricx_score": 0.20939618349075317, "metricx_qe_score": 0.28272944688796997, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für die Proben ohne „und“ Mengen ist die Gesamtleistung tatsächlich höher als die Gesamtleistung.", "metrics": {"bleu_score": 36.15855225145533, "chrf_score": 61.669693226894495, "xcomet_score": 0.7084080576896667, "xcomet_qe_score": 0.5414929389953613, "metricx_score": 6.31683874130249, "metricx_qe_score": 7.925026893615723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber mit diesen Proben, die eine ungenutzte Menge haben, ist es tatsächlich viel schlechter als die, die viel schlechter sind als", "metrics": {"bleu_score": 12.962472880491877, "chrf_score": 54.978142019930566, "xcomet_score": 0.7363377809524536, "xcomet_qe_score": 0.7617260217666626, "metricx_score": 11.712529182434082, "metricx_qe_score": 10.449692726135254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Leistung von MAWP-Speichern haben wir nicht wirklich viele Todesfälle, also ignoriere ich diesen Teil einfach.", "metrics": {"bleu_score": 56.82854869630478, "chrf_score": 81.6234134674753, "xcomet_score": 0.8015440702438354, "xcomet_qe_score": 0.7509957551956177, "metricx_score": 6.237487316131592, "metricx_qe_score": 7.28727388381958, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretierbarkeit anhand eines Beispiels für die Crash-Vorhersage zeigen.", "metrics": {"bleu_score": 34.38931217657843, "chrf_score": 68.23291880655535, "xcomet_score": 0.8622099161148071, "xcomet_qe_score": 0.8462141752243042, "metricx_score": 4.833736896514893, "metricx_qe_score": 5.539735794067383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Hier macht unser Modell tatsächlich eine falsche Vorhersage im ersten Schritt.", "metrics": {"bleu_score": 76.7733168433653, "chrf_score": 91.63609174797219, "xcomet_score": 0.9902490377426147, "xcomet_qe_score": 0.9762187004089355, "metricx_score": 0.346386194229126, "metricx_qe_score": 0.5226640701293945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren, okay?", "metrics": {"bleu_score": 75.77395672414198, "chrf_score": 92.4350760138374, "xcomet_score": 0.9998232126235962, "xcomet_qe_score": 0.9988508224487305, "metricx_score": 0.6390624046325684, "metricx_qe_score": 0.7242619395256042, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken, dass dieser Satz das Modell zu einer falschen Vorhersage verleiten könnte.", "metrics": {"bleu_score": 54.10822690539399, "chrf_score": 82.56139688599697, "xcomet_score": 0.999963641166687, "xcomet_qe_score": 0.9997636079788208, "metricx_score": 0.2406361848115921, "metricx_qe_score": 0.25704246759414673, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Hier führt das Einfügen einer weiteren 35 dazu, dass das Modell denkt, es sollte ein Additionsoperator sein.", "metrics": {"bleu_score": 46.84580982108429, "chrf_score": 76.27744831863596, "xcomet_score": 0.9220806360244751, "xcomet_qe_score": 0.8399518728256226, "metricx_score": 1.5839663743972778, "metricx_qe_score": 2.654695510864258, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben versucht, den Satz zu überarbeiten, sodass er etwa so lautet: „Die Anzahl der Birnbäume ist 55 geringer als die der Apfelbäume.“", "metrics": {"bleu_score": 15.04843536148922, "chrf_score": 57.16545976108879, "xcomet_score": 0.9761838316917419, "xcomet_qe_score": 0.9814930558204651, "metricx_score": 2.003983736038208, "metricx_qe_score": 1.4968115091323853, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben es so gestaltet, dass es genauere Semantik vermittelt, sodass das Modell in der Lage ist, die Vorhersage korrekt zu treffen.", "metrics": {"bleu_score": 63.941271162881165, "chrf_score": 76.95182762448404, "xcomet_score": 0.9918088912963867, "xcomet_qe_score": 0.9792304039001465, "metricx_score": 0.8484247922897339, "metricx_qe_score": 1.121612787246704, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie interpretierbare Vorhersagen uns helfen, das Modellverhalten zu verstehen.", "metrics": {"bleu_score": 48.23958272912998, "chrf_score": 81.4397856175313, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4173453748226166, "metricx_qe_score": 0.582865297794342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell tatsächlich ziemlich effizient.", "metrics": {"bleu_score": 67.61304462994481, "chrf_score": 86.72354926587705, "xcomet_score": 0.9828131198883057, "xcomet_qe_score": 0.9648829698562622, "metricx_score": 0.6819745898246765, "metricx_qe_score": 0.8676100373268127, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Wir können ein interpretierbares Lösungsverfahren bereitstellen.", "metrics": {"bleu_score": 15.685718045401451, "chrf_score": 61.99305491790934, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.22890545427799225, "metricx_qe_score": 0.24012765288352966, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Wir können leicht einige Vorwissen als Einschränkung einbeziehen, was die Leistung verbessern kann.", "metrics": {"bleu_score": 14.545983747002639, "chrf_score": 55.33057237059524, "xcomet_score": 0.9814717769622803, "xcomet_qe_score": 0.9754199981689453, "metricx_score": 1.127995252609253, "metricx_qe_score": 0.8842276334762573, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf mathematische Problemlösungsaufgaben angewendet werden kann, sondern auch auf andere Aufgaben, die mehrstufiges Denken erfordern.", "metrics": {"bleu_score": 21.284976748471415, "chrf_score": 61.78921536529278, "xcomet_score": 0.9709017276763916, "xcomet_qe_score": 0.9839080572128296, "metricx_score": 1.4765522480010986, "metricx_qe_score": 2.171584129333496, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben jedoch auch bestimmte Einschränkungen.", "metrics": {"bleu_score": 6.567274736060395, "chrf_score": 16.86450392790623, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, kann der Speicherverbrauch ziemlich hoch sein.", "metrics": {"bleu_score": 83.94327083733333, "chrf_score": 93.01356276863744, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.45400747656822205, "metricx_qe_score": 0.47154533863067627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, dass, wie bereits erwähnt, die Wahrscheinlichkeitsverteilung zu verschiedenen Zeitpunkten unausgeglichen ist, sodass es auch ziemlich schwierig ist, Strahlsuchen anzuwenden.", "metrics": {"bleu_score": 5.064476165466096, "chrf_score": 51.96778991176237, "xcomet_score": 0.9106115102767944, "xcomet_qe_score": 0.9468741416931152, "metricx_score": 3.105285406112671, "metricx_qe_score": 3.8730416297912598, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das war's mit dem Vortrag und Fragen sind willkommen. Danke.", "metrics": {"bleu_score": 3.1572564565455266, "chrf_score": 28.159288641574687, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7352865934371948, "metricx_qe_score": 0.48235130310058594, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, ich heiße Antoine und komme von der Universität Maastricht.", "metrics": {"bleu_score": 35.3174306771528, "chrf_score": 66.67789756034168, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.007650792598724365, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde meine gemeinsame Arbeit mit Jerry vorstellen, die sich mit einem neuen Datensatz für die Abrufbarkeit von Gesetzesartikeln befasst.", "metrics": {"bleu_score": 44.03867502943715, "chrf_score": 72.65516691509379, "xcomet_score": 0.9799036979675293, "xcomet_qe_score": 0.977490246295929, "metricx_score": 1.4163234233856201, "metricx_qe_score": 1.097512125968933, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtliche Fragen sind ein integraler Bestandteil des Lebens vieler Menschen.", "metrics": {"bleu_score": 51.93071778680675, "chrf_score": 78.77400495094894, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4245132803916931, "metricx_qe_score": 0.3024641275405884, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat nur wenig oder gar keine Kenntnisse über ihre Rechte und grundlegende rechtliche Verfahren.", "metrics": {"bleu_score": 54.68017145144114, "chrf_score": 78.12114821223003, "xcomet_score": 0.9985650777816772, "xcomet_qe_score": 0.9965877532958984, "metricx_score": 0.28052544593811035, "metricx_qe_score": 0.48253437876701355, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Folge davon bleiben viele gefährdete Bürger, die sich die teure Hilfe eines Rechtsberaters nicht leisten können, ungeschützt oder schlimmstenfalls werden sie ausgebeutet.", "metrics": {"bleu_score": 26.92473675911823, "chrf_score": 58.55125653131357, "xcomet_score": 0.984154224395752, "xcomet_qe_score": 0.9911736845970154, "metricx_score": 0.36138761043548584, "metricx_qe_score": 0.3182520568370819, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Kluft zwischen Menschen und dem Gesetz zu überbrücken, indem wir ein effektives Abrufsystem für gesetzliche Artikel entwickeln.", "metrics": {"bleu_score": 60.493083201449835, "chrf_score": 77.67675524933748, "xcomet_score": 0.9712827205657959, "xcomet_qe_score": 0.9754902720451355, "metricx_score": 0.7323035001754761, "metricx_qe_score": 0.5287465453147888, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte einen kostenlosen professionellen Rechtsbeistand für ungebildete Menschen anbieten.", "metrics": {"bleu_score": 59.230330720232516, "chrf_score": 78.19126523114912, "xcomet_score": 0.9767031669616699, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.7102258205413818, "metricx_qe_score": 0.41659215092658997, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit beschäftigen, beschreiben wir zunächst das Problem der Abrufung von Gesetzesartikeln.", "metrics": {"bleu_score": 33.35910322759462, "chrf_score": 72.71775998318867, "xcomet_score": 0.9739854335784912, "xcomet_qe_score": 0.979875385761261, "metricx_score": 1.5171946287155151, "metricx_qe_score": 1.0590800046920776, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer einfachen Frage zu Allelen, wie z. B. „Welche Risiken gehe ich ein, wenn ich die berufliche Vertraulichkeit verletze?“", "metrics": {"bleu_score": 10.864991539917154, "chrf_score": 41.72941301351735, "xcomet_score": 0.823572039604187, "xcomet_qe_score": 0.8564146161079407, "metricx_score": 7.020621299743652, "metricx_qe_score": 6.710383415222168, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetzeskörper abzurufen.", "metrics": {"bleu_score": 22.35942642459069, "chrf_score": 56.12192368315196, "xcomet_score": 0.9906802773475647, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.3956226706504822, "metricx_qe_score": 0.39148005843162537, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsabrufsaufgabe bringt ihre eigenen Herausforderungen mit sich.", "metrics": {"bleu_score": 29.5580130165708, "chrf_score": 69.2358443346171, "xcomet_score": 0.9819878339767456, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6693226099014282, "metricx_qe_score": 0.2802746593952179, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst einmal geht es um zwei Arten von Sprachen.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 61.9969692307089, "xcomet_score": 0.9988100528717041, "xcomet_qe_score": 0.9957095384597778, "metricx_score": 0.19476734101772308, "metricx_qe_score": 0.22556333243846893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "Allgemeine Umgangssprache für die Fragen und komplexe Rechtssprache für die Gesetze.", "metrics": {"bleu_score": 31.289743229238155, "chrf_score": 56.81154016586526, "xcomet_score": 0.9870761632919312, "xcomet_qe_score": 1.0, "metricx_score": 0.4292537569999695, "metricx_qe_score": 0.3604431450366974, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in der Sprachverteilung erschweren es einem System, relevante Kandidaten abzurufen, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die der Terminologie der Gesetze entspricht.", "metrics": {"bleu_score": 65.92096920050079, "chrf_score": 83.91969850334692, "xcomet_score": 0.9205211400985718, "xcomet_qe_score": 0.8555479645729065, "metricx_score": 1.6000702381134033, "metricx_qe_score": 1.292995572090149, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das Gesetz nicht einfach ein Stapel unabhängiger Artikel, die als vollständige Informationsquelle behandelt werden können, wie z. B. Nachrichten oder Rezepte.", "metrics": {"bleu_score": 27.610912695209617, "chrf_score": 64.77121470899161, "xcomet_score": 0.9992673397064209, "xcomet_qe_score": 1.0, "metricx_score": 0.9053893089294434, "metricx_qe_score": 0.802681028842926, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen handelt es sich um eine strukturierte Sammlung von Rechtsvorschriften, die nur dann eine vollständige Bedeutung haben, wenn sie in ihrem Gesamtzusammenhang betrachtet werden, d. h. zusammen mit den ergänzenden Informationen aus den benachbarten Artikeln, den Bereichen und Unterbereichen, zu denen sie gehören, und ihrem Platz in der Struktur des Gesetzes.", "metrics": {"bleu_score": 47.78264310675315, "chrf_score": 76.26767078714188, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.11162184178829193, "metricx_qe_score": 0.1953071802854538, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich sind gesetzliche Artikel kein kleiner Absatz, was in den meisten Retrieval-Arbeiten die typische Abrufeinheit ist.", "metrics": {"bleu_score": 23.447977464683532, "chrf_score": 51.50828942256901, "xcomet_score": 0.9405982494354248, "xcomet_qe_score": 0.9221628904342651, "metricx_score": 1.6300503015518188, "metricx_qe_score": 2.512286424636841, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier gibt es lange Dokumente, die bis zu 6000 Wörter umfassen können.", "metrics": {"bleu_score": 78.25422900366432, "chrf_score": 94.04098148255471, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.04275370389223099, "metricx_qe_score": 0.08780504763126373, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte in der NLP haben großes Interesse an vielen juristischen Aufgaben geweckt, wie z. B. der Vorhersage von Rechtsurteilen oder der automatischen Vertragsprüfung.", "metrics": {"bleu_score": 45.567792897196725, "chrf_score": 73.14520985726902, "xcomet_score": 0.9826030731201172, "xcomet_qe_score": 0.9832593202590942, "metricx_score": 0.6470980644226074, "metricx_qe_score": 1.5814876556396484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die Abrufbarkeit von Gesetzesartikeln ist jedoch aufgrund des Mangels an großen und qualitativ hochwertigen Datensätzen mit Beschriftungen weitgehend unverändert geblieben.", "metrics": {"bleu_score": 38.091370416670806, "chrf_score": 74.6750469785092, "xcomet_score": 0.9775806665420532, "xcomet_qe_score": 0.984963595867157, "metricx_score": 0.7840510010719299, "metricx_qe_score": 0.6735779047012329, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit stellen wir einen neuen, französischsprachigen, bürgerzentrierten Datensatz vor, um zu untersuchen, ob ein Abrufmodell die Effizienz und Zuverlässigkeit eines Rechtsfachmanns für die Aufgabe des Abrufs von Gesetzesartikeln annähern kann.", "metrics": {"bleu_score": 26.527534815184076, "chrf_score": 60.21734764287054, "xcomet_score": 0.889549732208252, "xcomet_qe_score": 0.9357158541679382, "metricx_score": 2.34070086479187, "metricx_qe_score": 2.2900960445404053, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Der belgische Datensatz zur gesetzlichen Artikelabrufbarkeit umfasst mehr als 1.100.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.000.0", "metrics": {"bleu_score": 1.8751197657869223, "chrf_score": 3.9764530723662967, "xcomet_score": 0.2658514082431793, "xcomet_qe_score": 0.26619842648506165, "metricx_score": 11.917867660522461, "metricx_qe_score": 10.168020248413086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen decken eine breite Palette von Themen ab, von Familie, Wohnen, Geld bis hin zu Arbeit und Sozialversicherung.", "metrics": {"bleu_score": 62.50901130891216, "chrf_score": 73.71883530003926, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.14768609404563904, "metricx_qe_score": 0.07766592502593994, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen wurde von erfahrenen Juristen mit Verweisen auf relevante Artikel aus einem Korpus von mehr als 22.600 Artikeln gekennzeichnet.", "metrics": {"bleu_score": 71.12545753924933, "chrf_score": 72.52872714563455, "xcomet_score": 0.8902087807655334, "xcomet_qe_score": 0.9337219595909119, "metricx_score": 2.6442744731903076, "metricx_qe_score": 3.082571029663086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Gesetzbücher. Lassen Sie uns nun darüber sprechen, wie wir diese Datensätze gesammelt haben.", "metrics": {"bleu_score": 56.35190098079901, "chrf_score": 81.12083830659668, "xcomet_score": 0.6875137090682983, "xcomet_qe_score": 0.7104877829551697, "metricx_score": 6.143500804901123, "metricx_qe_score": 10.299114227294922, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst begannen wir mit der Zusammenstellung eines großen Korpus von Rechtsartikeln.", "metrics": {"bleu_score": 24.384183193426086, "chrf_score": 67.94059325167929, "xcomet_score": 1.0, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.18062573671340942, "metricx_qe_score": 0.47216296195983887, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich zugängliche belgische Codes in Betracht gezogen und alle ihre Artikel sowie die entsprechenden Abschnittsüberschriften extrahiert.", "metrics": {"bleu_score": 55.882651974144544, "chrf_score": 80.07156870176222, "xcomet_score": 0.9854049682617188, "xcomet_qe_score": 0.9909180402755737, "metricx_score": 2.4789175987243652, "metricx_qe_score": 1.2237541675567627, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf relevante Gesetze.", "metrics": {"bleu_score": 46.65904311461236, "chrf_score": 61.41642355332066, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3132973313331604, "metricx_qe_score": 0.2885987162590027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa 4.000 E-Mails von belgischen Bürgern erhält, die um Rat zu einem persönlichen Rechtsproblem bitten.", "metrics": {"bleu_score": 72.62931407233668, "chrf_score": 80.85322304227482, "xcomet_score": 0.9993928670883179, "xcomet_qe_score": 1.0, "metricx_score": 0.15738362073898315, "metricx_qe_score": 0.1483677476644516, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir hatten das Glück, Zugang zu ihren Websites zu erhalten, auf denen ihr Team erfahrener Juristen die häufigsten rechtlichen Probleme in Belgien behandelt.", "metrics": {"bleu_score": 67.32378032068624, "chrf_score": 75.45597118707808, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5246574878692627, "metricx_qe_score": 0.6252104043960571, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen gesammelt, die mit Kategorien, Unterkategorien und rechtlichen Verweisen auf relevante Gesetze versehen sind.", "metrics": {"bleu_score": 43.7241098509127, "chrf_score": 72.93847645025652, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.33742743730545044, "metricx_qe_score": 0.2953531742095947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich haben wir die rechtlichen Referenzen durchgesehen und die Fragen herausgefiltert, deren Referenzen nicht Artikel in einem der von uns berücksichtigten Gesetzbücher waren.", "metrics": {"bleu_score": 58.798374010174506, "chrf_score": 74.27582558354511, "xcomet_score": 0.9748846292495728, "xcomet_qe_score": 0.9803054332733154, "metricx_score": 0.623691976070404, "metricx_qe_score": 0.6700136065483093, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die restlichen Referenzen wurden mit den entsprechenden Artikel-IDs aus OCorpus abgeglichen und konvertiert.", "metrics": {"bleu_score": 13.919157443507983, "chrf_score": 52.477184797362675, "xcomet_score": 0.979210376739502, "xcomet_qe_score": 0.9767132997512817, "metricx_score": 2.733567476272583, "metricx_qe_score": 2.208000421524048, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.108 Fragen, die jeweils sorgfältig mit den Ideen der relevanten Artikel aus Wikipedia versehen waren.", "metrics": {"bleu_score": 16.70341916223, "chrf_score": 44.302742316389775, "xcomet_score": 0.7596644163131714, "xcomet_qe_score": 0.7368621230125427, "metricx_score": 8.301862716674805, "metricx_qe_score": 12.36463737487793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zudem hat jede Frage eine Hauptkategorie und eine Verkettung von Unterkategorien.", "metrics": {"bleu_score": 74.25271143743538, "chrf_score": 79.56231740187945, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3901602029800415, "metricx_qe_score": 0.590121328830719, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Jeder Artikel wird mit der Verkettung der nachfolgenden Überschrift in der Struktur des Gesetzes versehen.", "metrics": {"bleu_score": 9.375572291917328, "chrf_score": 58.08742982362527, "xcomet_score": 0.9672528505325317, "xcomet_qe_score": 0.9419910907745361, "metricx_score": 2.9462060928344727, "metricx_qe_score": 4.446910381317139, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzlichen Informationen werden in der vorliegenden Arbeit nicht verwendet, könnten aber für zukünftige Forschungen zur juristischen Informationsbeschaffung oder zur Klassifizierung juristischer Texte von Interesse sein.", "metrics": {"bleu_score": 60.65859249958907, "chrf_score": 81.966169976001, "xcomet_score": 0.9896233081817627, "xcomet_qe_score": 0.999557375907898, "metricx_score": 0.7616946697235107, "metricx_qe_score": 0.9843029975891113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale der Datensätze an.", "metrics": {"bleu_score": 51.33450480401705, "chrf_score": 68.10836397087367, "xcomet_score": 0.9848153591156006, "xcomet_qe_score": 0.9983623027801514, "metricx_score": 0.2762190103530884, "metricx_qe_score": 0.09951961040496826, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Fragen sind zwischen fünf und vierundvierzig Wörter lang, mit einem Median von vierzehn Wörtern.", "metrics": {"bleu_score": 54.11927503805856, "chrf_score": 69.41788649329817, "xcomet_score": 0.9658852219581604, "xcomet_qe_score": 0.9728624224662781, "metricx_score": 2.304790496826172, "metricx_qe_score": 1.4095020294189453, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer mittleren Länge von 77 Wörtern, wobei 140.000", "metrics": {"bleu_score": 19.513877075399087, "chrf_score": 49.22897506053464, "xcomet_score": 0.7462666034698486, "xcomet_qe_score": 0.7466183304786682, "metricx_score": 10.110245704650879, "metricx_qe_score": 9.744891166687012, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "Zwei von ihnen überschritten 1.000.", "metrics": {"bleu_score": 9.22364410103253, "chrf_score": 23.685078217113844, "xcomet_score": 0.2174503356218338, "xcomet_qe_score": 0.15997375547885895, "metricx_score": 6.944401264190674, "metricx_qe_score": 5.833672523498535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, behandeln die Fragen eine Vielzahl von Themen, wobei etwa 85 % von ihnen entweder Familie, Wohnen, Geld oder Gerechtigkeit betreffen.", "metrics": {"bleu_score": 23.985416543727368, "chrf_score": 60.79724959352759, "xcomet_score": 0.9897127151489258, "xcomet_qe_score": 0.9860270023345947, "metricx_score": 0.14454789459705353, "metricx_qe_score": 0.1991303712129593, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Die restlichen 15 % betreffen entweder die Sozialversicherung, Ausländer oder die Arbeit.", "metrics": {"bleu_score": 22.355093096292105, "chrf_score": 66.36293921666294, "xcomet_score": 0.9897557497024536, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.189749836921692, "metricx_qe_score": 0.4423508644104004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr vielfältig, da sie aus 32 verschiedenen belgischen Codes stammen, die eine große Anzahl von Rechtsgebieten abdecken.", "metrics": {"bleu_score": 69.63845241054851, "chrf_score": 78.62454592053241, "xcomet_score": 0.9845517873764038, "xcomet_qe_score": 0.9929523468017578, "metricx_score": 1.42317533493042, "metricx_qe_score": 0.9215279221534729, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Codes gesammelt wurden.", "metrics": {"bleu_score": 61.47881529512643, "chrf_score": 74.7960335439847, "xcomet_score": 0.9758502244949341, "xcomet_qe_score": 0.94249027967453, "metricx_score": 3.0755269527435303, "metricx_qe_score": 2.747055768966675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Von den 22.633 Artikeln werden nur 1.612 als relevant für mindestens", "metrics": {"bleu_score": 57.95782787848098, "chrf_score": 71.23228282396461, "xcomet_score": 0.7470851540565491, "xcomet_qe_score": 0.7184002995491028, "metricx_score": 8.473337173461914, "metricx_qe_score": 4.80129337310791, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "In etwa 80 % der zitierten Artikel handelt es sich um den Zivilgesetzbuch, das Gerichtsverfassungsgesetz, das Strafprozessgesetz oder das Strafgesetzbuch.", "metrics": {"bleu_score": 6.044162384201478, "chrf_score": 47.13634202794524, "xcomet_score": 0.9172840118408203, "xcomet_qe_score": 0.9168565273284912, "metricx_score": 2.042487621307373, "metricx_qe_score": 1.0164320468902588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "In der Zwischenzeit haben 18 von 32 Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden.", "metrics": {"bleu_score": 37.494051432044955, "chrf_score": 66.0496061161837, "xcomet_score": 0.9578199982643127, "xcomet_qe_score": 0.9828119277954102, "metricx_score": 3.042081832885742, "metricx_qe_score": 2.719695806503296, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies lässt sich damit erklären, dass das Deuteronomium weniger auf Individuen und ihre Anliegen fokussiert.", "metrics": {"bleu_score": 15.660302767990029, "chrf_score": 45.338720057474156, "xcomet_score": 0.8950226306915283, "xcomet_qe_score": 0.8978275060653687, "metricx_score": 4.925379753112793, "metricx_qe_score": 7.484311103820801, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt liegt die mittlere Anzahl der Zitationen für diese zitierten Artikel bei zwei, und weniger als 25 % von ihnen haben", "metrics": {"bleu_score": 29.64664796992539, "chrf_score": 55.04394412640554, "xcomet_score": 0.8020311594009399, "xcomet_qe_score": 0.8383917808532715, "metricx_score": 9.725787162780762, "metricx_qe_score": 9.002153396606445, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen haben wir mehrere Abrufmethoden, einschließlich lexikalischer und dichter Architektur, bewertet.", "metrics": {"bleu_score": 35.077702152152504, "chrf_score": 50.81048610016108, "xcomet_score": 0.9627292156219482, "xcomet_qe_score": 0.9676138162612915, "metricx_score": 0.956133246421814, "metricx_qe_score": 0.8574934005737305, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einem lexikalischen Modell wird einem Artikel-Query-Paar eine Punktzahl zugewiesen, indem die Summe der Gewichte jedes dieser Begriffe in diesem Artikel über die Query-Begriffe berechnet wird.", "metrics": {"bleu_score": 21.403247674815056, "chrf_score": 60.403165414714934, "xcomet_score": 0.8997468948364258, "xcomet_qe_score": 0.8273292183876038, "metricx_score": 4.403677463531494, "metricx_qe_score": 2.7300221920013428, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TF-IDF- und BM25-Rangfunktionen.", "metrics": {"bleu_score": 32.46679154750989, "chrf_score": 75.61498141720861, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 1.0, "metricx_score": 0.7974021434783936, "metricx_qe_score": 1.0548841953277588, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die die im Abfrage enthaltenen Schlüsselwörter enthalten.", "metrics": {"bleu_score": 52.17815896177006, "chrf_score": 75.3997997763992, "xcomet_score": 0.9643106460571289, "xcomet_qe_score": 0.9609290361404419, "metricx_score": 1.6376311779022217, "metricx_qe_score": 1.06293785572052, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann.", "metrics": {"bleu_score": 87.87419089273847, "chrf_score": 94.0489601912323, "xcomet_score": 0.9998520612716675, "xcomet_qe_score": 0.9999477863311768, "metricx_score": 0.4494284987449646, "metricx_qe_score": 0.3703739643096924, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Encoder-Modell, das Abfragen und Artikel in dichte Vektordarstellungen abbildet und einen Relevanzwert zwischen einem Abfrage-Artikel-Paar durch die Ähnlichkeit ihrer Einbettungen berechnet.", "metrics": {"bleu_score": 58.41177597069676, "chrf_score": 88.66428023817559, "xcomet_score": 0.9025408029556274, "xcomet_qe_score": 0.8785021305084229, "metricx_score": 1.9778019189834595, "metricx_qe_score": 2.9886252880096436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen resultieren in der Regel aus einer Pooling-Operation am Ausgang eines Wort-Einbettungsmodells.", "metrics": {"bleu_score": 58.31101839887756, "chrf_score": 85.14268601814966, "xcomet_score": 0.9101036787033081, "xcomet_qe_score": 0.8718739748001099, "metricx_score": 1.6136630773544312, "metricx_qe_score": 2.2789485454559326, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit von Siamese-Bi-Encodern in einer Nullschuss-Bewertungsumgebung, was bedeutet, dass vorab trainierte Wortembedding-Modelle ohne zusätzliche Feinabstimmung direkt angewendet werden.", "metrics": {"bleu_score": 18.212698395097043, "chrf_score": 62.75425000838263, "xcomet_score": 0.8603380918502808, "xcomet_qe_score": 0.7589061260223389, "metricx_score": 4.406740665435791, "metricx_qe_score": 3.8778281211853027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Textcodierern, nämlich Word2Vec und FastText, und kontextabhängigen Einbettungsmodellen, nämlich RoBERTa und speziell CamemBERT, einem französischen RoBERTa-Modell.", "metrics": {"bleu_score": 35.385578200606375, "chrf_score": 72.60897859083946, "xcomet_score": 0.9477601051330566, "xcomet_qe_score": 0.9624558687210083, "metricx_score": 0.8097028732299805, "metricx_qe_score": 0.724611759185791, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich haben wir unser eigenes auf Camembert basierendes Modell jenseits von Codern trainiert.", "metrics": {"bleu_score": 10.865553568907545, "chrf_score": 49.36701409631627, "xcomet_score": 0.739740252494812, "xcomet_qe_score": 0.7677022218704224, "metricx_score": 7.264078140258789, "metricx_qe_score": 7.224548816680908, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Auf allen Datensätzen. Beachten Sie, dass wir beim Training mit den zwei Varianten der BERT-Architektur experimentiert haben.", "metrics": {"bleu_score": 44.44183736091338, "chrf_score": 74.92078419713528, "xcomet_score": 0.8066446781158447, "xcomet_qe_score": 0.847243070602417, "metricx_score": 4.534525394439697, "metricx_qe_score": 5.512465953826904, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Wort-Einbettungsmodell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraumbereich abbildet, und Two-Tower, das zwei unabhängige Wort-Einbettungsmodelle verwendet, die die Abfrage und den Artikel separat in verschiedene Einbettungsbereiche codieren.", "metrics": {"bleu_score": 57.16764988674784, "chrf_score": 82.82625015093642, "xcomet_score": 0.9202077388763428, "xcomet_qe_score": 0.8505751490592957, "metricx_score": 2.7770373821258545, "metricx_qe_score": 4.45541524887085, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit Mittelwert, Max und CLS-Pooling sowie Punktprodukt und Kosinus zur Berechnung von Ähnlichkeiten.", "metrics": {"bleu_score": 40.74362040846931, "chrf_score": 78.95597343371983, "xcomet_score": 0.8026947975158691, "xcomet_qe_score": 0.7509037852287292, "metricx_score": 1.7783619165420532, "metricx_qe_score": 2.10341477394104, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Grundmodells auf dem Testdatensatz.", "metrics": {"bleu_score": 29.071536848410968, "chrf_score": 59.59777193363901, "xcomet_score": 0.9645508527755737, "xcomet_qe_score": 0.9390527009963989, "metricx_score": 1.1461846828460693, "metricx_qe_score": 0.974964439868927, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Mit den oben genannten lexikalischen Methoden, den Siamese B-Encodern, die in einer Zero-Shot-Konfiguration bewertet wurden, und den unten aufgeführten feinabgestimmten B-Encodern.", "metrics": {"bleu_score": 5.217592866832707, "chrf_score": 58.02644103378666, "xcomet_score": 0.7632896304130554, "xcomet_qe_score": 0.7449367046356201, "metricx_score": 4.752016067504883, "metricx_qe_score": 5.399497985839844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt schneidet der feinabgestimmte Decoder deutlich besser ab als alle anderen Basislinien.", "metrics": {"bleu_score": 8.130850857597444, "chrf_score": 61.173383226723175, "xcomet_score": 0.8700522184371948, "xcomet_qe_score": 0.8749099969863892, "metricx_score": 2.593161106109619, "metricx_qe_score": 3.117539167404175, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Zwei-Turm-Modell verbessert sich gegenüber seiner siamesischen Variante bei der Recall bei 100, verhält sich aber bei den anderen Metriken ähnlich.", "metrics": {"bleu_score": 29.81792160679168, "chrf_score": 69.58704320194413, "xcomet_score": 0.8927405476570129, "xcomet_qe_score": 0.9169383645057678, "metricx_score": 4.154892921447754, "metricx_qe_score": 4.526094436645508, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM25 im Vergleich zu den trainierten BERT-Codern deutlich schlechter abschnitt, deutet seine Leistung darauf hin, dass es immer noch eine starke Basis für die domänenspezifische Abfrage ist.", "metrics": {"bleu_score": 11.930622746137239, "chrf_score": 64.05539728883628, "xcomet_score": 0.8655942678451538, "xcomet_qe_score": 0.8678101301193237, "metricx_score": 1.7581696510314941, "metricx_qe_score": 2.4063830375671387, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Was die Nullschussbewertung des Siamese-BiEncoders betrifft, so haben wir festgestellt, dass die direkte Verwendung der Einbettungen eines vorab trainierten CamemBERT-Modells ohne Optimierung für die Informationsabrufaufgabe zu schlechten Ergebnissen führt, was mit früheren Erkenntnissen übereinstimmt.", "metrics": {"bleu_score": 42.46284753063224, "chrf_score": 72.58166473943946, "xcomet_score": 0.9072233438491821, "xcomet_qe_score": 0.9138212203979492, "metricx_score": 1.8071030378341675, "metricx_qe_score": 1.872816801071167, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus stellten wir fest, dass der auf Word2Vec basierende Biaff-Biencoder die Modelle FastText und BERT deutlich übertraf, was darauf hindeutet, dass möglicherweise vorab trainierte Wortembeddings für die Aufgabe besser geeignet sind als Zeichen- oder Subwortembeddings, wenn sie direkt verwendet werden.", "metrics": {"bleu_score": 42.17435626204722, "chrf_score": 60.19245283606782, "xcomet_score": 0.6844563484191895, "xcomet_qe_score": 0.8050084114074707, "metricx_score": 5.061227798461914, "metricx_qe_score": 4.635388374328613, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl diese Ergebnisse vielversprechend sind, deuten sie auf eine große Chance zur Verbesserung im Vergleich zu einem erfahrenen Experten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann.", "metrics": {"bleu_score": 42.32691015191597, "chrf_score": 69.19284157646291, "xcomet_score": 0.9969871044158936, "xcomet_qe_score": 0.9877491593360901, "metricx_score": 0.7075396776199341, "metricx_qe_score": 0.5301275253295898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns mit der Diskussion zweier Einschränkungen unserer Datensätze abschließen.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 51.210445986498144, "xcomet_score": 0.9903885722160339, "xcomet_qe_score": 1.0, "metricx_score": 1.730907917022705, "metricx_qe_score": 1.237544298171997, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf diejenigen beschränkt, die aus den 32 betrachteten belgischen Gesetzbüchern gesammelt wurden, was nicht das gesamte belgische Recht abdeckt, da Artikel aus Dekreten, Richtlinien und Verordnungen fehlen.", "metrics": {"bleu_score": 60.69548573053057, "chrf_score": 80.90699927958434, "xcomet_score": 0.9639572501182556, "xcomet_qe_score": 0.9338213205337524, "metricx_score": 0.6853633522987366, "metricx_qe_score": 0.7067681550979614, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzerstellung werden alle Verweise auf diese nicht gesammelten Artikel ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl relevanter Artikel erhalten.", "metrics": {"bleu_score": 42.63216905958759, "chrf_score": 72.02828574974139, "xcomet_score": 0.9787648916244507, "xcomet_qe_score": 0.9759702682495117, "metricx_score": 1.1881582736968994, "metricx_qe_score": 1.0394368171691895, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Dieser Informationsverlust bedeutet, dass die Antwort, die in den verbleibenden relevanten Artikeln enthalten ist, möglicherweise unvollständig ist, obwohl sie immer noch vollständig angemessen ist.", "metrics": {"bleu_score": 50.85286303114507, "chrf_score": 70.31071215020795, "xcomet_score": 0.9763476252555847, "xcomet_qe_score": 0.9513496160507202, "metricx_score": 1.6655242443084717, "metricx_qe_score": 1.6548864841461182, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.111781045794487, "metricx_qe_score": 0.16189205646514893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel lautet die Frage: Kann ich meine Mieter wegen Lärmbelästigung rauswerfen?", "metrics": {"bleu_score": 10.116512508890024, "chrf_score": 46.261389410964945, "xcomet_score": 0.9608237743377686, "xcomet_qe_score": 0.9674833416938782, "metricx_score": 0.15670767426490784, "metricx_qe_score": 0.0519203320145607, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Das Gesetz könnte keine detaillierte Antwort enthalten, die einen bestimmten Lärmpegel angibt, bei dem eine Räumung erlaubt ist.", "metrics": {"bleu_score": 11.215887247912582, "chrf_score": 49.416148266998235, "xcomet_score": 0.9635894894599915, "xcomet_qe_score": 0.9559383392333984, "metricx_score": 0.7163283824920654, "metricx_qe_score": 1.8381576538085938, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich eher auf die Rechtsprechung vertrauen und Präzedenzfälle finden, die seiner derzeitigen Situation ähneln.", "metrics": {"bleu_score": 41.709417232262034, "chrf_score": 72.16909868569724, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.33762267231941223, "metricx_qe_score": 0.18049758672714233, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Mieter bis zum 2. August zwei Zahlungen pro Woche.", "metrics": {"bleu_score": 8.839374326825924, "chrf_score": 37.46807856180055, "xcomet_score": 0.3291374444961548, "xcomet_qe_score": 0.3224385380744934, "metricx_score": 17.736745834350586, "metricx_qe_score": 10.212920188903809, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher eignen sich einige Fragen besser als andere für die Aufgabe der Abrufbarkeit von Gesetzesartikeln, und der Bereich der weniger geeigneten Fragen muss noch bestimmt werden.", "metrics": {"bleu_score": 49.582717346593746, "chrf_score": 76.49982796737673, "xcomet_score": 0.9727068543434143, "xcomet_qe_score": 0.9548203945159912, "metricx_score": 2.5523130893707275, "metricx_qe_score": 2.3107779026031494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass unsere Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur Abfrage von Gesetzesartikeln weckt.", "metrics": {"bleu_score": 77.59071335214406, "chrf_score": 87.51411779784554, "xcomet_score": 0.9991217851638794, "xcomet_qe_score": 1.0, "metricx_score": 0.48500770330429077, "metricx_qe_score": 0.21266208589076996, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann helfen, den Zugang zur Justiz für alle zu verbessern.", "metrics": {"bleu_score": 69.81025376257924, "chrf_score": 73.36844101323132, "xcomet_score": 0.9875004291534424, "xcomet_qe_score": 1.0, "metricx_score": 0.5993624925613403, "metricx_qe_score": 0.38967961072921753, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unseren Artikel, das Datenset und den Code unter den folgenden Links einsehen. Vielen Dank.", "metrics": {"bleu_score": 42.794691107478805, "chrf_score": 66.0793695937656, "xcomet_score": 0.9773613214492798, "xcomet_qe_score": 0.9934700727462769, "metricx_score": 2.9939897060394287, "metricx_qe_score": 0.4148867130279541, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, Ihnen unsere Arbeit zu VALSE vorzustellen, einem aufgabenunabhängigen Benchmark, der für die Prüfung von Vision- und Sprachmodellen mit spezifischen linguistischen Phänomenen gedacht ist.", "metrics": {"bleu_score": 38.219139116425254, "chrf_score": 65.66969071532213, "xcomet_score": 0.9591840505599976, "xcomet_qe_score": 0.9532322883605957, "metricx_score": 1.44749116897583, "metricx_qe_score": 1.0897884368896484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark zu erstellen?", "metrics": {"bleu_score": 75.39221180326287, "chrf_score": 80.95810712220886, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.23551928997039795, "metricx_qe_score": 0.31118887662887573, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformer-basierten Vision- und Sprachmodellen gesehen, die auf großen Mengen von Bild-Text-Paaren vorab trainiert wurden.", "metrics": {"bleu_score": 33.79468125963495, "chrf_score": 73.45358079158994, "xcomet_score": 0.9692970514297485, "xcomet_qe_score": 0.9636021256446838, "metricx_score": 1.4327999353408813, "metricx_qe_score": 2.0529093742370605, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle treibt die Spitzenforschung in den Bereichen Vision und Sprache voran, wie z. B. visuelle Beantwortung von Fragen, visuelles Alltagswissen, Bildabruf und Phrasengrundierung.", "metrics": {"bleu_score": 29.43648977575368, "chrf_score": 48.81797135286632, "xcomet_score": 0.9251822829246521, "xcomet_qe_score": 0.9500449299812317, "metricx_score": 2.650820732116699, "metricx_qe_score": 2.3582990169525146, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Nachricht erhalten, dass die Genauigkeiten bei diesen aufgabenbezogenen Benchmarks stetig steigen.", "metrics": {"bleu_score": 53.17281059781487, "chrf_score": 76.77244874821191, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7605504393577576, "metricx_qe_score": 1.1208500862121582, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5102907419204712, "metricx_qe_score": 0.9778188467025757, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was versteht ein Vision-and-Language-Transformer, wenn er einer Abbildung und einem Satz eine hohe Übereinstimmung zuweist?", "metrics": {"bleu_score": 13.922162089907253, "chrf_score": 42.12007467425068, "xcomet_score": 0.7977709770202637, "xcomet_qe_score": 0.9109786748886108, "metricx_score": 1.4045382738113403, "metricx_qe_score": 1.539760708808899, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und die niedrigste Punktzahl für diese.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 53.44448548256254, "xcomet_score": 0.959048867225647, "xcomet_qe_score": 0.9649909138679504, "metricx_score": 1.0191603899002075, "metricx_qe_score": 0.7881344556808472, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?", "metrics": {"bleu_score": 20.90067144241745, "chrf_score": 60.27342618027498, "xcomet_score": 0.937651515007019, "xcomet_qe_score": 0.9570304155349731, "metricx_score": 1.4751598834991455, "metricx_qe_score": 0.4880390465259552, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Verzerrungen, wie es frühere Arbeiten gezeigt haben?", "metrics": {"bleu_score": 54.3742768222752, "chrf_score": 75.54852823701415, "xcomet_score": 0.9873086214065552, "xcomet_qe_score": 0.886705756187439, "metricx_score": 0.21394747495651245, "metricx_qe_score": 0.44897013902664185, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um diesen Aspekt weiter zu beleuchten, schlagen wir eine eher aufgabenagnostische Richtung vor und führen VALSE ein, das die Empfindlichkeit von Vision- und Sprachmodellen gegenüber bestimmten sprachlichen Phänomenen testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen.", "metrics": {"bleu_score": 62.22093739558568, "chrf_score": 81.69092086603762, "xcomet_score": 0.9365692138671875, "xcomet_qe_score": 0.9284166693687439, "metricx_score": 1.3516333103179932, "metricx_qe_score": 1.1426281929016113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitäts-Coreferenz ab.", "metrics": {"bleu_score": 66.75075987129311, "chrf_score": 88.06646550091173, "xcomet_score": 0.924040675163269, "xcomet_qe_score": 0.9472472667694092, "metricx_score": 1.3297815322875977, "metricx_qe_score": 1.405611276626587, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen erfasst haben?", "metrics": {"bleu_score": 47.13945310979296, "chrf_score": 65.03328164318137, "xcomet_score": 0.9866929650306702, "xcomet_qe_score": 0.9897239804267883, "metricx_score": 1.1591687202453613, "metricx_qe_score": 0.6309834122657776, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch FOILing, eine Methode, die zuvor nur für Vision- und Sprachmodelle für Nominalphrasen von Ravi Shekhar und Kollegen und für das Zählen von uns in früheren Arbeiten angewendet wurde.", "metrics": {"bleu_score": 25.907400141639528, "chrf_score": 57.180715281758076, "xcomet_score": 0.7557364702224731, "xcomet_qe_score": 0.791715145111084, "metricx_score": 4.002251625061035, "metricx_qe_score": 3.5601966381073, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "\"Foiling\" bedeutet im Grunde, dass wir die Bildunterschrift nehmen und eine Fälschung erstellen, indem wir die Bildunterschrift so verändern, dass sie das Bild nicht mehr beschreibt.", "metrics": {"bleu_score": 60.55223296065568, "chrf_score": 70.68090854891179, "xcomet_score": 0.9254170656204224, "xcomet_qe_score": 0.9611244797706604, "metricx_score": 1.2429945468902588, "metricx_qe_score": 1.0044760704040527, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Und wir führen diese Phrasenänderungen durch, indem wir uns auf sechs spezifische Bereiche konzentrieren, wie z. B. Existenz, Pluralität, Zählen, räumliche Beziehungen, Handlungen und Entitäts-Coreferenz, wobei jeder Bereich aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, um Foil-Instanz zu erstellen.", "metrics": {"bleu_score": 45.60789575378439, "chrf_score": 75.03968873408567, "xcomet_score": 0.7927700281143188, "xcomet_qe_score": 0.8095369338989258, "metricx_score": 5.234378814697266, "metricx_qe_score": 5.497942924499512, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir im Fall des Aktionsstücks zwei Instrumente, eines, bei dem das Aktionsverb durch eine andere Aktion ersetzt wird, und eines, bei dem die Akteure ausgetauscht werden.", "metrics": {"bleu_score": 67.0531982416014, "chrf_score": 74.79669146113665, "xcomet_score": 0.963921070098877, "xcomet_qe_score": 0.9626035690307617, "metricx_score": 2.0097084045410156, "metricx_qe_score": 2.9300239086151123, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Korreferenz sind ebenfalls Stücke, die mehr als ein Instrument haben.", "metrics": {"bleu_score": 54.3742768222752, "chrf_score": 71.02239871571828, "xcomet_score": 0.8872798085212708, "xcomet_qe_score": 0.8851831555366516, "metricx_score": 3.198819875717163, "metricx_qe_score": 2.4799396991729736, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Wir erstellen diese Falschaussagen, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalisch korrekt und ansonsten gültige Sätze sind.", "metrics": {"bleu_score": 61.312107396449676, "chrf_score": 76.01526399239438, "xcomet_score": 0.9888837337493896, "xcomet_qe_score": 0.9872434139251709, "metricx_score": 0.3789823353290558, "metricx_qe_score": 0.9730875492095947, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach, weil eine gefälschte Bildunterschrift weniger wahrscheinlich ist als die ursprüngliche Bildunterschrift.", "metrics": {"bleu_score": 22.49124239944387, "chrf_score": 62.94284022398079, "xcomet_score": 0.9882439374923706, "xcomet_qe_score": 0.9896694421768188, "metricx_score": 0.4109309911727905, "metricx_qe_score": 0.35142582654953003, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise ist es zwar nicht unmöglich, aber statistisch gesehen ist es unwahrscheinlicher, dass Pflanzen einen Mann verletzen, als dass ein Mann Pflanzen verletzt, und große Sprach- und Sehmodelle könnten dies erkennen.", "metrics": {"bleu_score": 48.9249515453182, "chrf_score": 73.14279307467238, "xcomet_score": 0.9642266035079956, "xcomet_qe_score": 0.9488990306854248, "metricx_score": 0.9095934629440308, "metricx_qe_score": 0.44791048765182495, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um daher gültige Folien zu erhalten, müssen wir Maßnahmen ergreifen.", "metrics": {"bleu_score": 8.91376552139813, "chrf_score": 39.684013755434236, "xcomet_score": 0.9002021551132202, "xcomet_qe_score": 0.924623966217041, "metricx_score": 2.901329755783081, "metricx_qe_score": 1.3954429626464844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir starke Sprachmodelle, um Folien vorzuschlagen.", "metrics": {"bleu_score": 58.14307369682194, "chrf_score": 70.38287290947997, "xcomet_score": 0.8168504238128662, "xcomet_qe_score": 0.8294556140899658, "metricx_score": 3.0913758277893066, "metricx_qe_score": 1.3697267770767212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir natürliche Sprachinferenz (kurz NLI), um Falschaussagen herauszufiltern, die das Bild immer noch beschreiben könnten, da wir beim Erstellen von Falschaussagen sicherstellen müssen, dass sie das Bild nicht beschreiben.", "metrics": {"bleu_score": 36.60648960911581, "chrf_score": 66.52096995820253, "xcomet_score": 0.9730469584465027, "xcomet_qe_score": 0.9943262338638306, "metricx_score": 2.293879270553589, "metricx_qe_score": 3.3145592212677, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir natürliche Sprachinferenz mit folgender Begründung an.", "metrics": {"bleu_score": 40.80873631534954, "chrf_score": 66.94572582113224, "xcomet_score": 0.9894979000091553, "xcomet_qe_score": 0.9944472312927246, "metricx_score": 1.1542607545852661, "metricx_qe_score": 0.9382692575454712, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als Prämisse und seine Bildunterschrift als die implizite Hypothese.", "metrics": {"bleu_score": 36.65531081103153, "chrf_score": 65.73201609385538, "xcomet_score": 0.9986851215362549, "xcomet_qe_score": 1.0, "metricx_score": 0.15138015151023865, "metricx_qe_score": 0.18084372580051422, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "Zudem gehen wir davon aus, dass die Bildunterschrift die Prämisse ist und die Ablenkung die Hypothese.", "metrics": {"bleu_score": 6.986768364373987, "chrf_score": 39.82303941822949, "xcomet_score": 0.9578808546066284, "xcomet_qe_score": 0.9426602721214294, "metricx_score": 3.679675817489624, "metricx_qe_score": 2.7501437664031982, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell vorhersagt, dass die FOIL im Widerspruch zu der Bildunterschrift steht oder neutral ist, nehmen wir dies als Indikator für eine gültige FOIL.", "metrics": {"bleu_score": 38.694317759010325, "chrf_score": 61.326444168953955, "xcomet_score": 0.795435905456543, "xcomet_qe_score": 0.8403594493865967, "metricx_score": 4.743499279022217, "metricx_qe_score": 2.2081243991851807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Falschaussage aus der Bildunterschrift abgeleitet werden kann, kann es sich nicht um eine gute Falschaussage handeln, da sie aufgrund der Transitivität eine wahrheitsgemäße Beschreibung des Bildes liefert und wir diese Falschaussagen herausfiltern.", "metrics": {"bleu_score": 33.8641614934274, "chrf_score": 62.10925341878921, "xcomet_score": 0.8904213905334473, "xcomet_qe_score": 0.8764705061912537, "metricx_score": 2.5906546115875244, "metricx_qe_score": 4.455286979675293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Dieses Verfahren ist jedoch nicht perfekt. Es ist nur ein Indikator für gültige Folien.", "metrics": {"bleu_score": 34.46073377034663, "chrf_score": 63.98326079518311, "xcomet_score": 0.9038062691688538, "xcomet_qe_score": 0.9506180286407471, "metricx_score": 2.0043745040893555, "metricx_qe_score": 0.6558524370193481, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Als dritte Maßnahme zur Erstellung gültiger FOIs lassen wir menschliche Annotatoren die in VALS verwendeten Daten validieren.", "metrics": {"bleu_score": 11.498617530677414, "chrf_score": 60.86113617154083, "xcomet_score": 0.9226894378662109, "xcomet_qe_score": 0.980175793170929, "metricx_score": 3.1550872325897217, "metricx_qe_score": 3.134091377258301, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir so viele Testinstanzen, wie in dieser Tabelle beschrieben.", "metrics": {"bleu_score": 72.88361338482602, "chrf_score": 82.68511564897327, "xcomet_score": 0.9988127946853638, "xcomet_qe_score": 0.9922828674316406, "metricx_score": 0.5026815533638, "metricx_qe_score": 0.7014657258987427, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Bitte beachten Sie, dass VALSE keine Trainingsdaten liefert, sondern nur Testdaten.", "metrics": {"bleu_score": 47.855439210937384, "chrf_score": 84.72463918443849, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.10995469242334366, "metricx_qe_score": 0.15600943565368652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um eine Benchmark für Null-Schuss-Tests handelt, ist sie darauf ausgelegt, die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach dem Vortraining zu nutzen.", "metrics": {"bleu_score": 14.557496889528018, "chrf_score": 59.40751528444414, "xcomet_score": 0.7957440614700317, "xcomet_qe_score": 0.8532403707504272, "metricx_score": 2.6829118728637695, "metricx_qe_score": 3.3973405361175537, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Feinabstimmung würde es Modellen nur ermöglichen, Artefakte oder statistische Verzerrungen in den Daten auszunutzen.", "metrics": {"bleu_score": 78.1627531804133, "chrf_score": 93.0392986763655, "xcomet_score": 0.9988124370574951, "xcomet_qe_score": 0.9922803640365601, "metricx_score": 0.227815642952919, "metricx_qe_score": 0.2785191833972931, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne schummeln und Abkürzungen nehmen.", "metrics": {"bleu_score": 61.62607099729587, "chrf_score": 91.83834013382479, "xcomet_score": 0.9979071617126465, "xcomet_qe_score": 0.999207615852356, "metricx_score": 0.635805606842041, "metricx_qe_score": 0.752661943435669, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie wir sagten, sind wir daran interessiert, die Fähigkeiten der Vision- und Sprachmodelle nach dem Vortraining zu bewerten.", "metrics": {"bleu_score": 25.131752275138197, "chrf_score": 64.17197392863724, "xcomet_score": 0.9748339653015137, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.186532735824585, "metricx_qe_score": 0.824004590511322, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision-and-Language-Modellen auf VALSE, nämlich mit CLIP, ALIGN, ViLBERT, ViLBERT12in1 und VisualBERT.", "metrics": {"bleu_score": 42.11640764894448, "chrf_score": 67.82486083695771, "xcomet_score": 0.750487744808197, "xcomet_qe_score": 0.8020821809768677, "metricx_score": 5.170368671417236, "metricx_qe_score": 5.224167346954346, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bild-Satz-Paaren in Beschreibungen und Falschmeldungen.", "metrics": {"bleu_score": 46.09603493497927, "chrf_score": 75.71385720054418, "xcomet_score": 0.9032122492790222, "xcomet_qe_score": 0.7725504040718079, "metricx_score": 2.515342950820923, "metricx_qe_score": 4.016144752502441, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht relevanter für dieses Video, wir werden unsere großzügigere Metrik vorstellen, die paarweise Genauigkeit, die misst, ob die Bild-Satz-Ausrichtungsbewertung für das korrekte Bild-Text-Paar höher ist als für sein gefälschtes Paar.", "metrics": {"bleu_score": 31.643893659595477, "chrf_score": 74.65838984113401, "xcomet_score": 0.8405947685241699, "xcomet_qe_score": 0.8255428075790405, "metricx_score": 2.5372841358184814, "metricx_qe_score": 2.5344536304473877, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Metriken und Ergebnisse finden Sie in unserem Paper.", "metrics": {"bleu_score": 71.0866788975034, "chrf_score": 89.06756192394944, "xcomet_score": 0.9886081218719482, "xcomet_qe_score": 0.9141401052474976, "metricx_score": 0.807175874710083, "metricx_qe_score": 2.200127601623535, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit der paarweisen Genauigkeit werden hier gezeigt und sind mit den Ergebnissen, die wir von den anderen Metriken erhalten haben, konsistent. Die beste Null-Schuss-Leistung wird von VilBERT 12-in-1 erzielt, gefolgt von VilBERT, AlexMERT, CLIP und schließlich VisualBERT.", "metrics": {"bleu_score": 44.076653885766156, "chrf_score": 67.27628198981948, "xcomet_score": 0.6143211722373962, "xcomet_qe_score": 0.6246898174285889, "metricx_score": 5.993972301483154, "metricx_qe_score": 5.262270450592041, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Substantivphrasen konzentrieren, fast vollständig von Wilbert 12 in 1 gelöst werden, was darauf hinweist, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren.", "metrics": {"bleu_score": 55.83580202466087, "chrf_score": 74.5291302434275, "xcomet_score": 0.8838150501251221, "xcomet_qe_score": 0.854876697063446, "metricx_score": 3.2782793045043945, "metricx_qe_score": 3.4991955757141113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann keines der verbleibenden Teile in unseren feindlichen Umgebungen zuverlässig gelöst werden.", "metrics": {"bleu_score": 29.420957081163703, "chrf_score": 62.003236365425494, "xcomet_score": 0.9626510143280029, "xcomet_qe_score": 0.9614651203155518, "metricx_score": 2.414438009262085, "metricx_qe_score": 2.5184662342071533, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäts- und Zählinstrumenten geht hervor, dass Sprach- und Sehmodelle Schwierigkeiten haben, zwischen Verweisen auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen.", "metrics": {"bleu_score": 49.342411798176485, "chrf_score": 76.73603546399474, "xcomet_score": 0.9991309642791748, "xcomet_qe_score": 0.9889629483222961, "metricx_score": 0.48298510909080505, "metricx_qe_score": 0.5733605623245239, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Studie „Relation Piece“ zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren.", "metrics": {"bleu_score": 58.15025407036991, "chrf_score": 76.42164058569973, "xcomet_score": 0.8727022409439087, "xcomet_qe_score": 0.8648471832275391, "metricx_score": 2.9088470935821533, "metricx_qe_score": 2.4019038677215576, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Handlungen zu unterscheiden und ihre Teilnehmer zu identifizieren, selbst wenn sie durch Plausibilitätsvoreingenommenheit unterstützt werden, wie wir im Abschnitt über Handlungen sehen.", "metrics": {"bleu_score": 72.09099852383686, "chrf_score": 85.9283728627733, "xcomet_score": 0.9489977359771729, "xcomet_qe_score": 0.9094843864440918, "metricx_score": 1.572366714477539, "metricx_qe_score": 2.493391275405884, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Abschnitt zur Koreferenz geht hervor, dass es für visuelle und sprachliche Modelle ebenfalls schwierig ist, mehrere Verweise auf dasselbe Objekt in einem Bild mithilfe von Pronomen zu verfolgen.", "metrics": {"bleu_score": 28.9832172349846, "chrf_score": 58.548703672998, "xcomet_score": 0.9821634292602539, "xcomet_qe_score": 0.9277868270874023, "metricx_score": 0.4414551556110382, "metricx_qe_score": 0.7208694815635681, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Plausibilitätsprüfung und weil es ein interessantes Experiment ist, haben wir auch zwei textbasierte Modelle, GPT-1 und GPT-2, verglichen, um zu bewerten, ob VALSE durch diese unimodalen Modelle gelöst werden kann, indem wir die Verwirrung der richtigen und der falschen Bildunterschrift (kein Bild hier) berechnen und den Eintrag mit der niedrigsten Verwirrung vorhersagen.", "metrics": {"bleu_score": 31.068496598427643, "chrf_score": 57.60513690249868, "xcomet_score": 0.935103178024292, "xcomet_qe_score": 0.9636795520782471, "metricx_score": 2.3432507514953613, "metricx_qe_score": 1.8158320188522339, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung bei der Fälschung höher ist, nehmen wir dies als Hinweis darauf, dass die gefälschte Bildunterschrift unter einem Plausibilitätsbias oder anderen sprachlichen Verzerrungen leiden könnte.", "metrics": {"bleu_score": 17.465362077660064, "chrf_score": 59.53753967414094, "xcomet_score": 0.9658195972442627, "xcomet_qe_score": 0.9334882497787476, "metricx_score": 2.088395357131958, "metricx_qe_score": 1.5948426723480225, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Es ist interessant zu sehen, dass in einigen Fällen die nur auf Text basierenden GPT-Modelle die Plausibilität der Welt besser erfasst haben als die Vision- und Sprachmodelle.", "metrics": {"bleu_score": 67.59482608831081, "chrf_score": 83.43647660707344, "xcomet_score": 0.9701560735702515, "xcomet_qe_score": 0.9655139446258545, "metricx_score": 1.2773064374923706, "metricx_qe_score": 0.8875324130058289, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammengefasst ist VALSE eine Benchmark, die linguistische Konstrukte nutzt, um der Community zu helfen, Modelle für Vision und Sprache zu verbessern, indem sie deren Fähigkeiten zur visuellen Verankerung auf die Probe stellt.", "metrics": {"bleu_score": 3.459819640550157, "chrf_score": 42.53468438630814, "xcomet_score": 0.9008773565292358, "xcomet_qe_score": 0.8999636173248291, "metricx_score": 3.3953983783721924, "metricx_qe_score": 2.902942180633545, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Sprach- und Sehmodelle benannte Objekte in Bildern gut erkennen, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu verankern, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren.", "metrics": {"bleu_score": 52.42742492001942, "chrf_score": 76.35684515043361, "xcomet_score": 0.8984545469284058, "xcomet_qe_score": 0.8894436359405518, "metricx_score": 2.632089614868164, "metricx_qe_score": 2.690762519836426, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich ermutigen, VALSE zur Messung des Fortschritts bei der Verankerung von Sprache mit Vision- und Sprachmodellen zu verwenden.", "metrics": {"bleu_score": 29.906271972271124, "chrf_score": 70.37320854636033, "xcomet_score": 0.9562512636184692, "xcomet_qe_score": 0.9806479811668396, "metricx_score": 2.1329379081726074, "metricx_qe_score": 2.430828332901001, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, VALS könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz den Modellen hilft, sich in einem der von VALS getesteten Aspekte zu verbessern.", "metrics": {"bleu_score": 53.818091909165915, "chrf_score": 76.11021212076547, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.3856760859489441, "metricx_qe_score": 0.474373459815979, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, werfen Sie einen Blick auf die Vals-Daten auf GitHub und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren.", "metrics": {"bleu_score": 42.75215862300699, "chrf_score": 63.55595392372848, "xcomet_score": 0.966189980506897, "xcomet_qe_score": 0.9652923941612244, "metricx_score": 1.8667868375778198, "metricx_qe_score": 2.477949380874634, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizuru von der Universität Tokio.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 83.6991967882831, "xcomet_score": 0.8530445098876953, "xcomet_qe_score": 0.8706544041633606, "metricx_score": 3.1884074211120605, "metricx_qe_score": 2.804647207260132, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde einen Artikel mit dem Titel „RNNSum: A Large-Scale Dataset for Automatic Release Note Generation via Commit Log Summarization“ vorstellen.", "metrics": {"bleu_score": 48.624389134644154, "chrf_score": 78.33764075530763, "xcomet_score": 0.9962171316146851, "xcomet_qe_score": 0.996768593788147, "metricx_score": 3.604382276535034, "metricx_qe_score": 2.722395658493042, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich habe in dieser Ordnung Erfahrung.", "metrics": {"bleu_score": 13.540372457315735, "chrf_score": 24.50791276333836, "xcomet_score": 0.7861177325248718, "xcomet_qe_score": 0.3446248471736908, "metricx_score": 5.6041364669799805, "metricx_qe_score": 4.765567302703857, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Wissensgenerierung vorstellen, an der wir in dieser Forschung arbeiten.", "metrics": {"bleu_score": 71.9548353625319, "chrf_score": 80.22186396810956, "xcomet_score": 0.813502311706543, "xcomet_qe_score": 0.8010785579681396, "metricx_score": 2.7659690380096436, "metricx_qe_score": 2.025817394256592, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "Ein Release-Notiz ist ein technisches Dokument, das die Änderungen zusammenfasst, die mit jeder Version eines Softwareprodukts verteilt werden.", "metrics": {"bleu_score": 78.78025709745913, "chrf_score": 81.63403676425857, "xcomet_score": 0.9573186635971069, "xcomet_qe_score": 0.9619758725166321, "metricx_score": 2.0153019428253174, "metricx_qe_score": 2.339639902114868, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Versionshinweise für Version 2.6.", "metrics": {"bleu_score": 18.70274255449444, "chrf_score": 56.60916562494903, "xcomet_score": 0.7452239990234375, "xcomet_qe_score": 0.7310791611671448, "metricx_score": 3.484370708465576, "metricx_qe_score": 3.0944292545318604, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "Diese Knoten spielen eine wichtige Rolle bei der Open-Source-Entwicklung, sind aber zeitaufwendig, wenn man sie manuell vorbereitet.", "metrics": {"bleu_score": 13.947196297357515, "chrf_score": 58.080325639673006, "xcomet_score": 0.8992314338684082, "xcomet_qe_score": 0.8607534170150757, "metricx_score": 5.303892612457275, "metricx_qe_score": 5.248921871185303, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Es wäre daher sehr nützlich, wenn man in der Lage wäre, automatisch qualitativ hochwertige Versionshinweise zu generieren.", "metrics": {"bleu_score": 32.26386416030253, "chrf_score": 78.03679269391264, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3413519263267517, "metricx_qe_score": 0.6026856303215027, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Arbeiten zum automatischen Hörerzeugungsverfahren verweisen.", "metrics": {"bleu_score": 10.71174444166974, "chrf_score": 42.14506176421726, "xcomet_score": 0.7716058492660522, "xcomet_qe_score": 0.865825355052948, "metricx_score": 7.619516849517822, "metricx_qe_score": 4.44666862487793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste ist ein System namens Arena, das 2014 veröffentlicht wurde.", "metrics": {"bleu_score": 19.209413468550956, "chrf_score": 52.08972312408571, "xcomet_score": 0.9819424152374268, "xcomet_qe_score": 0.9836039543151855, "metricx_score": 0.3357934057712555, "metricx_qe_score": 0.4636992812156677, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet einen regelbasierten Ansatz, z. B. den Change Extractor, um Kernunterschiede, Bibliotheksänderungen und Dokumentänderungen aus den Unterschieden zwischen den Releases zu extrahieren und diese schließlich zu kombinieren.", "metrics": {"bleu_score": 33.405246077327135, "chrf_score": 73.98158285313089, "xcomet_score": 0.9582381844520569, "xcomet_qe_score": 0.8842372894287109, "metricx_score": 1.0838302373886108, "metricx_qe_score": 1.020012617111206, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das herausragendste Merkmal dieses Systems ist der Auszug in der oberen rechten Ecke.", "metrics": {"bleu_score": 53.16967153331756, "chrf_score": 56.41427094681494, "xcomet_score": 0.8584456443786621, "xcomet_qe_score": 0.8457044959068298, "metricx_score": 3.093674659729004, "metricx_qe_score": 3.7475826740264893, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Es muss mit JIRA, dem Issue-Tracking-System, verknüpft sein und kann nur auf Projekte angewendet werden, die JIRA verwenden.", "metrics": {"bleu_score": 43.52399425673389, "chrf_score": 55.67223767056102, "xcomet_score": 0.9266059398651123, "xcomet_qe_score": 0.8607587814331055, "metricx_score": 1.808689832687378, "metricx_qe_score": 1.632406234741211, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden.", "metrics": {"bleu_score": 72.41577342575832, "chrf_score": 93.16258475153698, "xcomet_score": 0.9909387230873108, "xcomet_qe_score": 0.9895014762878418, "metricx_score": 0.2981245517730713, "metricx_qe_score": 0.4196746051311493, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Das zweite ist Trauer. Es wurde 2013 angekündigt.", "metrics": {"bleu_score": 15.20797122409784, "chrf_score": 45.16572239250829, "xcomet_score": 0.33273887634277344, "xcomet_qe_score": 0.6024102568626404, "metricx_score": 14.156723022460938, "metricx_qe_score": 13.564458847045898, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "Es ist im Internet verfügbar und kann von einer Person gespeichert werden.", "metrics": {"bleu_score": 52.055103630534376, "chrf_score": 68.06716646473573, "xcomet_score": 0.8103122711181641, "xcomet_qe_score": 0.8052444458007812, "metricx_score": 6.215249538421631, "metricx_qe_score": 7.255455017089844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches, auf maschinellem Lernen basierendes Textklassifikationsmodell und gibt eines von fünf Labels aus, wie z. B. „Features“ oder „Bugfixes“ für jede Eingabe der Commit-Nachricht.", "metrics": {"bleu_score": 25.299682930744943, "chrf_score": 62.28324896484176, "xcomet_score": 0.9683183431625366, "xcomet_qe_score": 0.9729524254798889, "metricx_score": 0.8620027899742126, "metricx_qe_score": 0.9897910952568054, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist eine Beispielnutzung, die eine Korrektur für ein Bugfixes-Label zurückgibt.", "metrics": {"bleu_score": 14.342165432034776, "chrf_score": 44.24338985172059, "xcomet_score": 0.8366614580154419, "xcomet_qe_score": 0.8365338444709778, "metricx_score": 6.201596736907959, "metricx_qe_score": 5.148970127105713, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsdaten von Quora sind ziemlich klein, etwa 5000, und werden in den unten beschriebenen Experimenten gezeigt.", "metrics": {"bleu_score": 70.76534431960266, "chrf_score": 89.38410520601676, "xcomet_score": 0.7829916477203369, "xcomet_qe_score": 0.758275032043457, "metricx_score": 6.527252197265625, "metricx_qe_score": 8.254740715026855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des Textklassifikationsmodells ist nicht hoch.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26596003770828247, "metricx_qe_score": 0.4735175371170044, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit der eingeschränkten Anwendbarkeit und der Knappheit der Datenressourcen.", "metrics": {"bleu_score": 6.632379583706114, "chrf_score": 54.93374806698432, "xcomet_score": 0.9808542728424072, "xcomet_qe_score": 0.9835562109947205, "metricx_score": 0.3054162561893463, "metricx_qe_score": 0.2590346336364746, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Artikel löst diese beiden Probleme und generiert automatisch qualitativ hochwertige Versionshinweise.", "metrics": {"bleu_score": 38.058030016749456, "chrf_score": 75.36063048191231, "xcomet_score": 0.9977588653564453, "xcomet_qe_score": 0.9766324162483215, "metricx_score": 1.3410564661026, "metricx_qe_score": 1.3079280853271484, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das Problem der eingeschränkten Anwendbarkeit schlagen wir eine Methode zur Zusammenfassung von Git-Commits in hoher Qualität vor, die nur die Commit-Nachricht als Eingabe verwendet.", "metrics": {"bleu_score": 26.59147948472494, "chrf_score": 60.79625111123259, "xcomet_score": 0.9832130670547485, "xcomet_qe_score": 0.9963207244873047, "metricx_score": 0.8529409170150757, "metricx_qe_score": 1.0597996711730957, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Verben verwendet werden.", "metrics": {"bleu_score": 70.16879391277372, "chrf_score": 81.95584407989871, "xcomet_score": 0.8638731241226196, "xcomet_qe_score": 0.8881499171257019, "metricx_score": 2.7735679149627686, "metricx_qe_score": 3.717010974884033, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Um das zweite Problem der knappen Ressourcen zu lösen, haben wir einen R- und Summen-Datensatz mit etwa 82.000 Datensätzen erstellt, indem wir Daten aus öffentlichen GitHub-Repositories mit der GitHub-API gesammelt haben.", "metrics": {"bleu_score": 19.22360192645047, "chrf_score": 64.78803922376356, "xcomet_score": 0.8648529052734375, "xcomet_qe_score": 0.8684963583946228, "metricx_score": 4.612710475921631, "metricx_qe_score": 4.774956703186035, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes beschreibe ich die Daten.", "metrics": {"bleu_score": 13.540372457315735, "chrf_score": 49.33122217622682, "xcomet_score": 0.9910798072814941, "xcomet_qe_score": 0.9917929172515869, "metricx_score": 0.08525656163692474, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist ein Beispiel für Daten.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 81.3052385800557, "xcomet_score": 0.9865502119064331, "xcomet_qe_score": 0.9950288534164429, "metricx_score": 0.11113797873258591, "metricx_qe_score": 0.3509396016597748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Auf der linken Seite befindet sich die Commit-Nachricht und auf der rechten Seite die Release-Notizen.", "metrics": {"bleu_score": 47.92365811426397, "chrf_score": 65.5842129982345, "xcomet_score": 0.9784042835235596, "xcomet_qe_score": 0.8940222859382629, "metricx_score": 0.7519800662994385, "metricx_qe_score": 0.8915225267410278, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Versionshinweise sind als Verbesserungen, Fehlerbehebungen usw. gekennzeichnet.", "metrics": {"bleu_score": 41.72261448611506, "chrf_score": 65.59983913947471, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.3011317849159241, "metricx_qe_score": 0.5520150661468506, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Commit-Nachrichten als Eingabe nimmt und die Rohwert-Knoten als Ausgabe liefert.", "metrics": {"bleu_score": 42.59578174723158, "chrf_score": 67.75158677548706, "xcomet_score": 0.8332967758178711, "xcomet_qe_score": 0.7003094553947449, "metricx_score": 4.707033634185791, "metricx_qe_score": 5.361685276031494, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als eine Zusammenfassungsaufgabe betrachtet werden.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.04869714006781578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Labels vordefiniert: Features, Verbesserungen, Bugfixes, Deprecations, Removals und Breaking Changes.", "metrics": {"bleu_score": 15.593439508212386, "chrf_score": 36.5693023393293, "xcomet_score": 0.780579686164856, "xcomet_qe_score": 0.8950347900390625, "metricx_score": 5.868401050567627, "metricx_qe_score": 4.404065132141113, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden auf der Grundlage früherer Forschung und anderer Fakten festgelegt.", "metrics": {"bleu_score": 34.68626146171918, "chrf_score": 72.67181811449464, "xcomet_score": 0.9908897876739502, "xcomet_qe_score": 0.9895122051239014, "metricx_score": 0.785622239112854, "metricx_qe_score": 0.7506442666053772, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Reißzwecken auf der unteren rechten Seite wurden aus den Reißzwecken auf der unteren linken Seite extrahiert.", "metrics": {"bleu_score": 6.423094863383858, "chrf_score": 38.248188031668775, "xcomet_score": 0.6476266384124756, "xcomet_qe_score": 0.6539121866226196, "metricx_score": 9.018256187438965, "metricx_qe_score": 9.994742393493652, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "Zu diesem Zeitpunkt ist es notwendig, die vier zuvor festgelegten Fallen zu erkennen.", "metrics": {"bleu_score": 12.583171179755176, "chrf_score": 38.007760951833255, "xcomet_score": 0.9297654628753662, "xcomet_qe_score": 0.9782902002334595, "metricx_score": 4.180541515350342, "metricx_qe_score": 2.7010843753814697, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Die Labels sind jedoch nicht immer mit jeder Bibliothek konsistent.", "metrics": {"bleu_score": 41.72261448611506, "chrf_score": 59.143048291815006, "xcomet_score": 0.9602006673812866, "xcomet_qe_score": 0.9688054919242859, "metricx_score": 3.905891180038452, "metricx_qe_score": 3.550410747528076, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise umfasst die Verbesserungsrate Verbesserungen, Verbesserungen, Optimierungen und so weiter.", "metrics": {"bleu_score": 40.818511424237265, "chrf_score": 70.56474665808524, "xcomet_score": 0.797257661819458, "xcomet_qe_score": 0.788482129573822, "metricx_score": 7.735218048095703, "metricx_qe_score": 6.718700885772705, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Wortliste mit Studienbegriffen für jede dieser Notationsvarianten erstellt.", "metrics": {"bleu_score": 46.15415465297943, "chrf_score": 71.36879865247127, "xcomet_score": 0.9164921045303345, "xcomet_qe_score": 0.9572253823280334, "metricx_score": 3.5748190879821777, "metricx_qe_score": 3.080687999725342, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Freigabebemerkungsklassen zu erkennen und den Text der folgenden Freigabebemerkungssätze für die Klasse zu korrigieren.", "metrics": {"bleu_score": 8.960464287044383, "chrf_score": 31.56681059460421, "xcomet_score": 0.8042450547218323, "xcomet_qe_score": 0.7957911491394043, "metricx_score": 5.996426105499268, "metricx_qe_score": 5.633565425872803, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Commit-Nachricht.", "metrics": {"bleu_score": 32.46679154750991, "chrf_score": 72.44814691505867, "xcomet_score": 0.9991000890731812, "xcomet_qe_score": 0.9501502513885498, "metricx_score": 0.7596041560173035, "metricx_qe_score": 1.0487115383148193, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Commit-Nachrichten sind nicht an jede Release gebunden.", "metrics": {"bleu_score": 36.28241434631104, "chrf_score": 63.05047706376533, "xcomet_score": 0.9803799986839294, "xcomet_qe_score": 0.974917471408844, "metricx_score": 0.8910590410232544, "metricx_qe_score": 1.6831640005111694, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie im folgenden Bild gezeigt, wenn die aktuelle Version 2.5.19 ist, müssen wir die Identität", "metrics": {"bleu_score": 11.542738134663779, "chrf_score": 43.503393609561726, "xcomet_score": 0.7154431343078613, "xcomet_qe_score": 0.6925331354141235, "metricx_score": 13.532234191894531, "metricx_qe_score": 15.699331283569336, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "Sie müssen die vorherige Versionsnummer (2.5.18) abrufen und deren Tiefe ermitteln. Das ist etwas mühsam und es reicht nicht aus, nur eine Liste der Versionen zu erhalten und sich die vorherige und die nachfolgende anzusehen.", "metrics": {"bleu_score": 30.858955062958387, "chrf_score": 57.832701828975075, "xcomet_score": 0.7054570913314819, "xcomet_qe_score": 0.7215268015861511, "metricx_score": 9.191012382507324, "metricx_qe_score": 9.126874923706055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine heuristische Abgleichregel erstellt, um die vorherige und die nächste Version zu erhalten.", "metrics": {"bleu_score": 70.85876411943929, "chrf_score": 87.46348659529112, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.38353756070137024, "metricx_qe_score": 0.4680708348751068, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ein Arzneimittel.", "metrics": {"bleu_score": 10.682175159905848, "chrf_score": 12.353469218498505, "xcomet_score": 0.10761722922325134, "xcomet_qe_score": 0.08383049815893173, "metricx_score": 8.32802963256836, "metricx_qe_score": 12.375292778015137, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "Am Ende waren es 7200 Repositories.", "metrics": {"bleu_score": 10.175282441454787, "chrf_score": 43.262796673625026, "xcomet_score": 0.8081121444702148, "xcomet_qe_score": 0.5132638216018677, "metricx_score": 8.880833625793457, "metricx_qe_score": 13.03747844696045, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Auch die durchschnittliche Anzahl der freigegebenen Knoten-Token beträgt 63, was für eine Summierungsaufgabe ziemlich hoch ist.", "metrics": {"bleu_score": 40.335820725998886, "chrf_score": 57.40558166924039, "xcomet_score": 0.8048118352890015, "xcomet_qe_score": 0.8640058040618896, "metricx_score": 7.721992015838623, "metricx_qe_score": 5.0151166915893555, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Anzahl der einzigartigen Token ist ziemlich groß, nämlich 830.000.", "metrics": {"bleu_score": 51.424016050282624, "chrf_score": 74.28804502969588, "xcomet_score": 0.9981303215026855, "xcomet_qe_score": 0.9923341274261475, "metricx_score": 0.5946205854415894, "metricx_qe_score": 0.7913498878479004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "Aufgrund der großen Anzahl an einzigartigen Klassen- und Methodenbezeichnern in der Bibliothek", "metrics": {"bleu_score": 3.1364240458810366, "chrf_score": 35.80677959104126, "xcomet_score": 0.9589021801948547, "xcomet_qe_score": 0.9678342342376709, "metricx_score": 1.8075551986694336, "metricx_qe_score": 0.720818817615509, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als Nächstes werde ich die vorgeschlagene Methode erläutern.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Modell für die klassifizierende extraktive und abstrakte Zusammenfassung besteht aus zwei neuronalen Modulen.", "metrics": {"bleu_score": 37.5022891676693, "chrf_score": 70.5455883273252, "xcomet_score": 0.9391079545021057, "xcomet_qe_score": 0.9362465143203735, "metricx_score": 2.211064577102661, "metricx_qe_score": 3.2953712940216064, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifizierer, der BART oder CodeBART verwendet, und ein Generator, der BART verwendet.", "metrics": {"bleu_score": 11.203754340102181, "chrf_score": 64.6259617872643, "xcomet_score": 0.9775713682174683, "xcomet_qe_score": 0.9943703413009644, "metricx_score": 3.4210188388824463, "metricx_qe_score": 2.2096023559570312, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet CAS einen Klassifizierer, um jede Commit-Nachricht in fünf Release-Note-Klassen zu klassifizieren, nämlich Features, Implementierungen, Bugfixes, Deletionen und Andere.", "metrics": {"bleu_score": 22.934861887625132, "chrf_score": 50.499193476863965, "xcomet_score": 0.810875654220581, "xcomet_qe_score": 0.7852358222007751, "metricx_score": 5.359315395355225, "metricx_qe_score": 4.785514831542969, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die Commit-Nachrichten werden als „andere“ oder „verwerfen“ klassifiziert.", "metrics": {"bleu_score": 11.99014838091355, "chrf_score": 48.22822772164032, "xcomet_score": 0.914267897605896, "xcomet_qe_score": 0.930068850517273, "metricx_score": 3.565941572189331, "metricx_qe_score": 4.654175281524658, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet CAS den Generator auf die vier Label-Dokumente unabhängig an und erstellt einen Release-Knoten für jede Klasse.", "metrics": {"bleu_score": 39.159269732992925, "chrf_score": 63.63363911407046, "xcomet_score": 0.6782820224761963, "xcomet_qe_score": 0.6879698038101196, "metricx_score": 6.722108840942383, "metricx_qe_score": 6.788600444793701, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Entsprechungen zwischen Commit-Nachrichten und Gründen nicht bekannt.", "metrics": {"bleu_score": 43.748114312246464, "chrf_score": 70.05303007764542, "xcomet_score": 0.8069003820419312, "xcomet_qe_score": 0.735093355178833, "metricx_score": 6.906047821044922, "metricx_qe_score": 7.161110877990723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um die Klassifikationsdatei zu trainieren, weisen wir jedem Eingabe-Commit-Nachricht mithilfe der ersten 10 Zeichen jeder Commit-Nachricht ein Pseudolabel zu.", "metrics": {"bleu_score": 10.935069850572576, "chrf_score": 53.214628064387625, "xcomet_score": 0.8375133872032166, "xcomet_qe_score": 0.8773940801620483, "metricx_score": 4.9355573654174805, "metricx_qe_score": 4.735178470611572, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die klassifizierten abstrakten Zusammenfassungen unseres Ansatzes mit zwei verschiedenen Methoden.", "metrics": {"bleu_score": 4.6192151051305474, "chrf_score": 62.943986345013045, "xcomet_score": 0.9672307968139648, "xcomet_qe_score": 0.9574003219604492, "metricx_score": 2.467648506164551, "metricx_qe_score": 2.3754851818084717, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GCS-Single nennen, besteht aus einem einzelnen seq2seq-Netzwerk und generiert einen einzelnen langen Stück-Notentext, der eine Verkettung der Eingabe-Commit-Nachrichten darstellt.", "metrics": {"bleu_score": 36.80080890747155, "chrf_score": 68.72422641077996, "xcomet_score": 0.6286439299583435, "xcomet_qe_score": 0.6610462665557861, "metricx_score": 7.424990177154541, "metricx_qe_score": 7.121487617492676, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgabetext kann in klassenweite Segmente unterteilt werden, die auf speziellen klassenbezogenen Endpunktsymbolen basieren.", "metrics": {"bleu_score": 10.82597837309053, "chrf_score": 55.551547288530955, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.596513032913208, "metricx_qe_score": 0.7681682109832764, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir als CS-Match bezeichnen, besteht aus vier verschiedenen Sek-zu-Sek-Netzwerken, von denen jedes einer der drei Knotenklassen entspricht.", "metrics": {"bleu_score": 53.611312694955046, "chrf_score": 70.15599596660843, "xcomet_score": 0.6471460461616516, "xcomet_qe_score": 0.6374000906944275, "metricx_score": 5.652797698974609, "metricx_qe_score": 5.947703838348389, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, lassen Sie mich das Experiment erklären.", "metrics": {"bleu_score": 9.535414040914192, "chrf_score": 49.75269042427508, "xcomet_score": 0.9954168796539307, "xcomet_qe_score": 0.9940097332000732, "metricx_score": 0.2833854854106903, "metricx_qe_score": 0.276653915643692, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Fünf Methoden wurden verglichen: CES, CES-Single, CES-Multi, Plassering und die vorherige Studie von Griff.", "metrics": {"bleu_score": 23.08087288583725, "chrf_score": 58.642105843295276, "xcomet_score": 0.7409248352050781, "xcomet_qe_score": 0.7460125684738159, "metricx_score": 10.36050033569336, "metricx_qe_score": 10.739588737487793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Was die Bewertung betrifft, so wird in einigen Fällen die Ausgabe in mehreren Sätzen erfolgen.", "metrics": {"bleu_score": 29.213008358451262, "chrf_score": 54.776458412552955, "xcomet_score": 0.892177402973175, "xcomet_qe_score": 0.9279730916023254, "metricx_score": 1.077907919883728, "metricx_qe_score": 1.3548405170440674, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt.", "metrics": {"bleu_score": 83.95876230925758, "chrf_score": 91.66775843741057, "xcomet_score": 0.998297929763794, "xcomet_qe_score": 1.0, "metricx_score": 0.625493586063385, "metricx_qe_score": 1.1572595834732056, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild wird gepinnt, wenn das System einen kurzen Satz ausgibt.", "metrics": {"bleu_score": 66.52049901111006, "chrf_score": 67.54799545041365, "xcomet_score": 0.7956010103225708, "xcomet_qe_score": 0.8009142875671387, "metricx_score": 5.9393110275268555, "metricx_qe_score": 4.765568733215332, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem niedrigeren BLEU-Wert in den im Folgenden beschriebenen Experimentergebnissen.", "metrics": {"bleu_score": 46.0462862587273, "chrf_score": 68.40534515241373, "xcomet_score": 0.9120367765426636, "xcomet_qe_score": 0.9305379986763, "metricx_score": 2.2937066555023193, "metricx_qe_score": 1.9142699241638184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich berechnen wir auch die Spezifität, da Rouge und Bleu nicht berechnet werden können, wenn die Referenznotizen leer sind.", "metrics": {"bleu_score": 64.7084148066781, "chrf_score": 74.1717912741259, "xcomet_score": 0.8104053139686584, "xcomet_qe_score": 0.8327611684799194, "metricx_score": 1.8003127574920654, "metricx_qe_score": 1.9137780666351318, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass das Modell korrekt einen leeren Text ausgibt, wenn die Referenznoten leer sind.", "metrics": {"bleu_score": 29.79698962250273, "chrf_score": 60.03502330360799, "xcomet_score": 0.9919800758361816, "xcomet_qe_score": 0.9879817962646484, "metricx_score": 2.021223306655884, "metricx_qe_score": 2.046523332595825, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse.", "metrics": {"bleu_score": 42.72870063962342, "chrf_score": 48.96283815298874, "xcomet_score": 0.9982582330703735, "xcomet_qe_score": 0.9951757192611694, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Datensatz E-Mail-Adressen, Hash-Werte usw. enthält, haben wir auch den bereinigten Datensatz ausgewertet, der diese ausschließt.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9878028631210327, "xcomet_qe_score": 0.9883376955986023, "metricx_score": 0.32451337575912476, "metricx_qe_score": 0.373135507106781, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "CEAS und CAS erzielten ROUGE-Werte, die mehr als 10 Punkte über den Basiswerten lagen.", "metrics": {"bleu_score": 30.62049088236489, "chrf_score": 67.1322865557844, "xcomet_score": 0.9825015068054199, "xcomet_qe_score": 0.987436056137085, "metricx_score": 1.9343842267990112, "metricx_qe_score": 2.7965309619903564, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem sauberen Testdatensatz sprang die Punktzahl zwischen der vorgeschlagenen Methode und dem Basiswert um mehr als 20 Punkte.", "metrics": {"bleu_score": 21.89321973004432, "chrf_score": 53.890500529625406, "xcomet_score": 0.920684278011322, "xcomet_qe_score": 0.9285101890563965, "metricx_score": 3.9876365661621094, "metricx_qe_score": 3.887296199798584, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse deuten darauf hin, dass CS und CS signifikant wirksam sind.", "metrics": {"bleu_score": 10.571070857151541, "chrf_score": 54.91050602376346, "xcomet_score": 0.7024462223052979, "xcomet_qe_score": 0.7323187589645386, "metricx_score": 11.909339904785156, "metricx_qe_score": 12.665682792663574, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "CAS erzielte einen besseren ROUGE-L-Wert als CAS, was darauf hindeutet, dass die Kombination eines Klassifizierers und eines Generators effektiv ist und das Training des Klassifizierers mit Pseudodaten.", "metrics": {"bleu_score": 43.485960528703046, "chrf_score": 75.50125595943186, "xcomet_score": 0.6015793085098267, "xcomet_qe_score": 0.520487368106842, "metricx_score": 10.620647430419922, "metricx_qe_score": 10.694664001464844, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Abdeckung von CLS kann wahrscheinlich erreicht werden, da der Klassifizierer sich darauf konzentrieren kann, relevante Commit-Nachrichten für jede Klasse auszuwählen.", "metrics": {"bleu_score": 36.760411441989504, "chrf_score": 76.09125146218288, "xcomet_score": 0.8917983174324036, "xcomet_qe_score": 0.8962974548339844, "metricx_score": 4.251952648162842, "metricx_qe_score": 5.364718437194824, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "CAS-Märkte neigen dazu, eine höhere Liquidität zu haben als CAS-Einzelmärkte.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 25.845293878071786, "xcomet_score": 0.2474970817565918, "xcomet_qe_score": 0.736350417137146, "metricx_score": 8.610512733459473, "metricx_qe_score": 6.477594375610352, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es auch effektiv ist, für jede Notenklasse unabhängig verschiedene abstraktive Zusammenfassungsmodelle zu entwickeln.", "metrics": {"bleu_score": 29.12311601944168, "chrf_score": 56.38978580586077, "xcomet_score": 0.9066218137741089, "xcomet_qe_score": 0.9917944669723511, "metricx_score": 5.519840240478516, "metricx_qe_score": 1.5830700397491455, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist eine Fehleranalyse.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9995009899139404, "xcomet_qe_score": 0.996755838394165, "metricx_score": 0.199920654296875, "metricx_qe_score": 0.19591045379638672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "CS-Methoden neigen dazu, kürzere Sätze als menschliche Referenzsätze auszugeben.", "metrics": {"bleu_score": 18.36028134946796, "chrf_score": 71.03068329317165, "xcomet_score": 0.9569727182388306, "xcomet_qe_score": 0.9189335107803345, "metricx_score": 2.331177234649658, "metricx_qe_score": 2.9443938732147217, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Abbildung rechts hat der Referenzsatz drei oder vier Sätze, während der CUS nur einen hat.", "metrics": {"bleu_score": 22.081791502306793, "chrf_score": 65.04396078279234, "xcomet_score": 0.9459340572357178, "xcomet_qe_score": 0.8751664161682129, "metricx_score": 4.140008926391602, "metricx_qe_score": 4.938417434692383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für die Zurückhaltung dieses Modells ist, dass in den Trainingsdaten nur 33 % der Sätze im Merkmalslabel und 40 % im Verbesserungslabel vorhanden sind.", "metrics": {"bleu_score": 39.32252854221628, "chrf_score": 54.788803939171316, "xcomet_score": 0.9641613960266113, "xcomet_qe_score": 0.988274335861206, "metricx_score": 1.8342424631118774, "metricx_qe_score": 1.5293227434158325, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CS-Methoden ohne zusätzliche Informationen keine genauen Knotenpunkte generieren.", "metrics": {"bleu_score": 43.66835442847811, "chrf_score": 72.97794858773649, "xcomet_score": 0.7742142677307129, "xcomet_qe_score": 0.7636765241622925, "metricx_score": 6.851050853729248, "metricx_qe_score": 7.197779178619385, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr unübersichtliche Commit-Nachricht, und der vollständige Satz kann nicht ohne Bezug auf die entsprechende Pull-Anfrage oder das Issue erstellt werden.", "metrics": {"bleu_score": 52.60207544323876, "chrf_score": 75.90694663876138, "xcomet_score": 0.9076735377311707, "xcomet_qe_score": 0.9081977009773254, "metricx_score": 2.862863302230835, "metricx_qe_score": 2.794112205505371, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das folgende Beispiel zeigt, dass die beiden Commit-Nachrichten im Eingabebereich zusammenhängen und zu einem Satz kombiniert werden sollten, aber es ist nicht in der Lage, dies zu tun.", "metrics": {"bleu_score": 42.33412377983105, "chrf_score": 72.47760546056705, "xcomet_score": 0.9699723720550537, "xcomet_qe_score": 0.9698984622955322, "metricx_score": 1.03981351852417, "metricx_qe_score": 1.2202386856079102, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Endlich ein Schlussfolgerung.", "metrics": {"bleu_score": 9.688464563433238, "chrf_score": 8.293687032730688, "xcomet_score": 0.9296220541000366, "xcomet_qe_score": 0.9355574250221252, "metricx_score": 3.793226718902588, "metricx_qe_score": 2.386927366256714, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Bildunterschrifterstellung erstellt.", "metrics": {"bleu_score": 61.85985276068634, "chrf_score": 64.64876335278912, "xcomet_score": 0.9102790951728821, "xcomet_qe_score": 0.9743515253067017, "metricx_score": 1.273285984992981, "metricx_qe_score": 1.140967845916748, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe übernommen, Commit-Nachrichten einzugeben und sie so zusammenzufassen, dass sie für alle Projekte in englischer Sprache anwendbar sind.", "metrics": {"bleu_score": 11.196951206580167, "chrf_score": 54.72182453708223, "xcomet_score": 0.9967609643936157, "xcomet_qe_score": 0.9970227479934692, "metricx_score": 1.089107632637024, "metricx_qe_score": 1.4586255550384521, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode im Vergleich zu den Basislinien bei höherer Abdeckung weniger verrauschte Blattnoten erzeugt.", "metrics": {"bleu_score": 38.75407750115175, "chrf_score": 67.28939053525801, "xcomet_score": 0.8160849809646606, "xcomet_qe_score": 0.840019941329956, "metricx_score": 4.7619829177856445, "metricx_qe_score": 4.215037822723389, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte überprüfen Sie die Kreditkarte oder Debitkarte.", "metrics": {"bleu_score": 5.660233915657916, "chrf_score": 18.730923351284375, "xcomet_score": 0.1337393820285797, "xcomet_qe_score": 0.12909957766532898, "metricx_score": 5.563376426696777, "metricx_qe_score": 14.857891082763672, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke.", "metrics": {"bleu_score": 0.0, "chrf_score": 20.4664420548395, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.02491046115756035, "metricx_qe_score": 0.1274172067642212, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Asaf Harari.", "metrics": {"bleu_score": 54.10822690539397, "chrf_score": 81.82110562545346, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [1, "NYNORSK"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde unseren Artikel „Few-Shot Tabellarische Datenanreicherung durch Feinabstimmung von Transformer-Architekturen“ vorstellen.", "metrics": {"bleu_score": 6.299392144493405, "chrf_score": 49.15190583196248, "xcomet_score": 0.8342900276184082, "xcomet_qe_score": 0.8245478868484497, "metricx_score": 3.5784621238708496, "metricx_qe_score": 4.776658058166504, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Ein Datenwissenschaftler analysiert Daten und konzentriert sich hauptsächlich auf die Manipulation der vorhandenen Merkmale der Daten.", "metrics": {"bleu_score": 35.66325206249313, "chrf_score": 74.32374616790764, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.31927740573883057, "metricx_qe_score": 0.43289533257484436, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind diese Funktionen eingeschränkt.", "metrics": {"bleu_score": 64.34588841607616, "chrf_score": 77.23728006526383, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.09981583058834076, "metricx_qe_score": 0.053570352494716644, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Generierung von Merkmalen mit einer anderen Datenquelle kann erhebliche Informationen hinzufügen.", "metrics": {"bleu_score": 33.094278637005694, "chrf_score": 68.77137526650878, "xcomet_score": 0.9318251609802246, "xcomet_qe_score": 0.9854501485824585, "metricx_score": 0.9519442319869995, "metricx_qe_score": 0.5810158252716064, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung von Tabellendaten mit Hilfe von externen Quellen und Freitext.", "metrics": {"bleu_score": 35.83129187641355, "chrf_score": 70.50422549136591, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.552281379699707, "metricx_qe_score": 0.5164240002632141, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Angenommen, wir haben einen tabellarischen Datensatz und eine Wissensdatenbank.", "metrics": {"bleu_score": 80.70557274927978, "chrf_score": 90.56639279059108, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.42374300956726074, "metricx_qe_score": 0.5424605011940002, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der Entity-Linking und Textanalyse umfasst, um neue Merkmale aus dem freien Text der Wissensdatenbank zu extrahieren.", "metrics": {"bleu_score": 46.61126078391023, "chrf_score": 75.52398574265798, "xcomet_score": 0.994632363319397, "xcomet_qe_score": 0.9947315454483032, "metricx_score": 0.5816729664802551, "metricx_qe_score": 0.6486860513687134, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Framework F.A.S.T. ist genau dieser automatische Prozess.", "metrics": {"bleu_score": 31.314224813827344, "chrf_score": 71.94008810824428, "xcomet_score": 0.8641369342803955, "xcomet_qe_score": 0.8882192373275757, "metricx_score": 2.4083352088928223, "metricx_qe_score": 2.356740713119507, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir also ein Beispiel. In einem Datensatz, der in FAST eingegeben wird,", "metrics": {"bleu_score": 17.696061128311285, "chrf_score": 55.627293031551325, "xcomet_score": 0.843608021736145, "xcomet_qe_score": 0.8432995080947876, "metricx_score": 6.228757381439209, "metricx_qe_score": 5.189748764038086, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Datensatz der Universitätsdatensatz.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.996767520904541, "xcomet_qe_score": 0.9648513793945312, "metricx_score": 0.24305054545402527, "metricx_qe_score": 0.6734426021575928, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig und hoch eingestufte Universitäten zu klassifizieren.", "metrics": {"bleu_score": 3.716499092256817, "chrf_score": 40.264880975281194, "xcomet_score": 0.958512544631958, "xcomet_qe_score": 1.0, "metricx_score": 0.9131710529327393, "metricx_qe_score": 0.6599442362785339, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase von FACE ist die Entitätsverknüpfung.", "metrics": {"bleu_score": 33.03164318013809, "chrf_score": 54.068599557758226, "xcomet_score": 0.8599870800971985, "xcomet_qe_score": 0.86273592710495, "metricx_score": 4.292385578155518, "metricx_qe_score": 4.725816249847412, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Einheit in diesem Beispiel, der Universitätsname, mit einer Einheit in der Wissensbasis verknüpft ist.", "metrics": {"bleu_score": 15.424886686569662, "chrf_score": 61.340219925375486, "xcomet_score": 0.9397602081298828, "xcomet_qe_score": 0.9673734903335571, "metricx_score": 1.7633283138275146, "metricx_qe_score": 0.9960551857948303, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "Der Text der Entitäten der Wissensbasis wird extrahiert und der Datensatz wird hinzugefügt.", "metrics": {"bleu_score": 49.4799546857679, "chrf_score": 84.38355460964603, "xcomet_score": 0.980074405670166, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.769563674926758, "metricx_qe_score": 2.701035261154175, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text die Wikipedia-Seitenzusammenfassung.", "metrics": {"bleu_score": 48.88290318657944, "chrf_score": 69.81205440655678, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.39785298705101013, "metricx_qe_score": 0.39478129148483276, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Merkmale aus dem abgerufenen Text generieren oder extrahieren.", "metrics": {"bleu_score": 67.0422683816333, "chrf_score": 77.33494683082183, "xcomet_score": 0.9531110525131226, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.8071900010108948, "metricx_qe_score": 0.34741824865341187, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen also eine Merkmalsextraktionsphase, die eine Textanalyse umfasst.", "metrics": {"bleu_score": 7.126814447219878, "chrf_score": 45.821874056384196, "xcomet_score": 0.990280270576477, "xcomet_qe_score": 0.9877825975418091, "metricx_score": 4.109596252441406, "metricx_qe_score": 3.532917022705078, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Das ist die Hauptneuerung dieses Papiers und ich werde in den nächsten Folien darauf eingehen.", "metrics": {"bleu_score": 14.769381080839452, "chrf_score": 56.485499087746085, "xcomet_score": 0.9706738591194153, "xcomet_qe_score": 0.9472904205322266, "metricx_score": 1.3323378562927246, "metricx_qe_score": 2.03373122215271, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Merkmalsextraktionsphase gibt es eine Merkmalsgenerierungsphase, in der die extrahierten Merkmale verwendet werden, um eine kleine Anzahl neuer Merkmale zu generieren.", "metrics": {"bleu_score": 25.758623906530957, "chrf_score": 52.608917811659126, "xcomet_score": 0.9626513719558716, "xcomet_qe_score": 0.9875475168228149, "metricx_score": 0.3899295926094055, "metricx_qe_score": 0.35055118799209595, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Erstellen Sie zunächst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes.", "metrics": {"bleu_score": 57.60844201603898, "chrf_score": 67.14453095184793, "xcomet_score": 0.8808572888374329, "xcomet_qe_score": 0.8498636484146118, "metricx_score": 3.3072919845581055, "metricx_qe_score": 3.7931361198425293, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.08455271273851395, "metricx_qe_score": 0.3038375675678253, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "FAST generiert zwei neue Merkmale.", "metrics": {"bleu_score": 16.341219448835542, "chrf_score": 40.993568033102314, "xcomet_score": 0.8588351011276245, "xcomet_qe_score": 0.8572210073471069, "metricx_score": 5.831135272979736, "metricx_qe_score": 5.38856315612793, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, werden zuerst fünf neue Merkmale generiert.", "metrics": {"bleu_score": 54.451788461394045, "chrf_score": 69.62009756114138, "xcomet_score": 0.8642224073410034, "xcomet_qe_score": 0.9679117202758789, "metricx_score": 0.9346655011177063, "metricx_qe_score": 1.5719428062438965, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jedes Merkmal stellt die Wahrscheinlichkeit für jede Klasse dar.", "metrics": {"bleu_score": 75.98356856515926, "chrf_score": 80.87613221584733, "xcomet_score": 0.9944548606872559, "xcomet_qe_score": 1.0, "metricx_score": 0.44356730580329895, "metricx_qe_score": 0.26466989517211914, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, nämlich Transformator-basierte Sprachmodelle wie BERT, XLNet usw.", "metrics": {"bleu_score": 35.68130880200823, "chrf_score": 66.88317735879761, "xcomet_score": 0.9959748983383179, "xcomet_qe_score": 0.978366494178772, "metricx_score": 1.5178807973861694, "metricx_qe_score": 1.234339952468872, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedatensätzen trainieren können.", "metrics": {"bleu_score": 28.977907494497117, "chrf_score": 71.8197433398536, "xcomet_score": 0.9898693561553955, "xcomet_qe_score": 0.9837964773178101, "metricx_score": 0.8059920072555542, "metricx_qe_score": 1.2084702253341675, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wäre also eine Feinabstimmung für die Zielaufgabe.", "metrics": {"bleu_score": 24.384183193426086, "chrf_score": 61.64028791316619, "xcomet_score": 0.9733928442001343, "xcomet_qe_score": 0.9654176235198975, "metricx_score": 1.1307142972946167, "metricx_qe_score": 1.749509572982788, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Merkmalsextraktion können wir ein vorab trainiertes Sprachmodell herunterladen und das Sprachmodell auf dem Ziel-Datensatz feinabstimmen.", "metrics": {"bleu_score": 28.50782270836371, "chrf_score": 73.88447944903255, "xcomet_score": 0.9687356948852539, "xcomet_qe_score": 0.9553158283233643, "metricx_score": 0.3935399353504181, "metricx_qe_score": 0.5852683782577515, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell so angepasst, dass es Text in die Klassen „abstrakt“ und „konkret“ einteilt.", "metrics": {"bleu_score": 9.181924734076214, "chrf_score": 39.483647297635464, "xcomet_score": 0.8541611433029175, "xcomet_qe_score": 0.8340325355529785, "metricx_score": 2.3420848846435547, "metricx_qe_score": 5.524777889251709, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen Sie die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse ist, und verwenden Sie sie als neue Merkmale.", "metrics": {"bleu_score": 56.83565265173783, "chrf_score": 73.22275352871695, "xcomet_score": 0.9180306196212769, "xcomet_qe_score": 0.9524835348129272, "metricx_score": 1.302284598350525, "metricx_qe_score": 0.9626094698905945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datensätze nur wenige verschiedene Entitätstags haben.", "metrics": {"bleu_score": 49.942858047930116, "chrf_score": 61.33000719305356, "xcomet_score": 0.927977442741394, "xcomet_qe_score": 0.9217727184295654, "metricx_score": 2.5478403568267822, "metricx_qe_score": 2.180744171142578, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als 400 Proben und der kleinste Datensatz enthielt 35 Proben in seinem Trainingssatz.", "metrics": {"bleu_score": 47.8219647449668, "chrf_score": 80.49680488679745, "xcomet_score": 0.9715559482574463, "xcomet_qe_score": 0.9648252725601196, "metricx_score": 0.4781830310821533, "metricx_qe_score": 0.8482542634010315, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Die Feinabstimmung eines Sprachmodells auf diesem Datensatz wäre also ineffektiv.", "metrics": {"bleu_score": 26.985534666825092, "chrf_score": 65.68040975598764, "xcomet_score": 0.9903790950775146, "xcomet_qe_score": 0.9909271001815796, "metricx_score": 0.4555022418498993, "metricx_qe_score": 0.2851836085319519, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können aber Vorwissen über vorab analysierte Datensätze nutzen.", "metrics": {"bleu_score": 26.305014340253436, "chrf_score": 56.63472479152014, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.12369386851787567, "metricx_qe_score": 0.21882227063179016, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die n-1 Datensätze verwenden, um Informationen über die n-1 Datensätze zu sammeln und diese Informationen verwenden, wenn wir den n-ten Datensatz analysieren.", "metrics": {"bleu_score": 61.60374066124534, "chrf_score": 84.44914059052864, "xcomet_score": 0.7250744700431824, "xcomet_qe_score": 0.7390174865722656, "metricx_score": 2.700120449066162, "metricx_qe_score": 2.5597634315490723, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir vorschlagen, ist eine weitere Feinabstimmungsphase hinzuzufügen.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 85.87863575855958, "xcomet_score": 0.9772741794586182, "xcomet_qe_score": 0.9562488794326782, "metricx_score": 0.8425611257553101, "metricx_qe_score": 0.9712173938751221, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Multitasking-Feinabstimmungsphase.", "metrics": {"bleu_score": 11.521590992286539, "chrf_score": 81.26861889672587, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.5895780324935913, "metricx_qe_score": 0.8907869458198547, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie ein Sprachmodell über N-1-Datensätze feinabstimmen,", "metrics": {"bleu_score": 3.7968017775955714, "chrf_score": 47.97265963108212, "xcomet_score": 0.9097775816917419, "xcomet_qe_score": 0.814358115196228, "metricx_score": 1.3166286945343018, "metricx_qe_score": 1.0774903297424316, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Danach führen wir eine weitere Feinabstimmungsphase durch, die eine Zielaufgaben-Feinabstimmung ist, bei der wir das Sprachmodell über den n-ten Ziel-Datensatz feinabstimmen.", "metrics": {"bleu_score": 55.319614741021326, "chrf_score": 78.35247044460662, "xcomet_score": 0.8878064155578613, "xcomet_qe_score": 0.8615779876708984, "metricx_score": 1.7162014245986938, "metricx_qe_score": 1.3771424293518066, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der aktuelle Stand der Technik beim Multitasking-Finetuning wird als MT-DNN bezeichnet.", "metrics": {"bleu_score": 4.02724819242185, "chrf_score": 31.8323693891814, "xcomet_score": 0.9786809682846069, "xcomet_qe_score": 0.9682139158248901, "metricx_score": 2.7295031547546387, "metricx_qe_score": 2.3811583518981934, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MT-DNN werden so viele Köpfe wie Aufgaben im Trainingsdatensatz gehalten.", "metrics": {"bleu_score": 6.344849033136089, "chrf_score": 36.38433780639394, "xcomet_score": 0.8340734243392944, "xcomet_qe_score": 0.8781155347824097, "metricx_score": 11.118947982788086, "metricx_qe_score": 7.310001850128174, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es vier Aufgaben im Trainingssatz, sodass ein leeres DNN vier Köpfe behält, wie Sie auf dem Bild sehen können.", "metrics": {"bleu_score": 54.119533608948146, "chrf_score": 67.61032906015748, "xcomet_score": 0.874071478843689, "xcomet_qe_score": 0.8842984437942505, "metricx_score": 8.54061508178711, "metricx_qe_score": 7.928953170776367, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Es entnimmt eine zufällige Stichprobe aus dem Trainingsdatensatz.", "metrics": {"bleu_score": 10.729256185679601, "chrf_score": 52.6950971213975, "xcomet_score": 0.9784504175186157, "xcomet_qe_score": 0.971786379814148, "metricx_score": 1.5006515979766846, "metricx_qe_score": 2.0808703899383545, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Eingabebatch beispielsweise zu einer Aufgabe der Einzelzellenklassifizierung gehört, führt er einen Vorwärts- und Rückwärtsdurchlauf durch den ersten Kopf aus.", "metrics": {"bleu_score": 10.665549155965792, "chrf_score": 48.96943461395863, "xcomet_score": 0.7365477681159973, "xcomet_qe_score": 0.7610371112823486, "metricx_score": 8.163180351257324, "metricx_qe_score": 7.003668785095215, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der zufällige Batch zur paarweisen Rangfolgeaufgabe gehört, wird er in Vorwärts- und Rückwärtsrichtung durch den letzten Kopf geführt.", "metrics": {"bleu_score": 6.429451441231725, "chrf_score": 49.609088781814506, "xcomet_score": 0.8162111043930054, "xcomet_qe_score": 0.8731609582901001, "metricx_score": 5.789957046508789, "metricx_qe_score": 3.5154428482055664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario variiert die Anzahl der Klassen in den Tabellen-Datasets.", "metrics": {"bleu_score": 22.781556051062047, "chrf_score": 62.654479825718546, "xcomet_score": 0.9932911396026611, "xcomet_qe_score": 0.9951905012130737, "metricx_score": 2.064690351486206, "metricx_qe_score": 1.429830551147461, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.05911726504564285, "metricx_qe_score": 0.12243705987930298, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "Ein leeres neuronales Netzwerk behält die Anzahl der Klassen, Köpfe (Ausgabeschichten).", "metrics": {"bleu_score": 6.250381527944883, "chrf_score": 29.645194168029004, "xcomet_score": 0.6936671733856201, "xcomet_qe_score": 0.8422032594680786, "metricx_score": 8.420842170715332, "metricx_qe_score": 8.266481399536133, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich muss mtDNA neue Köpfe für einen neuen Datensatz mit einer neuen Aufgabe initialisieren.", "metrics": {"bleu_score": 61.32167468990615, "chrf_score": 74.01303498744896, "xcomet_score": 0.8537733554840088, "xcomet_qe_score": 0.8918019533157349, "metricx_score": 6.045273780822754, "metricx_qe_score": 5.520477294921875, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als „Aufgabenreformulierung und Feinabstimmung“ bezeichnet wird, besteht darin, dass wir anstelle der Beibehaltung mehrerer Köpfe jeden Datensatz in ein Satz-zu-Klassifikationsproblem umformulieren, das eine Aufgabe mit zwei Klassen ist.", "metrics": {"bleu_score": 21.245026220526633, "chrf_score": 62.89209213494355, "xcomet_score": 0.7691113948822021, "xcomet_qe_score": 0.7761979103088379, "metricx_score": 7.6946797370910645, "metricx_qe_score": 4.864134788513184, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns ein Beispiel an.", "metrics": {"bleu_score": 80.91067115702207, "chrf_score": 82.06979784224109, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.035305172204971313, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Eingabedatensatz, der aus Entitäten, Merkmalen, Texten und Klassen besteht.", "metrics": {"bleu_score": 44.02004976281389, "chrf_score": 68.35251117024768, "xcomet_score": 0.9899753332138062, "xcomet_qe_score": 0.9885627627372742, "metricx_score": 0.5625899434089661, "metricx_qe_score": 0.3184806704521179, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Wir werden die Aufgabe von der Klassifizierung des Textes in „niedrig“ und „hoch“ in die Klassifizierung des Textes, des Abstracts und der Klasse in „wahr“ oder „falsch“ umformulieren.", "metrics": {"bleu_score": 43.994654743790214, "chrf_score": 75.55762189963782, "xcomet_score": 0.976173996925354, "xcomet_qe_score": 0.939998984336853, "metricx_score": 0.6347491145133972, "metricx_qe_score": 0.8100576400756836, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "Mit anderen Worten, wir trainieren das Sprachmodell, um zu klassifizieren, ob ein Abstract zu einer Klasse gehört oder nicht.", "metrics": {"bleu_score": 15.795049600663667, "chrf_score": 53.11256755135253, "xcomet_score": 0.5722086429595947, "xcomet_qe_score": 0.4701421856880188, "metricx_score": 2.343808174133301, "metricx_qe_score": 5.131760597229004, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Label-Vektor besteht im Fall von X also immer aus zwei Klassen.", "metrics": {"bleu_score": 17.658800420844404, "chrf_score": 40.49022238339454, "xcomet_score": 0.9485912322998047, "xcomet_qe_score": 0.8734673261642456, "metricx_score": 3.82975172996521, "metricx_qe_score": 4.5054802894592285, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist der Algorithmus für unseren neu formulierten Feinabstimmungsansatz.", "metrics": {"bleu_score": 66.06328636027612, "chrf_score": 90.6887104374834, "xcomet_score": 0.9963152408599854, "xcomet_qe_score": 0.9739564061164856, "metricx_score": 0.9213470220565796, "metricx_qe_score": 1.2436248064041138, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Sehen wir uns den vollständigen Rahmen an.", "metrics": {"bleu_score": 23.87517132417733, "chrf_score": 47.74301213881398, "xcomet_score": 0.9471232891082764, "xcomet_qe_score": 0.9389484524726868, "metricx_score": 0.7608739137649536, "metricx_qe_score": 1.0074098110198975, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "Der Datensatz wird in FASTA eingegeben.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 61.314688730744294, "xcomet_score": 0.8610962629318237, "xcomet_qe_score": 0.8779367804527283, "metricx_score": 3.4030330181121826, "metricx_qe_score": 2.5688421726226807, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Dann eine schnelle Ausführungsphase der Entitätsverknüpfung.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 23.315515722586042, "xcomet_score": 0.8702676296234131, "xcomet_qe_score": 0.9090422987937927, "metricx_score": 5.655413627624512, "metricx_qe_score": 6.5858964920043945, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensdatenbank, die in diesem Beispiel der Abstract der Wikipedia-Seite ist.", "metrics": {"bleu_score": 66.7278568794606, "chrf_score": 86.34553929435954, "xcomet_score": 0.9775482416152954, "xcomet_qe_score": 0.9384680390357971, "metricx_score": 1.1991604566574097, "metricx_qe_score": 1.5967621803283691, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann formuliert es die Aufgabe in eine Satz-zu-Satz-Klassifizierungsaufgabe um.", "metrics": {"bleu_score": 42.2683921634124, "chrf_score": 64.40909685104, "xcomet_score": 0.8914721012115479, "xcomet_qe_score": 0.846792459487915, "metricx_score": 0.9993879795074463, "metricx_qe_score": 0.978076159954071, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und geben Sie die Wahrscheinlichkeit für jede Klasse aus.", "metrics": {"bleu_score": 20.522120509305022, "chrf_score": 67.84521726058627, "xcomet_score": 0.8582490682601929, "xcomet_qe_score": 0.849443793296814, "metricx_score": 0.6048263311386108, "metricx_qe_score": 1.3853343725204468, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über den Datensatz N-1 unter Verwendung einer vorläufigen Multitasking-Feinabstimmung feinabgestimmt wurde.", "metrics": {"bleu_score": 23.210911117419965, "chrf_score": 71.99165580694182, "xcomet_score": 0.91091388463974, "xcomet_qe_score": 0.8449099063873291, "metricx_score": 2.0440714359283447, "metricx_qe_score": 2.669736385345459, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu generiertes Merkmal in der Anzahl der Klassen.", "metrics": {"bleu_score": 48.25893492910237, "chrf_score": 78.77131668956869, "xcomet_score": 0.9281067848205566, "xcomet_qe_score": 0.9129951000213623, "metricx_score": 0.7006075382232666, "metricx_qe_score": 1.164575219154358, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unseren Rahmen zu bewerten, verwenden wir 17 tabellarische Klassifizierungsdatensätze, die sich in Größe, Merkmalen, Ausgewogenheit, Domäne und anfänglicher Leistung unterscheiden.", "metrics": {"bleu_score": 55.345478089080956, "chrf_score": 77.22189754350389, "xcomet_score": 0.9742966890335083, "xcomet_qe_score": 0.907701849937439, "metricx_score": 0.7353247404098511, "metricx_qe_score": 1.375623106956482, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unser Experiment als Leave-one-out-Bewertung gestaltet, bei der wir FAST an 16 Datensätzen trainieren und es dann auf den 17. Datensatz anwenden.", "metrics": {"bleu_score": 39.392661757434155, "chrf_score": 66.00101218192658, "xcomet_score": 0.8243609666824341, "xcomet_qe_score": 0.8231717348098755, "metricx_score": 3.0977909564971924, "metricx_qe_score": 3.5928244590759277, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch jede Datenspalte in vier Faltungen aufgeteilt und eine vierfache Kreuzvalidierung angewendet.", "metrics": {"bleu_score": 12.51723443026766, "chrf_score": 53.8478992395687, "xcomet_score": 0.8281431198120117, "xcomet_qe_score": 0.8147814273834229, "metricx_score": 3.7332968711853027, "metricx_qe_score": 4.2792582511901855, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Merkmale und bewerten sie mit fünf Bewertungs-Klassifikatoren.", "metrics": {"bleu_score": 59.230330720232516, "chrf_score": 68.0299814166746, "xcomet_score": 0.9900964498519897, "xcomet_qe_score": 0.9999524354934692, "metricx_score": 1.0327194929122925, "metricx_qe_score": 1.0336765050888062, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment verwenden wir eine BERT-basierte Architektur.", "metrics": {"bleu_score": 5.669791110976001, "chrf_score": 55.04754338685888, "xcomet_score": 0.9994149208068848, "xcomet_qe_score": 1.0, "metricx_score": 0.4602672755718231, "metricx_qe_score": 0.8600165247917175, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 85.51131524815735, "xcomet_score": 0.9987486600875854, "xcomet_qe_score": 0.9999598264694214, "metricx_score": 0.0, "metricx_qe_score": 0.0, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unseren Rahmen mit der Feinabstimmung des Ziel-Datensatzes, der Feinabstimmung der Zielaufgabe und der vorläufigen Feinabstimmung von MT-DNN vergleichen.", "metrics": {"bleu_score": 60.493083201449835, "chrf_score": 85.86676751395092, "xcomet_score": 0.9686628580093384, "xcomet_qe_score": 0.9172540903091431, "metricx_score": 2.0970423221588135, "metricx_qe_score": 3.5565438270568848, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Unsere neu formulierte Feinabstimmung erzielte die besten Ergebnisse, die beste Leistung.", "metrics": {"bleu_score": 38.67706276352344, "chrf_score": 75.08891157308102, "xcomet_score": 0.9648839235305786, "xcomet_qe_score": 0.9511882066726685, "metricx_score": 0.34599608182907104, "metricx_qe_score": 0.5567026138305664, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MT-DNN eine Verbesserung von 2 % gegenüber der Feinabstimmung auf dem Ziel-Datensatz erzielte,", "metrics": {"bleu_score": 10.511846841633776, "chrf_score": 57.772606437041894, "xcomet_score": 0.9179993271827698, "xcomet_qe_score": 0.9420238137245178, "metricx_score": 1.7200701236724854, "metricx_qe_score": 2.1445741653442383, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz erzielte eine Verbesserung von 6 %.", "metrics": {"bleu_score": 14.448814886766836, "chrf_score": 40.95749393921971, "xcomet_score": 0.985198974609375, "xcomet_qe_score": 0.9885041117668152, "metricx_score": 0.14844700694084167, "metricx_qe_score": 0.2075570523738861, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleine Datenmenge ansehen, können wir feststellen, dass die Leistung des leeren DNN abnimmt und die Verbesserung der mehrstufigen Feinabstimmungsphase auf 1,5 % sinkt.", "metrics": {"bleu_score": 27.131522293656104, "chrf_score": 62.433502903813796, "xcomet_score": 0.7238529324531555, "xcomet_qe_score": 0.7258074879646301, "metricx_score": 6.095028400421143, "metricx_qe_score": 7.2738447189331055, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Leistung stieg jedoch um 11 % im Vergleich zur Feinabstimmung der Zielaufgabe.", "metrics": {"bleu_score": 20.458069164373967, "chrf_score": 57.03667406835524, "xcomet_score": 0.9815198183059692, "xcomet_qe_score": 0.962350606918335, "metricx_score": 1.1623985767364502, "metricx_qe_score": 1.6552408933639526, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für das Summieren ermöglicht FAST eine Few-Shot-Verbesserung aus 35 Proben in unserem Experiment.", "metrics": {"bleu_score": 13.508625657351418, "chrf_score": 63.08690340617286, "xcomet_score": 0.7776241302490234, "xcomet_qe_score": 0.7562897801399231, "metricx_score": 5.6126508712768555, "metricx_qe_score": 7.27853536605835, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben und Datensätze.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9911325573921204, "xcomet_qe_score": 0.990761399269104, "metricx_score": 0.262288898229599, "metricx_qe_score": 0.4292936623096466, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells.", "metrics": {"bleu_score": 27.054113452696992, "chrf_score": 54.42421912540176, "xcomet_score": 0.798446536064148, "xcomet_qe_score": 0.8068912029266357, "metricx_score": 4.322042465209961, "metricx_qe_score": 5.432572841644287, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Es fügt jedoch eine Reformulierungsphase hinzu.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 79.32204011312707, "xcomet_score": 0.9725054502487183, "xcomet_qe_score": 0.933185338973999, "metricx_score": 0.296936959028244, "metricx_qe_score": 0.7336371541023254, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es erweitert den Datensatz um einen Zielwert mit semantischer Bedeutung, sodass wir ihn in das Sprachmodell einspeisen und ihn im Satz-zu-Klassifikationsproblem verwenden können.", "metrics": {"bleu_score": 49.81804438211992, "chrf_score": 75.4117933226284, "xcomet_score": 0.8266188502311707, "xcomet_qe_score": 0.7765039205551147, "metricx_score": 3.5212721824645996, "metricx_qe_score": 4.268820285797119, "linguapy_score": [0, "GERMAN"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Vielen Dank.", "metrics": {"bleu_score": 0.0, "chrf_score": 87.72426647426647, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.0, "metricx_qe_score": 0.008224070072174072, "linguapy_score": [0, "GERMAN"]}}
