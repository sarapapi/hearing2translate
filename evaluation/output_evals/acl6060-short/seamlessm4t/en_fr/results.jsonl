{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "fr", "output": "Bonjour à tous. Aujourd'hui, je vais présenter notre travail de recherche sur l'apprentissage du raisonnement déductif. Le problème de la matière est l'extraction de raisonnements complexes.", "metrics": {"bleu_score": 21.77486375225483, "chrf_score": 56.3148895799932, "xcomet_score": 0.7005549669265747, "xcomet_qe_score": 0.7346048951148987, "metricx_score": 6.688130855560303, "metricx_qe_score": 7.602171897888184, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "fr", "output": "Je suis Alan du laboratoire aérien de Biden et c'est un travail conjoint avec Chiri de l'Université du Texas à Austin et Weidell de S.U.D.", "metrics": {"bleu_score": 23.772018834023733, "chrf_score": 47.89762620990661, "xcomet_score": 0.10356420278549194, "xcomet_qe_score": 0.2332887053489685, "metricx_score": 18.416601181030273, "metricx_qe_score": 18.7995662689209, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, j'aimerais parler de notre motivation pour le raisonnement.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2991740703582764, "metricx_qe_score": 1.329599380493164, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "fr", "output": "On va voir des exemples où la prise de masse est utile.", "metrics": {"bleu_score": 9.809884033350569, "chrf_score": 25.476909715609796, "xcomet_score": 0.23389488458633423, "xcomet_qe_score": 0.4305223822593689, "metricx_score": 14.938522338867188, "metricx_qe_score": 13.917570114135742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "fr", "output": "Cette figure est tirée du papier de poche, où ils font des promptings pour résoudre le problème de mathématiques dans un scénario de futur.", "metrics": {"bleu_score": 12.3069678407633, "chrf_score": 37.16418923096384, "xcomet_score": 0.14017315208911896, "xcomet_qe_score": 0.3669331669807434, "metricx_score": 15.9436674118042, "metricx_qe_score": 14.932782173156738, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "fr", "output": "Donc sur le site de NetPen, nous pouvons voir que si nous donnons des échantillons avec des réponses juste correctives, nous ne pourrons peut-être pas obtenir les bonnes réponses.", "metrics": {"bleu_score": 28.704483729049826, "chrf_score": 53.18418815084499, "xcomet_score": 0.32301539182662964, "xcomet_qe_score": 0.27584338188171387, "metricx_score": 7.014819145202637, "metricx_qe_score": 7.429731369018555, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si nous donnons une description plus raisonnable, le modèle est capable de prédire la description raisonnable et aussi de faire une prédiction correcte ici.", "metrics": {"bleu_score": 25.187882547726936, "chrf_score": 56.18699804150397, "xcomet_score": 0.7181679010391235, "xcomet_qe_score": 0.8924581408500671, "metricx_score": 5.934930801391602, "metricx_qe_score": 2.9680333137512207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "fr", "output": "Donc c'est bon d'avoir un multi-step de sortie.", "metrics": {"bleu_score": 6.506124089578341, "chrf_score": 20.515734689644983, "xcomet_score": 0.35462743043899536, "xcomet_qe_score": 0.6160316467285156, "metricx_score": 11.255277633666992, "metricx_qe_score": 11.22841739654541, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pensons aussi que le problème méthodologique est une application stricte pour évaluer de telles capacités de raisonnement.", "metrics": {"bleu_score": 40.9961728958804, "chrf_score": 66.86449272143557, "xcomet_score": 0.6467500925064087, "xcomet_qe_score": 0.7002195119857788, "metricx_score": 12.490856170654297, "metricx_qe_score": 11.420404434204102, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans notre configuration de problème, compte tenu des questions, nous devons résoudre cette question et obtenir les réponses numériques.", "metrics": {"bleu_score": 92.62536587978961, "chrf_score": 96.13136134079981, "xcomet_score": 0.9667623043060303, "xcomet_qe_score": 0.927720308303833, "metricx_score": 1.1695979833602905, "metricx_qe_score": 1.218113899230957, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "fr", "output": "Donc dans nos ensembles de données, nous sommes aussi donnés l'expression mathématique, qui mène à cette réponse particulière aussi.", "metrics": {"bleu_score": 19.107222957437607, "chrf_score": 61.10506305446687, "xcomet_score": 0.9306485056877136, "xcomet_qe_score": 0.9424303770065308, "metricx_score": 6.444601535797119, "metricx_qe_score": 6.390134811401367, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "fr", "output": "Donc certaines hypothèses s'appliquent aussi, comme dans le travail précédent.", "metrics": {"bleu_score": 17.827531042796263, "chrf_score": 61.858676322262106, "xcomet_score": 0.9959211349487305, "xcomet_qe_score": 1.0, "metricx_score": 2.2014212608337402, "metricx_qe_score": 2.4614291191101074, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons la précision des quantités connues.", "metrics": {"bleu_score": 33.27714551776234, "chrf_score": 76.55684922678351, "xcomet_score": 0.965651273727417, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 6.085655212402344, "metricx_qe_score": 6.133429527282715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous ne considérons que des opérateurs de base tels que l'addition, la soustraction, la multiplication, la division et l'exponentiel.", "metrics": {"bleu_score": 80.40514736345938, "chrf_score": 94.86365438103559, "xcomet_score": 0.965031623840332, "xcomet_qe_score": 0.9775030016899109, "metricx_score": 0.6933842301368713, "metricx_qe_score": 0.6506344079971313, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "fr", "output": "En outre, les opérateurs compliqués peuvent être décomposés en ces opérateurs de base.", "metrics": {"bleu_score": 81.96501312471537, "chrf_score": 86.66911742239392, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.8321952819824219, "metricx_qe_score": 0.7586758732795715, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "fr", "output": "Donc le travail précédent dans la résolution de problèmes mathématiques peut être catégorisé en séquence à séquence et séquence à modèle d'arbre.", "metrics": {"bleu_score": 33.182524073076834, "chrf_score": 65.42506080267546, "xcomet_score": 0.6545127630233765, "xcomet_qe_score": 0.6117199659347534, "metricx_score": 6.105288028717041, "metricx_qe_score": 5.6130828857421875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "fr", "output": "Donc le modèle traditionnel de séquence à séquence convertit l'expression en une séquence spécifique pour une génération.", "metrics": {"bleu_score": 38.8905561152711, "chrf_score": 83.2453404571256, "xcomet_score": 0.7645593881607056, "xcomet_qe_score": 0.6384366154670715, "metricx_score": 1.9879910945892334, "metricx_qe_score": 2.6593008041381836, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est assez facile à mettre en œuvre, et il peut généraliser à de nombreux problèmes compliqués.", "metrics": {"bleu_score": 46.661736281950525, "chrf_score": 72.13417213128153, "xcomet_score": 0.7612453699111938, "xcomet_qe_score": 0.7853735685348511, "metricx_score": 5.488824844360352, "metricx_qe_score": 4.905898094177246, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les inconvénients de la performance ne sont généralement pas meilleurs que le modèle structurel, et il s'agit d'un manque d'interprétabilité pour la prédiction.", "metrics": {"bleu_score": 13.292032579101747, "chrf_score": 74.41103735566625, "xcomet_score": 0.5513693690299988, "xcomet_qe_score": 0.6803032755851746, "metricx_score": 11.066855430603027, "metricx_qe_score": 10.5133056640625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette direction est toujours très populaire à cause du modèle Transformers.", "metrics": {"bleu_score": 13.229996644640526, "chrf_score": 48.2144455161798, "xcomet_score": 0.8688271045684814, "xcomet_qe_score": 0.9725357294082642, "metricx_score": 5.708308696746826, "metricx_qe_score": 3.5476231575012207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "fr", "output": "Donc dans les modèles à base d'arbres, nous structurons ces expressions dans une forme d'arbre et suivons un préordre traversal dans trois générations.", "metrics": {"bleu_score": 29.267447336153182, "chrf_score": 68.87920975834919, "xcomet_score": 0.73345947265625, "xcomet_qe_score": 0.6900839805603027, "metricx_score": 6.226367950439453, "metricx_qe_score": 5.527392864227295, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ici, nous continuons à générer les opérateurs jusqu'à ce que nous atteignions les feuilles qui sont les quantités.", "metrics": {"bleu_score": 74.08842640893447, "chrf_score": 87.00275650077015, "xcomet_score": 0.8770772218704224, "xcomet_qe_score": 0.857928991317749, "metricx_score": 3.0197906494140625, "metricx_qe_score": 4.009443283081055, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "fr", "output": "Donc le bon côté, c'est qu'il nous donne cette structure binaire d'arbre, et c'est qu'on génère les opérateurs d'abord, et ensuite on génère les quantités.", "metrics": {"bleu_score": 9.761900205844166, "chrf_score": 44.95627916432031, "xcomet_score": 0.712260365486145, "xcomet_qe_score": 0.6775078773498535, "metricx_score": 11.12304973602295, "metricx_qe_score": 12.825818061828613, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "fr", "output": "Et la seconde chose, c'est qu'il contient aussi des calculs répétitifs.", "metrics": {"bleu_score": 24.71244254525359, "chrf_score": 53.594893374531004, "xcomet_score": 0.9303665161132812, "xcomet_qe_score": 0.9812315702438354, "metricx_score": 1.7570395469665527, "metricx_qe_score": 1.2043919563293457, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ici, si nous regardons cette expression, 8 fois 3 plus 3 est réellement généré deux fois, mais en fait, nous devrions utiliser les résultats", "metrics": {"bleu_score": 49.21487095847661, "chrf_score": 71.89249282221299, "xcomet_score": 0.9644340872764587, "xcomet_qe_score": 0.9697661995887756, "metricx_score": 2.2738304138183594, "metricx_qe_score": 1.87095308303833, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre approche proposée, nous voulons résoudre ces problèmes pas à pas et de manière interprétable.", "metrics": {"bleu_score": 58.527733690258756, "chrf_score": 80.06207837019652, "xcomet_score": 0.999382734298706, "xcomet_qe_score": 1.0, "metricx_score": 1.0168461799621582, "metricx_qe_score": 0.7606877088546753, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, par exemple, ici, dans la deuxième étape, on peut obtenir ces diviseurs, qui sont 27.", "metrics": {"bleu_score": 29.10624919304027, "chrf_score": 64.69075913190827, "xcomet_score": 0.9955950975418091, "xcomet_qe_score": 0.9776954650878906, "metricx_score": 2.5313475131988525, "metricx_qe_score": 4.46058464050293, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "fr", "output": "On peut aussi revenir aux questions originales pour trouver le contenu pertinent.", "metrics": {"bleu_score": 55.552241883290684, "chrf_score": 66.9681851821312, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7598135471343994, "metricx_qe_score": 0.937008261680603, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "fr", "output": "Et dans ces étapes, nous allons atteindre les divisors.", "metrics": {"bleu_score": 49.616830003403614, "chrf_score": 65.27192865902174, "xcomet_score": 0.7727739810943604, "xcomet_qe_score": 0.8408507108688354, "metricx_score": 7.6141486167907715, "metricx_qe_score": 7.3232927322387695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, et puis à cette troisième étape, on obtient en fait le quotient", "metrics": {"bleu_score": 29.256127307315065, "chrf_score": 57.45411839755974, "xcomet_score": 0.9578676223754883, "xcomet_qe_score": 0.9637236595153809, "metricx_score": 4.054070949554443, "metricx_qe_score": 4.195234775543213, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "fr", "output": "Après ces trois étapes, nous pouvons utiliser les résultats de la deuxième étape, puis obtenir les résultats de la quatrième étape, et finalement obtenir les dividendes.", "metrics": {"bleu_score": 59.83352337011315, "chrf_score": 79.1106662551473, "xcomet_score": 0.9592829942703247, "xcomet_qe_score": 0.9124264717102051, "metricx_score": 2.814749240875244, "metricx_qe_score": 3.595898151397705, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ici, nous générons l'expression entière directement, plutôt que de générer des opérateurs ou des quantités.", "metrics": {"bleu_score": 27.767499285849123, "chrf_score": 63.99323052907224, "xcomet_score": 0.9593731164932251, "xcomet_qe_score": 0.9935325384140015, "metricx_score": 1.5194954872131348, "metricx_qe_score": 1.970656156539917, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ça rend le processus plus précis.", "metrics": {"bleu_score": 68.037493331712, "chrf_score": 87.76792293037043, "xcomet_score": 0.9926266670227051, "xcomet_qe_score": 0.9873424768447876, "metricx_score": 1.1323952674865723, "metricx_qe_score": 1.2863491773605347, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre système de déduction, nous commençons par un groupe de quantités présentées dans les questions, et incluons aussi des constantes comme initialismes.", "metrics": {"bleu_score": 24.247559192786618, "chrf_score": 59.34089954036658, "xcomet_score": 0.8475280404090881, "xcomet_qe_score": 0.8403099179267883, "metricx_score": 6.1832990646362305, "metricx_qe_score": 6.662559986114502, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "fr", "output": "Donc l'expression est représentée par EIJOP.", "metrics": {"bleu_score": 21.28139770959968, "chrf_score": 70.7240109403783, "xcomet_score": 0.9711586236953735, "xcomet_qe_score": 0.9702193140983582, "metricx_score": 1.2167434692382812, "metricx_qe_score": 1.881912350654602, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "fr", "output": "où nous performons des opérateurs de QI à QJ, et telle expression est en fait dirigée.", "metrics": {"bleu_score": 27.278200342554264, "chrf_score": 56.60870010999341, "xcomet_score": 0.8168821334838867, "xcomet_qe_score": 0.7444553375244141, "metricx_score": 8.214397430419922, "metricx_qe_score": 9.926854133605957, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "fr", "output": "Donc nous avons aussi la soustraction avec des mots ici pour représenter la direction opposée.", "metrics": {"bleu_score": 55.31281525513731, "chrf_score": 78.56989423263691, "xcomet_score": 0.9877818822860718, "xcomet_qe_score": 0.9777818918228149, "metricx_score": 1.3072084188461304, "metricx_qe_score": 1.6995055675506592, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "fr", "output": "C'est assez similaire à l'extraction rodéienne.", "metrics": {"bleu_score": 18.094495256969623, "chrf_score": 53.60483720344797, "xcomet_score": 0.6634246110916138, "xcomet_qe_score": 0.7379815578460693, "metricx_score": 6.505260467529297, "metricx_qe_score": 7.819778919219971, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "fr", "output": "Donc dans un système déductif formel, à la étape T, on applique l'opérateur entre le QI et le QJP, et on obtient cette nouvelle expression.", "metrics": {"bleu_score": 39.280900563491315, "chrf_score": 70.88137631531485, "xcomet_score": 0.7348953485488892, "xcomet_qe_score": 0.8205733299255371, "metricx_score": 6.626747131347656, "metricx_qe_score": 5.905506134033203, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "fr", "output": "Nous l'ajoutons aux États suivants pour devenir une nouvelle quantité.", "metrics": {"bleu_score": 51.93071778680675, "chrf_score": 80.58142021528664, "xcomet_score": 0.8990134000778198, "xcomet_qe_score": 0.9170875549316406, "metricx_score": 2.496669054031372, "metricx_qe_score": 3.470491886138916, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "fr", "output": "Donc cette lumière visualise l'évolution des états, où nous continuons à ajouter de l'expression aux états actuels.", "metrics": {"bleu_score": 30.334116500029243, "chrf_score": 59.04103978600437, "xcomet_score": 0.7155804634094238, "xcomet_qe_score": 0.5706288814544678, "metricx_score": 15.333821296691895, "metricx_qe_score": 14.91637134552002, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "fr", "output": "Dans nos implémentations de modèles, nous utilisons d'abord un modèle de langage prétraité qui peut être des mots ou des verbs, puis nous encodons la phrase, et puis nous obtenons ces représentations quantitatives.", "metrics": {"bleu_score": 37.70363455929218, "chrf_score": 70.57866987624409, "xcomet_score": 0.6298249959945679, "xcomet_qe_score": 0.6969705820083618, "metricx_score": 7.717527866363525, "metricx_qe_score": 8.025861740112305, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "fr", "output": "Donc une fois que nous avons les représentations quantitatives, nous pouvons commencer à faire des inférences.", "metrics": {"bleu_score": 42.61228357037425, "chrf_score": 74.13177608172953, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.3944151401519775, "metricx_qe_score": 1.603595495223999, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, nous montrons un exemple de Q1 pour obtenir la représentation de Q1 divisé par Q2 et puis par Q4", "metrics": {"bleu_score": 12.880690301716463, "chrf_score": 56.02162502887656, "xcomet_score": 0.6185459494590759, "xcomet_qe_score": 0.6839399337768555, "metricx_score": 16.083824157714844, "metricx_qe_score": 9.206893920898438, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "fr", "output": "D'abord, nous obtenons la représentation de paire, qui est essentiellement juste la concaténation entre Q1 et Q2, et puis nous appliquons un réseau feed-forward qui est paramétré par l'opérateur.", "metrics": {"bleu_score": 45.92267605076169, "chrf_score": 71.94136196956208, "xcomet_score": 0.7368147969245911, "xcomet_qe_score": 0.7006111741065979, "metricx_score": 5.257083892822266, "metricx_qe_score": 5.391579627990723, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "fr", "output": "Et puis, finalement, on obtient la représentation d'expression Q1 divisé par Q2", "metrics": {"bleu_score": 5.366912772746423, "chrf_score": 51.564859561680706, "xcomet_score": 0.9153751730918884, "xcomet_qe_score": 0.8848987221717834, "metricx_score": 4.400391578674316, "metricx_qe_score": 4.5242204666137695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "fr", "output": "Mais en pratique, à l'infanterie, on pourrait aussi avoir des expressions incorrectes.", "metrics": {"bleu_score": 5.5140290363691244, "chrf_score": 38.650774645056444, "xcomet_score": 0.5141296982765198, "xcomet_qe_score": 0.5184667110443115, "metricx_score": 13.013312339782715, "metricx_qe_score": 14.837699890136719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ici, toutes les expressions possibles sont égales à trois fois le nombre d'opérateurs.", "metrics": {"bleu_score": 45.788313721339826, "chrf_score": 79.16845981023401, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.754374086856842, "metricx_qe_score": 1.4526339769363403, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "fr", "output": "Donc la bonne chose ici, c'est que nous pouvons facilement ajouter des contraintes pour contrôler ces recherches.", "metrics": {"bleu_score": 49.410069749619, "chrf_score": 74.14592932939004, "xcomet_score": 0.8460292816162109, "xcomet_qe_score": 0.8379274010658264, "metricx_score": 2.4927000999450684, "metricx_qe_score": 3.1240291595458984, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, si cette expression n'est pas autorisée, nous pouvons simplement enlever cette expression dans notre espace de recherche.", "metrics": {"bleu_score": 87.25129388059685, "chrf_score": 92.07006688274785, "xcomet_score": 0.9862370491027832, "xcomet_qe_score": 0.9909194707870483, "metricx_score": 0.4657979905605316, "metricx_qe_score": 0.4877927899360657, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "fr", "output": "Donc dans la deuxième étape, on fait la même chose, mais la seule différence, c'est qu'on a une quantité de plus.", "metrics": {"bleu_score": 54.914752612160676, "chrf_score": 71.47118097718253, "xcomet_score": 0.9719721078872681, "xcomet_qe_score": 0.9382966756820679, "metricx_score": 3.6465256214141846, "metricx_qe_score": 4.534778118133545, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "fr", "output": "Cette quantité vient de la précédente expression calculée.", "metrics": {"bleu_score": 11.99014838091355, "chrf_score": 59.9158638933175, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.714428722858429, "metricx_qe_score": 1.3007758855819702, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, finalement, on peut obtenir cette dernière expression", "metrics": {"bleu_score": 4.955970694341068, "chrf_score": 44.30252606012445, "xcomet_score": 0.4945780038833618, "xcomet_qe_score": 0.7942623496055603, "metricx_score": 6.815099239349365, "metricx_qe_score": 13.343912124633789, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "fr", "output": "et on peut aussi voir que le nombre de toutes les expressions possibles est différent de la précédente", "metrics": {"bleu_score": 59.99201813792485, "chrf_score": 67.23681147584972, "xcomet_score": 0.851224422454834, "xcomet_qe_score": 0.8396446704864502, "metricx_score": 4.406057357788086, "metricx_qe_score": 5.334022521972656, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ces différences rendent la recherche de faisceau difficile car la distribution de probabilité entre ces deux étapes est déséquilibrée.", "metrics": {"bleu_score": 49.15533898804662, "chrf_score": 67.09166232903307, "xcomet_score": 0.9096834063529968, "xcomet_qe_score": 0.9477817416191101, "metricx_score": 3.397360324859619, "metricx_qe_score": 2.9229090213775635, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "fr", "output": "Donc la procédure de formation est similaire à la formation d'un modèle séquence à séquence, où nous optimisons les lois à chaque étape.", "metrics": {"bleu_score": 48.43025957347058, "chrf_score": 77.62158308837192, "xcomet_score": 0.626979649066925, "xcomet_qe_score": 0.5379449725151062, "metricx_score": 7.566248416900635, "metricx_qe_score": 9.321054458618164, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous utilisons aussi ce \"tow\" pour représenter quand nous devrions terminer ce processus de génération.", "metrics": {"bleu_score": 36.173905261890994, "chrf_score": 63.18575096109056, "xcomet_score": 0.8448920249938965, "xcomet_qe_score": 0.7901071310043335, "metricx_score": 6.22773551940918, "metricx_qe_score": 6.540439128875732, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, l'espace est différent de séquence en séquence, parce que l'espace est différent à chaque étape, alors que dans le modèle traditionnel de séquence en séquence, c'est le nombre de vocabulaire.", "metrics": {"bleu_score": 54.44028739655124, "chrf_score": 79.13294424050723, "xcomet_score": 0.48653435707092285, "xcomet_qe_score": 0.5217072367668152, "metricx_score": 7.68778133392334, "metricx_qe_score": 8.238231658935547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "fr", "output": "Et il nous permet aussi d'imposer certaines contraintes, de savoir.", "metrics": {"bleu_score": 15.090679227647147, "chrf_score": 47.79931142239138, "xcomet_score": 0.7329928874969482, "xcomet_qe_score": 0.7383529543876648, "metricx_score": 9.440913200378418, "metricx_qe_score": 9.79379940032959, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "fr", "output": "Donc nous avons fait des expériences sur les problèmes mathématiques les plus couramment utilisés, comme le MSWPS, le Math23k, le MathQA et le Swamp.", "metrics": {"bleu_score": 12.06145072081554, "chrf_score": 56.74022409916116, "xcomet_score": 0.5396143794059753, "xcomet_qe_score": 0.6973313689231873, "metricx_score": 6.706172466278076, "metricx_qe_score": 6.331580638885498, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous avons brièvement montré les résultats comparés aux meilleures approches précédentes.", "metrics": {"bleu_score": 51.497322032579355, "chrf_score": 77.59822996408666, "xcomet_score": 0.8328937292098999, "xcomet_qe_score": 0.7502976655960083, "metricx_score": 0.9541527628898621, "metricx_qe_score": 1.2504668235778809, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "fr", "output": "Donc notre meilleur joueur est Robert de la raison détective.", "metrics": {"bleu_score": 5.604233375480572, "chrf_score": 30.821206705100234, "xcomet_score": 0.4233444333076477, "xcomet_qe_score": 0.4875735342502594, "metricx_score": 16.2777042388916, "metricx_qe_score": 14.927801132202148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "fr", "output": "Et en fait, nous n'utilisons pas BeamSearch, contrairement aux approches évidentes qui utilisent BeamSearch.", "metrics": {"bleu_score": 13.592365419892024, "chrf_score": 48.40636454758351, "xcomet_score": 0.692479133605957, "xcomet_qe_score": 0.6510078310966492, "metricx_score": 5.454544544219971, "metricx_qe_score": 4.1406121253967285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "fr", "output": "Donc les meilleures approches sont souvent des modèles basés sur des arbres.", "metrics": {"bleu_score": 24.029210317584685, "chrf_score": 59.318576247536015, "xcomet_score": 0.9643086194992065, "xcomet_qe_score": 0.9826924204826355, "metricx_score": 1.556418776512146, "metricx_qe_score": 1.4363231658935547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, au total, notre raisonnement est capable de surperformer de manière significative ce modèle à trois bases.", "metrics": {"bleu_score": 15.435109972796836, "chrf_score": 53.44968708556254, "xcomet_score": 0.635427713394165, "xcomet_qe_score": 0.904705286026001, "metricx_score": 8.165082931518555, "metricx_qe_score": 6.936291217803955, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "fr", "output": "mais on peut voir que les nombres absolus sur MathQA ou Swamp ne sont pas vraiment élevés.", "metrics": {"bleu_score": 65.40585844910977, "chrf_score": 75.14696778431981, "xcomet_score": 0.8861466646194458, "xcomet_qe_score": 0.8498392105102539, "metricx_score": 2.8145651817321777, "metricx_qe_score": 4.764675617218018, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "fr", "output": "Donc nous avons enquêté plus en détail sur les résultats.", "metrics": {"bleu_score": 19.081654556856684, "chrf_score": 50.498311121803816, "xcomet_score": 0.4927971661090851, "xcomet_qe_score": 0.5516254901885986, "metricx_score": 2.1554880142211914, "metricx_qe_score": 4.433391094207764, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "fr", "output": "Et ce jeu de données est difficile parce que l'auteur a essayé d'ajouter manuellement quelque chose pour confondre le modèle NLB, comme l'ajout d'informations environnementales et de quantités supplémentaires.", "metrics": {"bleu_score": 40.36798550528491, "chrf_score": 66.45154042190192, "xcomet_score": 0.5974127650260925, "xcomet_qe_score": 0.5140644311904907, "metricx_score": 5.947944164276123, "metricx_qe_score": 5.902792453765869, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "fr", "output": "Donc dans notre prédiction, nous trouvons que certaines des valeurs intermédiaires sont en fait négatives.", "metrics": {"bleu_score": 59.79628578936394, "chrf_score": 81.68470253421336, "xcomet_score": 0.9896867275238037, "xcomet_qe_score": 1.0, "metricx_score": 1.5058561563491821, "metricx_qe_score": 0.938815176486969, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans ces questions, on demande combien de pommes a Jake.", "metrics": {"bleu_score": 56.6713706600882, "chrf_score": 77.73597043737574, "xcomet_score": 0.951998233795166, "xcomet_qe_score": 0.9359656572341919, "metricx_score": 1.8791005611419678, "metricx_qe_score": 2.3399875164031982, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "fr", "output": "Mais nous avons des informations supplémentaires, comme dix-sept pitches de terrain et Steven a huit pitches, ce qui est totalement irrelevant.", "metrics": {"bleu_score": 31.699734601562977, "chrf_score": 65.15336764562704, "xcomet_score": 0.44184523820877075, "xcomet_qe_score": 0.3084288537502289, "metricx_score": 13.432622909545898, "metricx_qe_score": 13.547658920288086, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "fr", "output": "Donc notre modèle fait des prédictions comme celles-ci, qui produisent des valeurs négatives.", "metrics": {"bleu_score": 21.651956746181064, "chrf_score": 61.63114185515918, "xcomet_score": 0.9880633354187012, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.7471632957458496, "metricx_qe_score": 1.2685037851333618, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous avons observé ces deux expressions", "metrics": {"bleu_score": 11.308396107326717, "chrf_score": 35.6353996453962, "xcomet_score": 0.16909030079841614, "xcomet_qe_score": 0.21421709656715393, "metricx_score": 16.429290771484375, "metricx_qe_score": 16.993135452270508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, nous pouvons limiter cet espace de recherche en supprimant les résultats négatifs, pour que nous puissions faire la réponse correcte.", "metrics": {"bleu_score": 54.30321466633389, "chrf_score": 83.17549293344587, "xcomet_score": 0.8420374393463135, "xcomet_qe_score": 0.7211313247680664, "metricx_score": 3.395582675933838, "metricx_qe_score": 4.670919895172119, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, on trouve que ces contraintes améliorent beaucoup la vie de certains modèles.", "metrics": {"bleu_score": 11.114924776032012, "chrf_score": 53.65450008829497, "xcomet_score": 0.8609706163406372, "xcomet_qe_score": 0.8174488544464111, "metricx_score": 4.7490692138671875, "metricx_qe_score": 5.171039581298828, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, pour les birds, on améliore de 7 points, et pour le robot de base, on améliore de 2 points.", "metrics": {"bleu_score": 17.07675677929755, "chrf_score": 32.1877040482474, "xcomet_score": 0.3979351222515106, "xcomet_qe_score": 0.4320827126502991, "metricx_score": 13.132490158081055, "metricx_qe_score": 12.524247169494629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "fr", "output": "Donc un meilleur modèle linguistique a une meilleure capacité de compréhension linguistique, donc le nombre ici est plus élevé pour les robots et plus bas pour les robots.", "metrics": {"bleu_score": 26.606969666286776, "chrf_score": 47.00160204401657, "xcomet_score": 0.5296825170516968, "xcomet_qe_score": 0.6211169958114624, "metricx_score": 15.47957706451416, "metricx_qe_score": 12.833636283874512, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous allons aussi essayer d'analyser la difficulté derrière ce #ahB.", "metrics": {"bleu_score": 23.90108882452814, "chrf_score": 54.997390171340534, "xcomet_score": 0.5811307430267334, "xcomet_qe_score": 0.5708444118499756, "metricx_score": 10.125222206115723, "metricx_qe_score": 14.346864700317383, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "fr", "output": "Nous supposons que le nombre de quantités inutilisées peut être considéré comme une information irrelevant ici.", "metrics": {"bleu_score": 67.89753693372478, "chrf_score": 82.80511048562921, "xcomet_score": 0.9195683002471924, "xcomet_qe_score": 0.9239628911018372, "metricx_score": 5.656264781951904, "metricx_qe_score": 8.528566360473633, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, on peut voir que nous avons le pourcentage d'échantillons avec des quantités inutilisées et que le jeu de données des marais a la plus grande part.", "metrics": {"bleu_score": 41.23855261385295, "chrf_score": 72.77058191600008, "xcomet_score": 0.7090033888816833, "xcomet_qe_score": 0.670000433921814, "metricx_score": 8.546396255493164, "metricx_qe_score": 8.85016918182373, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "fr", "output": "Et ici, nous montrons aussi la performance globale.", "metrics": {"bleu_score": 65.80370064762461, "chrf_score": 76.23452488248672, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7257865071296692, "metricx_qe_score": 1.0054198503494263, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ces samples sans qualités d'utilisation, l'efficacité générale est donc plus élevée que l'efficacité générale.", "metrics": {"bleu_score": 5.675727444525874, "chrf_score": 30.398258783641886, "xcomet_score": 0.17069295048713684, "xcomet_qe_score": 0.14353327453136444, "metricx_score": 14.467000961303711, "metricx_qe_score": 15.699613571166992, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "fr", "output": "mais avec ces échantillons qui, avec une qualité inutilisée, est en fait bien pire que le...", "metrics": {"bleu_score": 26.153117750218023, "chrf_score": 62.820166922621446, "xcomet_score": 0.3288290500640869, "xcomet_qe_score": 0.2601207196712494, "metricx_score": 15.439984321594238, "metricx_qe_score": 15.975982666015625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "fr", "output": "Pour M.W.P.S. nous n'avons pas vraiment combien de cas j'ai donc je peux juste dire ce que c'est.", "metrics": {"bleu_score": 11.556647985416689, "chrf_score": 40.10704577599864, "xcomet_score": 0.3306390643119812, "xcomet_qe_score": 0.297410249710083, "metricx_score": 15.019645690917969, "metricx_qe_score": 15.643025398254395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, enfin, nous voulons montrer l'interprétabilité à travers un exemple de participation de crash.", "metrics": {"bleu_score": 37.709297891717654, "chrf_score": 65.2209514182914, "xcomet_score": 0.30216723680496216, "xcomet_qe_score": 0.3757414221763611, "metricx_score": 9.329378128051758, "metricx_qe_score": 11.130970001220703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "fr", "output": "Donc ici, notre modèle fait une fausse prédiction à la première étape.", "metrics": {"bleu_score": 47.20305201905447, "chrf_score": 54.57388405095538, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9606519341468811, "metricx_qe_score": 0.8988900184631348, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "fr", "output": "Donc on peut corréler cette expression avec la phrase ici,", "metrics": {"bleu_score": 37.452423894596954, "chrf_score": 54.885694158270006, "xcomet_score": 0.8455051183700562, "xcomet_qe_score": 0.8876749277114868, "metricx_score": 5.862261772155762, "metricx_qe_score": 3.3512895107269287, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "fr", "output": "Donc nous pensons que ces indicateurs pourraient induire le modèle en erreur.", "metrics": {"bleu_score": 23.909302951697416, "chrf_score": 49.68568079175912, "xcomet_score": 0.7554556131362915, "xcomet_qe_score": 0.5099689960479736, "metricx_score": 5.241944313049316, "metricx_qe_score": 4.333081245422363, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, ici, planter un autre 35 fait que le modèle pense qu'il devrait être un opérateur d'addition.", "metrics": {"bleu_score": 35.37053193768171, "chrf_score": 63.77805306098172, "xcomet_score": 0.7253086566925049, "xcomet_qe_score": 0.5808181166648865, "metricx_score": 5.431325912475586, "metricx_qe_score": 6.252884864807129, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "fr", "output": "Alors nous avons essayé de réviser la phrase pour qu'elle soit quelque chose comme le nombre de poires est de 35 moins que le nombre d'apples.", "metrics": {"bleu_score": 26.008583326188383, "chrf_score": 52.83494702642086, "xcomet_score": 0.6910678148269653, "xcomet_qe_score": 0.794809877872467, "metricx_score": 13.751099586486816, "metricx_qe_score": 11.912055969238281, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, nous le faisons pour que la sémantique soit plus précise, de sorte que le modèle soit capable de faire la prédiction correcte.", "metrics": {"bleu_score": 24.343304284910328, "chrf_score": 58.679277928707805, "xcomet_score": 0.8655596971511841, "xcomet_qe_score": 0.8651484847068787, "metricx_score": 3.188560724258423, "metricx_qe_score": 2.3911285400390625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "fr", "output": "Cette étude montre comment les prédictions interprétables nous aident à comprendre le comportement de la mère.", "metrics": {"bleu_score": 47.82215756494833, "chrf_score": 81.7992146063065, "xcomet_score": 0.4061467945575714, "xcomet_qe_score": 0.468212753534317, "metricx_score": 7.70552921295166, "metricx_qe_score": 7.527606010437012, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "fr", "output": "Donc pour conclure notre travail, notre modèle est en fait assez efficace.", "metrics": {"bleu_score": 66.46817937381975, "chrf_score": 81.97328150940378, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.324360966682434, "metricx_qe_score": 1.4632874727249146, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "fr", "output": "et nous sommes en mesure de fournir une procédure de solvabilité interprétable.", "metrics": {"bleu_score": 70.16035864257111, "chrf_score": 80.98806287376107, "xcomet_score": 0.8088419437408447, "xcomet_qe_score": 0.8857635259628296, "metricx_score": 6.162261009216309, "metricx_qe_score": 5.452755928039551, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous pouvons facilement incorporer des connaissances préalables comme contraintes qui peuvent aider à améliorer la performance.", "metrics": {"bleu_score": 69.6015973294402, "chrf_score": 83.21524170647496, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.9963873624801636, "metricx_qe_score": 1.2755464315414429, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "fr", "output": "Et la dernière chose, c'est que le mécanisme sous-jacent ne s'applique pas seulement aux tâches de résolution de problèmes de réseau, mais aussi à d'autres tâches qui impliquent le raisonnement multi-étapes.", "metrics": {"bleu_score": 56.76006714726631, "chrf_score": 84.46121479165272, "xcomet_score": 0.9979660511016846, "xcomet_qe_score": 1.0, "metricx_score": 0.8748214840888977, "metricx_qe_score": 0.9909663796424866, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous avons aussi certaines limitations.", "metrics": {"bleu_score": 8.643019616048525, "chrf_score": 53.930010648795346, "xcomet_score": 0.9846639037132263, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.30755379796028137, "metricx_qe_score": 0.16676509380340576, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "fr", "output": "Si nous avons un grand nombre d'opérateurs ou de constantes, la consommation de mémoire pourrait être assez élevée.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0386240482330322, "metricx_qe_score": 1.0148998498916626, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "fr", "output": "Et la deuxième chose, comme je l'ai dit, c'est que la distribution de probabilités est déséquilibrée à différents stades, donc c'est aussi un défi pour les chercheurs.", "metrics": {"bleu_score": 12.150672435722083, "chrf_score": 46.409671136524686, "xcomet_score": 0.8398729562759399, "xcomet_qe_score": 0.8540285229682922, "metricx_score": 3.8053982257843018, "metricx_qe_score": 5.616521835327148, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "fr", "output": "Donc c'est la fin de la discussion et les questions sont les bienvenues.", "metrics": {"bleu_score": 38.098420997397426, "chrf_score": 63.14179666219653, "xcomet_score": 0.9734100103378296, "xcomet_qe_score": 0.9376817941665649, "metricx_score": 2.66318941116333, "metricx_qe_score": 3.0031473636627197, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "fr", "output": "Je m'appelle Antoine et je viens de l'université de Maastricht.", "metrics": {"bleu_score": 29.251718341295526, "chrf_score": 71.56204961542319, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 3.177481174468994, "metricx_qe_score": 1.759749412536621, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter mon travail de John avec Jerry, qui est sur un nouveau jeu de données pour la récupération d'articles statutaires.", "metrics": {"bleu_score": 18.747025716022478, "chrf_score": 54.099236276773745, "xcomet_score": 0.3630802035331726, "xcomet_qe_score": 0.3309933543205261, "metricx_score": 10.294926643371582, "metricx_qe_score": 8.676709175109863, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "fr", "output": "Les questions juridiques font partie intégrante de la vie de beaucoup de gens.", "metrics": {"bleu_score": 69.30977286178778, "chrf_score": 74.6979024242017, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.4181632101535797, "metricx_qe_score": 0.4647359251976013, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la majorité des citoyens ont peu ou pas de connaissances sur leurs droits et leurs processus juridiques fondamentaux.", "metrics": {"bleu_score": 80.3154665668484, "chrf_score": 96.3784686352963, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0468275547027588, "metricx_qe_score": 1.8563034534454346, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "fr", "output": "En conséquence, de nombreux citoyens vulnérables qui ne peuvent pas se permettre l'assistance coûteuse d'un expert juridique sont laissés non protégés ou, pire, exploités.", "metrics": {"bleu_score": 46.00585798331265, "chrf_score": 70.7331230958988, "xcomet_score": 0.9758676290512085, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.846705675125122, "metricx_qe_score": 3.376739263534546, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "fr", "output": "Notre travail vise à combler l'écart entre les gens et la loi en développant un système de récupération efficace des articles statutaires.", "metrics": {"bleu_score": 28.612496481907357, "chrf_score": 55.985901401882344, "xcomet_score": 0.8166647553443909, "xcomet_qe_score": 0.8402795791625977, "metricx_score": 5.125396251678467, "metricx_qe_score": 4.387754440307617, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "fr", "output": "Un tel système pourrait fournir un service professionnel gratuit d'aide juridique pour les humains non qualifiés.", "metrics": {"bleu_score": 43.68363644461544, "chrf_score": 80.63806594071967, "xcomet_score": 0.9381486177444458, "xcomet_qe_score": 0.9533690810203552, "metricx_score": 1.4454071521759033, "metricx_qe_score": 1.188032627105713, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "fr", "output": "Avant de plonger dans la contribution principale de ce travail, décrivons d'abord le problème de la récupération d'articles statutaires.", "metrics": {"bleu_score": 30.91327937802876, "chrf_score": 64.2390172620644, "xcomet_score": 0.8134631514549255, "xcomet_qe_score": 0.7815635204315186, "metricx_score": 5.66942024230957, "metricx_qe_score": 4.398686408996582, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "fr", "output": "Donnée une simple question sur une petite question telle que qu'est ce que je risque si je viole la confidentialité professionnelle", "metrics": {"bleu_score": 44.526528518549355, "chrf_score": 74.37865425139556, "xcomet_score": 0.6459686160087585, "xcomet_qe_score": 0.5474504232406616, "metricx_score": 8.31065559387207, "metricx_qe_score": 10.707566261291504, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "fr", "output": "Un modèle est nécessaire pour récupérer tous les articles statutaires pertinents d'un grand corps de législation.", "metrics": {"bleu_score": 36.73341329152364, "chrf_score": 73.38524714978351, "xcomet_score": 0.9133631587028503, "xcomet_qe_score": 0.9888594150543213, "metricx_score": 4.165149688720703, "metricx_qe_score": 3.22798228263855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "fr", "output": "Cette tâche d'obtention d'informations comporte son propre ensemble de défis.", "metrics": {"bleu_score": 57.66735394403278, "chrf_score": 81.55910769403252, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.0394158363342285, "metricx_qe_score": 1.1549333333969116, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, il traite de deux types de langages.", "metrics": {"bleu_score": 38.66252716278829, "chrf_score": 55.102006223259494, "xcomet_score": 0.8360258340835571, "xcomet_qe_score": 0.9907128810882568, "metricx_score": 2.0687739849090576, "metricx_qe_score": 1.0689460039138794, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "fr", "output": "langage naturel commun pour les questions et langage juridique complexe pour les statuts", "metrics": {"bleu_score": 30.706596465808243, "chrf_score": 68.90585276121199, "xcomet_score": 0.8476454615592957, "xcomet_qe_score": 0.8564560413360596, "metricx_score": 4.175654888153076, "metricx_qe_score": 3.1410443782806396, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "fr", "output": "cette différence dans les distributions linguistiques rend plus difficile pour un système de récupérer les candidats pertinents car il nécessite indirectement un système d'interprétation inhérent qui peut traduire une question naturelle en une question juridique qui correspond à la terminologie des statuts", "metrics": {"bleu_score": 60.87329679249157, "chrf_score": 83.77601425592648, "xcomet_score": 0.8309236764907837, "xcomet_qe_score": 0.8277102112770081, "metricx_score": 6.148683547973633, "metricx_qe_score": 5.901568412780762, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "fr", "output": "d'ailleurs le droit statutaire n'est pas une pile d'articles indépendants qui peuvent être traités comme une source complète d'information sur eux mêmes un peu comme les nouvelles ou les recettes par exemple", "metrics": {"bleu_score": 44.72776174208238, "chrf_score": 73.15105552093148, "xcomet_score": 0.8479483127593994, "xcomet_qe_score": 0.9099541306495667, "metricx_score": 7.66139554977417, "metricx_qe_score": 6.986767768859863, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "fr", "output": "En lieu de cela, c'est une collection structurée de dispositions légales qui n'ont un sens complet que si on les considère dans leur contexte général, c'est-à-dire avec l'information supplémentaire provenant des articles voisins, des champs et sous-champs auxquels ils appartiennent et leur place dans la structure de la loi.", "metrics": {"bleu_score": 36.995484389517145, "chrf_score": 64.2726143871495, "xcomet_score": 0.8109992146492004, "xcomet_qe_score": 0.9888467192649841, "metricx_score": 2.937061309814453, "metricx_qe_score": 2.0201356410980225, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, les articles statutaires ne sont pas de petits paragraphes, qui est généralement l'unité de récupération typique dans la plupart des travaux de récupération.", "metrics": {"bleu_score": 46.445316553607185, "chrf_score": 71.82325032823277, "xcomet_score": 0.4200364351272583, "xcomet_qe_score": 0.49479925632476807, "metricx_score": 7.906517028808594, "metricx_qe_score": 6.766088962554932, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "fr", "output": "ici, il y a de longs documents qui peuvent être jusqu'à", "metrics": {"bleu_score": 52.2535597476003, "chrf_score": 66.22742866424196, "xcomet_score": 0.2521668076515198, "xcomet_qe_score": 0.2682773470878601, "metricx_score": 16.367033004760742, "metricx_qe_score": 11.882194519042969, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "fr", "output": "Les progrès récents dans le domaine de la NLP ont suscité un énorme intérêt dans de nombreuses tâches juridiques, telles que la prédiction du jugement juridique ou la révision automatique des contrats.", "metrics": {"bleu_score": 30.51197694241533, "chrf_score": 56.176356267013105, "xcomet_score": 0.8013122081756592, "xcomet_qe_score": 0.9391218423843384, "metricx_score": 2.1679108142852783, "metricx_qe_score": 2.1984472274780273, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "fr", "output": "Mais la récupération d'articles statutaires est restée principalement intacte en raison du manque de ensembles de données étiquetés de grande et haute qualité.", "metrics": {"bleu_score": 23.546900700701926, "chrf_score": 60.847544927812436, "xcomet_score": 0.6469848155975342, "xcomet_qe_score": 0.7172689437866211, "metricx_score": 5.611791610717773, "metricx_qe_score": 4.957211017608643, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "fr", "output": "Dans ce travail, nous présentons un nouvel ensemble de données francophone et centré sur les citoyens pour étudier si le modèle de récupération peut approximer l'efficacité et la fiabilité d'un expert juridique pour la tâche de récupération d'articles statutaires.", "metrics": {"bleu_score": 33.960092349934946, "chrf_score": 63.342164267815946, "xcomet_score": 0.543797492980957, "xcomet_qe_score": 0.6082711219787598, "metricx_score": 7.128749847412109, "metricx_qe_score": 4.943228244781494, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "fr", "output": "ou l'article légal belge de récupération de données, qui se compose de plus de 1 100", "metrics": {"bleu_score": 7.42226469215118, "chrf_score": 29.95563033916799, "xcomet_score": 0.23030804097652435, "xcomet_qe_score": 0.15535283088684082, "metricx_score": 21.548969268798828, "metricx_qe_score": 22.631887435913086, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "fr", "output": "Ces questions couvrent un large éventail de sujets, de la famille, du logement, de l'argent au travail et à la sécurité sociale.", "metrics": {"bleu_score": 45.86402483839224, "chrf_score": 73.32584532930375, "xcomet_score": 0.9988237619400024, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 1.453884482383728, "metricx_qe_score": 0.790571391582489, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "fr", "output": "chacune d'elles a été étiquetée par des juristes expérimentés avec des références à des articles pertinents d'un corpus de plus de 22 600", "metrics": {"bleu_score": 50.41882776685546, "chrf_score": 65.08119059416735, "xcomet_score": 0.3025333881378174, "xcomet_qe_score": 0.27552539110183716, "metricx_score": 8.571463584899902, "metricx_qe_score": 8.038740158081055, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "fr", "output": "les codes belges de la loi. Parlons maintenant de la façon dont nous avons collecté ces", "metrics": {"bleu_score": 55.81600587827485, "chrf_score": 83.67127473677132, "xcomet_score": 0.24397873878479004, "xcomet_qe_score": 0.16520355641841888, "metricx_score": 15.5374174118042, "metricx_qe_score": 20.225862503051758, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "fr", "output": "D'abord, nous avons commencé par compiler un grand corpus d'articles juridiques.", "metrics": {"bleu_score": 84.46319809857219, "chrf_score": 94.05596522348701, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7939795851707458, "metricx_qe_score": 0.9563464522361755, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons examiné trente-deux codes belges publiquement disponibles et extrait tous leurs articles ainsi que les titres des sections correspondantes.", "metrics": {"bleu_score": 44.14550051593924, "chrf_score": 79.13663985963869, "xcomet_score": 0.9958093166351318, "xcomet_qe_score": 0.9793475866317749, "metricx_score": 2.392617702484131, "metricx_qe_score": 1.9277315139770508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, nous avons rassemblé des questions juridiques avec des références à des statuts pertinents.", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 77.9794611579874, "xcomet_score": 0.9787472486495972, "xcomet_qe_score": 1.0, "metricx_score": 3.440849781036377, "metricx_qe_score": 2.092256546020508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "fr", "output": "Pour ce faire, nous nous assouplions avec un cabinet d'avocats belge qui reçoit chaque année environ quatre mille e mails de citoyens belges qui demandent conseil sur une question personnelle ou juridique.", "metrics": {"bleu_score": 48.77631706376612, "chrf_score": 79.5162142223376, "xcomet_score": 0.7645459175109863, "xcomet_qe_score": 0.7589561939239502, "metricx_score": 8.003440856933594, "metricx_qe_score": 7.201401710510254, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons eu la chance d'accéder à leurs sites web où leur équipe de juristes expérimentés aborde les questions juridiques les plus courantes en Belgique.", "metrics": {"bleu_score": 65.69250405646801, "chrf_score": 84.08545699073767, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 2.3338379859924316, "metricx_qe_score": 1.865904450416565, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons recueilli des milliers de questions annotées avec des catégories, des sous-catégories et des références juridiques aux statuts pertinents.", "metrics": {"bleu_score": 86.41944207171434, "chrf_score": 93.30161739687497, "xcomet_score": 0.9886753559112549, "xcomet_qe_score": 1.0, "metricx_score": 3.0905537605285645, "metricx_qe_score": 1.5324335098266602, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "fr", "output": "enfin nous passâmes les références légales et filtrâmes les questions dont les références n'étaient pas articles dans l'un des codes de loi que nous considérâmes", "metrics": {"bleu_score": 37.42857202410802, "chrf_score": 66.04973263962712, "xcomet_score": 0.8333947658538818, "xcomet_qe_score": 0.8344558477401733, "metricx_score": 4.773468971252441, "metricx_qe_score": 7.218296051025391, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "fr", "output": "Les références restantes ont été assorties et converties aux articles correspondants des ID de O Corpus.", "metrics": {"bleu_score": 31.007120066002052, "chrf_score": 66.42379323957267, "xcomet_score": 0.690880298614502, "xcomet_qe_score": 0.7359601259231567, "metricx_score": 7.386655807495117, "metricx_qe_score": 8.046089172363281, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons finalement fini par poser 1 100 8 questions, chacune soigneusement étiquetée avec les idées des articles pertinents de", "metrics": {"bleu_score": 22.125630859854848, "chrf_score": 45.64183337475667, "xcomet_score": 0.23854157328605652, "xcomet_qe_score": 0.24662642180919647, "metricx_score": 19.121992111206055, "metricx_qe_score": 16.593486785888672, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "fr", "output": "En outre, chaque question comporte une catégorie principale et une concaténation de sous-catégories.", "metrics": {"bleu_score": 19.515485074742998, "chrf_score": 57.36437474916678, "xcomet_score": 0.9567291736602783, "xcomet_qe_score": 0.9686036109924316, "metricx_score": 5.14819860458374, "metricx_qe_score": 5.532846450805664, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "fr", "output": "Et chaque article est accompagné d'une concaténation de leurs sous-séquences dans la structure de la loi.", "metrics": {"bleu_score": 41.345637683545284, "chrf_score": 59.060039987729276, "xcomet_score": 0.902479887008667, "xcomet_qe_score": 0.8413218259811401, "metricx_score": 7.471438884735107, "metricx_qe_score": 7.272342681884766, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "fr", "output": "Cette information supplémentaire n'est pas utilisée dans le travail actuel, mais pourrait être d'intérêt pour la recherche future sur l'obtention d'informations juridiques ou la classification du texte juridique.", "metrics": {"bleu_score": 15.564830894799535, "chrf_score": 66.35672409017211, "xcomet_score": 0.9655594825744629, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 2.2751290798187256, "metricx_qe_score": 2.370640754699707, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "fr", "output": "Regardons quelques caractéristiques de tous ces ensembles de données.", "metrics": {"bleu_score": 10.738977135035864, "chrf_score": 49.71205704048901, "xcomet_score": 0.616628885269165, "xcomet_qe_score": 0.8459908962249756, "metricx_score": 3.503871202468872, "metricx_qe_score": 3.2283363342285156, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "fr", "output": "Les questionnaires sont de cinq à quarante-quatre mots longs, avec une moyenne de quarante mots.", "metrics": {"bleu_score": 20.455163269401236, "chrf_score": 63.2428187143738, "xcomet_score": 0.8646245002746582, "xcomet_qe_score": 0.9489155411720276, "metricx_score": 10.40170669555664, "metricx_qe_score": 8.415841102600098, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "fr", "output": "les articles sont beaucoup plus longs, avec une longueur moyenne de 77 mots, avec 140", "metrics": {"bleu_score": 33.90762156517553, "chrf_score": 48.86821721951241, "xcomet_score": 0.18878480792045593, "xcomet_qe_score": 0.23535796999931335, "metricx_score": 13.628215789794922, "metricx_qe_score": 12.837029457092285, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "fr", "output": "deux d'entre eux, excédant un tiers.", "metrics": {"bleu_score": 3.3495035708457803, "chrf_score": 10.531028682946232, "xcomet_score": 0.13604183495044708, "xcomet_qe_score": 0.13954414427280426, "metricx_score": 24.353853225708008, "metricx_qe_score": 22.352811813354492, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "fr", "output": "comme précédemment mentionné la question couvre un large éventail de sujets avec autour de quatre-vingt-cinq pour cent d'entre eux étant soit sur famille logement argent ou justice", "metrics": {"bleu_score": 7.381278975119652, "chrf_score": 55.897526400207674, "xcomet_score": 0.7247681021690369, "xcomet_qe_score": 0.7303495407104492, "metricx_score": 5.844714164733887, "metricx_qe_score": 6.461949825286865, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "fr", "output": "Alors que les quinze pour cent restants concernent la sécurité sociale, les étrangers ou le travail.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 1.2312910556793213, "metricx_qe_score": 1.4345992803573608, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "fr", "output": "Les articles sont également très divers, car ils proviennent de 32 codes belges différents qui couvrent un grand nombre de sujets juridiques.", "metrics": {"bleu_score": 51.02002548573252, "chrf_score": 77.11398468633138, "xcomet_score": 0.9291741847991943, "xcomet_qe_score": 0.9881991147994995, "metricx_score": 1.239342212677002, "metricx_qe_score": 0.9468382000923157, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le nombre total d'articles recueillis dans chacun de ces codes belges.", "metrics": {"bleu_score": 57.475393483140245, "chrf_score": 73.11515816698521, "xcomet_score": 0.9821270704269409, "xcomet_qe_score": 1.0, "metricx_score": 1.9027090072631836, "metricx_qe_score": 3.081489086151123, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "fr", "output": "Sur les vingt deux mille six cent trente trois articles, seulement un mille six cent douze sont considérés comme pertinents, au moins", "metrics": {"bleu_score": 23.489318616801178, "chrf_score": 66.92383441337455, "xcomet_score": 0.5966238975524902, "xcomet_qe_score": 0.8310995697975159, "metricx_score": 11.422607421875, "metricx_qe_score": 8.385784149169922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "fr", "output": "une question dans les données, et environ 80 % de ces articles cités proviennent de la cour civile, de la cour judiciaire, de la cour pénale ou de la cour pénale.", "metrics": {"bleu_score": 11.755743200908038, "chrf_score": 46.139280547965996, "xcomet_score": 0.1437634974718094, "xcomet_qe_score": 0.12920287251472473, "metricx_score": 16.030433654785156, "metricx_qe_score": 16.025753021240234, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant ce temps, dix-huit des trente-deux codes ont moins de cinq articles mentionnés comme pertinents pour au moins une question.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9955633878707886, "xcomet_qe_score": 0.9854298830032349, "metricx_score": 1.280003547668457, "metricx_qe_score": 1.5099163055419922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "fr", "output": "Ce qui peut être expliqué par le fait que ces codes se concentrent moins sur les individus et leurs préoccupations.", "metrics": {"bleu_score": 67.12403123245673, "chrf_score": 86.1373473225153, "xcomet_score": 0.9966295957565308, "xcomet_qe_score": 1.0, "metricx_score": 2.852947950363159, "metricx_qe_score": 3.244204044342041, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "fr", "output": "globalement, le nombre médian de citations pour ces articles cités est de deux, et moins de 25% d'entre eux", "metrics": {"bleu_score": 43.53754487410807, "chrf_score": 55.9215283436953, "xcomet_score": 0.41351836919784546, "xcomet_qe_score": 0.5982179045677185, "metricx_score": 15.470708847045898, "metricx_qe_score": 12.686971664428711, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "fr", "output": "En utilisant nos ensembles de données, nous comparons plusieurs approches de récupération, y compris l'architecture lexicale et dense.", "metrics": {"bleu_score": 44.77845944135174, "chrf_score": 75.009935328519, "xcomet_score": 0.7520583271980286, "xcomet_qe_score": 0.8250503540039062, "metricx_score": 4.155781269073486, "metricx_qe_score": 4.14773416519165, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "fr", "output": "donné une query dans un article un modèle lexical attribue une note à la paire d'articles de query en calculant la somme sur les termes de query des poids de chacun de ces termes dans cet article", "metrics": {"bleu_score": 56.33921324910178, "chrf_score": 76.43245682097437, "xcomet_score": 0.4696861505508423, "xcomet_qe_score": 0.5367661118507385, "metricx_score": 11.187731742858887, "metricx_qe_score": 10.228516578674316, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons les fonctions de classement standard TfIdF et BM25.", "metrics": {"bleu_score": 30.608171640228516, "chrf_score": 74.12526215029725, "xcomet_score": 0.9056704044342041, "xcomet_qe_score": 0.8934429287910461, "metricx_score": 2.6030585765838623, "metricx_qe_score": 4.110066890716553, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème principal avec ces approches est qu'ils ne peuvent récupérer que des articles contenant des mots clés présents dans la requête.", "metrics": {"bleu_score": 29.12882094260591, "chrf_score": 75.15643614084388, "xcomet_score": 0.9104457497596741, "xcomet_qe_score": 0.9313122034072876, "metricx_score": 1.9073455333709717, "metricx_qe_score": 2.193666696548462, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "fr", "output": "Pour surmonter cette limitation, nous expérimentons une architecture basée sur le neurone qui peut capturer la relation sémantique entre les requêtes et les articles.", "metrics": {"bleu_score": 46.22377023605668, "chrf_score": 84.63770437348282, "xcomet_score": 0.9460138082504272, "xcomet_qe_score": 0.9278865456581116, "metricx_score": 2.0077645778656006, "metricx_qe_score": 1.4537889957427979, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons un modèle de codage binaire qui mappe les requêtes et les articles en représentations vectorielles denses et calcule une note pertinente entre une paire d'articles de requête par la similitude de leurs intégrations.", "metrics": {"bleu_score": 58.56596027429396, "chrf_score": 78.8785069496061, "xcomet_score": 0.7251580953598022, "xcomet_qe_score": 0.6825469136238098, "metricx_score": 5.1218366622924805, "metricx_qe_score": 5.670543193817139, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "fr", "output": "Ces intégrations résultent généralement d'une opération de pooling sur la sortie d'un modèle d'intégration de mots.", "metrics": {"bleu_score": 82.82477531331043, "chrf_score": 90.96908691044948, "xcomet_score": 0.8626084327697754, "xcomet_qe_score": 0.7329448461532593, "metricx_score": 3.66196608543396, "metricx_qe_score": 6.458038806915283, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, nous étudions l'efficacité des coders bianchies siamès dans une configuration d'évaluation à zéro tir, ce qui signifie que les modèles d'intégration prétraînés sont appliqués hors de la boîte sans aucun ajustement fin supplémentaire.", "metrics": {"bleu_score": 30.546184813776897, "chrf_score": 66.60151654128789, "xcomet_score": 0.37019023299217224, "xcomet_qe_score": 0.3784397840499878, "metricx_score": 13.575959205627441, "metricx_qe_score": 12.419151306152344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec un encodeur de texte indépendant du contexte, à savoir WordtoVec et Fasttext, et des modèles d'intégration dépendants du contexte, à savoir Roberta et plus précisément Camembert, qui est un modèle de Roberta français.", "metrics": {"bleu_score": 63.457989639265016, "chrf_score": 86.32606194855994, "xcomet_score": 0.9315409660339355, "xcomet_qe_score": 0.9694037437438965, "metricx_score": 3.649003744125366, "metricx_qe_score": 3.168105363845825, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "fr", "output": "De plus, nous formons notre propre modèle basé sur Camembert,", "metrics": {"bleu_score": 21.87411438104692, "chrf_score": 47.00929112223511, "xcomet_score": 0.47277966141700745, "xcomet_qe_score": 0.34062689542770386, "metricx_score": 16.289941787719727, "metricx_qe_score": 10.106884002685547, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "fr", "output": "sur tous les ensembles de données notez que pour la formation nous expérimentons les deux saveurs de l'architecture biancoro", "metrics": {"bleu_score": 18.951629567590746, "chrf_score": 69.02745524385651, "xcomet_score": 0.2256849706172943, "xcomet_qe_score": 0.2312818318605423, "metricx_score": 15.119573593139648, "metricx_qe_score": 15.65923023223877, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "fr", "output": "Siamese, qui utilise un modèle unique d'intégration de mots qui mappe le query et l'article ensemble dans un espace vectoriel dense partagé, et Toutaoua, qui utilise deux modèles d'intégration de mots indépendants qui encodent le query et l'article séparément dans différents espaces d'intégration.", "metrics": {"bleu_score": 50.33842864291527, "chrf_score": 73.06781707430285, "xcomet_score": 0.4079752266407013, "xcomet_qe_score": 0.4201835095882416, "metricx_score": 13.207433700561523, "metricx_qe_score": 12.247331619262695, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec mean, max et cls pooling, ainsi que dot product et cosine pour calculer les similitudes.", "metrics": {"bleu_score": 24.257867329175667, "chrf_score": 57.84955434921816, "xcomet_score": 0.5728352069854736, "xcomet_qe_score": 0.6942653059959412, "metricx_score": 9.728940963745117, "metricx_qe_score": 9.064766883850098, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "fr", "output": "Voici le résultat de notre ligne de base sur le jeu de tests.", "metrics": {"bleu_score": 32.55964126200301, "chrf_score": 68.4877540247579, "xcomet_score": 0.5787562131881714, "xcomet_qe_score": 0.633527398109436, "metricx_score": 5.577253341674805, "metricx_qe_score": 5.839080810546875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "fr", "output": "avec les méthodes lexicales ci-dessus, les codants biancodes siamès évalués dans un zero shot setup dans le milieu et les codants biancodes finement tunés en dessous", "metrics": {"bleu_score": 22.117856823621686, "chrf_score": 53.117283251738556, "xcomet_score": 0.2520979344844818, "xcomet_qe_score": 0.3333236277103424, "metricx_score": 17.158140182495117, "metricx_qe_score": 14.582965850830078, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "fr", "output": "Dans l'ensemble, les Bianchoter de Fine Tune surpassent de façon significative toutes les autres lignes de basse.", "metrics": {"bleu_score": 19.51797195341104, "chrf_score": 57.80937285934395, "xcomet_score": 0.4133826494216919, "xcomet_qe_score": 0.3706820607185364, "metricx_score": 13.87256908416748, "metricx_qe_score": 11.251225471496582, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle à deux tours s'améliore par rapport à sa variante siamese sur le rappel à une centaine, mais fonctionne de manière similaire sur les autres matrices.", "metrics": {"bleu_score": 43.06165652033611, "chrf_score": 69.24716861480535, "xcomet_score": 0.45400044322013855, "xcomet_qe_score": 0.3599586486816406, "metricx_score": 6.669919490814209, "metricx_qe_score": 6.945813179016113, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "fr", "output": "Bien que B.M. 25 ait submergé le train de B.C. de manière significative, ses performances indiquent qu'il est toujours une base solide pour le domaine spécifique de la rétrocession.", "metrics": {"bleu_score": 25.450282931832767, "chrf_score": 63.16723237956514, "xcomet_score": 0.12571774423122406, "xcomet_qe_score": 0.11030270904302597, "metricx_score": 17.759965896606445, "metricx_qe_score": 18.35175132751465, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'évaluation à zéro tir de la bianconderie siamese, nous trouvons que l'utilisation directe des intégrations d'un modèle de camembert préentraîné sans optimiser la tâche de récupération d'informations donne de mauvais résultats, ce qui est conforme aux résultats précédents.", "metrics": {"bleu_score": 41.843375848681035, "chrf_score": 67.77844295490175, "xcomet_score": 0.342783123254776, "xcomet_qe_score": 0.36666449904441833, "metricx_score": 11.398101806640625, "metricx_qe_score": 11.781192779541016, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "fr", "output": "En outre, nous avons observé que le code biancoder basé sur le mot \"to vech\" surpasse de manière significative le texte rapide et le modèle basé sur le mot, ce qui suggère que les intégrations au niveau du mot préentraînées sont plus appropriées pour la tâche que les intégrations au niveau du caractère ou au niveau du sous-mot lorsqu'elles sont utilisées hors de la boîte.", "metrics": {"bleu_score": 23.836529635045427, "chrf_score": 56.91591256647337, "xcomet_score": 0.1523449718952179, "xcomet_qe_score": 0.21915483474731445, "metricx_score": 14.062385559082031, "metricx_qe_score": 14.441433906555176, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "fr", "output": "bien que prometteurs, ces résultats suggèrent une ample opportunité d'amélioration comparée à un expert peu habile qui peut éventuellement récupérer tous les articles pertinents à n'importe quelle question et ainsi obtenir des scores parfaits", "metrics": {"bleu_score": 50.13654287661956, "chrf_score": 74.7004460237053, "xcomet_score": 0.6728350520133972, "xcomet_qe_score": 0.6160081624984741, "metricx_score": 7.511424541473389, "metricx_qe_score": 7.294963836669922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "fr", "output": "Concluons en discutant deux limitations de tous les ensembles de données.", "metrics": {"bleu_score": 17.827531042796263, "chrf_score": 72.69820597280447, "xcomet_score": 0.897990345954895, "xcomet_qe_score": 0.8632693886756897, "metricx_score": 4.131923198699951, "metricx_qe_score": 2.940253257751465, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "fr", "output": "premièrement le corpus d'articles est limité à ceux recueillis à partir des trente deux codes belges considérés qui ne couvrent pas l'ensemble du droit belge comme les articles de décrets directives et ordonnances sont manquants", "metrics": {"bleu_score": 33.26328933307349, "chrf_score": 79.83871811333422, "xcomet_score": 0.8368023037910461, "xcomet_qe_score": 0.834342360496521, "metricx_score": 6.1561126708984375, "metricx_qe_score": 6.131289958953857, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "fr", "output": "Pendant la construction du jeu de données, toutes les références à ces articles non recueillis sont ignorées, ce qui provoque des questions qui ne finissent qu'avec une fraction du nombre initial d'articles pertinents.", "metrics": {"bleu_score": 55.035634313579784, "chrf_score": 74.92329346621095, "xcomet_score": 0.8983808159828186, "xcomet_qe_score": 0.9142084717750549, "metricx_score": 2.7588069438934326, "metricx_qe_score": 3.1557576656341553, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "fr", "output": "Cette perte d'information implique que la réponse contenue dans les articles restants pertinents pourrait être incomplète, bien qu'elle soit encore complètement appropriée.", "metrics": {"bleu_score": 48.54117278144115, "chrf_score": 76.68077206995126, "xcomet_score": 0.9552388191223145, "xcomet_qe_score": 0.9494810104370117, "metricx_score": 2.2770934104919434, "metricx_qe_score": 2.07363224029541, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous devrions noter que toutes les questions juridiques ne peuvent pas être répondues par des statuts seuls.", "metrics": {"bleu_score": 17.04921280749691, "chrf_score": 57.15480548429505, "xcomet_score": 0.9922043085098267, "xcomet_qe_score": 1.0, "metricx_score": 5.273509502410889, "metricx_qe_score": 3.0151519775390625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, la question : puis-je évacuer mes locataires s'ils font trop de bruit?", "metrics": {"bleu_score": 64.49131835432436, "chrf_score": 81.8648901587984, "xcomet_score": 0.8873264193534851, "xcomet_qe_score": 0.8934694528579712, "metricx_score": 1.6711435317993164, "metricx_qe_score": 1.532730221748352, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "fr", "output": "ne pourrait pas avoir une réponse détaillée dans le droit statutaire qui quantifie un seuil de bruit spécifique auquel l'expulsion est autorisée", "metrics": {"bleu_score": 43.18504517013496, "chrf_score": 76.32903822403651, "xcomet_score": 0.8139495849609375, "xcomet_qe_score": 0.8955387473106384, "metricx_score": 6.032173156738281, "metricx_qe_score": 6.376599311828613, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "fr", "output": "Au lieu de cela, les propriétaires devraient probablement s'appuyer plus sur la jurisprudence et trouver des précédents similaires à la situation actuelle.", "metrics": {"bleu_score": 43.769712992887364, "chrf_score": 79.77786481762519, "xcomet_score": 0.9957364797592163, "xcomet_qe_score": 0.998427152633667, "metricx_score": 1.280653476715088, "metricx_qe_score": 1.7344520092010498, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le locataire fait deux fêtes par semaine jusqu'à 2h00.", "metrics": {"bleu_score": 14.145615024654424, "chrf_score": 53.12835796697073, "xcomet_score": 0.8641349673271179, "xcomet_qe_score": 0.9023469686508179, "metricx_score": 4.790131092071533, "metricx_qe_score": 3.5175929069519043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "fr", "output": "hence certaines questions sont mieux adaptées que d'autres à la tâche de récupération d'articles statutaires et le domaine des moins appropriés reste à déterminer", "metrics": {"bleu_score": 47.85682400489466, "chrf_score": 69.78933243066655, "xcomet_score": 0.8023949861526489, "xcomet_qe_score": 0.5832821726799011, "metricx_score": 7.589017868041992, "metricx_qe_score": 7.2908616065979, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "fr", "output": "Nous espérons que tous ces travaux susciteront un intérêt pour le développement de modèles pratiques et fiables de récupération d'articles.", "metrics": {"bleu_score": 15.265280945577954, "chrf_score": 66.40840107062523, "xcomet_score": 0.7205654382705688, "xcomet_qe_score": 0.7608017325401306, "metricx_score": 5.172151565551758, "metricx_qe_score": 4.621691703796387, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "fr", "output": "ça peut aider à améliorer l'accès à JusticeFall.", "metrics": {"bleu_score": 43.742343691381734, "chrf_score": 65.79859330486498, "xcomet_score": 0.28782063722610474, "xcomet_qe_score": 0.2923452854156494, "metricx_score": 15.169868469238281, "metricx_qe_score": 14.403861999511719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez consulter notre document qui est codé aux liens suivants.", "metrics": {"bleu_score": 27.952629090528294, "chrf_score": 55.64839504416996, "xcomet_score": 0.4779830276966095, "xcomet_qe_score": 0.4420456290245056, "metricx_score": 7.0829925537109375, "metricx_qe_score": 8.175698280334473, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "fr", "output": "Hello, we are happy to present our work on vowels, a task independent benchmark meant for testing vision and language models with specific linguistic phenomena.", "metrics": {"bleu_score": 1.274329911846156, "chrf_score": 23.649960270995614, "xcomet_score": 0.67110276222229, "xcomet_qe_score": 0.8048508167266846, "metricx_score": 19.15138816833496, "metricx_qe_score": 11.152304649353027, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "fr", "output": "Pourquoi avons-nous fait le mal de mettre en place ce point de référence?", "metrics": {"bleu_score": 28.65612242047131, "chrf_score": 66.1790031934597, "xcomet_score": 0.6832482814788818, "xcomet_qe_score": 0.7304996252059937, "metricx_score": 6.4924516677856445, "metricx_qe_score": 4.34722900390625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "fr", "output": "Bien, au cours des dernières années, nous avons vu une explosion de modèles de vision et de langage basés sur des transformateurs, préentraînés sur de grandes quantités de paires de textes d'images.", "metrics": {"bleu_score": 60.09678153909896, "chrf_score": 79.29698666440083, "xcomet_score": 0.8470621705055237, "xcomet_qe_score": 0.8519463539123535, "metricx_score": 3.8692383766174316, "metricx_qe_score": 5.022909164428711, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque modèle pousse l'état de l'art sur les tâches de vision et de langage, telles que la réponse à des questions visuelles, le raisonnement de bon sens visuel, la rétraction d'images, le frottement de phrases.", "metrics": {"bleu_score": 41.04373678031295, "chrf_score": 68.62589390851012, "xcomet_score": 0.4049025774002075, "xcomet_qe_score": 0.3650423586368561, "metricx_score": 10.871634483337402, "metricx_qe_score": 12.329925537109375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "fr", "output": "Donc on a un message : les précisions sur ces benchmarks spécifiques à la tâche&nbsp;augmentent de façon constante.", "metrics": {"bleu_score": 28.073304156067923, "chrf_score": 48.784808322239044, "xcomet_score": 0.7810502052307129, "xcomet_qe_score": 0.7877511978149414, "metricx_score": 6.584289073944092, "metricx_qe_score": 7.630821228027344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "fr", "output": "Mais savons-nous ce que les modèles ont appris?", "metrics": {"bleu_score": 71.89393375176813, "chrf_score": 80.10302034076437, "xcomet_score": 0.9675363302230835, "xcomet_qe_score": 1.0, "metricx_score": 1.4594377279281616, "metricx_qe_score": 2.2625784873962402, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "fr", "output": "Qu'est-ce qu'un transformateur de vision et de langage a compris en attribuant un score élevé à cette image et à cette phrase pour qu'elles correspondent?", "metrics": {"bleu_score": 11.511237881432505, "chrf_score": 68.79106655782937, "xcomet_score": 0.6823065280914307, "xcomet_qe_score": 0.6370753049850464, "metricx_score": 2.62823224067688, "metricx_qe_score": 2.5372207164764404, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "fr", "output": "et une faible note pour ce un.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 21.94422557309456, "xcomet_score": 0.598453164100647, "xcomet_qe_score": 0.8647481203079224, "metricx_score": 7.0265655517578125, "metricx_qe_score": 5.58116340637207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "fr", "output": "Les modèles de vision et de langage se concentrent-ils sur la bonne chose?", "metrics": {"bleu_score": 32.281751885843555, "chrf_score": 68.20305147191763, "xcomet_score": 0.7627543210983276, "xcomet_qe_score": 0.7895306944847107, "metricx_score": 1.7370388507843018, "metricx_qe_score": 2.117433786392212, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "fr", "output": "Ou se concentrent-ils sur les préjugés, comme le montrent les travaux précédents?", "metrics": {"bleu_score": 31.61487584488944, "chrf_score": 61.327431733048265, "xcomet_score": 0.9792611598968506, "xcomet_qe_score": 1.0, "metricx_score": 0.8692505359649658, "metricx_qe_score": 0.9889103174209595, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "fr", "output": "Pour faire plus clair sur cet aspect, nous proposons une direction plus toscagnostique et introduisons des valves qui testent la sensibilité des modèles de vision et de langage à des phénomènes linguistiques spécifiques qui affectent à la fois les modalités linguistiques et visuelles.", "metrics": {"bleu_score": 51.8950373695691, "chrf_score": 75.45143723165725, "xcomet_score": 0.3929092288017273, "xcomet_qe_score": 0.44582122564315796, "metricx_score": 9.792731285095215, "metricx_qe_score": 8.70930004119873, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "fr", "output": "Nous ciblons l'existence, la pluralité, le comptage, les relations spatiales, les actions et les références d'entités.", "metrics": {"bleu_score": 74.23231271372502, "chrf_score": 88.9685159733428, "xcomet_score": 0.9456319808959961, "xcomet_qe_score": 0.9623863697052002, "metricx_score": 2.7433557510375977, "metricx_qe_score": 4.083306312561035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "fr", "output": "Mais comment testons-nous si les modèles de vision et de langage ont capturé ces phénomènes?", "metrics": {"bleu_score": 24.903286388467727, "chrf_score": 73.32586792195416, "xcomet_score": 0.9510176181793213, "xcomet_qe_score": 0.9546465277671814, "metricx_score": 1.7257195711135864, "metricx_qe_score": 2.1222803592681885, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "fr", "output": "par foil, une méthode précédemment appliquée pour les modèles de vision et de langage, seulement pour les phrases non-nominales de Ravi Shekhar et de ses collaborateurs, et en comptant par nous dans le travail précédent.", "metrics": {"bleu_score": 55.353698172770656, "chrf_score": 76.05105040774593, "xcomet_score": 0.21840481460094452, "xcomet_qe_score": 0.32901856303215027, "metricx_score": 16.71652603149414, "metricx_qe_score": 16.633255004882812, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "fr", "output": "Foilage signifie que nous prenons la caption d'une image et produisons une feuille en modifiant la caption de manière à ce qu'elle ne décrive plus l'image.", "metrics": {"bleu_score": 38.839201741996064, "chrf_score": 60.09954162358254, "xcomet_score": 0.389868825674057, "xcomet_qe_score": 0.6666934490203857, "metricx_score": 10.039480209350586, "metricx_qe_score": 8.205510139465332, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "fr", "output": "et nous faisons ces phrases alterations en focalisant sur six pièces spécifiques, telles que l'existence, la pluralité, le comptage, les relations spatiales, les actions et la référence d'entité, où chaque pièce peut consister en un ou plus d'instruments en cas de trouver plus d'une façon intéressante de créer des instances de foil.", "metrics": {"bleu_score": 49.935453531852275, "chrf_score": 68.84964130545022, "xcomet_score": 0.1559518575668335, "xcomet_qe_score": 0.1827191263437271, "metricx_score": 12.226907730102539, "metricx_qe_score": 12.85067081451416, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, dans le cas de l'action piece, nous avons deux instruments, un dans lequel le verbe d'action est changé avec une action différente et un dans lequel les actants sont échangés.", "metrics": {"bleu_score": 67.24991659498573, "chrf_score": 81.7564821367505, "xcomet_score": 0.5545856952667236, "xcomet_qe_score": 0.648081362247467, "metricx_score": 6.090285301208496, "metricx_qe_score": 6.0110039710998535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "fr", "output": "Le comptage et la co-référence sont aussi des pièces qui ont plus d'un instrument.", "metrics": {"bleu_score": 21.651956746181064, "chrf_score": 58.6515336010236, "xcomet_score": 0.6288557052612305, "xcomet_qe_score": 0.5619214177131653, "metricx_score": 6.11320686340332, "metricx_qe_score": 6.52931022644043, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous créons ces feuilles en nous assurant qu'elles ne décrivent pas l'image, qu'elles sont grammaticales et par ailleurs valides.", "metrics": {"bleu_score": 28.21254638256662, "chrf_score": 65.23223716546728, "xcomet_score": 0.7641915082931519, "xcomet_qe_score": 0.7431406378746033, "metricx_score": 6.0658392906188965, "metricx_qe_score": 6.40498685836792, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "fr", "output": "Ce n'est pas facile à faire parce qu'une légende fausse&nbsp;peut être moins probable que la légende originale.", "metrics": {"bleu_score": 58.52187596735431, "chrf_score": 76.14250970794497, "xcomet_score": 0.940018355846405, "xcomet_qe_score": 0.9368329048156738, "metricx_score": 4.320737361907959, "metricx_qe_score": 2.5327935218811035, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, bien que ce ne soit pas impossible, il est statistiquement moins probable que des plantes cèdent un homme qu'un homme cède des plantes, et les modèles de vision et de langage pourraient s'en occuper.", "metrics": {"bleu_score": 57.006601316557024, "chrf_score": 79.39928750786392, "xcomet_score": 0.4130309522151947, "xcomet_qe_score": 0.47539204359054565, "metricx_score": 13.185569763183594, "metricx_qe_score": 11.73615837097168, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour obtenir des foils valides, nous devons prendre des mesures.", "metrics": {"bleu_score": 71.66258375282708, "chrf_score": 87.00963502864994, "xcomet_score": 0.9978336095809937, "xcomet_qe_score": 1.0, "metricx_score": 1.6868655681610107, "metricx_qe_score": 4.286237716674805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, nous utilisons des modèles de langage forts pour proposer des foils.", "metrics": {"bleu_score": 65.15132562023375, "chrf_score": 78.36864818672288, "xcomet_score": 0.9588971138000488, "xcomet_qe_score": 0.9185986518859863, "metricx_score": 3.3868186473846436, "metricx_qe_score": 5.969285488128662, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "fr", "output": "Deuxièmement, nous utilisons la langue naturelle pour filtrer les foils qui pourraient encore décrire l'image, puisque, quand on construit des foils, nous devons nous assurer qu'ils ne décrivent pas l'image.", "metrics": {"bleu_score": 59.319057853510884, "chrf_score": 78.04538652813929, "xcomet_score": 0.593528687953949, "xcomet_qe_score": 0.6041130423545837, "metricx_score": 7.4509687423706055, "metricx_qe_score": 11.620624542236328, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "fr", "output": "Pour tester ceci automatiquement, nous appliquons l'inférence&nbsp;naturelle du langage avec le rationnel suivant:", "metrics": {"bleu_score": 23.210911117419965, "chrf_score": 68.61998415036861, "xcomet_score": 0.9392006397247314, "xcomet_qe_score": 0.9517603516578674, "metricx_score": 4.336856365203857, "metricx_qe_score": 4.2246270179748535, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "fr", "output": "Nous considérons une image comme la prémisse et sa sous-titre comme l'hypothèse qui l'entoure.", "metrics": {"bleu_score": 21.023693683267553, "chrf_score": 55.95163657942792, "xcomet_score": 0.8189840912818909, "xcomet_qe_score": 0.8295445442199707, "metricx_score": 6.8053297996521, "metricx_qe_score": 5.515532970428467, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "fr", "output": "En outre, nous considérons la légende comme la prémisse et le papier est son hypothèse.", "metrics": {"bleu_score": 69.26989774939868, "chrf_score": 85.71571679027417, "xcomet_score": 0.7519428133964539, "xcomet_qe_score": 0.6437671184539795, "metricx_score": 5.505931854248047, "metricx_qe_score": 6.08109188079834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "fr", "output": "Si un modèle NLI prédit que le foil est contradictoire ou neutre par rapport à la caption, nous prenons ceci comme un indicateur d'un foil valide.", "metrics": {"bleu_score": 54.06637414781749, "chrf_score": 71.01427705055266, "xcomet_score": 0.7757898569107056, "xcomet_qe_score": 0.44145748019218445, "metricx_score": 7.307255744934082, "metricx_qe_score": 8.968245506286621, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "fr", "output": "Si un NLI prédit que le foil doit être entaillé par la décaption, il ne peut pas être un bon foil, puisque par transitivité il donnera une description vraie de l'image et nous filtrons ces foils.", "metrics": {"bleu_score": 43.26389730340497, "chrf_score": 64.97299021033875, "xcomet_score": 0.3599117398262024, "xcomet_qe_score": 0.372700035572052, "metricx_score": 14.053872108459473, "metricx_qe_score": 15.18684196472168, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "fr", "output": "Mais cette procédure n'est pas parfaite, c'est juste un indicateur pour les feuilles valides.", "metrics": {"bleu_score": 46.365472160346705, "chrf_score": 70.2333968576679, "xcomet_score": 0.8560318350791931, "xcomet_qe_score": 0.8055280447006226, "metricx_score": 4.945434093475342, "metricx_qe_score": 4.353758811950684, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, comme troisième mesure pour générer des foils valides, nous employons des annotateurs humains pour valider les données utilisées dans les valves.", "metrics": {"bleu_score": 60.84121675336109, "chrf_score": 74.37382794910991, "xcomet_score": 0.6473290324211121, "xcomet_qe_score": 0.658720850944519, "metricx_score": 6.89464807510376, "metricx_qe_score": 7.540221214294434, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, après filtrage et évaluation humaine, nous avons autant d'exemples de test que décrits dans ce tableau.", "metrics": {"bleu_score": 70.76534431960266, "chrf_score": 86.84355124438567, "xcomet_score": 0.9721137285232544, "xcomet_qe_score": 0.9997761249542236, "metricx_score": 2.021247148513794, "metricx_qe_score": 2.611661911010742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que Valve ne fournit pas de données de formation, mais seulement des données de test.", "metrics": {"bleu_score": 68.99302125555486, "chrf_score": 87.22779096713127, "xcomet_score": 0.7684351801872253, "xcomet_qe_score": 0.7795580625534058, "metricx_score": 2.68332839012146, "metricx_qe_score": 1.7587966918945312, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "fr", "output": "Puisqu'il s'agit d'un benchmark de test à zéro tir seulement, il est conçu pour tirer parti des capacités existantes des modèles de vision et de langage après pré-entraînement.", "metrics": {"bleu_score": 43.856800578143876, "chrf_score": 60.10628459408066, "xcomet_score": 0.7472771406173706, "xcomet_qe_score": 0.7744331955909729, "metricx_score": 5.284968376159668, "metricx_qe_score": 5.068817615509033, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "fr", "output": "Le fine tuning ne permettrait qu'aux modèles d'exploiter des artefacts ou des biais statistiques dans les données.", "metrics": {"bleu_score": 65.91096049931349, "chrf_score": 79.30461739888001, "xcomet_score": 0.9010275602340698, "xcomet_qe_score": 0.9410277605056763, "metricx_score": 4.152705192565918, "metricx_qe_score": 4.3713860511779785, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "fr", "output": "Et nous savons tous que ces modèles aiment tricher et prendre des raccourcis.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998902082443237, "xcomet_qe_score": 1.0, "metricx_score": 1.3476738929748535, "metricx_qe_score": 2.4462342262268066, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "fr", "output": "Et comme nous l'avons dit, nous sommes intéressés à évaluer les capacités des modèles de vision et de langage après le pré-entraînement.", "metrics": {"bleu_score": 40.025074540692394, "chrf_score": 67.1397990197807, "xcomet_score": 0.9655847549438477, "xcomet_qe_score": 1.0, "metricx_score": 1.9174749851226807, "metricx_qe_score": 1.7723112106323242, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "fr", "output": "Nous expérimentons avec cinq modèles de vision et de langage sur les voyelles, à savoir avec Clip, Alex Mert, Wilbert, Wilbert 12 en 1 et Visual Bird.", "metrics": {"bleu_score": 27.30879756698326, "chrf_score": 53.79237508766309, "xcomet_score": 0.26622116565704346, "xcomet_qe_score": 0.3103991150856018, "metricx_score": 10.352964401245117, "metricx_qe_score": 8.078554153442383, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "fr", "output": "Deux de nos principales mesures d'évaluation sont l'exactitude des modèles dans la classification des paires de phrases d'image en captions et feuilles.", "metrics": {"bleu_score": 24.451495934553943, "chrf_score": 57.862154501748094, "xcomet_score": 0.5242300033569336, "xcomet_qe_score": 0.5689661502838135, "metricx_score": 8.52734375, "metricx_qe_score": 7.678311824798584, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "fr", "output": "peut être plus pertinent pour cette vidéo nous allons montrer notre métrique plus primitive la précision par paires qui mesure si le score d'alignement de la phrase d'image est plus grand pour la paire de texte d'image correcte que pour sa paire foilée", "metrics": {"bleu_score": 28.59028028114882, "chrf_score": 58.82261814490871, "xcomet_score": 0.4461750090122223, "xcomet_qe_score": 0.44138553738594055, "metricx_score": 8.793400764465332, "metricx_qe_score": 8.125373840332031, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "fr", "output": "Pour plus de métriques et résultats, faites-vous un tour de notre papier.", "metrics": {"bleu_score": 9.55204080682377, "chrf_score": 38.71438686613903, "xcomet_score": 0.6876016855239868, "xcomet_qe_score": 0.6997666358947754, "metricx_score": 6.877307415008545, "metricx_qe_score": 5.666069507598877, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "fr", "output": "Les résultats avec une précision par paires sont montrés ici et ils sont cohérents avec les résultats que nous avons obtenus avec les autres matrices. La meilleure performance de zéro tir est obtenue par Wilbert 12 en un, suivi par Wilbert Alex Merck Clive et finalement Visual Bird.", "metrics": {"bleu_score": 47.517194692538354, "chrf_score": 68.67569536123052, "xcomet_score": 0.2450699806213379, "xcomet_qe_score": 0.23766331374645233, "metricx_score": 15.188085556030273, "metricx_qe_score": 15.491460800170898, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "fr", "output": "Il est notable que les instruments centrés sur les objets individuels, comme l'existence et les phrases nommées, sont presque résolus par Wilbert 121, soulignant que les modèles sont capables d'identifier des objets nommés et leur présence dans les images.", "metrics": {"bleu_score": 61.68871888996325, "chrf_score": 78.5391490408133, "xcomet_score": 0.6287062168121338, "xcomet_qe_score": 0.4808970093727112, "metricx_score": 6.559902667999268, "metricx_qe_score": 6.480303764343262, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "fr", "output": "Cependant, aucune des pièces restantes ne peut être résolue de manière fiable dans nos paramètres de foulage adversaire.", "metrics": {"bleu_score": 40.1577332834242, "chrf_score": 68.28321360688858, "xcomet_score": 0.6767973899841309, "xcomet_qe_score": 0.6085445880889893, "metricx_score": 6.19901180267334, "metricx_qe_score": 5.515295505523682, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "fr", "output": "Nous voyons, à partir de l'instrument de pluralité et de comptage, que les modèles de vision et de langage ont du mal à distinguer les références à des objets simples ou multiples ou à les compter dans une image.", "metrics": {"bleu_score": 54.9464180340485, "chrf_score": 73.7710626741564, "xcomet_score": 0.914616584777832, "xcomet_qe_score": 0.8759157657623291, "metricx_score": 2.379819393157959, "metricx_qe_score": 3.198239326477051, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "fr", "output": "La relation P montre qu'ils ont des difficultés à classer correctement une relation spatiale entre des objets dans une image.", "metrics": {"bleu_score": 73.62853809865184, "chrf_score": 84.08469203715332, "xcomet_score": 0.8102883100509644, "xcomet_qe_score": 0.7775167226791382, "metricx_score": 5.054068088531494, "metricx_qe_score": 5.862584114074707, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "fr", "output": "Ils ont aussi du mal à distinguer les actions et à identifier les participants, même s'ils sont soutenus par des biais de plausibilité, comme nous le voyons dans l'action piece.", "metrics": {"bleu_score": 66.8194883835197, "chrf_score": 81.58982308083337, "xcomet_score": 0.7631831169128418, "xcomet_qe_score": 0.8014142513275146, "metricx_score": 4.878509998321533, "metricx_qe_score": 5.264980316162109, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "fr", "output": "de la coréférence piece we find out that tracing multiple references to the same object in an image by using pronouns is also difficult for vision and language models", "metrics": {"bleu_score": 1.4795944318036467, "chrf_score": 29.843699899865843, "xcomet_score": 0.3541543781757355, "xcomet_qe_score": 0.7437328696250916, "metricx_score": 24.522052764892578, "metricx_qe_score": 24.35887336730957, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "fr", "output": "Comme un test de sanité et parce que c'est un intéressant experiment, nous avons également benchmarqué deux text only models, GPT 1 et GPT 2, pour évaluer si les valves sont solvables par ces unimodels models, en calculant la perplexité de la correction et de la faute capture, et en prédisant l'entrée avec la plus basse perplexité.", "metrics": {"bleu_score": 22.757028825331155, "chrf_score": 52.26203335816143, "xcomet_score": 0.12011614441871643, "xcomet_qe_score": 0.265982061624527, "metricx_score": 21.58122444152832, "metricx_qe_score": 18.472509384155273, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "fr", "output": "si la perplexité est plus élevée pour le foil, nous prenons cela comme une indication que la sous-titre foilée peut souffrir de biais de plausibilité ou d'autres biais linguistiques", "metrics": {"bleu_score": 65.25725962194696, "chrf_score": 80.60948588029761, "xcomet_score": 0.4292682409286499, "xcomet_qe_score": 0.5204735398292542, "metricx_score": 7.75056266784668, "metricx_qe_score": 10.00761890411377, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est intéressant de voir que dans certains cas, les modèles GPT ont capté la plausibilité du monde mieux que les modèles de vision et de langage.", "metrics": {"bleu_score": 58.571570353878776, "chrf_score": 77.9376129598142, "xcomet_score": 0.7297706007957458, "xcomet_qe_score": 0.7484971284866333, "metricx_score": 5.483884811401367, "metricx_qe_score": 6.440704345703125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "fr", "output": "Pour résumer, Valse est un point de référence qui utilise la longueur des constructions linguistiques pour aider la communauté à améliorer les modèles de vision et de langage en testant dur leurs capacités de mise au sol visuelle.", "metrics": {"bleu_score": 43.58757237161805, "chrf_score": 73.75096090996453, "xcomet_score": 0.35625118017196655, "xcomet_qe_score": 0.3994022309780121, "metricx_score": 10.494511604309082, "metricx_qe_score": 10.76305103302002, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "fr", "output": "nos expériences montrent que les modèles linguistiques identifient les objets et les images bien présentés par l'existence, mais se battent pour les relations et les relations avec les signes visuels, et pour respecter les indicateurs linguistiques.", "metrics": {"bleu_score": 12.511169405813577, "chrf_score": 53.05848332653129, "xcomet_score": 0.2660039961338043, "xcomet_qe_score": 0.22744615375995636, "metricx_score": 14.258560180664062, "metricx_qe_score": 14.7167329788208, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "fr", "output": "Nous aimerions encourager la communauté à utiliser les valves pour mesurer le progrès vers le language grounding avec vision et language models.", "metrics": {"bleu_score": 19.080094553267216, "chrf_score": 60.49652217875536, "xcomet_score": 0.43187570571899414, "xcomet_qe_score": 0.5519111156463623, "metricx_score": 12.513288497924805, "metricx_qe_score": 14.93464469909668, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "fr", "output": "Et encore plus, les valves pourraient être utilisées comme une évaluation indirecte des ensembles de données, car les modèles pourraient être évalués avant et après la formation ou le réglage fin pour voir si un ensemble de données aide les modèles à améliorer l'un ou l'autre des aspects testés par les valves.", "metrics": {"bleu_score": 46.83452044631733, "chrf_score": 76.39990372245941, "xcomet_score": 0.6919350624084473, "xcomet_qe_score": 0.6431885957717896, "metricx_score": 10.388497352600098, "metricx_qe_score": 8.99173641204834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "fr", "output": "Si vous êtes intéressé, vérifiez les fausses données sur GitHub et si vous avez des questions, n'hésitez pas à nous contacter.", "metrics": {"bleu_score": 67.57784746936484, "chrf_score": 79.43692681208408, "xcomet_score": 0.7624201774597168, "xcomet_qe_score": 0.8703352212905884, "metricx_score": 7.576956272125244, "metricx_qe_score": 7.258449077606201, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "fr", "output": "Je m'appelle Kamizawa, j'appartiens à l'université de Tokyo.", "metrics": {"bleu_score": 17.747405280050266, "chrf_score": 59.439134613315034, "xcomet_score": 0.906668484210968, "xcomet_qe_score": 0.9203353524208069, "metricx_score": 3.122068166732788, "metricx_qe_score": 2.6760408878326416, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais présenter un article intitulé R&amp;Sum, un jeu à grande échelle pour la reproduction automatique de la ressonance via la sommation de committé.", "metrics": {"bleu_score": 24.9893651242067, "chrf_score": 52.958727149550064, "xcomet_score": 0.053140297532081604, "xcomet_qe_score": 0.20913469791412354, "metricx_score": 18.299346923828125, "metricx_qe_score": 18.270780563354492, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "fr", "output": "Je vais expliquer dans cet ordre.", "metrics": {"bleu_score": 61.29752413741059, "chrf_score": 82.67586467120438, "xcomet_score": 0.9803920984268188, "xcomet_qe_score": 1.0, "metricx_score": 0.5986242294311523, "metricx_qe_score": 0.8819785118103027, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "fr", "output": "Tout d'abord, je vais vous présenter la génération de viscosité automatique sur laquelle nous travaillons dans cette recherche.", "metrics": {"bleu_score": 67.31407775173051, "chrf_score": 85.34926084138722, "xcomet_score": 0.722343385219574, "xcomet_qe_score": 0.7325019836425781, "metricx_score": 6.024484157562256, "metricx_qe_score": 4.6002044677734375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "fr", "output": "ReleaseNote est un document technique qui résume les changements distribués avec chaque sortie d'un produit logiciel.", "metrics": {"bleu_score": 42.51436507786929, "chrf_score": 61.97340731553796, "xcomet_score": 0.8675413131713867, "xcomet_qe_score": 0.8924338817596436, "metricx_score": 4.0379252433776855, "metricx_qe_score": 4.866456508636475, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "fr", "output": "Une image montre une note de sortie de bouton 2,6", "metrics": {"bleu_score": 11.292956255471855, "chrf_score": 27.79145010874885, "xcomet_score": 0.13196247816085815, "xcomet_qe_score": 0.14480531215667725, "metricx_score": 14.892156600952148, "metricx_qe_score": 18.418254852294922, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "fr", "output": "Ces notes jouent un rôle important dans le développement open source, mais elles prennent du temps à préparer manuellement.", "metrics": {"bleu_score": 55.96261706753688, "chrf_score": 75.76121265834364, "xcomet_score": 0.9993470907211304, "xcomet_qe_score": 1.0, "metricx_score": 1.1836025714874268, "metricx_qe_score": 1.6854114532470703, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, il serait très utile d'être capable de générer automatiquement des notes de bail de haute qualité.", "metrics": {"bleu_score": 60.39435155169266, "chrf_score": 78.97740678329642, "xcomet_score": 0.7841715812683105, "xcomet_qe_score": 0.8356375098228455, "metricx_score": 6.522696495056152, "metricx_qe_score": 4.595086574554443, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "fr", "output": "J'ai fait référence à deux recherches précédentes sur la génération automatique de résines.", "metrics": {"bleu_score": 31.744430345967675, "chrf_score": 57.49238003986409, "xcomet_score": 0.3546534776687622, "xcomet_qe_score": 0.42076507210731506, "metricx_score": 13.707515716552734, "metricx_qe_score": 10.608778953552246, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier est un système appelé Array, sorti en 2014.", "metrics": {"bleu_score": 26.20251007173262, "chrf_score": 45.211631094793056, "xcomet_score": 0.15937644243240356, "xcomet_qe_score": 0.16309455037117004, "metricx_score": 6.546071529388428, "metricx_qe_score": 7.393444538116455, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "fr", "output": "Il adopte une approche basée sur les règles, par exemple en utilisant l'extracteur de changement pour extraire les différences de noyau, les changements de bibliothèque et les changements de document des différences entre les versions, et finalement les combiner.", "metrics": {"bleu_score": 54.79840959445536, "chrf_score": 81.4664021445692, "xcomet_score": 0.7820279598236084, "xcomet_qe_score": 0.8769567608833313, "metricx_score": 2.898653984069824, "metricx_qe_score": 1.4886884689331055, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "fr", "output": "La caractéristique la plus remarquable de ce système est l'extracteur en haut à droite.", "metrics": {"bleu_score": 34.64195993780226, "chrf_score": 60.95652249073162, "xcomet_score": 0.7628819346427917, "xcomet_qe_score": 0.8259593844413757, "metricx_score": 4.072049140930176, "metricx_qe_score": 4.189970016479492, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "fr", "output": "qui doit être lié à zéro dans le système de circuits émis et ne peut être appliqué qu'aux produits qui utilisent zéro.", "metrics": {"bleu_score": 24.39746377431538, "chrf_score": 59.295010358465724, "xcomet_score": 0.14149974286556244, "xcomet_qe_score": 0.14322654902935028, "metricx_score": 22.52052116394043, "metricx_qe_score": 22.664642333984375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, il ne peut pas être utilisé pour de nombreux projets sur guitare.", "metrics": {"bleu_score": 72.97627709554281, "chrf_score": 81.80575777141262, "xcomet_score": 0.5009975433349609, "xcomet_qe_score": 0.42382287979125977, "metricx_score": 8.764021873474121, "metricx_qe_score": 8.294472694396973, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "fr", "output": "Le second est le grief, récemment annoncé en", "metrics": {"bleu_score": 10.147104008451905, "chrf_score": 45.60958258185675, "xcomet_score": 0.14474961161613464, "xcomet_qe_score": 0.18686595559120178, "metricx_score": 17.795835494995117, "metricx_qe_score": 11.856206893920898, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "fr", "output": "Il est disponible sur Internet et peut être stocké via Pip.", "metrics": {"bleu_score": 22.781556051062047, "chrf_score": 61.00133508729878, "xcomet_score": 0.5312228202819824, "xcomet_qe_score": 0.8074154853820801, "metricx_score": 6.139378070831299, "metricx_qe_score": 5.350916862487793, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "fr", "output": "Ce système a un simple modèle de classification basé sur l'exécution et la sortie d'un des cinq rubriques, telles que les fonctionnalités ou les corrections de bugs, pour chaque message de commit d'entrée.", "metrics": {"bleu_score": 24.263763794008042, "chrf_score": 60.58907966204622, "xcomet_score": 0.46398642659187317, "xcomet_qe_score": 0.5220621824264526, "metricx_score": 6.7678656578063965, "metricx_qe_score": 6.06640100479126, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "fr", "output": "L'image est une utilisation simple qui rend un label correctif ou de correction de bug.", "metrics": {"bleu_score": 8.47178590796544, "chrf_score": 46.39330122687051, "xcomet_score": 0.5510135889053345, "xcomet_qe_score": 0.5824437141418457, "metricx_score": 6.7552595138549805, "metricx_qe_score": 6.488805294036865, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "fr", "output": "Les données de formation de Griffith sont assez petites, environ cinq mille, et nous allons les montrer dans les expériences décrites ci-dessous.", "metrics": {"bleu_score": 64.44280974574026, "chrf_score": 81.70606571944126, "xcomet_score": 0.7706235647201538, "xcomet_qe_score": 0.9015989303588867, "metricx_score": 6.597635269165039, "metricx_qe_score": 7.086452484130859, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "fr", "output": "La performance du modèle de classification de texte n'est pas élevée.", "metrics": {"bleu_score": 41.24914892312113, "chrf_score": 77.37520089391352, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.7285580635070801, "metricx_qe_score": 1.104062795639038, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "fr", "output": "Je présente deux recherches connexes, mais il y a des problèmes d'applicabilité limitée et de ressources de données rares.", "metrics": {"bleu_score": 48.45766087853282, "chrf_score": 82.35147828234967, "xcomet_score": 0.9677211046218872, "xcomet_qe_score": 0.9111800193786621, "metricx_score": 1.0704854726791382, "metricx_qe_score": 1.2610890865325928, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "fr", "output": "Notre article résout ces deux problèmes et génère automatiquement des auditeurs de haute qualité.", "metrics": {"bleu_score": 70.0418991088418, "chrf_score": 83.72907494640633, "xcomet_score": 0.6909562349319458, "xcomet_qe_score": 0.6622534990310669, "metricx_score": 12.133160591125488, "metricx_qe_score": 10.499191284179688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le problème de l'applicabilité limitée, il propose une méthode de résumé classifié de haute qualité, utilisant uniquement le message du comité comme entrée.", "metrics": {"bleu_score": 11.88359194952101, "chrf_score": 56.87968611193307, "xcomet_score": 0.5674622058868408, "xcomet_qe_score": 0.5729752779006958, "metricx_score": 8.543556213378906, "metricx_qe_score": 7.216241836547852, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "fr", "output": "Cette méthode proposée peut être utilisée pour tous les dispositifs en anglais.", "metrics": {"bleu_score": 70.16035864257111, "chrf_score": 79.18576585859644, "xcomet_score": 0.8152583241462708, "xcomet_qe_score": 0.8066561222076416, "metricx_score": 7.546844959259033, "metricx_qe_score": 7.655466556549072, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le second problème, nous avons construit notre propre déchet d'enzyme, composé d'environ 82 000 pièces de données, en collectant des données de dépôts publics GitHub en utilisant la API GitHub.", "metrics": {"bleu_score": 17.550898685997666, "chrf_score": 50.00844647200059, "xcomet_score": 0.4231202304363251, "xcomet_qe_score": 0.5107649564743042, "metricx_score": 10.730148315429688, "metricx_qe_score": 10.78575611114502, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, je vais décrire notre désert.", "metrics": {"bleu_score": 54.10822690539397, "chrf_score": 71.50858936957206, "xcomet_score": 0.4768860638141632, "xcomet_qe_score": 0.5776309967041016, "metricx_score": 12.75596809387207, "metricx_qe_score": 14.679444313049316, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "fr", "output": "Voici un exemple de données.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 0.9998996257781982, "xcomet_qe_score": 0.9993472099304199, "metricx_score": 0.5450457334518433, "metricx_qe_score": 0.6231614351272583, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "fr", "output": "Le côté gauche est le message de commutation et le côté droit est la note de résumé.", "metrics": {"bleu_score": 30.928520903947533, "chrf_score": 54.91463728404512, "xcomet_score": 0.6707816123962402, "xcomet_qe_score": 0.6392049789428711, "metricx_score": 8.050373077392578, "metricx_qe_score": 7.046339988708496, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "fr", "output": "Les résonants sont évalus comme des améliorations, des fonctions, etc.", "metrics": {"bleu_score": 14.211672443220438, "chrf_score": 41.55752598462657, "xcomet_score": 0.1344931572675705, "xcomet_qe_score": 0.14117994904518127, "metricx_score": 17.62173080444336, "metricx_qe_score": 15.800625801086426, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons mis en place une tâche qui prend les messages de comité comme entrées et sorties qui ne sont pas autorisées.", "metrics": {"bleu_score": 53.39935148604844, "chrf_score": 60.46675581372115, "xcomet_score": 0.20069663226604462, "xcomet_qe_score": 0.21061821281909943, "metricx_score": 13.754413604736328, "metricx_qe_score": 13.950200080871582, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "fr", "output": "Cela peut être considéré comme une tâche de résumé.", "metrics": {"bleu_score": 78.25422900366438, "chrf_score": 80.28616903243483, "xcomet_score": 0.9564080238342285, "xcomet_qe_score": 0.9850058555603027, "metricx_score": 1.28573477268219, "metricx_qe_score": 0.8809378743171692, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons prédéfinis quatre niveaux: fonctionnalités, améliorations, corrections de bugs, décomposition, suppression et changements de freinage.", "metrics": {"bleu_score": 32.50555793482135, "chrf_score": 58.87401522021655, "xcomet_score": 0.4386875033378601, "xcomet_qe_score": 0.34190085530281067, "metricx_score": 13.03006362915039, "metricx_qe_score": 10.671485900878906, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "fr", "output": "Ces projets de loi sont basés sur des recherches antérieures et d'autres facteurs.", "metrics": {"bleu_score": 18.3186413935951, "chrf_score": 52.18018499415318, "xcomet_score": 0.7055150270462036, "xcomet_qe_score": 0.6862375736236572, "metricx_score": 9.457988739013672, "metricx_qe_score": 9.166168212890625, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "fr", "output": "il n'y a pas de nœud en bas à droite et extrait quand il n'y a pas de nœud en bas à gauche", "metrics": {"bleu_score": 21.800193956058234, "chrf_score": 43.67019809828743, "xcomet_score": 0.14592914283275604, "xcomet_qe_score": 0.15251424908638, "metricx_score": 19.1115779876709, "metricx_qe_score": 19.345979690551758, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "fr", "output": "À ce moment-là, il est nécessaire de détecter les quatre décombres qui ont été installés à l'avance.", "metrics": {"bleu_score": 48.24766987096574, "chrf_score": 63.988643911359354, "xcomet_score": 0.590122401714325, "xcomet_qe_score": 0.5539723634719849, "metricx_score": 10.032055854797363, "metricx_qe_score": 10.300305366516113, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "fr", "output": "Mais les niveaux ne sont pas toujours cohérents avec chaque liposuction.", "metrics": {"bleu_score": 29.50234363196403, "chrf_score": 59.781193123264686, "xcomet_score": 0.14361527562141418, "xcomet_qe_score": 0.09538812190294266, "metricx_score": 13.443530082702637, "metricx_qe_score": 14.654840469360352, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "fr", "output": "Par exemple, le niveau d'amélioration comprend des améliorations, des améliorations, des optimisations, etc.", "metrics": {"bleu_score": 47.18372009351201, "chrf_score": 65.08893316411977, "xcomet_score": 0.6166261434555054, "xcomet_qe_score": 0.7456319332122803, "metricx_score": 6.269484519958496, "metricx_qe_score": 6.626492023468018, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons préparé une liste vocabulaire de trente mots pour chacune de ces variations de rotation.", "metrics": {"bleu_score": 49.701084283458314, "chrf_score": 72.13551745021418, "xcomet_score": 0.5158417224884033, "xcomet_qe_score": 0.5731048583984375, "metricx_score": 8.161104202270508, "metricx_qe_score": 7.659643173217773, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "fr", "output": "Utilisez-le pour détecter les classes raisonnables et corriger le texte des classes qui suit comme la phrase raisonnable pour la classe.", "metrics": {"bleu_score": 10.263189215790339, "chrf_score": 38.77067074186565, "xcomet_score": 0.2481730729341507, "xcomet_qe_score": 0.12746435403823853, "metricx_score": 20.90459632873535, "metricx_qe_score": 21.41342544555664, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "fr", "output": "Le prochain message est un message de commitment.", "metrics": {"bleu_score": 17.0653267718276, "chrf_score": 31.581367691753588, "xcomet_score": 0.5439859628677368, "xcomet_qe_score": 0.9516773223876953, "metricx_score": 5.348040580749512, "metricx_qe_score": 4.7676215171813965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de commutation ne sont pas liés à chaque pièce.", "metrics": {"bleu_score": 54.52469119630866, "chrf_score": 69.47033861399947, "xcomet_score": 0.5727461576461792, "xcomet_qe_score": 0.5860080122947693, "metricx_score": 9.257802963256836, "metricx_qe_score": 6.2332377433776855, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "fr", "output": "Comme on le voit dans l'image ci-dessous, si la valeur actuelle est de 2,5 à 19, il faut identifier", "metrics": {"bleu_score": 11.487542244407226, "chrf_score": 31.747381265968173, "xcomet_score": 0.24931521713733673, "xcomet_qe_score": 0.17812922596931458, "metricx_score": 19.688499450683594, "metricx_qe_score": 18.085052490234375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "fr", "output": "pour la version précédente, 2.518 et get it fixed. c'est un peu tedius et il n'est pas assez de juste obtenir une liste de releases et de regarder les before and after.", "metrics": {"bleu_score": 8.8760743367864, "chrf_score": 49.481965752683564, "xcomet_score": 0.3359639048576355, "xcomet_qe_score": 0.1838277131319046, "metricx_score": 21.31194305419922, "metricx_qe_score": 21.62347984313965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "fr", "output": "Il a créé un outil de match heuristique pour obtenir les versions précédentes et suivantes.", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 55.930246033327094, "xcomet_score": 0.6209120750427246, "xcomet_qe_score": 0.3817048668861389, "metricx_score": 4.992031574249268, "metricx_qe_score": 4.676753044128418, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "fr", "output": "Des centaines d'annerses.", "metrics": {"bleu_score": 15.97357760615681, "chrf_score": 18.04292555915677, "xcomet_score": 0.12648221850395203, "xcomet_qe_score": 0.11669562011957169, "metricx_score": 20.307994842529297, "metricx_qe_score": 16.408174514770508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "fr", "output": "Au final, sept mille deux cents dépôts", "metrics": {"bleu_score": 15.181216783202624, "chrf_score": 29.66463753407857, "xcomet_score": 0.1627390831708908, "xcomet_qe_score": 0.14450986683368683, "metricx_score": 23.152732849121094, "metricx_qe_score": 20.16863250732422, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "fr", "output": "En outre, le nombre moyen de jetons distribués est de soixante-trois, ce qui est assez élevé pour les tâches de simplification.", "metrics": {"bleu_score": 55.797295712576044, "chrf_score": 66.5568994980008, "xcomet_score": 0.5158849954605103, "xcomet_qe_score": 0.6044307947158813, "metricx_score": 6.3059539794921875, "metricx_qe_score": 4.196307182312012, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "fr", "output": "En outre, le nombre de jetons uniques est assez élevé, à 8 830 000.", "metrics": {"bleu_score": 17.89117353466845, "chrf_score": 36.09187609542536, "xcomet_score": 0.7659900188446045, "xcomet_qe_score": 0.9483704566955566, "metricx_score": 4.015220642089844, "metricx_qe_score": 2.1759486198425293, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "fr", "output": "En raison du grand nombre de classes et de noms de méthodes uniques trouvés dans le laboratoire.", "metrics": {"bleu_score": 17.699051342800775, "chrf_score": 61.57982448882522, "xcomet_score": 0.6435705423355103, "xcomet_qe_score": 0.6145806312561035, "metricx_score": 5.959916114807129, "metricx_qe_score": 4.908799648284912, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, j'expliquerai la méthode proposée.", "metrics": {"bleu_score": 36.74145494215666, "chrf_score": 75.59105076499984, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.26971232891082764, "metricx_qe_score": 0.1778177171945572, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "fr", "output": "Le modèle de résumé extractif puis abstrait de Crosswise se compose de deux modules neutres.", "metrics": {"bleu_score": 32.37722713145643, "chrf_score": 59.11216421736375, "xcomet_score": 0.2605508863925934, "xcomet_qe_score": 0.27248242497444153, "metricx_score": 8.354656219482422, "metricx_qe_score": 8.552396774291992, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "fr", "output": "un classificateur utilisant butt ou code butt et un générateur utilisant butt", "metrics": {"bleu_score": 26.20251007173262, "chrf_score": 67.48827821741557, "xcomet_score": 0.296365886926651, "xcomet_qe_score": 0.35442569851875305, "metricx_score": 14.430000305175781, "metricx_qe_score": 15.790885925292969, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "fr", "output": "Premièrement, CAS utilise un classificateur pour classer chaque message commandé en cinq classes distinctes : fonctionnalités, améliorations, corrections de bug, applications, plus et autres.", "metrics": {"bleu_score": 23.625012787704538, "chrf_score": 56.51954244500096, "xcomet_score": 0.3281734585762024, "xcomet_qe_score": 0.3095031976699829, "metricx_score": 10.86422348022461, "metricx_qe_score": 10.954911231994629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "fr", "output": "Les messages de commentaire classés comme autres sont rejetés.", "metrics": {"bleu_score": 39.281465090051285, "chrf_score": 61.18560001793808, "xcomet_score": 0.8125633597373962, "xcomet_qe_score": 0.7512661218643188, "metricx_score": 4.791293144226074, "metricx_qe_score": 4.372282028198242, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "fr", "output": "Ensuite, GAS applique le générateur aux quatre documents de rang indépendamment et génère des notes pour chaque classe.", "metrics": {"bleu_score": 54.61493541806697, "chrf_score": 78.45805418059432, "xcomet_score": 0.38767391443252563, "xcomet_qe_score": 0.3437446355819702, "metricx_score": 9.900103569030762, "metricx_qe_score": 10.638731956481934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cette tâche, les correspondances directes entre les messages du comité et les notes de raisonnement ne sont pas connues.", "metrics": {"bleu_score": 68.88074582865497, "chrf_score": 80.37536163750227, "xcomet_score": 0.6787689924240112, "xcomet_qe_score": 0.6263185739517212, "metricx_score": 8.75384521484375, "metricx_qe_score": 8.051037788391113, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "fr", "output": "Par conséquent, pour former le classificateur, nous attribuons des niveaux à chaque message de commentaire d'entrée en utilisant les dix premiers caractères de chaque message de commentaire.", "metrics": {"bleu_score": 60.393656026930365, "chrf_score": 69.97825648459474, "xcomet_score": 0.6693145632743835, "xcomet_qe_score": 0.7374464273452759, "metricx_score": 6.4321513175964355, "metricx_qe_score": 6.261016845703125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "fr", "output": "Nous modélisons l'approche de résumé obstructif classé par deux méthodes différentes.", "metrics": {"bleu_score": 21.099261895175324, "chrf_score": 54.64636375295242, "xcomet_score": 0.5920788049697876, "xcomet_qe_score": 0.5112797021865845, "metricx_score": 5.967724323272705, "metricx_qe_score": 4.993145942687988, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "fr", "output": "Le premier modèle, que nous appelons GAS single, se compose d'un seul réseau sexto sex et génère une seule pièce sans texte, donnée une concurrence de messages commit d'entrée.", "metrics": {"bleu_score": 25.24728436996476, "chrf_score": 49.8507064028555, "xcomet_score": 0.05422606319189072, "xcomet_qe_score": 0.07550550252199173, "metricx_score": 20.323482513427734, "metricx_qe_score": 18.250091552734375, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "fr", "output": "Les taquettes de sortie peuvent être divisées en segments transversaux sur la base de symboles de points de fin spéciaux.", "metrics": {"bleu_score": 30.02086140405868, "chrf_score": 56.794255173583586, "xcomet_score": 0.5169657468795776, "xcomet_qe_score": 0.6597685813903809, "metricx_score": 8.627691268920898, "metricx_qe_score": 8.046435356140137, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "fr", "output": "La méthode, que nous appelons GSmart, se compose de quatre différents réseaux sec-to-sec, chacun correspondant à l'une des classes de notes les plus basses.", "metrics": {"bleu_score": 40.3622788629783, "chrf_score": 64.46423237545069, "xcomet_score": 0.1341158002614975, "xcomet_qe_score": 0.16706527769565582, "metricx_score": 16.86322021484375, "metricx_qe_score": 16.32904624938965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "fr", "output": "Ok, laisse moi expliquer l'expérience.", "metrics": {"bleu_score": 11.737849637633069, "chrf_score": 51.75270752950478, "xcomet_score": 0.9024250507354736, "xcomet_qe_score": 0.9239698648452759, "metricx_score": 2.7389562129974365, "metricx_qe_score": 2.2150816917419434, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "fr", "output": "Cinq méthodes ont été utilisées: cheers, cheers single, cheers march, wrestling et grief de étude précédente.", "metrics": {"bleu_score": 14.64087843918566, "chrf_score": 32.39743848863982, "xcomet_score": 0.14435280859470367, "xcomet_qe_score": 0.15146349370479584, "metricx_score": 21.671646118164062, "metricx_qe_score": 22.47109031677246, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "fr", "output": "En ce qui concerne l'aberration, dans certains cas, ces notes sont publiées en plusieurs phrases.", "metrics": {"bleu_score": 43.7596876206843, "chrf_score": 68.72081755995322, "xcomet_score": 0.46853289008140564, "xcomet_qe_score": 0.2637275159358978, "metricx_score": 7.519804954528809, "metricx_qe_score": 9.666024208068848, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné qu'il est difficile de corriger le nombre de phrases à zéro, elles sont combinées avec des espaces et traitées comme une longue phrase.", "metrics": {"bleu_score": 53.31034421473964, "chrf_score": 71.26486623822964, "xcomet_score": 0.5715171098709106, "xcomet_qe_score": 0.5266344547271729, "metricx_score": 8.334120750427246, "metricx_qe_score": 9.547820091247559, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "fr", "output": "Le bureau est pénalisé quand le système émet une courte sentence.", "metrics": {"bleu_score": 11.390778025531022, "chrf_score": 44.16305766839672, "xcomet_score": 0.6420606374740601, "xcomet_qe_score": 0.6922327280044556, "metricx_score": 12.107992172241211, "metricx_qe_score": 12.219696998596191, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "fr", "output": "Cette pénalité entraîne une valeur réelle inférieure, comme le décrivent les résultats de l'expérience ci-après.", "metrics": {"bleu_score": 20.455163269401236, "chrf_score": 58.51822701647622, "xcomet_score": 0.8356450796127319, "xcomet_qe_score": 0.8412340879440308, "metricx_score": 6.303589344024658, "metricx_qe_score": 6.613576412200928, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin, nous corrigeons aussi la spécificité, parce que rouge et bleu ne peuvent pas être corrigés si les lignes ne sont pas vides.", "metrics": {"bleu_score": 17.797644045771207, "chrf_score": 46.810813314219615, "xcomet_score": 0.4523414373397827, "xcomet_qe_score": 0.34967389702796936, "metricx_score": 11.47600269317627, "metricx_qe_score": 10.310200691223145, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "fr", "output": "Une spécificité élevée signifie que les sorties correctes du modèle sont des textes vides, dans les cas où les notes de base sont supposées vides.", "metrics": {"bleu_score": 32.128549679729616, "chrf_score": 63.37139940301161, "xcomet_score": 0.8598763942718506, "xcomet_qe_score": 0.8519411087036133, "metricx_score": 4.68384313583374, "metricx_qe_score": 4.145084381103516, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "fr", "output": "Ici, on est à la troisième.", "metrics": {"bleu_score": 5.522397783539471, "chrf_score": 10.895198987728378, "xcomet_score": 0.13866853713989258, "xcomet_qe_score": 0.13389037549495697, "metricx_score": 13.11387825012207, "metricx_qe_score": 13.823295593261719, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "fr", "output": "Étant donné que l'ensemble de données contient des adresses e-mail, des valeurs de hachage, etc., nous exploitons également l'ensemble de données imprimé, qui les exclut.", "metrics": {"bleu_score": 28.9331164128846, "chrf_score": 57.88863465132075, "xcomet_score": 0.6296981573104858, "xcomet_qe_score": 0.7044875621795654, "metricx_score": 8.063446998596191, "metricx_qe_score": 7.684967994689941, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "fr", "output": "CEA et CEA ont obtenu des scores de Louis L de plus de dix points supérieurs à ceux des lignes de base.", "metrics": {"bleu_score": 32.920103612911184, "chrf_score": 54.74447154744387, "xcomet_score": 0.12645110487937927, "xcomet_qe_score": 0.15191298723220825, "metricx_score": 14.33095645904541, "metricx_qe_score": 14.604835510253906, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "fr", "output": "En particulier, sur le jeu de tests de client, l'écart de score entre la méthode proposée et la ligne de base a augmenté de plus de 20 points.", "metrics": {"bleu_score": 37.8878212033196, "chrf_score": 63.68012695817673, "xcomet_score": 0.43712854385375977, "xcomet_qe_score": 0.38376423716545105, "metricx_score": 7.36264705657959, "metricx_qe_score": 6.264571666717529, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "fr", "output": "Ces résultats indiquent qu'elle l'est et qu'elle est significativement efficace.", "metrics": {"bleu_score": 13.215955651112736, "chrf_score": 42.30220439612125, "xcomet_score": 0.1307176649570465, "xcomet_qe_score": 0.13421711325645447, "metricx_score": 17.711017608642578, "metricx_qe_score": 13.154781341552734, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "fr", "output": "GAS a un meilleur score de base que GAS, ce qui suggère que la combinaison d'un classificateur et d'un générateur est efficace et que la formation du classificateur à l'aide de sous-titres.", "metrics": {"bleu_score": 51.41181436095541, "chrf_score": 70.56877612370671, "xcomet_score": 0.16472136974334717, "xcomet_qe_score": 0.1487724334001541, "metricx_score": 19.472206115722656, "metricx_qe_score": 19.51175308227539, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "fr", "output": "Une couverture élevée des CAL peut être obtenue correctement parce que le classificateur peut se concentrer sur la sélection de messages de comité pertinents pour chaque classe.", "metrics": {"bleu_score": 48.46180202807096, "chrf_score": 75.77345594979356, "xcomet_score": 0.5633598566055298, "xcomet_qe_score": 0.5376624464988708, "metricx_score": 8.078415870666504, "metricx_qe_score": 7.39665412902832, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "fr", "output": "Elle a beaucoup tendance à être plus riche que seule.", "metrics": {"bleu_score": 4.035011337465489, "chrf_score": 20.5937030916988, "xcomet_score": 0.14320948719978333, "xcomet_qe_score": 0.14876332879066467, "metricx_score": 23.75467872619629, "metricx_qe_score": 23.750457763671875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "fr", "output": "suggérant qu'il est également efficace de développer indépendamment des modèles de résumé abstraits différents pour chaque pièce, note, classe.", "metrics": {"bleu_score": 38.58862439751674, "chrf_score": 67.78579126046276, "xcomet_score": 0.4930550754070282, "xcomet_qe_score": 0.3197759687900543, "metricx_score": 11.383563995361328, "metricx_qe_score": 9.188858985900879, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "fr", "output": "héros et éronasis.", "metrics": {"bleu_score": 12.44023474812678, "chrf_score": 8.254135499237094, "xcomet_score": 0.11043250560760498, "xcomet_qe_score": 0.11067400127649307, "metricx_score": 23.360706329345703, "metricx_qe_score": 25.0, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "fr", "output": "Les méthodes de Shear ont tendance à produire des phrases plus courtes que les phrases de référence humaine.", "metrics": {"bleu_score": 70.42311846346826, "chrf_score": 90.9254891601162, "xcomet_score": 0.5874277353286743, "xcomet_qe_score": 0.5216825604438782, "metricx_score": 10.561103820800781, "metricx_qe_score": 12.867878913879395, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "fr", "output": "Dans la figure de droite, la phrase de référence a trois ou quatre phrases tandis que la sienne n'a qu'une seule.", "metrics": {"bleu_score": 64.75302235948476, "chrf_score": 83.29884811212519, "xcomet_score": 0.6649414300918579, "xcomet_qe_score": 0.4459579885005951, "metricx_score": 7.67132568359375, "metricx_qe_score": 7.73118257522583, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "fr", "output": "La raison de cette moindre réticence est que, dans les données de formation, seulement 33 % des phrases sont présentes au niveau des caractéristiques et 40 % au niveau des applications.", "metrics": {"bleu_score": 28.243525032576773, "chrf_score": 50.47851365502611, "xcomet_score": 0.4800184965133667, "xcomet_qe_score": 0.45267120003700256, "metricx_score": 7.206843376159668, "metricx_qe_score": 7.593967914581299, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "fr", "output": "En outre, les méthodes de C. S. A. ne peuvent pas générer des notes de résumé précises sans informations supplémentaires.", "metrics": {"bleu_score": 51.249480270291265, "chrf_score": 84.70740829628237, "xcomet_score": 0.7479274868965149, "xcomet_qe_score": 0.8131549954414368, "metricx_score": 4.539999008178711, "metricx_qe_score": 4.7812042236328125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple supérieur à droite est un exemple d'un message de commutation très désordonné, et la phrase complète ne peut pas être générée sans référence au prélude ou à la question correspondante.", "metrics": {"bleu_score": 50.04486500055368, "chrf_score": 72.64721466595999, "xcomet_score": 0.6125427484512329, "xcomet_qe_score": 0.5818933844566345, "metricx_score": 7.664946556091309, "metricx_qe_score": 6.281600475311279, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "fr", "output": "L'exemple ci-dessous montre que les deux messages committés dans l'entrée sont liés et devraient être combinés en une phrase, mais cela ne le fait pas.", "metrics": {"bleu_score": 51.97294810870306, "chrf_score": 73.35161193075551, "xcomet_score": 0.8373467922210693, "xcomet_qe_score": 0.8804285526275635, "metricx_score": 7.059130668640137, "metricx_qe_score": 6.924714088439941, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "fr", "output": "Enfin une conclusion.", "metrics": {"bleu_score": 16.70067963244422, "chrf_score": 47.84397202861422, "xcomet_score": 0.9810041189193726, "xcomet_qe_score": 1.0, "metricx_score": 1.931408166885376, "metricx_qe_score": 1.9700369834899902, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons construit un nouveau décor pour la génération de pièces automatiques.", "metrics": {"bleu_score": 17.817371610898217, "chrf_score": 56.381115721273076, "xcomet_score": 0.45810094475746155, "xcomet_qe_score": 0.5376487970352173, "metricx_score": 11.327239036560059, "metricx_qe_score": 10.802754402160645, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons également pour moi la tâche d'entrer des messages de comité et de les résumer de manière à ce qu'ils s'appliquent à tous les projets écrits en anglais.", "metrics": {"bleu_score": 34.758221480506116, "chrf_score": 56.93531800103183, "xcomet_score": 0.5734657645225525, "xcomet_qe_score": 0.573137640953064, "metricx_score": 7.513063907623291, "metricx_qe_score": 8.13036823272705, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "fr", "output": "Nos expériences ont montré que la méthode proposée générait moins de bruit et une couverture plus élevée que les lignes de base.", "metrics": {"bleu_score": 35.13874939965221, "chrf_score": 63.510449066271576, "xcomet_score": 0.7138723134994507, "xcomet_qe_score": 0.7159329652786255, "metricx_score": 5.915040493011475, "metricx_qe_score": 5.347504615783691, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "fr", "output": "Veuillez vérifier si c'est sur GitHub.", "metrics": {"bleu_score": 26.269098944241588, "chrf_score": 42.78971375750962, "xcomet_score": 0.8421192169189453, "xcomet_qe_score": 0.8861340284347534, "metricx_score": 5.617103576660156, "metricx_qe_score": 6.058170318603516, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "fr", "output": "Merci beaucoup!", "metrics": {"bleu_score": 0.0, "chrf_score": 42.46447951555532, "xcomet_score": 0.9960094690322876, "xcomet_qe_score": 1.0, "metricx_score": 0.16409055888652802, "metricx_qe_score": 0.3364661931991577, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "fr", "output": "Hello, mais il est bien, il est un Ferrari.", "metrics": {"bleu_score": 3.3864985683445354, "chrf_score": 17.673024586267495, "xcomet_score": 0.09649908542633057, "xcomet_qe_score": 0.10030081123113632, "metricx_score": 24.418643951416016, "metricx_qe_score": 25.0, "linguapy_score": [1, "ITALIAN"]}}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "fr", "output": "And I will present our paper, Future tabular data enrichment using fine tuned transformers architectures.", "metrics": {"bleu_score": 1.7042146160049085, "chrf_score": 31.418830136723862, "xcomet_score": 0.6894456148147583, "xcomet_qe_score": 0.8092246651649475, "metricx_score": 16.781505584716797, "metricx_qe_score": 13.046704292297363, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "fr", "output": "Est-ce qu'un scientifique analyse des données et se concentre principalement sur la démanipulation des caractéristiques existantes des données?", "metrics": {"bleu_score": 17.636478563502965, "chrf_score": 73.30338958205681, "xcomet_score": 0.36282598972320557, "xcomet_qe_score": 0.24924027919769287, "metricx_score": 11.278154373168945, "metricx_qe_score": 14.645491600036621, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "fr", "output": "Mais parfois, ses caractéristiques sont limitées.", "metrics": {"bleu_score": 34.57207846419412, "chrf_score": 62.1161615141463, "xcomet_score": 0.9521632194519043, "xcomet_qe_score": 0.9524307250976562, "metricx_score": 1.1204359531402588, "metricx_qe_score": 0.6555015444755554, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "fr", "output": "La génération future utilisant une autre source de données peut ajouter des informations substantielles.", "metrics": {"bleu_score": 72.1350012406248, "chrf_score": 85.49566914592236, "xcomet_score": 0.7932543754577637, "xcomet_qe_score": 0.8249595761299133, "metricx_score": 5.92153787612915, "metricx_qe_score": 6.14050817489624, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "fr", "output": "Notre objectif de recherche est l'enrichissement automatique des données tabulaires en utilisant des sources externes libres de texte.", "metrics": {"bleu_score": 56.959884327614716, "chrf_score": 91.32033615569618, "xcomet_score": 0.9817912578582764, "xcomet_qe_score": 0.9877548813819885, "metricx_score": 1.1527621746063232, "metricx_qe_score": 0.9926407933235168, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "fr", "output": "Supposons que nous ayons un ensemble de données tabulaire et une base de connaissances.", "metrics": {"bleu_score": 50.389204852596336, "chrf_score": 84.80860816183377, "xcomet_score": 0.997411847114563, "xcomet_qe_score": 1.0, "metricx_score": 0.9825718402862549, "metricx_qe_score": 1.1273525953292847, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons besoin d'un processus automatique, qui implique l'entité de lien et l'analyse de texte, pour extraire de nouvelles caractéristiques du texte libre basé sur la connaissance.", "metrics": {"bleu_score": 38.10048863884788, "chrf_score": 73.6162016869877, "xcomet_score": 0.6504546403884888, "xcomet_qe_score": 0.6153547167778015, "metricx_score": 8.04781436920166, "metricx_qe_score": 7.792698860168457, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "fr", "output": "Notre framework, first, is exactly this automatic process. Notre cadre, first, is exactly this automatic process.", "metrics": {"bleu_score": 3.8229746997386345, "chrf_score": 40.11254341532508, "xcomet_score": 0.1599864363670349, "xcomet_qe_score": 0.21655836701393127, "metricx_score": 25.0, "metricx_qe_score": 21.54896354675293, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, laissez-moi donner un exemple, dans un dataset, on est en train de faire un test.", "metrics": {"bleu_score": 4.553719184146073, "chrf_score": 29.55415786579018, "xcomet_score": 0.21470516920089722, "xcomet_qe_score": 0.1937159150838852, "metricx_score": 9.317895889282227, "metricx_qe_score": 9.43543529510498, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le dataset est un dataset universitaire.", "metrics": {"bleu_score": 24.808415001701817, "chrf_score": 52.90380825510431, "xcomet_score": 0.975731611251831, "xcomet_qe_score": 0.9904412031173706, "metricx_score": 6.415273189544678, "metricx_qe_score": 5.446154594421387, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "fr", "output": "quand son but est de classer les universités en universités de faible rang et universités de haut rang.", "metrics": {"bleu_score": 59.08871032231054, "chrf_score": 75.67633221681083, "xcomet_score": 0.9509234428405762, "xcomet_qe_score": 0.9609610438346863, "metricx_score": 1.756480097770691, "metricx_qe_score": 1.5346523523330688, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "fr", "output": "En tant que base de connaissances, nous utilisons Wikipédia.", "metrics": {"bleu_score": 100.00000000000004, "chrf_score": 100.0, "xcomet_score": 1.0, "xcomet_qe_score": 1.0, "metricx_score": 0.37776264548301697, "metricx_qe_score": 0.43033844232559204, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "fr", "output": "La première phase de Fest est l'entité-linking.", "metrics": {"bleu_score": 29.797147054518835, "chrf_score": 57.71512335598449, "xcomet_score": 0.4699860215187073, "xcomet_qe_score": 0.4380965232849121, "metricx_score": 12.875589370727539, "metricx_qe_score": 15.257429122924805, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "fr", "output": "quand chaque entité, dans cet exemple le nom de l'université, est liée à une entité au sein de la base de connaissances.", "metrics": {"bleu_score": 85.46472208904508, "chrf_score": 90.45180564091355, "xcomet_score": 0.9555785655975342, "xcomet_qe_score": 0.9293614029884338, "metricx_score": 0.9412853121757507, "metricx_qe_score": 1.0503536462783813, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "fr", "output": "et le texte des entités de la base de connaissances est extrait et ajouté au dataset.", "metrics": {"bleu_score": 75.41859578343532, "chrf_score": 86.5841778912224, "xcomet_score": 0.9242388010025024, "xcomet_qe_score": 0.926859438419342, "metricx_score": 5.127912998199463, "metricx_qe_score": 5.583958148956299, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le texte est l'abstrait de la page de Wikipédia.", "metrics": {"bleu_score": 57.3122448409426, "chrf_score": 76.4392118763421, "xcomet_score": 0.9672919511795044, "xcomet_qe_score": 0.9720434546470642, "metricx_score": 3.119382381439209, "metricx_qe_score": 1.6899539232254028, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "fr", "output": "Maintenant, nous devons générer ou extraire des caractéristiques du texte récupéré.", "metrics": {"bleu_score": 53.69787816169342, "chrf_score": 65.77794216507486, "xcomet_score": 0.9783259630203247, "xcomet_qe_score": 1.0, "metricx_score": 2.0327789783477783, "metricx_qe_score": 1.393066167831421, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "fr", "output": "Donc on a besoin d'une phase d'extraction de fonctionnalité qui inclut l'analyse de texte.", "metrics": {"bleu_score": 20.255556775654846, "chrf_score": 57.99965481897983, "xcomet_score": 0.890211820602417, "xcomet_qe_score": 0.7891403436660767, "metricx_score": 4.065990447998047, "metricx_qe_score": 4.573938369750977, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "fr", "output": "et c'est la nouveauté de ce papier et je vais plonger profondément dans la prochaine page.", "metrics": {"bleu_score": 10.702981958567012, "chrf_score": 36.655980054259835, "xcomet_score": 0.45878586173057556, "xcomet_qe_score": 0.4518892765045166, "metricx_score": 10.599380493164062, "metricx_qe_score": 8.925027847290039, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "fr", "output": "Après la phase d'extraction de fonctionnalités, il y a la phase de génération de fonctionnalités, où nous utilisons les fonctionnalités extraites pour générer un petit nombre de nouvelles fonctionnalités.", "metrics": {"bleu_score": 47.76629322522497, "chrf_score": 81.7438842448554, "xcomet_score": 0.9926199913024902, "xcomet_qe_score": 0.9994075298309326, "metricx_score": 1.0820728540420532, "metricx_qe_score": 1.2832980155944824, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "fr", "output": "Générer des caractéristiques dans le nombre de classes de l'ensemble de données original.", "metrics": {"bleu_score": 29.89950354998137, "chrf_score": 55.47075845122216, "xcomet_score": 0.632808268070221, "xcomet_qe_score": 0.875696063041687, "metricx_score": 5.393084526062012, "metricx_qe_score": 5.930908203125, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "fr", "output": "Dans cet exemple, le jeu de données original a deux classes.", "metrics": {"bleu_score": 28.917849332325716, "chrf_score": 68.75565832191802, "xcomet_score": 0.9794766902923584, "xcomet_qe_score": 0.9230731725692749, "metricx_score": 1.34528386592865, "metricx_qe_score": 1.899640440940857, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, il faut d'abord générer deux nouvelles fonctionnalités.", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 52.0967123535957, "xcomet_score": 0.30506253242492676, "xcomet_qe_score": 0.40226396918296814, "metricx_score": 11.884876251220703, "metricx_qe_score": 11.009957313537598, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "fr", "output": "Mais si le jeu de données a cinq classes, il faut d'abord générer cinq nouvelles fonctionnalités.", "metrics": {"bleu_score": 12.512236921161914, "chrf_score": 61.353754671853224, "xcomet_score": 0.6135275363922119, "xcomet_qe_score": 0.5188561677932739, "metricx_score": 9.962177276611328, "metricx_qe_score": 9.1939058303833, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "fr", "output": "Chaque caractéristique représente la probabilité pour chaque classe.", "metrics": {"bleu_score": 75.06238537503395, "chrf_score": 78.89231057183392, "xcomet_score": 0.9665066003799438, "xcomet_qe_score": 1.0, "metricx_score": 1.271324634552002, "metricx_qe_score": 1.2625250816345215, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "fr", "output": "Pour analyser le texte, nous utilisons l'état actuel de l'art de l'analyse de texte, qui sont des modèles de langage basés sur des transformateurs, SBS, GPT, Excel, etc.", "metrics": {"bleu_score": 37.838485456537555, "chrf_score": 61.66141443477383, "xcomet_score": 0.621625542640686, "xcomet_qe_score": 0.5436036586761475, "metricx_score": 11.494078636169434, "metricx_qe_score": 11.776338577270508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "fr", "output": "mais ce n'est pas probable que nous puissions former un modèle de langage en utilisant les données d'entrée.", "metrics": {"bleu_score": 31.669349232191585, "chrf_score": 67.05175411382402, "xcomet_score": 0.9252520799636841, "xcomet_qe_score": 0.9030171632766724, "metricx_score": 4.158023834228516, "metricx_qe_score": 4.601045608520508, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "fr", "output": "Donc une approche naïve sera un ajustement fin de la tâche cible.", "metrics": {"bleu_score": 48.44273237963865, "chrf_score": 65.64708417366839, "xcomet_score": 0.9611812829971313, "xcomet_qe_score": 0.8891847133636475, "metricx_score": 3.9226927757263184, "metricx_qe_score": 5.2075676918029785, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "fr", "output": "Donc, dans la phase d'extraction future, nous pouvons télécharger le modèle de langage par tendance, fin tuner le modèle de langage sur le jeu de données cible", "metrics": {"bleu_score": 15.337871109155067, "chrf_score": 61.75355723582066, "xcomet_score": 0.4692225456237793, "xcomet_qe_score": 0.37770286202430725, "metricx_score": 11.46567440032959, "metricx_qe_score": 12.085371017456055, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "fr", "output": "dans cet exemple pour fin tuner le langage model pour classer le texte en classes, abstraits en classes, low ou high", "metrics": {"bleu_score": 28.025206995655843, "chrf_score": 54.42934873997917, "xcomet_score": 0.3157541751861572, "xcomet_qe_score": 0.34691521525382996, "metricx_score": 17.1287841796875, "metricx_qe_score": 18.587533950805664, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "fr", "output": "Recevez la sortie du modèle de langage, qui est la probabilité pour chaque classe, et utilisez ses nouvelles fonctionnalités.", "metrics": {"bleu_score": 25.376192011638008, "chrf_score": 62.91720547302133, "xcomet_score": 0.7177097797393799, "xcomet_qe_score": 0.7617600560188293, "metricx_score": 2.9589483737945557, "metricx_qe_score": 2.249695062637329, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "fr", "output": "Le problème avec cette approche est que les ensembles de données peuvent avoir quelques tags d'entités distinctes.", "metrics": {"bleu_score": 39.63844376774479, "chrf_score": 74.55342462828719, "xcomet_score": 0.8345526456832886, "xcomet_qe_score": 0.8510693311691284, "metricx_score": 7.652609825134277, "metricx_qe_score": 6.623343467712402, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre expérience, presque la moitié des ensembles de données contiennent moins de 400 échantillons et le plus petit d'entre eux contient 35 échantillons dans son ensemble d'entraînement.", "metrics": {"bleu_score": 23.1834539013154, "chrf_score": 64.4160415588917, "xcomet_score": 0.9273560047149658, "xcomet_qe_score": 0.9483253359794617, "metricx_score": 1.3267468214035034, "metricx_qe_score": 1.076185703277588, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "fr", "output": "Donc pour finir de régler un modèle linguistique sur ce jeu de données, ce sera inefficace.", "metrics": {"bleu_score": 6.256118460580956, "chrf_score": 48.51403933203241, "xcomet_score": 0.7171674966812134, "xcomet_qe_score": 0.7342778444290161, "metricx_score": 5.578668594360352, "metricx_qe_score": 6.257631778717041, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "fr", "output": "mais nous pouvons utiliser des connaissances préalables sur des données préanalysées", "metrics": {"bleu_score": 81.55395405382076, "chrf_score": 97.50898464883025, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9823999404907227, "metricx_score": 0.7983390092849731, "metricx_qe_score": 1.3284237384796143, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "fr", "output": "Parce que c'est rapide, on peut appliquer des données multiples, on peut utiliser les données n+1 pour collecter des informations sur les données n+1 et utiliser cette information pour analyser les données n+1", "metrics": {"bleu_score": 25.069449381435252, "chrf_score": 54.72368494793318, "xcomet_score": 0.5528140664100647, "xcomet_qe_score": 0.6033313274383545, "metricx_score": 8.936544418334961, "metricx_qe_score": 7.536127090454102, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "fr", "output": "ce que nous suggérons est d'ajouter une autre phase de réglage fin", "metrics": {"bleu_score": 39.01103647256417, "chrf_score": 73.24033869552068, "xcomet_score": 0.8517938852310181, "xcomet_qe_score": 0.7432973384857178, "metricx_score": 3.9144110679626465, "metricx_qe_score": 1.934777021408081, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "fr", "output": "et préliminaires multitask fine tuning phase.", "metrics": {"bleu_score": 7.809849842300637, "chrf_score": 44.28252814260101, "xcomet_score": 0.2533422112464905, "xcomet_qe_score": 0.44837135076522827, "metricx_score": 20.99101448059082, "metricx_qe_score": 18.989282608032227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "fr", "output": "quand on fait le modèle linguistique sur les ensembles de données", "metrics": {"bleu_score": 8.93094818591774, "chrf_score": 39.37674967565538, "xcomet_score": 0.23598229885101318, "xcomet_qe_score": 0.42166563868522644, "metricx_score": 15.356748580932617, "metricx_qe_score": 15.46551513671875, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "fr", "output": "Et puis on exécute une autre phase de finition qui est une phase de finition ciblée quand on trouve le modèle de langage sur le dernier ensemble de données.", "metrics": {"bleu_score": 13.532043663194468, "chrf_score": 41.67796722020008, "xcomet_score": 0.44186216592788696, "xcomet_qe_score": 0.43441274762153625, "metricx_score": 7.896827697753906, "metricx_qe_score": 7.766826629638672, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "fr", "output": "L'état de l'art dans le multitasking fine-tuning, appelé MTDN.", "metrics": {"bleu_score": 4.9323515694897075, "chrf_score": 35.18784238881294, "xcomet_score": 0.6806478500366211, "xcomet_qe_score": 0.7509607076644897, "metricx_score": 8.926514625549316, "metricx_qe_score": 9.308460235595703, "linguapy_score": [1, "NYNORSK"]}}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "fr", "output": "En MTDN, on maintient des têtes dans le nombre de tâches dans le set de formation.", "metrics": {"bleu_score": 41.180376356915765, "chrf_score": 71.99301764800565, "xcomet_score": 0.4047950208187103, "xcomet_qe_score": 0.4553752541542053, "metricx_score": 11.075763702392578, "metricx_qe_score": 14.203214645385742, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "fr", "output": "Donc dans cet exemple, il y a 4 tâches dans le set de training, donc empty dnn, maintain 4 heads, comme vous pouvez voir à l'image", "metrics": {"bleu_score": 27.72817600273212, "chrf_score": 44.769704985210886, "xcomet_score": 0.422319620847702, "xcomet_qe_score": 0.5234770774841309, "metricx_score": 13.805356979370117, "metricx_qe_score": 14.203733444213867, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "fr", "output": "et il s'appelle un badge de la formation.", "metrics": {"bleu_score": 9.600960275119885, "chrf_score": 27.03992641246285, "xcomet_score": 0.12736356258392334, "xcomet_qe_score": 0.10438941419124603, "metricx_score": 16.938234329223633, "metricx_qe_score": 16.239486694335938, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le runner badge appartient à, par exemple, singleton's classification tasks, il est exécuté pour and backward pass through the first head.", "metrics": {"bleu_score": 10.179259729998483, "chrf_score": 36.731429604310485, "xcomet_score": 0.1614995002746582, "xcomet_qe_score": 0.22212131321430206, "metricx_score": 23.091014862060547, "metricx_qe_score": 20.831480026245117, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "fr", "output": "Et si le batch de random est destiné à la rançonnage, la tâche est de faire passer le bac en arrière par la dernière tête.", "metrics": {"bleu_score": 15.955799528969331, "chrf_score": 34.1033640891997, "xcomet_score": 0.19373230636119843, "xcomet_qe_score": 0.23174680769443512, "metricx_score": 19.158445358276367, "metricx_qe_score": 18.818754196166992, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre scénario, tableau, dataset, et row sont le nombre de classes.", "metrics": {"bleu_score": 38.35193624233828, "chrf_score": 55.22684711274556, "xcomet_score": 0.3985796272754669, "xcomet_qe_score": 0.4989500343799591, "metricx_score": 18.419178009033203, "metricx_qe_score": 20.09739112854004, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "fr", "output": "Donc il y a beaucoup de tâches.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 72.4645837254533, "xcomet_score": 0.9912000298500061, "xcomet_qe_score": 0.9911999702453613, "metricx_score": 0.6619732975959778, "metricx_qe_score": 1.0443570613861084, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "fr", "output": "MTDN maintient un nombre de classes de têtes, de couches de sortie", "metrics": {"bleu_score": 24.450989066362567, "chrf_score": 65.86359928125827, "xcomet_score": 0.5222697854042053, "xcomet_qe_score": 0.6078832149505615, "metricx_score": 7.05128288269043, "metricx_qe_score": 8.035432815551758, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "fr", "output": "Et de plus, MTDN a besoin d'initier de nouvelles têtes pour un nouveau jeu de données avec une nouvelle tâche.", "metrics": {"bleu_score": 34.53064989552127, "chrf_score": 62.075550841138806, "xcomet_score": 0.5921952724456787, "xcomet_qe_score": 0.5321980118751526, "metricx_score": 5.892040729522705, "metricx_qe_score": 6.676793098449707, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "fr", "output": "Dans notre approche, au lieu de maintenir plusieurs têtes, nous reformulons chaque dataset en une phrase par problème de classification, qui est deux classes de tâches.", "metrics": {"bleu_score": 30.491326867385705, "chrf_score": 55.09976954521086, "xcomet_score": 0.5440280437469482, "xcomet_qe_score": 0.5399658679962158, "metricx_score": 9.57858657836914, "metricx_qe_score": 10.521937370300293, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "fr", "output": "Alors, voyons un exemple.", "metrics": {"bleu_score": 30.213753973567677, "chrf_score": 46.04927041293183, "xcomet_score": 0.9384474754333496, "xcomet_qe_score": 0.9470594525337219, "metricx_score": 0.4609590768814087, "metricx_qe_score": 0.4758671522140503, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "fr", "output": "Voici notre ensemble de données d'entrée qui se compose d'entités, de fonctionnalités, de textes et de classes.", "metrics": {"bleu_score": 22.423870508323304, "chrf_score": 71.07896691938859, "xcomet_score": 0.9587031602859497, "xcomet_qe_score": 0.9811974763870239, "metricx_score": 1.998420000076294, "metricx_qe_score": 2.469846487045288, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "fr", "output": "et nous reformulons la tâche de classifier le texte en bas et haut pour classer le texte, l'abstrait et la classe en vrai ou faux.", "metrics": {"bleu_score": 50.802763012721854, "chrf_score": 69.41745996331025, "xcomet_score": 0.49824607372283936, "xcomet_qe_score": 0.48154690861701965, "metricx_score": 7.032773494720459, "metricx_qe_score": 6.366025447845459, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "fr", "output": "En d'autres termes, nous avons formé le modèle linguistique pour classer les abstraits en classes, si l'abstrait appartient à la classe ou non.", "metrics": {"bleu_score": 33.548043365407445, "chrf_score": 57.20359165150535, "xcomet_score": 0.6271345615386963, "xcomet_qe_score": 0.46490901708602905, "metricx_score": 8.466468811035156, "metricx_qe_score": 8.896249771118164, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "fr", "output": "Donc le vecteur de label dans ce cas reste toujours avec deux classes.", "metrics": {"bleu_score": 21.35901256790989, "chrf_score": 57.087920957894646, "xcomet_score": 0.8842864036560059, "xcomet_qe_score": 0.8473944067955017, "metricx_score": 7.592473983764648, "metricx_qe_score": 7.8594160079956055, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "fr", "output": "Et c'est l'algorithme pour notre approche de finissage réformulée.", "metrics": {"bleu_score": 14.320952289897711, "chrf_score": 53.86217035959234, "xcomet_score": 0.8022003173828125, "xcomet_qe_score": 0.6984080672264099, "metricx_score": 5.977597236633301, "metricx_qe_score": 7.152987480163574, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "fr", "output": "Alors voyons voir le cadre complet.", "metrics": {"bleu_score": 41.11336169005198, "chrf_score": 73.00081363093499, "xcomet_score": 0.9050922989845276, "xcomet_qe_score": 0.8617420792579651, "metricx_score": 1.3151394128799438, "metricx_qe_score": 3.630525827407837, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "fr", "output": "et ça se met vraiment en fait", "metrics": {"bleu_score": 0.0, "chrf_score": 8.73978017460009, "xcomet_score": 0.1111307218670845, "xcomet_qe_score": 0.08719023317098618, "metricx_score": 8.785429000854492, "metricx_qe_score": 15.005504608154297, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "fr", "output": "et puis, on exécute en phase de relance.", "metrics": {"bleu_score": 9.980099403873663, "chrf_score": 31.90925803432694, "xcomet_score": 0.14378967881202698, "xcomet_qe_score": 0.1658135950565338, "metricx_score": 17.47300910949707, "metricx_qe_score": 19.179302215576172, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "fr", "output": "extraire le texte de la base de la connaissance qui dans cet exemple est l'abstraction de la page de Wikipédia.", "metrics": {"bleu_score": 45.85015057701145, "chrf_score": 71.38751530975675, "xcomet_score": 0.6342122554779053, "xcomet_qe_score": 0.6618309617042542, "metricx_score": 9.894587516784668, "metricx_qe_score": 9.125321388244629, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "fr", "output": "puis il reformule la tâche en tasks de classification par phrase", "metrics": {"bleu_score": 11.059312504429313, "chrf_score": 49.171712905461234, "xcomet_score": 0.6848095059394836, "xcomet_qe_score": 0.7072134017944336, "metricx_score": 9.692031860351562, "metricx_qe_score": 10.75833797454834, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "fr", "output": "appliqué le modèle de langage à la nouvelle tâche et la probabilité de sortie pour chaque classe", "metrics": {"bleu_score": 69.42566745278681, "chrf_score": 91.51680850106328, "xcomet_score": 0.7891201376914978, "xcomet_qe_score": 0.6999766826629639, "metricx_score": 3.929292678833008, "metricx_qe_score": 4.441644668579102, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "fr", "output": "Notez que le modèle de langage est déjà fin tuné sur un ensemble de données N-1 en utilisant un préalable multitasking fin tuning.", "metrics": {"bleu_score": 12.384901282810546, "chrf_score": 44.63288205230593, "xcomet_score": 0.39237767457962036, "xcomet_qe_score": 0.3782157897949219, "metricx_score": 9.636307716369629, "metricx_qe_score": 9.39651107788086, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "fr", "output": "Puis, nous utilisons le vecteur de sortie du modèle de langage, comme une fonctionnalité nouvellement générée dans le nombre de classes.", "metrics": {"bleu_score": 68.7941939352187, "chrf_score": 88.3573344194023, "xcomet_score": 0.8506543040275574, "xcomet_qe_score": 0.735994815826416, "metricx_score": 4.680022239685059, "metricx_qe_score": 5.965600967407227, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "fr", "output": "Pour évaluer notre cadre, nous utilisons un ensemble de données de classification 17 tabulaires, qui varient en taille, caractéristiques, équilibre de domaine et performance initiale.", "metrics": {"bleu_score": 49.3995038439672, "chrf_score": 79.13945300390374, "xcomet_score": 0.7054274082183838, "xcomet_qe_score": 0.667363166809082, "metricx_score": 7.922660827636719, "metricx_qe_score": 7.808799743652344, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "fr", "output": "et comme base de connaissances, nous utilisons Wikipedia.", "metrics": {"bleu_score": 43.98917247584221, "chrf_score": 75.78095972291328, "xcomet_score": 0.9795872569084167, "xcomet_qe_score": 0.9819538593292236, "metricx_score": 0.5033841133117676, "metricx_qe_score": 0.4938074052333832, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "fr", "output": "Nous concevons notre expérience comme une évaluation live one out, quand nous entraînons vite plus de 16 ensembles de données et l'appliquons au 17e ensemble de données.", "metrics": {"bleu_score": 25.214324243688417, "chrf_score": 62.930643107411875, "xcomet_score": 0.15454217791557312, "xcomet_qe_score": 0.187747985124588, "metricx_score": 12.429526329040527, "metricx_qe_score": 12.54780101776123, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "fr", "output": "Nous avons aussi divisé les données en quatre fausses et en quatre fausses validations de croix.", "metrics": {"bleu_score": 6.256118460580956, "chrf_score": 37.487055463395826, "xcomet_score": 0.39785122871398926, "xcomet_qe_score": 0.5015929937362671, "metricx_score": 17.498291015625, "metricx_qe_score": 16.15245246887207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "fr", "output": "Puis, nous générons la nouvelle fonctionnalité et nous les évaluons en utilisant 5 classificateurs d'évaluation.", "metrics": {"bleu_score": 27.098211583470043, "chrf_score": 73.72463553882105, "xcomet_score": 0.9173153042793274, "xcomet_qe_score": 0.9258841872215271, "metricx_score": 2.9449000358581543, "metricx_qe_score": 3.965834856033325, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "fr", "output": "Nous utilisons dans notre architecture basée sur l'expérience, la naissance.", "metrics": {"bleu_score": 8.930069801473408, "chrf_score": 37.236586902850526, "xcomet_score": 0.16179803013801575, "xcomet_qe_score": 0.29062896966934204, "metricx_score": 21.120853424072266, "metricx_qe_score": 18.33067512512207, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "fr", "output": "Voici les résultats de notre expérience.", "metrics": {"bleu_score": 43.47208719449914, "chrf_score": 82.16212638893361, "xcomet_score": 0.9823514223098755, "xcomet_qe_score": 0.9937252998352051, "metricx_score": 0.3568568527698517, "metricx_qe_score": 0.5269936919212341, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "fr", "output": "Vous pouvez voir que nous comparons notre framework à Target Dataset Fine Tuning et MTDN Preliminary Fine Tuning", "metrics": {"bleu_score": 21.121537610047792, "chrf_score": 37.88564374125085, "xcomet_score": 0.6938014626502991, "xcomet_qe_score": 0.8075504899024963, "metricx_score": 10.059675216674805, "metricx_qe_score": 12.21077823638916, "linguapy_score": [1, "ENGLISH"]}}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "fr", "output": "Et notre réformulation fine tuning a obtenu le meilleur résultat, la meilleure performance.", "metrics": {"bleu_score": 26.518122980477767, "chrf_score": 65.32916984165225, "xcomet_score": 0.8109208941459656, "xcomet_qe_score": 0.774645209312439, "metricx_score": 6.358620643615723, "metricx_qe_score": 6.500133037567139, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "fr", "output": "Alors que MTDNN a obtenu une amélioration de 2% par rapport au fine-tuning des ensembles de données cibles,", "metrics": {"bleu_score": 35.705835125874, "chrf_score": 66.18563796300872, "xcomet_score": 0.7163457274436951, "xcomet_qe_score": 0.7793146371841431, "metricx_score": 5.130762100219727, "metricx_qe_score": 4.519348621368408, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "fr", "output": "Notre poche a obtenu une amélioration de 6%.", "metrics": {"bleu_score": 38.66252716278829, "chrf_score": 64.36899807256871, "xcomet_score": 0.7006017565727234, "xcomet_qe_score": 0.7288292050361633, "metricx_score": 13.715343475341797, "metricx_qe_score": 13.8175630569458, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "fr", "output": "Quand on regarde le petit dataset, on peut voir que la performance de MTDN diminue et l'amélioration de la phase de finition préalable diminue à 1,5%.", "metrics": {"bleu_score": 25.395034602400433, "chrf_score": 44.142094179291966, "xcomet_score": 0.5174403786659241, "xcomet_qe_score": 0.654728889465332, "metricx_score": 8.237247467041016, "metricx_qe_score": 8.189064025878906, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "fr", "output": "mais notre performance a augmenté à 11% comparé à la tâche cible fine tuning seule", "metrics": {"bleu_score": 25.576360687094816, "chrf_score": 57.82311431475262, "xcomet_score": 0.6320250034332275, "xcomet_qe_score": 0.6474626660346985, "metricx_score": 7.340288162231445, "metricx_qe_score": 9.463438987731934, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "fr", "output": "Pour le summing, Fast enables le view shot enrichment, à partir de 35 échantillons dans notre expérience.", "metrics": {"bleu_score": 10.079037376973913, "chrf_score": 43.007843615524, "xcomet_score": 0.2729552984237671, "xcomet_qe_score": 0.3566582500934601, "metricx_score": 20.394363403320312, "metricx_qe_score": 18.00726890563965, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "fr", "output": "Il utilise une architecture pour tous les ensembles de données de tâches.", "metrics": {"bleu_score": 33.495318896976464, "chrf_score": 75.42593815170618, "xcomet_score": 0.9868813753128052, "xcomet_qe_score": 0.9803872108459473, "metricx_score": 3.605736017227173, "metricx_qe_score": 3.802783966064453, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "fr", "output": "et il garde la tête du modèle.", "metrics": {"bleu_score": 84.08964152537145, "chrf_score": 95.31916500738012, "xcomet_score": 0.8584520816802979, "xcomet_qe_score": 0.533896803855896, "metricx_score": 4.091800689697266, "metricx_qe_score": 5.7462477684021, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "fr", "output": "mais il y a une phase de reformulation.", "metrics": {"bleu_score": 44.63236137853326, "chrf_score": 66.26474556585711, "xcomet_score": 0.9304350018501282, "xcomet_qe_score": 0.9254094362258911, "metricx_score": 2.8675005435943604, "metricx_qe_score": 3.809303045272827, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "fr", "output": "Il faut que le train soit plus long et qu'il ait une valeur cible avec un sens sémantique, donc on peut le mettre dans le modèle linguistique et l'utiliser dans le problème de classification des phrases.", "metrics": {"bleu_score": 32.830112894112574, "chrf_score": 58.09156162830348, "xcomet_score": 0.6135993003845215, "xcomet_qe_score": 0.6350373029708862, "metricx_score": 11.3329439163208, "metricx_qe_score": 10.253432273864746, "linguapy_score": [0, "FRENCH"]}}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "fr", "output": "Merci beaucoup!", "metrics": {"bleu_score": 0.0, "chrf_score": 42.46447951555532, "xcomet_score": 0.9960094690322876, "xcomet_qe_score": 1.0, "metricx_score": 0.16409055888652802, "metricx_qe_score": 0.3364661931991577, "linguapy_score": [0, "FRENCH"]}}
