{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle. Heute werde ich unsere Forschungsarbeit Lernen zu reisen deduktiv, Methodenproblemlösung als komplexe Rasen-Extraktion vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Zahl stammt aus dem POWN-Papier, in dem sie Anweisungen zur Lösung des Methodenproblems in einem Fluch-Learning-Szenario ausführen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite können wir sehen, dass wir, wenn wir einige Beispiele nur mit Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch noch mehr Beschreibungen geben, kann das Modell die Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, als Ausgabe interpretierbares Mehrstufenrechnungsverfahren zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken auch, dass ein Methodenproblem eine einfache Anwendung zur Bewertung solcher Argumentationsfähigkeiten ist."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier müssen wir also in unserer Problemkonfiguration, angesichts der Fragen, diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser besonderen Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Größen bekannt ist"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren aufgeteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Eine frühere Arbeit im Lösungsproblem der Methode kann also tatsächlich in Sequenz- und Baummodell kategorisiert werden."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenzmodelle konvertieren den Ausdruck also in eine bestimmte Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ziemlich einfach umzusetzen und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil ist, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell und es fehlt an Interpretabilität für die Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Direction noch ziemlich populär, weil der Transformermodell"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also die Operatoren weiter, bis wir die Lifts erreichen, die die Größen sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt, aber es ist eigentlich ganz entgegengesetzt, weil wir zuerst den Operator generieren und dann am Ende die Größen generieren."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens enthält es auch einige wiederholte Berechnungen."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck hier ansehen, wird acht mal drei plus drei tatsächlich zweimal erzeugt. Aber tatsächlich sollten wir die Ergebnisse verwenden"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und in interpretierbaren Methoden lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diesen Teiler erhalten, der 27 ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir bei diesem dritten Schritt tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Okay. Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schritts tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als unser Anfangszustand ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Operatoren von QY bis QJ aus, und dieser Ausdruck ist tatsächlich gerichtet."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "So, wir haben hier auch Subtraction-Wert, um die entgegengesetzte Richtung zu repräsentieren."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie bei der Strahlungsauffnahme."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es in den nächsten Zustand hinzu, um eine neue Menge zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folien visualisieren also tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zuständen immer wieder Ausdrücke hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Sprachmodell, das Vögel oder Robetts sein kann, und dann kodieren wir den Satz und erhalten diese Mengenrepräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengen darstellen, können wir mit der Schlussfolgerung beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q4 multipliziert wird."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Anweisung, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist. Dann wenden wir ein Fit-Forward-Netzwerk an, das vom Operator parametriert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksrepräsentation Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Schlussfolgerung möglicherweise auch den falschen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier entspricht also jeder möglichen Ausdruck dreimal so viel wie die Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchbereich entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir noch eine Menge mehr haben."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe stammt aus dem vorherigen berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir diesen letzten Ausdruck Q3 erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke von dem vorherigen Schritt unterschiedlich ist."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede machen es schwierig, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsmethode ist ähnlich wie bei der Schulung eines Sequenzmodells, bei dem wir den Verlust bei jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch diese Tao, um darzustellen, wann wir diesen Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz anders, weil der Raum bei jedem Zeitpunkt anders ist, während es im traditionellen Sequenz- zu-Sequenz-Modell die Anzahl des Wortschatzes ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht es uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen zu verhängen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen also Experimente mit den häufig verwendeten Method-Problem-Datensätzen durch, MAWPS, Math23K, MathQA und SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Variante ist also Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir BeamSearch nicht, im Gegensatz zu offensichtlichen Ansätzen mit BeamSearch."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Okay, die besten Ansätze sind oft ein Baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Vernunft also dieses Baumbasierungsmodell deutlich übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MatQuery oder SWAM nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse weiter."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist eine Herausforderung, weil der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. irrelevante Informationen und zusätzliche Mengen hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Also, in unserer Vorhersage finden wir, dass einige der intermediären Werte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Pitchs und Stephen hat acht Pitchs, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse als negativ entfernen, damit wir die Antwort richtig machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert und bei dem Roberta-Basemodell tatsächlich zwei Punkte verbessert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat also bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Bert niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information angesehen werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der ungenutzten Mengen haben und der SWAMP-Datensatz den größten Teil enthält."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen ist die Gesamtleistung tatsächlich höher als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlimmer ist als die, äh, viel schlimmer als."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für MAWPS haben wir nicht wirklich viele Desk-Cases, also ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretationsfähigkeit durch ein Beispiel für die Zusammenstoßpartizierung zeigen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also tatsächlich eine falsche Vorhersage im ersten Schritt."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren, oder?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben also, dass dieser Satz das Modell in eine falsche Vorhersage führen könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man hier also noch 35 plant, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu ändern, dass er so aussieht wie die Anzahl der Birnenfäden fünfundfünfzig weniger ist als die Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen es also so, dass es genauere Semantik vermittelt, damit das Modell die Vorhersage richtig machen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell eigentlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können eine interpretierbare Lösungsmethode bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige vorherige Kenntnisse als Konstrakt einbeziehen, was uns helfen kann, die Leistung zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur für Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch für andere Aufgaben, die mehrtretende Argumentation beinhalten."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung in verschiedenen Zeitzonen unbalanciert ist, daher ist es auch ziemlich schwierig, Beam-Suche anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also das Ende des Vortrags und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Maastricht University."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein Johannes Werk mit Jerry vorstellen, das sich mit einem neuen Datensatz für die Abholung von gesetzlichen Artikeln befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein wesentlicher Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat wenig oder kein Wissen über ihre Rechte und grundlegenden Rechtsverfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Ergebnis sind viele vulnerable Bürger, die sich nicht die kostbare Assistance eines Legal Experts erwarten können, unprotegt oder worstens, exploitiert."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Lücke zwischen Menschen und dem Gesetz zu schließen, indem wir ein effektives Rückholsystem für gesetzliche Artikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte für unqualifizierte Menschen einen kostenlosen professionellen Rechtshilfenservice bieten."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem der statutarischen Artikelabholung."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ich eine einfache Frage zu einem rechtlichen Thema stelle, wie zum Beispiel: Was mache ich, wenn ich die professionelle Vertraulichkeit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetz zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe zur Informationserfassung bringt eine ganze Reihe von Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst geht es um zwei Sprachtypen."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "für die Fragen eine gängige natürliche Sprache und für die Statuten eine komplexe rechtliche Sprache."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in den Sprachverteilungen machen es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die mit der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das gesetzliche Recht kein Stapel unabhängiger Artikel, die als vollständige Informationsquelle an sich behandelt werden können, wie zum Beispiel Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Insted ist es eine Strukturkollektion von legalen Provisionen, die nur in der allgemeinen Kontext betrachtet sind, zusammen mit den zusätzlichen Informationen aus den neighbouring Artikeln, den Feldern und Subfeldern, zu denen sie gehören, und ihrer Platz in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, statutory Articles RN small paragraph, was usuell die typische Retrieval Unit in Most Retrieval Works ist."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Jahre dauern können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich NLP haben großes Interesse an vielen rechtlichen Aufgaben wie der Vorhersage von Rechtsentscheidungen oder der automatisierten Überprüfung von Vertragsverträgen weckt."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabholung ist jedoch aufgrund des Mangels an großen und hochwertigen gekennzeichneten Datensätzen größtenteils unberührt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir ein neues französisches, zentrales, zentrales Datenkett, um zu untersuchen, ob ein Rückholmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten für die Aufgabe der Statutorienartikelrückholung nähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Our Belgian Statutory Article Retrieval Data Sets consist von mehr als einem Jahrzehnt Liter."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnraum, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen hat von erfahrenen Juristen mit Referenzen zu relevanten Artikeln aus einem Corpus von mehr als twenty zwei Tausend sechshundert."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Codes of Law. Lassen Sie uns nun über die Erstellung dieser Datsätze sprechen."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir mit der Zusammenstellung eines großen Korpus an rechtlichen Artikeln begonnen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich verfügbare Belgische Codes und alle Artikel sowie die entsprechenden Abschnittshebungen entnommen."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf relevante Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich, auf ihre Websites zuzugreifen, wo ihr Team von erfahrenen Juristen Belgien's am häufigsten rechtlichen Probleme behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen zusammengestellt, mit Kategorien, Subkategorien und rechtlichen Verweisen auf relevante Statuten."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, wir passten die legalen Referenzen und filterten die Fragen aus, die Referenzen nicht Artikel in einem der Codes of Law wirkten."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Verweise wurden in die entsprechenden Artikel-IDs aus O Corpus abgestimmt und umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.108 Fragen, jeder sorgfältig mit den IDs der relevanten Artikel aus dem Buch."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich enthält jede Frage eine Hauptkategorie und eine Konkatenation von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel kommt mit einer Konkatenation ihrer nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzliche Information wird nicht in der Präsentation verwendet, aber sie könnte für zukünftige Research auf Legal Information Retrieval oder Legaltext Classification interessant sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale unserer Datensätze an."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Frage ist zwischen fünf und vierundvierzig Wort lang, mit einem Median von vierzig Wort."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer medianen Länge von sechzig sieben Wörtern, mit 140 Gramm."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei von ihnen, die eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine Vielzahl von Themen, von denen etwa 85 % entweder über Familie, Wohnraum, Geld oder Gerechtigkeit betraf."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Während die restlichen fünfzehn Prozent entweder mit der Sozialversicherung, Ausländern oder Arbeit zu tun haben."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr diverse, da sie aus dreißig zwei verschiedenen Belgischen Codes kommen, die eine große Anzahl von illegalen Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel aus jedem dieser belgischen Codes."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Aus den twenty two thousand six hundred thirty three Artikeln, nur eintausend sechs hundred twelve sind als relevant zu at least einem"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "nur eine Frage in den Daten sätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafverfolgungsgesetz."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen enthalten achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann durch die Tatsache erklärt werden, dass diese Codes weniger auf Einzelpersonen und ihre Anliegen fokussieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünf Prozent von ihnen sind in der"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen benchmarken wir verschiedene Rückholmethoden, einschließlich lexikalischer und denser Architektur."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrageartikelpaar eine Punktzahl zu, indem es die Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfragezeiten berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM-25-Rankingfunktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert und eine relevante Punktzahl zwischen einem Abfrage-Artikelpaar anhand der Ähnlichkeit ihrer Eingebettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit siamesischer Biancoder in einer Nullschussbewertung, was bedeutet, dass vorgebildete Word-Embedding-Modelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, und kontextunabhängigen Einbettungsmodellen, nämlich Roberta und genauer gesagt Camembert, das ein französisches Roberta-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes Camembert-basiertes Modell. Beyond quoters."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beispiele auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Flavors der Bianco architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Query und den Artikel in einem gemeinsamen Densivektorraum mappiert, und Tutor, das zwei unabhängige Word-Embedding-Modelle verwendet, die die Query und den Artikel separat in zwei verschiedene Embedding-Spaces codieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit dem Pooling von Mittel, Max und CLS sowie mit dem Punktprodukt und dem Kosinus für die Rechengelähnungen."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Ausgangslinie auf den Testsätzen."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Dann mit den lexikalischen Methoden oben, den Siamese-B-Encodern, die in einer Null-Schuss-Einrichtung evaluiert wurden, und den fein abgestimmten B-Encodern unten."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchore alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two Tower Modell verbessert sich gegenüber seiner Siamese-Variante auf Recallat one hundred, aber es funktioniert ähnlich bei den anderen Metriken."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five den trainierten Biancode erheblich unterlegen hat, zeigt seine Leistung, dass es immer noch eine starke Grundlage für Domain Specific Retrieval ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Was die Nullschussbewertung des siamesischen Biancoders betrifft, stellen wir fest, dass die direkte Verwendung der Eingebettungen eines vorgebildeten Kamembert-Modells ohne Optimierung für die Informationsabholungsaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir festgestellt, dass der Word-Tuec-basierte Biancoder den Vastex- und Vogelbasierten Modell deutlich übertrifft, was darauf hindeutet, dass möglicherweise vor-train-Word-Level-Embeddings für die Aufgabe besser geeignet sind als Charakter- oder Unterword-Level-Embeddings, wenn sie von vorn verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Möglichkeiten für Verbesserungen im Vergleich zu einem geschickten Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns mit zwei Einschränkungen aller Datensätze abschließen."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf die aus den 32 belgischen Gesetzen gezogenen beschränkt, die nicht das gesamte belgische Gesetz abdecken, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Referenzen zu diesen ungesammelten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl relevanten Artikeln erhalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsloss impliziert, dass die Antwort in den verbleibenden relevanten Artikeln unvollständig sein könnte, obwohl sie immer noch vollständig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Kann ich meine Mieter vertreiben, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Might not have a detaillierte Antwort innerhalb des gesetzlichen Gesetzes, das eine spezifische Noise-Threshold quantifiziert, bei der Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich mehr auf die Rechtsprechung vertrauen und Präzedenzfälle finden, die ähnlich zu ihrer aktuellen Situation sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Tenant zwei Parties pro Woche und tut es."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser als andere für die gesetzliche Artikel-Retrieval-Tasche geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass all diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur Berechnung von gesetzlichen Artikeln weckt,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Papier, Datset und Code unter den folgenden Links sehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorzustellen, einem unabhängigen Benchmark, der für die Testung von Vision- und Sprachmodellen mit bestimmten sprachlichen Phänomenen gedacht ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark festzulegen?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformer-basierten Vision- und Sprachmodellen gesehen, die auf große Mengen an Bild-Textpaaren vorgebildet wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle drängt die Moderne in der Vision und Sprachaufgaben wie der Antwort auf visuelle Fragen, der visuellen Sinnesreasoning, der Bildherstellung und der Phrase-Grundung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Nachricht erhalten. Die Genauigkeit dieser für die Aufgabe spezifischen Benchmarks steigt stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprachtransformer verstanden, als er diesem Bild und diesem Satz eine hohe Punktzahl zugewiesen hat, um es zu vereinbaren?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und der niedrige Punkt für diesen."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie durch frühere Arbeiten gezeigt?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf diesen Aspekt zu werfen, schlagen wir eine tauschfreundlichere Richtung vor und führen VALS ein, das die Empfindlichkeit von Seh- und Sprachmodellen auf spezifische sprachliche Phänomene testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Vielfalt, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenzen ab."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen festgehalten haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor nur für Vision und Sprachmodelle von Ravi Shakar und seinen Mitarbeitern für Nomenphrasen angewendet wurde, und bei der Zählung von uns in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde, dass wir den Bildunterschrift eines Bildes nehmen und einen Foil erzeugen, indem wir den Unterschrift so verändern, dass er das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Wir ändern diese Phrase, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenz, wobei jedes Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, FOIL-Instanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir im Fall des Aktionsstücks zwei Instrumente, eines, bei dem das Aktionsverb mit einer anderen Aktion geändert wird, und eines, bei dem die Spielzeuge ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Ko-Referenzen sind auch Stücke, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schaffen diese Fehler, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererseits gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach, da eine fehlerhafte Beschreibung weniger wahrscheinlich sein kann als die ursprüngliche Beschreibung."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es zwar nicht unmöglich, statistisch gesehen ist es weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann Pflanzen schneiden, und große Vision- und Sprachmodelle könnten dies aufgreifen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um gültige Folien zu erhalten, müssen wir daher Maßnahmen ergreifen."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir starke Sprachmodelle, um FOILs vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir die Inferenz durch natürliche Sprache oder kurz NLI, um Folien zu filtern, die das Bild noch beschreiben könnten, da wir bei der Konstruktion von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir eine Schlussfolgerung aus natürlicher Sprache mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Beschriftung als die damit verbundene Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In addition, wir betrachten die Kaption als die Premise und die FOIL als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell die FOIL als widersprechend oder neutral gegenüber dem Untertitel vorhersagt, nehmen wir dies als Indikator für eine gültige FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Folie durch den Untertitel enthalten ist, kann es keine gute Folie sein, da sie durch Transitivität eine wahrhaftige Beschreibung des Bildes liefert und wir diese Folien ausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Prozedere ist nicht perfekt. Es ist nur ein Indikator für valide Foil."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Erstellung gültiger FOILs menschliche Annotatoren, um die in Valse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir also so viele Testfälle wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um einen Benchmark für Null-Schuss-Tests handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vorausbildung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Die Feinabstimmung würde es den Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nutzen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vorausbildung haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen auf Vowels, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin I und VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bilder-Satzpaaren in Untertitel und FOILs."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht ist für dieses Video relevanter, dass wir unsere permissivere Metrik, die Paargenauigkeit, präsentieren, die misst, ob der Ausrichtungswert des Bildesatzes für das korrekte Textpaar des Bildes höher ist als für das fehlerhafte Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Metriken und Ergebnisse zu diesen Ergebnissen finden Sie in unserer Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit Paar-Präzision sind hier gezeigt und entsprechen den Ergebnissen, die wir aus den anderen Metriken erhalten haben. Die beste Leistung bei Nullschüssen wird von Wilbert zwölf in einem, gefolgt von Wilbert, LXMert, Clip und schließlich VisualBird erreicht."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert Twelve in One fast gelöst werden, wobei er hervorhebt, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann in unseren Adversarial Foiling-Einstellungen keine der verbleibenden Teile zuverlässig gelöst werden"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäten und Zählungsinstrumenten sehen wir, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Aktionen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie durch plausibel Vorurteile unterstützt werden, wie wir im Aktionsteil sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Bereich erfahren wir, dass es für Vision- und Sprachmodelle ebenfalls schwierig ist, mehrere Referenzen auf das gleiche Objekt in einem Bild mit Pronomen zu verfolgen."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Verstandskontrolle und weil es ein interessantes Experiment ist, haben wir auch zwei Textmodelle, GPT eins und GPT zwei, benchmarkt, um zu beurteilen, ob Valse durch diese Einmodalmodelle gelöst werden kann, indem wir die Verwirrung der richtigen und der fehlgeschlagenen Beschriftung berechnen und den Eintrag mit der geringsten Verwirrung vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die FOIL höher ist, nehmen wir dies als Hinweis darauf, dass die FOIL-Beschriftung unter einer plausibilen Voreingenommenheit oder anderen sprachlichen Voreingenommenheiten leidet."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die Text nur GPT Modelle die Plausibilität der Welt besser erfassen haben als die Vision und Language Modelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALS ein Benchmark ist, der die Linse der sprachlichen Konstruktionen nutzt, um der Community bei der Verbesserung von Seh- und Sprachmodellen zu helfen, indem sie ihre visuellen Grundlagefähigkeiten hart testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu begründen, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich ermutigen, VALS zur Messung des Fortschritts hin zur Sprachbasis mit Vision und Sprachmodellen zu verwenden."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, VALS könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von VALS getesteten Aspekte hilft."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, sollten Sie sich die Walls-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde eine Papier entitelt RNSAM, ein Large Scale DSET für automatische Risikogrammierung beim Commitologizieren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikogenerierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNote ist ein technisches Dokument, das die bei jeder Veröffentlichung eines Softwareprodukts zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Restnoten für Bosch 2.6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "User Us Library These Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consuming, um manuell zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, hochwertige Release-Noten automatisch zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Frischknotengenerierung verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste System, das Arena erstellt wurde, wurde 2014 erstellt."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert eine ruralbasierte Approach, zum Beispiel, indem man die Change Extractor verwendet, um Code differenzen, Bibliothekänder und Dokumentenänderungen von den differenzen zwischen Releases zu extrahieren, und schließlich kombinieren sie."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das bemerkenswerteste Merkmal dieses Systems ist der Ausgaben-Extraktor in der oberen rechten Ecke,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dieses muss mit dem Issues-Ökosystem verbunden sein und kann nur auf Projekte mit Null angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist Grief. Dies entweder angesagt in 2014."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "2020. Es ist auf dem Internet verfügbar und kann via PIP gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches Textklassifizierungsmodell basierendes auf Lernen und Ausgaben aus fünf Labors, wie z. B. Funktionen oder Fehlerbehebungen, für jede Eingabe-Kommentarnachricht."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Sample-User, das eine Korrektur für Fehlerkorrekturen erhält."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingdaten sind sehr klein, etwa fünftausend, und werden in den Experimenten beschriebenen unten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Kreuzschaltmodells ist nicht höher."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier löst diese beiden Probleme und erzeugt automatisch hochwertige Freigabe-Noten."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das begrenzte Anwendungsprogramm schlagen wir eine hochwertige Klassifizierungsmethode mit nur Kommentarmeldungen als Eingabe vor."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Repositories verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der Skarbstaatressourcen haben wir eine RNSAM DSET konsistent mit etwa 82.000 Datenpunkten erstellt, indem wir Daten aus öffentlichen GitHub Repositories mit der GitHub API erstellen."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unsere Daseinsetzung."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Nachricht des Komitees und die rechte Seite ist die Release-Note."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Riesen sind als Verbesserungen, Verbesserungen, etc. gelobt."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Kommentarnachrichten als Eingaben aufnimmt und die Raveled-Please-Notizen ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassungsaufgabe angesehen werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Rubber, Funktionen, Verbesserungen, Fehlerbehebungen, Deprekationen, Entfernungen und Bremsänderungen vorgedefiniert."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden aufgrund früherer Forschung und anderer Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Rhythmus-Noten unten rechts werden aus den Rhythmus-Noten unten links abgezogen."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Moment müssen die vier Schuttwerke, die im Voraus aufgestellt wurden, entdeckt werden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Lager sind nicht immer mit jeder Freiheit übereinstimmen"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, um Verbesserungen zu treffen, zu erhöhen, Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabulärliste mit etwa 30 Numbers für jede dieser Rotationsvariationen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Restnotkrasten zu erkennen und den Text der Restnotkrasten zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Komiteemeldung."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachrichten des Komitees sind nicht an jede Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der image below, wenn die aktuelle Realität Boson zwei Punkt fünf zwei neunzehn, müssen wir die IDECHTEN"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "erfüllt die vorherige Version 2.5218 und erhält einen Tiff. Dies ist ein bisschen mühsam und es reicht nicht aus, nur eine Liste der Releases zu erhalten und sich die Vorher und Nachher anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine Heuristik, die mit Ihnen übereinstimmt, um die vorherigen und nächsten Schauspielzeiten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind die Horses."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "In der Hand, siebentausend zwei hundert Repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Token 63, was für eine Zusammenfassungsaufgabe ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Nummer der Unique Tokens ist bei Roger at eight thousand eight hundred thirty thousand."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl von einzigartigen Kasten und Methoden im Repertory."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes erkläre ich die vorgeschlagene Methode."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Querschnitts-, Extraktions- und Abstruktionsmodell besteht aus zwei neuer Modulen"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifier mit Bot oder Code Bot und ein Generator mit Bot."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Klassifizierer, um jede Kommentarnachricht in fünf RESNOT-Klassen zu klassifizieren: Funktionen, Verbesserungen, Fehlerbehebungen, Duplizierungen und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als anderer eingestuften Komitee-Nachrichten werden abgelehnt."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GAS den Generator unabhängig auf die vier Rudder-Dokumente an und erzeugt für jede Klasse Risikonode."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Übereinstimmungen zwischen Commit-Nachrichten und Lesemerkungen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifizierer zu trainieren, weisen wir jeder Eingabe-Commit-Nachricht Pseudorabben zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Kreuzstreifen-Abstruktiv-Summersätze durch zwei verschiedene Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzigen SEC-Netzwerk und generiert einen einzigen Long-SNode-Text, der eine Kombination von Eingabe-Commit-Nachrichten liefert."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgangstext kann in Kreuzzeichen aufgeteilt werden, basierend auf speziellen Kreuz-Spezifischen Endpunkt-Symbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSMarch nennen, besteht aus vier verschiedenen SEC-to-SEC-Netzwerken, von denen jede einer der RES-Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das macht Spain's Experiment."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: CS, CS Single, CS Smart, Russelling und die vorherige Studienbeschreibung."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Abrissung sind in einigen Fällen diese Noten in mehreren Sätzen ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro ist penetrativ, wenn das System einen kurzen Satz ausgibt"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Brauvolumen. In den als nächstes beschriebenen Experimentenergebnissen"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erzeugen wir auch eine Spezifität, da Rouge und Brux nicht erzeugt werden können, wenn die Riesen-Knoten leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass die Modellprojekte ausgegeben sind, die in Fällen, in denen die Reasonals empfangen, empfindlich sind."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Daseit Emailadresse, Hashbarriers, etc. enthält, erweitern wir auch den Quint Daseit, der sie ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat und sie hat Rouge Air-Punkte erreicht, die mehr als zehn Punkte höher waren als die Baselines."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Green Test set, der Square Gap zwischen der proposierten Methode und der Basis jumped zu mehr als 20 Punkten."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie und sie erfolgreich sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS hat eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Crossfire und eines Generators auf das Training des Crossfire-Systems mit Pseudobus effektiv ist."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, weil der Klassifizierer sich auf die relevanten Kommittentests für jeden Kurs konzentrieren kann."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie isst in dieser Zeit viel höher als wenn sie ledig ist."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es auch effektiv ist, für jede dieser Notengrasse unabhängig verschiedene Perspektivsummerisierungsmodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hero und Eronasus"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xia's Methoden neigen dazu, kürzere Sätze als menschliche Referenz-Sätze zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Figur auf der rechten Referenz hat drei oder vier Sätze, während CS nur eins hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzugabe ist, dass in den Trainingsdaten nur 33 % der Sätze im Rabel Merkmale und 40 % im Rabel Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES Methoden ohne zusätzliche Informationen keine genauen Risikobewertungen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommentarmeldung, und die Kommentarfassung kann nicht generiert werden, ohne auf die entsprechende Peru-Request oder -Erstellung hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das untenstehende Beispiel zeigt, dass die beiden Kommentarberichte im Eingaben miteinander verbunden sind und in einen Satz kombiniert werden sollten, aber dies geschieht nicht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Personalgenerierung erstellt,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Kommentarmeldungen einzugeben und sie zusammenzufassen, sodass sie für alle Projekte auf Englisch anwendbar ist."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die Bassrate besser laut macht als die Bassrate."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte schauen Sie sich unsere Dessert-Audit-Tab an."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist ein Safarari,"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unsere Arbeit über die Anreicherung von Tabellen mit Hilfe von fein abgestimmten Transformatoren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Merkmale der Daten."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen begrenzt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Funktionen mit einer anderen Datenquelle kann erhebliche Informationen bieten."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung von Tabelldaten mit externen Quellen-Freitexten."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben eine Tabelldatensammlung und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Funktionen aus dem künstlichen Text der Wissensbasis zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel sehen. In einem Datensatz, der in FEST eingeführt wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist die Datenmenge Universitätsdatenmenge."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten zu unterteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festes ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Einheit, in diesem Beispiel der Name der Universität, mit einer Einheit innerhalb der Wissensbasis verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Knowledge-Basis wird extrahiert und in die Daten setzt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text der Abstrakt der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Funktionen aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen also eine Funktionsaufnahmephase, die Textanalyse beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde mich in den nächsten Folien tiefer damit befassen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Extraktionsphase der Merkmale gibt es eine Generierungsphase der Merkmale, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst generieren Sie Funktionen in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also, erstens zwei neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Funktion stellt die Wahrscheinlichkeit für jede Klasse dar."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, die sich auf Transformer basieren lassen, wie Baird, GPT, XLED und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe zur Feinabstimmung sein."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Funktionsauffnahme können wir also ein Parent-Train-Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell verfeinert, um Text in Klassen zu klassifizieren, abstrakt in Klassen, niedrig oder hoch."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse ist, und verwenden Sie sie als neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datenmengen möglicherweise wenige unterschiedliche Entitätsstapel haben."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Proben, und der kleinste Datensatz enthält fünfunddreißig Proben in seinem Trainings-Satz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorherige Kenntnisse über voranalyseierte Datensätze nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir den nth-Datensatz analysieren."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sugest, ist die Hälfte der Fine Tuning Phase."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Phase der Fine-Tuning-Multitask."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über n minus eins Datensätze finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine weitere Feinabstimmungsphase durch, die eine Feinabstimmung der Zielaufgaben ist, wenn wir das Sprachmodell über den n-Tiel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der neueste Stand der Multitask-Fine-Tuning, der MTDNN genannt wird."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN hält MTDNN eine Anzahl von Aufgaben im Trainingsatz aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainings-Set. Also leere DNN und halte vier Kopfhäupter, wie Sie auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es samplet eine zufällige Charge aus dem Trainingsset."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Run-Batch zu einer, zum Beispiel, Sing und Selton-Klassifizierungsaufgabe gehört, führt er einen Vorwärts- und Rückwärtspass durch den ersten Kopf aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zu einer Paar-Ranking-Tasche gehört, wird sie durch den letzten Kopf weitergegeben und zurückgegeben."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario verifiziert eine Datenmenge-Tabelle die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN hält die Anzahl der Klassen-Heads-Ausgaben-Schichten aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss MTDNN eine neue HEADS für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Task Reformulation Fine Tuning bezeichnet wird, besteht darin, dass wir in unserem Ansatz Task Reformation Fine Tuning statt mehrere Kopfgruppen zu behalten, jeden Datensatz in ein Satz pro Klassifizierungsproblem umformulieren, das zwei Klassen-Aufgaben ist."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also ein Beispiel sehen."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Input-Datensatz, der von Entitäten, Funktionen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zu der Klassifizierung des Textes, des Abstrakts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, wir haben das Sprachmodell so trainiert, dass es abstrakt und in der Klasse klassifiziert, ob die Abstrakt-Klasse in der Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Etikettvektor besteht in diesem Fall also immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren fertigen oder formulierten Feintuning-Ansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also das vollständige Framework betrachten."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und das set fade into fast"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Entity-Linking-Phase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensbasis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird die Aufgabe in eine Satz-Per-Classifikation-Tasche reformuliert."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und die Ausgabenwahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über n-1-Datensatz mit einer vorläufigen Multitask-Fine-Tuning verfeinert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu erstelltes Merkmal in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Rahmenwerk zu bewerten, verwenden wir eine Datenmenge mit siebzehn Tabellen, die Größe, Merkmale, Balance, Bereich und anfängliche Leistung variieren."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unser Experiment als Live-Out-Evaluierung gestaltet, bei der wir schnell über sechzehn Datensätze trainieren und sie auf das siebzehnte Datenset anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datensatz in vier Fehler auf und wenden eine Falten-Cross-Validation an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Funktionen und bewerten sie mit fünf Bewertungs-Klassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-Basis-Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Rahmenwerk mit der Feinabstimmung des Zieldatensatzes, der Feinabstimmung der Zielaufgabe und der vorläufigen Feinabstimmung der MTDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere Formulierung ist ein Feintuning, das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2% gegenüber der Feinabstimmung des Zieldatensatzes erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Poach hat eine Verbesserung um sechs Prozent erzielt."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Daten ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Feinabstimmung bei mehrere Aufgaben auf 1,5 Prozent abnimmt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung hat sich im Vergleich zu der Zielaufgabe, die allein mit der Feinabstimmung verbessert wurde, um elf Prozent zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Zusammenfassung ermöglicht Fast die Bereicherung von Fushot aus 35 Proben in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulationsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satzpaar-Klassifizierungsproblematik verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle. Heute werde ich unsere Forschungsarbeit Lernen zu reisen deduktiv, Methodenproblemlösung als komplexe Rasen-Extraktion vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Zahl stammt aus dem POWN-Papier, in dem sie Anweisungen zur Lösung des Methodenproblems in einem Fluch-Learning-Szenario ausführen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite können wir sehen, dass wir, wenn wir einige Beispiele nur mit Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch noch mehr Beschreibungen geben, kann das Modell die Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, als Ausgabe interpretierbares Mehrstufenrechnungsverfahren zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken auch, dass ein Methodenproblem eine einfache Anwendung zur Bewertung solcher Argumentationsfähigkeiten ist."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier müssen wir also in unserer Problemkonfiguration, angesichts der Fragen, diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser besonderen Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Größen bekannt ist"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren aufgeteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Eine frühere Arbeit im Lösungsproblem der Methode kann also tatsächlich in Sequenz- und Baummodell kategorisiert werden."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenzmodelle konvertieren den Ausdruck also in eine bestimmte Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ziemlich einfach umzusetzen und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil ist, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell und es fehlt an Interpretabilität für die Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Direction noch ziemlich populär, weil der Transformermodell"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also die Operatoren weiter, bis wir die Lifts erreichen, die die Größen sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt, aber es ist eigentlich ganz entgegengesetzt, weil wir zuerst den Operator generieren und dann am Ende die Größen generieren."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens enthält es auch einige wiederholte Berechnungen."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck hier ansehen, wird acht mal drei plus drei tatsächlich zweimal erzeugt. Aber tatsächlich sollten wir die Ergebnisse verwenden"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und in interpretierbaren Methoden lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diesen Teiler erhalten, der 27 ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir bei diesem dritten Schritt tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Okay. Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schritts tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als unser Anfangszustand ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Operatoren von QY bis QJ aus, und dieser Ausdruck ist tatsächlich gerichtet."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "So, wir haben hier auch Subtraction-Wert, um die entgegengesetzte Richtung zu repräsentieren."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie bei der Strahlungsauffnahme."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es in den nächsten Zustand hinzu, um eine neue Menge zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folien visualisieren also tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zuständen immer wieder Ausdrücke hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Sprachmodell, das Vögel oder Robetts sein kann, und dann kodieren wir den Satz und erhalten diese Mengenrepräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengen darstellen, können wir mit der Schlussfolgerung beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q4 multipliziert wird."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Anweisung, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist. Dann wenden wir ein Fit-Forward-Netzwerk an, das vom Operator parametriert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksrepräsentation Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Schlussfolgerung möglicherweise auch den falschen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier entspricht also jeder möglichen Ausdruck dreimal so viel wie die Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchbereich entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir noch eine Menge mehr haben."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe stammt aus dem vorherigen berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir diesen letzten Ausdruck Q3 erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke von dem vorherigen Schritt unterschiedlich ist."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede machen es schwierig, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsmethode ist ähnlich wie bei der Schulung eines Sequenzmodells, bei dem wir den Verlust bei jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch diese Tao, um darzustellen, wann wir diesen Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz anders, weil der Raum bei jedem Zeitpunkt anders ist, während es im traditionellen Sequenz- zu-Sequenz-Modell die Anzahl des Wortschatzes ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht es uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen zu verhängen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen also Experimente mit den häufig verwendeten Method-Problem-Datensätzen durch, MAWPS, Math23K, MathQA und SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Variante ist also Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir BeamSearch nicht, im Gegensatz zu offensichtlichen Ansätzen mit BeamSearch."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Okay, die besten Ansätze sind oft ein Baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Vernunft also dieses Baumbasierungsmodell deutlich übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MatQuery oder SWAM nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse weiter."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist eine Herausforderung, weil der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. irrelevante Informationen und zusätzliche Mengen hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Also, in unserer Vorhersage finden wir, dass einige der intermediären Werte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Pitchs und Stephen hat acht Pitchs, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse als negativ entfernen, damit wir die Antwort richtig machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert und bei dem Roberta-Basemodell tatsächlich zwei Punkte verbessert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat also bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Bert niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information angesehen werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der ungenutzten Mengen haben und der SWAMP-Datensatz den größten Teil enthält."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen ist die Gesamtleistung tatsächlich höher als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlimmer ist als die, äh, viel schlimmer als."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für MAWPS haben wir nicht wirklich viele Desk-Cases, also ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretationsfähigkeit durch ein Beispiel für die Zusammenstoßpartizierung zeigen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also tatsächlich eine falsche Vorhersage im ersten Schritt."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren, oder?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben also, dass dieser Satz das Modell in eine falsche Vorhersage führen könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man hier also noch 35 plant, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu ändern, dass er so aussieht wie die Anzahl der Birnenfäden fünfundfünfzig weniger ist als die Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen es also so, dass es genauere Semantik vermittelt, damit das Modell die Vorhersage richtig machen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell eigentlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können eine interpretierbare Lösungsmethode bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige vorherige Kenntnisse als Konstrakt einbeziehen, was uns helfen kann, die Leistung zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur für Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch für andere Aufgaben, die mehrtretende Argumentation beinhalten."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung in verschiedenen Zeitzonen unbalanciert ist, daher ist es auch ziemlich schwierig, Beam-Suche anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also das Ende des Vortrags und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Maastricht University."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein Johannes Werk mit Jerry vorstellen, das sich mit einem neuen Datensatz für die Abholung von gesetzlichen Artikeln befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein wesentlicher Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat wenig oder kein Wissen über ihre Rechte und grundlegenden Rechtsverfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Ergebnis sind viele vulnerable Bürger, die sich nicht die kostbare Assistance eines Legal Experts erwarten können, unprotegt oder worstens, exploitiert."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Lücke zwischen Menschen und dem Gesetz zu schließen, indem wir ein effektives Rückholsystem für gesetzliche Artikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte für unqualifizierte Menschen einen kostenlosen professionellen Rechtshilfenservice bieten."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem der statutarischen Artikelabholung."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ich eine einfache Frage zu einem rechtlichen Thema stelle, wie zum Beispiel: Was mache ich, wenn ich die professionelle Vertraulichkeit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetz zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe zur Informationserfassung bringt eine ganze Reihe von Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst geht es um zwei Sprachtypen."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "für die Fragen eine gängige natürliche Sprache und für die Statuten eine komplexe rechtliche Sprache."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in den Sprachverteilungen machen es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die mit der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das gesetzliche Recht kein Stapel unabhängiger Artikel, die als vollständige Informationsquelle an sich behandelt werden können, wie zum Beispiel Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Insted ist es eine Strukturkollektion von legalen Provisionen, die nur in der allgemeinen Kontext betrachtet sind, zusammen mit den zusätzlichen Informationen aus den neighbouring Artikeln, den Feldern und Subfeldern, zu denen sie gehören, und ihrer Platz in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, statutory Articles RN small paragraph, was usuell die typische Retrieval Unit in Most Retrieval Works ist."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Jahre dauern können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich NLP haben großes Interesse an vielen rechtlichen Aufgaben wie der Vorhersage von Rechtsentscheidungen oder der automatisierten Überprüfung von Vertragsverträgen weckt."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabholung ist jedoch aufgrund des Mangels an großen und hochwertigen gekennzeichneten Datensätzen größtenteils unberührt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir ein neues französisches, zentrales, zentrales Datenkett, um zu untersuchen, ob ein Rückholmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten für die Aufgabe der Statutorienartikelrückholung nähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Our Belgian Statutory Article Retrieval Data Sets consist von mehr als einem Jahrzehnt Liter."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnraum, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen hat von erfahrenen Juristen mit Referenzen zu relevanten Artikeln aus einem Corpus von mehr als twenty zwei Tausend sechshundert."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Codes of Law. Lassen Sie uns nun über die Erstellung dieser Datsätze sprechen."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir mit der Zusammenstellung eines großen Korpus an rechtlichen Artikeln begonnen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich verfügbare Belgische Codes und alle Artikel sowie die entsprechenden Abschnittshebungen entnommen."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf relevante Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich, auf ihre Websites zuzugreifen, wo ihr Team von erfahrenen Juristen Belgien's am häufigsten rechtlichen Probleme behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen zusammengestellt, mit Kategorien, Subkategorien und rechtlichen Verweisen auf relevante Statuten."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, wir passten die legalen Referenzen und filterten die Fragen aus, die Referenzen nicht Artikel in einem der Codes of Law wirkten."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Verweise wurden in die entsprechenden Artikel-IDs aus O Corpus abgestimmt und umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.108 Fragen, jeder sorgfältig mit den IDs der relevanten Artikel aus dem Buch."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich enthält jede Frage eine Hauptkategorie und eine Konkatenation von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel kommt mit einer Konkatenation ihrer nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzliche Information wird nicht in der Präsentation verwendet, aber sie könnte für zukünftige Research auf Legal Information Retrieval oder Legaltext Classification interessant sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale unserer Datensätze an."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Frage ist zwischen fünf und vierundvierzig Wort lang, mit einem Median von vierzig Wort."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer medianen Länge von sechzig sieben Wörtern, mit 140 Gramm."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei von ihnen, die eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine Vielzahl von Themen, von denen etwa 85 % entweder über Familie, Wohnraum, Geld oder Gerechtigkeit betraf."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Während die restlichen fünfzehn Prozent entweder mit der Sozialversicherung, Ausländern oder Arbeit zu tun haben."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr diverse, da sie aus dreißig zwei verschiedenen Belgischen Codes kommen, die eine große Anzahl von illegalen Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel aus jedem dieser belgischen Codes."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Aus den twenty two thousand six hundred thirty three Artikeln, nur eintausend sechs hundred twelve sind als relevant zu at least einem"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "nur eine Frage in den Daten sätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafverfolgungsgesetz."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen enthalten achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann durch die Tatsache erklärt werden, dass diese Codes weniger auf Einzelpersonen und ihre Anliegen fokussieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünf Prozent von ihnen sind in der"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen benchmarken wir verschiedene Rückholmethoden, einschließlich lexikalischer und denser Architektur."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrageartikelpaar eine Punktzahl zu, indem es die Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfragezeiten berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM-25-Rankingfunktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert und eine relevante Punktzahl zwischen einem Abfrage-Artikelpaar anhand der Ähnlichkeit ihrer Eingebettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit siamesischer Biancoder in einer Nullschussbewertung, was bedeutet, dass vorgebildete Word-Embedding-Modelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, und kontextunabhängigen Einbettungsmodellen, nämlich Roberta und genauer gesagt Camembert, das ein französisches Roberta-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes Camembert-basiertes Modell. Beyond quoters."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beispiele auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Flavors der Bianco architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Query und den Artikel in einem gemeinsamen Densivektorraum mappiert, und Tutor, das zwei unabhängige Word-Embedding-Modelle verwendet, die die Query und den Artikel separat in zwei verschiedene Embedding-Spaces codieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit dem Pooling von Mittel, Max und CLS sowie mit dem Punktprodukt und dem Kosinus für die Rechengelähnungen."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Ausgangslinie auf den Testsätzen."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Dann mit den lexikalischen Methoden oben, den Siamese-B-Encodern, die in einer Null-Schuss-Einrichtung evaluiert wurden, und den fein abgestimmten B-Encodern unten."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchore alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two Tower Modell verbessert sich gegenüber seiner Siamese-Variante auf Recallat one hundred, aber es funktioniert ähnlich bei den anderen Metriken."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five den trainierten Biancode erheblich unterlegen hat, zeigt seine Leistung, dass es immer noch eine starke Grundlage für Domain Specific Retrieval ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Was die Nullschussbewertung des siamesischen Biancoders betrifft, stellen wir fest, dass die direkte Verwendung der Eingebettungen eines vorgebildeten Kamembert-Modells ohne Optimierung für die Informationsabholungsaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir festgestellt, dass der Word-Tuec-basierte Biancoder den Vastex- und Vogelbasierten Modell deutlich übertrifft, was darauf hindeutet, dass möglicherweise vor-train-Word-Level-Embeddings für die Aufgabe besser geeignet sind als Charakter- oder Unterword-Level-Embeddings, wenn sie von vorn verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Möglichkeiten für Verbesserungen im Vergleich zu einem geschickten Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns mit zwei Einschränkungen aller Datensätze abschließen."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf die aus den 32 belgischen Gesetzen gezogenen beschränkt, die nicht das gesamte belgische Gesetz abdecken, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Referenzen zu diesen ungesammelten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl relevanten Artikeln erhalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsloss impliziert, dass die Antwort in den verbleibenden relevanten Artikeln unvollständig sein könnte, obwohl sie immer noch vollständig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Kann ich meine Mieter vertreiben, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Might not have a detaillierte Antwort innerhalb des gesetzlichen Gesetzes, das eine spezifische Noise-Threshold quantifiziert, bei der Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich mehr auf die Rechtsprechung vertrauen und Präzedenzfälle finden, die ähnlich zu ihrer aktuellen Situation sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Tenant zwei Parties pro Woche und tut es."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser als andere für die gesetzliche Artikel-Retrieval-Tasche geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass all diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur Berechnung von gesetzlichen Artikeln weckt,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Papier, Datset und Code unter den folgenden Links sehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorzustellen, einem unabhängigen Benchmark, der für die Testung von Vision- und Sprachmodellen mit bestimmten sprachlichen Phänomenen gedacht ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark festzulegen?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformer-basierten Vision- und Sprachmodellen gesehen, die auf große Mengen an Bild-Textpaaren vorgebildet wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle drängt die Moderne in der Vision und Sprachaufgaben wie der Antwort auf visuelle Fragen, der visuellen Sinnesreasoning, der Bildherstellung und der Phrase-Grundung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Nachricht erhalten. Die Genauigkeit dieser für die Aufgabe spezifischen Benchmarks steigt stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprachtransformer verstanden, als er diesem Bild und diesem Satz eine hohe Punktzahl zugewiesen hat, um es zu vereinbaren?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und der niedrige Punkt für diesen."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie durch frühere Arbeiten gezeigt?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf diesen Aspekt zu werfen, schlagen wir eine tauschfreundlichere Richtung vor und führen VALS ein, das die Empfindlichkeit von Seh- und Sprachmodellen auf spezifische sprachliche Phänomene testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Vielfalt, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenzen ab."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen festgehalten haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor nur für Vision und Sprachmodelle von Ravi Shakar und seinen Mitarbeitern für Nomenphrasen angewendet wurde, und bei der Zählung von uns in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde, dass wir den Bildunterschrift eines Bildes nehmen und einen Foil erzeugen, indem wir den Unterschrift so verändern, dass er das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Wir ändern diese Phrase, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenz, wobei jedes Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, FOIL-Instanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir im Fall des Aktionsstücks zwei Instrumente, eines, bei dem das Aktionsverb mit einer anderen Aktion geändert wird, und eines, bei dem die Spielzeuge ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Ko-Referenzen sind auch Stücke, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schaffen diese Fehler, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererseits gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach, da eine fehlerhafte Beschreibung weniger wahrscheinlich sein kann als die ursprüngliche Beschreibung."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es zwar nicht unmöglich, statistisch gesehen ist es weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann Pflanzen schneiden, und große Vision- und Sprachmodelle könnten dies aufgreifen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um gültige Folien zu erhalten, müssen wir daher Maßnahmen ergreifen."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir starke Sprachmodelle, um FOILs vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir die Inferenz durch natürliche Sprache oder kurz NLI, um Folien zu filtern, die das Bild noch beschreiben könnten, da wir bei der Konstruktion von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir eine Schlussfolgerung aus natürlicher Sprache mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Beschriftung als die damit verbundene Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In addition, wir betrachten die Kaption als die Premise und die FOIL als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell die FOIL als widersprechend oder neutral gegenüber dem Untertitel vorhersagt, nehmen wir dies als Indikator für eine gültige FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Folie durch den Untertitel enthalten ist, kann es keine gute Folie sein, da sie durch Transitivität eine wahrhaftige Beschreibung des Bildes liefert und wir diese Folien ausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Prozedere ist nicht perfekt. Es ist nur ein Indikator für valide Foil."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Erstellung gültiger FOILs menschliche Annotatoren, um die in Valse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir also so viele Testfälle wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um einen Benchmark für Null-Schuss-Tests handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vorausbildung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Die Feinabstimmung würde es den Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nutzen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vorausbildung haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen auf Vowels, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin I und VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bilder-Satzpaaren in Untertitel und FOILs."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht ist für dieses Video relevanter, dass wir unsere permissivere Metrik, die Paargenauigkeit, präsentieren, die misst, ob der Ausrichtungswert des Bildesatzes für das korrekte Textpaar des Bildes höher ist als für das fehlerhafte Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Metriken und Ergebnisse zu diesen Ergebnissen finden Sie in unserer Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit Paar-Präzision sind hier gezeigt und entsprechen den Ergebnissen, die wir aus den anderen Metriken erhalten haben. Die beste Leistung bei Nullschüssen wird von Wilbert zwölf in einem, gefolgt von Wilbert, LXMert, Clip und schließlich VisualBird erreicht."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert Twelve in One fast gelöst werden, wobei er hervorhebt, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann in unseren Adversarial Foiling-Einstellungen keine der verbleibenden Teile zuverlässig gelöst werden"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäten und Zählungsinstrumenten sehen wir, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Aktionen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie durch plausibel Vorurteile unterstützt werden, wie wir im Aktionsteil sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Bereich erfahren wir, dass es für Vision- und Sprachmodelle ebenfalls schwierig ist, mehrere Referenzen auf das gleiche Objekt in einem Bild mit Pronomen zu verfolgen."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Verstandskontrolle und weil es ein interessantes Experiment ist, haben wir auch zwei Textmodelle, GPT eins und GPT zwei, benchmarkt, um zu beurteilen, ob Valse durch diese Einmodalmodelle gelöst werden kann, indem wir die Verwirrung der richtigen und der fehlgeschlagenen Beschriftung berechnen und den Eintrag mit der geringsten Verwirrung vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die FOIL höher ist, nehmen wir dies als Hinweis darauf, dass die FOIL-Beschriftung unter einer plausibilen Voreingenommenheit oder anderen sprachlichen Voreingenommenheiten leidet."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die Text nur GPT Modelle die Plausibilität der Welt besser erfassen haben als die Vision und Language Modelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALS ein Benchmark ist, der die Linse der sprachlichen Konstruktionen nutzt, um der Community bei der Verbesserung von Seh- und Sprachmodellen zu helfen, indem sie ihre visuellen Grundlagefähigkeiten hart testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu begründen, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich ermutigen, VALS zur Messung des Fortschritts hin zur Sprachbasis mit Vision und Sprachmodellen zu verwenden."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, VALS könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von VALS getesteten Aspekte hilft."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, sollten Sie sich die Walls-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde eine Papier entitelt RNSAM, ein Large Scale DSET für automatische Risikogrammierung beim Commitologizieren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikogenerierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNote ist ein technisches Dokument, das die bei jeder Veröffentlichung eines Softwareprodukts zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Restnoten für Bosch 2.6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "User Us Library These Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consuming, um manuell zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, hochwertige Release-Noten automatisch zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Frischknotengenerierung verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste System, das Arena erstellt wurde, wurde 2014 erstellt."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert eine ruralbasierte Approach, zum Beispiel, indem man die Change Extractor verwendet, um Code differenzen, Bibliothekänder und Dokumentenänderungen von den differenzen zwischen Releases zu extrahieren, und schließlich kombinieren sie."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das bemerkenswerteste Merkmal dieses Systems ist der Ausgaben-Extraktor in der oberen rechten Ecke,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dieses muss mit dem Issues-Ökosystem verbunden sein und kann nur auf Projekte mit Null angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist Grief. Dies entweder angesagt in 2014."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "2020. Es ist auf dem Internet verfügbar und kann via PIP gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches Textklassifizierungsmodell basierendes auf Lernen und Ausgaben aus fünf Labors, wie z. B. Funktionen oder Fehlerbehebungen, für jede Eingabe-Kommentarnachricht."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Sample-User, das eine Korrektur für Fehlerkorrekturen erhält."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingdaten sind sehr klein, etwa fünftausend, und werden in den Experimenten beschriebenen unten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Kreuzschaltmodells ist nicht höher."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier löst diese beiden Probleme und erzeugt automatisch hochwertige Freigabe-Noten."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das begrenzte Anwendungsprogramm schlagen wir eine hochwertige Klassifizierungsmethode mit nur Kommentarmeldungen als Eingabe vor."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Repositories verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der Skarbstaatressourcen haben wir eine RNSAM DSET konsistent mit etwa 82.000 Datenpunkten erstellt, indem wir Daten aus öffentlichen GitHub Repositories mit der GitHub API erstellen."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unsere Daseinsetzung."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Nachricht des Komitees und die rechte Seite ist die Release-Note."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Riesen sind als Verbesserungen, Verbesserungen, etc. gelobt."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Kommentarnachrichten als Eingaben aufnimmt und die Raveled-Please-Notizen ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassungsaufgabe angesehen werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Rubber, Funktionen, Verbesserungen, Fehlerbehebungen, Deprekationen, Entfernungen und Bremsänderungen vorgedefiniert."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden aufgrund früherer Forschung und anderer Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Rhythmus-Noten unten rechts werden aus den Rhythmus-Noten unten links abgezogen."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Moment müssen die vier Schuttwerke, die im Voraus aufgestellt wurden, entdeckt werden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Lager sind nicht immer mit jeder Freiheit übereinstimmen"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, um Verbesserungen zu treffen, zu erhöhen, Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabulärliste mit etwa 30 Numbers für jede dieser Rotationsvariationen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Restnotkrasten zu erkennen und den Text der Restnotkrasten zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Komiteemeldung."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachrichten des Komitees sind nicht an jede Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der image below, wenn die aktuelle Realität Boson zwei Punkt fünf zwei neunzehn, müssen wir die IDECHTEN"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "erfüllt die vorherige Version 2.5218 und erhält einen Tiff. Dies ist ein bisschen mühsam und es reicht nicht aus, nur eine Liste der Releases zu erhalten und sich die Vorher und Nachher anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine Heuristik, die mit Ihnen übereinstimmt, um die vorherigen und nächsten Schauspielzeiten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind die Horses."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "In der Hand, siebentausend zwei hundert Repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Token 63, was für eine Zusammenfassungsaufgabe ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Nummer der Unique Tokens ist bei Roger at eight thousand eight hundred thirty thousand."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl von einzigartigen Kasten und Methoden im Repertory."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes erkläre ich die vorgeschlagene Methode."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Querschnitts-, Extraktions- und Abstruktionsmodell besteht aus zwei neuer Modulen"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifier mit Bot oder Code Bot und ein Generator mit Bot."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Klassifizierer, um jede Kommentarnachricht in fünf RESNOT-Klassen zu klassifizieren: Funktionen, Verbesserungen, Fehlerbehebungen, Duplizierungen und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als anderer eingestuften Komitee-Nachrichten werden abgelehnt."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GAS den Generator unabhängig auf die vier Rudder-Dokumente an und erzeugt für jede Klasse Risikonode."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Übereinstimmungen zwischen Commit-Nachrichten und Lesemerkungen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifizierer zu trainieren, weisen wir jeder Eingabe-Commit-Nachricht Pseudorabben zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Kreuzstreifen-Abstruktiv-Summersätze durch zwei verschiedene Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzigen SEC-Netzwerk und generiert einen einzigen Long-SNode-Text, der eine Kombination von Eingabe-Commit-Nachrichten liefert."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgangstext kann in Kreuzzeichen aufgeteilt werden, basierend auf speziellen Kreuz-Spezifischen Endpunkt-Symbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSMarch nennen, besteht aus vier verschiedenen SEC-to-SEC-Netzwerken, von denen jede einer der RES-Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das macht Spain's Experiment."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: CS, CS Single, CS Smart, Russelling und die vorherige Studienbeschreibung."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Abrissung sind in einigen Fällen diese Noten in mehreren Sätzen ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro ist penetrativ, wenn das System einen kurzen Satz ausgibt"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Brauvolumen. In den als nächstes beschriebenen Experimentenergebnissen"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erzeugen wir auch eine Spezifität, da Rouge und Brux nicht erzeugt werden können, wenn die Riesen-Knoten leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass die Modellprojekte ausgegeben sind, die in Fällen, in denen die Reasonals empfangen, empfindlich sind."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Daseit Emailadresse, Hashbarriers, etc. enthält, erweitern wir auch den Quint Daseit, der sie ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat und sie hat Rouge Air-Punkte erreicht, die mehr als zehn Punkte höher waren als die Baselines."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Green Test set, der Square Gap zwischen der proposierten Methode und der Basis jumped zu mehr als 20 Punkten."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie und sie erfolgreich sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS hat eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Crossfire und eines Generators auf das Training des Crossfire-Systems mit Pseudobus effektiv ist."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, weil der Klassifizierer sich auf die relevanten Kommittentests für jeden Kurs konzentrieren kann."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie isst in dieser Zeit viel höher als wenn sie ledig ist."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es auch effektiv ist, für jede dieser Notengrasse unabhängig verschiedene Perspektivsummerisierungsmodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hero und Eronasus"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xia's Methoden neigen dazu, kürzere Sätze als menschliche Referenz-Sätze zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Figur auf der rechten Referenz hat drei oder vier Sätze, während CS nur eins hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzugabe ist, dass in den Trainingsdaten nur 33 % der Sätze im Rabel Merkmale und 40 % im Rabel Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES Methoden ohne zusätzliche Informationen keine genauen Risikobewertungen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommentarmeldung, und die Kommentarfassung kann nicht generiert werden, ohne auf die entsprechende Peru-Request oder -Erstellung hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das untenstehende Beispiel zeigt, dass die beiden Kommentarberichte im Eingaben miteinander verbunden sind und in einen Satz kombiniert werden sollten, aber dies geschieht nicht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Personalgenerierung erstellt,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Kommentarmeldungen einzugeben und sie zusammenzufassen, sodass sie für alle Projekte auf Englisch anwendbar ist."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die Bassrate besser laut macht als die Bassrate."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte schauen Sie sich unsere Dessert-Audit-Tab an."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist ein Safarari,"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unsere Arbeit über die Anreicherung von Tabellen mit Hilfe von fein abgestimmten Transformatoren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Merkmale der Daten."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen begrenzt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Funktionen mit einer anderen Datenquelle kann erhebliche Informationen bieten."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung von Tabelldaten mit externen Quellen-Freitexten."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben eine Tabelldatensammlung und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Funktionen aus dem künstlichen Text der Wissensbasis zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel sehen. In einem Datensatz, der in FEST eingeführt wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist die Datenmenge Universitätsdatenmenge."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten zu unterteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festes ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Einheit, in diesem Beispiel der Name der Universität, mit einer Einheit innerhalb der Wissensbasis verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Knowledge-Basis wird extrahiert und in die Daten setzt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text der Abstrakt der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Funktionen aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen also eine Funktionsaufnahmephase, die Textanalyse beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde mich in den nächsten Folien tiefer damit befassen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Extraktionsphase der Merkmale gibt es eine Generierungsphase der Merkmale, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst generieren Sie Funktionen in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also, erstens zwei neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Funktion stellt die Wahrscheinlichkeit für jede Klasse dar."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, die sich auf Transformer basieren lassen, wie Baird, GPT, XLED und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe zur Feinabstimmung sein."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Funktionsauffnahme können wir also ein Parent-Train-Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell verfeinert, um Text in Klassen zu klassifizieren, abstrakt in Klassen, niedrig oder hoch."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse ist, und verwenden Sie sie als neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datenmengen möglicherweise wenige unterschiedliche Entitätsstapel haben."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Proben, und der kleinste Datensatz enthält fünfunddreißig Proben in seinem Trainings-Satz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorherige Kenntnisse über voranalyseierte Datensätze nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir den nth-Datensatz analysieren."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sugest, ist die Hälfte der Fine Tuning Phase."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Phase der Fine-Tuning-Multitask."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über n minus eins Datensätze finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine weitere Feinabstimmungsphase durch, die eine Feinabstimmung der Zielaufgaben ist, wenn wir das Sprachmodell über den n-Tiel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der neueste Stand der Multitask-Fine-Tuning, der MTDNN genannt wird."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN hält MTDNN eine Anzahl von Aufgaben im Trainingsatz aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainings-Set. Also leere DNN und halte vier Kopfhäupter, wie Sie auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es samplet eine zufällige Charge aus dem Trainingsset."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Run-Batch zu einer, zum Beispiel, Sing und Selton-Klassifizierungsaufgabe gehört, führt er einen Vorwärts- und Rückwärtspass durch den ersten Kopf aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zu einer Paar-Ranking-Tasche gehört, wird sie durch den letzten Kopf weitergegeben und zurückgegeben."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario verifiziert eine Datenmenge-Tabelle die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN hält die Anzahl der Klassen-Heads-Ausgaben-Schichten aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss MTDNN eine neue HEADS für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Task Reformulation Fine Tuning bezeichnet wird, besteht darin, dass wir in unserem Ansatz Task Reformation Fine Tuning statt mehrere Kopfgruppen zu behalten, jeden Datensatz in ein Satz pro Klassifizierungsproblem umformulieren, das zwei Klassen-Aufgaben ist."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also ein Beispiel sehen."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Input-Datensatz, der von Entitäten, Funktionen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zu der Klassifizierung des Textes, des Abstrakts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, wir haben das Sprachmodell so trainiert, dass es abstrakt und in der Klasse klassifiziert, ob die Abstrakt-Klasse in der Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Etikettvektor besteht in diesem Fall also immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren fertigen oder formulierten Feintuning-Ansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also das vollständige Framework betrachten."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und das set fade into fast"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Entity-Linking-Phase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensbasis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird die Aufgabe in eine Satz-Per-Classifikation-Tasche reformuliert."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und die Ausgabenwahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über n-1-Datensatz mit einer vorläufigen Multitask-Fine-Tuning verfeinert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu erstelltes Merkmal in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Rahmenwerk zu bewerten, verwenden wir eine Datenmenge mit siebzehn Tabellen, die Größe, Merkmale, Balance, Bereich und anfängliche Leistung variieren."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unser Experiment als Live-Out-Evaluierung gestaltet, bei der wir schnell über sechzehn Datensätze trainieren und sie auf das siebzehnte Datenset anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datensatz in vier Fehler auf und wenden eine Falten-Cross-Validation an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Funktionen und bewerten sie mit fünf Bewertungs-Klassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-Basis-Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Rahmenwerk mit der Feinabstimmung des Zieldatensatzes, der Feinabstimmung der Zielaufgabe und der vorläufigen Feinabstimmung der MTDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere Formulierung ist ein Feintuning, das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2% gegenüber der Feinabstimmung des Zieldatensatzes erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Poach hat eine Verbesserung um sechs Prozent erzielt."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Daten ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Feinabstimmung bei mehrere Aufgaben auf 1,5 Prozent abnimmt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung hat sich im Vergleich zu der Zielaufgabe, die allein mit der Feinabstimmung verbessert wurde, um elf Prozent zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Zusammenfassung ermöglicht Fast die Bereicherung von Fushot aus 35 Proben in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulationsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satzpaar-Klassifizierungsproblematik verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle. Heute werde ich unsere Forschungsarbeit Lernen zu reisen deduktiv, Methodenproblemlösung als komplexe Rasen-Extraktion vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Zahl stammt aus dem POWN-Papier, in dem sie Anweisungen zur Lösung des Methodenproblems in einem Fluch-Learning-Szenario ausführen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite können wir sehen, dass wir, wenn wir einige Beispiele nur mit Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch noch mehr Beschreibungen geben, kann das Modell die Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, als Ausgabe interpretierbares Mehrstufenrechnungsverfahren zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken auch, dass ein Methodenproblem eine einfache Anwendung zur Bewertung solcher Argumentationsfähigkeiten ist."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier müssen wir also in unserer Problemkonfiguration, angesichts der Fragen, diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser besonderen Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Größen bekannt ist"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren aufgeteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Eine frühere Arbeit im Lösungsproblem der Methode kann also tatsächlich in Sequenz- und Baummodell kategorisiert werden."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenzmodelle konvertieren den Ausdruck also in eine bestimmte Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ziemlich einfach umzusetzen und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil ist, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell und es fehlt an Interpretabilität für die Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Direction noch ziemlich populär, weil der Transformermodell"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also die Operatoren weiter, bis wir die Lifts erreichen, die die Größen sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt, aber es ist eigentlich ganz entgegengesetzt, weil wir zuerst den Operator generieren und dann am Ende die Größen generieren."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens enthält es auch einige wiederholte Berechnungen."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck hier ansehen, wird acht mal drei plus drei tatsächlich zweimal erzeugt. Aber tatsächlich sollten wir die Ergebnisse verwenden"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und in interpretierbaren Methoden lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diesen Teiler erhalten, der 27 ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir bei diesem dritten Schritt tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Okay. Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schritts tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als unser Anfangszustand ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Operatoren von QY bis QJ aus, und dieser Ausdruck ist tatsächlich gerichtet."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "So, wir haben hier auch Subtraction-Wert, um die entgegengesetzte Richtung zu repräsentieren."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie bei der Strahlungsauffnahme."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es in den nächsten Zustand hinzu, um eine neue Menge zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folien visualisieren also tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zuständen immer wieder Ausdrücke hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Sprachmodell, das Vögel oder Robetts sein kann, und dann kodieren wir den Satz und erhalten diese Mengenrepräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengen darstellen, können wir mit der Schlussfolgerung beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q4 multipliziert wird."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Anweisung, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist. Dann wenden wir ein Fit-Forward-Netzwerk an, das vom Operator parametriert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksrepräsentation Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Schlussfolgerung möglicherweise auch den falschen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier entspricht also jeder möglichen Ausdruck dreimal so viel wie die Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchbereich entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir noch eine Menge mehr haben."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe stammt aus dem vorherigen berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir diesen letzten Ausdruck Q3 erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke von dem vorherigen Schritt unterschiedlich ist."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede machen es schwierig, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsmethode ist ähnlich wie bei der Schulung eines Sequenzmodells, bei dem wir den Verlust bei jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch diese Tao, um darzustellen, wann wir diesen Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz anders, weil der Raum bei jedem Zeitpunkt anders ist, während es im traditionellen Sequenz- zu-Sequenz-Modell die Anzahl des Wortschatzes ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht es uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen zu verhängen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen also Experimente mit den häufig verwendeten Method-Problem-Datensätzen durch, MAWPS, Math23K, MathQA und SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Variante ist also Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir BeamSearch nicht, im Gegensatz zu offensichtlichen Ansätzen mit BeamSearch."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Okay, die besten Ansätze sind oft ein Baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Vernunft also dieses Baumbasierungsmodell deutlich übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MatQuery oder SWAM nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse weiter."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist eine Herausforderung, weil der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. irrelevante Informationen und zusätzliche Mengen hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Also, in unserer Vorhersage finden wir, dass einige der intermediären Werte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Pitchs und Stephen hat acht Pitchs, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse als negativ entfernen, damit wir die Antwort richtig machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert und bei dem Roberta-Basemodell tatsächlich zwei Punkte verbessert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat also bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Bert niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information angesehen werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der ungenutzten Mengen haben und der SWAMP-Datensatz den größten Teil enthält."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen ist die Gesamtleistung tatsächlich höher als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlimmer ist als die, äh, viel schlimmer als."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für MAWPS haben wir nicht wirklich viele Desk-Cases, also ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretationsfähigkeit durch ein Beispiel für die Zusammenstoßpartizierung zeigen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also tatsächlich eine falsche Vorhersage im ersten Schritt."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren, oder?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben also, dass dieser Satz das Modell in eine falsche Vorhersage führen könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man hier also noch 35 plant, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu ändern, dass er so aussieht wie die Anzahl der Birnenfäden fünfundfünfzig weniger ist als die Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen es also so, dass es genauere Semantik vermittelt, damit das Modell die Vorhersage richtig machen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell eigentlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können eine interpretierbare Lösungsmethode bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige vorherige Kenntnisse als Konstrakt einbeziehen, was uns helfen kann, die Leistung zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur für Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch für andere Aufgaben, die mehrtretende Argumentation beinhalten."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung in verschiedenen Zeitzonen unbalanciert ist, daher ist es auch ziemlich schwierig, Beam-Suche anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also das Ende des Vortrags und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Maastricht University."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein Johannes Werk mit Jerry vorstellen, das sich mit einem neuen Datensatz für die Abholung von gesetzlichen Artikeln befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein wesentlicher Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat wenig oder kein Wissen über ihre Rechte und grundlegenden Rechtsverfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Ergebnis sind viele vulnerable Bürger, die sich nicht die kostbare Assistance eines Legal Experts erwarten können, unprotegt oder worstens, exploitiert."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Lücke zwischen Menschen und dem Gesetz zu schließen, indem wir ein effektives Rückholsystem für gesetzliche Artikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte für unqualifizierte Menschen einen kostenlosen professionellen Rechtshilfenservice bieten."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem der statutarischen Artikelabholung."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ich eine einfache Frage zu einem rechtlichen Thema stelle, wie zum Beispiel: Was mache ich, wenn ich die professionelle Vertraulichkeit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetz zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe zur Informationserfassung bringt eine ganze Reihe von Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst geht es um zwei Sprachtypen."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "für die Fragen eine gängige natürliche Sprache und für die Statuten eine komplexe rechtliche Sprache."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in den Sprachverteilungen machen es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die mit der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das gesetzliche Recht kein Stapel unabhängiger Artikel, die als vollständige Informationsquelle an sich behandelt werden können, wie zum Beispiel Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Insted ist es eine Strukturkollektion von legalen Provisionen, die nur in der allgemeinen Kontext betrachtet sind, zusammen mit den zusätzlichen Informationen aus den neighbouring Artikeln, den Feldern und Subfeldern, zu denen sie gehören, und ihrer Platz in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, statutory Articles RN small paragraph, was usuell die typische Retrieval Unit in Most Retrieval Works ist."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Jahre dauern können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich NLP haben großes Interesse an vielen rechtlichen Aufgaben wie der Vorhersage von Rechtsentscheidungen oder der automatisierten Überprüfung von Vertragsverträgen weckt."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabholung ist jedoch aufgrund des Mangels an großen und hochwertigen gekennzeichneten Datensätzen größtenteils unberührt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir ein neues französisches, zentrales, zentrales Datenkett, um zu untersuchen, ob ein Rückholmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten für die Aufgabe der Statutorienartikelrückholung nähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Our Belgian Statutory Article Retrieval Data Sets consist von mehr als einem Jahrzehnt Liter."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnraum, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen hat von erfahrenen Juristen mit Referenzen zu relevanten Artikeln aus einem Corpus von mehr als twenty zwei Tausend sechshundert."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Codes of Law. Lassen Sie uns nun über die Erstellung dieser Datsätze sprechen."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir mit der Zusammenstellung eines großen Korpus an rechtlichen Artikeln begonnen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich verfügbare Belgische Codes und alle Artikel sowie die entsprechenden Abschnittshebungen entnommen."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf relevante Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich, auf ihre Websites zuzugreifen, wo ihr Team von erfahrenen Juristen Belgien's am häufigsten rechtlichen Probleme behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen zusammengestellt, mit Kategorien, Subkategorien und rechtlichen Verweisen auf relevante Statuten."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, wir passten die legalen Referenzen und filterten die Fragen aus, die Referenzen nicht Artikel in einem der Codes of Law wirkten."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Verweise wurden in die entsprechenden Artikel-IDs aus O Corpus abgestimmt und umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.108 Fragen, jeder sorgfältig mit den IDs der relevanten Artikel aus dem Buch."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich enthält jede Frage eine Hauptkategorie und eine Konkatenation von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel kommt mit einer Konkatenation ihrer nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzliche Information wird nicht in der Präsentation verwendet, aber sie könnte für zukünftige Research auf Legal Information Retrieval oder Legaltext Classification interessant sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale unserer Datensätze an."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Frage ist zwischen fünf und vierundvierzig Wort lang, mit einem Median von vierzig Wort."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer medianen Länge von sechzig sieben Wörtern, mit 140 Gramm."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei von ihnen, die eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine Vielzahl von Themen, von denen etwa 85 % entweder über Familie, Wohnraum, Geld oder Gerechtigkeit betraf."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Während die restlichen fünfzehn Prozent entweder mit der Sozialversicherung, Ausländern oder Arbeit zu tun haben."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr diverse, da sie aus dreißig zwei verschiedenen Belgischen Codes kommen, die eine große Anzahl von illegalen Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel aus jedem dieser belgischen Codes."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Aus den twenty two thousand six hundred thirty three Artikeln, nur eintausend sechs hundred twelve sind als relevant zu at least einem"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "nur eine Frage in den Daten sätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafverfolgungsgesetz."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen enthalten achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann durch die Tatsache erklärt werden, dass diese Codes weniger auf Einzelpersonen und ihre Anliegen fokussieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünf Prozent von ihnen sind in der"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen benchmarken wir verschiedene Rückholmethoden, einschließlich lexikalischer und denser Architektur."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrageartikelpaar eine Punktzahl zu, indem es die Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfragezeiten berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM-25-Rankingfunktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert und eine relevante Punktzahl zwischen einem Abfrage-Artikelpaar anhand der Ähnlichkeit ihrer Eingebettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit siamesischer Biancoder in einer Nullschussbewertung, was bedeutet, dass vorgebildete Word-Embedding-Modelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, und kontextunabhängigen Einbettungsmodellen, nämlich Roberta und genauer gesagt Camembert, das ein französisches Roberta-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes Camembert-basiertes Modell. Beyond quoters."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beispiele auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Flavors der Bianco architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Query und den Artikel in einem gemeinsamen Densivektorraum mappiert, und Tutor, das zwei unabhängige Word-Embedding-Modelle verwendet, die die Query und den Artikel separat in zwei verschiedene Embedding-Spaces codieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit dem Pooling von Mittel, Max und CLS sowie mit dem Punktprodukt und dem Kosinus für die Rechengelähnungen."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Ausgangslinie auf den Testsätzen."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Dann mit den lexikalischen Methoden oben, den Siamese-B-Encodern, die in einer Null-Schuss-Einrichtung evaluiert wurden, und den fein abgestimmten B-Encodern unten."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchore alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two Tower Modell verbessert sich gegenüber seiner Siamese-Variante auf Recallat one hundred, aber es funktioniert ähnlich bei den anderen Metriken."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five den trainierten Biancode erheblich unterlegen hat, zeigt seine Leistung, dass es immer noch eine starke Grundlage für Domain Specific Retrieval ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Was die Nullschussbewertung des siamesischen Biancoders betrifft, stellen wir fest, dass die direkte Verwendung der Eingebettungen eines vorgebildeten Kamembert-Modells ohne Optimierung für die Informationsabholungsaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir festgestellt, dass der Word-Tuec-basierte Biancoder den Vastex- und Vogelbasierten Modell deutlich übertrifft, was darauf hindeutet, dass möglicherweise vor-train-Word-Level-Embeddings für die Aufgabe besser geeignet sind als Charakter- oder Unterword-Level-Embeddings, wenn sie von vorn verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Möglichkeiten für Verbesserungen im Vergleich zu einem geschickten Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns mit zwei Einschränkungen aller Datensätze abschließen."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf die aus den 32 belgischen Gesetzen gezogenen beschränkt, die nicht das gesamte belgische Gesetz abdecken, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Referenzen zu diesen ungesammelten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl relevanten Artikeln erhalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsloss impliziert, dass die Antwort in den verbleibenden relevanten Artikeln unvollständig sein könnte, obwohl sie immer noch vollständig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Kann ich meine Mieter vertreiben, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Might not have a detaillierte Antwort innerhalb des gesetzlichen Gesetzes, das eine spezifische Noise-Threshold quantifiziert, bei der Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich mehr auf die Rechtsprechung vertrauen und Präzedenzfälle finden, die ähnlich zu ihrer aktuellen Situation sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Tenant zwei Parties pro Woche und tut es."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser als andere für die gesetzliche Artikel-Retrieval-Tasche geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass all diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur Berechnung von gesetzlichen Artikeln weckt,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Papier, Datset und Code unter den folgenden Links sehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorzustellen, einem unabhängigen Benchmark, der für die Testung von Vision- und Sprachmodellen mit bestimmten sprachlichen Phänomenen gedacht ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark festzulegen?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformer-basierten Vision- und Sprachmodellen gesehen, die auf große Mengen an Bild-Textpaaren vorgebildet wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle drängt die Moderne in der Vision und Sprachaufgaben wie der Antwort auf visuelle Fragen, der visuellen Sinnesreasoning, der Bildherstellung und der Phrase-Grundung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Nachricht erhalten. Die Genauigkeit dieser für die Aufgabe spezifischen Benchmarks steigt stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprachtransformer verstanden, als er diesem Bild und diesem Satz eine hohe Punktzahl zugewiesen hat, um es zu vereinbaren?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und der niedrige Punkt für diesen."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie durch frühere Arbeiten gezeigt?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf diesen Aspekt zu werfen, schlagen wir eine tauschfreundlichere Richtung vor und führen VALS ein, das die Empfindlichkeit von Seh- und Sprachmodellen auf spezifische sprachliche Phänomene testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Vielfalt, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenzen ab."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen festgehalten haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor nur für Vision und Sprachmodelle von Ravi Shakar und seinen Mitarbeitern für Nomenphrasen angewendet wurde, und bei der Zählung von uns in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde, dass wir den Bildunterschrift eines Bildes nehmen und einen Foil erzeugen, indem wir den Unterschrift so verändern, dass er das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Wir ändern diese Phrase, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenz, wobei jedes Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, FOIL-Instanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir im Fall des Aktionsstücks zwei Instrumente, eines, bei dem das Aktionsverb mit einer anderen Aktion geändert wird, und eines, bei dem die Spielzeuge ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Ko-Referenzen sind auch Stücke, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schaffen diese Fehler, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererseits gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach, da eine fehlerhafte Beschreibung weniger wahrscheinlich sein kann als die ursprüngliche Beschreibung."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es zwar nicht unmöglich, statistisch gesehen ist es weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann Pflanzen schneiden, und große Vision- und Sprachmodelle könnten dies aufgreifen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um gültige Folien zu erhalten, müssen wir daher Maßnahmen ergreifen."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir starke Sprachmodelle, um FOILs vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir die Inferenz durch natürliche Sprache oder kurz NLI, um Folien zu filtern, die das Bild noch beschreiben könnten, da wir bei der Konstruktion von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir eine Schlussfolgerung aus natürlicher Sprache mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Beschriftung als die damit verbundene Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In addition, wir betrachten die Kaption als die Premise und die FOIL als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell die FOIL als widersprechend oder neutral gegenüber dem Untertitel vorhersagt, nehmen wir dies als Indikator für eine gültige FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Folie durch den Untertitel enthalten ist, kann es keine gute Folie sein, da sie durch Transitivität eine wahrhaftige Beschreibung des Bildes liefert und wir diese Folien ausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Prozedere ist nicht perfekt. Es ist nur ein Indikator für valide Foil."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Erstellung gültiger FOILs menschliche Annotatoren, um die in Valse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir also so viele Testfälle wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um einen Benchmark für Null-Schuss-Tests handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vorausbildung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Die Feinabstimmung würde es den Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nutzen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vorausbildung haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen auf Vowels, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin I und VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bilder-Satzpaaren in Untertitel und FOILs."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht ist für dieses Video relevanter, dass wir unsere permissivere Metrik, die Paargenauigkeit, präsentieren, die misst, ob der Ausrichtungswert des Bildesatzes für das korrekte Textpaar des Bildes höher ist als für das fehlerhafte Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Metriken und Ergebnisse zu diesen Ergebnissen finden Sie in unserer Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit Paar-Präzision sind hier gezeigt und entsprechen den Ergebnissen, die wir aus den anderen Metriken erhalten haben. Die beste Leistung bei Nullschüssen wird von Wilbert zwölf in einem, gefolgt von Wilbert, LXMert, Clip und schließlich VisualBird erreicht."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert Twelve in One fast gelöst werden, wobei er hervorhebt, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann in unseren Adversarial Foiling-Einstellungen keine der verbleibenden Teile zuverlässig gelöst werden"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäten und Zählungsinstrumenten sehen wir, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Aktionen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie durch plausibel Vorurteile unterstützt werden, wie wir im Aktionsteil sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Bereich erfahren wir, dass es für Vision- und Sprachmodelle ebenfalls schwierig ist, mehrere Referenzen auf das gleiche Objekt in einem Bild mit Pronomen zu verfolgen."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Verstandskontrolle und weil es ein interessantes Experiment ist, haben wir auch zwei Textmodelle, GPT eins und GPT zwei, benchmarkt, um zu beurteilen, ob Valse durch diese Einmodalmodelle gelöst werden kann, indem wir die Verwirrung der richtigen und der fehlgeschlagenen Beschriftung berechnen und den Eintrag mit der geringsten Verwirrung vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die FOIL höher ist, nehmen wir dies als Hinweis darauf, dass die FOIL-Beschriftung unter einer plausibilen Voreingenommenheit oder anderen sprachlichen Voreingenommenheiten leidet."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die Text nur GPT Modelle die Plausibilität der Welt besser erfassen haben als die Vision und Language Modelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALS ein Benchmark ist, der die Linse der sprachlichen Konstruktionen nutzt, um der Community bei der Verbesserung von Seh- und Sprachmodellen zu helfen, indem sie ihre visuellen Grundlagefähigkeiten hart testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu begründen, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich ermutigen, VALS zur Messung des Fortschritts hin zur Sprachbasis mit Vision und Sprachmodellen zu verwenden."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, VALS könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von VALS getesteten Aspekte hilft."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, sollten Sie sich die Walls-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde eine Papier entitelt RNSAM, ein Large Scale DSET für automatische Risikogrammierung beim Commitologizieren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikogenerierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNote ist ein technisches Dokument, das die bei jeder Veröffentlichung eines Softwareprodukts zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Restnoten für Bosch 2.6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "User Us Library These Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consuming, um manuell zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, hochwertige Release-Noten automatisch zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Frischknotengenerierung verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste System, das Arena erstellt wurde, wurde 2014 erstellt."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert eine ruralbasierte Approach, zum Beispiel, indem man die Change Extractor verwendet, um Code differenzen, Bibliothekänder und Dokumentenänderungen von den differenzen zwischen Releases zu extrahieren, und schließlich kombinieren sie."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das bemerkenswerteste Merkmal dieses Systems ist der Ausgaben-Extraktor in der oberen rechten Ecke,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dieses muss mit dem Issues-Ökosystem verbunden sein und kann nur auf Projekte mit Null angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist Grief. Dies entweder angesagt in 2014."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "2020. Es ist auf dem Internet verfügbar und kann via PIP gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches Textklassifizierungsmodell basierendes auf Lernen und Ausgaben aus fünf Labors, wie z. B. Funktionen oder Fehlerbehebungen, für jede Eingabe-Kommentarnachricht."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Sample-User, das eine Korrektur für Fehlerkorrekturen erhält."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingdaten sind sehr klein, etwa fünftausend, und werden in den Experimenten beschriebenen unten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Kreuzschaltmodells ist nicht höher."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier löst diese beiden Probleme und erzeugt automatisch hochwertige Freigabe-Noten."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das begrenzte Anwendungsprogramm schlagen wir eine hochwertige Klassifizierungsmethode mit nur Kommentarmeldungen als Eingabe vor."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Repositories verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der Skarbstaatressourcen haben wir eine RNSAM DSET konsistent mit etwa 82.000 Datenpunkten erstellt, indem wir Daten aus öffentlichen GitHub Repositories mit der GitHub API erstellen."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unsere Daseinsetzung."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Nachricht des Komitees und die rechte Seite ist die Release-Note."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Riesen sind als Verbesserungen, Verbesserungen, etc. gelobt."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Kommentarnachrichten als Eingaben aufnimmt und die Raveled-Please-Notizen ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassungsaufgabe angesehen werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Rubber, Funktionen, Verbesserungen, Fehlerbehebungen, Deprekationen, Entfernungen und Bremsänderungen vorgedefiniert."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden aufgrund früherer Forschung und anderer Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Rhythmus-Noten unten rechts werden aus den Rhythmus-Noten unten links abgezogen."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Moment müssen die vier Schuttwerke, die im Voraus aufgestellt wurden, entdeckt werden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Lager sind nicht immer mit jeder Freiheit übereinstimmen"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, um Verbesserungen zu treffen, zu erhöhen, Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabulärliste mit etwa 30 Numbers für jede dieser Rotationsvariationen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Restnotkrasten zu erkennen und den Text der Restnotkrasten zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Komiteemeldung."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachrichten des Komitees sind nicht an jede Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der image below, wenn die aktuelle Realität Boson zwei Punkt fünf zwei neunzehn, müssen wir die IDECHTEN"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "erfüllt die vorherige Version 2.5218 und erhält einen Tiff. Dies ist ein bisschen mühsam und es reicht nicht aus, nur eine Liste der Releases zu erhalten und sich die Vorher und Nachher anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine Heuristik, die mit Ihnen übereinstimmt, um die vorherigen und nächsten Schauspielzeiten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind die Horses."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "In der Hand, siebentausend zwei hundert Repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Token 63, was für eine Zusammenfassungsaufgabe ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Nummer der Unique Tokens ist bei Roger at eight thousand eight hundred thirty thousand."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl von einzigartigen Kasten und Methoden im Repertory."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes erkläre ich die vorgeschlagene Methode."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Querschnitts-, Extraktions- und Abstruktionsmodell besteht aus zwei neuer Modulen"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifier mit Bot oder Code Bot und ein Generator mit Bot."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Klassifizierer, um jede Kommentarnachricht in fünf RESNOT-Klassen zu klassifizieren: Funktionen, Verbesserungen, Fehlerbehebungen, Duplizierungen und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als anderer eingestuften Komitee-Nachrichten werden abgelehnt."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GAS den Generator unabhängig auf die vier Rudder-Dokumente an und erzeugt für jede Klasse Risikonode."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Übereinstimmungen zwischen Commit-Nachrichten und Lesemerkungen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifizierer zu trainieren, weisen wir jeder Eingabe-Commit-Nachricht Pseudorabben zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Kreuzstreifen-Abstruktiv-Summersätze durch zwei verschiedene Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzigen SEC-Netzwerk und generiert einen einzigen Long-SNode-Text, der eine Kombination von Eingabe-Commit-Nachrichten liefert."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgangstext kann in Kreuzzeichen aufgeteilt werden, basierend auf speziellen Kreuz-Spezifischen Endpunkt-Symbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSMarch nennen, besteht aus vier verschiedenen SEC-to-SEC-Netzwerken, von denen jede einer der RES-Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das macht Spain's Experiment."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: CS, CS Single, CS Smart, Russelling und die vorherige Studienbeschreibung."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Abrissung sind in einigen Fällen diese Noten in mehreren Sätzen ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro ist penetrativ, wenn das System einen kurzen Satz ausgibt"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Brauvolumen. In den als nächstes beschriebenen Experimentenergebnissen"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erzeugen wir auch eine Spezifität, da Rouge und Brux nicht erzeugt werden können, wenn die Riesen-Knoten leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass die Modellprojekte ausgegeben sind, die in Fällen, in denen die Reasonals empfangen, empfindlich sind."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Daseit Emailadresse, Hashbarriers, etc. enthält, erweitern wir auch den Quint Daseit, der sie ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat und sie hat Rouge Air-Punkte erreicht, die mehr als zehn Punkte höher waren als die Baselines."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Green Test set, der Square Gap zwischen der proposierten Methode und der Basis jumped zu mehr als 20 Punkten."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie und sie erfolgreich sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS hat eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Crossfire und eines Generators auf das Training des Crossfire-Systems mit Pseudobus effektiv ist."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, weil der Klassifizierer sich auf die relevanten Kommittentests für jeden Kurs konzentrieren kann."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie isst in dieser Zeit viel höher als wenn sie ledig ist."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es auch effektiv ist, für jede dieser Notengrasse unabhängig verschiedene Perspektivsummerisierungsmodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hero und Eronasus"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xia's Methoden neigen dazu, kürzere Sätze als menschliche Referenz-Sätze zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Figur auf der rechten Referenz hat drei oder vier Sätze, während CS nur eins hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzugabe ist, dass in den Trainingsdaten nur 33 % der Sätze im Rabel Merkmale und 40 % im Rabel Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES Methoden ohne zusätzliche Informationen keine genauen Risikobewertungen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommentarmeldung, und die Kommentarfassung kann nicht generiert werden, ohne auf die entsprechende Peru-Request oder -Erstellung hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das untenstehende Beispiel zeigt, dass die beiden Kommentarberichte im Eingaben miteinander verbunden sind und in einen Satz kombiniert werden sollten, aber dies geschieht nicht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Personalgenerierung erstellt,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Kommentarmeldungen einzugeben und sie zusammenzufassen, sodass sie für alle Projekte auf Englisch anwendbar ist."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die Bassrate besser laut macht als die Bassrate."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte schauen Sie sich unsere Dessert-Audit-Tab an."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist ein Safarari,"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unsere Arbeit über die Anreicherung von Tabellen mit Hilfe von fein abgestimmten Transformatoren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Merkmale der Daten."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen begrenzt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Funktionen mit einer anderen Datenquelle kann erhebliche Informationen bieten."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung von Tabelldaten mit externen Quellen-Freitexten."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben eine Tabelldatensammlung und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Funktionen aus dem künstlichen Text der Wissensbasis zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel sehen. In einem Datensatz, der in FEST eingeführt wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist die Datenmenge Universitätsdatenmenge."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten zu unterteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festes ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Einheit, in diesem Beispiel der Name der Universität, mit einer Einheit innerhalb der Wissensbasis verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Knowledge-Basis wird extrahiert und in die Daten setzt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text der Abstrakt der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Funktionen aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen also eine Funktionsaufnahmephase, die Textanalyse beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde mich in den nächsten Folien tiefer damit befassen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Extraktionsphase der Merkmale gibt es eine Generierungsphase der Merkmale, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst generieren Sie Funktionen in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also, erstens zwei neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Funktion stellt die Wahrscheinlichkeit für jede Klasse dar."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, die sich auf Transformer basieren lassen, wie Baird, GPT, XLED und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe zur Feinabstimmung sein."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Funktionsauffnahme können wir also ein Parent-Train-Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell verfeinert, um Text in Klassen zu klassifizieren, abstrakt in Klassen, niedrig oder hoch."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse ist, und verwenden Sie sie als neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datenmengen möglicherweise wenige unterschiedliche Entitätsstapel haben."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Proben, und der kleinste Datensatz enthält fünfunddreißig Proben in seinem Trainings-Satz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorherige Kenntnisse über voranalyseierte Datensätze nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir den nth-Datensatz analysieren."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sugest, ist die Hälfte der Fine Tuning Phase."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Phase der Fine-Tuning-Multitask."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über n minus eins Datensätze finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine weitere Feinabstimmungsphase durch, die eine Feinabstimmung der Zielaufgaben ist, wenn wir das Sprachmodell über den n-Tiel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der neueste Stand der Multitask-Fine-Tuning, der MTDNN genannt wird."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN hält MTDNN eine Anzahl von Aufgaben im Trainingsatz aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainings-Set. Also leere DNN und halte vier Kopfhäupter, wie Sie auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es samplet eine zufällige Charge aus dem Trainingsset."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Run-Batch zu einer, zum Beispiel, Sing und Selton-Klassifizierungsaufgabe gehört, führt er einen Vorwärts- und Rückwärtspass durch den ersten Kopf aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zu einer Paar-Ranking-Tasche gehört, wird sie durch den letzten Kopf weitergegeben und zurückgegeben."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario verifiziert eine Datenmenge-Tabelle die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN hält die Anzahl der Klassen-Heads-Ausgaben-Schichten aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss MTDNN eine neue HEADS für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Task Reformulation Fine Tuning bezeichnet wird, besteht darin, dass wir in unserem Ansatz Task Reformation Fine Tuning statt mehrere Kopfgruppen zu behalten, jeden Datensatz in ein Satz pro Klassifizierungsproblem umformulieren, das zwei Klassen-Aufgaben ist."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also ein Beispiel sehen."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Input-Datensatz, der von Entitäten, Funktionen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zu der Klassifizierung des Textes, des Abstrakts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, wir haben das Sprachmodell so trainiert, dass es abstrakt und in der Klasse klassifiziert, ob die Abstrakt-Klasse in der Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Etikettvektor besteht in diesem Fall also immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren fertigen oder formulierten Feintuning-Ansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also das vollständige Framework betrachten."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und das set fade into fast"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Entity-Linking-Phase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensbasis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird die Aufgabe in eine Satz-Per-Classifikation-Tasche reformuliert."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und die Ausgabenwahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über n-1-Datensatz mit einer vorläufigen Multitask-Fine-Tuning verfeinert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu erstelltes Merkmal in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Rahmenwerk zu bewerten, verwenden wir eine Datenmenge mit siebzehn Tabellen, die Größe, Merkmale, Balance, Bereich und anfängliche Leistung variieren."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unser Experiment als Live-Out-Evaluierung gestaltet, bei der wir schnell über sechzehn Datensätze trainieren und sie auf das siebzehnte Datenset anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datensatz in vier Fehler auf und wenden eine Falten-Cross-Validation an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Funktionen und bewerten sie mit fünf Bewertungs-Klassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-Basis-Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Rahmenwerk mit der Feinabstimmung des Zieldatensatzes, der Feinabstimmung der Zielaufgabe und der vorläufigen Feinabstimmung der MTDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere Formulierung ist ein Feintuning, das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2% gegenüber der Feinabstimmung des Zieldatensatzes erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Poach hat eine Verbesserung um sechs Prozent erzielt."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Daten ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Feinabstimmung bei mehrere Aufgaben auf 1,5 Prozent abnimmt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung hat sich im Vergleich zu der Zielaufgabe, die allein mit der Feinabstimmung verbessert wurde, um elf Prozent zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Zusammenfassung ermöglicht Fast die Bereicherung von Fushot aus 35 Proben in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulationsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satzpaar-Klassifizierungsproblematik verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Assa Farari und ich werde unsere Arbeit FUSHOT Tabellendatenanbau mit fein abgestimmten Transformers-Architekturen vorstellen. Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Datenmerkmale, aber manchmal sind diese Merkmale begrenzt. Die Generierung von Merkmalen mit einer anderen Datenquelle kann erhebliche Informationen hinzufügen. Unser Forschungsziel ist die automatische Tabellendatenanbau mit externen Quellen, freiem Text. Nehmen wir an, wir haben eine Tabellendatenmenge und eine Wissensbasis. Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Merkmale aus dem kostenlosen Text der Wissensbasis zu extrahieren. Unser Framework FEST ist genau dieser automatische Prozess. Lassen Sie uns ein Beispiel betrachten. In einem Datensatz, der in FEST eingeführt wird. In diesem Beispiel ist der Datensatz ein Universitätsdatensatz, wenn sein Ziel es ist, Universitäten in niedrig rankende Universitäten und hochrangige Universitäten. Als Wissensbasis verwenden wir Wikipedia. Die erste Phase von FEST ist die Entitätslinkung, bei der jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität innerhalb der Wissensbasis verknüpft wird und der Text der Entitäten der Wissensbasis extrahiert und zum Datensatz hinzugefügt wird. In diesem Beispiel ist der Text der Wikipedia-Seitenabschnitt. Jetzt müssen wir Features aus dem erhaltenen Text generieren oder extrahieren. Wir benötigen also eine Feature-Extraction-Phase, die Textanalyse beinhaltet. Und das ist die Hauptnota dieser Arbeit, und ich werde mich in den nächsten Folien damit befassen. Nach der Feature-Extraction-Phase gibt es eine Feature-Generation-Phase, in der wir die extrahierten Features verwenden, um eine kleine Anzahl von Features zu generieren. Sie eine kleine Anzahl neuer Merkmale. Erstellen Sie zuerst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes. In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen, also erstellen Sie zuerst zwei neue Merkmale. Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Merkmale. Jede Merkmale repräsentiert die Wahrscheinlichkeit für jede Klasse. Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, nämlich transformierbare Sprachmodelle wie BERT, GPT, XLERT und so weiter. Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können. Daher wäre eine naive Herangehensweise die Feinabstimmung der Zielaufgabe. In der Fase der Extraktion der Funktionen können wir ein pertrainiertes Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset feinabstimmen. In diesem Beispiel können wir das Sprachmodell fe soll Text in Klassen, Abstract in Klassen, Low oder High, in Klassen eingeteilt, die Sprachmodell-Ausgaben erhalten, die für jede Klasse die Wahrscheinlichkeit sind, und als neue Funktionen verwendet werden. Das Problem bei diesem Ansatz ist, dass Daten sätze möglicherweise wenige unterschiedliche Entitäten wie Text enthalten. In unserem Experiment enthalten fast die Hälfte der Daten sätze weniger als 400 Samples und die kleinsten Daten sätze enthalten. Es enthält 35 Proben in seinem Trainings-Set. Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern. Wir können jedoch vorherige Kenntnisse über voranalysierte Datensätze nutzen, da wir FAST über mehrere Datensätze anwenden. Wir können die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir die nth Dataset. Was wir vorschlagen, ist eine weitere Fein-Tuning-Phase, eine preliminäre Multitask-Fein-Tuning-Phase, wenn wir das Languagemodell über n-1 Datasets fein-tunen. Und dann führen wir eine weitere Fein-Tuning-Phase aus, die eine Target-Task-Fein-Tuning ist, wenn wir das Languagemodell über das nth-Target-Dataset fein-tunen. Der Stand der Welt in der Multitask-Fein-Tuning-Phase. Fine-Tuning-Anwendung namens MTDNN. In MTDNN, MTDNN, mainten Sie eine Hälfte der Taschen im Trainingssatz. In diesem Beispiel gibt es vier Taschen im Trainingssatz. MTDNN mainten Sie vier Hälfte, wie Sie sehen können, im Bild. Es sampelt eine Random-Batch aus dem Trainingssatz. Und wenn die Random-Batch zu einem Zum Beispiel Singenselten's Classification-Tasks, es führt Vor- und Rückwärtspfade durch den ersten Kopf aus. Und wenn der Random-Batch zu Paar-Wise-Ranking-Task gehört, führt es Vor- und Rückwärtspfade durch den letzten Kopf aus. In unserem Szenario verringen Tableau-Datensätze die Anzahl der Klassen. Es gibt also viele Aufgaben. MTDNN-Mainten. DNN hält eine Reihe von Klassen-Heads-Ausgaben-Lagen aufrecht und zusätzlich muss MTDNN neue Heads für einen neuen Datensatz mit einer neuen Aufgabe initialisieren. Unser Ansatz, der als Task-Reformulation-Fine-Tuning bezeichnet wird, ist, dass wir in unserem Ansatz Task-Reformulation-Fine-Tuning, anstatt mehrere Heads aufrechtzuerhalten, jedes Datensatz in ein Satz pro Klassifizierungsproblem, das zwei Klassen-Taschen. Also, sehen wir ein Beispiel. Hier ist unser Input-Datensatz, der entweder von Entitäten, Funktionen, Text und Klassen besteht. Und wir reformulieren die Tasche von der Klassifizierung der Text in Low und High, um die Text, den Abstrakt und die Klasse in True oder False zu klassifizieren. Oder in anderen Worten, wir trainieren das Languagemodell, um eine Abstrakt- und Klassenklasse zu klassifizieren, ob die Abstrakt- und Klassenklasse zur Klasse gehören oder nicht. Der Etikettvektor bleibt in diesem Fall immer mit zwei Klassen bestehen. Und das ist der Algorithmus für unsere Find-Orientierung. find reformulated fine-tuning approach. Also, sehen wir uns den vollständigen Framework an. Ein Datensatz wird in FAST eingeführt und dann FAST execute in die Linkingphase. Es extrahiert den Text aus der Knowledge-Basis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist. Dann wird die Task reformuliert in Satz-Per-Classification-Tasks, das Sprachmodell auf die neue Task und die Ausgaben-Likelihood für jede Klasse. Beachten Sie, dass das Language-Modell bereits über n-1-Datensätze mit einer vorläufigen Multitask-Fine-Tuning abgestimmt ist. Dann verwenden wir den Ausgabenvektor des Language-Modells als neu generierten Funktion in der Anzahl der Klassen. Um unser Framework zu evaluieren, verwenden wir eine 17. Wir haben eine siebzehn-Tabellklassifizierungsdatensätze, die die Größe, die Merkmale, den Bereich und die anfängliche Leistung in Einklang bringt. Und als Wissensbasis verwenden wir Wikipedia. Wir haben unser Experiment als eine Live-Out-Evaluierung entworfen, bei der wir schnell über sechzehn Datensätze trainieren und sie auf die siebzehnte Datensätze anwenden. Wir haben auch jede Datensätze in vier Daten aufgeteilt. Wir erstellen Fehler und wenden eine Fork-Fehler-Kreuzvalidierung an. Dann generieren wir die neue Funktion und bewerten sie mit fünf Bewertungs-Klassifikatoren. In unserem Experiment verwenden wir eine auf Bild-Basis basierte Architektur. Hier sind die Ergebnisse unseres Experiments. Sie sehen, dass wir unser Framework mit der Feinabstimmung des Zieldatensatzes vergleichen, der Feinabstimmung der Zielaufgabe. und MTDNN preliminäre Feintuning und unsere reformulierte Feintuning erreichten den besten Ergebnis, die besten Leistungen, während MTDNN 2% Verbesserung über die Target-Datenset-Fine-Tuning erreichte. Unser Produkt erreichte 6% Verbesserung. Wenn wir uns die kleinen Daten ansehen, Aus dem Datensatz können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Fine-Tuning für mehrere Aufgaben auf 1,5 Prozent abnimmt, aber unsere Leistung steigt auf 11 Prozent im Vergleich zur alleinigen Fine-Tuning für die Zielaufgabe. Für die Zusammenfassung ermöglicht FAST die Bereicherung von Flux-Schüssen aus 35 Proben in unserem Experiment. verwendet eine Architektur für alle Aufgaben-Datensätze und behält den Kopf des Modells bei. Aber es fügt eine Formulierungsphase hinzu, es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satz-Par-Klassifizierungsproblematik verwenden können. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen. Heute werde ich unser Forschungswerk Lernen, deduktiv zu denken, Methodenproblemlösung als komplexe Rationsauffnahme vorstellen. Ich bin Alan vom Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD. Zunächst möchte ich über unsere Motivation für das Denken sprechen. Hier zeigen wir Beispiele, in denen mehrträgliches Denken hilfreich ist. Diese Zahl stammt aus der POWN-Artikel, in der sie die Anregung zur Lösung des Methodenproblems in einem Future-Learning-Szenario durchführen. Auf der Netto-Pan-Seite können wir sehen, dass wir, wenn wir einige Beispiele mit nur Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten. Wenn wir jedoch eine weitere Beschreibung geben, kann das Modell die Beschreibung vorhersagen und auch eine korrekte Vorhersage treffen. Es ist also gut, als Ausgabe interpretierbare Mehrstufige Beschreibung zu haben. Wir denken auch, dass das Methodenproblem eine einfache Anwendung ist, um solche Beschreibungsfähigkeiten zu bewerten. Hier in unserer Problemkonfiguration müssen wir diese Frage aufgrund der Fragen lösen und die numerischen Antworten erhalten. In unseren Datensätzen erhalten wir also auch den mathematischen Ausdruck, der auch zu dieser bestimmten Antwort führt. Daher gelten bestimmte Annahmen wie in früheren Arbeiten. Wir gehen davon aus, dass die Präzision von Größen bekannt ist, und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential. Darüber hinaus können komplizierte Operatoren tatsächlich ent in diese grundlegenden Operatoren aufgeteilt werden. Frühere Arbeiten im Lösungsproblem der Methode können also tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baummodell kategorisiert werden. Traditionelle Sequenz-zu-Sequenz-Modelle konvertieren den Ausdruck in eine spezifische Sequenz für die Generierung, und es ist ziemlich einfach zu implementieren, und es kann auf viele verschiedene komplizierte Probleme verallgemeinert werden. Aber die Nachteile sind, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell, und es fehlt an Interpretabilität für die die Vorhersage. Aber eigentlich ist diese Richtung aufgrund des Transformator-Modells immer noch ziemlich beliebt. In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen. Hier generieren wir also die Operatoren, bis wir die Blätter erreichen, die die Größen sind. Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt. Aber eigentlich ist es ziemlich kontraintuitiv. Denn wir generieren zuerst den Operator und dann am Ende die Größen. Und das Zweite ist, dass er auch einige wiederholte Berechnungen enthält. Wenn wir uns also diesen Ausdruck a mal drei plus drei ansehen, wird er tatsächlich zweimal generiert. Aber tatsächlich sollten wir die Ergebnisse wiederverwenden. In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und interpretierbar lösen. Zum Beispiel können wir hier im zweiten Schritt die Daten erhalten., die 27 sind. Und wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden. Und in diesen Schritten erhalten wir die Teiler. Und dann erhalten wir in diesem dritten Schritt tatsächlich den Quotienten. Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse des zweiten Schritts wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten. Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren. Dies macht den Prozess genauer. In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als Anfangszustände ein. Der Ausdruck wird also durch EIJOP dargestellt, bei dem wir Operatoren von Qi bis Qj ausführen, und dieser Ausdruck ist tatsächlich gelenkt. Wir haben hier auch eine Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen. Das ist ziemlich ähnlich wie eine Relationsentfernung. In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diesen neuen Ausdruck. Wir fügen ihn den nächsten Zuständen hinzu, um eine neue Größe zu erhalten. Diese Folien visualisieren tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zustand weiterhin Ausdrücke hinzufügen. In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Netzwerkmodell, das Vögel oder Roberto sein kann, und dann codieren wir den Satz und erhalten diese Mengenrepräsentationen. Sobald wir die Mengenrepräsentationen erhalten, können wir mit der Schlussfolgerung beginnen. Hier zeigen wir ein Beispiel für Q1, um die Repräsentation für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q3 multipliziert wird. Zuerst erhalten wir die Paarrepräsentation, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist, und dann wenden wir ein Fit-Forward-Netzwerk an, das ist. Dies wird durch den Operator parametriert. Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2. Aber in der Praxis könnten wir im Inferenzstadium auch den falschen Ausdruck erhalten. Hier sind alle möglichen Ausdrücke gleich dreimal so viele Operatoren. Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern. Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchraum entfernen. Im zweiten Schritt machen wir also das Gleiche, aber der einzige Unterschied ist eine weitere Größe. Diese Größe stammt also aus dem vorher berechneten Ausdruck. Schließlich können wir diesen endgültigen Ausdruck Q drei mal Q vier erhalten. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke vom vorherigen Schritt unterschiedlich ist. Solche Unterschiede machen es schwierig, ihn anzuwenden. Es ist schwer, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist. Der Trainingsverfahren ist ähnlich wie bei der Schulung eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust bei jedem Zeitschritt optimieren, und hier verwenden wir auch diese Zeichen, um darzustellen, wann wir diesen Generierungsprozess beenden sollten. Und hier ist der Raum von Sequenz zu Sequenz anders, da der Raum bei jedem Zeitschritt unterschiedlich ist, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Wortschatzes ist. Es ermöglicht uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen aufzustellen. Wir führen also Experimente mit den häufig verwendeten Methodenproblemdatensätzen durch, MAWPS, Math twenty three K, MathQA und SWAM. Hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen. Unsere am besten funktionierende Variante ist Roberta Deductive Reasoner. Tatsächlich verwenden wir nicht BeamSearch, im Gegensatz zu den vorherigen Ansätzen mitze sind oft ein Baumbasiertes Modell. Insgesamt kann unser Argumentationsmodell dieses Baumbasierten Modells deutlich übertreffen, aber wir können sehen, dass die absoluten Zahlen bei MathQA oder SWAM nicht wirklich hoch sind. Wir untersuchen die Ergebnisse bei SWAM weiter, und dieser Datensatz ist eine Herausforderung, da der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie zum Beispiel das Hininzufügung von irrelevanten Informationen und zusätzlichen Mengen. In unserer Vorhersage stellen wir fest, dass einige der Zwischenwerte tatsächlich negativ sind. In diesen Fragen fragen wir zum Beispiel, wie viele Äpfel Jake hat, aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Töne und Stephen hat acht Töne, was völlig irrelevant ist. Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt. Und wir beobachten, dass diese beiden Ausdrücke tatsächlich ähnliche Zahlen haben. Wir haben tatsächlich ähnliche Punktzahlen. Wir können also diesen Suchraum einschränken, indem wir diese negativen Ergebnisse entfernen, damit wir die Antwort richtig machen können. Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert. Zum Beispiel verbessern wir für Vögel sieben Punkte und für das Roberta-basierte Modell zwei Punkte. Ein besseres Sprachmodell hat also eine bessere Sprachverständnisfähigkeit, sodass die Zahl hier. Hier ist es höher für Roberta und niedriger für Vögel. Und wir versuchen auch, die Schwierigkeit hinter all diesen Daten zu analysieren. Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Informationen angesehen werden kann. Hier können wir also sehen, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und der SWAMP-Datenmenge den größten Teil hat. Und hier zeigen wir auch die Gesamtleistung für diese Proben ohne ungenutzte Mengen. Die Gesamtleistung ist also tatsächlich höher als die. Und die Leistung ist tatsächlich höher als die Gesamtleistung. Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlechter ist als die Gesamtleistung. Für MAWPS haben wir nicht wirklich viele Datenfälle, also ignoriere ich diesen Teil einfach. Schließlich möchten wir die Interpretbarkeit durch ein Beispiel für das Zusammenbruch zeigen. Hier macht unser Modell also tatsächlich eine falsche Vorhersage im ersten Schritt. Wir können diesen Ausdruck tatsächlich mit dem Satz hier korrelieren. Wir denken, dass dieser Satz das Modell mit einer falschen Vorhersage irreführt. Wenn wir hier also weitere 35 Pflanzen pflanzen, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte. Wir versuchen, den Satz so zu ändern, dass die Anzahl der Birnen 35 weniger als die Apfelbäume ist. Wir machen es also, um genauere Semantik zu vermitteln, sodass das Modell die Vorhersage richtig machen kann. Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Verhalten des Modells zu verstehen. Um unsere Arbeit abzuschließen: Zunächst ist unser Modell ziemlich effizient und wir können interpretierbare Lösungsmethoden bereitstellen, und wir können ein wenig vorheriges Wissen als Einschränkung einbeziehen, was die Leistung verbessern kann. Das letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch auf andere Aufgaben, die mehrträgliches Denken beinhalten. Wir haben aber auch bestimmte Einschränkungen. Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein. Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung bei verschiedenen Zeitstufen unbalanciert ist, daher ist es auch ziemlich schwierig, eine Beam-Suche-Strategie anzuwenden. Das ist also das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich bin von der Maastricht University. Ich werde meine gemeinsame Arbeit mit Jerry vorstellen, die sich mit einer neuen Datensammlung für die Erfassung von gesetzlichen Artikeln befasst. Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen, aber die Mehrheit der Bürger hat wenig bis kein Knowledge über ihre Rechte und grundlegenden Rechtsprozesse. Daher werden viele gefährdeten Bürger, die sich die kostspielige Unterstützung eines Rechtsexperten nicht leisten können, ungeschützt oder schlimmer gesagt, ausgenutzt. Unsere Arbeit zielt darauf ab, die Grenze zwischen Menschen und dem Gesetz zu schließen, indem er ein effektives Retrievalsystem für Statutartikel entwickelt. Ein solches System könnte eine freie professionelle Rechtshilfegemeinschaft für unqualifizierte Menschen bieten. Bevor wir uns auf den Hauptbegriff dieser Arbeit konzentrieren, sollten wir uns zunächst mit dem Problem der Statutartikelretrieval befassen. Bei einer einfachen Frage auf einem Rechtsmaterial, wie zum Beispiel was ich riskieren kann, wenn ich professionelle Privatsphäre verletze, ist ein Modell erforderlich, um alle relevanten Statutartikel aus einem großen Bereich der der Gesetzgebung. Diese Information Retrieval Task kommt mit seiner eigenen Setz von Challenges. Erstens geht es mit zwei Arten von Linguage, der normalen natürlichen Sprache für die Fragen und der komplexen legalen Sprache für die Statuten zu tun. Diese Differenz in Languageverteilungen macht es für ein System schwieriger, relevante Kandidaten zu retrieveren, da es indirekt eine inhärente Interpretationssysteme erfordert, die eine natürliche Frage zu einer rechtlichen Frage, die die Terminologie der Statuten entspricht, translatiert. Besides, statutory Law ist nicht ein Stack von Independent Artikeln, die als eine vollständige Source von Informationen auf der Own behandelt werden können, wie neue Rezepte, zum Beispiel. Instead, es ist eine Struktur, eine Sammlung von legalen Provisionen, die eine ganze Bedeutung nur in der allgemeinen Kontext haben, das ist zusammen mit der supplementären Information aus den neighbouring Artikeln, den Feldern und Subfields, die sie belong zu, und ihrer Platz in der Struktur der Laub. Lastly, statutory Artikel sind ein kleiner Paragraph. was in den meisten Retrievalwerken die typische Retrieval-Einheit ist. Hier sind es lange Dokumente, die bis zu sechstausend Wörter schreiben können. Die recenten Entwicklungen in NLP haben enorme Interesse in vielen Rechtsakten wie Legal Judgment Prediction oder automatisierten Kontaktkontraktreview gespielt, aber die Statutory Article Retrieval hat sich aufgrund der Lack von groß und hochwertigen Labeldatensätzen in der Lage geblieben. In dieser Arbeit präsentieren wir eine neue French Native Citizen Centric Datenset zu studieren, ob ein Retrievalmodell die Effizienz und Reliabilität eines Legal Experts für die Task der Statutory Article Retrieval angeht. Unser Belgisch Statutory Article Retrieval Datsatsatz besteht aus mehr als 1.100 legalen Fragen, die von Belgischen Bürgern gestellt werden. Diese Fragen umfassen eine wide Reihe von Themen von Familie, Housing, Money, bis hin zu Work und Sozialversicherung. Each of them ist von erfahrenen Juristen mit Referenzen zu relevanten Artikel aus einem Corpus von mehr als 22.600 legal Artikeln aus Belgischen Codes of Law. Lassen Sie uns nun über die Art und Weise sprechen, wie wir diese Daten setzen. Erst, wir starten mit der Compilierung eines Large Corpus von legal Artikeln. Wir betrachteten 32 öffentlich verfügbare Belgischen Codes und extrahierten alle Artikel sowie die correspondenden Section Headings. Dann gingen wir mit Referenzen zu relevanten Statuten zusammen. To tun so, wir partnerten mit der Belgischen Law Firma. jedes Jahr um viertausend Emails von Belgischen Bürgern, die um Rat und persönliche Rechtsfragen bitten. Wir hatten die Glück, Zugang zu ihren Websites zu bekommen, wo ihr Team erfahrener Juristen belgische am häufigsten rechtlichen Fragen behandelt. Wir sammelten Tausende von Fragen, die mit Kategorien, Subkategorien und Rechtsreferenzen zu relevanten Statuten angepasst wurden. Lastlich durchgingen wir die Rechtsreferenzen und filterten die Fragen, die nicht Artikel in einem der Codes of Law we considered. Die remaining Referenzen wurden matched und zu den corresponding Artikel IDs von O Corpus. Wir eventuell endeten mit einem Jahrhundert und acht Fragen, die sich sorgfältig mit den IDs der relevanten Artikel aus unserem Large Corpus von twenty two thousand six hundred thirty three Statutory Articles labelten. In addition, jeder Frage kommt mit einer Mainkategorie und einer Konkatenation von Subkategorien. Jeder Artikel enthält eine Konkatenation der nachfolgenden Überschriften in der Struktur des Gesetzes. Diese zusätzlichen Informationen werden in der aktuellen Arbeit nicht verwendet, aber könnten für zukünftige Forschungen zur Rechtsinformationserfassung oder zur Klassifizierung von Rechtstexten interessant sein. Schauen wir uns einige Merkmale unserer Datensätze an. Die Frage ist zwischen fünf und vierundvierzig Wörter lang mit einem Median von vierzig Wörtern. Die Artikel sind viel länger mit einem Median von siebzig sieben Wörtern, wobei einhundertvierundvierzig davon mehr als tausend Wörter betragen. Die Länge eines von fünftausend siebenhundert und neunzig Wörtern. Wie bereits erwähnt, umfassen die Frage eine breite Palette von Themen, wobei etwa achtzig Prozent davon entweder Familie, Wohnung, Geld oder Justiz betreffen, während die restlichen fünfzehn Prozent entweder Sozialversicherung, Ausländer oder Arbeit betreffen. Die Artikel sind auch sehr vielfältig, da sie aus dreißig zwei verschiedenen belgischen Gesetzen stammen, die eine große Anzahl von illegalen Themen abdecken. Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Gesetze gesammelt wurden. Von den 22.633 Artikeln werden nur 1.612 als relevant für mindestens eine Frage in den Datensätzen angegeben, und etwa 80 % dieser zitierten Artikel stammen entweder aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafgesetz. Inzwischen werden 18 von 32 Gesetzen weniger als fünf Artikel als relevant für mindestens eine Frage angege, die durch die Tatsache verursacht wird, dass diese Code weniger auf individuelle und ihre Anliegen fokussiert. Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünfundzwanzig Prozent von ihnen sind mehr als fünfmal citiert. Mit unseren Data sets benchmarken wir verschiedene Retrievalapproaches, einschließlich Lexical und Densarchitektur. Given eine query in einem Artikel, eine Lexicalmodelle assigniert eine Score zu den queryartikelpaaren. Durch die Berechnung der Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfrage-Terme. Wir experimentieren mit den Standard-TFIDF- und BM25-Rankingsfunktionen. Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten. Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die die semantische Beziehung zwischen Abfragen und Artikeln erfassen kann. Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert. und berechnen einen relevanten Punkt zwischen einem Artikelpaar der Abfrage anhand der Ähnlichkeit ihrer Eingebettungen. Diese Eingebettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Eingebettungsmodells. Zunächst untersuchen wir die Effektivität siamesischer B-Encoder in einer Zero-Shot-Evaluierungs-Einrichtung, was bedeutet, dass vorgebildete Word-Eingebettungsmodelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden. Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und Fastastex und kontextabhängige Embeddingmodelle, nämlich Roberta und speziell Kamembert, ein französisches Roberta-Modell. Darüber hinaus trainieren wir unsere eigenen Kamembert basierenden Biencoders auf allen Datenmengen. Beachten Sie, dass wir für das Training mit den beiden Arten der Biencoder Architektur experimentieren. Siamese, das ein einzigartiges Wort-Embeddingmodell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraum mappiert. Und Tutor, das zwei unabhängige Wort-Embeddingmodelle verwendet. Wir haben zwei Independent Word Embedding Models, die den Query und Artikel separat in verschiedene Embeddingsphasen codieren. Wir experimentieren mit Mean, Max und CLS Pooling sowie Dot Product und Cosine für die Computing-Similaritäten. Hier sind die Ergebnisse unserer Baseline auf dem Testset, mit den Lexikonmethoden oben, den Siamese BE Encoders evaluiert in einem Zero Shot Setup in der Mitte, und den Fein Tun BE Encoders unten. Overall, die Fein Tun BE Encoders übertragen alle anderen Baselines. seine Siamese-Variante auf RECOLAT 100, aber ähnlich auf den anderen Metriken abschneidet. Obwohl BM 25 den trainierten Biancoder erheblich unterlegen hat, deutet seine Leistung darauf hin, dass es immer noch eine starke Grundlage für Domain-spezifische Rückholung ist. Bei der Zero Shot Evaluation des Siamese Biancoders finden wir, dass die direkte Verwendung der Embeddings eines vortrainierten Kamembert-Modells ohne Optimierung für die Informationsaufnahmeaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt. Der Word-to-Vec-basierte Biancoder übertraf die Fastex- und Vogelbasierten Modelle deutlich, was darauf hindeutet, dass möglicherweise vor-train-Word-Einbettungen für die Aufgabe angemessener sind als Charakter- oder Unterword-Einbettungen, wenn sie von Anfang an verwendet werden. Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Verbesserungsmöglichkeiten im Vergleich zu einem geschickten Experten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann. Lassen Sie uns mit zwei Limitationen von allen Datensätzen beginnen. Erstens ist der Corpus von Artikeln limitiert zu denen, die aus den dreißig zwei betrachteten Belgischen Codes erfasst werden, was nicht den gesamten Belgischen Law abdeckt, da Artikel aus Dekrees, Direktives und Ordinanzen enthalten sind. Durch die Datensatzkonstruktion werden alle Referenzen zu diesen unkollektierten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Fragment der initialen Anzahl relevanter Artikeln enthalten. Dieser Informationlaus impliquiert, dass die Antwort in den remaining relevanten Artikelnkel könnten incomplete sein, obwohl es immer noch vollständig appropriate ist. Second, wir sollten merken, dass nicht alle Rechtsfragen mit Statuten alone beantwortet werden können. For instance, die Frage kann ich meine Tenants evicten, wenn sie zu viel Noise machen, könnte nicht eine detaillierte Antwort in statutory Law enthalten, die eine spezifische Noise Threshold at which Eviction ist. Insted sollten die Landlage wahrscheinlich mehr auf Fallslaw und Präceden ähnlich wie der aktuelle Situation finden. Zwei Parteien pro Woche bis 2 Uhr morgens. Daher sind einige Fragen besser als andere für die Aufgabe der gesetzlichen Artikelerfassung geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen. Wir hoffen, dass unsere Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle der gesetzlichen Artikelerfassung weckt, die den Zugang zur Justiz für alle verbessern können. Sie können sich unsere Arbeit Datensätze und Code unter den folgenden Links ansehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir sind froh, unsere Arbeit auf VALS, einem Taskindependenten Benchmark für das Testen von Vision und Language Models mit spezifischen linguistiken Phänomenen zu präsentieren. Warum haben wir uns die Trouble in der Setzung dieses Benchmarks gemacht? Nun, während der letzten Jahre haben wir eine explosion von Transformer basierten Vision und Language Models, die auf große Mengen von Image Textpaaren geprägt sind. Each dieser Modelle pusht State of the Art auf Vision und Language Tasks, wie z. B. visuelle Fragen Sinnesrechnung, Bildretrieval, Phrase-Grundung. Wir haben also eine Nachricht, die Akuragen auf diesen spezifischen Benchmarks steigern, aber wissen wir, was die Modelle tatsächlich gelernt haben? Was hat ein Vision und Language Transformer verstanden, als er eine High Score für dieses Bild und diesen Satz zugewiesen hat und eine Low Score für dieses Bild? Fokusieren Vision und Language Models auf das Richtige oder konzentrieren sie sich auf Biasen? wie gezeigt durch vorherige Arbeit. Um mehr Licht auf diesen Aspekt zu senden, propellieren wir eine mehr task agnostic direction und einführen WALS, das die Sensitivität von Vision und Language Models zu spezifischen linguistiken Phenomenen, die sowohl die linguistic als auch die visuelle Modalitäten beeinflussen. Wir targen Existenz, Pluralität, Zählung, Spatialrelationen, Aktionen und Entity Coreference. Aber wie testen wir, ob die Vision und Language Models diese Phenomena erfasst haben? Foiling, eine Methode, die vorher für Vision und Language Models, nur für Nanphrasen von Ravi Shakar und Kollaborators und auf Counting von Asin previous worked. Foiling basically means, dass wir den Caption of an Image und einen Foil produzieren, indem wir den Caption so verändern, dass er nicht die Image anymore beschreibt. Und wir machen diese Phrasealterations, indem wir uns auf sechs spezifische Pieces wie Existenz, Pluralität, Counting, Spatialrelations, Actions, und Entity Coreference. Jede Piece kann aus einem oder mehreren Instrumenten bestehen, in dem Fall, dass wir mehr als eine interessante Möglichkeit gefunden haben, FOIL instanzen zu erstellen. Zum Beispiel haben wir in der Fall der Aktionspiece zwei Instrumente, einen in dem das Action verb mit einer anderen Action geändert wird und einen in dem Actants gewechselt werden. Zählen und Coreferenz sind auch Pieces, die mehr als eine Instrumenten haben. Und wir erstellen diese FOILs, indem wir unserstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererweit validierten Sätze sind. Dies ist nicht einfach zu tun, weil eine Foiled Caption weniger wahrscheinlich ist als die ursprüngliche Caption. Zum Beispiel, though it's not impossible, ist es statistisch weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann, und Largevision und Language Models könnten dies erkennen. Daher müssen wir, um valid Foils zu erhalten, Action unternehmen. Erstens, wir machen uns auf Strong Language Models zu propellieren. Zweitens, wir verwenden Natural Language Inference oder NLI, um Foils zu filtern, die noch beschreibiben das Bild immer noch, da wir bei der Konstruktion von FOILs sicherstellen müssen, dass sie das Bild nicht beschreiben. Um dies automatisch zu testen, wenden wir eine natürliche Sprachinferenz mit der folgenden Begründung an. Wir betrachten ein Bild als die Premise und seine Beschriftung als die damit verbundene Hypothese. Darüber hinaus betrachten wir die Beschriftung als die Premise und die FOIL als ihre Hypothese. Wenn ein NLI-Modell die FOIL zu widersprechen oder neutral zu den Beschriftungen zu sein, nehmen wir dies als Indikator für eine gültige FOIL. Wenn wir die Foil zu beentalten, kann es nicht eine gute Foil sein, da es durch Transitivität eine truthliche Beschreibung der Image geben wird und wir diese Foils ausfiltern. Aber dieser Prozess ist nicht perfekt. Es ist nur ein Indikator für valide Foils, daher als eine dritte Möglichkeit für die generierung von valid Foils, wir verwenden Humananannotators, um die Daten zu validieren, die in Valse verwendet werden. Also, nach Filtering und Human Evaluation, wir haben so viele Testinstanzen wie in dieser Tabelle. Note, dass Valse nicht trainierend Daten liefert. Aber nur Testdaten, da es sich nur um einen Benchmark für Null-Shot-Tests handelt. Es ist darauf ausgelegt, die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vor-Training-Aktivität zu nutzen. Die Feinabstimmung würde es Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen. Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen einschlagen. Und wie wir sagten, sind wir daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vor-Training-Aktivität haben. Wir experimentieren mit fünf Vision- und Sprachmodellen auf WALS, nämlich mit CLIP, Wilbert, Wilbert Kelvin I und Visual Bert. Zwei unserer wichtigsten Evaluierungsmetriken sind die Accuracy der Modelle in der Klassifizierung von Image Sentenzenpaaren in Untertitel und Foils. Perhaps für dieses Video mehr relevant, wir werden unsere permissive Metrik, die Paarwise Accuracy, die messen, ob die Image Sentenz alignment score für die korrekte Image Textpaar als für ihre Foilpaar ist. Für mehr Metriken und Ergebnisse auf themen, doch checken Sie unsere Papier. Die Ergebnisse mit Paarwise Accuracy sind hier und sie sind konsistent mit den Ergebnissen, die wir von den anderen Metriken bekommen haben. Es ist, dass die besten Zero Shot Performance durch Wilbert zwölf in one, gefolgt von Wilbert, Alex Mert, Clip, und schließlich Visual Bird. Es ist notabel, wie Instrumente centered on individuelle Objekte wie Existenz und Nounphrases fast solviert werden, wobei Wilbert zwölf in one, highlighting, dass Models ableistisch genannte Objekte und ihre Präsenz in Images identifizieren können. Allerdings können none der remaining Pieces in unseren adversarialen Foiling-Settings reliably solviert werden. Instrumenten, dass Vision und Language Models Trouble distinguisieren, referenzieren zu single versus multiple Objekten oder in einem Image. Die Relation Piece zeigt, dass sie Schwierigkeiten haben, eine named spatiale Relation zwischen Objekten in einem Image zu klassifizieren. Sie haben auch Trouble, Aktionen zu distinguieren und ihre Partizipanten zu identifizieren, selbst wenn sie durch Plausibility bias sind, wie wir in der Aktionspiece sehen. Aus der Referenzpiece finden wir, dass das Tracing multiple Referenzen zu dem gleichen Objekt in einem Image durch Pronouns auch für Vision und Language Models. Als eine Sanity Check und weil es ein interessantes Experiment ist, benchmarken wir auch zwei Textonlegermodelle GPT one und GPT two, um zu assessieren, ob Valse solvable durch diese Unimodalmodelle ist, indem wir die Perplexität der korrekt und der foiled Caption, keine Image hier, und die Entry mit der lowest Perplexität. Wenn die Perplexität höher für die Foil ist, dann nehmen wir dies als eine Indikation, dass die foiled Caption möglicherweise von Plausibility bias oder anderen linguistiken Biasen leidet. Und es ist interessant zu sehen, dass in einigen Fällen Die Textmodelle nur GPT haben die Plausibilität der Welt besser erfasst als die Vision und Language Models. Zusammenfassend ist VALSE ein Benchmark, das die Lensen von Linguistikkonstrukten verwendet, um die Community zu helfen, Vision und Language Models zu verbessern, indem sie ihre visuellen Grounding-Fähigkeiten hart testen. Unsere Experimente zeigen, dass Vision und Language Models namensgelegene Objekte in ihrer Präsenz in Bildern gut identifizieren, wie gezeigt durch das Existenzstück, aber es schwerwiegt, ihre Interdependence und Relationships in visuellen Szenen zu genehmigen, wenn sie gezwungen sind, linguistic Indikatoren zu respektieren. Wir möchten die Community wirklich ermutigen, Valse zur Messung des Fortschritts hin zur Sprachbasis mit Vision- und Sprachmodellen zu verwenden. Und noch mehr, Valse könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von Valse getesteten Aspekte hilft. Wenn Sie interessiert sind, sollten Sie sich die Valse-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamisara von der University of Tokio. Ich werde eine Papier entitelt RNSAM, ein großes Dasein für automatische Restnoturation bei der Commit Dog Summization. Ich werde in dieser Ordnung erklären. Erst, ich werde die automatische Restnoturation, die wir in dieser Research arbeiten, einführen. ReleaseNode ist ein technischer Dokument, das die Changes mit jedem Release von einem Softwareprodukt zusammenfasst. Das Image zeigt die ReleaseNode für Version zwei. sechs. vier der GBUJS Library. Diese Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consumierend zu erstellen. Daher wird es sehr nützlich sein, automatisch hochqualitäre Release Nodes zu generieren. Ich werde auf zwei frühere Researchers auf automatische Release Node Generation eingehen. Der erste ist ein System namens Arena, das in twenty fourteen erstellt wurde. Es ergreift eine Rule basierende Approach, zum Beispiel, indem es die Change Extractor verwendet, um Code differenzen zu extrahieren. Bibliotheksänderungen und Dokumentenänderungen von den differenzierten Releases und schließlich kombinieren. Die meisten erkennbaren Funktionen dieses Systems sind die Issue Extractor in der oberen rechten Ecke, die mit Jira, dem Issue Toco System, verknüpft und nur für Projekte verwendet werden kann. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden. Die zweite ist Griff, die Entry angeboten wurde in twenty twenty. Sie ist auf dem Internet und kann durch PIPSTEMENSSER Dieses System hat ein einfaches Lernbasis für Textklassifikation und erhält eine von fünf Rabellen, die Funktionen oder Bugfixen für jedes Input Commit-Message enthalten. Das Bild ist eine Sample-Usage, die eine korrekte oder Bugfixen-Rabelle enthält. Die gerade erstellten Rabellen sind ziemlich klein, etwa fünftausend, und werden in den Experimenten beschriebenen darüber gezeigt. Die Leistung des Textklassifikationsmodells ist nicht hoch. Ich präsentiere zwei related Researchers, aber es gibt Probleme mit begrenztem Erwerb und geringen Daten. und Scar State Resources. Unser Papier löst diese beiden Probleme und automatisch generiert High Quality Releasing Notes. Für das limitierte Applicability Programm, wir propagieren eine High Quality Classifier Summarization Methode, die nur Committee Message als Input verwendet. Diese Methode kann für alle English Repositories verwendet werden. Für das zweite Problem der Scar State Resources, wir bauen RL und SAM DSET konsistent mit etwa achtzig zwei Tausend Pieces von Daten, die von öffentlichen GitHub API. Next, ich beschreibe unser Desert. Hier ist ein Beispiel für Daten. Die linke Seite ist ein Commit Message und die rechte Seite ist die RISE Nodes. Die RISE Nodes sind Raveled als Implement, Bug fixes, etc. Wir haben eine Task setup, die die Commit Messages als Input und die Raveled RISE Nodes aufwendet. Dies kann als eine Summarization Task bezeichnet werden. Wir haben vier Raveled Features, Implement, Bug fixes, Duplications, Removables und Breaking Changes. Diese wurden basierend auf PBR research und anderen Faktoren. Die RISE Noten auf der bottom right und extrahiert von den RISE Noten auf der bottom left. At diesem Zeitpunkt ist es notwendig, die vier Rabels zu detektieren, die in der Passage sind, aber die Rabels sind nicht immer konsistent mit jeder Repository. Zum Beispiel, die Improvements Rabels inklusive Improvements, Enhancements, Optimisations und so weiter. Wir haben eine Vokabularliste oder Studie Rabels für jeden dieser Notation. variations. Verwenden Sie es, um die Restknoten zu erkennen und den Text der Restknoten zu korrigieren. Als nächstes kommt eine Kommittemessage. Kommittemessagen sind nicht zu jeder Rest. Wie in der image below, wenn die aktuelle Rest Persönlich 2.5219 ist, müssen wir die vorherige Rest Persönlich 2.5218 identifizieren und einen Tiff erhalten. Dies ist ein bisschen tedious und es ist nicht genug, nur eine Rest der Restknoten zu erhalten. Und wir haben die Vorhand nach. Wir haben eine heuristic Matching Blue erstellt, um die vorherigen und nächsten Persönlichkeiten zu erhalten. Dasset Analysis In der End, 7.200 Repositories und 82.000 PSO wurden korrektiv. Außerdem ist die average Anzahl von ReleaseNode Tokens 63, was für eine Summarisation Task ziemlich hoch ist. Außerdem ist die Anzahl von Unique Tokens ziemlich groß, also 8.830.000. Dies ist auf die große Anzahl von Unique Kosten und Methoden zurück namens in der Repository. Next, ich werde explain die proposierte Methode. Das Crosswise Extractive and Abstractive Summarization Model besteht aus zwei neuronalen Modules, einem Classifier, der Bot oder Code Bot und einem Generator, der Bot verwendet. Erstens, GAS verwendet einen Classifier, um jedes Committee Message in fünf Risnode Classes, Features, Improvements, Bugfixes, Duplications, Plus, und andere. Die Committee Messages klassifiziert als andere oder diskutiert. Dann GAS wendet einen Generator zu den vier Rabelschnitteln unabhängig und generiert RISE NOTE für jeden Kurs. In diesem Zusammenhang sind die direkten Korrespondenzen zwischen Commit Messages und RISE NOTE nicht bekannt. Daher, um den Kurs zu trainieren, wir zwar Rabelschnitteln zu jedem Input Commit Message verwenden, indem wir die ersten zehn Charaktere für jedes Commit Message verwenden. Wir modellieren den Kurs abstruktiven Summarisierungsansatz durch zwei verschiedene Methoden. Das erste Modell, das wir als GAS Single Sync konsist von einer Sync zwei Sync Network und generiert eine Sync Long RISE Node Tagist, geben eine Konkurrenz von Input Committee Messages. Die Output Tagist kann in Crosswise Segment basierend auf speziellen Cross Specific Endpoint Symbols unterteilt werden. Die zweite Methode, Methode, die wir CSMUCH, besteht aus vier verschiedenen Sync zwei Sync Networks, jeder von denen zu einer der RISE Node Classes entspricht. Okay, lassen Sie mich das Experiment erklären. Fünf Methoden wurden GS, GS Single, GS Marge, Russelling und previous studied Griff. Regarding Abortion, in einigen Fällen, diese Noten sind in multiple Sentenzen. Da es difficil ist, die Nummer von Sentenzen zu erkennen, sind sie kombiniert mit Spaces und treaten als ein langer Satz. Der Blue ist penalisiert, wenn das System einen kurzen Satz erfährt. Diese Penalty resultiert in einem loweren Blue Value in den Experimenten der Results describiert. Finally, wir auch die Spezifität erkennen, weil Rouge und Brew nicht erkennen können, wenn die Rouge Nodes leer sind. Eine hohe Spezifität bedeutet, dass die Modellkorrektie auspackt ist, in denen die Rouge Nodes leer sind. Hier sind die Ergebnisse. Da der Daseit Emailadresse, Hashbarrieren, etc. enthält, haben wir auch den Green Daseit erkannt, der sie ausschließt. GAS und GAS erreichten Rouge Error Scores mehr als zehn Punkte höher als die Baselines. Auf dem grünen Testset stieg die Score-Gap zwischen der vorgeschlagenen Methode und der Basis auf mehr als zwanzig Punkte. Diese Ergebnisse zeigen, dass GAS und GAS signifikant effektiv sind. GAS erreichte eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Klassifierers und eines Generators effektiv ist und das Training des Klassifierers mit Pseudoberseiten. Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, da der Klassifier sich auf das Sekten relevanter Kommittemechanismen für jede Klasse konzentrieren kann. Xia ist viel zu höheren Ruder als Xia single, suggesting, dass es auch effektiv ist, unterschiedliche perspektive Summarisationsmodelle für jedes Nodecraft zu entwickeln. Hier sind Erronnas. Xia's Methods tend to output shorter Sentenzen als humanen Referenz Sentenzen. In der Figur auf der rechten Referenz Sentenzen hat drei oder vier Sentenzen, während Xia nur eins hat. Der Grund für diese Modellrücktanz ist, dass in den Trainingdaten nur 33 Prozent der Sentenzen sind in der Features Rabel und 40 Prozent in der Improvements Rabel. Für die More CS Methods können nicht akurat mit Noten ohne zusätzliche Informationen generiert werden. Das Top Exempel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommittemessage und die Komplettesentence kann nicht generiert werden, ohne dass es sich auf die correspondente Periodrequest oder Issue bezieht. Das Beispiel below zeigt, dass die zwei Kommittemessagen in der Input related und sollten kombiniert werden. Aber es versucht dies zu tun. Schließlich eine Konklusion. Wir haben eine neue DSET für automatische Rezensionsschnittgenerierung erstellt. Wir haben auch die Aufgabe erstellt, Kommentarn zu enthalten und sie so zu summarisieren, dass sie für alle Projekte in Englisch anwendbar ist. Unser Experiment zeigt, dass die vorgeschlagene Methode weniger Noisy Rezensionsschnittgenerierung bei höherer Abdeckung als die Basisrate erzeugt. Bitte schauen Sie sich unsere DSET auf GitHub an. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle. Heute werde ich unsere Forschungsarbeit Lernen zu reisen deduktiv, Methodenproblemlösung als komplexe Rasen-Extraktion vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Zahl stammt aus dem POWN-Papier, in dem sie Anweisungen zur Lösung des Methodenproblems in einem Fluch-Learning-Szenario ausführen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite können wir sehen, dass wir, wenn wir einige Beispiele nur mit Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch noch mehr Beschreibungen geben, kann das Modell die Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, als Ausgabe interpretierbares Mehrstufenrechnungsverfahren zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken auch, dass ein Methodenproblem eine einfache Anwendung zur Bewertung solcher Argumentationsfähigkeiten ist."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier müssen wir also in unserer Problemkonfiguration, angesichts der Fragen, diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser besonderen Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Größen bekannt ist"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren aufgeteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Eine frühere Arbeit im Lösungsproblem der Methode kann also tatsächlich in Sequenz- und Baummodell kategorisiert werden."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenzmodelle konvertieren den Ausdruck also in eine bestimmte Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ziemlich einfach umzusetzen und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil ist, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell und es fehlt an Interpretabilität für die Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Direction noch ziemlich populär, weil der Transformermodell"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also die Operatoren weiter, bis wir die Lifts erreichen, die die Größen sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt, aber es ist eigentlich ganz entgegengesetzt, weil wir zuerst den Operator generieren und dann am Ende die Größen generieren."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens enthält es auch einige wiederholte Berechnungen."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck hier ansehen, wird acht mal drei plus drei tatsächlich zweimal erzeugt. Aber tatsächlich sollten wir die Ergebnisse verwenden"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und in interpretierbaren Methoden lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diesen Teiler erhalten, der 27 ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir bei diesem dritten Schritt tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Okay. Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schritts tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als unser Anfangszustand ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Operatoren von QY bis QJ aus, und dieser Ausdruck ist tatsächlich gerichtet."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "So, wir haben hier auch Subtraction-Wert, um die entgegengesetzte Richtung zu repräsentieren."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie bei der Strahlungsauffnahme."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es in den nächsten Zustand hinzu, um eine neue Menge zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folien visualisieren also tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zuständen immer wieder Ausdrücke hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Sprachmodell, das Vögel oder Robetts sein kann, und dann kodieren wir den Satz und erhalten diese Mengenrepräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengen darstellen, können wir mit der Schlussfolgerung beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q4 multipliziert wird."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Anweisung, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist. Dann wenden wir ein Fit-Forward-Netzwerk an, das vom Operator parametriert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksrepräsentation Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Schlussfolgerung möglicherweise auch den falschen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier entspricht also jeder möglichen Ausdruck dreimal so viel wie die Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchbereich entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir noch eine Menge mehr haben."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe stammt aus dem vorherigen berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir diesen letzten Ausdruck Q3 erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke von dem vorherigen Schritt unterschiedlich ist."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede machen es schwierig, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsmethode ist ähnlich wie bei der Schulung eines Sequenzmodells, bei dem wir den Verlust bei jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch diese Tao, um darzustellen, wann wir diesen Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz anders, weil der Raum bei jedem Zeitpunkt anders ist, während es im traditionellen Sequenz- zu-Sequenz-Modell die Anzahl des Wortschatzes ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht es uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen zu verhängen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen also Experimente mit den häufig verwendeten Method-Problem-Datensätzen durch, MAWPS, Math23K, MathQA und SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Variante ist also Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir BeamSearch nicht, im Gegensatz zu offensichtlichen Ansätzen mit BeamSearch."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Okay, die besten Ansätze sind oft ein Baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Vernunft also dieses Baumbasierungsmodell deutlich übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MatQuery oder SWAM nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse weiter."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist eine Herausforderung, weil der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. irrelevante Informationen und zusätzliche Mengen hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Also, in unserer Vorhersage finden wir, dass einige der intermediären Werte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Pitchs und Stephen hat acht Pitchs, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse als negativ entfernen, damit wir die Antwort richtig machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert und bei dem Roberta-Basemodell tatsächlich zwei Punkte verbessert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat also bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Bert niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information angesehen werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der ungenutzten Mengen haben und der SWAMP-Datensatz den größten Teil enthält."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen ist die Gesamtleistung tatsächlich höher als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlimmer ist als die, äh, viel schlimmer als."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für MAWPS haben wir nicht wirklich viele Desk-Cases, also ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretationsfähigkeit durch ein Beispiel für die Zusammenstoßpartizierung zeigen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also tatsächlich eine falsche Vorhersage im ersten Schritt."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren, oder?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben also, dass dieser Satz das Modell in eine falsche Vorhersage führen könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man hier also noch 35 plant, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu ändern, dass er so aussieht wie die Anzahl der Birnenfäden fünfundfünfzig weniger ist als die Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen es also so, dass es genauere Semantik vermittelt, damit das Modell die Vorhersage richtig machen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell eigentlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können eine interpretierbare Lösungsmethode bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige vorherige Kenntnisse als Konstrakt einbeziehen, was uns helfen kann, die Leistung zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur für Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch für andere Aufgaben, die mehrtretende Argumentation beinhalten."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung in verschiedenen Zeitzonen unbalanciert ist, daher ist es auch ziemlich schwierig, Beam-Suche anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also das Ende des Vortrags und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Maastricht University."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein Johannes Werk mit Jerry vorstellen, das sich mit einem neuen Datensatz für die Abholung von gesetzlichen Artikeln befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein wesentlicher Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat wenig oder kein Wissen über ihre Rechte und grundlegenden Rechtsverfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Ergebnis sind viele vulnerable Bürger, die sich nicht die kostbare Assistance eines Legal Experts erwarten können, unprotegt oder worstens, exploitiert."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Lücke zwischen Menschen und dem Gesetz zu schließen, indem wir ein effektives Rückholsystem für gesetzliche Artikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte für unqualifizierte Menschen einen kostenlosen professionellen Rechtshilfenservice bieten."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem der statutarischen Artikelabholung."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ich eine einfache Frage zu einem rechtlichen Thema stelle, wie zum Beispiel: Was mache ich, wenn ich die professionelle Vertraulichkeit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetz zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe zur Informationserfassung bringt eine ganze Reihe von Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst geht es um zwei Sprachtypen."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "für die Fragen eine gängige natürliche Sprache und für die Statuten eine komplexe rechtliche Sprache."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in den Sprachverteilungen machen es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die mit der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das gesetzliche Recht kein Stapel unabhängiger Artikel, die als vollständige Informationsquelle an sich behandelt werden können, wie zum Beispiel Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Insted ist es eine Strukturkollektion von legalen Provisionen, die nur in der allgemeinen Kontext betrachtet sind, zusammen mit den zusätzlichen Informationen aus den neighbouring Artikeln, den Feldern und Subfeldern, zu denen sie gehören, und ihrer Platz in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, statutory Articles RN small paragraph, was usuell die typische Retrieval Unit in Most Retrieval Works ist."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Jahre dauern können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich NLP haben großes Interesse an vielen rechtlichen Aufgaben wie der Vorhersage von Rechtsentscheidungen oder der automatisierten Überprüfung von Vertragsverträgen weckt."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabholung ist jedoch aufgrund des Mangels an großen und hochwertigen gekennzeichneten Datensätzen größtenteils unberührt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir ein neues französisches, zentrales, zentrales Datenkett, um zu untersuchen, ob ein Rückholmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten für die Aufgabe der Statutorienartikelrückholung nähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Our Belgian Statutory Article Retrieval Data Sets consist von mehr als einem Jahrzehnt Liter."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnraum, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen hat von erfahrenen Juristen mit Referenzen zu relevanten Artikeln aus einem Corpus von mehr als twenty zwei Tausend sechshundert."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Codes of Law. Lassen Sie uns nun über die Erstellung dieser Datsätze sprechen."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir mit der Zusammenstellung eines großen Korpus an rechtlichen Artikeln begonnen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich verfügbare Belgische Codes und alle Artikel sowie die entsprechenden Abschnittshebungen entnommen."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf relevante Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich, auf ihre Websites zuzugreifen, wo ihr Team von erfahrenen Juristen Belgien's am häufigsten rechtlichen Probleme behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen zusammengestellt, mit Kategorien, Subkategorien und rechtlichen Verweisen auf relevante Statuten."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, wir passten die legalen Referenzen und filterten die Fragen aus, die Referenzen nicht Artikel in einem der Codes of Law wirkten."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Verweise wurden in die entsprechenden Artikel-IDs aus O Corpus abgestimmt und umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.108 Fragen, jeder sorgfältig mit den IDs der relevanten Artikel aus dem Buch."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich enthält jede Frage eine Hauptkategorie und eine Konkatenation von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel kommt mit einer Konkatenation ihrer nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzliche Information wird nicht in der Präsentation verwendet, aber sie könnte für zukünftige Research auf Legal Information Retrieval oder Legaltext Classification interessant sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale unserer Datensätze an."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Frage ist zwischen fünf und vierundvierzig Wort lang, mit einem Median von vierzig Wort."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer medianen Länge von sechzig sieben Wörtern, mit 140 Gramm."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei von ihnen, die eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine Vielzahl von Themen, von denen etwa 85 % entweder über Familie, Wohnraum, Geld oder Gerechtigkeit betraf."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Während die restlichen fünfzehn Prozent entweder mit der Sozialversicherung, Ausländern oder Arbeit zu tun haben."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr diverse, da sie aus dreißig zwei verschiedenen Belgischen Codes kommen, die eine große Anzahl von illegalen Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel aus jedem dieser belgischen Codes."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Aus den twenty two thousand six hundred thirty three Artikeln, nur eintausend sechs hundred twelve sind als relevant zu at least einem"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "nur eine Frage in den Daten sätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafverfolgungsgesetz."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen enthalten achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann durch die Tatsache erklärt werden, dass diese Codes weniger auf Einzelpersonen und ihre Anliegen fokussieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünf Prozent von ihnen sind in der"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen benchmarken wir verschiedene Rückholmethoden, einschließlich lexikalischer und denser Architektur."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrageartikelpaar eine Punktzahl zu, indem es die Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfragezeiten berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM-25-Rankingfunktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert und eine relevante Punktzahl zwischen einem Abfrage-Artikelpaar anhand der Ähnlichkeit ihrer Eingebettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit siamesischer Biancoder in einer Nullschussbewertung, was bedeutet, dass vorgebildete Word-Embedding-Modelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, und kontextunabhängigen Einbettungsmodellen, nämlich Roberta und genauer gesagt Camembert, das ein französisches Roberta-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes Camembert-basiertes Modell. Beyond quoters."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beispiele auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Flavors der Bianco architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Query und den Artikel in einem gemeinsamen Densivektorraum mappiert, und Tutor, das zwei unabhängige Word-Embedding-Modelle verwendet, die die Query und den Artikel separat in zwei verschiedene Embedding-Spaces codieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit dem Pooling von Mittel, Max und CLS sowie mit dem Punktprodukt und dem Kosinus für die Rechengelähnungen."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Ausgangslinie auf den Testsätzen."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Dann mit den lexikalischen Methoden oben, den Siamese-B-Encodern, die in einer Null-Schuss-Einrichtung evaluiert wurden, und den fein abgestimmten B-Encodern unten."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchore alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two Tower Modell verbessert sich gegenüber seiner Siamese-Variante auf Recallat one hundred, aber es funktioniert ähnlich bei den anderen Metriken."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five den trainierten Biancode erheblich unterlegen hat, zeigt seine Leistung, dass es immer noch eine starke Grundlage für Domain Specific Retrieval ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Was die Nullschussbewertung des siamesischen Biancoders betrifft, stellen wir fest, dass die direkte Verwendung der Eingebettungen eines vorgebildeten Kamembert-Modells ohne Optimierung für die Informationsabholungsaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir festgestellt, dass der Word-Tuec-basierte Biancoder den Vastex- und Vogelbasierten Modell deutlich übertrifft, was darauf hindeutet, dass möglicherweise vor-train-Word-Level-Embeddings für die Aufgabe besser geeignet sind als Charakter- oder Unterword-Level-Embeddings, wenn sie von vorn verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Möglichkeiten für Verbesserungen im Vergleich zu einem geschickten Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns mit zwei Einschränkungen aller Datensätze abschließen."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf die aus den 32 belgischen Gesetzen gezogenen beschränkt, die nicht das gesamte belgische Gesetz abdecken, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Referenzen zu diesen ungesammelten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl relevanten Artikeln erhalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsloss impliziert, dass die Antwort in den verbleibenden relevanten Artikeln unvollständig sein könnte, obwohl sie immer noch vollständig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Kann ich meine Mieter vertreiben, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Might not have a detaillierte Antwort innerhalb des gesetzlichen Gesetzes, das eine spezifische Noise-Threshold quantifiziert, bei der Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich mehr auf die Rechtsprechung vertrauen und Präzedenzfälle finden, die ähnlich zu ihrer aktuellen Situation sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Tenant zwei Parties pro Woche und tut es."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser als andere für die gesetzliche Artikel-Retrieval-Tasche geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass all diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur Berechnung von gesetzlichen Artikeln weckt,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Papier, Datset und Code unter den folgenden Links sehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorzustellen, einem unabhängigen Benchmark, der für die Testung von Vision- und Sprachmodellen mit bestimmten sprachlichen Phänomenen gedacht ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark festzulegen?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformer-basierten Vision- und Sprachmodellen gesehen, die auf große Mengen an Bild-Textpaaren vorgebildet wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle drängt die Moderne in der Vision und Sprachaufgaben wie der Antwort auf visuelle Fragen, der visuellen Sinnesreasoning, der Bildherstellung und der Phrase-Grundung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Nachricht erhalten. Die Genauigkeit dieser für die Aufgabe spezifischen Benchmarks steigt stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprachtransformer verstanden, als er diesem Bild und diesem Satz eine hohe Punktzahl zugewiesen hat, um es zu vereinbaren?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und der niedrige Punkt für diesen."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie durch frühere Arbeiten gezeigt?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf diesen Aspekt zu werfen, schlagen wir eine tauschfreundlichere Richtung vor und führen VALS ein, das die Empfindlichkeit von Seh- und Sprachmodellen auf spezifische sprachliche Phänomene testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Vielfalt, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenzen ab."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen festgehalten haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor nur für Vision und Sprachmodelle von Ravi Shakar und seinen Mitarbeitern für Nomenphrasen angewendet wurde, und bei der Zählung von uns in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde, dass wir den Bildunterschrift eines Bildes nehmen und einen Foil erzeugen, indem wir den Unterschrift so verändern, dass er das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Wir ändern diese Phrase, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenz, wobei jedes Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, FOIL-Instanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir im Fall des Aktionsstücks zwei Instrumente, eines, bei dem das Aktionsverb mit einer anderen Aktion geändert wird, und eines, bei dem die Spielzeuge ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Ko-Referenzen sind auch Stücke, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schaffen diese Fehler, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererseits gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach, da eine fehlerhafte Beschreibung weniger wahrscheinlich sein kann als die ursprüngliche Beschreibung."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es zwar nicht unmöglich, statistisch gesehen ist es weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann Pflanzen schneiden, und große Vision- und Sprachmodelle könnten dies aufgreifen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um gültige Folien zu erhalten, müssen wir daher Maßnahmen ergreifen."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir starke Sprachmodelle, um FOILs vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir die Inferenz durch natürliche Sprache oder kurz NLI, um Folien zu filtern, die das Bild noch beschreiben könnten, da wir bei der Konstruktion von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir eine Schlussfolgerung aus natürlicher Sprache mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Beschriftung als die damit verbundene Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In addition, wir betrachten die Kaption als die Premise und die FOIL als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell die FOIL als widersprechend oder neutral gegenüber dem Untertitel vorhersagt, nehmen wir dies als Indikator für eine gültige FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Folie durch den Untertitel enthalten ist, kann es keine gute Folie sein, da sie durch Transitivität eine wahrhaftige Beschreibung des Bildes liefert und wir diese Folien ausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Prozedere ist nicht perfekt. Es ist nur ein Indikator für valide Foil."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Erstellung gültiger FOILs menschliche Annotatoren, um die in Valse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir also so viele Testfälle wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um einen Benchmark für Null-Schuss-Tests handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vorausbildung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Die Feinabstimmung würde es den Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nutzen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vorausbildung haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen auf Vowels, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin I und VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bilder-Satzpaaren in Untertitel und FOILs."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht ist für dieses Video relevanter, dass wir unsere permissivere Metrik, die Paargenauigkeit, präsentieren, die misst, ob der Ausrichtungswert des Bildesatzes für das korrekte Textpaar des Bildes höher ist als für das fehlerhafte Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Metriken und Ergebnisse zu diesen Ergebnissen finden Sie in unserer Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit Paar-Präzision sind hier gezeigt und entsprechen den Ergebnissen, die wir aus den anderen Metriken erhalten haben. Die beste Leistung bei Nullschüssen wird von Wilbert zwölf in einem, gefolgt von Wilbert, LXMert, Clip und schließlich VisualBird erreicht."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert Twelve in One fast gelöst werden, wobei er hervorhebt, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann in unseren Adversarial Foiling-Einstellungen keine der verbleibenden Teile zuverlässig gelöst werden"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäten und Zählungsinstrumenten sehen wir, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Aktionen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie durch plausibel Vorurteile unterstützt werden, wie wir im Aktionsteil sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Bereich erfahren wir, dass es für Vision- und Sprachmodelle ebenfalls schwierig ist, mehrere Referenzen auf das gleiche Objekt in einem Bild mit Pronomen zu verfolgen."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Verstandskontrolle und weil es ein interessantes Experiment ist, haben wir auch zwei Textmodelle, GPT eins und GPT zwei, benchmarkt, um zu beurteilen, ob Valse durch diese Einmodalmodelle gelöst werden kann, indem wir die Verwirrung der richtigen und der fehlgeschlagenen Beschriftung berechnen und den Eintrag mit der geringsten Verwirrung vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die FOIL höher ist, nehmen wir dies als Hinweis darauf, dass die FOIL-Beschriftung unter einer plausibilen Voreingenommenheit oder anderen sprachlichen Voreingenommenheiten leidet."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die Text nur GPT Modelle die Plausibilität der Welt besser erfassen haben als die Vision und Language Modelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALS ein Benchmark ist, der die Linse der sprachlichen Konstruktionen nutzt, um der Community bei der Verbesserung von Seh- und Sprachmodellen zu helfen, indem sie ihre visuellen Grundlagefähigkeiten hart testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu begründen, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich ermutigen, VALS zur Messung des Fortschritts hin zur Sprachbasis mit Vision und Sprachmodellen zu verwenden."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, VALS könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von VALS getesteten Aspekte hilft."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, sollten Sie sich die Walls-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde eine Papier entitelt RNSAM, ein Large Scale DSET für automatische Risikogrammierung beim Commitologizieren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikogenerierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNote ist ein technisches Dokument, das die bei jeder Veröffentlichung eines Softwareprodukts zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Restnoten für Bosch 2.6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "User Us Library These Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consuming, um manuell zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, hochwertige Release-Noten automatisch zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Frischknotengenerierung verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste System, das Arena erstellt wurde, wurde 2014 erstellt."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert eine ruralbasierte Approach, zum Beispiel, indem man die Change Extractor verwendet, um Code differenzen, Bibliothekänder und Dokumentenänderungen von den differenzen zwischen Releases zu extrahieren, und schließlich kombinieren sie."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das bemerkenswerteste Merkmal dieses Systems ist der Ausgaben-Extraktor in der oberen rechten Ecke,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dieses muss mit dem Issues-Ökosystem verbunden sein und kann nur auf Projekte mit Null angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist Grief. Dies entweder angesagt in 2014."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "2020. Es ist auf dem Internet verfügbar und kann via PIP gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches Textklassifizierungsmodell basierendes auf Lernen und Ausgaben aus fünf Labors, wie z. B. Funktionen oder Fehlerbehebungen, für jede Eingabe-Kommentarnachricht."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Sample-User, das eine Korrektur für Fehlerkorrekturen erhält."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingdaten sind sehr klein, etwa fünftausend, und werden in den Experimenten beschriebenen unten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Kreuzschaltmodells ist nicht höher."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier löst diese beiden Probleme und erzeugt automatisch hochwertige Freigabe-Noten."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das begrenzte Anwendungsprogramm schlagen wir eine hochwertige Klassifizierungsmethode mit nur Kommentarmeldungen als Eingabe vor."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Repositories verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der Skarbstaatressourcen haben wir eine RNSAM DSET konsistent mit etwa 82.000 Datenpunkten erstellt, indem wir Daten aus öffentlichen GitHub Repositories mit der GitHub API erstellen."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unsere Daseinsetzung."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Nachricht des Komitees und die rechte Seite ist die Release-Note."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Riesen sind als Verbesserungen, Verbesserungen, etc. gelobt."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Kommentarnachrichten als Eingaben aufnimmt und die Raveled-Please-Notizen ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassungsaufgabe angesehen werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Rubber, Funktionen, Verbesserungen, Fehlerbehebungen, Deprekationen, Entfernungen und Bremsänderungen vorgedefiniert."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden aufgrund früherer Forschung und anderer Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Rhythmus-Noten unten rechts werden aus den Rhythmus-Noten unten links abgezogen."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Moment müssen die vier Schuttwerke, die im Voraus aufgestellt wurden, entdeckt werden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Lager sind nicht immer mit jeder Freiheit übereinstimmen"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, um Verbesserungen zu treffen, zu erhöhen, Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabulärliste mit etwa 30 Numbers für jede dieser Rotationsvariationen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Restnotkrasten zu erkennen und den Text der Restnotkrasten zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Komiteemeldung."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachrichten des Komitees sind nicht an jede Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der image below, wenn die aktuelle Realität Boson zwei Punkt fünf zwei neunzehn, müssen wir die IDECHTEN"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "erfüllt die vorherige Version 2.5218 und erhält einen Tiff. Dies ist ein bisschen mühsam und es reicht nicht aus, nur eine Liste der Releases zu erhalten und sich die Vorher und Nachher anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine Heuristik, die mit Ihnen übereinstimmt, um die vorherigen und nächsten Schauspielzeiten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind die Horses."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "In der Hand, siebentausend zwei hundert Repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Token 63, was für eine Zusammenfassungsaufgabe ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Nummer der Unique Tokens ist bei Roger at eight thousand eight hundred thirty thousand."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl von einzigartigen Kasten und Methoden im Repertory."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes erkläre ich die vorgeschlagene Methode."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Querschnitts-, Extraktions- und Abstruktionsmodell besteht aus zwei neuer Modulen"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifier mit Bot oder Code Bot und ein Generator mit Bot."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Klassifizierer, um jede Kommentarnachricht in fünf RESNOT-Klassen zu klassifizieren: Funktionen, Verbesserungen, Fehlerbehebungen, Duplizierungen und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als anderer eingestuften Komitee-Nachrichten werden abgelehnt."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GAS den Generator unabhängig auf die vier Rudder-Dokumente an und erzeugt für jede Klasse Risikonode."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Übereinstimmungen zwischen Commit-Nachrichten und Lesemerkungen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifizierer zu trainieren, weisen wir jeder Eingabe-Commit-Nachricht Pseudorabben zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Kreuzstreifen-Abstruktiv-Summersätze durch zwei verschiedene Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzigen SEC-Netzwerk und generiert einen einzigen Long-SNode-Text, der eine Kombination von Eingabe-Commit-Nachrichten liefert."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgangstext kann in Kreuzzeichen aufgeteilt werden, basierend auf speziellen Kreuz-Spezifischen Endpunkt-Symbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSMarch nennen, besteht aus vier verschiedenen SEC-to-SEC-Netzwerken, von denen jede einer der RES-Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das macht Spain's Experiment."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: CS, CS Single, CS Smart, Russelling und die vorherige Studienbeschreibung."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Abrissung sind in einigen Fällen diese Noten in mehreren Sätzen ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro ist penetrativ, wenn das System einen kurzen Satz ausgibt"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Brauvolumen. In den als nächstes beschriebenen Experimentenergebnissen"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erzeugen wir auch eine Spezifität, da Rouge und Brux nicht erzeugt werden können, wenn die Riesen-Knoten leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass die Modellprojekte ausgegeben sind, die in Fällen, in denen die Reasonals empfangen, empfindlich sind."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Daseit Emailadresse, Hashbarriers, etc. enthält, erweitern wir auch den Quint Daseit, der sie ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat und sie hat Rouge Air-Punkte erreicht, die mehr als zehn Punkte höher waren als die Baselines."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Green Test set, der Square Gap zwischen der proposierten Methode und der Basis jumped zu mehr als 20 Punkten."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie und sie erfolgreich sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS hat eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Crossfire und eines Generators auf das Training des Crossfire-Systems mit Pseudobus effektiv ist."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, weil der Klassifizierer sich auf die relevanten Kommittentests für jeden Kurs konzentrieren kann."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie isst in dieser Zeit viel höher als wenn sie ledig ist."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es auch effektiv ist, für jede dieser Notengrasse unabhängig verschiedene Perspektivsummerisierungsmodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hero und Eronasus"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xia's Methoden neigen dazu, kürzere Sätze als menschliche Referenz-Sätze zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Figur auf der rechten Referenz hat drei oder vier Sätze, während CS nur eins hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzugabe ist, dass in den Trainingsdaten nur 33 % der Sätze im Rabel Merkmale und 40 % im Rabel Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES Methoden ohne zusätzliche Informationen keine genauen Risikobewertungen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommentarmeldung, und die Kommentarfassung kann nicht generiert werden, ohne auf die entsprechende Peru-Request oder -Erstellung hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das untenstehende Beispiel zeigt, dass die beiden Kommentarberichte im Eingaben miteinander verbunden sind und in einen Satz kombiniert werden sollten, aber dies geschieht nicht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Personalgenerierung erstellt,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Kommentarmeldungen einzugeben und sie zusammenzufassen, sodass sie für alle Projekte auf Englisch anwendbar ist."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die Bassrate besser laut macht als die Bassrate."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte schauen Sie sich unsere Dessert-Audit-Tab an."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist ein Safarari,"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unsere Arbeit über die Anreicherung von Tabellen mit Hilfe von fein abgestimmten Transformatoren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Merkmale der Daten."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen begrenzt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Funktionen mit einer anderen Datenquelle kann erhebliche Informationen bieten."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung von Tabelldaten mit externen Quellen-Freitexten."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben eine Tabelldatensammlung und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Funktionen aus dem künstlichen Text der Wissensbasis zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel sehen. In einem Datensatz, der in FEST eingeführt wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist die Datenmenge Universitätsdatenmenge."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten zu unterteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festes ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Einheit, in diesem Beispiel der Name der Universität, mit einer Einheit innerhalb der Wissensbasis verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Knowledge-Basis wird extrahiert und in die Daten setzt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text der Abstrakt der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Funktionen aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen also eine Funktionsaufnahmephase, die Textanalyse beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde mich in den nächsten Folien tiefer damit befassen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Extraktionsphase der Merkmale gibt es eine Generierungsphase der Merkmale, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst generieren Sie Funktionen in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also, erstens zwei neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Funktion stellt die Wahrscheinlichkeit für jede Klasse dar."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, die sich auf Transformer basieren lassen, wie Baird, GPT, XLED und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe zur Feinabstimmung sein."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Funktionsauffnahme können wir also ein Parent-Train-Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell verfeinert, um Text in Klassen zu klassifizieren, abstrakt in Klassen, niedrig oder hoch."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse ist, und verwenden Sie sie als neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datenmengen möglicherweise wenige unterschiedliche Entitätsstapel haben."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Proben, und der kleinste Datensatz enthält fünfunddreißig Proben in seinem Trainings-Satz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorherige Kenntnisse über voranalyseierte Datensätze nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir den nth-Datensatz analysieren."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sugest, ist die Hälfte der Fine Tuning Phase."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Phase der Fine-Tuning-Multitask."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über n minus eins Datensätze finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine weitere Feinabstimmungsphase durch, die eine Feinabstimmung der Zielaufgaben ist, wenn wir das Sprachmodell über den n-Tiel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der neueste Stand der Multitask-Fine-Tuning, der MTDNN genannt wird."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN hält MTDNN eine Anzahl von Aufgaben im Trainingsatz aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainings-Set. Also leere DNN und halte vier Kopfhäupter, wie Sie auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es samplet eine zufällige Charge aus dem Trainingsset."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Run-Batch zu einer, zum Beispiel, Sing und Selton-Klassifizierungsaufgabe gehört, führt er einen Vorwärts- und Rückwärtspass durch den ersten Kopf aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zu einer Paar-Ranking-Tasche gehört, wird sie durch den letzten Kopf weitergegeben und zurückgegeben."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario verifiziert eine Datenmenge-Tabelle die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN hält die Anzahl der Klassen-Heads-Ausgaben-Schichten aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss MTDNN eine neue HEADS für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Task Reformulation Fine Tuning bezeichnet wird, besteht darin, dass wir in unserem Ansatz Task Reformation Fine Tuning statt mehrere Kopfgruppen zu behalten, jeden Datensatz in ein Satz pro Klassifizierungsproblem umformulieren, das zwei Klassen-Aufgaben ist."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also ein Beispiel sehen."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Input-Datensatz, der von Entitäten, Funktionen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zu der Klassifizierung des Textes, des Abstrakts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, wir haben das Sprachmodell so trainiert, dass es abstrakt und in der Klasse klassifiziert, ob die Abstrakt-Klasse in der Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Etikettvektor besteht in diesem Fall also immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren fertigen oder formulierten Feintuning-Ansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also das vollständige Framework betrachten."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und das set fade into fast"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Entity-Linking-Phase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensbasis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird die Aufgabe in eine Satz-Per-Classifikation-Tasche reformuliert."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und die Ausgabenwahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über n-1-Datensatz mit einer vorläufigen Multitask-Fine-Tuning verfeinert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu erstelltes Merkmal in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Rahmenwerk zu bewerten, verwenden wir eine Datenmenge mit siebzehn Tabellen, die Größe, Merkmale, Balance, Bereich und anfängliche Leistung variieren."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unser Experiment als Live-Out-Evaluierung gestaltet, bei der wir schnell über sechzehn Datensätze trainieren und sie auf das siebzehnte Datenset anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datensatz in vier Fehler auf und wenden eine Falten-Cross-Validation an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Funktionen und bewerten sie mit fünf Bewertungs-Klassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-Basis-Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Rahmenwerk mit der Feinabstimmung des Zieldatensatzes, der Feinabstimmung der Zielaufgabe und der vorläufigen Feinabstimmung der MTDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere Formulierung ist ein Feintuning, das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2% gegenüber der Feinabstimmung des Zieldatensatzes erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Poach hat eine Verbesserung um sechs Prozent erzielt."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Daten ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Feinabstimmung bei mehrere Aufgaben auf 1,5 Prozent abnimmt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung hat sich im Vergleich zu der Zielaufgabe, die allein mit der Feinabstimmung verbessert wurde, um elf Prozent zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Zusammenfassung ermöglicht Fast die Bereicherung von Fushot aus 35 Proben in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulationsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satzpaar-Klassifizierungsproblematik verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Assa Farari und ich werde unsere Arbeit FUSHOT Tabellendatenanbau mit fein abgestimmten Transformers-Architekturen vorstellen. Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Datenmerkmale, aber manchmal sind diese Merkmale begrenzt. Die Generierung von Merkmalen mit einer anderen Datenquelle kann erhebliche Informationen hinzufügen. Unser Forschungsziel ist die automatische Tabellendatenanbau mit externen Quellen, freiem Text. Nehmen wir an, wir haben eine Tabellendatenmenge und eine Wissensbasis. Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Merkmale aus dem kostenlosen Text der Wissensbasis zu extrahieren. Unser Framework FEST ist genau dieser automatische Prozess. Lassen Sie uns ein Beispiel betrachten. In einem Datensatz, der in FEST eingeführt wird. In diesem Beispiel ist der Datensatz ein Universitätsdatensatz, wenn sein Ziel es ist, Universitäten in niedrig rankende Universitäten und hochrangige Universitäten. Als Wissensbasis verwenden wir Wikipedia. Die erste Phase von FEST ist die Entitätslinkung, bei der jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität innerhalb der Wissensbasis verknüpft wird und der Text der Entitäten der Wissensbasis extrahiert und zum Datensatz hinzugefügt wird. In diesem Beispiel ist der Text der Wikipedia-Seitenabschnitt. Jetzt müssen wir Features aus dem erhaltenen Text generieren oder extrahieren. Wir benötigen also eine Feature-Extraction-Phase, die Textanalyse beinhaltet. Und das ist die Hauptnota dieser Arbeit, und ich werde mich in den nächsten Folien damit befassen. Nach der Feature-Extraction-Phase gibt es eine Feature-Generation-Phase, in der wir die extrahierten Features verwenden, um eine kleine Anzahl von Features zu generieren. Sie eine kleine Anzahl neuer Merkmale. Erstellen Sie zuerst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes. In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen, also erstellen Sie zuerst zwei neue Merkmale. Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Merkmale. Jede Merkmale repräsentiert die Wahrscheinlichkeit für jede Klasse. Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, nämlich transformierbare Sprachmodelle wie BERT, GPT, XLERT und so weiter. Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können. Daher wäre eine naive Herangehensweise die Feinabstimmung der Zielaufgabe. In der Fase der Extraktion der Funktionen können wir ein pertrainiertes Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset feinabstimmen. In diesem Beispiel können wir das Sprachmodell fe soll Text in Klassen, Abstract in Klassen, Low oder High, in Klassen eingeteilt, die Sprachmodell-Ausgaben erhalten, die für jede Klasse die Wahrscheinlichkeit sind, und als neue Funktionen verwendet werden. Das Problem bei diesem Ansatz ist, dass Daten sätze möglicherweise wenige unterschiedliche Entitäten wie Text enthalten. In unserem Experiment enthalten fast die Hälfte der Daten sätze weniger als 400 Samples und die kleinsten Daten sätze enthalten. Es enthält 35 Proben in seinem Trainings-Set. Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern. Wir können jedoch vorherige Kenntnisse über voranalysierte Datensätze nutzen, da wir FAST über mehrere Datensätze anwenden. Wir können die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir die nth Dataset. Was wir vorschlagen, ist eine weitere Fein-Tuning-Phase, eine preliminäre Multitask-Fein-Tuning-Phase, wenn wir das Languagemodell über n-1 Datasets fein-tunen. Und dann führen wir eine weitere Fein-Tuning-Phase aus, die eine Target-Task-Fein-Tuning ist, wenn wir das Languagemodell über das nth-Target-Dataset fein-tunen. Der Stand der Welt in der Multitask-Fein-Tuning-Phase. Fine-Tuning-Anwendung namens MTDNN. In MTDNN, MTDNN, mainten Sie eine Hälfte der Taschen im Trainingssatz. In diesem Beispiel gibt es vier Taschen im Trainingssatz. MTDNN mainten Sie vier Hälfte, wie Sie sehen können, im Bild. Es sampelt eine Random-Batch aus dem Trainingssatz. Und wenn die Random-Batch zu einem Zum Beispiel Singenselten's Classification-Tasks, es führt Vor- und Rückwärtspfade durch den ersten Kopf aus. Und wenn der Random-Batch zu Paar-Wise-Ranking-Task gehört, führt es Vor- und Rückwärtspfade durch den letzten Kopf aus. In unserem Szenario verringen Tableau-Datensätze die Anzahl der Klassen. Es gibt also viele Aufgaben. MTDNN-Mainten. DNN hält eine Reihe von Klassen-Heads-Ausgaben-Lagen aufrecht und zusätzlich muss MTDNN neue Heads für einen neuen Datensatz mit einer neuen Aufgabe initialisieren. Unser Ansatz, der als Task-Reformulation-Fine-Tuning bezeichnet wird, ist, dass wir in unserem Ansatz Task-Reformulation-Fine-Tuning, anstatt mehrere Heads aufrechtzuerhalten, jedes Datensatz in ein Satz pro Klassifizierungsproblem, das zwei Klassen-Taschen. Also, sehen wir ein Beispiel. Hier ist unser Input-Datensatz, der entweder von Entitäten, Funktionen, Text und Klassen besteht. Und wir reformulieren die Tasche von der Klassifizierung der Text in Low und High, um die Text, den Abstrakt und die Klasse in True oder False zu klassifizieren. Oder in anderen Worten, wir trainieren das Languagemodell, um eine Abstrakt- und Klassenklasse zu klassifizieren, ob die Abstrakt- und Klassenklasse zur Klasse gehören oder nicht. Der Etikettvektor bleibt in diesem Fall immer mit zwei Klassen bestehen. Und das ist der Algorithmus für unsere Find-Orientierung. find reformulated fine-tuning approach. Also, sehen wir uns den vollständigen Framework an. Ein Datensatz wird in FAST eingeführt und dann FAST execute in die Linkingphase. Es extrahiert den Text aus der Knowledge-Basis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist. Dann wird die Task reformuliert in Satz-Per-Classification-Tasks, das Sprachmodell auf die neue Task und die Ausgaben-Likelihood für jede Klasse. Beachten Sie, dass das Language-Modell bereits über n-1-Datensätze mit einer vorläufigen Multitask-Fine-Tuning abgestimmt ist. Dann verwenden wir den Ausgabenvektor des Language-Modells als neu generierten Funktion in der Anzahl der Klassen. Um unser Framework zu evaluieren, verwenden wir eine 17. Wir haben eine siebzehn-Tabellklassifizierungsdatensätze, die die Größe, die Merkmale, den Bereich und die anfängliche Leistung in Einklang bringt. Und als Wissensbasis verwenden wir Wikipedia. Wir haben unser Experiment als eine Live-Out-Evaluierung entworfen, bei der wir schnell über sechzehn Datensätze trainieren und sie auf die siebzehnte Datensätze anwenden. Wir haben auch jede Datensätze in vier Daten aufgeteilt. Wir erstellen Fehler und wenden eine Fork-Fehler-Kreuzvalidierung an. Dann generieren wir die neue Funktion und bewerten sie mit fünf Bewertungs-Klassifikatoren. In unserem Experiment verwenden wir eine auf Bild-Basis basierte Architektur. Hier sind die Ergebnisse unseres Experiments. Sie sehen, dass wir unser Framework mit der Feinabstimmung des Zieldatensatzes vergleichen, der Feinabstimmung der Zielaufgabe. und MTDNN preliminäre Feintuning und unsere reformulierte Feintuning erreichten den besten Ergebnis, die besten Leistungen, während MTDNN 2% Verbesserung über die Target-Datenset-Fine-Tuning erreichte. Unser Produkt erreichte 6% Verbesserung. Wenn wir uns die kleinen Daten ansehen, Aus dem Datensatz können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Fine-Tuning für mehrere Aufgaben auf 1,5 Prozent abnimmt, aber unsere Leistung steigt auf 11 Prozent im Vergleich zur alleinigen Fine-Tuning für die Zielaufgabe. Für die Zusammenfassung ermöglicht FAST die Bereicherung von Flux-Schüssen aus 35 Proben in unserem Experiment. verwendet eine Architektur für alle Aufgaben-Datensätze und behält den Kopf des Modells bei. Aber es fügt eine Formulierungsphase hinzu, es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satz-Par-Klassifizierungsproblematik verwenden können. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen. Heute werde ich unser Forschungswerk Lernen, deduktiv zu denken, Methodenproblemlösung als komplexe Rationsauffnahme vorstellen. Ich bin Alan vom Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD. Zunächst möchte ich über unsere Motivation für das Denken sprechen. Hier zeigen wir Beispiele, in denen mehrträgliches Denken hilfreich ist. Diese Zahl stammt aus der POWN-Artikel, in der sie die Anregung zur Lösung des Methodenproblems in einem Future-Learning-Szenario durchführen. Auf der Netto-Pan-Seite können wir sehen, dass wir, wenn wir einige Beispiele mit nur Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten. Wenn wir jedoch eine weitere Beschreibung geben, kann das Modell die Beschreibung vorhersagen und auch eine korrekte Vorhersage treffen. Es ist also gut, als Ausgabe interpretierbare Mehrstufige Beschreibung zu haben. Wir denken auch, dass das Methodenproblem eine einfache Anwendung ist, um solche Beschreibungsfähigkeiten zu bewerten. Hier in unserer Problemkonfiguration müssen wir diese Frage aufgrund der Fragen lösen und die numerischen Antworten erhalten. In unseren Datensätzen erhalten wir also auch den mathematischen Ausdruck, der auch zu dieser bestimmten Antwort führt. Daher gelten bestimmte Annahmen wie in früheren Arbeiten. Wir gehen davon aus, dass die Präzision von Größen bekannt ist, und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential. Darüber hinaus können komplizierte Operatoren tatsächlich ent in diese grundlegenden Operatoren aufgeteilt werden. Frühere Arbeiten im Lösungsproblem der Methode können also tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baummodell kategorisiert werden. Traditionelle Sequenz-zu-Sequenz-Modelle konvertieren den Ausdruck in eine spezifische Sequenz für die Generierung, und es ist ziemlich einfach zu implementieren, und es kann auf viele verschiedene komplizierte Probleme verallgemeinert werden. Aber die Nachteile sind, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell, und es fehlt an Interpretabilität für die die Vorhersage. Aber eigentlich ist diese Richtung aufgrund des Transformator-Modells immer noch ziemlich beliebt. In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen. Hier generieren wir also die Operatoren, bis wir die Blätter erreichen, die die Größen sind. Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt. Aber eigentlich ist es ziemlich kontraintuitiv. Denn wir generieren zuerst den Operator und dann am Ende die Größen. Und das Zweite ist, dass er auch einige wiederholte Berechnungen enthält. Wenn wir uns also diesen Ausdruck a mal drei plus drei ansehen, wird er tatsächlich zweimal generiert. Aber tatsächlich sollten wir die Ergebnisse wiederverwenden. In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und interpretierbar lösen. Zum Beispiel können wir hier im zweiten Schritt die Daten erhalten., die 27 sind. Und wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden. Und in diesen Schritten erhalten wir die Teiler. Und dann erhalten wir in diesem dritten Schritt tatsächlich den Quotienten. Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse des zweiten Schritts wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten. Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren. Dies macht den Prozess genauer. In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als Anfangszustände ein. Der Ausdruck wird also durch EIJOP dargestellt, bei dem wir Operatoren von Qi bis Qj ausführen, und dieser Ausdruck ist tatsächlich gelenkt. Wir haben hier auch eine Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen. Das ist ziemlich ähnlich wie eine Relationsentfernung. In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diesen neuen Ausdruck. Wir fügen ihn den nächsten Zuständen hinzu, um eine neue Größe zu erhalten. Diese Folien visualisieren tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zustand weiterhin Ausdrücke hinzufügen. In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Netzwerkmodell, das Vögel oder Roberto sein kann, und dann codieren wir den Satz und erhalten diese Mengenrepräsentationen. Sobald wir die Mengenrepräsentationen erhalten, können wir mit der Schlussfolgerung beginnen. Hier zeigen wir ein Beispiel für Q1, um die Repräsentation für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q3 multipliziert wird. Zuerst erhalten wir die Paarrepräsentation, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist, und dann wenden wir ein Fit-Forward-Netzwerk an, das ist. Dies wird durch den Operator parametriert. Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2. Aber in der Praxis könnten wir im Inferenzstadium auch den falschen Ausdruck erhalten. Hier sind alle möglichen Ausdrücke gleich dreimal so viele Operatoren. Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern. Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchraum entfernen. Im zweiten Schritt machen wir also das Gleiche, aber der einzige Unterschied ist eine weitere Größe. Diese Größe stammt also aus dem vorher berechneten Ausdruck. Schließlich können wir diesen endgültigen Ausdruck Q drei mal Q vier erhalten. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke vom vorherigen Schritt unterschiedlich ist. Solche Unterschiede machen es schwierig, ihn anzuwenden. Es ist schwer, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist. Der Trainingsverfahren ist ähnlich wie bei der Schulung eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust bei jedem Zeitschritt optimieren, und hier verwenden wir auch diese Zeichen, um darzustellen, wann wir diesen Generierungsprozess beenden sollten. Und hier ist der Raum von Sequenz zu Sequenz anders, da der Raum bei jedem Zeitschritt unterschiedlich ist, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Wortschatzes ist. Es ermöglicht uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen aufzustellen. Wir führen also Experimente mit den häufig verwendeten Methodenproblemdatensätzen durch, MAWPS, Math twenty three K, MathQA und SWAM. Hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen. Unsere am besten funktionierende Variante ist Roberta Deductive Reasoner. Tatsächlich verwenden wir nicht BeamSearch, im Gegensatz zu den vorherigen Ansätzen mitze sind oft ein Baumbasiertes Modell. Insgesamt kann unser Argumentationsmodell dieses Baumbasierten Modells deutlich übertreffen, aber wir können sehen, dass die absoluten Zahlen bei MathQA oder SWAM nicht wirklich hoch sind. Wir untersuchen die Ergebnisse bei SWAM weiter, und dieser Datensatz ist eine Herausforderung, da der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie zum Beispiel das Hininzufügung von irrelevanten Informationen und zusätzlichen Mengen. In unserer Vorhersage stellen wir fest, dass einige der Zwischenwerte tatsächlich negativ sind. In diesen Fragen fragen wir zum Beispiel, wie viele Äpfel Jake hat, aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Töne und Stephen hat acht Töne, was völlig irrelevant ist. Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt. Und wir beobachten, dass diese beiden Ausdrücke tatsächlich ähnliche Zahlen haben. Wir haben tatsächlich ähnliche Punktzahlen. Wir können also diesen Suchraum einschränken, indem wir diese negativen Ergebnisse entfernen, damit wir die Antwort richtig machen können. Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert. Zum Beispiel verbessern wir für Vögel sieben Punkte und für das Roberta-basierte Modell zwei Punkte. Ein besseres Sprachmodell hat also eine bessere Sprachverständnisfähigkeit, sodass die Zahl hier. Hier ist es höher für Roberta und niedriger für Vögel. Und wir versuchen auch, die Schwierigkeit hinter all diesen Daten zu analysieren. Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Informationen angesehen werden kann. Hier können wir also sehen, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und der SWAMP-Datenmenge den größten Teil hat. Und hier zeigen wir auch die Gesamtleistung für diese Proben ohne ungenutzte Mengen. Die Gesamtleistung ist also tatsächlich höher als die. Und die Leistung ist tatsächlich höher als die Gesamtleistung. Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlechter ist als die Gesamtleistung. Für MAWPS haben wir nicht wirklich viele Datenfälle, also ignoriere ich diesen Teil einfach. Schließlich möchten wir die Interpretbarkeit durch ein Beispiel für das Zusammenbruch zeigen. Hier macht unser Modell also tatsächlich eine falsche Vorhersage im ersten Schritt. Wir können diesen Ausdruck tatsächlich mit dem Satz hier korrelieren. Wir denken, dass dieser Satz das Modell mit einer falschen Vorhersage irreführt. Wenn wir hier also weitere 35 Pflanzen pflanzen, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte. Wir versuchen, den Satz so zu ändern, dass die Anzahl der Birnen 35 weniger als die Apfelbäume ist. Wir machen es also, um genauere Semantik zu vermitteln, sodass das Modell die Vorhersage richtig machen kann. Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Verhalten des Modells zu verstehen. Um unsere Arbeit abzuschließen: Zunächst ist unser Modell ziemlich effizient und wir können interpretierbare Lösungsmethoden bereitstellen, und wir können ein wenig vorheriges Wissen als Einschränkung einbeziehen, was die Leistung verbessern kann. Das letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch auf andere Aufgaben, die mehrträgliches Denken beinhalten. Wir haben aber auch bestimmte Einschränkungen. Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein. Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung bei verschiedenen Zeitstufen unbalanciert ist, daher ist es auch ziemlich schwierig, eine Beam-Suche-Strategie anzuwenden. Das ist also das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich bin von der Maastricht University. Ich werde meine gemeinsame Arbeit mit Jerry vorstellen, die sich mit einer neuen Datensammlung für die Erfassung von gesetzlichen Artikeln befasst. Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen, aber die Mehrheit der Bürger hat wenig bis kein Knowledge über ihre Rechte und grundlegenden Rechtsprozesse. Daher werden viele gefährdeten Bürger, die sich die kostspielige Unterstützung eines Rechtsexperten nicht leisten können, ungeschützt oder schlimmer gesagt, ausgenutzt. Unsere Arbeit zielt darauf ab, die Grenze zwischen Menschen und dem Gesetz zu schließen, indem er ein effektives Retrievalsystem für Statutartikel entwickelt. Ein solches System könnte eine freie professionelle Rechtshilfegemeinschaft für unqualifizierte Menschen bieten. Bevor wir uns auf den Hauptbegriff dieser Arbeit konzentrieren, sollten wir uns zunächst mit dem Problem der Statutartikelretrieval befassen. Bei einer einfachen Frage auf einem Rechtsmaterial, wie zum Beispiel was ich riskieren kann, wenn ich professionelle Privatsphäre verletze, ist ein Modell erforderlich, um alle relevanten Statutartikel aus einem großen Bereich der der Gesetzgebung. Diese Information Retrieval Task kommt mit seiner eigenen Setz von Challenges. Erstens geht es mit zwei Arten von Linguage, der normalen natürlichen Sprache für die Fragen und der komplexen legalen Sprache für die Statuten zu tun. Diese Differenz in Languageverteilungen macht es für ein System schwieriger, relevante Kandidaten zu retrieveren, da es indirekt eine inhärente Interpretationssysteme erfordert, die eine natürliche Frage zu einer rechtlichen Frage, die die Terminologie der Statuten entspricht, translatiert. Besides, statutory Law ist nicht ein Stack von Independent Artikeln, die als eine vollständige Source von Informationen auf der Own behandelt werden können, wie neue Rezepte, zum Beispiel. Instead, es ist eine Struktur, eine Sammlung von legalen Provisionen, die eine ganze Bedeutung nur in der allgemeinen Kontext haben, das ist zusammen mit der supplementären Information aus den neighbouring Artikeln, den Feldern und Subfields, die sie belong zu, und ihrer Platz in der Struktur der Laub. Lastly, statutory Artikel sind ein kleiner Paragraph. was in den meisten Retrievalwerken die typische Retrieval-Einheit ist. Hier sind es lange Dokumente, die bis zu sechstausend Wörter schreiben können. Die recenten Entwicklungen in NLP haben enorme Interesse in vielen Rechtsakten wie Legal Judgment Prediction oder automatisierten Kontaktkontraktreview gespielt, aber die Statutory Article Retrieval hat sich aufgrund der Lack von groß und hochwertigen Labeldatensätzen in der Lage geblieben. In dieser Arbeit präsentieren wir eine neue French Native Citizen Centric Datenset zu studieren, ob ein Retrievalmodell die Effizienz und Reliabilität eines Legal Experts für die Task der Statutory Article Retrieval angeht. Unser Belgisch Statutory Article Retrieval Datsatsatz besteht aus mehr als 1.100 legalen Fragen, die von Belgischen Bürgern gestellt werden. Diese Fragen umfassen eine wide Reihe von Themen von Familie, Housing, Money, bis hin zu Work und Sozialversicherung. Each of them ist von erfahrenen Juristen mit Referenzen zu relevanten Artikel aus einem Corpus von mehr als 22.600 legal Artikeln aus Belgischen Codes of Law. Lassen Sie uns nun über die Art und Weise sprechen, wie wir diese Daten setzen. Erst, wir starten mit der Compilierung eines Large Corpus von legal Artikeln. Wir betrachteten 32 öffentlich verfügbare Belgischen Codes und extrahierten alle Artikel sowie die correspondenden Section Headings. Dann gingen wir mit Referenzen zu relevanten Statuten zusammen. To tun so, wir partnerten mit der Belgischen Law Firma. jedes Jahr um viertausend Emails von Belgischen Bürgern, die um Rat und persönliche Rechtsfragen bitten. Wir hatten die Glück, Zugang zu ihren Websites zu bekommen, wo ihr Team erfahrener Juristen belgische am häufigsten rechtlichen Fragen behandelt. Wir sammelten Tausende von Fragen, die mit Kategorien, Subkategorien und Rechtsreferenzen zu relevanten Statuten angepasst wurden. Lastlich durchgingen wir die Rechtsreferenzen und filterten die Fragen, die nicht Artikel in einem der Codes of Law we considered. Die remaining Referenzen wurden matched und zu den corresponding Artikel IDs von O Corpus. Wir eventuell endeten mit einem Jahrhundert und acht Fragen, die sich sorgfältig mit den IDs der relevanten Artikel aus unserem Large Corpus von twenty two thousand six hundred thirty three Statutory Articles labelten. In addition, jeder Frage kommt mit einer Mainkategorie und einer Konkatenation von Subkategorien. Jeder Artikel enthält eine Konkatenation der nachfolgenden Überschriften in der Struktur des Gesetzes. Diese zusätzlichen Informationen werden in der aktuellen Arbeit nicht verwendet, aber könnten für zukünftige Forschungen zur Rechtsinformationserfassung oder zur Klassifizierung von Rechtstexten interessant sein. Schauen wir uns einige Merkmale unserer Datensätze an. Die Frage ist zwischen fünf und vierundvierzig Wörter lang mit einem Median von vierzig Wörtern. Die Artikel sind viel länger mit einem Median von siebzig sieben Wörtern, wobei einhundertvierundvierzig davon mehr als tausend Wörter betragen. Die Länge eines von fünftausend siebenhundert und neunzig Wörtern. Wie bereits erwähnt, umfassen die Frage eine breite Palette von Themen, wobei etwa achtzig Prozent davon entweder Familie, Wohnung, Geld oder Justiz betreffen, während die restlichen fünfzehn Prozent entweder Sozialversicherung, Ausländer oder Arbeit betreffen. Die Artikel sind auch sehr vielfältig, da sie aus dreißig zwei verschiedenen belgischen Gesetzen stammen, die eine große Anzahl von illegalen Themen abdecken. Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Gesetze gesammelt wurden. Von den 22.633 Artikeln werden nur 1.612 als relevant für mindestens eine Frage in den Datensätzen angegeben, und etwa 80 % dieser zitierten Artikel stammen entweder aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafgesetz. Inzwischen werden 18 von 32 Gesetzen weniger als fünf Artikel als relevant für mindestens eine Frage angege, die durch die Tatsache verursacht wird, dass diese Code weniger auf individuelle und ihre Anliegen fokussiert. Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünfundzwanzig Prozent von ihnen sind mehr als fünfmal citiert. Mit unseren Data sets benchmarken wir verschiedene Retrievalapproaches, einschließlich Lexical und Densarchitektur. Given eine query in einem Artikel, eine Lexicalmodelle assigniert eine Score zu den queryartikelpaaren. Durch die Berechnung der Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfrage-Terme. Wir experimentieren mit den Standard-TFIDF- und BM25-Rankingsfunktionen. Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten. Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die die semantische Beziehung zwischen Abfragen und Artikeln erfassen kann. Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert. und berechnen einen relevanten Punkt zwischen einem Artikelpaar der Abfrage anhand der Ähnlichkeit ihrer Eingebettungen. Diese Eingebettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Eingebettungsmodells. Zunächst untersuchen wir die Effektivität siamesischer B-Encoder in einer Zero-Shot-Evaluierungs-Einrichtung, was bedeutet, dass vorgebildete Word-Eingebettungsmodelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden. Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und Fastastex und kontextabhängige Embeddingmodelle, nämlich Roberta und speziell Kamembert, ein französisches Roberta-Modell. Darüber hinaus trainieren wir unsere eigenen Kamembert basierenden Biencoders auf allen Datenmengen. Beachten Sie, dass wir für das Training mit den beiden Arten der Biencoder Architektur experimentieren. Siamese, das ein einzigartiges Wort-Embeddingmodell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraum mappiert. Und Tutor, das zwei unabhängige Wort-Embeddingmodelle verwendet. Wir haben zwei Independent Word Embedding Models, die den Query und Artikel separat in verschiedene Embeddingsphasen codieren. Wir experimentieren mit Mean, Max und CLS Pooling sowie Dot Product und Cosine für die Computing-Similaritäten. Hier sind die Ergebnisse unserer Baseline auf dem Testset, mit den Lexikonmethoden oben, den Siamese BE Encoders evaluiert in einem Zero Shot Setup in der Mitte, und den Fein Tun BE Encoders unten. Overall, die Fein Tun BE Encoders übertragen alle anderen Baselines. seine Siamese-Variante auf RECOLAT 100, aber ähnlich auf den anderen Metriken abschneidet. Obwohl BM 25 den trainierten Biancoder erheblich unterlegen hat, deutet seine Leistung darauf hin, dass es immer noch eine starke Grundlage für Domain-spezifische Rückholung ist. Bei der Zero Shot Evaluation des Siamese Biancoders finden wir, dass die direkte Verwendung der Embeddings eines vortrainierten Kamembert-Modells ohne Optimierung für die Informationsaufnahmeaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt. Der Word-to-Vec-basierte Biancoder übertraf die Fastex- und Vogelbasierten Modelle deutlich, was darauf hindeutet, dass möglicherweise vor-train-Word-Einbettungen für die Aufgabe angemessener sind als Charakter- oder Unterword-Einbettungen, wenn sie von Anfang an verwendet werden. Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Verbesserungsmöglichkeiten im Vergleich zu einem geschickten Experten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann. Lassen Sie uns mit zwei Limitationen von allen Datensätzen beginnen. Erstens ist der Corpus von Artikeln limitiert zu denen, die aus den dreißig zwei betrachteten Belgischen Codes erfasst werden, was nicht den gesamten Belgischen Law abdeckt, da Artikel aus Dekrees, Direktives und Ordinanzen enthalten sind. Durch die Datensatzkonstruktion werden alle Referenzen zu diesen unkollektierten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Fragment der initialen Anzahl relevanter Artikeln enthalten. Dieser Informationlaus impliquiert, dass die Antwort in den remaining relevanten Artikelnkel könnten incomplete sein, obwohl es immer noch vollständig appropriate ist. Second, wir sollten merken, dass nicht alle Rechtsfragen mit Statuten alone beantwortet werden können. For instance, die Frage kann ich meine Tenants evicten, wenn sie zu viel Noise machen, könnte nicht eine detaillierte Antwort in statutory Law enthalten, die eine spezifische Noise Threshold at which Eviction ist. Insted sollten die Landlage wahrscheinlich mehr auf Fallslaw und Präceden ähnlich wie der aktuelle Situation finden. Zwei Parteien pro Woche bis 2 Uhr morgens. Daher sind einige Fragen besser als andere für die Aufgabe der gesetzlichen Artikelerfassung geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen. Wir hoffen, dass unsere Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle der gesetzlichen Artikelerfassung weckt, die den Zugang zur Justiz für alle verbessern können. Sie können sich unsere Arbeit Datensätze und Code unter den folgenden Links ansehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir sind froh, unsere Arbeit auf VALS, einem Taskindependenten Benchmark für das Testen von Vision und Language Models mit spezifischen linguistiken Phänomenen zu präsentieren. Warum haben wir uns die Trouble in der Setzung dieses Benchmarks gemacht? Nun, während der letzten Jahre haben wir eine explosion von Transformer basierten Vision und Language Models, die auf große Mengen von Image Textpaaren geprägt sind. Each dieser Modelle pusht State of the Art auf Vision und Language Tasks, wie z. B. visuelle Fragen Sinnesrechnung, Bildretrieval, Phrase-Grundung. Wir haben also eine Nachricht, die Akuragen auf diesen spezifischen Benchmarks steigern, aber wissen wir, was die Modelle tatsächlich gelernt haben? Was hat ein Vision und Language Transformer verstanden, als er eine High Score für dieses Bild und diesen Satz zugewiesen hat und eine Low Score für dieses Bild? Fokusieren Vision und Language Models auf das Richtige oder konzentrieren sie sich auf Biasen? wie gezeigt durch vorherige Arbeit. Um mehr Licht auf diesen Aspekt zu senden, propellieren wir eine mehr task agnostic direction und einführen WALS, das die Sensitivität von Vision und Language Models zu spezifischen linguistiken Phenomenen, die sowohl die linguistic als auch die visuelle Modalitäten beeinflussen. Wir targen Existenz, Pluralität, Zählung, Spatialrelationen, Aktionen und Entity Coreference. Aber wie testen wir, ob die Vision und Language Models diese Phenomena erfasst haben? Foiling, eine Methode, die vorher für Vision und Language Models, nur für Nanphrasen von Ravi Shakar und Kollaborators und auf Counting von Asin previous worked. Foiling basically means, dass wir den Caption of an Image und einen Foil produzieren, indem wir den Caption so verändern, dass er nicht die Image anymore beschreibt. Und wir machen diese Phrasealterations, indem wir uns auf sechs spezifische Pieces wie Existenz, Pluralität, Counting, Spatialrelations, Actions, und Entity Coreference. Jede Piece kann aus einem oder mehreren Instrumenten bestehen, in dem Fall, dass wir mehr als eine interessante Möglichkeit gefunden haben, FOIL instanzen zu erstellen. Zum Beispiel haben wir in der Fall der Aktionspiece zwei Instrumente, einen in dem das Action verb mit einer anderen Action geändert wird und einen in dem Actants gewechselt werden. Zählen und Coreferenz sind auch Pieces, die mehr als eine Instrumenten haben. Und wir erstellen diese FOILs, indem wir unserstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererweit validierten Sätze sind. Dies ist nicht einfach zu tun, weil eine Foiled Caption weniger wahrscheinlich ist als die ursprüngliche Caption. Zum Beispiel, though it's not impossible, ist es statistisch weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann, und Largevision und Language Models könnten dies erkennen. Daher müssen wir, um valid Foils zu erhalten, Action unternehmen. Erstens, wir machen uns auf Strong Language Models zu propellieren. Zweitens, wir verwenden Natural Language Inference oder NLI, um Foils zu filtern, die noch beschreibiben das Bild immer noch, da wir bei der Konstruktion von FOILs sicherstellen müssen, dass sie das Bild nicht beschreiben. Um dies automatisch zu testen, wenden wir eine natürliche Sprachinferenz mit der folgenden Begründung an. Wir betrachten ein Bild als die Premise und seine Beschriftung als die damit verbundene Hypothese. Darüber hinaus betrachten wir die Beschriftung als die Premise und die FOIL als ihre Hypothese. Wenn ein NLI-Modell die FOIL zu widersprechen oder neutral zu den Beschriftungen zu sein, nehmen wir dies als Indikator für eine gültige FOIL. Wenn wir die Foil zu beentalten, kann es nicht eine gute Foil sein, da es durch Transitivität eine truthliche Beschreibung der Image geben wird und wir diese Foils ausfiltern. Aber dieser Prozess ist nicht perfekt. Es ist nur ein Indikator für valide Foils, daher als eine dritte Möglichkeit für die generierung von valid Foils, wir verwenden Humananannotators, um die Daten zu validieren, die in Valse verwendet werden. Also, nach Filtering und Human Evaluation, wir haben so viele Testinstanzen wie in dieser Tabelle. Note, dass Valse nicht trainierend Daten liefert. Aber nur Testdaten, da es sich nur um einen Benchmark für Null-Shot-Tests handelt. Es ist darauf ausgelegt, die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vor-Training-Aktivität zu nutzen. Die Feinabstimmung würde es Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen. Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen einschlagen. Und wie wir sagten, sind wir daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vor-Training-Aktivität haben. Wir experimentieren mit fünf Vision- und Sprachmodellen auf WALS, nämlich mit CLIP, Wilbert, Wilbert Kelvin I und Visual Bert. Zwei unserer wichtigsten Evaluierungsmetriken sind die Accuracy der Modelle in der Klassifizierung von Image Sentenzenpaaren in Untertitel und Foils. Perhaps für dieses Video mehr relevant, wir werden unsere permissive Metrik, die Paarwise Accuracy, die messen, ob die Image Sentenz alignment score für die korrekte Image Textpaar als für ihre Foilpaar ist. Für mehr Metriken und Ergebnisse auf themen, doch checken Sie unsere Papier. Die Ergebnisse mit Paarwise Accuracy sind hier und sie sind konsistent mit den Ergebnissen, die wir von den anderen Metriken bekommen haben. Es ist, dass die besten Zero Shot Performance durch Wilbert zwölf in one, gefolgt von Wilbert, Alex Mert, Clip, und schließlich Visual Bird. Es ist notabel, wie Instrumente centered on individuelle Objekte wie Existenz und Nounphrases fast solviert werden, wobei Wilbert zwölf in one, highlighting, dass Models ableistisch genannte Objekte und ihre Präsenz in Images identifizieren können. Allerdings können none der remaining Pieces in unseren adversarialen Foiling-Settings reliably solviert werden. Instrumenten, dass Vision und Language Models Trouble distinguisieren, referenzieren zu single versus multiple Objekten oder in einem Image. Die Relation Piece zeigt, dass sie Schwierigkeiten haben, eine named spatiale Relation zwischen Objekten in einem Image zu klassifizieren. Sie haben auch Trouble, Aktionen zu distinguieren und ihre Partizipanten zu identifizieren, selbst wenn sie durch Plausibility bias sind, wie wir in der Aktionspiece sehen. Aus der Referenzpiece finden wir, dass das Tracing multiple Referenzen zu dem gleichen Objekt in einem Image durch Pronouns auch für Vision und Language Models. Als eine Sanity Check und weil es ein interessantes Experiment ist, benchmarken wir auch zwei Textonlegermodelle GPT one und GPT two, um zu assessieren, ob Valse solvable durch diese Unimodalmodelle ist, indem wir die Perplexität der korrekt und der foiled Caption, keine Image hier, und die Entry mit der lowest Perplexität. Wenn die Perplexität höher für die Foil ist, dann nehmen wir dies als eine Indikation, dass die foiled Caption möglicherweise von Plausibility bias oder anderen linguistiken Biasen leidet. Und es ist interessant zu sehen, dass in einigen Fällen Die Textmodelle nur GPT haben die Plausibilität der Welt besser erfasst als die Vision und Language Models. Zusammenfassend ist VALSE ein Benchmark, das die Lensen von Linguistikkonstrukten verwendet, um die Community zu helfen, Vision und Language Models zu verbessern, indem sie ihre visuellen Grounding-Fähigkeiten hart testen. Unsere Experimente zeigen, dass Vision und Language Models namensgelegene Objekte in ihrer Präsenz in Bildern gut identifizieren, wie gezeigt durch das Existenzstück, aber es schwerwiegt, ihre Interdependence und Relationships in visuellen Szenen zu genehmigen, wenn sie gezwungen sind, linguistic Indikatoren zu respektieren. Wir möchten die Community wirklich ermutigen, Valse zur Messung des Fortschritts hin zur Sprachbasis mit Vision- und Sprachmodellen zu verwenden. Und noch mehr, Valse könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von Valse getesteten Aspekte hilft. Wenn Sie interessiert sind, sollten Sie sich die Valse-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamisara von der University of Tokio. Ich werde eine Papier entitelt RNSAM, ein großes Dasein für automatische Restnoturation bei der Commit Dog Summization. Ich werde in dieser Ordnung erklären. Erst, ich werde die automatische Restnoturation, die wir in dieser Research arbeiten, einführen. ReleaseNode ist ein technischer Dokument, das die Changes mit jedem Release von einem Softwareprodukt zusammenfasst. Das Image zeigt die ReleaseNode für Version zwei. sechs. vier der GBUJS Library. Diese Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consumierend zu erstellen. Daher wird es sehr nützlich sein, automatisch hochqualitäre Release Nodes zu generieren. Ich werde auf zwei frühere Researchers auf automatische Release Node Generation eingehen. Der erste ist ein System namens Arena, das in twenty fourteen erstellt wurde. Es ergreift eine Rule basierende Approach, zum Beispiel, indem es die Change Extractor verwendet, um Code differenzen zu extrahieren. Bibliotheksänderungen und Dokumentenänderungen von den differenzierten Releases und schließlich kombinieren. Die meisten erkennbaren Funktionen dieses Systems sind die Issue Extractor in der oberen rechten Ecke, die mit Jira, dem Issue Toco System, verknüpft und nur für Projekte verwendet werden kann. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden. Die zweite ist Griff, die Entry angeboten wurde in twenty twenty. Sie ist auf dem Internet und kann durch PIPSTEMENSSER Dieses System hat ein einfaches Lernbasis für Textklassifikation und erhält eine von fünf Rabellen, die Funktionen oder Bugfixen für jedes Input Commit-Message enthalten. Das Bild ist eine Sample-Usage, die eine korrekte oder Bugfixen-Rabelle enthält. Die gerade erstellten Rabellen sind ziemlich klein, etwa fünftausend, und werden in den Experimenten beschriebenen darüber gezeigt. Die Leistung des Textklassifikationsmodells ist nicht hoch. Ich präsentiere zwei related Researchers, aber es gibt Probleme mit begrenztem Erwerb und geringen Daten. und Scar State Resources. Unser Papier löst diese beiden Probleme und automatisch generiert High Quality Releasing Notes. Für das limitierte Applicability Programm, wir propagieren eine High Quality Classifier Summarization Methode, die nur Committee Message als Input verwendet. Diese Methode kann für alle English Repositories verwendet werden. Für das zweite Problem der Scar State Resources, wir bauen RL und SAM DSET konsistent mit etwa achtzig zwei Tausend Pieces von Daten, die von öffentlichen GitHub API. Next, ich beschreibe unser Desert. Hier ist ein Beispiel für Daten. Die linke Seite ist ein Commit Message und die rechte Seite ist die RISE Nodes. Die RISE Nodes sind Raveled als Implement, Bug fixes, etc. Wir haben eine Task setup, die die Commit Messages als Input und die Raveled RISE Nodes aufwendet. Dies kann als eine Summarization Task bezeichnet werden. Wir haben vier Raveled Features, Implement, Bug fixes, Duplications, Removables und Breaking Changes. Diese wurden basierend auf PBR research und anderen Faktoren. Die RISE Noten auf der bottom right und extrahiert von den RISE Noten auf der bottom left. At diesem Zeitpunkt ist es notwendig, die vier Rabels zu detektieren, die in der Passage sind, aber die Rabels sind nicht immer konsistent mit jeder Repository. Zum Beispiel, die Improvements Rabels inklusive Improvements, Enhancements, Optimisations und so weiter. Wir haben eine Vokabularliste oder Studie Rabels für jeden dieser Notation. variations. Verwenden Sie es, um die Restknoten zu erkennen und den Text der Restknoten zu korrigieren. Als nächstes kommt eine Kommittemessage. Kommittemessagen sind nicht zu jeder Rest. Wie in der image below, wenn die aktuelle Rest Persönlich 2.5219 ist, müssen wir die vorherige Rest Persönlich 2.5218 identifizieren und einen Tiff erhalten. Dies ist ein bisschen tedious und es ist nicht genug, nur eine Rest der Restknoten zu erhalten. Und wir haben die Vorhand nach. Wir haben eine heuristic Matching Blue erstellt, um die vorherigen und nächsten Persönlichkeiten zu erhalten. Dasset Analysis In der End, 7.200 Repositories und 82.000 PSO wurden korrektiv. Außerdem ist die average Anzahl von ReleaseNode Tokens 63, was für eine Summarisation Task ziemlich hoch ist. Außerdem ist die Anzahl von Unique Tokens ziemlich groß, also 8.830.000. Dies ist auf die große Anzahl von Unique Kosten und Methoden zurück namens in der Repository. Next, ich werde explain die proposierte Methode. Das Crosswise Extractive and Abstractive Summarization Model besteht aus zwei neuronalen Modules, einem Classifier, der Bot oder Code Bot und einem Generator, der Bot verwendet. Erstens, GAS verwendet einen Classifier, um jedes Committee Message in fünf Risnode Classes, Features, Improvements, Bugfixes, Duplications, Plus, und andere. Die Committee Messages klassifiziert als andere oder diskutiert. Dann GAS wendet einen Generator zu den vier Rabelschnitteln unabhängig und generiert RISE NOTE für jeden Kurs. In diesem Zusammenhang sind die direkten Korrespondenzen zwischen Commit Messages und RISE NOTE nicht bekannt. Daher, um den Kurs zu trainieren, wir zwar Rabelschnitteln zu jedem Input Commit Message verwenden, indem wir die ersten zehn Charaktere für jedes Commit Message verwenden. Wir modellieren den Kurs abstruktiven Summarisierungsansatz durch zwei verschiedene Methoden. Das erste Modell, das wir als GAS Single Sync konsist von einer Sync zwei Sync Network und generiert eine Sync Long RISE Node Tagist, geben eine Konkurrenz von Input Committee Messages. Die Output Tagist kann in Crosswise Segment basierend auf speziellen Cross Specific Endpoint Symbols unterteilt werden. Die zweite Methode, Methode, die wir CSMUCH, besteht aus vier verschiedenen Sync zwei Sync Networks, jeder von denen zu einer der RISE Node Classes entspricht. Okay, lassen Sie mich das Experiment erklären. Fünf Methoden wurden GS, GS Single, GS Marge, Russelling und previous studied Griff. Regarding Abortion, in einigen Fällen, diese Noten sind in multiple Sentenzen. Da es difficil ist, die Nummer von Sentenzen zu erkennen, sind sie kombiniert mit Spaces und treaten als ein langer Satz. Der Blue ist penalisiert, wenn das System einen kurzen Satz erfährt. Diese Penalty resultiert in einem loweren Blue Value in den Experimenten der Results describiert. Finally, wir auch die Spezifität erkennen, weil Rouge und Brew nicht erkennen können, wenn die Rouge Nodes leer sind. Eine hohe Spezifität bedeutet, dass die Modellkorrektie auspackt ist, in denen die Rouge Nodes leer sind. Hier sind die Ergebnisse. Da der Daseit Emailadresse, Hashbarrieren, etc. enthält, haben wir auch den Green Daseit erkannt, der sie ausschließt. GAS und GAS erreichten Rouge Error Scores mehr als zehn Punkte höher als die Baselines. Auf dem grünen Testset stieg die Score-Gap zwischen der vorgeschlagenen Methode und der Basis auf mehr als zwanzig Punkte. Diese Ergebnisse zeigen, dass GAS und GAS signifikant effektiv sind. GAS erreichte eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Klassifierers und eines Generators effektiv ist und das Training des Klassifierers mit Pseudoberseiten. Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, da der Klassifier sich auf das Sekten relevanter Kommittemechanismen für jede Klasse konzentrieren kann. Xia ist viel zu höheren Ruder als Xia single, suggesting, dass es auch effektiv ist, unterschiedliche perspektive Summarisationsmodelle für jedes Nodecraft zu entwickeln. Hier sind Erronnas. Xia's Methods tend to output shorter Sentenzen als humanen Referenz Sentenzen. In der Figur auf der rechten Referenz Sentenzen hat drei oder vier Sentenzen, während Xia nur eins hat. Der Grund für diese Modellrücktanz ist, dass in den Trainingdaten nur 33 Prozent der Sentenzen sind in der Features Rabel und 40 Prozent in der Improvements Rabel. Für die More CS Methods können nicht akurat mit Noten ohne zusätzliche Informationen generiert werden. Das Top Exempel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommittemessage und die Komplettesentence kann nicht generiert werden, ohne dass es sich auf die correspondente Periodrequest oder Issue bezieht. Das Beispiel below zeigt, dass die zwei Kommittemessagen in der Input related und sollten kombiniert werden. Aber es versucht dies zu tun. Schließlich eine Konklusion. Wir haben eine neue DSET für automatische Rezensionsschnittgenerierung erstellt. Wir haben auch die Aufgabe erstellt, Kommentarn zu enthalten und sie so zu summarisieren, dass sie für alle Projekte in Englisch anwendbar ist. Unser Experiment zeigt, dass die vorgeschlagene Methode weniger Noisy Rezensionsschnittgenerierung bei höherer Abdeckung als die Basisrate erzeugt. Bitte schauen Sie sich unsere DSET auf GitHub an. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle. Heute werde ich unsere Forschungsarbeit Lernen zu reisen deduktiv, Methodenproblemlösung als komplexe Rasen-Extraktion vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Zahl stammt aus dem POWN-Papier, in dem sie Anweisungen zur Lösung des Methodenproblems in einem Fluch-Learning-Szenario ausführen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite können wir sehen, dass wir, wenn wir einige Beispiele nur mit Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch noch mehr Beschreibungen geben, kann das Modell die Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, als Ausgabe interpretierbares Mehrstufenrechnungsverfahren zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken auch, dass ein Methodenproblem eine einfache Anwendung zur Bewertung solcher Argumentationsfähigkeiten ist."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier müssen wir also in unserer Problemkonfiguration, angesichts der Fragen, diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser besonderen Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Größen bekannt ist"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren aufgeteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Eine frühere Arbeit im Lösungsproblem der Methode kann also tatsächlich in Sequenz- und Baummodell kategorisiert werden."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenzmodelle konvertieren den Ausdruck also in eine bestimmte Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ziemlich einfach umzusetzen und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil ist, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell und es fehlt an Interpretabilität für die Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Direction noch ziemlich populär, weil der Transformermodell"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also die Operatoren weiter, bis wir die Lifts erreichen, die die Größen sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt, aber es ist eigentlich ganz entgegengesetzt, weil wir zuerst den Operator generieren und dann am Ende die Größen generieren."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens enthält es auch einige wiederholte Berechnungen."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck hier ansehen, wird acht mal drei plus drei tatsächlich zweimal erzeugt. Aber tatsächlich sollten wir die Ergebnisse verwenden"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und in interpretierbaren Methoden lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diesen Teiler erhalten, der 27 ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir bei diesem dritten Schritt tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Okay. Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schritts tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als unser Anfangszustand ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Operatoren von QY bis QJ aus, und dieser Ausdruck ist tatsächlich gerichtet."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "So, wir haben hier auch Subtraction-Wert, um die entgegengesetzte Richtung zu repräsentieren."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie bei der Strahlungsauffnahme."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es in den nächsten Zustand hinzu, um eine neue Menge zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folien visualisieren also tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zuständen immer wieder Ausdrücke hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Sprachmodell, das Vögel oder Robetts sein kann, und dann kodieren wir den Satz und erhalten diese Mengenrepräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengen darstellen, können wir mit der Schlussfolgerung beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q4 multipliziert wird."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Anweisung, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist. Dann wenden wir ein Fit-Forward-Netzwerk an, das vom Operator parametriert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksrepräsentation Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Schlussfolgerung möglicherweise auch den falschen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier entspricht also jeder möglichen Ausdruck dreimal so viel wie die Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchbereich entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir noch eine Menge mehr haben."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe stammt aus dem vorherigen berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir diesen letzten Ausdruck Q3 erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke von dem vorherigen Schritt unterschiedlich ist."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede machen es schwierig, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsmethode ist ähnlich wie bei der Schulung eines Sequenzmodells, bei dem wir den Verlust bei jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch diese Tao, um darzustellen, wann wir diesen Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz anders, weil der Raum bei jedem Zeitpunkt anders ist, während es im traditionellen Sequenz- zu-Sequenz-Modell die Anzahl des Wortschatzes ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht es uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen zu verhängen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen also Experimente mit den häufig verwendeten Method-Problem-Datensätzen durch, MAWPS, Math23K, MathQA und SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Variante ist also Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir BeamSearch nicht, im Gegensatz zu offensichtlichen Ansätzen mit BeamSearch."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Okay, die besten Ansätze sind oft ein Baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Vernunft also dieses Baumbasierungsmodell deutlich übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MatQuery oder SWAM nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse weiter."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist eine Herausforderung, weil der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. irrelevante Informationen und zusätzliche Mengen hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Also, in unserer Vorhersage finden wir, dass einige der intermediären Werte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Pitchs und Stephen hat acht Pitchs, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse als negativ entfernen, damit wir die Antwort richtig machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert und bei dem Roberta-Basemodell tatsächlich zwei Punkte verbessert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat also bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Bert niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information angesehen werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der ungenutzten Mengen haben und der SWAMP-Datensatz den größten Teil enthält."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen ist die Gesamtleistung tatsächlich höher als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlimmer ist als die, äh, viel schlimmer als."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für MAWPS haben wir nicht wirklich viele Desk-Cases, also ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretationsfähigkeit durch ein Beispiel für die Zusammenstoßpartizierung zeigen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also tatsächlich eine falsche Vorhersage im ersten Schritt."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren, oder?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben also, dass dieser Satz das Modell in eine falsche Vorhersage führen könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man hier also noch 35 plant, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu ändern, dass er so aussieht wie die Anzahl der Birnenfäden fünfundfünfzig weniger ist als die Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen es also so, dass es genauere Semantik vermittelt, damit das Modell die Vorhersage richtig machen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell eigentlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können eine interpretierbare Lösungsmethode bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige vorherige Kenntnisse als Konstrakt einbeziehen, was uns helfen kann, die Leistung zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur für Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch für andere Aufgaben, die mehrtretende Argumentation beinhalten."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung in verschiedenen Zeitzonen unbalanciert ist, daher ist es auch ziemlich schwierig, Beam-Suche anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also das Ende des Vortrags und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Maastricht University."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein Johannes Werk mit Jerry vorstellen, das sich mit einem neuen Datensatz für die Abholung von gesetzlichen Artikeln befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein wesentlicher Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat wenig oder kein Wissen über ihre Rechte und grundlegenden Rechtsverfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Ergebnis sind viele vulnerable Bürger, die sich nicht die kostbare Assistance eines Legal Experts erwarten können, unprotegt oder worstens, exploitiert."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Lücke zwischen Menschen und dem Gesetz zu schließen, indem wir ein effektives Rückholsystem für gesetzliche Artikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte für unqualifizierte Menschen einen kostenlosen professionellen Rechtshilfenservice bieten."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem der statutarischen Artikelabholung."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ich eine einfache Frage zu einem rechtlichen Thema stelle, wie zum Beispiel: Was mache ich, wenn ich die professionelle Vertraulichkeit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetz zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe zur Informationserfassung bringt eine ganze Reihe von Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst geht es um zwei Sprachtypen."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "für die Fragen eine gängige natürliche Sprache und für die Statuten eine komplexe rechtliche Sprache."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in den Sprachverteilungen machen es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die mit der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das gesetzliche Recht kein Stapel unabhängiger Artikel, die als vollständige Informationsquelle an sich behandelt werden können, wie zum Beispiel Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Insted ist es eine Strukturkollektion von legalen Provisionen, die nur in der allgemeinen Kontext betrachtet sind, zusammen mit den zusätzlichen Informationen aus den neighbouring Artikeln, den Feldern und Subfeldern, zu denen sie gehören, und ihrer Platz in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, statutory Articles RN small paragraph, was usuell die typische Retrieval Unit in Most Retrieval Works ist."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Jahre dauern können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich NLP haben großes Interesse an vielen rechtlichen Aufgaben wie der Vorhersage von Rechtsentscheidungen oder der automatisierten Überprüfung von Vertragsverträgen weckt."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabholung ist jedoch aufgrund des Mangels an großen und hochwertigen gekennzeichneten Datensätzen größtenteils unberührt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir ein neues französisches, zentrales, zentrales Datenkett, um zu untersuchen, ob ein Rückholmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten für die Aufgabe der Statutorienartikelrückholung nähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Our Belgian Statutory Article Retrieval Data Sets consist von mehr als einem Jahrzehnt Liter."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnraum, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen hat von erfahrenen Juristen mit Referenzen zu relevanten Artikeln aus einem Corpus von mehr als twenty zwei Tausend sechshundert."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Codes of Law. Lassen Sie uns nun über die Erstellung dieser Datsätze sprechen."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir mit der Zusammenstellung eines großen Korpus an rechtlichen Artikeln begonnen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich verfügbare Belgische Codes und alle Artikel sowie die entsprechenden Abschnittshebungen entnommen."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf relevante Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich, auf ihre Websites zuzugreifen, wo ihr Team von erfahrenen Juristen Belgien's am häufigsten rechtlichen Probleme behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen zusammengestellt, mit Kategorien, Subkategorien und rechtlichen Verweisen auf relevante Statuten."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, wir passten die legalen Referenzen und filterten die Fragen aus, die Referenzen nicht Artikel in einem der Codes of Law wirkten."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Verweise wurden in die entsprechenden Artikel-IDs aus O Corpus abgestimmt und umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.108 Fragen, jeder sorgfältig mit den IDs der relevanten Artikel aus dem Buch."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich enthält jede Frage eine Hauptkategorie und eine Konkatenation von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel kommt mit einer Konkatenation ihrer nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzliche Information wird nicht in der Präsentation verwendet, aber sie könnte für zukünftige Research auf Legal Information Retrieval oder Legaltext Classification interessant sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale unserer Datensätze an."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Frage ist zwischen fünf und vierundvierzig Wort lang, mit einem Median von vierzig Wort."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer medianen Länge von sechzig sieben Wörtern, mit 140 Gramm."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei von ihnen, die eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine Vielzahl von Themen, von denen etwa 85 % entweder über Familie, Wohnraum, Geld oder Gerechtigkeit betraf."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Während die restlichen fünfzehn Prozent entweder mit der Sozialversicherung, Ausländern oder Arbeit zu tun haben."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr diverse, da sie aus dreißig zwei verschiedenen Belgischen Codes kommen, die eine große Anzahl von illegalen Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel aus jedem dieser belgischen Codes."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Aus den twenty two thousand six hundred thirty three Artikeln, nur eintausend sechs hundred twelve sind als relevant zu at least einem"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "nur eine Frage in den Daten sätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafverfolgungsgesetz."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen enthalten achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann durch die Tatsache erklärt werden, dass diese Codes weniger auf Einzelpersonen und ihre Anliegen fokussieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünf Prozent von ihnen sind in der"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen benchmarken wir verschiedene Rückholmethoden, einschließlich lexikalischer und denser Architektur."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrageartikelpaar eine Punktzahl zu, indem es die Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfragezeiten berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM-25-Rankingfunktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert und eine relevante Punktzahl zwischen einem Abfrage-Artikelpaar anhand der Ähnlichkeit ihrer Eingebettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit siamesischer Biancoder in einer Nullschussbewertung, was bedeutet, dass vorgebildete Word-Embedding-Modelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, und kontextunabhängigen Einbettungsmodellen, nämlich Roberta und genauer gesagt Camembert, das ein französisches Roberta-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes Camembert-basiertes Modell. Beyond quoters."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beispiele auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Flavors der Bianco architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Query und den Artikel in einem gemeinsamen Densivektorraum mappiert, und Tutor, das zwei unabhängige Word-Embedding-Modelle verwendet, die die Query und den Artikel separat in zwei verschiedene Embedding-Spaces codieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit dem Pooling von Mittel, Max und CLS sowie mit dem Punktprodukt und dem Kosinus für die Rechengelähnungen."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Ausgangslinie auf den Testsätzen."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Dann mit den lexikalischen Methoden oben, den Siamese-B-Encodern, die in einer Null-Schuss-Einrichtung evaluiert wurden, und den fein abgestimmten B-Encodern unten."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchore alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two Tower Modell verbessert sich gegenüber seiner Siamese-Variante auf Recallat one hundred, aber es funktioniert ähnlich bei den anderen Metriken."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five den trainierten Biancode erheblich unterlegen hat, zeigt seine Leistung, dass es immer noch eine starke Grundlage für Domain Specific Retrieval ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Was die Nullschussbewertung des siamesischen Biancoders betrifft, stellen wir fest, dass die direkte Verwendung der Eingebettungen eines vorgebildeten Kamembert-Modells ohne Optimierung für die Informationsabholungsaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir festgestellt, dass der Word-Tuec-basierte Biancoder den Vastex- und Vogelbasierten Modell deutlich übertrifft, was darauf hindeutet, dass möglicherweise vor-train-Word-Level-Embeddings für die Aufgabe besser geeignet sind als Charakter- oder Unterword-Level-Embeddings, wenn sie von vorn verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Möglichkeiten für Verbesserungen im Vergleich zu einem geschickten Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns mit zwei Einschränkungen aller Datensätze abschließen."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf die aus den 32 belgischen Gesetzen gezogenen beschränkt, die nicht das gesamte belgische Gesetz abdecken, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Referenzen zu diesen ungesammelten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl relevanten Artikeln erhalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsloss impliziert, dass die Antwort in den verbleibenden relevanten Artikeln unvollständig sein könnte, obwohl sie immer noch vollständig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Kann ich meine Mieter vertreiben, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Might not have a detaillierte Antwort innerhalb des gesetzlichen Gesetzes, das eine spezifische Noise-Threshold quantifiziert, bei der Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich mehr auf die Rechtsprechung vertrauen und Präzedenzfälle finden, die ähnlich zu ihrer aktuellen Situation sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Tenant zwei Parties pro Woche und tut es."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser als andere für die gesetzliche Artikel-Retrieval-Tasche geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass all diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur Berechnung von gesetzlichen Artikeln weckt,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Papier, Datset und Code unter den folgenden Links sehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorzustellen, einem unabhängigen Benchmark, der für die Testung von Vision- und Sprachmodellen mit bestimmten sprachlichen Phänomenen gedacht ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark festzulegen?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformer-basierten Vision- und Sprachmodellen gesehen, die auf große Mengen an Bild-Textpaaren vorgebildet wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle drängt die Moderne in der Vision und Sprachaufgaben wie der Antwort auf visuelle Fragen, der visuellen Sinnesreasoning, der Bildherstellung und der Phrase-Grundung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Nachricht erhalten. Die Genauigkeit dieser für die Aufgabe spezifischen Benchmarks steigt stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprachtransformer verstanden, als er diesem Bild und diesem Satz eine hohe Punktzahl zugewiesen hat, um es zu vereinbaren?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und der niedrige Punkt für diesen."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie durch frühere Arbeiten gezeigt?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf diesen Aspekt zu werfen, schlagen wir eine tauschfreundlichere Richtung vor und führen VALS ein, das die Empfindlichkeit von Seh- und Sprachmodellen auf spezifische sprachliche Phänomene testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Vielfalt, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenzen ab."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen festgehalten haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor nur für Vision und Sprachmodelle von Ravi Shakar und seinen Mitarbeitern für Nomenphrasen angewendet wurde, und bei der Zählung von uns in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde, dass wir den Bildunterschrift eines Bildes nehmen und einen Foil erzeugen, indem wir den Unterschrift so verändern, dass er das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Wir ändern diese Phrase, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenz, wobei jedes Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, FOIL-Instanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir im Fall des Aktionsstücks zwei Instrumente, eines, bei dem das Aktionsverb mit einer anderen Aktion geändert wird, und eines, bei dem die Spielzeuge ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Ko-Referenzen sind auch Stücke, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schaffen diese Fehler, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererseits gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach, da eine fehlerhafte Beschreibung weniger wahrscheinlich sein kann als die ursprüngliche Beschreibung."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es zwar nicht unmöglich, statistisch gesehen ist es weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann Pflanzen schneiden, und große Vision- und Sprachmodelle könnten dies aufgreifen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um gültige Folien zu erhalten, müssen wir daher Maßnahmen ergreifen."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir starke Sprachmodelle, um FOILs vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir die Inferenz durch natürliche Sprache oder kurz NLI, um Folien zu filtern, die das Bild noch beschreiben könnten, da wir bei der Konstruktion von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir eine Schlussfolgerung aus natürlicher Sprache mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Beschriftung als die damit verbundene Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In addition, wir betrachten die Kaption als die Premise und die FOIL als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell die FOIL als widersprechend oder neutral gegenüber dem Untertitel vorhersagt, nehmen wir dies als Indikator für eine gültige FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Folie durch den Untertitel enthalten ist, kann es keine gute Folie sein, da sie durch Transitivität eine wahrhaftige Beschreibung des Bildes liefert und wir diese Folien ausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Prozedere ist nicht perfekt. Es ist nur ein Indikator für valide Foil."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Erstellung gültiger FOILs menschliche Annotatoren, um die in Valse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir also so viele Testfälle wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um einen Benchmark für Null-Schuss-Tests handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vorausbildung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Die Feinabstimmung würde es den Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nutzen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vorausbildung haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen auf Vowels, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin I und VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bilder-Satzpaaren in Untertitel und FOILs."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht ist für dieses Video relevanter, dass wir unsere permissivere Metrik, die Paargenauigkeit, präsentieren, die misst, ob der Ausrichtungswert des Bildesatzes für das korrekte Textpaar des Bildes höher ist als für das fehlerhafte Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Metriken und Ergebnisse zu diesen Ergebnissen finden Sie in unserer Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit Paar-Präzision sind hier gezeigt und entsprechen den Ergebnissen, die wir aus den anderen Metriken erhalten haben. Die beste Leistung bei Nullschüssen wird von Wilbert zwölf in einem, gefolgt von Wilbert, LXMert, Clip und schließlich VisualBird erreicht."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert Twelve in One fast gelöst werden, wobei er hervorhebt, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann in unseren Adversarial Foiling-Einstellungen keine der verbleibenden Teile zuverlässig gelöst werden"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäten und Zählungsinstrumenten sehen wir, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Aktionen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie durch plausibel Vorurteile unterstützt werden, wie wir im Aktionsteil sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Bereich erfahren wir, dass es für Vision- und Sprachmodelle ebenfalls schwierig ist, mehrere Referenzen auf das gleiche Objekt in einem Bild mit Pronomen zu verfolgen."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Verstandskontrolle und weil es ein interessantes Experiment ist, haben wir auch zwei Textmodelle, GPT eins und GPT zwei, benchmarkt, um zu beurteilen, ob Valse durch diese Einmodalmodelle gelöst werden kann, indem wir die Verwirrung der richtigen und der fehlgeschlagenen Beschriftung berechnen und den Eintrag mit der geringsten Verwirrung vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die FOIL höher ist, nehmen wir dies als Hinweis darauf, dass die FOIL-Beschriftung unter einer plausibilen Voreingenommenheit oder anderen sprachlichen Voreingenommenheiten leidet."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die Text nur GPT Modelle die Plausibilität der Welt besser erfassen haben als die Vision und Language Modelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALS ein Benchmark ist, der die Linse der sprachlichen Konstruktionen nutzt, um der Community bei der Verbesserung von Seh- und Sprachmodellen zu helfen, indem sie ihre visuellen Grundlagefähigkeiten hart testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu begründen, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich ermutigen, VALS zur Messung des Fortschritts hin zur Sprachbasis mit Vision und Sprachmodellen zu verwenden."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, VALS könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von VALS getesteten Aspekte hilft."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, sollten Sie sich die Walls-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde eine Papier entitelt RNSAM, ein Large Scale DSET für automatische Risikogrammierung beim Commitologizieren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikogenerierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNote ist ein technisches Dokument, das die bei jeder Veröffentlichung eines Softwareprodukts zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Restnoten für Bosch 2.6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "User Us Library These Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consuming, um manuell zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, hochwertige Release-Noten automatisch zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Frischknotengenerierung verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste System, das Arena erstellt wurde, wurde 2014 erstellt."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert eine ruralbasierte Approach, zum Beispiel, indem man die Change Extractor verwendet, um Code differenzen, Bibliothekänder und Dokumentenänderungen von den differenzen zwischen Releases zu extrahieren, und schließlich kombinieren sie."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das bemerkenswerteste Merkmal dieses Systems ist der Ausgaben-Extraktor in der oberen rechten Ecke,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dieses muss mit dem Issues-Ökosystem verbunden sein und kann nur auf Projekte mit Null angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist Grief. Dies entweder angesagt in 2014."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "2020. Es ist auf dem Internet verfügbar und kann via PIP gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches Textklassifizierungsmodell basierendes auf Lernen und Ausgaben aus fünf Labors, wie z. B. Funktionen oder Fehlerbehebungen, für jede Eingabe-Kommentarnachricht."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Sample-User, das eine Korrektur für Fehlerkorrekturen erhält."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingdaten sind sehr klein, etwa fünftausend, und werden in den Experimenten beschriebenen unten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Kreuzschaltmodells ist nicht höher."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier löst diese beiden Probleme und erzeugt automatisch hochwertige Freigabe-Noten."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das begrenzte Anwendungsprogramm schlagen wir eine hochwertige Klassifizierungsmethode mit nur Kommentarmeldungen als Eingabe vor."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Repositories verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der Skarbstaatressourcen haben wir eine RNSAM DSET konsistent mit etwa 82.000 Datenpunkten erstellt, indem wir Daten aus öffentlichen GitHub Repositories mit der GitHub API erstellen."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unsere Daseinsetzung."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Nachricht des Komitees und die rechte Seite ist die Release-Note."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Riesen sind als Verbesserungen, Verbesserungen, etc. gelobt."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Kommentarnachrichten als Eingaben aufnimmt und die Raveled-Please-Notizen ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassungsaufgabe angesehen werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Rubber, Funktionen, Verbesserungen, Fehlerbehebungen, Deprekationen, Entfernungen und Bremsänderungen vorgedefiniert."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden aufgrund früherer Forschung und anderer Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Rhythmus-Noten unten rechts werden aus den Rhythmus-Noten unten links abgezogen."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Moment müssen die vier Schuttwerke, die im Voraus aufgestellt wurden, entdeckt werden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Lager sind nicht immer mit jeder Freiheit übereinstimmen"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, um Verbesserungen zu treffen, zu erhöhen, Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabulärliste mit etwa 30 Numbers für jede dieser Rotationsvariationen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Restnotkrasten zu erkennen und den Text der Restnotkrasten zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Komiteemeldung."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachrichten des Komitees sind nicht an jede Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der image below, wenn die aktuelle Realität Boson zwei Punkt fünf zwei neunzehn, müssen wir die IDECHTEN"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "erfüllt die vorherige Version 2.5218 und erhält einen Tiff. Dies ist ein bisschen mühsam und es reicht nicht aus, nur eine Liste der Releases zu erhalten und sich die Vorher und Nachher anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine Heuristik, die mit Ihnen übereinstimmt, um die vorherigen und nächsten Schauspielzeiten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind die Horses."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "In der Hand, siebentausend zwei hundert Repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Token 63, was für eine Zusammenfassungsaufgabe ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Nummer der Unique Tokens ist bei Roger at eight thousand eight hundred thirty thousand."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl von einzigartigen Kasten und Methoden im Repertory."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes erkläre ich die vorgeschlagene Methode."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Querschnitts-, Extraktions- und Abstruktionsmodell besteht aus zwei neuer Modulen"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifier mit Bot oder Code Bot und ein Generator mit Bot."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Klassifizierer, um jede Kommentarnachricht in fünf RESNOT-Klassen zu klassifizieren: Funktionen, Verbesserungen, Fehlerbehebungen, Duplizierungen und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als anderer eingestuften Komitee-Nachrichten werden abgelehnt."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GAS den Generator unabhängig auf die vier Rudder-Dokumente an und erzeugt für jede Klasse Risikonode."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Übereinstimmungen zwischen Commit-Nachrichten und Lesemerkungen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifizierer zu trainieren, weisen wir jeder Eingabe-Commit-Nachricht Pseudorabben zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Kreuzstreifen-Abstruktiv-Summersätze durch zwei verschiedene Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzigen SEC-Netzwerk und generiert einen einzigen Long-SNode-Text, der eine Kombination von Eingabe-Commit-Nachrichten liefert."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgangstext kann in Kreuzzeichen aufgeteilt werden, basierend auf speziellen Kreuz-Spezifischen Endpunkt-Symbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSMarch nennen, besteht aus vier verschiedenen SEC-to-SEC-Netzwerken, von denen jede einer der RES-Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das macht Spain's Experiment."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: CS, CS Single, CS Smart, Russelling und die vorherige Studienbeschreibung."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Abrissung sind in einigen Fällen diese Noten in mehreren Sätzen ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro ist penetrativ, wenn das System einen kurzen Satz ausgibt"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Brauvolumen. In den als nächstes beschriebenen Experimentenergebnissen"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erzeugen wir auch eine Spezifität, da Rouge und Brux nicht erzeugt werden können, wenn die Riesen-Knoten leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass die Modellprojekte ausgegeben sind, die in Fällen, in denen die Reasonals empfangen, empfindlich sind."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Daseit Emailadresse, Hashbarriers, etc. enthält, erweitern wir auch den Quint Daseit, der sie ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat und sie hat Rouge Air-Punkte erreicht, die mehr als zehn Punkte höher waren als die Baselines."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Green Test set, der Square Gap zwischen der proposierten Methode und der Basis jumped zu mehr als 20 Punkten."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie und sie erfolgreich sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS hat eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Crossfire und eines Generators auf das Training des Crossfire-Systems mit Pseudobus effektiv ist."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, weil der Klassifizierer sich auf die relevanten Kommittentests für jeden Kurs konzentrieren kann."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie isst in dieser Zeit viel höher als wenn sie ledig ist."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es auch effektiv ist, für jede dieser Notengrasse unabhängig verschiedene Perspektivsummerisierungsmodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hero und Eronasus"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xia's Methoden neigen dazu, kürzere Sätze als menschliche Referenz-Sätze zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Figur auf der rechten Referenz hat drei oder vier Sätze, während CS nur eins hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzugabe ist, dass in den Trainingsdaten nur 33 % der Sätze im Rabel Merkmale und 40 % im Rabel Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES Methoden ohne zusätzliche Informationen keine genauen Risikobewertungen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommentarmeldung, und die Kommentarfassung kann nicht generiert werden, ohne auf die entsprechende Peru-Request oder -Erstellung hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das untenstehende Beispiel zeigt, dass die beiden Kommentarberichte im Eingaben miteinander verbunden sind und in einen Satz kombiniert werden sollten, aber dies geschieht nicht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Personalgenerierung erstellt,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Kommentarmeldungen einzugeben und sie zusammenzufassen, sodass sie für alle Projekte auf Englisch anwendbar ist."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die Bassrate besser laut macht als die Bassrate."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte schauen Sie sich unsere Dessert-Audit-Tab an."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist ein Safarari,"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unsere Arbeit über die Anreicherung von Tabellen mit Hilfe von fein abgestimmten Transformatoren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Merkmale der Daten."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen begrenzt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Funktionen mit einer anderen Datenquelle kann erhebliche Informationen bieten."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung von Tabelldaten mit externen Quellen-Freitexten."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben eine Tabelldatensammlung und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Funktionen aus dem künstlichen Text der Wissensbasis zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel sehen. In einem Datensatz, der in FEST eingeführt wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist die Datenmenge Universitätsdatenmenge."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten zu unterteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festes ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Einheit, in diesem Beispiel der Name der Universität, mit einer Einheit innerhalb der Wissensbasis verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Knowledge-Basis wird extrahiert und in die Daten setzt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text der Abstrakt der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Funktionen aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen also eine Funktionsaufnahmephase, die Textanalyse beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde mich in den nächsten Folien tiefer damit befassen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Extraktionsphase der Merkmale gibt es eine Generierungsphase der Merkmale, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst generieren Sie Funktionen in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also, erstens zwei neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Funktion stellt die Wahrscheinlichkeit für jede Klasse dar."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, die sich auf Transformer basieren lassen, wie Baird, GPT, XLED und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe zur Feinabstimmung sein."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Funktionsauffnahme können wir also ein Parent-Train-Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell verfeinert, um Text in Klassen zu klassifizieren, abstrakt in Klassen, niedrig oder hoch."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse ist, und verwenden Sie sie als neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datenmengen möglicherweise wenige unterschiedliche Entitätsstapel haben."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Proben, und der kleinste Datensatz enthält fünfunddreißig Proben in seinem Trainings-Satz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorherige Kenntnisse über voranalyseierte Datensätze nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir den nth-Datensatz analysieren."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sugest, ist die Hälfte der Fine Tuning Phase."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Phase der Fine-Tuning-Multitask."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über n minus eins Datensätze finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine weitere Feinabstimmungsphase durch, die eine Feinabstimmung der Zielaufgaben ist, wenn wir das Sprachmodell über den n-Tiel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der neueste Stand der Multitask-Fine-Tuning, der MTDNN genannt wird."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN hält MTDNN eine Anzahl von Aufgaben im Trainingsatz aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainings-Set. Also leere DNN und halte vier Kopfhäupter, wie Sie auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es samplet eine zufällige Charge aus dem Trainingsset."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Run-Batch zu einer, zum Beispiel, Sing und Selton-Klassifizierungsaufgabe gehört, führt er einen Vorwärts- und Rückwärtspass durch den ersten Kopf aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zu einer Paar-Ranking-Tasche gehört, wird sie durch den letzten Kopf weitergegeben und zurückgegeben."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario verifiziert eine Datenmenge-Tabelle die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN hält die Anzahl der Klassen-Heads-Ausgaben-Schichten aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss MTDNN eine neue HEADS für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Task Reformulation Fine Tuning bezeichnet wird, besteht darin, dass wir in unserem Ansatz Task Reformation Fine Tuning statt mehrere Kopfgruppen zu behalten, jeden Datensatz in ein Satz pro Klassifizierungsproblem umformulieren, das zwei Klassen-Aufgaben ist."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also ein Beispiel sehen."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Input-Datensatz, der von Entitäten, Funktionen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zu der Klassifizierung des Textes, des Abstrakts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, wir haben das Sprachmodell so trainiert, dass es abstrakt und in der Klasse klassifiziert, ob die Abstrakt-Klasse in der Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Etikettvektor besteht in diesem Fall also immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren fertigen oder formulierten Feintuning-Ansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also das vollständige Framework betrachten."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und das set fade into fast"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Entity-Linking-Phase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensbasis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird die Aufgabe in eine Satz-Per-Classifikation-Tasche reformuliert."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und die Ausgabenwahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über n-1-Datensatz mit einer vorläufigen Multitask-Fine-Tuning verfeinert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu erstelltes Merkmal in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Rahmenwerk zu bewerten, verwenden wir eine Datenmenge mit siebzehn Tabellen, die Größe, Merkmale, Balance, Bereich und anfängliche Leistung variieren."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unser Experiment als Live-Out-Evaluierung gestaltet, bei der wir schnell über sechzehn Datensätze trainieren und sie auf das siebzehnte Datenset anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datensatz in vier Fehler auf und wenden eine Falten-Cross-Validation an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Funktionen und bewerten sie mit fünf Bewertungs-Klassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-Basis-Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Rahmenwerk mit der Feinabstimmung des Zieldatensatzes, der Feinabstimmung der Zielaufgabe und der vorläufigen Feinabstimmung der MTDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere Formulierung ist ein Feintuning, das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2% gegenüber der Feinabstimmung des Zieldatensatzes erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Poach hat eine Verbesserung um sechs Prozent erzielt."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Daten ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Feinabstimmung bei mehrere Aufgaben auf 1,5 Prozent abnimmt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung hat sich im Vergleich zu der Zielaufgabe, die allein mit der Feinabstimmung verbessert wurde, um elf Prozent zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Zusammenfassung ermöglicht Fast die Bereicherung von Fushot aus 35 Proben in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulationsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satzpaar-Klassifizierungsproblematik verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Assa Farari und ich werde unsere Arbeit FUSHOT Tabellendatenanbau mit fein abgestimmten Transformers-Architekturen vorstellen. Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Datenmerkmale, aber manchmal sind diese Merkmale begrenzt. Die Generierung von Merkmalen mit einer anderen Datenquelle kann erhebliche Informationen hinzufügen. Unser Forschungsziel ist die automatische Tabellendatenanbau mit externen Quellen, freiem Text. Nehmen wir an, wir haben eine Tabellendatenmenge und eine Wissensbasis. Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Merkmale aus dem kostenlosen Text der Wissensbasis zu extrahieren. Unser Framework FEST ist genau dieser automatische Prozess. Lassen Sie uns ein Beispiel betrachten. In einem Datensatz, der in FEST eingeführt wird. In diesem Beispiel ist der Datensatz ein Universitätsdatensatz, wenn sein Ziel es ist, Universitäten in niedrig rankende Universitäten und hochrangige Universitäten. Als Wissensbasis verwenden wir Wikipedia. Die erste Phase von FEST ist die Entitätslinkung, bei der jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität innerhalb der Wissensbasis verknüpft wird und der Text der Entitäten der Wissensbasis extrahiert und zum Datensatz hinzugefügt wird. In diesem Beispiel ist der Text der Wikipedia-Seitenabschnitt. Jetzt müssen wir Features aus dem erhaltenen Text generieren oder extrahieren. Wir benötigen also eine Feature-Extraction-Phase, die Textanalyse beinhaltet. Und das ist die Hauptnota dieser Arbeit, und ich werde mich in den nächsten Folien damit befassen. Nach der Feature-Extraction-Phase gibt es eine Feature-Generation-Phase, in der wir die extrahierten Features verwenden, um eine kleine Anzahl von Features zu generieren. Sie eine kleine Anzahl neuer Merkmale. Erstellen Sie zuerst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes. In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen, also erstellen Sie zuerst zwei neue Merkmale. Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Merkmale. Jede Merkmale repräsentiert die Wahrscheinlichkeit für jede Klasse. Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, nämlich transformierbare Sprachmodelle wie BERT, GPT, XLERT und so weiter. Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können. Daher wäre eine naive Herangehensweise die Feinabstimmung der Zielaufgabe. In der Fase der Extraktion der Funktionen können wir ein pertrainiertes Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset feinabstimmen. In diesem Beispiel können wir das Sprachmodell fe soll Text in Klassen, Abstract in Klassen, Low oder High, in Klassen eingeteilt, die Sprachmodell-Ausgaben erhalten, die für jede Klasse die Wahrscheinlichkeit sind, und als neue Funktionen verwendet werden. Das Problem bei diesem Ansatz ist, dass Daten sätze möglicherweise wenige unterschiedliche Entitäten wie Text enthalten. In unserem Experiment enthalten fast die Hälfte der Daten sätze weniger als 400 Samples und die kleinsten Daten sätze enthalten. Es enthält 35 Proben in seinem Trainings-Set. Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern. Wir können jedoch vorherige Kenntnisse über voranalysierte Datensätze nutzen, da wir FAST über mehrere Datensätze anwenden. Wir können die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir die nth Dataset. Was wir vorschlagen, ist eine weitere Fein-Tuning-Phase, eine preliminäre Multitask-Fein-Tuning-Phase, wenn wir das Languagemodell über n-1 Datasets fein-tunen. Und dann führen wir eine weitere Fein-Tuning-Phase aus, die eine Target-Task-Fein-Tuning ist, wenn wir das Languagemodell über das nth-Target-Dataset fein-tunen. Der Stand der Welt in der Multitask-Fein-Tuning-Phase. Fine-Tuning-Anwendung namens MTDNN. In MTDNN, MTDNN, mainten Sie eine Hälfte der Taschen im Trainingssatz. In diesem Beispiel gibt es vier Taschen im Trainingssatz. MTDNN mainten Sie vier Hälfte, wie Sie sehen können, im Bild. Es sampelt eine Random-Batch aus dem Trainingssatz. Und wenn die Random-Batch zu einem Zum Beispiel Singenselten's Classification-Tasks, es führt Vor- und Rückwärtspfade durch den ersten Kopf aus. Und wenn der Random-Batch zu Paar-Wise-Ranking-Task gehört, führt es Vor- und Rückwärtspfade durch den letzten Kopf aus. In unserem Szenario verringen Tableau-Datensätze die Anzahl der Klassen. Es gibt also viele Aufgaben. MTDNN-Mainten. DNN hält eine Reihe von Klassen-Heads-Ausgaben-Lagen aufrecht und zusätzlich muss MTDNN neue Heads für einen neuen Datensatz mit einer neuen Aufgabe initialisieren. Unser Ansatz, der als Task-Reformulation-Fine-Tuning bezeichnet wird, ist, dass wir in unserem Ansatz Task-Reformulation-Fine-Tuning, anstatt mehrere Heads aufrechtzuerhalten, jedes Datensatz in ein Satz pro Klassifizierungsproblem, das zwei Klassen-Taschen. Also, sehen wir ein Beispiel. Hier ist unser Input-Datensatz, der entweder von Entitäten, Funktionen, Text und Klassen besteht. Und wir reformulieren die Tasche von der Klassifizierung der Text in Low und High, um die Text, den Abstrakt und die Klasse in True oder False zu klassifizieren. Oder in anderen Worten, wir trainieren das Languagemodell, um eine Abstrakt- und Klassenklasse zu klassifizieren, ob die Abstrakt- und Klassenklasse zur Klasse gehören oder nicht. Der Etikettvektor bleibt in diesem Fall immer mit zwei Klassen bestehen. Und das ist der Algorithmus für unsere Find-Orientierung. find reformulated fine-tuning approach. Also, sehen wir uns den vollständigen Framework an. Ein Datensatz wird in FAST eingeführt und dann FAST execute in die Linkingphase. Es extrahiert den Text aus der Knowledge-Basis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist. Dann wird die Task reformuliert in Satz-Per-Classification-Tasks, das Sprachmodell auf die neue Task und die Ausgaben-Likelihood für jede Klasse. Beachten Sie, dass das Language-Modell bereits über n-1-Datensätze mit einer vorläufigen Multitask-Fine-Tuning abgestimmt ist. Dann verwenden wir den Ausgabenvektor des Language-Modells als neu generierten Funktion in der Anzahl der Klassen. Um unser Framework zu evaluieren, verwenden wir eine 17. Wir haben eine siebzehn-Tabellklassifizierungsdatensätze, die die Größe, die Merkmale, den Bereich und die anfängliche Leistung in Einklang bringt. Und als Wissensbasis verwenden wir Wikipedia. Wir haben unser Experiment als eine Live-Out-Evaluierung entworfen, bei der wir schnell über sechzehn Datensätze trainieren und sie auf die siebzehnte Datensätze anwenden. Wir haben auch jede Datensätze in vier Daten aufgeteilt. Wir erstellen Fehler und wenden eine Fork-Fehler-Kreuzvalidierung an. Dann generieren wir die neue Funktion und bewerten sie mit fünf Bewertungs-Klassifikatoren. In unserem Experiment verwenden wir eine auf Bild-Basis basierte Architektur. Hier sind die Ergebnisse unseres Experiments. Sie sehen, dass wir unser Framework mit der Feinabstimmung des Zieldatensatzes vergleichen, der Feinabstimmung der Zielaufgabe. und MTDNN preliminäre Feintuning und unsere reformulierte Feintuning erreichten den besten Ergebnis, die besten Leistungen, während MTDNN 2% Verbesserung über die Target-Datenset-Fine-Tuning erreichte. Unser Produkt erreichte 6% Verbesserung. Wenn wir uns die kleinen Daten ansehen, Aus dem Datensatz können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Fine-Tuning für mehrere Aufgaben auf 1,5 Prozent abnimmt, aber unsere Leistung steigt auf 11 Prozent im Vergleich zur alleinigen Fine-Tuning für die Zielaufgabe. Für die Zusammenfassung ermöglicht FAST die Bereicherung von Flux-Schüssen aus 35 Proben in unserem Experiment. verwendet eine Architektur für alle Aufgaben-Datensätze und behält den Kopf des Modells bei. Aber es fügt eine Formulierungsphase hinzu, es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satz-Par-Klassifizierungsproblematik verwenden können. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen. Heute werde ich unser Forschungswerk Lernen, deduktiv zu denken, Methodenproblemlösung als komplexe Rationsauffnahme vorstellen. Ich bin Alan vom Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD. Zunächst möchte ich über unsere Motivation für das Denken sprechen. Hier zeigen wir Beispiele, in denen mehrträgliches Denken hilfreich ist. Diese Zahl stammt aus der POWN-Artikel, in der sie die Anregung zur Lösung des Methodenproblems in einem Future-Learning-Szenario durchführen. Auf der Netto-Pan-Seite können wir sehen, dass wir, wenn wir einige Beispiele mit nur Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten. Wenn wir jedoch eine weitere Beschreibung geben, kann das Modell die Beschreibung vorhersagen und auch eine korrekte Vorhersage treffen. Es ist also gut, als Ausgabe interpretierbare Mehrstufige Beschreibung zu haben. Wir denken auch, dass das Methodenproblem eine einfache Anwendung ist, um solche Beschreibungsfähigkeiten zu bewerten. Hier in unserer Problemkonfiguration müssen wir diese Frage aufgrund der Fragen lösen und die numerischen Antworten erhalten. In unseren Datensätzen erhalten wir also auch den mathematischen Ausdruck, der auch zu dieser bestimmten Antwort führt. Daher gelten bestimmte Annahmen wie in früheren Arbeiten. Wir gehen davon aus, dass die Präzision von Größen bekannt ist, und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential. Darüber hinaus können komplizierte Operatoren tatsächlich ent in diese grundlegenden Operatoren aufgeteilt werden. Frühere Arbeiten im Lösungsproblem der Methode können also tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baummodell kategorisiert werden. Traditionelle Sequenz-zu-Sequenz-Modelle konvertieren den Ausdruck in eine spezifische Sequenz für die Generierung, und es ist ziemlich einfach zu implementieren, und es kann auf viele verschiedene komplizierte Probleme verallgemeinert werden. Aber die Nachteile sind, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell, und es fehlt an Interpretabilität für die die Vorhersage. Aber eigentlich ist diese Richtung aufgrund des Transformator-Modells immer noch ziemlich beliebt. In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen. Hier generieren wir also die Operatoren, bis wir die Blätter erreichen, die die Größen sind. Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt. Aber eigentlich ist es ziemlich kontraintuitiv. Denn wir generieren zuerst den Operator und dann am Ende die Größen. Und das Zweite ist, dass er auch einige wiederholte Berechnungen enthält. Wenn wir uns also diesen Ausdruck a mal drei plus drei ansehen, wird er tatsächlich zweimal generiert. Aber tatsächlich sollten wir die Ergebnisse wiederverwenden. In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und interpretierbar lösen. Zum Beispiel können wir hier im zweiten Schritt die Daten erhalten., die 27 sind. Und wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden. Und in diesen Schritten erhalten wir die Teiler. Und dann erhalten wir in diesem dritten Schritt tatsächlich den Quotienten. Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse des zweiten Schritts wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten. Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren. Dies macht den Prozess genauer. In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als Anfangszustände ein. Der Ausdruck wird also durch EIJOP dargestellt, bei dem wir Operatoren von Qi bis Qj ausführen, und dieser Ausdruck ist tatsächlich gelenkt. Wir haben hier auch eine Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen. Das ist ziemlich ähnlich wie eine Relationsentfernung. In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diesen neuen Ausdruck. Wir fügen ihn den nächsten Zuständen hinzu, um eine neue Größe zu erhalten. Diese Folien visualisieren tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zustand weiterhin Ausdrücke hinzufügen. In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Netzwerkmodell, das Vögel oder Roberto sein kann, und dann codieren wir den Satz und erhalten diese Mengenrepräsentationen. Sobald wir die Mengenrepräsentationen erhalten, können wir mit der Schlussfolgerung beginnen. Hier zeigen wir ein Beispiel für Q1, um die Repräsentation für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q3 multipliziert wird. Zuerst erhalten wir die Paarrepräsentation, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist, und dann wenden wir ein Fit-Forward-Netzwerk an, das ist. Dies wird durch den Operator parametriert. Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2. Aber in der Praxis könnten wir im Inferenzstadium auch den falschen Ausdruck erhalten. Hier sind alle möglichen Ausdrücke gleich dreimal so viele Operatoren. Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern. Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchraum entfernen. Im zweiten Schritt machen wir also das Gleiche, aber der einzige Unterschied ist eine weitere Größe. Diese Größe stammt also aus dem vorher berechneten Ausdruck. Schließlich können wir diesen endgültigen Ausdruck Q drei mal Q vier erhalten. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke vom vorherigen Schritt unterschiedlich ist. Solche Unterschiede machen es schwierig, ihn anzuwenden. Es ist schwer, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist. Der Trainingsverfahren ist ähnlich wie bei der Schulung eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust bei jedem Zeitschritt optimieren, und hier verwenden wir auch diese Zeichen, um darzustellen, wann wir diesen Generierungsprozess beenden sollten. Und hier ist der Raum von Sequenz zu Sequenz anders, da der Raum bei jedem Zeitschritt unterschiedlich ist, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Wortschatzes ist. Es ermöglicht uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen aufzustellen. Wir führen also Experimente mit den häufig verwendeten Methodenproblemdatensätzen durch, MAWPS, Math twenty three K, MathQA und SWAM. Hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen. Unsere am besten funktionierende Variante ist Roberta Deductive Reasoner. Tatsächlich verwenden wir nicht BeamSearch, im Gegensatz zu den vorherigen Ansätzen mitze sind oft ein Baumbasiertes Modell. Insgesamt kann unser Argumentationsmodell dieses Baumbasierten Modells deutlich übertreffen, aber wir können sehen, dass die absoluten Zahlen bei MathQA oder SWAM nicht wirklich hoch sind. Wir untersuchen die Ergebnisse bei SWAM weiter, und dieser Datensatz ist eine Herausforderung, da der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie zum Beispiel das Hininzufügung von irrelevanten Informationen und zusätzlichen Mengen. In unserer Vorhersage stellen wir fest, dass einige der Zwischenwerte tatsächlich negativ sind. In diesen Fragen fragen wir zum Beispiel, wie viele Äpfel Jake hat, aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Töne und Stephen hat acht Töne, was völlig irrelevant ist. Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt. Und wir beobachten, dass diese beiden Ausdrücke tatsächlich ähnliche Zahlen haben. Wir haben tatsächlich ähnliche Punktzahlen. Wir können also diesen Suchraum einschränken, indem wir diese negativen Ergebnisse entfernen, damit wir die Antwort richtig machen können. Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert. Zum Beispiel verbessern wir für Vögel sieben Punkte und für das Roberta-basierte Modell zwei Punkte. Ein besseres Sprachmodell hat also eine bessere Sprachverständnisfähigkeit, sodass die Zahl hier. Hier ist es höher für Roberta und niedriger für Vögel. Und wir versuchen auch, die Schwierigkeit hinter all diesen Daten zu analysieren. Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Informationen angesehen werden kann. Hier können wir also sehen, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und der SWAMP-Datenmenge den größten Teil hat. Und hier zeigen wir auch die Gesamtleistung für diese Proben ohne ungenutzte Mengen. Die Gesamtleistung ist also tatsächlich höher als die. Und die Leistung ist tatsächlich höher als die Gesamtleistung. Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlechter ist als die Gesamtleistung. Für MAWPS haben wir nicht wirklich viele Datenfälle, also ignoriere ich diesen Teil einfach. Schließlich möchten wir die Interpretbarkeit durch ein Beispiel für das Zusammenbruch zeigen. Hier macht unser Modell also tatsächlich eine falsche Vorhersage im ersten Schritt. Wir können diesen Ausdruck tatsächlich mit dem Satz hier korrelieren. Wir denken, dass dieser Satz das Modell mit einer falschen Vorhersage irreführt. Wenn wir hier also weitere 35 Pflanzen pflanzen, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte. Wir versuchen, den Satz so zu ändern, dass die Anzahl der Birnen 35 weniger als die Apfelbäume ist. Wir machen es also, um genauere Semantik zu vermitteln, sodass das Modell die Vorhersage richtig machen kann. Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Verhalten des Modells zu verstehen. Um unsere Arbeit abzuschließen: Zunächst ist unser Modell ziemlich effizient und wir können interpretierbare Lösungsmethoden bereitstellen, und wir können ein wenig vorheriges Wissen als Einschränkung einbeziehen, was die Leistung verbessern kann. Das letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch auf andere Aufgaben, die mehrträgliches Denken beinhalten. Wir haben aber auch bestimmte Einschränkungen. Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein. Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung bei verschiedenen Zeitstufen unbalanciert ist, daher ist es auch ziemlich schwierig, eine Beam-Suche-Strategie anzuwenden. Das ist also das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich bin von der Maastricht University. Ich werde meine gemeinsame Arbeit mit Jerry vorstellen, die sich mit einer neuen Datensammlung für die Erfassung von gesetzlichen Artikeln befasst. Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen, aber die Mehrheit der Bürger hat wenig bis kein Knowledge über ihre Rechte und grundlegenden Rechtsprozesse. Daher werden viele gefährdeten Bürger, die sich die kostspielige Unterstützung eines Rechtsexperten nicht leisten können, ungeschützt oder schlimmer gesagt, ausgenutzt. Unsere Arbeit zielt darauf ab, die Grenze zwischen Menschen und dem Gesetz zu schließen, indem er ein effektives Retrievalsystem für Statutartikel entwickelt. Ein solches System könnte eine freie professionelle Rechtshilfegemeinschaft für unqualifizierte Menschen bieten. Bevor wir uns auf den Hauptbegriff dieser Arbeit konzentrieren, sollten wir uns zunächst mit dem Problem der Statutartikelretrieval befassen. Bei einer einfachen Frage auf einem Rechtsmaterial, wie zum Beispiel was ich riskieren kann, wenn ich professionelle Privatsphäre verletze, ist ein Modell erforderlich, um alle relevanten Statutartikel aus einem großen Bereich der der Gesetzgebung. Diese Information Retrieval Task kommt mit seiner eigenen Setz von Challenges. Erstens geht es mit zwei Arten von Linguage, der normalen natürlichen Sprache für die Fragen und der komplexen legalen Sprache für die Statuten zu tun. Diese Differenz in Languageverteilungen macht es für ein System schwieriger, relevante Kandidaten zu retrieveren, da es indirekt eine inhärente Interpretationssysteme erfordert, die eine natürliche Frage zu einer rechtlichen Frage, die die Terminologie der Statuten entspricht, translatiert. Besides, statutory Law ist nicht ein Stack von Independent Artikeln, die als eine vollständige Source von Informationen auf der Own behandelt werden können, wie neue Rezepte, zum Beispiel. Instead, es ist eine Struktur, eine Sammlung von legalen Provisionen, die eine ganze Bedeutung nur in der allgemeinen Kontext haben, das ist zusammen mit der supplementären Information aus den neighbouring Artikeln, den Feldern und Subfields, die sie belong zu, und ihrer Platz in der Struktur der Laub. Lastly, statutory Artikel sind ein kleiner Paragraph. was in den meisten Retrievalwerken die typische Retrieval-Einheit ist. Hier sind es lange Dokumente, die bis zu sechstausend Wörter schreiben können. Die recenten Entwicklungen in NLP haben enorme Interesse in vielen Rechtsakten wie Legal Judgment Prediction oder automatisierten Kontaktkontraktreview gespielt, aber die Statutory Article Retrieval hat sich aufgrund der Lack von groß und hochwertigen Labeldatensätzen in der Lage geblieben. In dieser Arbeit präsentieren wir eine neue French Native Citizen Centric Datenset zu studieren, ob ein Retrievalmodell die Effizienz und Reliabilität eines Legal Experts für die Task der Statutory Article Retrieval angeht. Unser Belgisch Statutory Article Retrieval Datsatsatz besteht aus mehr als 1.100 legalen Fragen, die von Belgischen Bürgern gestellt werden. Diese Fragen umfassen eine wide Reihe von Themen von Familie, Housing, Money, bis hin zu Work und Sozialversicherung. Each of them ist von erfahrenen Juristen mit Referenzen zu relevanten Artikel aus einem Corpus von mehr als 22.600 legal Artikeln aus Belgischen Codes of Law. Lassen Sie uns nun über die Art und Weise sprechen, wie wir diese Daten setzen. Erst, wir starten mit der Compilierung eines Large Corpus von legal Artikeln. Wir betrachteten 32 öffentlich verfügbare Belgischen Codes und extrahierten alle Artikel sowie die correspondenden Section Headings. Dann gingen wir mit Referenzen zu relevanten Statuten zusammen. To tun so, wir partnerten mit der Belgischen Law Firma. jedes Jahr um viertausend Emails von Belgischen Bürgern, die um Rat und persönliche Rechtsfragen bitten. Wir hatten die Glück, Zugang zu ihren Websites zu bekommen, wo ihr Team erfahrener Juristen belgische am häufigsten rechtlichen Fragen behandelt. Wir sammelten Tausende von Fragen, die mit Kategorien, Subkategorien und Rechtsreferenzen zu relevanten Statuten angepasst wurden. Lastlich durchgingen wir die Rechtsreferenzen und filterten die Fragen, die nicht Artikel in einem der Codes of Law we considered. Die remaining Referenzen wurden matched und zu den corresponding Artikel IDs von O Corpus. Wir eventuell endeten mit einem Jahrhundert und acht Fragen, die sich sorgfältig mit den IDs der relevanten Artikel aus unserem Large Corpus von twenty two thousand six hundred thirty three Statutory Articles labelten. In addition, jeder Frage kommt mit einer Mainkategorie und einer Konkatenation von Subkategorien. Jeder Artikel enthält eine Konkatenation der nachfolgenden Überschriften in der Struktur des Gesetzes. Diese zusätzlichen Informationen werden in der aktuellen Arbeit nicht verwendet, aber könnten für zukünftige Forschungen zur Rechtsinformationserfassung oder zur Klassifizierung von Rechtstexten interessant sein. Schauen wir uns einige Merkmale unserer Datensätze an. Die Frage ist zwischen fünf und vierundvierzig Wörter lang mit einem Median von vierzig Wörtern. Die Artikel sind viel länger mit einem Median von siebzig sieben Wörtern, wobei einhundertvierundvierzig davon mehr als tausend Wörter betragen. Die Länge eines von fünftausend siebenhundert und neunzig Wörtern. Wie bereits erwähnt, umfassen die Frage eine breite Palette von Themen, wobei etwa achtzig Prozent davon entweder Familie, Wohnung, Geld oder Justiz betreffen, während die restlichen fünfzehn Prozent entweder Sozialversicherung, Ausländer oder Arbeit betreffen. Die Artikel sind auch sehr vielfältig, da sie aus dreißig zwei verschiedenen belgischen Gesetzen stammen, die eine große Anzahl von illegalen Themen abdecken. Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Gesetze gesammelt wurden. Von den 22.633 Artikeln werden nur 1.612 als relevant für mindestens eine Frage in den Datensätzen angegeben, und etwa 80 % dieser zitierten Artikel stammen entweder aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafgesetz. Inzwischen werden 18 von 32 Gesetzen weniger als fünf Artikel als relevant für mindestens eine Frage angege, die durch die Tatsache verursacht wird, dass diese Code weniger auf individuelle und ihre Anliegen fokussiert. Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünfundzwanzig Prozent von ihnen sind mehr als fünfmal citiert. Mit unseren Data sets benchmarken wir verschiedene Retrievalapproaches, einschließlich Lexical und Densarchitektur. Given eine query in einem Artikel, eine Lexicalmodelle assigniert eine Score zu den queryartikelpaaren. Durch die Berechnung der Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfrage-Terme. Wir experimentieren mit den Standard-TFIDF- und BM25-Rankingsfunktionen. Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten. Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die die semantische Beziehung zwischen Abfragen und Artikeln erfassen kann. Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert. und berechnen einen relevanten Punkt zwischen einem Artikelpaar der Abfrage anhand der Ähnlichkeit ihrer Eingebettungen. Diese Eingebettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Eingebettungsmodells. Zunächst untersuchen wir die Effektivität siamesischer B-Encoder in einer Zero-Shot-Evaluierungs-Einrichtung, was bedeutet, dass vorgebildete Word-Eingebettungsmodelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden. Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und Fastastex und kontextabhängige Embeddingmodelle, nämlich Roberta und speziell Kamembert, ein französisches Roberta-Modell. Darüber hinaus trainieren wir unsere eigenen Kamembert basierenden Biencoders auf allen Datenmengen. Beachten Sie, dass wir für das Training mit den beiden Arten der Biencoder Architektur experimentieren. Siamese, das ein einzigartiges Wort-Embeddingmodell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraum mappiert. Und Tutor, das zwei unabhängige Wort-Embeddingmodelle verwendet. Wir haben zwei Independent Word Embedding Models, die den Query und Artikel separat in verschiedene Embeddingsphasen codieren. Wir experimentieren mit Mean, Max und CLS Pooling sowie Dot Product und Cosine für die Computing-Similaritäten. Hier sind die Ergebnisse unserer Baseline auf dem Testset, mit den Lexikonmethoden oben, den Siamese BE Encoders evaluiert in einem Zero Shot Setup in der Mitte, und den Fein Tun BE Encoders unten. Overall, die Fein Tun BE Encoders übertragen alle anderen Baselines. seine Siamese-Variante auf RECOLAT 100, aber ähnlich auf den anderen Metriken abschneidet. Obwohl BM 25 den trainierten Biancoder erheblich unterlegen hat, deutet seine Leistung darauf hin, dass es immer noch eine starke Grundlage für Domain-spezifische Rückholung ist. Bei der Zero Shot Evaluation des Siamese Biancoders finden wir, dass die direkte Verwendung der Embeddings eines vortrainierten Kamembert-Modells ohne Optimierung für die Informationsaufnahmeaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt. Der Word-to-Vec-basierte Biancoder übertraf die Fastex- und Vogelbasierten Modelle deutlich, was darauf hindeutet, dass möglicherweise vor-train-Word-Einbettungen für die Aufgabe angemessener sind als Charakter- oder Unterword-Einbettungen, wenn sie von Anfang an verwendet werden. Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Verbesserungsmöglichkeiten im Vergleich zu einem geschickten Experten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann. Lassen Sie uns mit zwei Limitationen von allen Datensätzen beginnen. Erstens ist der Corpus von Artikeln limitiert zu denen, die aus den dreißig zwei betrachteten Belgischen Codes erfasst werden, was nicht den gesamten Belgischen Law abdeckt, da Artikel aus Dekrees, Direktives und Ordinanzen enthalten sind. Durch die Datensatzkonstruktion werden alle Referenzen zu diesen unkollektierten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Fragment der initialen Anzahl relevanter Artikeln enthalten. Dieser Informationlaus impliquiert, dass die Antwort in den remaining relevanten Artikelnkel könnten incomplete sein, obwohl es immer noch vollständig appropriate ist. Second, wir sollten merken, dass nicht alle Rechtsfragen mit Statuten alone beantwortet werden können. For instance, die Frage kann ich meine Tenants evicten, wenn sie zu viel Noise machen, könnte nicht eine detaillierte Antwort in statutory Law enthalten, die eine spezifische Noise Threshold at which Eviction ist. Insted sollten die Landlage wahrscheinlich mehr auf Fallslaw und Präceden ähnlich wie der aktuelle Situation finden. Zwei Parteien pro Woche bis 2 Uhr morgens. Daher sind einige Fragen besser als andere für die Aufgabe der gesetzlichen Artikelerfassung geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen. Wir hoffen, dass unsere Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle der gesetzlichen Artikelerfassung weckt, die den Zugang zur Justiz für alle verbessern können. Sie können sich unsere Arbeit Datensätze und Code unter den folgenden Links ansehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir sind froh, unsere Arbeit auf VALS, einem Taskindependenten Benchmark für das Testen von Vision und Language Models mit spezifischen linguistiken Phänomenen zu präsentieren. Warum haben wir uns die Trouble in der Setzung dieses Benchmarks gemacht? Nun, während der letzten Jahre haben wir eine explosion von Transformer basierten Vision und Language Models, die auf große Mengen von Image Textpaaren geprägt sind. Each dieser Modelle pusht State of the Art auf Vision und Language Tasks, wie z. B. visuelle Fragen Sinnesrechnung, Bildretrieval, Phrase-Grundung. Wir haben also eine Nachricht, die Akuragen auf diesen spezifischen Benchmarks steigern, aber wissen wir, was die Modelle tatsächlich gelernt haben? Was hat ein Vision und Language Transformer verstanden, als er eine High Score für dieses Bild und diesen Satz zugewiesen hat und eine Low Score für dieses Bild? Fokusieren Vision und Language Models auf das Richtige oder konzentrieren sie sich auf Biasen? wie gezeigt durch vorherige Arbeit. Um mehr Licht auf diesen Aspekt zu senden, propellieren wir eine mehr task agnostic direction und einführen WALS, das die Sensitivität von Vision und Language Models zu spezifischen linguistiken Phenomenen, die sowohl die linguistic als auch die visuelle Modalitäten beeinflussen. Wir targen Existenz, Pluralität, Zählung, Spatialrelationen, Aktionen und Entity Coreference. Aber wie testen wir, ob die Vision und Language Models diese Phenomena erfasst haben? Foiling, eine Methode, die vorher für Vision und Language Models, nur für Nanphrasen von Ravi Shakar und Kollaborators und auf Counting von Asin previous worked. Foiling basically means, dass wir den Caption of an Image und einen Foil produzieren, indem wir den Caption so verändern, dass er nicht die Image anymore beschreibt. Und wir machen diese Phrasealterations, indem wir uns auf sechs spezifische Pieces wie Existenz, Pluralität, Counting, Spatialrelations, Actions, und Entity Coreference. Jede Piece kann aus einem oder mehreren Instrumenten bestehen, in dem Fall, dass wir mehr als eine interessante Möglichkeit gefunden haben, FOIL instanzen zu erstellen. Zum Beispiel haben wir in der Fall der Aktionspiece zwei Instrumente, einen in dem das Action verb mit einer anderen Action geändert wird und einen in dem Actants gewechselt werden. Zählen und Coreferenz sind auch Pieces, die mehr als eine Instrumenten haben. Und wir erstellen diese FOILs, indem wir unserstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererweit validierten Sätze sind. Dies ist nicht einfach zu tun, weil eine Foiled Caption weniger wahrscheinlich ist als die ursprüngliche Caption. Zum Beispiel, though it's not impossible, ist es statistisch weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann, und Largevision und Language Models könnten dies erkennen. Daher müssen wir, um valid Foils zu erhalten, Action unternehmen. Erstens, wir machen uns auf Strong Language Models zu propellieren. Zweitens, wir verwenden Natural Language Inference oder NLI, um Foils zu filtern, die noch beschreibiben das Bild immer noch, da wir bei der Konstruktion von FOILs sicherstellen müssen, dass sie das Bild nicht beschreiben. Um dies automatisch zu testen, wenden wir eine natürliche Sprachinferenz mit der folgenden Begründung an. Wir betrachten ein Bild als die Premise und seine Beschriftung als die damit verbundene Hypothese. Darüber hinaus betrachten wir die Beschriftung als die Premise und die FOIL als ihre Hypothese. Wenn ein NLI-Modell die FOIL zu widersprechen oder neutral zu den Beschriftungen zu sein, nehmen wir dies als Indikator für eine gültige FOIL. Wenn wir die Foil zu beentalten, kann es nicht eine gute Foil sein, da es durch Transitivität eine truthliche Beschreibung der Image geben wird und wir diese Foils ausfiltern. Aber dieser Prozess ist nicht perfekt. Es ist nur ein Indikator für valide Foils, daher als eine dritte Möglichkeit für die generierung von valid Foils, wir verwenden Humananannotators, um die Daten zu validieren, die in Valse verwendet werden. Also, nach Filtering und Human Evaluation, wir haben so viele Testinstanzen wie in dieser Tabelle. Note, dass Valse nicht trainierend Daten liefert. Aber nur Testdaten, da es sich nur um einen Benchmark für Null-Shot-Tests handelt. Es ist darauf ausgelegt, die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vor-Training-Aktivität zu nutzen. Die Feinabstimmung würde es Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen. Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen einschlagen. Und wie wir sagten, sind wir daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vor-Training-Aktivität haben. Wir experimentieren mit fünf Vision- und Sprachmodellen auf WALS, nämlich mit CLIP, Wilbert, Wilbert Kelvin I und Visual Bert. Zwei unserer wichtigsten Evaluierungsmetriken sind die Accuracy der Modelle in der Klassifizierung von Image Sentenzenpaaren in Untertitel und Foils. Perhaps für dieses Video mehr relevant, wir werden unsere permissive Metrik, die Paarwise Accuracy, die messen, ob die Image Sentenz alignment score für die korrekte Image Textpaar als für ihre Foilpaar ist. Für mehr Metriken und Ergebnisse auf themen, doch checken Sie unsere Papier. Die Ergebnisse mit Paarwise Accuracy sind hier und sie sind konsistent mit den Ergebnissen, die wir von den anderen Metriken bekommen haben. Es ist, dass die besten Zero Shot Performance durch Wilbert zwölf in one, gefolgt von Wilbert, Alex Mert, Clip, und schließlich Visual Bird. Es ist notabel, wie Instrumente centered on individuelle Objekte wie Existenz und Nounphrases fast solviert werden, wobei Wilbert zwölf in one, highlighting, dass Models ableistisch genannte Objekte und ihre Präsenz in Images identifizieren können. Allerdings können none der remaining Pieces in unseren adversarialen Foiling-Settings reliably solviert werden. Instrumenten, dass Vision und Language Models Trouble distinguisieren, referenzieren zu single versus multiple Objekten oder in einem Image. Die Relation Piece zeigt, dass sie Schwierigkeiten haben, eine named spatiale Relation zwischen Objekten in einem Image zu klassifizieren. Sie haben auch Trouble, Aktionen zu distinguieren und ihre Partizipanten zu identifizieren, selbst wenn sie durch Plausibility bias sind, wie wir in der Aktionspiece sehen. Aus der Referenzpiece finden wir, dass das Tracing multiple Referenzen zu dem gleichen Objekt in einem Image durch Pronouns auch für Vision und Language Models. Als eine Sanity Check und weil es ein interessantes Experiment ist, benchmarken wir auch zwei Textonlegermodelle GPT one und GPT two, um zu assessieren, ob Valse solvable durch diese Unimodalmodelle ist, indem wir die Perplexität der korrekt und der foiled Caption, keine Image hier, und die Entry mit der lowest Perplexität. Wenn die Perplexität höher für die Foil ist, dann nehmen wir dies als eine Indikation, dass die foiled Caption möglicherweise von Plausibility bias oder anderen linguistiken Biasen leidet. Und es ist interessant zu sehen, dass in einigen Fällen Die Textmodelle nur GPT haben die Plausibilität der Welt besser erfasst als die Vision und Language Models. Zusammenfassend ist VALSE ein Benchmark, das die Lensen von Linguistikkonstrukten verwendet, um die Community zu helfen, Vision und Language Models zu verbessern, indem sie ihre visuellen Grounding-Fähigkeiten hart testen. Unsere Experimente zeigen, dass Vision und Language Models namensgelegene Objekte in ihrer Präsenz in Bildern gut identifizieren, wie gezeigt durch das Existenzstück, aber es schwerwiegt, ihre Interdependence und Relationships in visuellen Szenen zu genehmigen, wenn sie gezwungen sind, linguistic Indikatoren zu respektieren. Wir möchten die Community wirklich ermutigen, Valse zur Messung des Fortschritts hin zur Sprachbasis mit Vision- und Sprachmodellen zu verwenden. Und noch mehr, Valse könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von Valse getesteten Aspekte hilft. Wenn Sie interessiert sind, sollten Sie sich die Valse-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamisara von der University of Tokio. Ich werde eine Papier entitelt RNSAM, ein großes Dasein für automatische Restnoturation bei der Commit Dog Summization. Ich werde in dieser Ordnung erklären. Erst, ich werde die automatische Restnoturation, die wir in dieser Research arbeiten, einführen. ReleaseNode ist ein technischer Dokument, das die Changes mit jedem Release von einem Softwareprodukt zusammenfasst. Das Image zeigt die ReleaseNode für Version zwei. sechs. vier der GBUJS Library. Diese Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consumierend zu erstellen. Daher wird es sehr nützlich sein, automatisch hochqualitäre Release Nodes zu generieren. Ich werde auf zwei frühere Researchers auf automatische Release Node Generation eingehen. Der erste ist ein System namens Arena, das in twenty fourteen erstellt wurde. Es ergreift eine Rule basierende Approach, zum Beispiel, indem es die Change Extractor verwendet, um Code differenzen zu extrahieren. Bibliotheksänderungen und Dokumentenänderungen von den differenzierten Releases und schließlich kombinieren. Die meisten erkennbaren Funktionen dieses Systems sind die Issue Extractor in der oberen rechten Ecke, die mit Jira, dem Issue Toco System, verknüpft und nur für Projekte verwendet werden kann. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden. Die zweite ist Griff, die Entry angeboten wurde in twenty twenty. Sie ist auf dem Internet und kann durch PIPSTEMENSSER Dieses System hat ein einfaches Lernbasis für Textklassifikation und erhält eine von fünf Rabellen, die Funktionen oder Bugfixen für jedes Input Commit-Message enthalten. Das Bild ist eine Sample-Usage, die eine korrekte oder Bugfixen-Rabelle enthält. Die gerade erstellten Rabellen sind ziemlich klein, etwa fünftausend, und werden in den Experimenten beschriebenen darüber gezeigt. Die Leistung des Textklassifikationsmodells ist nicht hoch. Ich präsentiere zwei related Researchers, aber es gibt Probleme mit begrenztem Erwerb und geringen Daten. und Scar State Resources. Unser Papier löst diese beiden Probleme und automatisch generiert High Quality Releasing Notes. Für das limitierte Applicability Programm, wir propagieren eine High Quality Classifier Summarization Methode, die nur Committee Message als Input verwendet. Diese Methode kann für alle English Repositories verwendet werden. Für das zweite Problem der Scar State Resources, wir bauen RL und SAM DSET konsistent mit etwa achtzig zwei Tausend Pieces von Daten, die von öffentlichen GitHub API. Next, ich beschreibe unser Desert. Hier ist ein Beispiel für Daten. Die linke Seite ist ein Commit Message und die rechte Seite ist die RISE Nodes. Die RISE Nodes sind Raveled als Implement, Bug fixes, etc. Wir haben eine Task setup, die die Commit Messages als Input und die Raveled RISE Nodes aufwendet. Dies kann als eine Summarization Task bezeichnet werden. Wir haben vier Raveled Features, Implement, Bug fixes, Duplications, Removables und Breaking Changes. Diese wurden basierend auf PBR research und anderen Faktoren. Die RISE Noten auf der bottom right und extrahiert von den RISE Noten auf der bottom left. At diesem Zeitpunkt ist es notwendig, die vier Rabels zu detektieren, die in der Passage sind, aber die Rabels sind nicht immer konsistent mit jeder Repository. Zum Beispiel, die Improvements Rabels inklusive Improvements, Enhancements, Optimisations und so weiter. Wir haben eine Vokabularliste oder Studie Rabels für jeden dieser Notation. variations. Verwenden Sie es, um die Restknoten zu erkennen und den Text der Restknoten zu korrigieren. Als nächstes kommt eine Kommittemessage. Kommittemessagen sind nicht zu jeder Rest. Wie in der image below, wenn die aktuelle Rest Persönlich 2.5219 ist, müssen wir die vorherige Rest Persönlich 2.5218 identifizieren und einen Tiff erhalten. Dies ist ein bisschen tedious und es ist nicht genug, nur eine Rest der Restknoten zu erhalten. Und wir haben die Vorhand nach. Wir haben eine heuristic Matching Blue erstellt, um die vorherigen und nächsten Persönlichkeiten zu erhalten. Dasset Analysis In der End, 7.200 Repositories und 82.000 PSO wurden korrektiv. Außerdem ist die average Anzahl von ReleaseNode Tokens 63, was für eine Summarisation Task ziemlich hoch ist. Außerdem ist die Anzahl von Unique Tokens ziemlich groß, also 8.830.000. Dies ist auf die große Anzahl von Unique Kosten und Methoden zurück namens in der Repository. Next, ich werde explain die proposierte Methode. Das Crosswise Extractive and Abstractive Summarization Model besteht aus zwei neuronalen Modules, einem Classifier, der Bot oder Code Bot und einem Generator, der Bot verwendet. Erstens, GAS verwendet einen Classifier, um jedes Committee Message in fünf Risnode Classes, Features, Improvements, Bugfixes, Duplications, Plus, und andere. Die Committee Messages klassifiziert als andere oder diskutiert. Dann GAS wendet einen Generator zu den vier Rabelschnitteln unabhängig und generiert RISE NOTE für jeden Kurs. In diesem Zusammenhang sind die direkten Korrespondenzen zwischen Commit Messages und RISE NOTE nicht bekannt. Daher, um den Kurs zu trainieren, wir zwar Rabelschnitteln zu jedem Input Commit Message verwenden, indem wir die ersten zehn Charaktere für jedes Commit Message verwenden. Wir modellieren den Kurs abstruktiven Summarisierungsansatz durch zwei verschiedene Methoden. Das erste Modell, das wir als GAS Single Sync konsist von einer Sync zwei Sync Network und generiert eine Sync Long RISE Node Tagist, geben eine Konkurrenz von Input Committee Messages. Die Output Tagist kann in Crosswise Segment basierend auf speziellen Cross Specific Endpoint Symbols unterteilt werden. Die zweite Methode, Methode, die wir CSMUCH, besteht aus vier verschiedenen Sync zwei Sync Networks, jeder von denen zu einer der RISE Node Classes entspricht. Okay, lassen Sie mich das Experiment erklären. Fünf Methoden wurden GS, GS Single, GS Marge, Russelling und previous studied Griff. Regarding Abortion, in einigen Fällen, diese Noten sind in multiple Sentenzen. Da es difficil ist, die Nummer von Sentenzen zu erkennen, sind sie kombiniert mit Spaces und treaten als ein langer Satz. Der Blue ist penalisiert, wenn das System einen kurzen Satz erfährt. Diese Penalty resultiert in einem loweren Blue Value in den Experimenten der Results describiert. Finally, wir auch die Spezifität erkennen, weil Rouge und Brew nicht erkennen können, wenn die Rouge Nodes leer sind. Eine hohe Spezifität bedeutet, dass die Modellkorrektie auspackt ist, in denen die Rouge Nodes leer sind. Hier sind die Ergebnisse. Da der Daseit Emailadresse, Hashbarrieren, etc. enthält, haben wir auch den Green Daseit erkannt, der sie ausschließt. GAS und GAS erreichten Rouge Error Scores mehr als zehn Punkte höher als die Baselines. Auf dem grünen Testset stieg die Score-Gap zwischen der vorgeschlagenen Methode und der Basis auf mehr als zwanzig Punkte. Diese Ergebnisse zeigen, dass GAS und GAS signifikant effektiv sind. GAS erreichte eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Klassifierers und eines Generators effektiv ist und das Training des Klassifierers mit Pseudoberseiten. Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, da der Klassifier sich auf das Sekten relevanter Kommittemechanismen für jede Klasse konzentrieren kann. Xia ist viel zu höheren Ruder als Xia single, suggesting, dass es auch effektiv ist, unterschiedliche perspektive Summarisationsmodelle für jedes Nodecraft zu entwickeln. Hier sind Erronnas. Xia's Methods tend to output shorter Sentenzen als humanen Referenz Sentenzen. In der Figur auf der rechten Referenz Sentenzen hat drei oder vier Sentenzen, während Xia nur eins hat. Der Grund für diese Modellrücktanz ist, dass in den Trainingdaten nur 33 Prozent der Sentenzen sind in der Features Rabel und 40 Prozent in der Improvements Rabel. Für die More CS Methods können nicht akurat mit Noten ohne zusätzliche Informationen generiert werden. Das Top Exempel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommittemessage und die Komplettesentence kann nicht generiert werden, ohne dass es sich auf die correspondente Periodrequest oder Issue bezieht. Das Beispiel below zeigt, dass die zwei Kommittemessagen in der Input related und sollten kombiniert werden. Aber es versucht dies zu tun. Schließlich eine Konklusion. Wir haben eine neue DSET für automatische Rezensionsschnittgenerierung erstellt. Wir haben auch die Aufgabe erstellt, Kommentarn zu enthalten und sie so zu summarisieren, dass sie für alle Projekte in Englisch anwendbar ist. Unser Experiment zeigt, dass die vorgeschlagene Methode weniger Noisy Rezensionsschnittgenerierung bei höherer Abdeckung als die Basisrate erzeugt. Bitte schauen Sie sich unsere DSET auf GitHub an. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle. Heute werde ich unsere Forschungsarbeit Lernen zu reisen deduktiv, Methodenproblemlösung als komplexe Rasen-Extraktion vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Zahl stammt aus dem POWN-Papier, in dem sie Anweisungen zur Lösung des Methodenproblems in einem Fluch-Learning-Szenario ausführen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite können wir sehen, dass wir, wenn wir einige Beispiele nur mit Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch noch mehr Beschreibungen geben, kann das Modell die Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, als Ausgabe interpretierbares Mehrstufenrechnungsverfahren zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken auch, dass ein Methodenproblem eine einfache Anwendung zur Bewertung solcher Argumentationsfähigkeiten ist."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier müssen wir also in unserer Problemkonfiguration, angesichts der Fragen, diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser besonderen Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Größen bekannt ist"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren aufgeteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Eine frühere Arbeit im Lösungsproblem der Methode kann also tatsächlich in Sequenz- und Baummodell kategorisiert werden."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenzmodelle konvertieren den Ausdruck also in eine bestimmte Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ziemlich einfach umzusetzen und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil ist, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell und es fehlt an Interpretabilität für die Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Direction noch ziemlich populär, weil der Transformermodell"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also die Operatoren weiter, bis wir die Lifts erreichen, die die Größen sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt, aber es ist eigentlich ganz entgegengesetzt, weil wir zuerst den Operator generieren und dann am Ende die Größen generieren."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens enthält es auch einige wiederholte Berechnungen."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck hier ansehen, wird acht mal drei plus drei tatsächlich zweimal erzeugt. Aber tatsächlich sollten wir die Ergebnisse verwenden"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und in interpretierbaren Methoden lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diesen Teiler erhalten, der 27 ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir bei diesem dritten Schritt tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Okay. Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schritts tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als unser Anfangszustand ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Operatoren von QY bis QJ aus, und dieser Ausdruck ist tatsächlich gerichtet."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "So, wir haben hier auch Subtraction-Wert, um die entgegengesetzte Richtung zu repräsentieren."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie bei der Strahlungsauffnahme."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es in den nächsten Zustand hinzu, um eine neue Menge zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folien visualisieren also tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zuständen immer wieder Ausdrücke hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Sprachmodell, das Vögel oder Robetts sein kann, und dann kodieren wir den Satz und erhalten diese Mengenrepräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengen darstellen, können wir mit der Schlussfolgerung beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q4 multipliziert wird."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Anweisung, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist. Dann wenden wir ein Fit-Forward-Netzwerk an, das vom Operator parametriert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksrepräsentation Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Schlussfolgerung möglicherweise auch den falschen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier entspricht also jeder möglichen Ausdruck dreimal so viel wie die Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchbereich entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir noch eine Menge mehr haben."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe stammt aus dem vorherigen berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir diesen letzten Ausdruck Q3 erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke von dem vorherigen Schritt unterschiedlich ist."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede machen es schwierig, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsmethode ist ähnlich wie bei der Schulung eines Sequenzmodells, bei dem wir den Verlust bei jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch diese Tao, um darzustellen, wann wir diesen Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz anders, weil der Raum bei jedem Zeitpunkt anders ist, während es im traditionellen Sequenz- zu-Sequenz-Modell die Anzahl des Wortschatzes ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht es uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen zu verhängen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen also Experimente mit den häufig verwendeten Method-Problem-Datensätzen durch, MAWPS, Math23K, MathQA und SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Variante ist also Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir BeamSearch nicht, im Gegensatz zu offensichtlichen Ansätzen mit BeamSearch."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Okay, die besten Ansätze sind oft ein Baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Vernunft also dieses Baumbasierungsmodell deutlich übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MatQuery oder SWAM nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse weiter."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist eine Herausforderung, weil der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. irrelevante Informationen und zusätzliche Mengen hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Also, in unserer Vorhersage finden wir, dass einige der intermediären Werte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Pitchs und Stephen hat acht Pitchs, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse als negativ entfernen, damit wir die Antwort richtig machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert und bei dem Roberta-Basemodell tatsächlich zwei Punkte verbessert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat also bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Bert niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information angesehen werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der ungenutzten Mengen haben und der SWAMP-Datensatz den größten Teil enthält."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen ist die Gesamtleistung tatsächlich höher als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlimmer ist als die, äh, viel schlimmer als."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für MAWPS haben wir nicht wirklich viele Desk-Cases, also ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretationsfähigkeit durch ein Beispiel für die Zusammenstoßpartizierung zeigen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also tatsächlich eine falsche Vorhersage im ersten Schritt."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren, oder?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben also, dass dieser Satz das Modell in eine falsche Vorhersage führen könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man hier also noch 35 plant, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu ändern, dass er so aussieht wie die Anzahl der Birnenfäden fünfundfünfzig weniger ist als die Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen es also so, dass es genauere Semantik vermittelt, damit das Modell die Vorhersage richtig machen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell eigentlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können eine interpretierbare Lösungsmethode bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige vorherige Kenntnisse als Konstrakt einbeziehen, was uns helfen kann, die Leistung zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur für Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch für andere Aufgaben, die mehrtretende Argumentation beinhalten."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung in verschiedenen Zeitzonen unbalanciert ist, daher ist es auch ziemlich schwierig, Beam-Suche anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also das Ende des Vortrags und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Maastricht University."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein Johannes Werk mit Jerry vorstellen, das sich mit einem neuen Datensatz für die Abholung von gesetzlichen Artikeln befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein wesentlicher Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat wenig oder kein Wissen über ihre Rechte und grundlegenden Rechtsverfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Ergebnis sind viele vulnerable Bürger, die sich nicht die kostbare Assistance eines Legal Experts erwarten können, unprotegt oder worstens, exploitiert."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Lücke zwischen Menschen und dem Gesetz zu schließen, indem wir ein effektives Rückholsystem für gesetzliche Artikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte für unqualifizierte Menschen einen kostenlosen professionellen Rechtshilfenservice bieten."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem der statutarischen Artikelabholung."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ich eine einfache Frage zu einem rechtlichen Thema stelle, wie zum Beispiel: Was mache ich, wenn ich die professionelle Vertraulichkeit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetz zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe zur Informationserfassung bringt eine ganze Reihe von Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst geht es um zwei Sprachtypen."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "für die Fragen eine gängige natürliche Sprache und für die Statuten eine komplexe rechtliche Sprache."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in den Sprachverteilungen machen es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die mit der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das gesetzliche Recht kein Stapel unabhängiger Artikel, die als vollständige Informationsquelle an sich behandelt werden können, wie zum Beispiel Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Insted ist es eine Strukturkollektion von legalen Provisionen, die nur in der allgemeinen Kontext betrachtet sind, zusammen mit den zusätzlichen Informationen aus den neighbouring Artikeln, den Feldern und Subfeldern, zu denen sie gehören, und ihrer Platz in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, statutory Articles RN small paragraph, was usuell die typische Retrieval Unit in Most Retrieval Works ist."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Jahre dauern können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich NLP haben großes Interesse an vielen rechtlichen Aufgaben wie der Vorhersage von Rechtsentscheidungen oder der automatisierten Überprüfung von Vertragsverträgen weckt."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabholung ist jedoch aufgrund des Mangels an großen und hochwertigen gekennzeichneten Datensätzen größtenteils unberührt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir ein neues französisches, zentrales, zentrales Datenkett, um zu untersuchen, ob ein Rückholmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten für die Aufgabe der Statutorienartikelrückholung nähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Our Belgian Statutory Article Retrieval Data Sets consist von mehr als einem Jahrzehnt Liter."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnraum, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen hat von erfahrenen Juristen mit Referenzen zu relevanten Artikeln aus einem Corpus von mehr als twenty zwei Tausend sechshundert."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Codes of Law. Lassen Sie uns nun über die Erstellung dieser Datsätze sprechen."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir mit der Zusammenstellung eines großen Korpus an rechtlichen Artikeln begonnen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich verfügbare Belgische Codes und alle Artikel sowie die entsprechenden Abschnittshebungen entnommen."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf relevante Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich, auf ihre Websites zuzugreifen, wo ihr Team von erfahrenen Juristen Belgien's am häufigsten rechtlichen Probleme behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen zusammengestellt, mit Kategorien, Subkategorien und rechtlichen Verweisen auf relevante Statuten."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, wir passten die legalen Referenzen und filterten die Fragen aus, die Referenzen nicht Artikel in einem der Codes of Law wirkten."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Verweise wurden in die entsprechenden Artikel-IDs aus O Corpus abgestimmt und umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.108 Fragen, jeder sorgfältig mit den IDs der relevanten Artikel aus dem Buch."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich enthält jede Frage eine Hauptkategorie und eine Konkatenation von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel kommt mit einer Konkatenation ihrer nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzliche Information wird nicht in der Präsentation verwendet, aber sie könnte für zukünftige Research auf Legal Information Retrieval oder Legaltext Classification interessant sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale unserer Datensätze an."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Frage ist zwischen fünf und vierundvierzig Wort lang, mit einem Median von vierzig Wort."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer medianen Länge von sechzig sieben Wörtern, mit 140 Gramm."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei von ihnen, die eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine Vielzahl von Themen, von denen etwa 85 % entweder über Familie, Wohnraum, Geld oder Gerechtigkeit betraf."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Während die restlichen fünfzehn Prozent entweder mit der Sozialversicherung, Ausländern oder Arbeit zu tun haben."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr diverse, da sie aus dreißig zwei verschiedenen Belgischen Codes kommen, die eine große Anzahl von illegalen Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel aus jedem dieser belgischen Codes."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Aus den twenty two thousand six hundred thirty three Artikeln, nur eintausend sechs hundred twelve sind als relevant zu at least einem"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "nur eine Frage in den Daten sätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafverfolgungsgesetz."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen enthalten achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann durch die Tatsache erklärt werden, dass diese Codes weniger auf Einzelpersonen und ihre Anliegen fokussieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünf Prozent von ihnen sind in der"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen benchmarken wir verschiedene Rückholmethoden, einschließlich lexikalischer und denser Architektur."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrageartikelpaar eine Punktzahl zu, indem es die Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfragezeiten berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM-25-Rankingfunktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert und eine relevante Punktzahl zwischen einem Abfrage-Artikelpaar anhand der Ähnlichkeit ihrer Eingebettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit siamesischer Biancoder in einer Nullschussbewertung, was bedeutet, dass vorgebildete Word-Embedding-Modelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, und kontextunabhängigen Einbettungsmodellen, nämlich Roberta und genauer gesagt Camembert, das ein französisches Roberta-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes Camembert-basiertes Modell. Beyond quoters."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beispiele auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Flavors der Bianco architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Query und den Artikel in einem gemeinsamen Densivektorraum mappiert, und Tutor, das zwei unabhängige Word-Embedding-Modelle verwendet, die die Query und den Artikel separat in zwei verschiedene Embedding-Spaces codieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit dem Pooling von Mittel, Max und CLS sowie mit dem Punktprodukt und dem Kosinus für die Rechengelähnungen."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Ausgangslinie auf den Testsätzen."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Dann mit den lexikalischen Methoden oben, den Siamese-B-Encodern, die in einer Null-Schuss-Einrichtung evaluiert wurden, und den fein abgestimmten B-Encodern unten."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchore alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two Tower Modell verbessert sich gegenüber seiner Siamese-Variante auf Recallat one hundred, aber es funktioniert ähnlich bei den anderen Metriken."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five den trainierten Biancode erheblich unterlegen hat, zeigt seine Leistung, dass es immer noch eine starke Grundlage für Domain Specific Retrieval ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Was die Nullschussbewertung des siamesischen Biancoders betrifft, stellen wir fest, dass die direkte Verwendung der Eingebettungen eines vorgebildeten Kamembert-Modells ohne Optimierung für die Informationsabholungsaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir festgestellt, dass der Word-Tuec-basierte Biancoder den Vastex- und Vogelbasierten Modell deutlich übertrifft, was darauf hindeutet, dass möglicherweise vor-train-Word-Level-Embeddings für die Aufgabe besser geeignet sind als Charakter- oder Unterword-Level-Embeddings, wenn sie von vorn verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Möglichkeiten für Verbesserungen im Vergleich zu einem geschickten Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns mit zwei Einschränkungen aller Datensätze abschließen."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf die aus den 32 belgischen Gesetzen gezogenen beschränkt, die nicht das gesamte belgische Gesetz abdecken, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Referenzen zu diesen ungesammelten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl relevanten Artikeln erhalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsloss impliziert, dass die Antwort in den verbleibenden relevanten Artikeln unvollständig sein könnte, obwohl sie immer noch vollständig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Kann ich meine Mieter vertreiben, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Might not have a detaillierte Antwort innerhalb des gesetzlichen Gesetzes, das eine spezifische Noise-Threshold quantifiziert, bei der Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich mehr auf die Rechtsprechung vertrauen und Präzedenzfälle finden, die ähnlich zu ihrer aktuellen Situation sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Tenant zwei Parties pro Woche und tut es."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser als andere für die gesetzliche Artikel-Retrieval-Tasche geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass all diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur Berechnung von gesetzlichen Artikeln weckt,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Papier, Datset und Code unter den folgenden Links sehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorzustellen, einem unabhängigen Benchmark, der für die Testung von Vision- und Sprachmodellen mit bestimmten sprachlichen Phänomenen gedacht ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark festzulegen?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformer-basierten Vision- und Sprachmodellen gesehen, die auf große Mengen an Bild-Textpaaren vorgebildet wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle drängt die Moderne in der Vision und Sprachaufgaben wie der Antwort auf visuelle Fragen, der visuellen Sinnesreasoning, der Bildherstellung und der Phrase-Grundung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Nachricht erhalten. Die Genauigkeit dieser für die Aufgabe spezifischen Benchmarks steigt stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprachtransformer verstanden, als er diesem Bild und diesem Satz eine hohe Punktzahl zugewiesen hat, um es zu vereinbaren?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und der niedrige Punkt für diesen."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie durch frühere Arbeiten gezeigt?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf diesen Aspekt zu werfen, schlagen wir eine tauschfreundlichere Richtung vor und führen VALS ein, das die Empfindlichkeit von Seh- und Sprachmodellen auf spezifische sprachliche Phänomene testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Vielfalt, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenzen ab."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen festgehalten haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor nur für Vision und Sprachmodelle von Ravi Shakar und seinen Mitarbeitern für Nomenphrasen angewendet wurde, und bei der Zählung von uns in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde, dass wir den Bildunterschrift eines Bildes nehmen und einen Foil erzeugen, indem wir den Unterschrift so verändern, dass er das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Wir ändern diese Phrase, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenz, wobei jedes Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, FOIL-Instanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir im Fall des Aktionsstücks zwei Instrumente, eines, bei dem das Aktionsverb mit einer anderen Aktion geändert wird, und eines, bei dem die Spielzeuge ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Ko-Referenzen sind auch Stücke, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schaffen diese Fehler, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererseits gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach, da eine fehlerhafte Beschreibung weniger wahrscheinlich sein kann als die ursprüngliche Beschreibung."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es zwar nicht unmöglich, statistisch gesehen ist es weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann Pflanzen schneiden, und große Vision- und Sprachmodelle könnten dies aufgreifen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um gültige Folien zu erhalten, müssen wir daher Maßnahmen ergreifen."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir starke Sprachmodelle, um FOILs vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir die Inferenz durch natürliche Sprache oder kurz NLI, um Folien zu filtern, die das Bild noch beschreiben könnten, da wir bei der Konstruktion von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir eine Schlussfolgerung aus natürlicher Sprache mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Beschriftung als die damit verbundene Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In addition, wir betrachten die Kaption als die Premise und die FOIL als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell die FOIL als widersprechend oder neutral gegenüber dem Untertitel vorhersagt, nehmen wir dies als Indikator für eine gültige FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Folie durch den Untertitel enthalten ist, kann es keine gute Folie sein, da sie durch Transitivität eine wahrhaftige Beschreibung des Bildes liefert und wir diese Folien ausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Prozedere ist nicht perfekt. Es ist nur ein Indikator für valide Foil."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Erstellung gültiger FOILs menschliche Annotatoren, um die in Valse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir also so viele Testfälle wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um einen Benchmark für Null-Schuss-Tests handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vorausbildung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Die Feinabstimmung würde es den Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nutzen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vorausbildung haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen auf Vowels, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin I und VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bilder-Satzpaaren in Untertitel und FOILs."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht ist für dieses Video relevanter, dass wir unsere permissivere Metrik, die Paargenauigkeit, präsentieren, die misst, ob der Ausrichtungswert des Bildesatzes für das korrekte Textpaar des Bildes höher ist als für das fehlerhafte Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Metriken und Ergebnisse zu diesen Ergebnissen finden Sie in unserer Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit Paar-Präzision sind hier gezeigt und entsprechen den Ergebnissen, die wir aus den anderen Metriken erhalten haben. Die beste Leistung bei Nullschüssen wird von Wilbert zwölf in einem, gefolgt von Wilbert, LXMert, Clip und schließlich VisualBird erreicht."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert Twelve in One fast gelöst werden, wobei er hervorhebt, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann in unseren Adversarial Foiling-Einstellungen keine der verbleibenden Teile zuverlässig gelöst werden"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäten und Zählungsinstrumenten sehen wir, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Aktionen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie durch plausibel Vorurteile unterstützt werden, wie wir im Aktionsteil sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Bereich erfahren wir, dass es für Vision- und Sprachmodelle ebenfalls schwierig ist, mehrere Referenzen auf das gleiche Objekt in einem Bild mit Pronomen zu verfolgen."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Verstandskontrolle und weil es ein interessantes Experiment ist, haben wir auch zwei Textmodelle, GPT eins und GPT zwei, benchmarkt, um zu beurteilen, ob Valse durch diese Einmodalmodelle gelöst werden kann, indem wir die Verwirrung der richtigen und der fehlgeschlagenen Beschriftung berechnen und den Eintrag mit der geringsten Verwirrung vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die FOIL höher ist, nehmen wir dies als Hinweis darauf, dass die FOIL-Beschriftung unter einer plausibilen Voreingenommenheit oder anderen sprachlichen Voreingenommenheiten leidet."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die Text nur GPT Modelle die Plausibilität der Welt besser erfassen haben als die Vision und Language Modelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALS ein Benchmark ist, der die Linse der sprachlichen Konstruktionen nutzt, um der Community bei der Verbesserung von Seh- und Sprachmodellen zu helfen, indem sie ihre visuellen Grundlagefähigkeiten hart testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu begründen, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich ermutigen, VALS zur Messung des Fortschritts hin zur Sprachbasis mit Vision und Sprachmodellen zu verwenden."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, VALS könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von VALS getesteten Aspekte hilft."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, sollten Sie sich die Walls-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde eine Papier entitelt RNSAM, ein Large Scale DSET für automatische Risikogrammierung beim Commitologizieren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikogenerierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNote ist ein technisches Dokument, das die bei jeder Veröffentlichung eines Softwareprodukts zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Restnoten für Bosch 2.6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "User Us Library These Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consuming, um manuell zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, hochwertige Release-Noten automatisch zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Frischknotengenerierung verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste System, das Arena erstellt wurde, wurde 2014 erstellt."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert eine ruralbasierte Approach, zum Beispiel, indem man die Change Extractor verwendet, um Code differenzen, Bibliothekänder und Dokumentenänderungen von den differenzen zwischen Releases zu extrahieren, und schließlich kombinieren sie."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das bemerkenswerteste Merkmal dieses Systems ist der Ausgaben-Extraktor in der oberen rechten Ecke,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dieses muss mit dem Issues-Ökosystem verbunden sein und kann nur auf Projekte mit Null angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist Grief. Dies entweder angesagt in 2014."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "2020. Es ist auf dem Internet verfügbar und kann via PIP gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches Textklassifizierungsmodell basierendes auf Lernen und Ausgaben aus fünf Labors, wie z. B. Funktionen oder Fehlerbehebungen, für jede Eingabe-Kommentarnachricht."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Sample-User, das eine Korrektur für Fehlerkorrekturen erhält."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingdaten sind sehr klein, etwa fünftausend, und werden in den Experimenten beschriebenen unten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Kreuzschaltmodells ist nicht höher."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier löst diese beiden Probleme und erzeugt automatisch hochwertige Freigabe-Noten."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das begrenzte Anwendungsprogramm schlagen wir eine hochwertige Klassifizierungsmethode mit nur Kommentarmeldungen als Eingabe vor."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Repositories verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der Skarbstaatressourcen haben wir eine RNSAM DSET konsistent mit etwa 82.000 Datenpunkten erstellt, indem wir Daten aus öffentlichen GitHub Repositories mit der GitHub API erstellen."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unsere Daseinsetzung."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Nachricht des Komitees und die rechte Seite ist die Release-Note."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Riesen sind als Verbesserungen, Verbesserungen, etc. gelobt."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Kommentarnachrichten als Eingaben aufnimmt und die Raveled-Please-Notizen ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassungsaufgabe angesehen werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Rubber, Funktionen, Verbesserungen, Fehlerbehebungen, Deprekationen, Entfernungen und Bremsänderungen vorgedefiniert."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden aufgrund früherer Forschung und anderer Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Rhythmus-Noten unten rechts werden aus den Rhythmus-Noten unten links abgezogen."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Moment müssen die vier Schuttwerke, die im Voraus aufgestellt wurden, entdeckt werden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Lager sind nicht immer mit jeder Freiheit übereinstimmen"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, um Verbesserungen zu treffen, zu erhöhen, Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabulärliste mit etwa 30 Numbers für jede dieser Rotationsvariationen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Restnotkrasten zu erkennen und den Text der Restnotkrasten zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Komiteemeldung."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachrichten des Komitees sind nicht an jede Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der image below, wenn die aktuelle Realität Boson zwei Punkt fünf zwei neunzehn, müssen wir die IDECHTEN"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "erfüllt die vorherige Version 2.5218 und erhält einen Tiff. Dies ist ein bisschen mühsam und es reicht nicht aus, nur eine Liste der Releases zu erhalten und sich die Vorher und Nachher anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine Heuristik, die mit Ihnen übereinstimmt, um die vorherigen und nächsten Schauspielzeiten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind die Horses."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "In der Hand, siebentausend zwei hundert Repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Token 63, was für eine Zusammenfassungsaufgabe ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Nummer der Unique Tokens ist bei Roger at eight thousand eight hundred thirty thousand."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl von einzigartigen Kasten und Methoden im Repertory."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes erkläre ich die vorgeschlagene Methode."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Querschnitts-, Extraktions- und Abstruktionsmodell besteht aus zwei neuer Modulen"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifier mit Bot oder Code Bot und ein Generator mit Bot."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Klassifizierer, um jede Kommentarnachricht in fünf RESNOT-Klassen zu klassifizieren: Funktionen, Verbesserungen, Fehlerbehebungen, Duplizierungen und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als anderer eingestuften Komitee-Nachrichten werden abgelehnt."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GAS den Generator unabhängig auf die vier Rudder-Dokumente an und erzeugt für jede Klasse Risikonode."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Übereinstimmungen zwischen Commit-Nachrichten und Lesemerkungen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifizierer zu trainieren, weisen wir jeder Eingabe-Commit-Nachricht Pseudorabben zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Kreuzstreifen-Abstruktiv-Summersätze durch zwei verschiedene Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzigen SEC-Netzwerk und generiert einen einzigen Long-SNode-Text, der eine Kombination von Eingabe-Commit-Nachrichten liefert."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgangstext kann in Kreuzzeichen aufgeteilt werden, basierend auf speziellen Kreuz-Spezifischen Endpunkt-Symbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSMarch nennen, besteht aus vier verschiedenen SEC-to-SEC-Netzwerken, von denen jede einer der RES-Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das macht Spain's Experiment."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: CS, CS Single, CS Smart, Russelling und die vorherige Studienbeschreibung."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Abrissung sind in einigen Fällen diese Noten in mehreren Sätzen ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro ist penetrativ, wenn das System einen kurzen Satz ausgibt"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Brauvolumen. In den als nächstes beschriebenen Experimentenergebnissen"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erzeugen wir auch eine Spezifität, da Rouge und Brux nicht erzeugt werden können, wenn die Riesen-Knoten leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass die Modellprojekte ausgegeben sind, die in Fällen, in denen die Reasonals empfangen, empfindlich sind."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Daseit Emailadresse, Hashbarriers, etc. enthält, erweitern wir auch den Quint Daseit, der sie ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat und sie hat Rouge Air-Punkte erreicht, die mehr als zehn Punkte höher waren als die Baselines."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Green Test set, der Square Gap zwischen der proposierten Methode und der Basis jumped zu mehr als 20 Punkten."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie und sie erfolgreich sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS hat eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Crossfire und eines Generators auf das Training des Crossfire-Systems mit Pseudobus effektiv ist."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, weil der Klassifizierer sich auf die relevanten Kommittentests für jeden Kurs konzentrieren kann."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie isst in dieser Zeit viel höher als wenn sie ledig ist."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es auch effektiv ist, für jede dieser Notengrasse unabhängig verschiedene Perspektivsummerisierungsmodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hero und Eronasus"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xia's Methoden neigen dazu, kürzere Sätze als menschliche Referenz-Sätze zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Figur auf der rechten Referenz hat drei oder vier Sätze, während CS nur eins hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzugabe ist, dass in den Trainingsdaten nur 33 % der Sätze im Rabel Merkmale und 40 % im Rabel Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES Methoden ohne zusätzliche Informationen keine genauen Risikobewertungen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommentarmeldung, und die Kommentarfassung kann nicht generiert werden, ohne auf die entsprechende Peru-Request oder -Erstellung hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das untenstehende Beispiel zeigt, dass die beiden Kommentarberichte im Eingaben miteinander verbunden sind und in einen Satz kombiniert werden sollten, aber dies geschieht nicht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Personalgenerierung erstellt,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Kommentarmeldungen einzugeben und sie zusammenzufassen, sodass sie für alle Projekte auf Englisch anwendbar ist."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die Bassrate besser laut macht als die Bassrate."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte schauen Sie sich unsere Dessert-Audit-Tab an."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist ein Safarari,"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unsere Arbeit über die Anreicherung von Tabellen mit Hilfe von fein abgestimmten Transformatoren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Merkmale der Daten."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen begrenzt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Funktionen mit einer anderen Datenquelle kann erhebliche Informationen bieten."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung von Tabelldaten mit externen Quellen-Freitexten."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben eine Tabelldatensammlung und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Funktionen aus dem künstlichen Text der Wissensbasis zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel sehen. In einem Datensatz, der in FEST eingeführt wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist die Datenmenge Universitätsdatenmenge."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten zu unterteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festes ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Einheit, in diesem Beispiel der Name der Universität, mit einer Einheit innerhalb der Wissensbasis verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Knowledge-Basis wird extrahiert und in die Daten setzt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text der Abstrakt der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Funktionen aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen also eine Funktionsaufnahmephase, die Textanalyse beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde mich in den nächsten Folien tiefer damit befassen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Extraktionsphase der Merkmale gibt es eine Generierungsphase der Merkmale, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst generieren Sie Funktionen in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also, erstens zwei neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Funktion stellt die Wahrscheinlichkeit für jede Klasse dar."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, die sich auf Transformer basieren lassen, wie Baird, GPT, XLED und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe zur Feinabstimmung sein."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Funktionsauffnahme können wir also ein Parent-Train-Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell verfeinert, um Text in Klassen zu klassifizieren, abstrakt in Klassen, niedrig oder hoch."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse ist, und verwenden Sie sie als neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datenmengen möglicherweise wenige unterschiedliche Entitätsstapel haben."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Proben, und der kleinste Datensatz enthält fünfunddreißig Proben in seinem Trainings-Satz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorherige Kenntnisse über voranalyseierte Datensätze nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir den nth-Datensatz analysieren."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sugest, ist die Hälfte der Fine Tuning Phase."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Phase der Fine-Tuning-Multitask."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über n minus eins Datensätze finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine weitere Feinabstimmungsphase durch, die eine Feinabstimmung der Zielaufgaben ist, wenn wir das Sprachmodell über den n-Tiel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der neueste Stand der Multitask-Fine-Tuning, der MTDNN genannt wird."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN hält MTDNN eine Anzahl von Aufgaben im Trainingsatz aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainings-Set. Also leere DNN und halte vier Kopfhäupter, wie Sie auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es samplet eine zufällige Charge aus dem Trainingsset."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Run-Batch zu einer, zum Beispiel, Sing und Selton-Klassifizierungsaufgabe gehört, führt er einen Vorwärts- und Rückwärtspass durch den ersten Kopf aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zu einer Paar-Ranking-Tasche gehört, wird sie durch den letzten Kopf weitergegeben und zurückgegeben."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario verifiziert eine Datenmenge-Tabelle die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN hält die Anzahl der Klassen-Heads-Ausgaben-Schichten aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss MTDNN eine neue HEADS für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Task Reformulation Fine Tuning bezeichnet wird, besteht darin, dass wir in unserem Ansatz Task Reformation Fine Tuning statt mehrere Kopfgruppen zu behalten, jeden Datensatz in ein Satz pro Klassifizierungsproblem umformulieren, das zwei Klassen-Aufgaben ist."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also ein Beispiel sehen."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Input-Datensatz, der von Entitäten, Funktionen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zu der Klassifizierung des Textes, des Abstrakts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, wir haben das Sprachmodell so trainiert, dass es abstrakt und in der Klasse klassifiziert, ob die Abstrakt-Klasse in der Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Etikettvektor besteht in diesem Fall also immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren fertigen oder formulierten Feintuning-Ansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also das vollständige Framework betrachten."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und das set fade into fast"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Entity-Linking-Phase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensbasis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird die Aufgabe in eine Satz-Per-Classifikation-Tasche reformuliert."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und die Ausgabenwahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über n-1-Datensatz mit einer vorläufigen Multitask-Fine-Tuning verfeinert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu erstelltes Merkmal in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Rahmenwerk zu bewerten, verwenden wir eine Datenmenge mit siebzehn Tabellen, die Größe, Merkmale, Balance, Bereich und anfängliche Leistung variieren."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unser Experiment als Live-Out-Evaluierung gestaltet, bei der wir schnell über sechzehn Datensätze trainieren und sie auf das siebzehnte Datenset anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datensatz in vier Fehler auf und wenden eine Falten-Cross-Validation an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Funktionen und bewerten sie mit fünf Bewertungs-Klassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-Basis-Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Rahmenwerk mit der Feinabstimmung des Zieldatensatzes, der Feinabstimmung der Zielaufgabe und der vorläufigen Feinabstimmung der MTDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere Formulierung ist ein Feintuning, das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2% gegenüber der Feinabstimmung des Zieldatensatzes erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Poach hat eine Verbesserung um sechs Prozent erzielt."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Daten ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Feinabstimmung bei mehrere Aufgaben auf 1,5 Prozent abnimmt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung hat sich im Vergleich zu der Zielaufgabe, die allein mit der Feinabstimmung verbessert wurde, um elf Prozent zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Zusammenfassung ermöglicht Fast die Bereicherung von Fushot aus 35 Proben in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulationsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satzpaar-Klassifizierungsproblematik verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Assa Farari und ich werde unsere Arbeit FUSHOT Tabellendatenanbau mit fein abgestimmten Transformers-Architekturen vorstellen. Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Datenmerkmale, aber manchmal sind diese Merkmale begrenzt. Die Generierung von Merkmalen mit einer anderen Datenquelle kann erhebliche Informationen hinzufügen. Unser Forschungsziel ist die automatische Tabellendatenanbau mit externen Quellen, freiem Text. Nehmen wir an, wir haben eine Tabellendatenmenge und eine Wissensbasis. Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Merkmale aus dem kostenlosen Text der Wissensbasis zu extrahieren. Unser Framework FEST ist genau dieser automatische Prozess. Lassen Sie uns ein Beispiel betrachten. In einem Datensatz, der in FEST eingeführt wird. In diesem Beispiel ist der Datensatz ein Universitätsdatensatz, wenn sein Ziel es ist, Universitäten in niedrig rankende Universitäten und hochrangige Universitäten. Als Wissensbasis verwenden wir Wikipedia. Die erste Phase von FEST ist die Entitätslinkung, bei der jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität innerhalb der Wissensbasis verknüpft wird und der Text der Entitäten der Wissensbasis extrahiert und zum Datensatz hinzugefügt wird. In diesem Beispiel ist der Text der Wikipedia-Seitenabschnitt. Jetzt müssen wir Features aus dem erhaltenen Text generieren oder extrahieren. Wir benötigen also eine Feature-Extraction-Phase, die Textanalyse beinhaltet. Und das ist die Hauptnota dieser Arbeit, und ich werde mich in den nächsten Folien damit befassen. Nach der Feature-Extraction-Phase gibt es eine Feature-Generation-Phase, in der wir die extrahierten Features verwenden, um eine kleine Anzahl von Features zu generieren. Sie eine kleine Anzahl neuer Merkmale. Erstellen Sie zuerst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes. In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen, also erstellen Sie zuerst zwei neue Merkmale. Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Merkmale. Jede Merkmale repräsentiert die Wahrscheinlichkeit für jede Klasse. Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, nämlich transformierbare Sprachmodelle wie BERT, GPT, XLERT und so weiter. Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können. Daher wäre eine naive Herangehensweise die Feinabstimmung der Zielaufgabe. In der Fase der Extraktion der Funktionen können wir ein pertrainiertes Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset feinabstimmen. In diesem Beispiel können wir das Sprachmodell fe soll Text in Klassen, Abstract in Klassen, Low oder High, in Klassen eingeteilt, die Sprachmodell-Ausgaben erhalten, die für jede Klasse die Wahrscheinlichkeit sind, und als neue Funktionen verwendet werden. Das Problem bei diesem Ansatz ist, dass Daten sätze möglicherweise wenige unterschiedliche Entitäten wie Text enthalten. In unserem Experiment enthalten fast die Hälfte der Daten sätze weniger als 400 Samples und die kleinsten Daten sätze enthalten. Es enthält 35 Proben in seinem Trainings-Set. Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern. Wir können jedoch vorherige Kenntnisse über voranalysierte Datensätze nutzen, da wir FAST über mehrere Datensätze anwenden. Wir können die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir die nth Dataset. Was wir vorschlagen, ist eine weitere Fein-Tuning-Phase, eine preliminäre Multitask-Fein-Tuning-Phase, wenn wir das Languagemodell über n-1 Datasets fein-tunen. Und dann führen wir eine weitere Fein-Tuning-Phase aus, die eine Target-Task-Fein-Tuning ist, wenn wir das Languagemodell über das nth-Target-Dataset fein-tunen. Der Stand der Welt in der Multitask-Fein-Tuning-Phase. Fine-Tuning-Anwendung namens MTDNN. In MTDNN, MTDNN, mainten Sie eine Hälfte der Taschen im Trainingssatz. In diesem Beispiel gibt es vier Taschen im Trainingssatz. MTDNN mainten Sie vier Hälfte, wie Sie sehen können, im Bild. Es sampelt eine Random-Batch aus dem Trainingssatz. Und wenn die Random-Batch zu einem Zum Beispiel Singenselten's Classification-Tasks, es führt Vor- und Rückwärtspfade durch den ersten Kopf aus. Und wenn der Random-Batch zu Paar-Wise-Ranking-Task gehört, führt es Vor- und Rückwärtspfade durch den letzten Kopf aus. In unserem Szenario verringen Tableau-Datensätze die Anzahl der Klassen. Es gibt also viele Aufgaben. MTDNN-Mainten. DNN hält eine Reihe von Klassen-Heads-Ausgaben-Lagen aufrecht und zusätzlich muss MTDNN neue Heads für einen neuen Datensatz mit einer neuen Aufgabe initialisieren. Unser Ansatz, der als Task-Reformulation-Fine-Tuning bezeichnet wird, ist, dass wir in unserem Ansatz Task-Reformulation-Fine-Tuning, anstatt mehrere Heads aufrechtzuerhalten, jedes Datensatz in ein Satz pro Klassifizierungsproblem, das zwei Klassen-Taschen. Also, sehen wir ein Beispiel. Hier ist unser Input-Datensatz, der entweder von Entitäten, Funktionen, Text und Klassen besteht. Und wir reformulieren die Tasche von der Klassifizierung der Text in Low und High, um die Text, den Abstrakt und die Klasse in True oder False zu klassifizieren. Oder in anderen Worten, wir trainieren das Languagemodell, um eine Abstrakt- und Klassenklasse zu klassifizieren, ob die Abstrakt- und Klassenklasse zur Klasse gehören oder nicht. Der Etikettvektor bleibt in diesem Fall immer mit zwei Klassen bestehen. Und das ist der Algorithmus für unsere Find-Orientierung. find reformulated fine-tuning approach. Also, sehen wir uns den vollständigen Framework an. Ein Datensatz wird in FAST eingeführt und dann FAST execute in die Linkingphase. Es extrahiert den Text aus der Knowledge-Basis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist. Dann wird die Task reformuliert in Satz-Per-Classification-Tasks, das Sprachmodell auf die neue Task und die Ausgaben-Likelihood für jede Klasse. Beachten Sie, dass das Language-Modell bereits über n-1-Datensätze mit einer vorläufigen Multitask-Fine-Tuning abgestimmt ist. Dann verwenden wir den Ausgabenvektor des Language-Modells als neu generierten Funktion in der Anzahl der Klassen. Um unser Framework zu evaluieren, verwenden wir eine 17. Wir haben eine siebzehn-Tabellklassifizierungsdatensätze, die die Größe, die Merkmale, den Bereich und die anfängliche Leistung in Einklang bringt. Und als Wissensbasis verwenden wir Wikipedia. Wir haben unser Experiment als eine Live-Out-Evaluierung entworfen, bei der wir schnell über sechzehn Datensätze trainieren und sie auf die siebzehnte Datensätze anwenden. Wir haben auch jede Datensätze in vier Daten aufgeteilt. Wir erstellen Fehler und wenden eine Fork-Fehler-Kreuzvalidierung an. Dann generieren wir die neue Funktion und bewerten sie mit fünf Bewertungs-Klassifikatoren. In unserem Experiment verwenden wir eine auf Bild-Basis basierte Architektur. Hier sind die Ergebnisse unseres Experiments. Sie sehen, dass wir unser Framework mit der Feinabstimmung des Zieldatensatzes vergleichen, der Feinabstimmung der Zielaufgabe. und MTDNN preliminäre Feintuning und unsere reformulierte Feintuning erreichten den besten Ergebnis, die besten Leistungen, während MTDNN 2% Verbesserung über die Target-Datenset-Fine-Tuning erreichte. Unser Produkt erreichte 6% Verbesserung. Wenn wir uns die kleinen Daten ansehen, Aus dem Datensatz können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Fine-Tuning für mehrere Aufgaben auf 1,5 Prozent abnimmt, aber unsere Leistung steigt auf 11 Prozent im Vergleich zur alleinigen Fine-Tuning für die Zielaufgabe. Für die Zusammenfassung ermöglicht FAST die Bereicherung von Flux-Schüssen aus 35 Proben in unserem Experiment. verwendet eine Architektur für alle Aufgaben-Datensätze und behält den Kopf des Modells bei. Aber es fügt eine Formulierungsphase hinzu, es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satz-Par-Klassifizierungsproblematik verwenden können. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen. Heute werde ich unser Forschungswerk Lernen, deduktiv zu denken, Methodenproblemlösung als komplexe Rationsauffnahme vorstellen. Ich bin Alan vom Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD. Zunächst möchte ich über unsere Motivation für das Denken sprechen. Hier zeigen wir Beispiele, in denen mehrträgliches Denken hilfreich ist. Diese Zahl stammt aus der POWN-Artikel, in der sie die Anregung zur Lösung des Methodenproblems in einem Future-Learning-Szenario durchführen. Auf der Netto-Pan-Seite können wir sehen, dass wir, wenn wir einige Beispiele mit nur Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten. Wenn wir jedoch eine weitere Beschreibung geben, kann das Modell die Beschreibung vorhersagen und auch eine korrekte Vorhersage treffen. Es ist also gut, als Ausgabe interpretierbare Mehrstufige Beschreibung zu haben. Wir denken auch, dass das Methodenproblem eine einfache Anwendung ist, um solche Beschreibungsfähigkeiten zu bewerten. Hier in unserer Problemkonfiguration müssen wir diese Frage aufgrund der Fragen lösen und die numerischen Antworten erhalten. In unseren Datensätzen erhalten wir also auch den mathematischen Ausdruck, der auch zu dieser bestimmten Antwort führt. Daher gelten bestimmte Annahmen wie in früheren Arbeiten. Wir gehen davon aus, dass die Präzision von Größen bekannt ist, und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential. Darüber hinaus können komplizierte Operatoren tatsächlich ent in diese grundlegenden Operatoren aufgeteilt werden. Frühere Arbeiten im Lösungsproblem der Methode können also tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baummodell kategorisiert werden. Traditionelle Sequenz-zu-Sequenz-Modelle konvertieren den Ausdruck in eine spezifische Sequenz für die Generierung, und es ist ziemlich einfach zu implementieren, und es kann auf viele verschiedene komplizierte Probleme verallgemeinert werden. Aber die Nachteile sind, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell, und es fehlt an Interpretabilität für die die Vorhersage. Aber eigentlich ist diese Richtung aufgrund des Transformator-Modells immer noch ziemlich beliebt. In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen. Hier generieren wir also die Operatoren, bis wir die Blätter erreichen, die die Größen sind. Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt. Aber eigentlich ist es ziemlich kontraintuitiv. Denn wir generieren zuerst den Operator und dann am Ende die Größen. Und das Zweite ist, dass er auch einige wiederholte Berechnungen enthält. Wenn wir uns also diesen Ausdruck a mal drei plus drei ansehen, wird er tatsächlich zweimal generiert. Aber tatsächlich sollten wir die Ergebnisse wiederverwenden. In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und interpretierbar lösen. Zum Beispiel können wir hier im zweiten Schritt die Daten erhalten., die 27 sind. Und wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden. Und in diesen Schritten erhalten wir die Teiler. Und dann erhalten wir in diesem dritten Schritt tatsächlich den Quotienten. Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse des zweiten Schritts wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten. Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren. Dies macht den Prozess genauer. In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als Anfangszustände ein. Der Ausdruck wird also durch EIJOP dargestellt, bei dem wir Operatoren von Qi bis Qj ausführen, und dieser Ausdruck ist tatsächlich gelenkt. Wir haben hier auch eine Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen. Das ist ziemlich ähnlich wie eine Relationsentfernung. In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diesen neuen Ausdruck. Wir fügen ihn den nächsten Zuständen hinzu, um eine neue Größe zu erhalten. Diese Folien visualisieren tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zustand weiterhin Ausdrücke hinzufügen. In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Netzwerkmodell, das Vögel oder Roberto sein kann, und dann codieren wir den Satz und erhalten diese Mengenrepräsentationen. Sobald wir die Mengenrepräsentationen erhalten, können wir mit der Schlussfolgerung beginnen. Hier zeigen wir ein Beispiel für Q1, um die Repräsentation für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q3 multipliziert wird. Zuerst erhalten wir die Paarrepräsentation, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist, und dann wenden wir ein Fit-Forward-Netzwerk an, das ist. Dies wird durch den Operator parametriert. Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2. Aber in der Praxis könnten wir im Inferenzstadium auch den falschen Ausdruck erhalten. Hier sind alle möglichen Ausdrücke gleich dreimal so viele Operatoren. Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern. Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchraum entfernen. Im zweiten Schritt machen wir also das Gleiche, aber der einzige Unterschied ist eine weitere Größe. Diese Größe stammt also aus dem vorher berechneten Ausdruck. Schließlich können wir diesen endgültigen Ausdruck Q drei mal Q vier erhalten. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke vom vorherigen Schritt unterschiedlich ist. Solche Unterschiede machen es schwierig, ihn anzuwenden. Es ist schwer, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist. Der Trainingsverfahren ist ähnlich wie bei der Schulung eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust bei jedem Zeitschritt optimieren, und hier verwenden wir auch diese Zeichen, um darzustellen, wann wir diesen Generierungsprozess beenden sollten. Und hier ist der Raum von Sequenz zu Sequenz anders, da der Raum bei jedem Zeitschritt unterschiedlich ist, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Wortschatzes ist. Es ermöglicht uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen aufzustellen. Wir führen also Experimente mit den häufig verwendeten Methodenproblemdatensätzen durch, MAWPS, Math twenty three K, MathQA und SWAM. Hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen. Unsere am besten funktionierende Variante ist Roberta Deductive Reasoner. Tatsächlich verwenden wir nicht BeamSearch, im Gegensatz zu den vorherigen Ansätzen mitze sind oft ein Baumbasiertes Modell. Insgesamt kann unser Argumentationsmodell dieses Baumbasierten Modells deutlich übertreffen, aber wir können sehen, dass die absoluten Zahlen bei MathQA oder SWAM nicht wirklich hoch sind. Wir untersuchen die Ergebnisse bei SWAM weiter, und dieser Datensatz ist eine Herausforderung, da der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie zum Beispiel das Hininzufügung von irrelevanten Informationen und zusätzlichen Mengen. In unserer Vorhersage stellen wir fest, dass einige der Zwischenwerte tatsächlich negativ sind. In diesen Fragen fragen wir zum Beispiel, wie viele Äpfel Jake hat, aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Töne und Stephen hat acht Töne, was völlig irrelevant ist. Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt. Und wir beobachten, dass diese beiden Ausdrücke tatsächlich ähnliche Zahlen haben. Wir haben tatsächlich ähnliche Punktzahlen. Wir können also diesen Suchraum einschränken, indem wir diese negativen Ergebnisse entfernen, damit wir die Antwort richtig machen können. Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert. Zum Beispiel verbessern wir für Vögel sieben Punkte und für das Roberta-basierte Modell zwei Punkte. Ein besseres Sprachmodell hat also eine bessere Sprachverständnisfähigkeit, sodass die Zahl hier. Hier ist es höher für Roberta und niedriger für Vögel. Und wir versuchen auch, die Schwierigkeit hinter all diesen Daten zu analysieren. Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Informationen angesehen werden kann. Hier können wir also sehen, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und der SWAMP-Datenmenge den größten Teil hat. Und hier zeigen wir auch die Gesamtleistung für diese Proben ohne ungenutzte Mengen. Die Gesamtleistung ist also tatsächlich höher als die. Und die Leistung ist tatsächlich höher als die Gesamtleistung. Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlechter ist als die Gesamtleistung. Für MAWPS haben wir nicht wirklich viele Datenfälle, also ignoriere ich diesen Teil einfach. Schließlich möchten wir die Interpretbarkeit durch ein Beispiel für das Zusammenbruch zeigen. Hier macht unser Modell also tatsächlich eine falsche Vorhersage im ersten Schritt. Wir können diesen Ausdruck tatsächlich mit dem Satz hier korrelieren. Wir denken, dass dieser Satz das Modell mit einer falschen Vorhersage irreführt. Wenn wir hier also weitere 35 Pflanzen pflanzen, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte. Wir versuchen, den Satz so zu ändern, dass die Anzahl der Birnen 35 weniger als die Apfelbäume ist. Wir machen es also, um genauere Semantik zu vermitteln, sodass das Modell die Vorhersage richtig machen kann. Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Verhalten des Modells zu verstehen. Um unsere Arbeit abzuschließen: Zunächst ist unser Modell ziemlich effizient und wir können interpretierbare Lösungsmethoden bereitstellen, und wir können ein wenig vorheriges Wissen als Einschränkung einbeziehen, was die Leistung verbessern kann. Das letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch auf andere Aufgaben, die mehrträgliches Denken beinhalten. Wir haben aber auch bestimmte Einschränkungen. Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein. Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung bei verschiedenen Zeitstufen unbalanciert ist, daher ist es auch ziemlich schwierig, eine Beam-Suche-Strategie anzuwenden. Das ist also das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich bin von der Maastricht University. Ich werde meine gemeinsame Arbeit mit Jerry vorstellen, die sich mit einer neuen Datensammlung für die Erfassung von gesetzlichen Artikeln befasst. Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen, aber die Mehrheit der Bürger hat wenig bis kein Knowledge über ihre Rechte und grundlegenden Rechtsprozesse. Daher werden viele gefährdeten Bürger, die sich die kostspielige Unterstützung eines Rechtsexperten nicht leisten können, ungeschützt oder schlimmer gesagt, ausgenutzt. Unsere Arbeit zielt darauf ab, die Grenze zwischen Menschen und dem Gesetz zu schließen, indem er ein effektives Retrievalsystem für Statutartikel entwickelt. Ein solches System könnte eine freie professionelle Rechtshilfegemeinschaft für unqualifizierte Menschen bieten. Bevor wir uns auf den Hauptbegriff dieser Arbeit konzentrieren, sollten wir uns zunächst mit dem Problem der Statutartikelretrieval befassen. Bei einer einfachen Frage auf einem Rechtsmaterial, wie zum Beispiel was ich riskieren kann, wenn ich professionelle Privatsphäre verletze, ist ein Modell erforderlich, um alle relevanten Statutartikel aus einem großen Bereich der der Gesetzgebung. Diese Information Retrieval Task kommt mit seiner eigenen Setz von Challenges. Erstens geht es mit zwei Arten von Linguage, der normalen natürlichen Sprache für die Fragen und der komplexen legalen Sprache für die Statuten zu tun. Diese Differenz in Languageverteilungen macht es für ein System schwieriger, relevante Kandidaten zu retrieveren, da es indirekt eine inhärente Interpretationssysteme erfordert, die eine natürliche Frage zu einer rechtlichen Frage, die die Terminologie der Statuten entspricht, translatiert. Besides, statutory Law ist nicht ein Stack von Independent Artikeln, die als eine vollständige Source von Informationen auf der Own behandelt werden können, wie neue Rezepte, zum Beispiel. Instead, es ist eine Struktur, eine Sammlung von legalen Provisionen, die eine ganze Bedeutung nur in der allgemeinen Kontext haben, das ist zusammen mit der supplementären Information aus den neighbouring Artikeln, den Feldern und Subfields, die sie belong zu, und ihrer Platz in der Struktur der Laub. Lastly, statutory Artikel sind ein kleiner Paragraph. was in den meisten Retrievalwerken die typische Retrieval-Einheit ist. Hier sind es lange Dokumente, die bis zu sechstausend Wörter schreiben können. Die recenten Entwicklungen in NLP haben enorme Interesse in vielen Rechtsakten wie Legal Judgment Prediction oder automatisierten Kontaktkontraktreview gespielt, aber die Statutory Article Retrieval hat sich aufgrund der Lack von groß und hochwertigen Labeldatensätzen in der Lage geblieben. In dieser Arbeit präsentieren wir eine neue French Native Citizen Centric Datenset zu studieren, ob ein Retrievalmodell die Effizienz und Reliabilität eines Legal Experts für die Task der Statutory Article Retrieval angeht. Unser Belgisch Statutory Article Retrieval Datsatsatz besteht aus mehr als 1.100 legalen Fragen, die von Belgischen Bürgern gestellt werden. Diese Fragen umfassen eine wide Reihe von Themen von Familie, Housing, Money, bis hin zu Work und Sozialversicherung. Each of them ist von erfahrenen Juristen mit Referenzen zu relevanten Artikel aus einem Corpus von mehr als 22.600 legal Artikeln aus Belgischen Codes of Law. Lassen Sie uns nun über die Art und Weise sprechen, wie wir diese Daten setzen. Erst, wir starten mit der Compilierung eines Large Corpus von legal Artikeln. Wir betrachteten 32 öffentlich verfügbare Belgischen Codes und extrahierten alle Artikel sowie die correspondenden Section Headings. Dann gingen wir mit Referenzen zu relevanten Statuten zusammen. To tun so, wir partnerten mit der Belgischen Law Firma. jedes Jahr um viertausend Emails von Belgischen Bürgern, die um Rat und persönliche Rechtsfragen bitten. Wir hatten die Glück, Zugang zu ihren Websites zu bekommen, wo ihr Team erfahrener Juristen belgische am häufigsten rechtlichen Fragen behandelt. Wir sammelten Tausende von Fragen, die mit Kategorien, Subkategorien und Rechtsreferenzen zu relevanten Statuten angepasst wurden. Lastlich durchgingen wir die Rechtsreferenzen und filterten die Fragen, die nicht Artikel in einem der Codes of Law we considered. Die remaining Referenzen wurden matched und zu den corresponding Artikel IDs von O Corpus. Wir eventuell endeten mit einem Jahrhundert und acht Fragen, die sich sorgfältig mit den IDs der relevanten Artikel aus unserem Large Corpus von twenty two thousand six hundred thirty three Statutory Articles labelten. In addition, jeder Frage kommt mit einer Mainkategorie und einer Konkatenation von Subkategorien. Jeder Artikel enthält eine Konkatenation der nachfolgenden Überschriften in der Struktur des Gesetzes. Diese zusätzlichen Informationen werden in der aktuellen Arbeit nicht verwendet, aber könnten für zukünftige Forschungen zur Rechtsinformationserfassung oder zur Klassifizierung von Rechtstexten interessant sein. Schauen wir uns einige Merkmale unserer Datensätze an. Die Frage ist zwischen fünf und vierundvierzig Wörter lang mit einem Median von vierzig Wörtern. Die Artikel sind viel länger mit einem Median von siebzig sieben Wörtern, wobei einhundertvierundvierzig davon mehr als tausend Wörter betragen. Die Länge eines von fünftausend siebenhundert und neunzig Wörtern. Wie bereits erwähnt, umfassen die Frage eine breite Palette von Themen, wobei etwa achtzig Prozent davon entweder Familie, Wohnung, Geld oder Justiz betreffen, während die restlichen fünfzehn Prozent entweder Sozialversicherung, Ausländer oder Arbeit betreffen. Die Artikel sind auch sehr vielfältig, da sie aus dreißig zwei verschiedenen belgischen Gesetzen stammen, die eine große Anzahl von illegalen Themen abdecken. Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Gesetze gesammelt wurden. Von den 22.633 Artikeln werden nur 1.612 als relevant für mindestens eine Frage in den Datensätzen angegeben, und etwa 80 % dieser zitierten Artikel stammen entweder aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafgesetz. Inzwischen werden 18 von 32 Gesetzen weniger als fünf Artikel als relevant für mindestens eine Frage angege, die durch die Tatsache verursacht wird, dass diese Code weniger auf individuelle und ihre Anliegen fokussiert. Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünfundzwanzig Prozent von ihnen sind mehr als fünfmal citiert. Mit unseren Data sets benchmarken wir verschiedene Retrievalapproaches, einschließlich Lexical und Densarchitektur. Given eine query in einem Artikel, eine Lexicalmodelle assigniert eine Score zu den queryartikelpaaren. Durch die Berechnung der Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfrage-Terme. Wir experimentieren mit den Standard-TFIDF- und BM25-Rankingsfunktionen. Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten. Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die die semantische Beziehung zwischen Abfragen und Artikeln erfassen kann. Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert. und berechnen einen relevanten Punkt zwischen einem Artikelpaar der Abfrage anhand der Ähnlichkeit ihrer Eingebettungen. Diese Eingebettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Eingebettungsmodells. Zunächst untersuchen wir die Effektivität siamesischer B-Encoder in einer Zero-Shot-Evaluierungs-Einrichtung, was bedeutet, dass vorgebildete Word-Eingebettungsmodelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden. Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und Fastastex und kontextabhängige Embeddingmodelle, nämlich Roberta und speziell Kamembert, ein französisches Roberta-Modell. Darüber hinaus trainieren wir unsere eigenen Kamembert basierenden Biencoders auf allen Datenmengen. Beachten Sie, dass wir für das Training mit den beiden Arten der Biencoder Architektur experimentieren. Siamese, das ein einzigartiges Wort-Embeddingmodell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraum mappiert. Und Tutor, das zwei unabhängige Wort-Embeddingmodelle verwendet. Wir haben zwei Independent Word Embedding Models, die den Query und Artikel separat in verschiedene Embeddingsphasen codieren. Wir experimentieren mit Mean, Max und CLS Pooling sowie Dot Product und Cosine für die Computing-Similaritäten. Hier sind die Ergebnisse unserer Baseline auf dem Testset, mit den Lexikonmethoden oben, den Siamese BE Encoders evaluiert in einem Zero Shot Setup in der Mitte, und den Fein Tun BE Encoders unten. Overall, die Fein Tun BE Encoders übertragen alle anderen Baselines. seine Siamese-Variante auf RECOLAT 100, aber ähnlich auf den anderen Metriken abschneidet. Obwohl BM 25 den trainierten Biancoder erheblich unterlegen hat, deutet seine Leistung darauf hin, dass es immer noch eine starke Grundlage für Domain-spezifische Rückholung ist. Bei der Zero Shot Evaluation des Siamese Biancoders finden wir, dass die direkte Verwendung der Embeddings eines vortrainierten Kamembert-Modells ohne Optimierung für die Informationsaufnahmeaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt. Der Word-to-Vec-basierte Biancoder übertraf die Fastex- und Vogelbasierten Modelle deutlich, was darauf hindeutet, dass möglicherweise vor-train-Word-Einbettungen für die Aufgabe angemessener sind als Charakter- oder Unterword-Einbettungen, wenn sie von Anfang an verwendet werden. Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Verbesserungsmöglichkeiten im Vergleich zu einem geschickten Experten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann. Lassen Sie uns mit zwei Limitationen von allen Datensätzen beginnen. Erstens ist der Corpus von Artikeln limitiert zu denen, die aus den dreißig zwei betrachteten Belgischen Codes erfasst werden, was nicht den gesamten Belgischen Law abdeckt, da Artikel aus Dekrees, Direktives und Ordinanzen enthalten sind. Durch die Datensatzkonstruktion werden alle Referenzen zu diesen unkollektierten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Fragment der initialen Anzahl relevanter Artikeln enthalten. Dieser Informationlaus impliquiert, dass die Antwort in den remaining relevanten Artikelnkel könnten incomplete sein, obwohl es immer noch vollständig appropriate ist. Second, wir sollten merken, dass nicht alle Rechtsfragen mit Statuten alone beantwortet werden können. For instance, die Frage kann ich meine Tenants evicten, wenn sie zu viel Noise machen, könnte nicht eine detaillierte Antwort in statutory Law enthalten, die eine spezifische Noise Threshold at which Eviction ist. Insted sollten die Landlage wahrscheinlich mehr auf Fallslaw und Präceden ähnlich wie der aktuelle Situation finden. Zwei Parteien pro Woche bis 2 Uhr morgens. Daher sind einige Fragen besser als andere für die Aufgabe der gesetzlichen Artikelerfassung geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen. Wir hoffen, dass unsere Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle der gesetzlichen Artikelerfassung weckt, die den Zugang zur Justiz für alle verbessern können. Sie können sich unsere Arbeit Datensätze und Code unter den folgenden Links ansehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir sind froh, unsere Arbeit auf VALS, einem Taskindependenten Benchmark für das Testen von Vision und Language Models mit spezifischen linguistiken Phänomenen zu präsentieren. Warum haben wir uns die Trouble in der Setzung dieses Benchmarks gemacht? Nun, während der letzten Jahre haben wir eine explosion von Transformer basierten Vision und Language Models, die auf große Mengen von Image Textpaaren geprägt sind. Each dieser Modelle pusht State of the Art auf Vision und Language Tasks, wie z. B. visuelle Fragen Sinnesrechnung, Bildretrieval, Phrase-Grundung. Wir haben also eine Nachricht, die Akuragen auf diesen spezifischen Benchmarks steigern, aber wissen wir, was die Modelle tatsächlich gelernt haben? Was hat ein Vision und Language Transformer verstanden, als er eine High Score für dieses Bild und diesen Satz zugewiesen hat und eine Low Score für dieses Bild? Fokusieren Vision und Language Models auf das Richtige oder konzentrieren sie sich auf Biasen? wie gezeigt durch vorherige Arbeit. Um mehr Licht auf diesen Aspekt zu senden, propellieren wir eine mehr task agnostic direction und einführen WALS, das die Sensitivität von Vision und Language Models zu spezifischen linguistiken Phenomenen, die sowohl die linguistic als auch die visuelle Modalitäten beeinflussen. Wir targen Existenz, Pluralität, Zählung, Spatialrelationen, Aktionen und Entity Coreference. Aber wie testen wir, ob die Vision und Language Models diese Phenomena erfasst haben? Foiling, eine Methode, die vorher für Vision und Language Models, nur für Nanphrasen von Ravi Shakar und Kollaborators und auf Counting von Asin previous worked. Foiling basically means, dass wir den Caption of an Image und einen Foil produzieren, indem wir den Caption so verändern, dass er nicht die Image anymore beschreibt. Und wir machen diese Phrasealterations, indem wir uns auf sechs spezifische Pieces wie Existenz, Pluralität, Counting, Spatialrelations, Actions, und Entity Coreference. Jede Piece kann aus einem oder mehreren Instrumenten bestehen, in dem Fall, dass wir mehr als eine interessante Möglichkeit gefunden haben, FOIL instanzen zu erstellen. Zum Beispiel haben wir in der Fall der Aktionspiece zwei Instrumente, einen in dem das Action verb mit einer anderen Action geändert wird und einen in dem Actants gewechselt werden. Zählen und Coreferenz sind auch Pieces, die mehr als eine Instrumenten haben. Und wir erstellen diese FOILs, indem wir unserstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererweit validierten Sätze sind. Dies ist nicht einfach zu tun, weil eine Foiled Caption weniger wahrscheinlich ist als die ursprüngliche Caption. Zum Beispiel, though it's not impossible, ist es statistisch weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann, und Largevision und Language Models könnten dies erkennen. Daher müssen wir, um valid Foils zu erhalten, Action unternehmen. Erstens, wir machen uns auf Strong Language Models zu propellieren. Zweitens, wir verwenden Natural Language Inference oder NLI, um Foils zu filtern, die noch beschreibiben das Bild immer noch, da wir bei der Konstruktion von FOILs sicherstellen müssen, dass sie das Bild nicht beschreiben. Um dies automatisch zu testen, wenden wir eine natürliche Sprachinferenz mit der folgenden Begründung an. Wir betrachten ein Bild als die Premise und seine Beschriftung als die damit verbundene Hypothese. Darüber hinaus betrachten wir die Beschriftung als die Premise und die FOIL als ihre Hypothese. Wenn ein NLI-Modell die FOIL zu widersprechen oder neutral zu den Beschriftungen zu sein, nehmen wir dies als Indikator für eine gültige FOIL. Wenn wir die Foil zu beentalten, kann es nicht eine gute Foil sein, da es durch Transitivität eine truthliche Beschreibung der Image geben wird und wir diese Foils ausfiltern. Aber dieser Prozess ist nicht perfekt. Es ist nur ein Indikator für valide Foils, daher als eine dritte Möglichkeit für die generierung von valid Foils, wir verwenden Humananannotators, um die Daten zu validieren, die in Valse verwendet werden. Also, nach Filtering und Human Evaluation, wir haben so viele Testinstanzen wie in dieser Tabelle. Note, dass Valse nicht trainierend Daten liefert. Aber nur Testdaten, da es sich nur um einen Benchmark für Null-Shot-Tests handelt. Es ist darauf ausgelegt, die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vor-Training-Aktivität zu nutzen. Die Feinabstimmung würde es Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen. Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen einschlagen. Und wie wir sagten, sind wir daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vor-Training-Aktivität haben. Wir experimentieren mit fünf Vision- und Sprachmodellen auf WALS, nämlich mit CLIP, Wilbert, Wilbert Kelvin I und Visual Bert. Zwei unserer wichtigsten Evaluierungsmetriken sind die Accuracy der Modelle in der Klassifizierung von Image Sentenzenpaaren in Untertitel und Foils. Perhaps für dieses Video mehr relevant, wir werden unsere permissive Metrik, die Paarwise Accuracy, die messen, ob die Image Sentenz alignment score für die korrekte Image Textpaar als für ihre Foilpaar ist. Für mehr Metriken und Ergebnisse auf themen, doch checken Sie unsere Papier. Die Ergebnisse mit Paarwise Accuracy sind hier und sie sind konsistent mit den Ergebnissen, die wir von den anderen Metriken bekommen haben. Es ist, dass die besten Zero Shot Performance durch Wilbert zwölf in one, gefolgt von Wilbert, Alex Mert, Clip, und schließlich Visual Bird. Es ist notabel, wie Instrumente centered on individuelle Objekte wie Existenz und Nounphrases fast solviert werden, wobei Wilbert zwölf in one, highlighting, dass Models ableistisch genannte Objekte und ihre Präsenz in Images identifizieren können. Allerdings können none der remaining Pieces in unseren adversarialen Foiling-Settings reliably solviert werden. Instrumenten, dass Vision und Language Models Trouble distinguisieren, referenzieren zu single versus multiple Objekten oder in einem Image. Die Relation Piece zeigt, dass sie Schwierigkeiten haben, eine named spatiale Relation zwischen Objekten in einem Image zu klassifizieren. Sie haben auch Trouble, Aktionen zu distinguieren und ihre Partizipanten zu identifizieren, selbst wenn sie durch Plausibility bias sind, wie wir in der Aktionspiece sehen. Aus der Referenzpiece finden wir, dass das Tracing multiple Referenzen zu dem gleichen Objekt in einem Image durch Pronouns auch für Vision und Language Models. Als eine Sanity Check und weil es ein interessantes Experiment ist, benchmarken wir auch zwei Textonlegermodelle GPT one und GPT two, um zu assessieren, ob Valse solvable durch diese Unimodalmodelle ist, indem wir die Perplexität der korrekt und der foiled Caption, keine Image hier, und die Entry mit der lowest Perplexität. Wenn die Perplexität höher für die Foil ist, dann nehmen wir dies als eine Indikation, dass die foiled Caption möglicherweise von Plausibility bias oder anderen linguistiken Biasen leidet. Und es ist interessant zu sehen, dass in einigen Fällen Die Textmodelle nur GPT haben die Plausibilität der Welt besser erfasst als die Vision und Language Models. Zusammenfassend ist VALSE ein Benchmark, das die Lensen von Linguistikkonstrukten verwendet, um die Community zu helfen, Vision und Language Models zu verbessern, indem sie ihre visuellen Grounding-Fähigkeiten hart testen. Unsere Experimente zeigen, dass Vision und Language Models namensgelegene Objekte in ihrer Präsenz in Bildern gut identifizieren, wie gezeigt durch das Existenzstück, aber es schwerwiegt, ihre Interdependence und Relationships in visuellen Szenen zu genehmigen, wenn sie gezwungen sind, linguistic Indikatoren zu respektieren. Wir möchten die Community wirklich ermutigen, Valse zur Messung des Fortschritts hin zur Sprachbasis mit Vision- und Sprachmodellen zu verwenden. Und noch mehr, Valse könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von Valse getesteten Aspekte hilft. Wenn Sie interessiert sind, sollten Sie sich die Valse-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamisara von der University of Tokio. Ich werde eine Papier entitelt RNSAM, ein großes Dasein für automatische Restnoturation bei der Commit Dog Summization. Ich werde in dieser Ordnung erklären. Erst, ich werde die automatische Restnoturation, die wir in dieser Research arbeiten, einführen. ReleaseNode ist ein technischer Dokument, das die Changes mit jedem Release von einem Softwareprodukt zusammenfasst. Das Image zeigt die ReleaseNode für Version zwei. sechs. vier der GBUJS Library. Diese Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consumierend zu erstellen. Daher wird es sehr nützlich sein, automatisch hochqualitäre Release Nodes zu generieren. Ich werde auf zwei frühere Researchers auf automatische Release Node Generation eingehen. Der erste ist ein System namens Arena, das in twenty fourteen erstellt wurde. Es ergreift eine Rule basierende Approach, zum Beispiel, indem es die Change Extractor verwendet, um Code differenzen zu extrahieren. Bibliotheksänderungen und Dokumentenänderungen von den differenzierten Releases und schließlich kombinieren. Die meisten erkennbaren Funktionen dieses Systems sind die Issue Extractor in der oberen rechten Ecke, die mit Jira, dem Issue Toco System, verknüpft und nur für Projekte verwendet werden kann. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden. Die zweite ist Griff, die Entry angeboten wurde in twenty twenty. Sie ist auf dem Internet und kann durch PIPSTEMENSSER Dieses System hat ein einfaches Lernbasis für Textklassifikation und erhält eine von fünf Rabellen, die Funktionen oder Bugfixen für jedes Input Commit-Message enthalten. Das Bild ist eine Sample-Usage, die eine korrekte oder Bugfixen-Rabelle enthält. Die gerade erstellten Rabellen sind ziemlich klein, etwa fünftausend, und werden in den Experimenten beschriebenen darüber gezeigt. Die Leistung des Textklassifikationsmodells ist nicht hoch. Ich präsentiere zwei related Researchers, aber es gibt Probleme mit begrenztem Erwerb und geringen Daten. und Scar State Resources. Unser Papier löst diese beiden Probleme und automatisch generiert High Quality Releasing Notes. Für das limitierte Applicability Programm, wir propagieren eine High Quality Classifier Summarization Methode, die nur Committee Message als Input verwendet. Diese Methode kann für alle English Repositories verwendet werden. Für das zweite Problem der Scar State Resources, wir bauen RL und SAM DSET konsistent mit etwa achtzig zwei Tausend Pieces von Daten, die von öffentlichen GitHub API. Next, ich beschreibe unser Desert. Hier ist ein Beispiel für Daten. Die linke Seite ist ein Commit Message und die rechte Seite ist die RISE Nodes. Die RISE Nodes sind Raveled als Implement, Bug fixes, etc. Wir haben eine Task setup, die die Commit Messages als Input und die Raveled RISE Nodes aufwendet. Dies kann als eine Summarization Task bezeichnet werden. Wir haben vier Raveled Features, Implement, Bug fixes, Duplications, Removables und Breaking Changes. Diese wurden basierend auf PBR research und anderen Faktoren. Die RISE Noten auf der bottom right und extrahiert von den RISE Noten auf der bottom left. At diesem Zeitpunkt ist es notwendig, die vier Rabels zu detektieren, die in der Passage sind, aber die Rabels sind nicht immer konsistent mit jeder Repository. Zum Beispiel, die Improvements Rabels inklusive Improvements, Enhancements, Optimisations und so weiter. Wir haben eine Vokabularliste oder Studie Rabels für jeden dieser Notation. variations. Verwenden Sie es, um die Restknoten zu erkennen und den Text der Restknoten zu korrigieren. Als nächstes kommt eine Kommittemessage. Kommittemessagen sind nicht zu jeder Rest. Wie in der image below, wenn die aktuelle Rest Persönlich 2.5219 ist, müssen wir die vorherige Rest Persönlich 2.5218 identifizieren und einen Tiff erhalten. Dies ist ein bisschen tedious und es ist nicht genug, nur eine Rest der Restknoten zu erhalten. Und wir haben die Vorhand nach. Wir haben eine heuristic Matching Blue erstellt, um die vorherigen und nächsten Persönlichkeiten zu erhalten. Dasset Analysis In der End, 7.200 Repositories und 82.000 PSO wurden korrektiv. Außerdem ist die average Anzahl von ReleaseNode Tokens 63, was für eine Summarisation Task ziemlich hoch ist. Außerdem ist die Anzahl von Unique Tokens ziemlich groß, also 8.830.000. Dies ist auf die große Anzahl von Unique Kosten und Methoden zurück namens in der Repository. Next, ich werde explain die proposierte Methode. Das Crosswise Extractive and Abstractive Summarization Model besteht aus zwei neuronalen Modules, einem Classifier, der Bot oder Code Bot und einem Generator, der Bot verwendet. Erstens, GAS verwendet einen Classifier, um jedes Committee Message in fünf Risnode Classes, Features, Improvements, Bugfixes, Duplications, Plus, und andere. Die Committee Messages klassifiziert als andere oder diskutiert. Dann GAS wendet einen Generator zu den vier Rabelschnitteln unabhängig und generiert RISE NOTE für jeden Kurs. In diesem Zusammenhang sind die direkten Korrespondenzen zwischen Commit Messages und RISE NOTE nicht bekannt. Daher, um den Kurs zu trainieren, wir zwar Rabelschnitteln zu jedem Input Commit Message verwenden, indem wir die ersten zehn Charaktere für jedes Commit Message verwenden. Wir modellieren den Kurs abstruktiven Summarisierungsansatz durch zwei verschiedene Methoden. Das erste Modell, das wir als GAS Single Sync konsist von einer Sync zwei Sync Network und generiert eine Sync Long RISE Node Tagist, geben eine Konkurrenz von Input Committee Messages. Die Output Tagist kann in Crosswise Segment basierend auf speziellen Cross Specific Endpoint Symbols unterteilt werden. Die zweite Methode, Methode, die wir CSMUCH, besteht aus vier verschiedenen Sync zwei Sync Networks, jeder von denen zu einer der RISE Node Classes entspricht. Okay, lassen Sie mich das Experiment erklären. Fünf Methoden wurden GS, GS Single, GS Marge, Russelling und previous studied Griff. Regarding Abortion, in einigen Fällen, diese Noten sind in multiple Sentenzen. Da es difficil ist, die Nummer von Sentenzen zu erkennen, sind sie kombiniert mit Spaces und treaten als ein langer Satz. Der Blue ist penalisiert, wenn das System einen kurzen Satz erfährt. Diese Penalty resultiert in einem loweren Blue Value in den Experimenten der Results describiert. Finally, wir auch die Spezifität erkennen, weil Rouge und Brew nicht erkennen können, wenn die Rouge Nodes leer sind. Eine hohe Spezifität bedeutet, dass die Modellkorrektie auspackt ist, in denen die Rouge Nodes leer sind. Hier sind die Ergebnisse. Da der Daseit Emailadresse, Hashbarrieren, etc. enthält, haben wir auch den Green Daseit erkannt, der sie ausschließt. GAS und GAS erreichten Rouge Error Scores mehr als zehn Punkte höher als die Baselines. Auf dem grünen Testset stieg die Score-Gap zwischen der vorgeschlagenen Methode und der Basis auf mehr als zwanzig Punkte. Diese Ergebnisse zeigen, dass GAS und GAS signifikant effektiv sind. GAS erreichte eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Klassifierers und eines Generators effektiv ist und das Training des Klassifierers mit Pseudoberseiten. Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, da der Klassifier sich auf das Sekten relevanter Kommittemechanismen für jede Klasse konzentrieren kann. Xia ist viel zu höheren Ruder als Xia single, suggesting, dass es auch effektiv ist, unterschiedliche perspektive Summarisationsmodelle für jedes Nodecraft zu entwickeln. Hier sind Erronnas. Xia's Methods tend to output shorter Sentenzen als humanen Referenz Sentenzen. In der Figur auf der rechten Referenz Sentenzen hat drei oder vier Sentenzen, während Xia nur eins hat. Der Grund für diese Modellrücktanz ist, dass in den Trainingdaten nur 33 Prozent der Sentenzen sind in der Features Rabel und 40 Prozent in der Improvements Rabel. Für die More CS Methods können nicht akurat mit Noten ohne zusätzliche Informationen generiert werden. Das Top Exempel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommittemessage und die Komplettesentence kann nicht generiert werden, ohne dass es sich auf die correspondente Periodrequest oder Issue bezieht. Das Beispiel below zeigt, dass die zwei Kommittemessagen in der Input related und sollten kombiniert werden. Aber es versucht dies zu tun. Schließlich eine Konklusion. Wir haben eine neue DSET für automatische Rezensionsschnittgenerierung erstellt. Wir haben auch die Aufgabe erstellt, Kommentarn zu enthalten und sie so zu summarisieren, dass sie für alle Projekte in Englisch anwendbar ist. Unser Experiment zeigt, dass die vorgeschlagene Methode weniger Noisy Rezensionsschnittgenerierung bei höherer Abdeckung als die Basisrate erzeugt. Bitte schauen Sie sich unsere DSET auf GitHub an. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle. Heute werde ich unsere Forschungsarbeit Lernen zu reisen deduktiv, Methodenproblemlösung als komplexe Rasen-Extraktion vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Zahl stammt aus dem POWN-Papier, in dem sie Anweisungen zur Lösung des Methodenproblems in einem Fluch-Learning-Szenario ausführen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite können wir sehen, dass wir, wenn wir einige Beispiele nur mit Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch noch mehr Beschreibungen geben, kann das Modell die Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, als Ausgabe interpretierbares Mehrstufenrechnungsverfahren zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken auch, dass ein Methodenproblem eine einfache Anwendung zur Bewertung solcher Argumentationsfähigkeiten ist."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier müssen wir also in unserer Problemkonfiguration, angesichts der Fragen, diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser besonderen Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Größen bekannt ist"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren aufgeteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Eine frühere Arbeit im Lösungsproblem der Methode kann also tatsächlich in Sequenz- und Baummodell kategorisiert werden."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenzmodelle konvertieren den Ausdruck also in eine bestimmte Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ziemlich einfach umzusetzen und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil ist, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell und es fehlt an Interpretabilität für die Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Direction noch ziemlich populär, weil der Transformermodell"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also die Operatoren weiter, bis wir die Lifts erreichen, die die Größen sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt, aber es ist eigentlich ganz entgegengesetzt, weil wir zuerst den Operator generieren und dann am Ende die Größen generieren."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens enthält es auch einige wiederholte Berechnungen."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck hier ansehen, wird acht mal drei plus drei tatsächlich zweimal erzeugt. Aber tatsächlich sollten wir die Ergebnisse verwenden"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und in interpretierbaren Methoden lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diesen Teiler erhalten, der 27 ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir bei diesem dritten Schritt tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Okay. Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schritts tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als unser Anfangszustand ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Operatoren von QY bis QJ aus, und dieser Ausdruck ist tatsächlich gerichtet."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "So, wir haben hier auch Subtraction-Wert, um die entgegengesetzte Richtung zu repräsentieren."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie bei der Strahlungsauffnahme."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es in den nächsten Zustand hinzu, um eine neue Menge zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folien visualisieren also tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zuständen immer wieder Ausdrücke hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Sprachmodell, das Vögel oder Robetts sein kann, und dann kodieren wir den Satz und erhalten diese Mengenrepräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengen darstellen, können wir mit der Schlussfolgerung beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q4 multipliziert wird."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Anweisung, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist. Dann wenden wir ein Fit-Forward-Netzwerk an, das vom Operator parametriert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksrepräsentation Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Schlussfolgerung möglicherweise auch den falschen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier entspricht also jeder möglichen Ausdruck dreimal so viel wie die Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchbereich entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir noch eine Menge mehr haben."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe stammt aus dem vorherigen berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir diesen letzten Ausdruck Q3 erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke von dem vorherigen Schritt unterschiedlich ist."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede machen es schwierig, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsmethode ist ähnlich wie bei der Schulung eines Sequenzmodells, bei dem wir den Verlust bei jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch diese Tao, um darzustellen, wann wir diesen Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz anders, weil der Raum bei jedem Zeitpunkt anders ist, während es im traditionellen Sequenz- zu-Sequenz-Modell die Anzahl des Wortschatzes ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht es uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen zu verhängen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen also Experimente mit den häufig verwendeten Method-Problem-Datensätzen durch, MAWPS, Math23K, MathQA und SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Variante ist also Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir BeamSearch nicht, im Gegensatz zu offensichtlichen Ansätzen mit BeamSearch."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Okay, die besten Ansätze sind oft ein Baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Vernunft also dieses Baumbasierungsmodell deutlich übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MatQuery oder SWAM nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse weiter."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist eine Herausforderung, weil der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. irrelevante Informationen und zusätzliche Mengen hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Also, in unserer Vorhersage finden wir, dass einige der intermediären Werte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Pitchs und Stephen hat acht Pitchs, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse als negativ entfernen, damit wir die Antwort richtig machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert und bei dem Roberta-Basemodell tatsächlich zwei Punkte verbessert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat also bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Bert niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information angesehen werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der ungenutzten Mengen haben und der SWAMP-Datensatz den größten Teil enthält."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen ist die Gesamtleistung tatsächlich höher als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlimmer ist als die, äh, viel schlimmer als."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für MAWPS haben wir nicht wirklich viele Desk-Cases, also ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretationsfähigkeit durch ein Beispiel für die Zusammenstoßpartizierung zeigen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also tatsächlich eine falsche Vorhersage im ersten Schritt."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren, oder?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben also, dass dieser Satz das Modell in eine falsche Vorhersage führen könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man hier also noch 35 plant, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu ändern, dass er so aussieht wie die Anzahl der Birnenfäden fünfundfünfzig weniger ist als die Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen es also so, dass es genauere Semantik vermittelt, damit das Modell die Vorhersage richtig machen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell eigentlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können eine interpretierbare Lösungsmethode bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige vorherige Kenntnisse als Konstrakt einbeziehen, was uns helfen kann, die Leistung zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur für Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch für andere Aufgaben, die mehrtretende Argumentation beinhalten."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung in verschiedenen Zeitzonen unbalanciert ist, daher ist es auch ziemlich schwierig, Beam-Suche anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also das Ende des Vortrags und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Maastricht University."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein Johannes Werk mit Jerry vorstellen, das sich mit einem neuen Datensatz für die Abholung von gesetzlichen Artikeln befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein wesentlicher Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat wenig oder kein Wissen über ihre Rechte und grundlegenden Rechtsverfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Ergebnis sind viele vulnerable Bürger, die sich nicht die kostbare Assistance eines Legal Experts erwarten können, unprotegt oder worstens, exploitiert."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Lücke zwischen Menschen und dem Gesetz zu schließen, indem wir ein effektives Rückholsystem für gesetzliche Artikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte für unqualifizierte Menschen einen kostenlosen professionellen Rechtshilfenservice bieten."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem der statutarischen Artikelabholung."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ich eine einfache Frage zu einem rechtlichen Thema stelle, wie zum Beispiel: Was mache ich, wenn ich die professionelle Vertraulichkeit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetz zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe zur Informationserfassung bringt eine ganze Reihe von Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst geht es um zwei Sprachtypen."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "für die Fragen eine gängige natürliche Sprache und für die Statuten eine komplexe rechtliche Sprache."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in den Sprachverteilungen machen es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die mit der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das gesetzliche Recht kein Stapel unabhängiger Artikel, die als vollständige Informationsquelle an sich behandelt werden können, wie zum Beispiel Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Insted ist es eine Strukturkollektion von legalen Provisionen, die nur in der allgemeinen Kontext betrachtet sind, zusammen mit den zusätzlichen Informationen aus den neighbouring Artikeln, den Feldern und Subfeldern, zu denen sie gehören, und ihrer Platz in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, statutory Articles RN small paragraph, was usuell die typische Retrieval Unit in Most Retrieval Works ist."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Jahre dauern können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich NLP haben großes Interesse an vielen rechtlichen Aufgaben wie der Vorhersage von Rechtsentscheidungen oder der automatisierten Überprüfung von Vertragsverträgen weckt."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabholung ist jedoch aufgrund des Mangels an großen und hochwertigen gekennzeichneten Datensätzen größtenteils unberührt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir ein neues französisches, zentrales, zentrales Datenkett, um zu untersuchen, ob ein Rückholmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten für die Aufgabe der Statutorienartikelrückholung nähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Our Belgian Statutory Article Retrieval Data Sets consist von mehr als einem Jahrzehnt Liter."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnraum, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen hat von erfahrenen Juristen mit Referenzen zu relevanten Artikeln aus einem Corpus von mehr als twenty zwei Tausend sechshundert."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Codes of Law. Lassen Sie uns nun über die Erstellung dieser Datsätze sprechen."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir mit der Zusammenstellung eines großen Korpus an rechtlichen Artikeln begonnen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich verfügbare Belgische Codes und alle Artikel sowie die entsprechenden Abschnittshebungen entnommen."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf relevante Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich, auf ihre Websites zuzugreifen, wo ihr Team von erfahrenen Juristen Belgien's am häufigsten rechtlichen Probleme behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen zusammengestellt, mit Kategorien, Subkategorien und rechtlichen Verweisen auf relevante Statuten."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, wir passten die legalen Referenzen und filterten die Fragen aus, die Referenzen nicht Artikel in einem der Codes of Law wirkten."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Verweise wurden in die entsprechenden Artikel-IDs aus O Corpus abgestimmt und umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.108 Fragen, jeder sorgfältig mit den IDs der relevanten Artikel aus dem Buch."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich enthält jede Frage eine Hauptkategorie und eine Konkatenation von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel kommt mit einer Konkatenation ihrer nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzliche Information wird nicht in der Präsentation verwendet, aber sie könnte für zukünftige Research auf Legal Information Retrieval oder Legaltext Classification interessant sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale unserer Datensätze an."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Frage ist zwischen fünf und vierundvierzig Wort lang, mit einem Median von vierzig Wort."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer medianen Länge von sechzig sieben Wörtern, mit 140 Gramm."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei von ihnen, die eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine Vielzahl von Themen, von denen etwa 85 % entweder über Familie, Wohnraum, Geld oder Gerechtigkeit betraf."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Während die restlichen fünfzehn Prozent entweder mit der Sozialversicherung, Ausländern oder Arbeit zu tun haben."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr diverse, da sie aus dreißig zwei verschiedenen Belgischen Codes kommen, die eine große Anzahl von illegalen Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel aus jedem dieser belgischen Codes."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Aus den twenty two thousand six hundred thirty three Artikeln, nur eintausend sechs hundred twelve sind als relevant zu at least einem"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "nur eine Frage in den Daten sätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafverfolgungsgesetz."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen enthalten achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann durch die Tatsache erklärt werden, dass diese Codes weniger auf Einzelpersonen und ihre Anliegen fokussieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünf Prozent von ihnen sind in der"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen benchmarken wir verschiedene Rückholmethoden, einschließlich lexikalischer und denser Architektur."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrageartikelpaar eine Punktzahl zu, indem es die Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfragezeiten berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM-25-Rankingfunktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert und eine relevante Punktzahl zwischen einem Abfrage-Artikelpaar anhand der Ähnlichkeit ihrer Eingebettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit siamesischer Biancoder in einer Nullschussbewertung, was bedeutet, dass vorgebildete Word-Embedding-Modelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, und kontextunabhängigen Einbettungsmodellen, nämlich Roberta und genauer gesagt Camembert, das ein französisches Roberta-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes Camembert-basiertes Modell. Beyond quoters."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beispiele auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Flavors der Bianco architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Query und den Artikel in einem gemeinsamen Densivektorraum mappiert, und Tutor, das zwei unabhängige Word-Embedding-Modelle verwendet, die die Query und den Artikel separat in zwei verschiedene Embedding-Spaces codieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit dem Pooling von Mittel, Max und CLS sowie mit dem Punktprodukt und dem Kosinus für die Rechengelähnungen."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Ausgangslinie auf den Testsätzen."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Dann mit den lexikalischen Methoden oben, den Siamese-B-Encodern, die in einer Null-Schuss-Einrichtung evaluiert wurden, und den fein abgestimmten B-Encodern unten."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchore alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two Tower Modell verbessert sich gegenüber seiner Siamese-Variante auf Recallat one hundred, aber es funktioniert ähnlich bei den anderen Metriken."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five den trainierten Biancode erheblich unterlegen hat, zeigt seine Leistung, dass es immer noch eine starke Grundlage für Domain Specific Retrieval ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Was die Nullschussbewertung des siamesischen Biancoders betrifft, stellen wir fest, dass die direkte Verwendung der Eingebettungen eines vorgebildeten Kamembert-Modells ohne Optimierung für die Informationsabholungsaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir festgestellt, dass der Word-Tuec-basierte Biancoder den Vastex- und Vogelbasierten Modell deutlich übertrifft, was darauf hindeutet, dass möglicherweise vor-train-Word-Level-Embeddings für die Aufgabe besser geeignet sind als Charakter- oder Unterword-Level-Embeddings, wenn sie von vorn verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Möglichkeiten für Verbesserungen im Vergleich zu einem geschickten Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns mit zwei Einschränkungen aller Datensätze abschließen."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf die aus den 32 belgischen Gesetzen gezogenen beschränkt, die nicht das gesamte belgische Gesetz abdecken, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Referenzen zu diesen ungesammelten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl relevanten Artikeln erhalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsloss impliziert, dass die Antwort in den verbleibenden relevanten Artikeln unvollständig sein könnte, obwohl sie immer noch vollständig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Kann ich meine Mieter vertreiben, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Might not have a detaillierte Antwort innerhalb des gesetzlichen Gesetzes, das eine spezifische Noise-Threshold quantifiziert, bei der Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich mehr auf die Rechtsprechung vertrauen und Präzedenzfälle finden, die ähnlich zu ihrer aktuellen Situation sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Tenant zwei Parties pro Woche und tut es."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser als andere für die gesetzliche Artikel-Retrieval-Tasche geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass all diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur Berechnung von gesetzlichen Artikeln weckt,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Papier, Datset und Code unter den folgenden Links sehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorzustellen, einem unabhängigen Benchmark, der für die Testung von Vision- und Sprachmodellen mit bestimmten sprachlichen Phänomenen gedacht ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark festzulegen?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformer-basierten Vision- und Sprachmodellen gesehen, die auf große Mengen an Bild-Textpaaren vorgebildet wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle drängt die Moderne in der Vision und Sprachaufgaben wie der Antwort auf visuelle Fragen, der visuellen Sinnesreasoning, der Bildherstellung und der Phrase-Grundung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Nachricht erhalten. Die Genauigkeit dieser für die Aufgabe spezifischen Benchmarks steigt stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprachtransformer verstanden, als er diesem Bild und diesem Satz eine hohe Punktzahl zugewiesen hat, um es zu vereinbaren?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und der niedrige Punkt für diesen."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie durch frühere Arbeiten gezeigt?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf diesen Aspekt zu werfen, schlagen wir eine tauschfreundlichere Richtung vor und führen VALS ein, das die Empfindlichkeit von Seh- und Sprachmodellen auf spezifische sprachliche Phänomene testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Vielfalt, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenzen ab."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen festgehalten haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor nur für Vision und Sprachmodelle von Ravi Shakar und seinen Mitarbeitern für Nomenphrasen angewendet wurde, und bei der Zählung von uns in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde, dass wir den Bildunterschrift eines Bildes nehmen und einen Foil erzeugen, indem wir den Unterschrift so verändern, dass er das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Wir ändern diese Phrase, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenz, wobei jedes Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, FOIL-Instanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir im Fall des Aktionsstücks zwei Instrumente, eines, bei dem das Aktionsverb mit einer anderen Aktion geändert wird, und eines, bei dem die Spielzeuge ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Ko-Referenzen sind auch Stücke, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schaffen diese Fehler, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererseits gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach, da eine fehlerhafte Beschreibung weniger wahrscheinlich sein kann als die ursprüngliche Beschreibung."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es zwar nicht unmöglich, statistisch gesehen ist es weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann Pflanzen schneiden, und große Vision- und Sprachmodelle könnten dies aufgreifen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um gültige Folien zu erhalten, müssen wir daher Maßnahmen ergreifen."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir starke Sprachmodelle, um FOILs vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir die Inferenz durch natürliche Sprache oder kurz NLI, um Folien zu filtern, die das Bild noch beschreiben könnten, da wir bei der Konstruktion von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir eine Schlussfolgerung aus natürlicher Sprache mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Beschriftung als die damit verbundene Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In addition, wir betrachten die Kaption als die Premise und die FOIL als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell die FOIL als widersprechend oder neutral gegenüber dem Untertitel vorhersagt, nehmen wir dies als Indikator für eine gültige FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Folie durch den Untertitel enthalten ist, kann es keine gute Folie sein, da sie durch Transitivität eine wahrhaftige Beschreibung des Bildes liefert und wir diese Folien ausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Prozedere ist nicht perfekt. Es ist nur ein Indikator für valide Foil."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Erstellung gültiger FOILs menschliche Annotatoren, um die in Valse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir also so viele Testfälle wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um einen Benchmark für Null-Schuss-Tests handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vorausbildung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Die Feinabstimmung würde es den Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nutzen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vorausbildung haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen auf Vowels, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin I und VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bilder-Satzpaaren in Untertitel und FOILs."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht ist für dieses Video relevanter, dass wir unsere permissivere Metrik, die Paargenauigkeit, präsentieren, die misst, ob der Ausrichtungswert des Bildesatzes für das korrekte Textpaar des Bildes höher ist als für das fehlerhafte Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Metriken und Ergebnisse zu diesen Ergebnissen finden Sie in unserer Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit Paar-Präzision sind hier gezeigt und entsprechen den Ergebnissen, die wir aus den anderen Metriken erhalten haben. Die beste Leistung bei Nullschüssen wird von Wilbert zwölf in einem, gefolgt von Wilbert, LXMert, Clip und schließlich VisualBird erreicht."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert Twelve in One fast gelöst werden, wobei er hervorhebt, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann in unseren Adversarial Foiling-Einstellungen keine der verbleibenden Teile zuverlässig gelöst werden"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäten und Zählungsinstrumenten sehen wir, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Aktionen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie durch plausibel Vorurteile unterstützt werden, wie wir im Aktionsteil sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Bereich erfahren wir, dass es für Vision- und Sprachmodelle ebenfalls schwierig ist, mehrere Referenzen auf das gleiche Objekt in einem Bild mit Pronomen zu verfolgen."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Verstandskontrolle und weil es ein interessantes Experiment ist, haben wir auch zwei Textmodelle, GPT eins und GPT zwei, benchmarkt, um zu beurteilen, ob Valse durch diese Einmodalmodelle gelöst werden kann, indem wir die Verwirrung der richtigen und der fehlgeschlagenen Beschriftung berechnen und den Eintrag mit der geringsten Verwirrung vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die FOIL höher ist, nehmen wir dies als Hinweis darauf, dass die FOIL-Beschriftung unter einer plausibilen Voreingenommenheit oder anderen sprachlichen Voreingenommenheiten leidet."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die Text nur GPT Modelle die Plausibilität der Welt besser erfassen haben als die Vision und Language Modelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALS ein Benchmark ist, der die Linse der sprachlichen Konstruktionen nutzt, um der Community bei der Verbesserung von Seh- und Sprachmodellen zu helfen, indem sie ihre visuellen Grundlagefähigkeiten hart testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu begründen, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich ermutigen, VALS zur Messung des Fortschritts hin zur Sprachbasis mit Vision und Sprachmodellen zu verwenden."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, VALS könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von VALS getesteten Aspekte hilft."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, sollten Sie sich die Walls-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde eine Papier entitelt RNSAM, ein Large Scale DSET für automatische Risikogrammierung beim Commitologizieren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikogenerierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNote ist ein technisches Dokument, das die bei jeder Veröffentlichung eines Softwareprodukts zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Restnoten für Bosch 2.6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "User Us Library These Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consuming, um manuell zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, hochwertige Release-Noten automatisch zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Frischknotengenerierung verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste System, das Arena erstellt wurde, wurde 2014 erstellt."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert eine ruralbasierte Approach, zum Beispiel, indem man die Change Extractor verwendet, um Code differenzen, Bibliothekänder und Dokumentenänderungen von den differenzen zwischen Releases zu extrahieren, und schließlich kombinieren sie."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das bemerkenswerteste Merkmal dieses Systems ist der Ausgaben-Extraktor in der oberen rechten Ecke,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dieses muss mit dem Issues-Ökosystem verbunden sein und kann nur auf Projekte mit Null angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist Grief. Dies entweder angesagt in 2014."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "2020. Es ist auf dem Internet verfügbar und kann via PIP gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches Textklassifizierungsmodell basierendes auf Lernen und Ausgaben aus fünf Labors, wie z. B. Funktionen oder Fehlerbehebungen, für jede Eingabe-Kommentarnachricht."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Sample-User, das eine Korrektur für Fehlerkorrekturen erhält."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingdaten sind sehr klein, etwa fünftausend, und werden in den Experimenten beschriebenen unten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Kreuzschaltmodells ist nicht höher."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier löst diese beiden Probleme und erzeugt automatisch hochwertige Freigabe-Noten."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das begrenzte Anwendungsprogramm schlagen wir eine hochwertige Klassifizierungsmethode mit nur Kommentarmeldungen als Eingabe vor."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Repositories verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der Skarbstaatressourcen haben wir eine RNSAM DSET konsistent mit etwa 82.000 Datenpunkten erstellt, indem wir Daten aus öffentlichen GitHub Repositories mit der GitHub API erstellen."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unsere Daseinsetzung."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Nachricht des Komitees und die rechte Seite ist die Release-Note."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Riesen sind als Verbesserungen, Verbesserungen, etc. gelobt."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Kommentarnachrichten als Eingaben aufnimmt und die Raveled-Please-Notizen ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassungsaufgabe angesehen werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Rubber, Funktionen, Verbesserungen, Fehlerbehebungen, Deprekationen, Entfernungen und Bremsänderungen vorgedefiniert."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden aufgrund früherer Forschung und anderer Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Rhythmus-Noten unten rechts werden aus den Rhythmus-Noten unten links abgezogen."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Moment müssen die vier Schuttwerke, die im Voraus aufgestellt wurden, entdeckt werden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Lager sind nicht immer mit jeder Freiheit übereinstimmen"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, um Verbesserungen zu treffen, zu erhöhen, Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabulärliste mit etwa 30 Numbers für jede dieser Rotationsvariationen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Restnotkrasten zu erkennen und den Text der Restnotkrasten zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Komiteemeldung."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachrichten des Komitees sind nicht an jede Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der image below, wenn die aktuelle Realität Boson zwei Punkt fünf zwei neunzehn, müssen wir die IDECHTEN"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "erfüllt die vorherige Version 2.5218 und erhält einen Tiff. Dies ist ein bisschen mühsam und es reicht nicht aus, nur eine Liste der Releases zu erhalten und sich die Vorher und Nachher anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine Heuristik, die mit Ihnen übereinstimmt, um die vorherigen und nächsten Schauspielzeiten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind die Horses."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "In der Hand, siebentausend zwei hundert Repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Token 63, was für eine Zusammenfassungsaufgabe ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Nummer der Unique Tokens ist bei Roger at eight thousand eight hundred thirty thousand."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl von einzigartigen Kasten und Methoden im Repertory."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes erkläre ich die vorgeschlagene Methode."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Querschnitts-, Extraktions- und Abstruktionsmodell besteht aus zwei neuer Modulen"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifier mit Bot oder Code Bot und ein Generator mit Bot."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Klassifizierer, um jede Kommentarnachricht in fünf RESNOT-Klassen zu klassifizieren: Funktionen, Verbesserungen, Fehlerbehebungen, Duplizierungen und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als anderer eingestuften Komitee-Nachrichten werden abgelehnt."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GAS den Generator unabhängig auf die vier Rudder-Dokumente an und erzeugt für jede Klasse Risikonode."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Übereinstimmungen zwischen Commit-Nachrichten und Lesemerkungen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifizierer zu trainieren, weisen wir jeder Eingabe-Commit-Nachricht Pseudorabben zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Kreuzstreifen-Abstruktiv-Summersätze durch zwei verschiedene Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzigen SEC-Netzwerk und generiert einen einzigen Long-SNode-Text, der eine Kombination von Eingabe-Commit-Nachrichten liefert."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgangstext kann in Kreuzzeichen aufgeteilt werden, basierend auf speziellen Kreuz-Spezifischen Endpunkt-Symbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSMarch nennen, besteht aus vier verschiedenen SEC-to-SEC-Netzwerken, von denen jede einer der RES-Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das macht Spain's Experiment."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: CS, CS Single, CS Smart, Russelling und die vorherige Studienbeschreibung."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Abrissung sind in einigen Fällen diese Noten in mehreren Sätzen ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro ist penetrativ, wenn das System einen kurzen Satz ausgibt"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Brauvolumen. In den als nächstes beschriebenen Experimentenergebnissen"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erzeugen wir auch eine Spezifität, da Rouge und Brux nicht erzeugt werden können, wenn die Riesen-Knoten leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass die Modellprojekte ausgegeben sind, die in Fällen, in denen die Reasonals empfangen, empfindlich sind."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Daseit Emailadresse, Hashbarriers, etc. enthält, erweitern wir auch den Quint Daseit, der sie ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat und sie hat Rouge Air-Punkte erreicht, die mehr als zehn Punkte höher waren als die Baselines."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Green Test set, der Square Gap zwischen der proposierten Methode und der Basis jumped zu mehr als 20 Punkten."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie und sie erfolgreich sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS hat eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Crossfire und eines Generators auf das Training des Crossfire-Systems mit Pseudobus effektiv ist."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, weil der Klassifizierer sich auf die relevanten Kommittentests für jeden Kurs konzentrieren kann."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie isst in dieser Zeit viel höher als wenn sie ledig ist."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es auch effektiv ist, für jede dieser Notengrasse unabhängig verschiedene Perspektivsummerisierungsmodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hero und Eronasus"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xia's Methoden neigen dazu, kürzere Sätze als menschliche Referenz-Sätze zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Figur auf der rechten Referenz hat drei oder vier Sätze, während CS nur eins hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzugabe ist, dass in den Trainingsdaten nur 33 % der Sätze im Rabel Merkmale und 40 % im Rabel Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES Methoden ohne zusätzliche Informationen keine genauen Risikobewertungen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommentarmeldung, und die Kommentarfassung kann nicht generiert werden, ohne auf die entsprechende Peru-Request oder -Erstellung hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das untenstehende Beispiel zeigt, dass die beiden Kommentarberichte im Eingaben miteinander verbunden sind und in einen Satz kombiniert werden sollten, aber dies geschieht nicht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Personalgenerierung erstellt,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Kommentarmeldungen einzugeben und sie zusammenzufassen, sodass sie für alle Projekte auf Englisch anwendbar ist."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die Bassrate besser laut macht als die Bassrate."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte schauen Sie sich unsere Dessert-Audit-Tab an."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist ein Safarari,"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unsere Arbeit über die Anreicherung von Tabellen mit Hilfe von fein abgestimmten Transformatoren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Merkmale der Daten."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen begrenzt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Funktionen mit einer anderen Datenquelle kann erhebliche Informationen bieten."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung von Tabelldaten mit externen Quellen-Freitexten."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben eine Tabelldatensammlung und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Funktionen aus dem künstlichen Text der Wissensbasis zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel sehen. In einem Datensatz, der in FEST eingeführt wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist die Datenmenge Universitätsdatenmenge."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten zu unterteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festes ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Einheit, in diesem Beispiel der Name der Universität, mit einer Einheit innerhalb der Wissensbasis verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Knowledge-Basis wird extrahiert und in die Daten setzt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text der Abstrakt der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Funktionen aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen also eine Funktionsaufnahmephase, die Textanalyse beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde mich in den nächsten Folien tiefer damit befassen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Extraktionsphase der Merkmale gibt es eine Generierungsphase der Merkmale, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst generieren Sie Funktionen in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also, erstens zwei neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Funktion stellt die Wahrscheinlichkeit für jede Klasse dar."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, die sich auf Transformer basieren lassen, wie Baird, GPT, XLED und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe zur Feinabstimmung sein."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Funktionsauffnahme können wir also ein Parent-Train-Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell verfeinert, um Text in Klassen zu klassifizieren, abstrakt in Klassen, niedrig oder hoch."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse ist, und verwenden Sie sie als neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datenmengen möglicherweise wenige unterschiedliche Entitätsstapel haben."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Proben, und der kleinste Datensatz enthält fünfunddreißig Proben in seinem Trainings-Satz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorherige Kenntnisse über voranalyseierte Datensätze nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir den nth-Datensatz analysieren."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sugest, ist die Hälfte der Fine Tuning Phase."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Phase der Fine-Tuning-Multitask."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über n minus eins Datensätze finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine weitere Feinabstimmungsphase durch, die eine Feinabstimmung der Zielaufgaben ist, wenn wir das Sprachmodell über den n-Tiel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der neueste Stand der Multitask-Fine-Tuning, der MTDNN genannt wird."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN hält MTDNN eine Anzahl von Aufgaben im Trainingsatz aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainings-Set. Also leere DNN und halte vier Kopfhäupter, wie Sie auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es samplet eine zufällige Charge aus dem Trainingsset."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Run-Batch zu einer, zum Beispiel, Sing und Selton-Klassifizierungsaufgabe gehört, führt er einen Vorwärts- und Rückwärtspass durch den ersten Kopf aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zu einer Paar-Ranking-Tasche gehört, wird sie durch den letzten Kopf weitergegeben und zurückgegeben."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario verifiziert eine Datenmenge-Tabelle die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN hält die Anzahl der Klassen-Heads-Ausgaben-Schichten aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss MTDNN eine neue HEADS für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Task Reformulation Fine Tuning bezeichnet wird, besteht darin, dass wir in unserem Ansatz Task Reformation Fine Tuning statt mehrere Kopfgruppen zu behalten, jeden Datensatz in ein Satz pro Klassifizierungsproblem umformulieren, das zwei Klassen-Aufgaben ist."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also ein Beispiel sehen."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Input-Datensatz, der von Entitäten, Funktionen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zu der Klassifizierung des Textes, des Abstrakts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, wir haben das Sprachmodell so trainiert, dass es abstrakt und in der Klasse klassifiziert, ob die Abstrakt-Klasse in der Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Etikettvektor besteht in diesem Fall also immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren fertigen oder formulierten Feintuning-Ansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also das vollständige Framework betrachten."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und das set fade into fast"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Entity-Linking-Phase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensbasis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird die Aufgabe in eine Satz-Per-Classifikation-Tasche reformuliert."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und die Ausgabenwahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über n-1-Datensatz mit einer vorläufigen Multitask-Fine-Tuning verfeinert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu erstelltes Merkmal in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Rahmenwerk zu bewerten, verwenden wir eine Datenmenge mit siebzehn Tabellen, die Größe, Merkmale, Balance, Bereich und anfängliche Leistung variieren."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unser Experiment als Live-Out-Evaluierung gestaltet, bei der wir schnell über sechzehn Datensätze trainieren und sie auf das siebzehnte Datenset anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datensatz in vier Fehler auf und wenden eine Falten-Cross-Validation an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Funktionen und bewerten sie mit fünf Bewertungs-Klassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-Basis-Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Rahmenwerk mit der Feinabstimmung des Zieldatensatzes, der Feinabstimmung der Zielaufgabe und der vorläufigen Feinabstimmung der MTDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere Formulierung ist ein Feintuning, das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2% gegenüber der Feinabstimmung des Zieldatensatzes erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Poach hat eine Verbesserung um sechs Prozent erzielt."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Daten ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Feinabstimmung bei mehrere Aufgaben auf 1,5 Prozent abnimmt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung hat sich im Vergleich zu der Zielaufgabe, die allein mit der Feinabstimmung verbessert wurde, um elf Prozent zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Zusammenfassung ermöglicht Fast die Bereicherung von Fushot aus 35 Proben in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulationsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satzpaar-Klassifizierungsproblematik verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Assa Farari und ich werde unsere Arbeit FUSHOT Tabellendatenanbau mit fein abgestimmten Transformers-Architekturen vorstellen. Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Datenmerkmale, aber manchmal sind diese Merkmale begrenzt. Die Generierung von Merkmalen mit einer anderen Datenquelle kann erhebliche Informationen hinzufügen. Unser Forschungsziel ist die automatische Tabellendatenanbau mit externen Quellen, freiem Text. Nehmen wir an, wir haben eine Tabellendatenmenge und eine Wissensbasis. Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Merkmale aus dem kostenlosen Text der Wissensbasis zu extrahieren. Unser Framework FEST ist genau dieser automatische Prozess. Lassen Sie uns ein Beispiel betrachten. In einem Datensatz, der in FEST eingeführt wird. In diesem Beispiel ist der Datensatz ein Universitätsdatensatz, wenn sein Ziel es ist, Universitäten in niedrig rankende Universitäten und hochrangige Universitäten. Als Wissensbasis verwenden wir Wikipedia. Die erste Phase von FEST ist die Entitätslinkung, bei der jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität innerhalb der Wissensbasis verknüpft wird und der Text der Entitäten der Wissensbasis extrahiert und zum Datensatz hinzugefügt wird. In diesem Beispiel ist der Text der Wikipedia-Seitenabschnitt. Jetzt müssen wir Features aus dem erhaltenen Text generieren oder extrahieren. Wir benötigen also eine Feature-Extraction-Phase, die Textanalyse beinhaltet. Und das ist die Hauptnota dieser Arbeit, und ich werde mich in den nächsten Folien damit befassen. Nach der Feature-Extraction-Phase gibt es eine Feature-Generation-Phase, in der wir die extrahierten Features verwenden, um eine kleine Anzahl von Features zu generieren. Sie eine kleine Anzahl neuer Merkmale. Erstellen Sie zuerst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes. In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen, also erstellen Sie zuerst zwei neue Merkmale. Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Merkmale. Jede Merkmale repräsentiert die Wahrscheinlichkeit für jede Klasse. Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, nämlich transformierbare Sprachmodelle wie BERT, GPT, XLERT und so weiter. Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können. Daher wäre eine naive Herangehensweise die Feinabstimmung der Zielaufgabe. In der Fase der Extraktion der Funktionen können wir ein pertrainiertes Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset feinabstimmen. In diesem Beispiel können wir das Sprachmodell fe soll Text in Klassen, Abstract in Klassen, Low oder High, in Klassen eingeteilt, die Sprachmodell-Ausgaben erhalten, die für jede Klasse die Wahrscheinlichkeit sind, und als neue Funktionen verwendet werden. Das Problem bei diesem Ansatz ist, dass Daten sätze möglicherweise wenige unterschiedliche Entitäten wie Text enthalten. In unserem Experiment enthalten fast die Hälfte der Daten sätze weniger als 400 Samples und die kleinsten Daten sätze enthalten. Es enthält 35 Proben in seinem Trainings-Set. Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern. Wir können jedoch vorherige Kenntnisse über voranalysierte Datensätze nutzen, da wir FAST über mehrere Datensätze anwenden. Wir können die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir die nth Dataset. Was wir vorschlagen, ist eine weitere Fein-Tuning-Phase, eine preliminäre Multitask-Fein-Tuning-Phase, wenn wir das Languagemodell über n-1 Datasets fein-tunen. Und dann führen wir eine weitere Fein-Tuning-Phase aus, die eine Target-Task-Fein-Tuning ist, wenn wir das Languagemodell über das nth-Target-Dataset fein-tunen. Der Stand der Welt in der Multitask-Fein-Tuning-Phase. Fine-Tuning-Anwendung namens MTDNN. In MTDNN, MTDNN, mainten Sie eine Hälfte der Taschen im Trainingssatz. In diesem Beispiel gibt es vier Taschen im Trainingssatz. MTDNN mainten Sie vier Hälfte, wie Sie sehen können, im Bild. Es sampelt eine Random-Batch aus dem Trainingssatz. Und wenn die Random-Batch zu einem Zum Beispiel Singenselten's Classification-Tasks, es führt Vor- und Rückwärtspfade durch den ersten Kopf aus. Und wenn der Random-Batch zu Paar-Wise-Ranking-Task gehört, führt es Vor- und Rückwärtspfade durch den letzten Kopf aus. In unserem Szenario verringen Tableau-Datensätze die Anzahl der Klassen. Es gibt also viele Aufgaben. MTDNN-Mainten. DNN hält eine Reihe von Klassen-Heads-Ausgaben-Lagen aufrecht und zusätzlich muss MTDNN neue Heads für einen neuen Datensatz mit einer neuen Aufgabe initialisieren. Unser Ansatz, der als Task-Reformulation-Fine-Tuning bezeichnet wird, ist, dass wir in unserem Ansatz Task-Reformulation-Fine-Tuning, anstatt mehrere Heads aufrechtzuerhalten, jedes Datensatz in ein Satz pro Klassifizierungsproblem, das zwei Klassen-Taschen. Also, sehen wir ein Beispiel. Hier ist unser Input-Datensatz, der entweder von Entitäten, Funktionen, Text und Klassen besteht. Und wir reformulieren die Tasche von der Klassifizierung der Text in Low und High, um die Text, den Abstrakt und die Klasse in True oder False zu klassifizieren. Oder in anderen Worten, wir trainieren das Languagemodell, um eine Abstrakt- und Klassenklasse zu klassifizieren, ob die Abstrakt- und Klassenklasse zur Klasse gehören oder nicht. Der Etikettvektor bleibt in diesem Fall immer mit zwei Klassen bestehen. Und das ist der Algorithmus für unsere Find-Orientierung. find reformulated fine-tuning approach. Also, sehen wir uns den vollständigen Framework an. Ein Datensatz wird in FAST eingeführt und dann FAST execute in die Linkingphase. Es extrahiert den Text aus der Knowledge-Basis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist. Dann wird die Task reformuliert in Satz-Per-Classification-Tasks, das Sprachmodell auf die neue Task und die Ausgaben-Likelihood für jede Klasse. Beachten Sie, dass das Language-Modell bereits über n-1-Datensätze mit einer vorläufigen Multitask-Fine-Tuning abgestimmt ist. Dann verwenden wir den Ausgabenvektor des Language-Modells als neu generierten Funktion in der Anzahl der Klassen. Um unser Framework zu evaluieren, verwenden wir eine 17. Wir haben eine siebzehn-Tabellklassifizierungsdatensätze, die die Größe, die Merkmale, den Bereich und die anfängliche Leistung in Einklang bringt. Und als Wissensbasis verwenden wir Wikipedia. Wir haben unser Experiment als eine Live-Out-Evaluierung entworfen, bei der wir schnell über sechzehn Datensätze trainieren und sie auf die siebzehnte Datensätze anwenden. Wir haben auch jede Datensätze in vier Daten aufgeteilt. Wir erstellen Fehler und wenden eine Fork-Fehler-Kreuzvalidierung an. Dann generieren wir die neue Funktion und bewerten sie mit fünf Bewertungs-Klassifikatoren. In unserem Experiment verwenden wir eine auf Bild-Basis basierte Architektur. Hier sind die Ergebnisse unseres Experiments. Sie sehen, dass wir unser Framework mit der Feinabstimmung des Zieldatensatzes vergleichen, der Feinabstimmung der Zielaufgabe. und MTDNN preliminäre Feintuning und unsere reformulierte Feintuning erreichten den besten Ergebnis, die besten Leistungen, während MTDNN 2% Verbesserung über die Target-Datenset-Fine-Tuning erreichte. Unser Produkt erreichte 6% Verbesserung. Wenn wir uns die kleinen Daten ansehen, Aus dem Datensatz können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Fine-Tuning für mehrere Aufgaben auf 1,5 Prozent abnimmt, aber unsere Leistung steigt auf 11 Prozent im Vergleich zur alleinigen Fine-Tuning für die Zielaufgabe. Für die Zusammenfassung ermöglicht FAST die Bereicherung von Flux-Schüssen aus 35 Proben in unserem Experiment. verwendet eine Architektur für alle Aufgaben-Datensätze und behält den Kopf des Modells bei. Aber es fügt eine Formulierungsphase hinzu, es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satz-Par-Klassifizierungsproblematik verwenden können. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen. Heute werde ich unser Forschungswerk Lernen, deduktiv zu denken, Methodenproblemlösung als komplexe Rationsauffnahme vorstellen. Ich bin Alan vom Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD. Zunächst möchte ich über unsere Motivation für das Denken sprechen. Hier zeigen wir Beispiele, in denen mehrträgliches Denken hilfreich ist. Diese Zahl stammt aus der POWN-Artikel, in der sie die Anregung zur Lösung des Methodenproblems in einem Future-Learning-Szenario durchführen. Auf der Netto-Pan-Seite können wir sehen, dass wir, wenn wir einige Beispiele mit nur Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten. Wenn wir jedoch eine weitere Beschreibung geben, kann das Modell die Beschreibung vorhersagen und auch eine korrekte Vorhersage treffen. Es ist also gut, als Ausgabe interpretierbare Mehrstufige Beschreibung zu haben. Wir denken auch, dass das Methodenproblem eine einfache Anwendung ist, um solche Beschreibungsfähigkeiten zu bewerten. Hier in unserer Problemkonfiguration müssen wir diese Frage aufgrund der Fragen lösen und die numerischen Antworten erhalten. In unseren Datensätzen erhalten wir also auch den mathematischen Ausdruck, der auch zu dieser bestimmten Antwort führt. Daher gelten bestimmte Annahmen wie in früheren Arbeiten. Wir gehen davon aus, dass die Präzision von Größen bekannt ist, und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential. Darüber hinaus können komplizierte Operatoren tatsächlich ent in diese grundlegenden Operatoren aufgeteilt werden. Frühere Arbeiten im Lösungsproblem der Methode können also tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baummodell kategorisiert werden. Traditionelle Sequenz-zu-Sequenz-Modelle konvertieren den Ausdruck in eine spezifische Sequenz für die Generierung, und es ist ziemlich einfach zu implementieren, und es kann auf viele verschiedene komplizierte Probleme verallgemeinert werden. Aber die Nachteile sind, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell, und es fehlt an Interpretabilität für die die Vorhersage. Aber eigentlich ist diese Richtung aufgrund des Transformator-Modells immer noch ziemlich beliebt. In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen. Hier generieren wir also die Operatoren, bis wir die Blätter erreichen, die die Größen sind. Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt. Aber eigentlich ist es ziemlich kontraintuitiv. Denn wir generieren zuerst den Operator und dann am Ende die Größen. Und das Zweite ist, dass er auch einige wiederholte Berechnungen enthält. Wenn wir uns also diesen Ausdruck a mal drei plus drei ansehen, wird er tatsächlich zweimal generiert. Aber tatsächlich sollten wir die Ergebnisse wiederverwenden. In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und interpretierbar lösen. Zum Beispiel können wir hier im zweiten Schritt die Daten erhalten., die 27 sind. Und wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden. Und in diesen Schritten erhalten wir die Teiler. Und dann erhalten wir in diesem dritten Schritt tatsächlich den Quotienten. Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse des zweiten Schritts wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten. Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren. Dies macht den Prozess genauer. In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als Anfangszustände ein. Der Ausdruck wird also durch EIJOP dargestellt, bei dem wir Operatoren von Qi bis Qj ausführen, und dieser Ausdruck ist tatsächlich gelenkt. Wir haben hier auch eine Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen. Das ist ziemlich ähnlich wie eine Relationsentfernung. In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diesen neuen Ausdruck. Wir fügen ihn den nächsten Zuständen hinzu, um eine neue Größe zu erhalten. Diese Folien visualisieren tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zustand weiterhin Ausdrücke hinzufügen. In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Netzwerkmodell, das Vögel oder Roberto sein kann, und dann codieren wir den Satz und erhalten diese Mengenrepräsentationen. Sobald wir die Mengenrepräsentationen erhalten, können wir mit der Schlussfolgerung beginnen. Hier zeigen wir ein Beispiel für Q1, um die Repräsentation für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q3 multipliziert wird. Zuerst erhalten wir die Paarrepräsentation, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist, und dann wenden wir ein Fit-Forward-Netzwerk an, das ist. Dies wird durch den Operator parametriert. Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2. Aber in der Praxis könnten wir im Inferenzstadium auch den falschen Ausdruck erhalten. Hier sind alle möglichen Ausdrücke gleich dreimal so viele Operatoren. Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern. Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchraum entfernen. Im zweiten Schritt machen wir also das Gleiche, aber der einzige Unterschied ist eine weitere Größe. Diese Größe stammt also aus dem vorher berechneten Ausdruck. Schließlich können wir diesen endgültigen Ausdruck Q drei mal Q vier erhalten. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke vom vorherigen Schritt unterschiedlich ist. Solche Unterschiede machen es schwierig, ihn anzuwenden. Es ist schwer, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist. Der Trainingsverfahren ist ähnlich wie bei der Schulung eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust bei jedem Zeitschritt optimieren, und hier verwenden wir auch diese Zeichen, um darzustellen, wann wir diesen Generierungsprozess beenden sollten. Und hier ist der Raum von Sequenz zu Sequenz anders, da der Raum bei jedem Zeitschritt unterschiedlich ist, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Wortschatzes ist. Es ermöglicht uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen aufzustellen. Wir führen also Experimente mit den häufig verwendeten Methodenproblemdatensätzen durch, MAWPS, Math twenty three K, MathQA und SWAM. Hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen. Unsere am besten funktionierende Variante ist Roberta Deductive Reasoner. Tatsächlich verwenden wir nicht BeamSearch, im Gegensatz zu den vorherigen Ansätzen mitze sind oft ein Baumbasiertes Modell. Insgesamt kann unser Argumentationsmodell dieses Baumbasierten Modells deutlich übertreffen, aber wir können sehen, dass die absoluten Zahlen bei MathQA oder SWAM nicht wirklich hoch sind. Wir untersuchen die Ergebnisse bei SWAM weiter, und dieser Datensatz ist eine Herausforderung, da der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie zum Beispiel das Hininzufügung von irrelevanten Informationen und zusätzlichen Mengen. In unserer Vorhersage stellen wir fest, dass einige der Zwischenwerte tatsächlich negativ sind. In diesen Fragen fragen wir zum Beispiel, wie viele Äpfel Jake hat, aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Töne und Stephen hat acht Töne, was völlig irrelevant ist. Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt. Und wir beobachten, dass diese beiden Ausdrücke tatsächlich ähnliche Zahlen haben. Wir haben tatsächlich ähnliche Punktzahlen. Wir können also diesen Suchraum einschränken, indem wir diese negativen Ergebnisse entfernen, damit wir die Antwort richtig machen können. Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert. Zum Beispiel verbessern wir für Vögel sieben Punkte und für das Roberta-basierte Modell zwei Punkte. Ein besseres Sprachmodell hat also eine bessere Sprachverständnisfähigkeit, sodass die Zahl hier. Hier ist es höher für Roberta und niedriger für Vögel. Und wir versuchen auch, die Schwierigkeit hinter all diesen Daten zu analysieren. Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Informationen angesehen werden kann. Hier können wir also sehen, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und der SWAMP-Datenmenge den größten Teil hat. Und hier zeigen wir auch die Gesamtleistung für diese Proben ohne ungenutzte Mengen. Die Gesamtleistung ist also tatsächlich höher als die. Und die Leistung ist tatsächlich höher als die Gesamtleistung. Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlechter ist als die Gesamtleistung. Für MAWPS haben wir nicht wirklich viele Datenfälle, also ignoriere ich diesen Teil einfach. Schließlich möchten wir die Interpretbarkeit durch ein Beispiel für das Zusammenbruch zeigen. Hier macht unser Modell also tatsächlich eine falsche Vorhersage im ersten Schritt. Wir können diesen Ausdruck tatsächlich mit dem Satz hier korrelieren. Wir denken, dass dieser Satz das Modell mit einer falschen Vorhersage irreführt. Wenn wir hier also weitere 35 Pflanzen pflanzen, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte. Wir versuchen, den Satz so zu ändern, dass die Anzahl der Birnen 35 weniger als die Apfelbäume ist. Wir machen es also, um genauere Semantik zu vermitteln, sodass das Modell die Vorhersage richtig machen kann. Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Verhalten des Modells zu verstehen. Um unsere Arbeit abzuschließen: Zunächst ist unser Modell ziemlich effizient und wir können interpretierbare Lösungsmethoden bereitstellen, und wir können ein wenig vorheriges Wissen als Einschränkung einbeziehen, was die Leistung verbessern kann. Das letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch auf andere Aufgaben, die mehrträgliches Denken beinhalten. Wir haben aber auch bestimmte Einschränkungen. Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein. Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung bei verschiedenen Zeitstufen unbalanciert ist, daher ist es auch ziemlich schwierig, eine Beam-Suche-Strategie anzuwenden. Das ist also das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich bin von der Maastricht University. Ich werde meine gemeinsame Arbeit mit Jerry vorstellen, die sich mit einer neuen Datensammlung für die Erfassung von gesetzlichen Artikeln befasst. Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen, aber die Mehrheit der Bürger hat wenig bis kein Knowledge über ihre Rechte und grundlegenden Rechtsprozesse. Daher werden viele gefährdeten Bürger, die sich die kostspielige Unterstützung eines Rechtsexperten nicht leisten können, ungeschützt oder schlimmer gesagt, ausgenutzt. Unsere Arbeit zielt darauf ab, die Grenze zwischen Menschen und dem Gesetz zu schließen, indem er ein effektives Retrievalsystem für Statutartikel entwickelt. Ein solches System könnte eine freie professionelle Rechtshilfegemeinschaft für unqualifizierte Menschen bieten. Bevor wir uns auf den Hauptbegriff dieser Arbeit konzentrieren, sollten wir uns zunächst mit dem Problem der Statutartikelretrieval befassen. Bei einer einfachen Frage auf einem Rechtsmaterial, wie zum Beispiel was ich riskieren kann, wenn ich professionelle Privatsphäre verletze, ist ein Modell erforderlich, um alle relevanten Statutartikel aus einem großen Bereich der der Gesetzgebung. Diese Information Retrieval Task kommt mit seiner eigenen Setz von Challenges. Erstens geht es mit zwei Arten von Linguage, der normalen natürlichen Sprache für die Fragen und der komplexen legalen Sprache für die Statuten zu tun. Diese Differenz in Languageverteilungen macht es für ein System schwieriger, relevante Kandidaten zu retrieveren, da es indirekt eine inhärente Interpretationssysteme erfordert, die eine natürliche Frage zu einer rechtlichen Frage, die die Terminologie der Statuten entspricht, translatiert. Besides, statutory Law ist nicht ein Stack von Independent Artikeln, die als eine vollständige Source von Informationen auf der Own behandelt werden können, wie neue Rezepte, zum Beispiel. Instead, es ist eine Struktur, eine Sammlung von legalen Provisionen, die eine ganze Bedeutung nur in der allgemeinen Kontext haben, das ist zusammen mit der supplementären Information aus den neighbouring Artikeln, den Feldern und Subfields, die sie belong zu, und ihrer Platz in der Struktur der Laub. Lastly, statutory Artikel sind ein kleiner Paragraph. was in den meisten Retrievalwerken die typische Retrieval-Einheit ist. Hier sind es lange Dokumente, die bis zu sechstausend Wörter schreiben können. Die recenten Entwicklungen in NLP haben enorme Interesse in vielen Rechtsakten wie Legal Judgment Prediction oder automatisierten Kontaktkontraktreview gespielt, aber die Statutory Article Retrieval hat sich aufgrund der Lack von groß und hochwertigen Labeldatensätzen in der Lage geblieben. In dieser Arbeit präsentieren wir eine neue French Native Citizen Centric Datenset zu studieren, ob ein Retrievalmodell die Effizienz und Reliabilität eines Legal Experts für die Task der Statutory Article Retrieval angeht. Unser Belgisch Statutory Article Retrieval Datsatsatz besteht aus mehr als 1.100 legalen Fragen, die von Belgischen Bürgern gestellt werden. Diese Fragen umfassen eine wide Reihe von Themen von Familie, Housing, Money, bis hin zu Work und Sozialversicherung. Each of them ist von erfahrenen Juristen mit Referenzen zu relevanten Artikel aus einem Corpus von mehr als 22.600 legal Artikeln aus Belgischen Codes of Law. Lassen Sie uns nun über die Art und Weise sprechen, wie wir diese Daten setzen. Erst, wir starten mit der Compilierung eines Large Corpus von legal Artikeln. Wir betrachteten 32 öffentlich verfügbare Belgischen Codes und extrahierten alle Artikel sowie die correspondenden Section Headings. Dann gingen wir mit Referenzen zu relevanten Statuten zusammen. To tun so, wir partnerten mit der Belgischen Law Firma. jedes Jahr um viertausend Emails von Belgischen Bürgern, die um Rat und persönliche Rechtsfragen bitten. Wir hatten die Glück, Zugang zu ihren Websites zu bekommen, wo ihr Team erfahrener Juristen belgische am häufigsten rechtlichen Fragen behandelt. Wir sammelten Tausende von Fragen, die mit Kategorien, Subkategorien und Rechtsreferenzen zu relevanten Statuten angepasst wurden. Lastlich durchgingen wir die Rechtsreferenzen und filterten die Fragen, die nicht Artikel in einem der Codes of Law we considered. Die remaining Referenzen wurden matched und zu den corresponding Artikel IDs von O Corpus. Wir eventuell endeten mit einem Jahrhundert und acht Fragen, die sich sorgfältig mit den IDs der relevanten Artikel aus unserem Large Corpus von twenty two thousand six hundred thirty three Statutory Articles labelten. In addition, jeder Frage kommt mit einer Mainkategorie und einer Konkatenation von Subkategorien. Jeder Artikel enthält eine Konkatenation der nachfolgenden Überschriften in der Struktur des Gesetzes. Diese zusätzlichen Informationen werden in der aktuellen Arbeit nicht verwendet, aber könnten für zukünftige Forschungen zur Rechtsinformationserfassung oder zur Klassifizierung von Rechtstexten interessant sein. Schauen wir uns einige Merkmale unserer Datensätze an. Die Frage ist zwischen fünf und vierundvierzig Wörter lang mit einem Median von vierzig Wörtern. Die Artikel sind viel länger mit einem Median von siebzig sieben Wörtern, wobei einhundertvierundvierzig davon mehr als tausend Wörter betragen. Die Länge eines von fünftausend siebenhundert und neunzig Wörtern. Wie bereits erwähnt, umfassen die Frage eine breite Palette von Themen, wobei etwa achtzig Prozent davon entweder Familie, Wohnung, Geld oder Justiz betreffen, während die restlichen fünfzehn Prozent entweder Sozialversicherung, Ausländer oder Arbeit betreffen. Die Artikel sind auch sehr vielfältig, da sie aus dreißig zwei verschiedenen belgischen Gesetzen stammen, die eine große Anzahl von illegalen Themen abdecken. Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Gesetze gesammelt wurden. Von den 22.633 Artikeln werden nur 1.612 als relevant für mindestens eine Frage in den Datensätzen angegeben, und etwa 80 % dieser zitierten Artikel stammen entweder aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafgesetz. Inzwischen werden 18 von 32 Gesetzen weniger als fünf Artikel als relevant für mindestens eine Frage angege, die durch die Tatsache verursacht wird, dass diese Code weniger auf individuelle und ihre Anliegen fokussiert. Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünfundzwanzig Prozent von ihnen sind mehr als fünfmal citiert. Mit unseren Data sets benchmarken wir verschiedene Retrievalapproaches, einschließlich Lexical und Densarchitektur. Given eine query in einem Artikel, eine Lexicalmodelle assigniert eine Score zu den queryartikelpaaren. Durch die Berechnung der Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfrage-Terme. Wir experimentieren mit den Standard-TFIDF- und BM25-Rankingsfunktionen. Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten. Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die die semantische Beziehung zwischen Abfragen und Artikeln erfassen kann. Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert. und berechnen einen relevanten Punkt zwischen einem Artikelpaar der Abfrage anhand der Ähnlichkeit ihrer Eingebettungen. Diese Eingebettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Eingebettungsmodells. Zunächst untersuchen wir die Effektivität siamesischer B-Encoder in einer Zero-Shot-Evaluierungs-Einrichtung, was bedeutet, dass vorgebildete Word-Eingebettungsmodelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden. Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und Fastastex und kontextabhängige Embeddingmodelle, nämlich Roberta und speziell Kamembert, ein französisches Roberta-Modell. Darüber hinaus trainieren wir unsere eigenen Kamembert basierenden Biencoders auf allen Datenmengen. Beachten Sie, dass wir für das Training mit den beiden Arten der Biencoder Architektur experimentieren. Siamese, das ein einzigartiges Wort-Embeddingmodell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraum mappiert. Und Tutor, das zwei unabhängige Wort-Embeddingmodelle verwendet. Wir haben zwei Independent Word Embedding Models, die den Query und Artikel separat in verschiedene Embeddingsphasen codieren. Wir experimentieren mit Mean, Max und CLS Pooling sowie Dot Product und Cosine für die Computing-Similaritäten. Hier sind die Ergebnisse unserer Baseline auf dem Testset, mit den Lexikonmethoden oben, den Siamese BE Encoders evaluiert in einem Zero Shot Setup in der Mitte, und den Fein Tun BE Encoders unten. Overall, die Fein Tun BE Encoders übertragen alle anderen Baselines. seine Siamese-Variante auf RECOLAT 100, aber ähnlich auf den anderen Metriken abschneidet. Obwohl BM 25 den trainierten Biancoder erheblich unterlegen hat, deutet seine Leistung darauf hin, dass es immer noch eine starke Grundlage für Domain-spezifische Rückholung ist. Bei der Zero Shot Evaluation des Siamese Biancoders finden wir, dass die direkte Verwendung der Embeddings eines vortrainierten Kamembert-Modells ohne Optimierung für die Informationsaufnahmeaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt. Der Word-to-Vec-basierte Biancoder übertraf die Fastex- und Vogelbasierten Modelle deutlich, was darauf hindeutet, dass möglicherweise vor-train-Word-Einbettungen für die Aufgabe angemessener sind als Charakter- oder Unterword-Einbettungen, wenn sie von Anfang an verwendet werden. Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Verbesserungsmöglichkeiten im Vergleich zu einem geschickten Experten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann. Lassen Sie uns mit zwei Limitationen von allen Datensätzen beginnen. Erstens ist der Corpus von Artikeln limitiert zu denen, die aus den dreißig zwei betrachteten Belgischen Codes erfasst werden, was nicht den gesamten Belgischen Law abdeckt, da Artikel aus Dekrees, Direktives und Ordinanzen enthalten sind. Durch die Datensatzkonstruktion werden alle Referenzen zu diesen unkollektierten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Fragment der initialen Anzahl relevanter Artikeln enthalten. Dieser Informationlaus impliquiert, dass die Antwort in den remaining relevanten Artikelnkel könnten incomplete sein, obwohl es immer noch vollständig appropriate ist. Second, wir sollten merken, dass nicht alle Rechtsfragen mit Statuten alone beantwortet werden können. For instance, die Frage kann ich meine Tenants evicten, wenn sie zu viel Noise machen, könnte nicht eine detaillierte Antwort in statutory Law enthalten, die eine spezifische Noise Threshold at which Eviction ist. Insted sollten die Landlage wahrscheinlich mehr auf Fallslaw und Präceden ähnlich wie der aktuelle Situation finden. Zwei Parteien pro Woche bis 2 Uhr morgens. Daher sind einige Fragen besser als andere für die Aufgabe der gesetzlichen Artikelerfassung geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen. Wir hoffen, dass unsere Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle der gesetzlichen Artikelerfassung weckt, die den Zugang zur Justiz für alle verbessern können. Sie können sich unsere Arbeit Datensätze und Code unter den folgenden Links ansehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir sind froh, unsere Arbeit auf VALS, einem Taskindependenten Benchmark für das Testen von Vision und Language Models mit spezifischen linguistiken Phänomenen zu präsentieren. Warum haben wir uns die Trouble in der Setzung dieses Benchmarks gemacht? Nun, während der letzten Jahre haben wir eine explosion von Transformer basierten Vision und Language Models, die auf große Mengen von Image Textpaaren geprägt sind. Each dieser Modelle pusht State of the Art auf Vision und Language Tasks, wie z. B. visuelle Fragen Sinnesrechnung, Bildretrieval, Phrase-Grundung. Wir haben also eine Nachricht, die Akuragen auf diesen spezifischen Benchmarks steigern, aber wissen wir, was die Modelle tatsächlich gelernt haben? Was hat ein Vision und Language Transformer verstanden, als er eine High Score für dieses Bild und diesen Satz zugewiesen hat und eine Low Score für dieses Bild? Fokusieren Vision und Language Models auf das Richtige oder konzentrieren sie sich auf Biasen? wie gezeigt durch vorherige Arbeit. Um mehr Licht auf diesen Aspekt zu senden, propellieren wir eine mehr task agnostic direction und einführen WALS, das die Sensitivität von Vision und Language Models zu spezifischen linguistiken Phenomenen, die sowohl die linguistic als auch die visuelle Modalitäten beeinflussen. Wir targen Existenz, Pluralität, Zählung, Spatialrelationen, Aktionen und Entity Coreference. Aber wie testen wir, ob die Vision und Language Models diese Phenomena erfasst haben? Foiling, eine Methode, die vorher für Vision und Language Models, nur für Nanphrasen von Ravi Shakar und Kollaborators und auf Counting von Asin previous worked. Foiling basically means, dass wir den Caption of an Image und einen Foil produzieren, indem wir den Caption so verändern, dass er nicht die Image anymore beschreibt. Und wir machen diese Phrasealterations, indem wir uns auf sechs spezifische Pieces wie Existenz, Pluralität, Counting, Spatialrelations, Actions, und Entity Coreference. Jede Piece kann aus einem oder mehreren Instrumenten bestehen, in dem Fall, dass wir mehr als eine interessante Möglichkeit gefunden haben, FOIL instanzen zu erstellen. Zum Beispiel haben wir in der Fall der Aktionspiece zwei Instrumente, einen in dem das Action verb mit einer anderen Action geändert wird und einen in dem Actants gewechselt werden. Zählen und Coreferenz sind auch Pieces, die mehr als eine Instrumenten haben. Und wir erstellen diese FOILs, indem wir unserstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererweit validierten Sätze sind. Dies ist nicht einfach zu tun, weil eine Foiled Caption weniger wahrscheinlich ist als die ursprüngliche Caption. Zum Beispiel, though it's not impossible, ist es statistisch weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann, und Largevision und Language Models könnten dies erkennen. Daher müssen wir, um valid Foils zu erhalten, Action unternehmen. Erstens, wir machen uns auf Strong Language Models zu propellieren. Zweitens, wir verwenden Natural Language Inference oder NLI, um Foils zu filtern, die noch beschreibiben das Bild immer noch, da wir bei der Konstruktion von FOILs sicherstellen müssen, dass sie das Bild nicht beschreiben. Um dies automatisch zu testen, wenden wir eine natürliche Sprachinferenz mit der folgenden Begründung an. Wir betrachten ein Bild als die Premise und seine Beschriftung als die damit verbundene Hypothese. Darüber hinaus betrachten wir die Beschriftung als die Premise und die FOIL als ihre Hypothese. Wenn ein NLI-Modell die FOIL zu widersprechen oder neutral zu den Beschriftungen zu sein, nehmen wir dies als Indikator für eine gültige FOIL. Wenn wir die Foil zu beentalten, kann es nicht eine gute Foil sein, da es durch Transitivität eine truthliche Beschreibung der Image geben wird und wir diese Foils ausfiltern. Aber dieser Prozess ist nicht perfekt. Es ist nur ein Indikator für valide Foils, daher als eine dritte Möglichkeit für die generierung von valid Foils, wir verwenden Humananannotators, um die Daten zu validieren, die in Valse verwendet werden. Also, nach Filtering und Human Evaluation, wir haben so viele Testinstanzen wie in dieser Tabelle. Note, dass Valse nicht trainierend Daten liefert. Aber nur Testdaten, da es sich nur um einen Benchmark für Null-Shot-Tests handelt. Es ist darauf ausgelegt, die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vor-Training-Aktivität zu nutzen. Die Feinabstimmung würde es Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen. Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen einschlagen. Und wie wir sagten, sind wir daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vor-Training-Aktivität haben. Wir experimentieren mit fünf Vision- und Sprachmodellen auf WALS, nämlich mit CLIP, Wilbert, Wilbert Kelvin I und Visual Bert. Zwei unserer wichtigsten Evaluierungsmetriken sind die Accuracy der Modelle in der Klassifizierung von Image Sentenzenpaaren in Untertitel und Foils. Perhaps für dieses Video mehr relevant, wir werden unsere permissive Metrik, die Paarwise Accuracy, die messen, ob die Image Sentenz alignment score für die korrekte Image Textpaar als für ihre Foilpaar ist. Für mehr Metriken und Ergebnisse auf themen, doch checken Sie unsere Papier. Die Ergebnisse mit Paarwise Accuracy sind hier und sie sind konsistent mit den Ergebnissen, die wir von den anderen Metriken bekommen haben. Es ist, dass die besten Zero Shot Performance durch Wilbert zwölf in one, gefolgt von Wilbert, Alex Mert, Clip, und schließlich Visual Bird. Es ist notabel, wie Instrumente centered on individuelle Objekte wie Existenz und Nounphrases fast solviert werden, wobei Wilbert zwölf in one, highlighting, dass Models ableistisch genannte Objekte und ihre Präsenz in Images identifizieren können. Allerdings können none der remaining Pieces in unseren adversarialen Foiling-Settings reliably solviert werden. Instrumenten, dass Vision und Language Models Trouble distinguisieren, referenzieren zu single versus multiple Objekten oder in einem Image. Die Relation Piece zeigt, dass sie Schwierigkeiten haben, eine named spatiale Relation zwischen Objekten in einem Image zu klassifizieren. Sie haben auch Trouble, Aktionen zu distinguieren und ihre Partizipanten zu identifizieren, selbst wenn sie durch Plausibility bias sind, wie wir in der Aktionspiece sehen. Aus der Referenzpiece finden wir, dass das Tracing multiple Referenzen zu dem gleichen Objekt in einem Image durch Pronouns auch für Vision und Language Models. Als eine Sanity Check und weil es ein interessantes Experiment ist, benchmarken wir auch zwei Textonlegermodelle GPT one und GPT two, um zu assessieren, ob Valse solvable durch diese Unimodalmodelle ist, indem wir die Perplexität der korrekt und der foiled Caption, keine Image hier, und die Entry mit der lowest Perplexität. Wenn die Perplexität höher für die Foil ist, dann nehmen wir dies als eine Indikation, dass die foiled Caption möglicherweise von Plausibility bias oder anderen linguistiken Biasen leidet. Und es ist interessant zu sehen, dass in einigen Fällen Die Textmodelle nur GPT haben die Plausibilität der Welt besser erfasst als die Vision und Language Models. Zusammenfassend ist VALSE ein Benchmark, das die Lensen von Linguistikkonstrukten verwendet, um die Community zu helfen, Vision und Language Models zu verbessern, indem sie ihre visuellen Grounding-Fähigkeiten hart testen. Unsere Experimente zeigen, dass Vision und Language Models namensgelegene Objekte in ihrer Präsenz in Bildern gut identifizieren, wie gezeigt durch das Existenzstück, aber es schwerwiegt, ihre Interdependence und Relationships in visuellen Szenen zu genehmigen, wenn sie gezwungen sind, linguistic Indikatoren zu respektieren. Wir möchten die Community wirklich ermutigen, Valse zur Messung des Fortschritts hin zur Sprachbasis mit Vision- und Sprachmodellen zu verwenden. Und noch mehr, Valse könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von Valse getesteten Aspekte hilft. Wenn Sie interessiert sind, sollten Sie sich die Valse-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamisara von der University of Tokio. Ich werde eine Papier entitelt RNSAM, ein großes Dasein für automatische Restnoturation bei der Commit Dog Summization. Ich werde in dieser Ordnung erklären. Erst, ich werde die automatische Restnoturation, die wir in dieser Research arbeiten, einführen. ReleaseNode ist ein technischer Dokument, das die Changes mit jedem Release von einem Softwareprodukt zusammenfasst. Das Image zeigt die ReleaseNode für Version zwei. sechs. vier der GBUJS Library. Diese Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consumierend zu erstellen. Daher wird es sehr nützlich sein, automatisch hochqualitäre Release Nodes zu generieren. Ich werde auf zwei frühere Researchers auf automatische Release Node Generation eingehen. Der erste ist ein System namens Arena, das in twenty fourteen erstellt wurde. Es ergreift eine Rule basierende Approach, zum Beispiel, indem es die Change Extractor verwendet, um Code differenzen zu extrahieren. Bibliotheksänderungen und Dokumentenänderungen von den differenzierten Releases und schließlich kombinieren. Die meisten erkennbaren Funktionen dieses Systems sind die Issue Extractor in der oberen rechten Ecke, die mit Jira, dem Issue Toco System, verknüpft und nur für Projekte verwendet werden kann. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden. Die zweite ist Griff, die Entry angeboten wurde in twenty twenty. Sie ist auf dem Internet und kann durch PIPSTEMENSSER Dieses System hat ein einfaches Lernbasis für Textklassifikation und erhält eine von fünf Rabellen, die Funktionen oder Bugfixen für jedes Input Commit-Message enthalten. Das Bild ist eine Sample-Usage, die eine korrekte oder Bugfixen-Rabelle enthält. Die gerade erstellten Rabellen sind ziemlich klein, etwa fünftausend, und werden in den Experimenten beschriebenen darüber gezeigt. Die Leistung des Textklassifikationsmodells ist nicht hoch. Ich präsentiere zwei related Researchers, aber es gibt Probleme mit begrenztem Erwerb und geringen Daten. und Scar State Resources. Unser Papier löst diese beiden Probleme und automatisch generiert High Quality Releasing Notes. Für das limitierte Applicability Programm, wir propagieren eine High Quality Classifier Summarization Methode, die nur Committee Message als Input verwendet. Diese Methode kann für alle English Repositories verwendet werden. Für das zweite Problem der Scar State Resources, wir bauen RL und SAM DSET konsistent mit etwa achtzig zwei Tausend Pieces von Daten, die von öffentlichen GitHub API. Next, ich beschreibe unser Desert. Hier ist ein Beispiel für Daten. Die linke Seite ist ein Commit Message und die rechte Seite ist die RISE Nodes. Die RISE Nodes sind Raveled als Implement, Bug fixes, etc. Wir haben eine Task setup, die die Commit Messages als Input und die Raveled RISE Nodes aufwendet. Dies kann als eine Summarization Task bezeichnet werden. Wir haben vier Raveled Features, Implement, Bug fixes, Duplications, Removables und Breaking Changes. Diese wurden basierend auf PBR research und anderen Faktoren. Die RISE Noten auf der bottom right und extrahiert von den RISE Noten auf der bottom left. At diesem Zeitpunkt ist es notwendig, die vier Rabels zu detektieren, die in der Passage sind, aber die Rabels sind nicht immer konsistent mit jeder Repository. Zum Beispiel, die Improvements Rabels inklusive Improvements, Enhancements, Optimisations und so weiter. Wir haben eine Vokabularliste oder Studie Rabels für jeden dieser Notation. variations. Verwenden Sie es, um die Restknoten zu erkennen und den Text der Restknoten zu korrigieren. Als nächstes kommt eine Kommittemessage. Kommittemessagen sind nicht zu jeder Rest. Wie in der image below, wenn die aktuelle Rest Persönlich 2.5219 ist, müssen wir die vorherige Rest Persönlich 2.5218 identifizieren und einen Tiff erhalten. Dies ist ein bisschen tedious und es ist nicht genug, nur eine Rest der Restknoten zu erhalten. Und wir haben die Vorhand nach. Wir haben eine heuristic Matching Blue erstellt, um die vorherigen und nächsten Persönlichkeiten zu erhalten. Dasset Analysis In der End, 7.200 Repositories und 82.000 PSO wurden korrektiv. Außerdem ist die average Anzahl von ReleaseNode Tokens 63, was für eine Summarisation Task ziemlich hoch ist. Außerdem ist die Anzahl von Unique Tokens ziemlich groß, also 8.830.000. Dies ist auf die große Anzahl von Unique Kosten und Methoden zurück namens in der Repository. Next, ich werde explain die proposierte Methode. Das Crosswise Extractive and Abstractive Summarization Model besteht aus zwei neuronalen Modules, einem Classifier, der Bot oder Code Bot und einem Generator, der Bot verwendet. Erstens, GAS verwendet einen Classifier, um jedes Committee Message in fünf Risnode Classes, Features, Improvements, Bugfixes, Duplications, Plus, und andere. Die Committee Messages klassifiziert als andere oder diskutiert. Dann GAS wendet einen Generator zu den vier Rabelschnitteln unabhängig und generiert RISE NOTE für jeden Kurs. In diesem Zusammenhang sind die direkten Korrespondenzen zwischen Commit Messages und RISE NOTE nicht bekannt. Daher, um den Kurs zu trainieren, wir zwar Rabelschnitteln zu jedem Input Commit Message verwenden, indem wir die ersten zehn Charaktere für jedes Commit Message verwenden. Wir modellieren den Kurs abstruktiven Summarisierungsansatz durch zwei verschiedene Methoden. Das erste Modell, das wir als GAS Single Sync konsist von einer Sync zwei Sync Network und generiert eine Sync Long RISE Node Tagist, geben eine Konkurrenz von Input Committee Messages. Die Output Tagist kann in Crosswise Segment basierend auf speziellen Cross Specific Endpoint Symbols unterteilt werden. Die zweite Methode, Methode, die wir CSMUCH, besteht aus vier verschiedenen Sync zwei Sync Networks, jeder von denen zu einer der RISE Node Classes entspricht. Okay, lassen Sie mich das Experiment erklären. Fünf Methoden wurden GS, GS Single, GS Marge, Russelling und previous studied Griff. Regarding Abortion, in einigen Fällen, diese Noten sind in multiple Sentenzen. Da es difficil ist, die Nummer von Sentenzen zu erkennen, sind sie kombiniert mit Spaces und treaten als ein langer Satz. Der Blue ist penalisiert, wenn das System einen kurzen Satz erfährt. Diese Penalty resultiert in einem loweren Blue Value in den Experimenten der Results describiert. Finally, wir auch die Spezifität erkennen, weil Rouge und Brew nicht erkennen können, wenn die Rouge Nodes leer sind. Eine hohe Spezifität bedeutet, dass die Modellkorrektie auspackt ist, in denen die Rouge Nodes leer sind. Hier sind die Ergebnisse. Da der Daseit Emailadresse, Hashbarrieren, etc. enthält, haben wir auch den Green Daseit erkannt, der sie ausschließt. GAS und GAS erreichten Rouge Error Scores mehr als zehn Punkte höher als die Baselines. Auf dem grünen Testset stieg die Score-Gap zwischen der vorgeschlagenen Methode und der Basis auf mehr als zwanzig Punkte. Diese Ergebnisse zeigen, dass GAS und GAS signifikant effektiv sind. GAS erreichte eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Klassifierers und eines Generators effektiv ist und das Training des Klassifierers mit Pseudoberseiten. Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, da der Klassifier sich auf das Sekten relevanter Kommittemechanismen für jede Klasse konzentrieren kann. Xia ist viel zu höheren Ruder als Xia single, suggesting, dass es auch effektiv ist, unterschiedliche perspektive Summarisationsmodelle für jedes Nodecraft zu entwickeln. Hier sind Erronnas. Xia's Methods tend to output shorter Sentenzen als humanen Referenz Sentenzen. In der Figur auf der rechten Referenz Sentenzen hat drei oder vier Sentenzen, während Xia nur eins hat. Der Grund für diese Modellrücktanz ist, dass in den Trainingdaten nur 33 Prozent der Sentenzen sind in der Features Rabel und 40 Prozent in der Improvements Rabel. Für die More CS Methods können nicht akurat mit Noten ohne zusätzliche Informationen generiert werden. Das Top Exempel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommittemessage und die Komplettesentence kann nicht generiert werden, ohne dass es sich auf die correspondente Periodrequest oder Issue bezieht. Das Beispiel below zeigt, dass die zwei Kommittemessagen in der Input related und sollten kombiniert werden. Aber es versucht dies zu tun. Schließlich eine Konklusion. Wir haben eine neue DSET für automatische Rezensionsschnittgenerierung erstellt. Wir haben auch die Aufgabe erstellt, Kommentarn zu enthalten und sie so zu summarisieren, dass sie für alle Projekte in Englisch anwendbar ist. Unser Experiment zeigt, dass die vorgeschlagene Methode weniger Noisy Rezensionsschnittgenerierung bei höherer Abdeckung als die Basisrate erzeugt. Bitte schauen Sie sich unsere DSET auf GitHub an. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle. Heute werde ich unsere Forschungsarbeit Lernen zu reisen deduktiv, Methodenproblemlösung als komplexe Rasen-Extraktion vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Zahl stammt aus dem POWN-Papier, in dem sie Anweisungen zur Lösung des Methodenproblems in einem Fluch-Learning-Szenario ausführen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite können wir sehen, dass wir, wenn wir einige Beispiele nur mit Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch noch mehr Beschreibungen geben, kann das Modell die Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, als Ausgabe interpretierbares Mehrstufenrechnungsverfahren zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken auch, dass ein Methodenproblem eine einfache Anwendung zur Bewertung solcher Argumentationsfähigkeiten ist."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier müssen wir also in unserer Problemkonfiguration, angesichts der Fragen, diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser besonderen Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Größen bekannt ist"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren aufgeteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Eine frühere Arbeit im Lösungsproblem der Methode kann also tatsächlich in Sequenz- und Baummodell kategorisiert werden."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenzmodelle konvertieren den Ausdruck also in eine bestimmte Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ziemlich einfach umzusetzen und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil ist, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell und es fehlt an Interpretabilität für die Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Direction noch ziemlich populär, weil der Transformermodell"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also die Operatoren weiter, bis wir die Lifts erreichen, die die Größen sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt, aber es ist eigentlich ganz entgegengesetzt, weil wir zuerst den Operator generieren und dann am Ende die Größen generieren."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens enthält es auch einige wiederholte Berechnungen."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck hier ansehen, wird acht mal drei plus drei tatsächlich zweimal erzeugt. Aber tatsächlich sollten wir die Ergebnisse verwenden"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und in interpretierbaren Methoden lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diesen Teiler erhalten, der 27 ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir bei diesem dritten Schritt tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Okay. Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schritts tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als unser Anfangszustand ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Operatoren von QY bis QJ aus, und dieser Ausdruck ist tatsächlich gerichtet."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "So, wir haben hier auch Subtraction-Wert, um die entgegengesetzte Richtung zu repräsentieren."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie bei der Strahlungsauffnahme."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es in den nächsten Zustand hinzu, um eine neue Menge zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folien visualisieren also tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zuständen immer wieder Ausdrücke hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Sprachmodell, das Vögel oder Robetts sein kann, und dann kodieren wir den Satz und erhalten diese Mengenrepräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengen darstellen, können wir mit der Schlussfolgerung beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q4 multipliziert wird."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Anweisung, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist. Dann wenden wir ein Fit-Forward-Netzwerk an, das vom Operator parametriert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksrepräsentation Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Schlussfolgerung möglicherweise auch den falschen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier entspricht also jeder möglichen Ausdruck dreimal so viel wie die Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchbereich entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir noch eine Menge mehr haben."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe stammt aus dem vorherigen berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir diesen letzten Ausdruck Q3 erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke von dem vorherigen Schritt unterschiedlich ist."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede machen es schwierig, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsmethode ist ähnlich wie bei der Schulung eines Sequenzmodells, bei dem wir den Verlust bei jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch diese Tao, um darzustellen, wann wir diesen Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz anders, weil der Raum bei jedem Zeitpunkt anders ist, während es im traditionellen Sequenz- zu-Sequenz-Modell die Anzahl des Wortschatzes ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht es uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen zu verhängen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen also Experimente mit den häufig verwendeten Method-Problem-Datensätzen durch, MAWPS, Math23K, MathQA und SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Variante ist also Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir BeamSearch nicht, im Gegensatz zu offensichtlichen Ansätzen mit BeamSearch."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Okay, die besten Ansätze sind oft ein Baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Vernunft also dieses Baumbasierungsmodell deutlich übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MatQuery oder SWAM nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse weiter."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist eine Herausforderung, weil der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. irrelevante Informationen und zusätzliche Mengen hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Also, in unserer Vorhersage finden wir, dass einige der intermediären Werte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Pitchs und Stephen hat acht Pitchs, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse als negativ entfernen, damit wir die Antwort richtig machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert und bei dem Roberta-Basemodell tatsächlich zwei Punkte verbessert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat also bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Bert niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information angesehen werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der ungenutzten Mengen haben und der SWAMP-Datensatz den größten Teil enthält."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen ist die Gesamtleistung tatsächlich höher als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlimmer ist als die, äh, viel schlimmer als."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für MAWPS haben wir nicht wirklich viele Desk-Cases, also ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretationsfähigkeit durch ein Beispiel für die Zusammenstoßpartizierung zeigen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also tatsächlich eine falsche Vorhersage im ersten Schritt."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren, oder?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben also, dass dieser Satz das Modell in eine falsche Vorhersage führen könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man hier also noch 35 plant, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu ändern, dass er so aussieht wie die Anzahl der Birnenfäden fünfundfünfzig weniger ist als die Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen es also so, dass es genauere Semantik vermittelt, damit das Modell die Vorhersage richtig machen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell eigentlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können eine interpretierbare Lösungsmethode bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige vorherige Kenntnisse als Konstrakt einbeziehen, was uns helfen kann, die Leistung zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur für Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch für andere Aufgaben, die mehrtretende Argumentation beinhalten."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung in verschiedenen Zeitzonen unbalanciert ist, daher ist es auch ziemlich schwierig, Beam-Suche anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also das Ende des Vortrags und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Maastricht University."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein Johannes Werk mit Jerry vorstellen, das sich mit einem neuen Datensatz für die Abholung von gesetzlichen Artikeln befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein wesentlicher Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat wenig oder kein Wissen über ihre Rechte und grundlegenden Rechtsverfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Ergebnis sind viele vulnerable Bürger, die sich nicht die kostbare Assistance eines Legal Experts erwarten können, unprotegt oder worstens, exploitiert."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Lücke zwischen Menschen und dem Gesetz zu schließen, indem wir ein effektives Rückholsystem für gesetzliche Artikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte für unqualifizierte Menschen einen kostenlosen professionellen Rechtshilfenservice bieten."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem der statutarischen Artikelabholung."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ich eine einfache Frage zu einem rechtlichen Thema stelle, wie zum Beispiel: Was mache ich, wenn ich die professionelle Vertraulichkeit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetz zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe zur Informationserfassung bringt eine ganze Reihe von Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst geht es um zwei Sprachtypen."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "für die Fragen eine gängige natürliche Sprache und für die Statuten eine komplexe rechtliche Sprache."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in den Sprachverteilungen machen es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die mit der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das gesetzliche Recht kein Stapel unabhängiger Artikel, die als vollständige Informationsquelle an sich behandelt werden können, wie zum Beispiel Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Insted ist es eine Strukturkollektion von legalen Provisionen, die nur in der allgemeinen Kontext betrachtet sind, zusammen mit den zusätzlichen Informationen aus den neighbouring Artikeln, den Feldern und Subfeldern, zu denen sie gehören, und ihrer Platz in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, statutory Articles RN small paragraph, was usuell die typische Retrieval Unit in Most Retrieval Works ist."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Jahre dauern können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich NLP haben großes Interesse an vielen rechtlichen Aufgaben wie der Vorhersage von Rechtsentscheidungen oder der automatisierten Überprüfung von Vertragsverträgen weckt."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabholung ist jedoch aufgrund des Mangels an großen und hochwertigen gekennzeichneten Datensätzen größtenteils unberührt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir ein neues französisches, zentrales, zentrales Datenkett, um zu untersuchen, ob ein Rückholmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten für die Aufgabe der Statutorienartikelrückholung nähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Our Belgian Statutory Article Retrieval Data Sets consist von mehr als einem Jahrzehnt Liter."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnraum, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen hat von erfahrenen Juristen mit Referenzen zu relevanten Artikeln aus einem Corpus von mehr als twenty zwei Tausend sechshundert."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Codes of Law. Lassen Sie uns nun über die Erstellung dieser Datsätze sprechen."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir mit der Zusammenstellung eines großen Korpus an rechtlichen Artikeln begonnen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich verfügbare Belgische Codes und alle Artikel sowie die entsprechenden Abschnittshebungen entnommen."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf relevante Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich, auf ihre Websites zuzugreifen, wo ihr Team von erfahrenen Juristen Belgien's am häufigsten rechtlichen Probleme behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen zusammengestellt, mit Kategorien, Subkategorien und rechtlichen Verweisen auf relevante Statuten."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, wir passten die legalen Referenzen und filterten die Fragen aus, die Referenzen nicht Artikel in einem der Codes of Law wirkten."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Verweise wurden in die entsprechenden Artikel-IDs aus O Corpus abgestimmt und umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.108 Fragen, jeder sorgfältig mit den IDs der relevanten Artikel aus dem Buch."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich enthält jede Frage eine Hauptkategorie und eine Konkatenation von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel kommt mit einer Konkatenation ihrer nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzliche Information wird nicht in der Präsentation verwendet, aber sie könnte für zukünftige Research auf Legal Information Retrieval oder Legaltext Classification interessant sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale unserer Datensätze an."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Frage ist zwischen fünf und vierundvierzig Wort lang, mit einem Median von vierzig Wort."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer medianen Länge von sechzig sieben Wörtern, mit 140 Gramm."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei von ihnen, die eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine Vielzahl von Themen, von denen etwa 85 % entweder über Familie, Wohnraum, Geld oder Gerechtigkeit betraf."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Während die restlichen fünfzehn Prozent entweder mit der Sozialversicherung, Ausländern oder Arbeit zu tun haben."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr diverse, da sie aus dreißig zwei verschiedenen Belgischen Codes kommen, die eine große Anzahl von illegalen Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel aus jedem dieser belgischen Codes."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Aus den twenty two thousand six hundred thirty three Artikeln, nur eintausend sechs hundred twelve sind als relevant zu at least einem"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "nur eine Frage in den Daten sätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafverfolgungsgesetz."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen enthalten achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann durch die Tatsache erklärt werden, dass diese Codes weniger auf Einzelpersonen und ihre Anliegen fokussieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünf Prozent von ihnen sind in der"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen benchmarken wir verschiedene Rückholmethoden, einschließlich lexikalischer und denser Architektur."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrageartikelpaar eine Punktzahl zu, indem es die Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfragezeiten berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM-25-Rankingfunktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert und eine relevante Punktzahl zwischen einem Abfrage-Artikelpaar anhand der Ähnlichkeit ihrer Eingebettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit siamesischer Biancoder in einer Nullschussbewertung, was bedeutet, dass vorgebildete Word-Embedding-Modelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, und kontextunabhängigen Einbettungsmodellen, nämlich Roberta und genauer gesagt Camembert, das ein französisches Roberta-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes Camembert-basiertes Modell. Beyond quoters."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beispiele auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Flavors der Bianco architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Query und den Artikel in einem gemeinsamen Densivektorraum mappiert, und Tutor, das zwei unabhängige Word-Embedding-Modelle verwendet, die die Query und den Artikel separat in zwei verschiedene Embedding-Spaces codieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit dem Pooling von Mittel, Max und CLS sowie mit dem Punktprodukt und dem Kosinus für die Rechengelähnungen."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Ausgangslinie auf den Testsätzen."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Dann mit den lexikalischen Methoden oben, den Siamese-B-Encodern, die in einer Null-Schuss-Einrichtung evaluiert wurden, und den fein abgestimmten B-Encodern unten."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchore alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two Tower Modell verbessert sich gegenüber seiner Siamese-Variante auf Recallat one hundred, aber es funktioniert ähnlich bei den anderen Metriken."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five den trainierten Biancode erheblich unterlegen hat, zeigt seine Leistung, dass es immer noch eine starke Grundlage für Domain Specific Retrieval ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Was die Nullschussbewertung des siamesischen Biancoders betrifft, stellen wir fest, dass die direkte Verwendung der Eingebettungen eines vorgebildeten Kamembert-Modells ohne Optimierung für die Informationsabholungsaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir festgestellt, dass der Word-Tuec-basierte Biancoder den Vastex- und Vogelbasierten Modell deutlich übertrifft, was darauf hindeutet, dass möglicherweise vor-train-Word-Level-Embeddings für die Aufgabe besser geeignet sind als Charakter- oder Unterword-Level-Embeddings, wenn sie von vorn verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Möglichkeiten für Verbesserungen im Vergleich zu einem geschickten Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns mit zwei Einschränkungen aller Datensätze abschließen."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf die aus den 32 belgischen Gesetzen gezogenen beschränkt, die nicht das gesamte belgische Gesetz abdecken, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Referenzen zu diesen ungesammelten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl relevanten Artikeln erhalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsloss impliziert, dass die Antwort in den verbleibenden relevanten Artikeln unvollständig sein könnte, obwohl sie immer noch vollständig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Kann ich meine Mieter vertreiben, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Might not have a detaillierte Antwort innerhalb des gesetzlichen Gesetzes, das eine spezifische Noise-Threshold quantifiziert, bei der Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich mehr auf die Rechtsprechung vertrauen und Präzedenzfälle finden, die ähnlich zu ihrer aktuellen Situation sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Tenant zwei Parties pro Woche und tut es."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser als andere für die gesetzliche Artikel-Retrieval-Tasche geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass all diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur Berechnung von gesetzlichen Artikeln weckt,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Papier, Datset und Code unter den folgenden Links sehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorzustellen, einem unabhängigen Benchmark, der für die Testung von Vision- und Sprachmodellen mit bestimmten sprachlichen Phänomenen gedacht ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark festzulegen?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformer-basierten Vision- und Sprachmodellen gesehen, die auf große Mengen an Bild-Textpaaren vorgebildet wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle drängt die Moderne in der Vision und Sprachaufgaben wie der Antwort auf visuelle Fragen, der visuellen Sinnesreasoning, der Bildherstellung und der Phrase-Grundung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Nachricht erhalten. Die Genauigkeit dieser für die Aufgabe spezifischen Benchmarks steigt stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprachtransformer verstanden, als er diesem Bild und diesem Satz eine hohe Punktzahl zugewiesen hat, um es zu vereinbaren?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und der niedrige Punkt für diesen."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie durch frühere Arbeiten gezeigt?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf diesen Aspekt zu werfen, schlagen wir eine tauschfreundlichere Richtung vor und führen VALS ein, das die Empfindlichkeit von Seh- und Sprachmodellen auf spezifische sprachliche Phänomene testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Vielfalt, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenzen ab."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen festgehalten haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor nur für Vision und Sprachmodelle von Ravi Shakar und seinen Mitarbeitern für Nomenphrasen angewendet wurde, und bei der Zählung von uns in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde, dass wir den Bildunterschrift eines Bildes nehmen und einen Foil erzeugen, indem wir den Unterschrift so verändern, dass er das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Wir ändern diese Phrase, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenz, wobei jedes Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, FOIL-Instanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir im Fall des Aktionsstücks zwei Instrumente, eines, bei dem das Aktionsverb mit einer anderen Aktion geändert wird, und eines, bei dem die Spielzeuge ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Ko-Referenzen sind auch Stücke, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schaffen diese Fehler, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererseits gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach, da eine fehlerhafte Beschreibung weniger wahrscheinlich sein kann als die ursprüngliche Beschreibung."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es zwar nicht unmöglich, statistisch gesehen ist es weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann Pflanzen schneiden, und große Vision- und Sprachmodelle könnten dies aufgreifen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um gültige Folien zu erhalten, müssen wir daher Maßnahmen ergreifen."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir starke Sprachmodelle, um FOILs vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir die Inferenz durch natürliche Sprache oder kurz NLI, um Folien zu filtern, die das Bild noch beschreiben könnten, da wir bei der Konstruktion von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir eine Schlussfolgerung aus natürlicher Sprache mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Beschriftung als die damit verbundene Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In addition, wir betrachten die Kaption als die Premise und die FOIL als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell die FOIL als widersprechend oder neutral gegenüber dem Untertitel vorhersagt, nehmen wir dies als Indikator für eine gültige FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Folie durch den Untertitel enthalten ist, kann es keine gute Folie sein, da sie durch Transitivität eine wahrhaftige Beschreibung des Bildes liefert und wir diese Folien ausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Prozedere ist nicht perfekt. Es ist nur ein Indikator für valide Foil."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Erstellung gültiger FOILs menschliche Annotatoren, um die in Valse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir also so viele Testfälle wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um einen Benchmark für Null-Schuss-Tests handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vorausbildung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Die Feinabstimmung würde es den Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nutzen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vorausbildung haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen auf Vowels, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin I und VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bilder-Satzpaaren in Untertitel und FOILs."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht ist für dieses Video relevanter, dass wir unsere permissivere Metrik, die Paargenauigkeit, präsentieren, die misst, ob der Ausrichtungswert des Bildesatzes für das korrekte Textpaar des Bildes höher ist als für das fehlerhafte Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Metriken und Ergebnisse zu diesen Ergebnissen finden Sie in unserer Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit Paar-Präzision sind hier gezeigt und entsprechen den Ergebnissen, die wir aus den anderen Metriken erhalten haben. Die beste Leistung bei Nullschüssen wird von Wilbert zwölf in einem, gefolgt von Wilbert, LXMert, Clip und schließlich VisualBird erreicht."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert Twelve in One fast gelöst werden, wobei er hervorhebt, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann in unseren Adversarial Foiling-Einstellungen keine der verbleibenden Teile zuverlässig gelöst werden"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäten und Zählungsinstrumenten sehen wir, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Aktionen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie durch plausibel Vorurteile unterstützt werden, wie wir im Aktionsteil sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Bereich erfahren wir, dass es für Vision- und Sprachmodelle ebenfalls schwierig ist, mehrere Referenzen auf das gleiche Objekt in einem Bild mit Pronomen zu verfolgen."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Verstandskontrolle und weil es ein interessantes Experiment ist, haben wir auch zwei Textmodelle, GPT eins und GPT zwei, benchmarkt, um zu beurteilen, ob Valse durch diese Einmodalmodelle gelöst werden kann, indem wir die Verwirrung der richtigen und der fehlgeschlagenen Beschriftung berechnen und den Eintrag mit der geringsten Verwirrung vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die FOIL höher ist, nehmen wir dies als Hinweis darauf, dass die FOIL-Beschriftung unter einer plausibilen Voreingenommenheit oder anderen sprachlichen Voreingenommenheiten leidet."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die Text nur GPT Modelle die Plausibilität der Welt besser erfassen haben als die Vision und Language Modelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALS ein Benchmark ist, der die Linse der sprachlichen Konstruktionen nutzt, um der Community bei der Verbesserung von Seh- und Sprachmodellen zu helfen, indem sie ihre visuellen Grundlagefähigkeiten hart testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu begründen, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich ermutigen, VALS zur Messung des Fortschritts hin zur Sprachbasis mit Vision und Sprachmodellen zu verwenden."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, VALS könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von VALS getesteten Aspekte hilft."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, sollten Sie sich die Walls-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde eine Papier entitelt RNSAM, ein Large Scale DSET für automatische Risikogrammierung beim Commitologizieren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikogenerierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNote ist ein technisches Dokument, das die bei jeder Veröffentlichung eines Softwareprodukts zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Restnoten für Bosch 2.6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "User Us Library These Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consuming, um manuell zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, hochwertige Release-Noten automatisch zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Frischknotengenerierung verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste System, das Arena erstellt wurde, wurde 2014 erstellt."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert eine ruralbasierte Approach, zum Beispiel, indem man die Change Extractor verwendet, um Code differenzen, Bibliothekänder und Dokumentenänderungen von den differenzen zwischen Releases zu extrahieren, und schließlich kombinieren sie."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das bemerkenswerteste Merkmal dieses Systems ist der Ausgaben-Extraktor in der oberen rechten Ecke,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dieses muss mit dem Issues-Ökosystem verbunden sein und kann nur auf Projekte mit Null angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist Grief. Dies entweder angesagt in 2014."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "2020. Es ist auf dem Internet verfügbar und kann via PIP gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches Textklassifizierungsmodell basierendes auf Lernen und Ausgaben aus fünf Labors, wie z. B. Funktionen oder Fehlerbehebungen, für jede Eingabe-Kommentarnachricht."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Sample-User, das eine Korrektur für Fehlerkorrekturen erhält."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingdaten sind sehr klein, etwa fünftausend, und werden in den Experimenten beschriebenen unten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Kreuzschaltmodells ist nicht höher."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier löst diese beiden Probleme und erzeugt automatisch hochwertige Freigabe-Noten."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das begrenzte Anwendungsprogramm schlagen wir eine hochwertige Klassifizierungsmethode mit nur Kommentarmeldungen als Eingabe vor."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Repositories verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der Skarbstaatressourcen haben wir eine RNSAM DSET konsistent mit etwa 82.000 Datenpunkten erstellt, indem wir Daten aus öffentlichen GitHub Repositories mit der GitHub API erstellen."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unsere Daseinsetzung."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Nachricht des Komitees und die rechte Seite ist die Release-Note."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Riesen sind als Verbesserungen, Verbesserungen, etc. gelobt."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Kommentarnachrichten als Eingaben aufnimmt und die Raveled-Please-Notizen ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassungsaufgabe angesehen werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Rubber, Funktionen, Verbesserungen, Fehlerbehebungen, Deprekationen, Entfernungen und Bremsänderungen vorgedefiniert."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden aufgrund früherer Forschung und anderer Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Rhythmus-Noten unten rechts werden aus den Rhythmus-Noten unten links abgezogen."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Moment müssen die vier Schuttwerke, die im Voraus aufgestellt wurden, entdeckt werden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Lager sind nicht immer mit jeder Freiheit übereinstimmen"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, um Verbesserungen zu treffen, zu erhöhen, Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabulärliste mit etwa 30 Numbers für jede dieser Rotationsvariationen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Restnotkrasten zu erkennen und den Text der Restnotkrasten zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Komiteemeldung."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachrichten des Komitees sind nicht an jede Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der image below, wenn die aktuelle Realität Boson zwei Punkt fünf zwei neunzehn, müssen wir die IDECHTEN"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "erfüllt die vorherige Version 2.5218 und erhält einen Tiff. Dies ist ein bisschen mühsam und es reicht nicht aus, nur eine Liste der Releases zu erhalten und sich die Vorher und Nachher anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine Heuristik, die mit Ihnen übereinstimmt, um die vorherigen und nächsten Schauspielzeiten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind die Horses."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "In der Hand, siebentausend zwei hundert Repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Token 63, was für eine Zusammenfassungsaufgabe ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Nummer der Unique Tokens ist bei Roger at eight thousand eight hundred thirty thousand."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl von einzigartigen Kasten und Methoden im Repertory."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes erkläre ich die vorgeschlagene Methode."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Querschnitts-, Extraktions- und Abstruktionsmodell besteht aus zwei neuer Modulen"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifier mit Bot oder Code Bot und ein Generator mit Bot."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Klassifizierer, um jede Kommentarnachricht in fünf RESNOT-Klassen zu klassifizieren: Funktionen, Verbesserungen, Fehlerbehebungen, Duplizierungen und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als anderer eingestuften Komitee-Nachrichten werden abgelehnt."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GAS den Generator unabhängig auf die vier Rudder-Dokumente an und erzeugt für jede Klasse Risikonode."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Übereinstimmungen zwischen Commit-Nachrichten und Lesemerkungen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifizierer zu trainieren, weisen wir jeder Eingabe-Commit-Nachricht Pseudorabben zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Kreuzstreifen-Abstruktiv-Summersätze durch zwei verschiedene Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzigen SEC-Netzwerk und generiert einen einzigen Long-SNode-Text, der eine Kombination von Eingabe-Commit-Nachrichten liefert."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgangstext kann in Kreuzzeichen aufgeteilt werden, basierend auf speziellen Kreuz-Spezifischen Endpunkt-Symbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSMarch nennen, besteht aus vier verschiedenen SEC-to-SEC-Netzwerken, von denen jede einer der RES-Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das macht Spain's Experiment."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: CS, CS Single, CS Smart, Russelling und die vorherige Studienbeschreibung."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Abrissung sind in einigen Fällen diese Noten in mehreren Sätzen ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro ist penetrativ, wenn das System einen kurzen Satz ausgibt"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Brauvolumen. In den als nächstes beschriebenen Experimentenergebnissen"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erzeugen wir auch eine Spezifität, da Rouge und Brux nicht erzeugt werden können, wenn die Riesen-Knoten leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass die Modellprojekte ausgegeben sind, die in Fällen, in denen die Reasonals empfangen, empfindlich sind."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Daseit Emailadresse, Hashbarriers, etc. enthält, erweitern wir auch den Quint Daseit, der sie ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat und sie hat Rouge Air-Punkte erreicht, die mehr als zehn Punkte höher waren als die Baselines."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Green Test set, der Square Gap zwischen der proposierten Methode und der Basis jumped zu mehr als 20 Punkten."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie und sie erfolgreich sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS hat eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Crossfire und eines Generators auf das Training des Crossfire-Systems mit Pseudobus effektiv ist."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, weil der Klassifizierer sich auf die relevanten Kommittentests für jeden Kurs konzentrieren kann."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie isst in dieser Zeit viel höher als wenn sie ledig ist."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es auch effektiv ist, für jede dieser Notengrasse unabhängig verschiedene Perspektivsummerisierungsmodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hero und Eronasus"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xia's Methoden neigen dazu, kürzere Sätze als menschliche Referenz-Sätze zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Figur auf der rechten Referenz hat drei oder vier Sätze, während CS nur eins hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzugabe ist, dass in den Trainingsdaten nur 33 % der Sätze im Rabel Merkmale und 40 % im Rabel Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES Methoden ohne zusätzliche Informationen keine genauen Risikobewertungen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommentarmeldung, und die Kommentarfassung kann nicht generiert werden, ohne auf die entsprechende Peru-Request oder -Erstellung hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das untenstehende Beispiel zeigt, dass die beiden Kommentarberichte im Eingaben miteinander verbunden sind und in einen Satz kombiniert werden sollten, aber dies geschieht nicht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Personalgenerierung erstellt,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Kommentarmeldungen einzugeben und sie zusammenzufassen, sodass sie für alle Projekte auf Englisch anwendbar ist."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die Bassrate besser laut macht als die Bassrate."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte schauen Sie sich unsere Dessert-Audit-Tab an."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist ein Safarari,"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unsere Arbeit über die Anreicherung von Tabellen mit Hilfe von fein abgestimmten Transformatoren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Merkmale der Daten."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen begrenzt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Funktionen mit einer anderen Datenquelle kann erhebliche Informationen bieten."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung von Tabelldaten mit externen Quellen-Freitexten."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben eine Tabelldatensammlung und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Funktionen aus dem künstlichen Text der Wissensbasis zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel sehen. In einem Datensatz, der in FEST eingeführt wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist die Datenmenge Universitätsdatenmenge."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten zu unterteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festes ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Einheit, in diesem Beispiel der Name der Universität, mit einer Einheit innerhalb der Wissensbasis verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Knowledge-Basis wird extrahiert und in die Daten setzt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text der Abstrakt der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Funktionen aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen also eine Funktionsaufnahmephase, die Textanalyse beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde mich in den nächsten Folien tiefer damit befassen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Extraktionsphase der Merkmale gibt es eine Generierungsphase der Merkmale, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst generieren Sie Funktionen in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also, erstens zwei neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Funktion stellt die Wahrscheinlichkeit für jede Klasse dar."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, die sich auf Transformer basieren lassen, wie Baird, GPT, XLED und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe zur Feinabstimmung sein."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Funktionsauffnahme können wir also ein Parent-Train-Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell verfeinert, um Text in Klassen zu klassifizieren, abstrakt in Klassen, niedrig oder hoch."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse ist, und verwenden Sie sie als neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datenmengen möglicherweise wenige unterschiedliche Entitätsstapel haben."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Proben, und der kleinste Datensatz enthält fünfunddreißig Proben in seinem Trainings-Satz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorherige Kenntnisse über voranalyseierte Datensätze nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir den nth-Datensatz analysieren."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sugest, ist die Hälfte der Fine Tuning Phase."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Phase der Fine-Tuning-Multitask."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über n minus eins Datensätze finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine weitere Feinabstimmungsphase durch, die eine Feinabstimmung der Zielaufgaben ist, wenn wir das Sprachmodell über den n-Tiel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der neueste Stand der Multitask-Fine-Tuning, der MTDNN genannt wird."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN hält MTDNN eine Anzahl von Aufgaben im Trainingsatz aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainings-Set. Also leere DNN und halte vier Kopfhäupter, wie Sie auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es samplet eine zufällige Charge aus dem Trainingsset."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Run-Batch zu einer, zum Beispiel, Sing und Selton-Klassifizierungsaufgabe gehört, führt er einen Vorwärts- und Rückwärtspass durch den ersten Kopf aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zu einer Paar-Ranking-Tasche gehört, wird sie durch den letzten Kopf weitergegeben und zurückgegeben."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario verifiziert eine Datenmenge-Tabelle die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN hält die Anzahl der Klassen-Heads-Ausgaben-Schichten aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss MTDNN eine neue HEADS für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Task Reformulation Fine Tuning bezeichnet wird, besteht darin, dass wir in unserem Ansatz Task Reformation Fine Tuning statt mehrere Kopfgruppen zu behalten, jeden Datensatz in ein Satz pro Klassifizierungsproblem umformulieren, das zwei Klassen-Aufgaben ist."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also ein Beispiel sehen."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Input-Datensatz, der von Entitäten, Funktionen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zu der Klassifizierung des Textes, des Abstrakts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, wir haben das Sprachmodell so trainiert, dass es abstrakt und in der Klasse klassifiziert, ob die Abstrakt-Klasse in der Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Etikettvektor besteht in diesem Fall also immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren fertigen oder formulierten Feintuning-Ansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also das vollständige Framework betrachten."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und das set fade into fast"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Entity-Linking-Phase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensbasis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird die Aufgabe in eine Satz-Per-Classifikation-Tasche reformuliert."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und die Ausgabenwahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über n-1-Datensatz mit einer vorläufigen Multitask-Fine-Tuning verfeinert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu erstelltes Merkmal in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Rahmenwerk zu bewerten, verwenden wir eine Datenmenge mit siebzehn Tabellen, die Größe, Merkmale, Balance, Bereich und anfängliche Leistung variieren."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unser Experiment als Live-Out-Evaluierung gestaltet, bei der wir schnell über sechzehn Datensätze trainieren und sie auf das siebzehnte Datenset anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datensatz in vier Fehler auf und wenden eine Falten-Cross-Validation an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Funktionen und bewerten sie mit fünf Bewertungs-Klassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-Basis-Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Rahmenwerk mit der Feinabstimmung des Zieldatensatzes, der Feinabstimmung der Zielaufgabe und der vorläufigen Feinabstimmung der MTDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere Formulierung ist ein Feintuning, das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2% gegenüber der Feinabstimmung des Zieldatensatzes erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Poach hat eine Verbesserung um sechs Prozent erzielt."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Daten ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Feinabstimmung bei mehrere Aufgaben auf 1,5 Prozent abnimmt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung hat sich im Vergleich zu der Zielaufgabe, die allein mit der Feinabstimmung verbessert wurde, um elf Prozent zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Zusammenfassung ermöglicht Fast die Bereicherung von Fushot aus 35 Proben in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulationsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satzpaar-Klassifizierungsproblematik verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Assa Farari und ich werde unsere Arbeit FUSHOT Tabellendatenanbau mit fein abgestimmten Transformers-Architekturen vorstellen. Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Datenmerkmale, aber manchmal sind diese Merkmale begrenzt. Die Generierung von Merkmalen mit einer anderen Datenquelle kann erhebliche Informationen hinzufügen. Unser Forschungsziel ist die automatische Tabellendatenanbau mit externen Quellen, freiem Text. Nehmen wir an, wir haben eine Tabellendatenmenge und eine Wissensbasis. Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Merkmale aus dem kostenlosen Text der Wissensbasis zu extrahieren. Unser Framework FEST ist genau dieser automatische Prozess. Lassen Sie uns ein Beispiel betrachten. In einem Datensatz, der in FEST eingeführt wird. In diesem Beispiel ist der Datensatz ein Universitätsdatensatz, wenn sein Ziel es ist, Universitäten in niedrig rankende Universitäten und hochrangige Universitäten. Als Wissensbasis verwenden wir Wikipedia. Die erste Phase von FEST ist die Entitätslinkung, bei der jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität innerhalb der Wissensbasis verknüpft wird und der Text der Entitäten der Wissensbasis extrahiert und zum Datensatz hinzugefügt wird. In diesem Beispiel ist der Text der Wikipedia-Seitenabschnitt. Jetzt müssen wir Features aus dem erhaltenen Text generieren oder extrahieren. Wir benötigen also eine Feature-Extraction-Phase, die Textanalyse beinhaltet. Und das ist die Hauptnota dieser Arbeit, und ich werde mich in den nächsten Folien damit befassen. Nach der Feature-Extraction-Phase gibt es eine Feature-Generation-Phase, in der wir die extrahierten Features verwenden, um eine kleine Anzahl von Features zu generieren. Sie eine kleine Anzahl neuer Merkmale. Erstellen Sie zuerst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes. In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen, also erstellen Sie zuerst zwei neue Merkmale. Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Merkmale. Jede Merkmale repräsentiert die Wahrscheinlichkeit für jede Klasse. Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, nämlich transformierbare Sprachmodelle wie BERT, GPT, XLERT und so weiter. Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können. Daher wäre eine naive Herangehensweise die Feinabstimmung der Zielaufgabe. In der Fase der Extraktion der Funktionen können wir ein pertrainiertes Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset feinabstimmen. In diesem Beispiel können wir das Sprachmodell fe soll Text in Klassen, Abstract in Klassen, Low oder High, in Klassen eingeteilt, die Sprachmodell-Ausgaben erhalten, die für jede Klasse die Wahrscheinlichkeit sind, und als neue Funktionen verwendet werden. Das Problem bei diesem Ansatz ist, dass Daten sätze möglicherweise wenige unterschiedliche Entitäten wie Text enthalten. In unserem Experiment enthalten fast die Hälfte der Daten sätze weniger als 400 Samples und die kleinsten Daten sätze enthalten. Es enthält 35 Proben in seinem Trainings-Set. Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern. Wir können jedoch vorherige Kenntnisse über voranalysierte Datensätze nutzen, da wir FAST über mehrere Datensätze anwenden. Wir können die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir die nth Dataset. Was wir vorschlagen, ist eine weitere Fein-Tuning-Phase, eine preliminäre Multitask-Fein-Tuning-Phase, wenn wir das Languagemodell über n-1 Datasets fein-tunen. Und dann führen wir eine weitere Fein-Tuning-Phase aus, die eine Target-Task-Fein-Tuning ist, wenn wir das Languagemodell über das nth-Target-Dataset fein-tunen. Der Stand der Welt in der Multitask-Fein-Tuning-Phase. Fine-Tuning-Anwendung namens MTDNN. In MTDNN, MTDNN, mainten Sie eine Hälfte der Taschen im Trainingssatz. In diesem Beispiel gibt es vier Taschen im Trainingssatz. MTDNN mainten Sie vier Hälfte, wie Sie sehen können, im Bild. Es sampelt eine Random-Batch aus dem Trainingssatz. Und wenn die Random-Batch zu einem Zum Beispiel Singenselten's Classification-Tasks, es führt Vor- und Rückwärtspfade durch den ersten Kopf aus. Und wenn der Random-Batch zu Paar-Wise-Ranking-Task gehört, führt es Vor- und Rückwärtspfade durch den letzten Kopf aus. In unserem Szenario verringen Tableau-Datensätze die Anzahl der Klassen. Es gibt also viele Aufgaben. MTDNN-Mainten. DNN hält eine Reihe von Klassen-Heads-Ausgaben-Lagen aufrecht und zusätzlich muss MTDNN neue Heads für einen neuen Datensatz mit einer neuen Aufgabe initialisieren. Unser Ansatz, der als Task-Reformulation-Fine-Tuning bezeichnet wird, ist, dass wir in unserem Ansatz Task-Reformulation-Fine-Tuning, anstatt mehrere Heads aufrechtzuerhalten, jedes Datensatz in ein Satz pro Klassifizierungsproblem, das zwei Klassen-Taschen. Also, sehen wir ein Beispiel. Hier ist unser Input-Datensatz, der entweder von Entitäten, Funktionen, Text und Klassen besteht. Und wir reformulieren die Tasche von der Klassifizierung der Text in Low und High, um die Text, den Abstrakt und die Klasse in True oder False zu klassifizieren. Oder in anderen Worten, wir trainieren das Languagemodell, um eine Abstrakt- und Klassenklasse zu klassifizieren, ob die Abstrakt- und Klassenklasse zur Klasse gehören oder nicht. Der Etikettvektor bleibt in diesem Fall immer mit zwei Klassen bestehen. Und das ist der Algorithmus für unsere Find-Orientierung. find reformulated fine-tuning approach. Also, sehen wir uns den vollständigen Framework an. Ein Datensatz wird in FAST eingeführt und dann FAST execute in die Linkingphase. Es extrahiert den Text aus der Knowledge-Basis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist. Dann wird die Task reformuliert in Satz-Per-Classification-Tasks, das Sprachmodell auf die neue Task und die Ausgaben-Likelihood für jede Klasse. Beachten Sie, dass das Language-Modell bereits über n-1-Datensätze mit einer vorläufigen Multitask-Fine-Tuning abgestimmt ist. Dann verwenden wir den Ausgabenvektor des Language-Modells als neu generierten Funktion in der Anzahl der Klassen. Um unser Framework zu evaluieren, verwenden wir eine 17. Wir haben eine siebzehn-Tabellklassifizierungsdatensätze, die die Größe, die Merkmale, den Bereich und die anfängliche Leistung in Einklang bringt. Und als Wissensbasis verwenden wir Wikipedia. Wir haben unser Experiment als eine Live-Out-Evaluierung entworfen, bei der wir schnell über sechzehn Datensätze trainieren und sie auf die siebzehnte Datensätze anwenden. Wir haben auch jede Datensätze in vier Daten aufgeteilt. Wir erstellen Fehler und wenden eine Fork-Fehler-Kreuzvalidierung an. Dann generieren wir die neue Funktion und bewerten sie mit fünf Bewertungs-Klassifikatoren. In unserem Experiment verwenden wir eine auf Bild-Basis basierte Architektur. Hier sind die Ergebnisse unseres Experiments. Sie sehen, dass wir unser Framework mit der Feinabstimmung des Zieldatensatzes vergleichen, der Feinabstimmung der Zielaufgabe. und MTDNN preliminäre Feintuning und unsere reformulierte Feintuning erreichten den besten Ergebnis, die besten Leistungen, während MTDNN 2% Verbesserung über die Target-Datenset-Fine-Tuning erreichte. Unser Produkt erreichte 6% Verbesserung. Wenn wir uns die kleinen Daten ansehen, Aus dem Datensatz können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Fine-Tuning für mehrere Aufgaben auf 1,5 Prozent abnimmt, aber unsere Leistung steigt auf 11 Prozent im Vergleich zur alleinigen Fine-Tuning für die Zielaufgabe. Für die Zusammenfassung ermöglicht FAST die Bereicherung von Flux-Schüssen aus 35 Proben in unserem Experiment. verwendet eine Architektur für alle Aufgaben-Datensätze und behält den Kopf des Modells bei. Aber es fügt eine Formulierungsphase hinzu, es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satz-Par-Klassifizierungsproblematik verwenden können. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen. Heute werde ich unser Forschungswerk Lernen, deduktiv zu denken, Methodenproblemlösung als komplexe Rationsauffnahme vorstellen. Ich bin Alan vom Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD. Zunächst möchte ich über unsere Motivation für das Denken sprechen. Hier zeigen wir Beispiele, in denen mehrträgliches Denken hilfreich ist. Diese Zahl stammt aus der POWN-Artikel, in der sie die Anregung zur Lösung des Methodenproblems in einem Future-Learning-Szenario durchführen. Auf der Netto-Pan-Seite können wir sehen, dass wir, wenn wir einige Beispiele mit nur Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten. Wenn wir jedoch eine weitere Beschreibung geben, kann das Modell die Beschreibung vorhersagen und auch eine korrekte Vorhersage treffen. Es ist also gut, als Ausgabe interpretierbare Mehrstufige Beschreibung zu haben. Wir denken auch, dass das Methodenproblem eine einfache Anwendung ist, um solche Beschreibungsfähigkeiten zu bewerten. Hier in unserer Problemkonfiguration müssen wir diese Frage aufgrund der Fragen lösen und die numerischen Antworten erhalten. In unseren Datensätzen erhalten wir also auch den mathematischen Ausdruck, der auch zu dieser bestimmten Antwort führt. Daher gelten bestimmte Annahmen wie in früheren Arbeiten. Wir gehen davon aus, dass die Präzision von Größen bekannt ist, und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential. Darüber hinaus können komplizierte Operatoren tatsächlich ent in diese grundlegenden Operatoren aufgeteilt werden. Frühere Arbeiten im Lösungsproblem der Methode können also tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baummodell kategorisiert werden. Traditionelle Sequenz-zu-Sequenz-Modelle konvertieren den Ausdruck in eine spezifische Sequenz für die Generierung, und es ist ziemlich einfach zu implementieren, und es kann auf viele verschiedene komplizierte Probleme verallgemeinert werden. Aber die Nachteile sind, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell, und es fehlt an Interpretabilität für die die Vorhersage. Aber eigentlich ist diese Richtung aufgrund des Transformator-Modells immer noch ziemlich beliebt. In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen. Hier generieren wir also die Operatoren, bis wir die Blätter erreichen, die die Größen sind. Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt. Aber eigentlich ist es ziemlich kontraintuitiv. Denn wir generieren zuerst den Operator und dann am Ende die Größen. Und das Zweite ist, dass er auch einige wiederholte Berechnungen enthält. Wenn wir uns also diesen Ausdruck a mal drei plus drei ansehen, wird er tatsächlich zweimal generiert. Aber tatsächlich sollten wir die Ergebnisse wiederverwenden. In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und interpretierbar lösen. Zum Beispiel können wir hier im zweiten Schritt die Daten erhalten., die 27 sind. Und wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden. Und in diesen Schritten erhalten wir die Teiler. Und dann erhalten wir in diesem dritten Schritt tatsächlich den Quotienten. Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse des zweiten Schritts wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten. Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren. Dies macht den Prozess genauer. In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als Anfangszustände ein. Der Ausdruck wird also durch EIJOP dargestellt, bei dem wir Operatoren von Qi bis Qj ausführen, und dieser Ausdruck ist tatsächlich gelenkt. Wir haben hier auch eine Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen. Das ist ziemlich ähnlich wie eine Relationsentfernung. In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diesen neuen Ausdruck. Wir fügen ihn den nächsten Zuständen hinzu, um eine neue Größe zu erhalten. Diese Folien visualisieren tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zustand weiterhin Ausdrücke hinzufügen. In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Netzwerkmodell, das Vögel oder Roberto sein kann, und dann codieren wir den Satz und erhalten diese Mengenrepräsentationen. Sobald wir die Mengenrepräsentationen erhalten, können wir mit der Schlussfolgerung beginnen. Hier zeigen wir ein Beispiel für Q1, um die Repräsentation für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q3 multipliziert wird. Zuerst erhalten wir die Paarrepräsentation, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist, und dann wenden wir ein Fit-Forward-Netzwerk an, das ist. Dies wird durch den Operator parametriert. Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2. Aber in der Praxis könnten wir im Inferenzstadium auch den falschen Ausdruck erhalten. Hier sind alle möglichen Ausdrücke gleich dreimal so viele Operatoren. Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern. Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchraum entfernen. Im zweiten Schritt machen wir also das Gleiche, aber der einzige Unterschied ist eine weitere Größe. Diese Größe stammt also aus dem vorher berechneten Ausdruck. Schließlich können wir diesen endgültigen Ausdruck Q drei mal Q vier erhalten. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke vom vorherigen Schritt unterschiedlich ist. Solche Unterschiede machen es schwierig, ihn anzuwenden. Es ist schwer, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist. Der Trainingsverfahren ist ähnlich wie bei der Schulung eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust bei jedem Zeitschritt optimieren, und hier verwenden wir auch diese Zeichen, um darzustellen, wann wir diesen Generierungsprozess beenden sollten. Und hier ist der Raum von Sequenz zu Sequenz anders, da der Raum bei jedem Zeitschritt unterschiedlich ist, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Wortschatzes ist. Es ermöglicht uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen aufzustellen. Wir führen also Experimente mit den häufig verwendeten Methodenproblemdatensätzen durch, MAWPS, Math twenty three K, MathQA und SWAM. Hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen. Unsere am besten funktionierende Variante ist Roberta Deductive Reasoner. Tatsächlich verwenden wir nicht BeamSearch, im Gegensatz zu den vorherigen Ansätzen mitze sind oft ein Baumbasiertes Modell. Insgesamt kann unser Argumentationsmodell dieses Baumbasierten Modells deutlich übertreffen, aber wir können sehen, dass die absoluten Zahlen bei MathQA oder SWAM nicht wirklich hoch sind. Wir untersuchen die Ergebnisse bei SWAM weiter, und dieser Datensatz ist eine Herausforderung, da der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie zum Beispiel das Hininzufügung von irrelevanten Informationen und zusätzlichen Mengen. In unserer Vorhersage stellen wir fest, dass einige der Zwischenwerte tatsächlich negativ sind. In diesen Fragen fragen wir zum Beispiel, wie viele Äpfel Jake hat, aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Töne und Stephen hat acht Töne, was völlig irrelevant ist. Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt. Und wir beobachten, dass diese beiden Ausdrücke tatsächlich ähnliche Zahlen haben. Wir haben tatsächlich ähnliche Punktzahlen. Wir können also diesen Suchraum einschränken, indem wir diese negativen Ergebnisse entfernen, damit wir die Antwort richtig machen können. Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert. Zum Beispiel verbessern wir für Vögel sieben Punkte und für das Roberta-basierte Modell zwei Punkte. Ein besseres Sprachmodell hat also eine bessere Sprachverständnisfähigkeit, sodass die Zahl hier. Hier ist es höher für Roberta und niedriger für Vögel. Und wir versuchen auch, die Schwierigkeit hinter all diesen Daten zu analysieren. Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Informationen angesehen werden kann. Hier können wir also sehen, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und der SWAMP-Datenmenge den größten Teil hat. Und hier zeigen wir auch die Gesamtleistung für diese Proben ohne ungenutzte Mengen. Die Gesamtleistung ist also tatsächlich höher als die. Und die Leistung ist tatsächlich höher als die Gesamtleistung. Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlechter ist als die Gesamtleistung. Für MAWPS haben wir nicht wirklich viele Datenfälle, also ignoriere ich diesen Teil einfach. Schließlich möchten wir die Interpretbarkeit durch ein Beispiel für das Zusammenbruch zeigen. Hier macht unser Modell also tatsächlich eine falsche Vorhersage im ersten Schritt. Wir können diesen Ausdruck tatsächlich mit dem Satz hier korrelieren. Wir denken, dass dieser Satz das Modell mit einer falschen Vorhersage irreführt. Wenn wir hier also weitere 35 Pflanzen pflanzen, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte. Wir versuchen, den Satz so zu ändern, dass die Anzahl der Birnen 35 weniger als die Apfelbäume ist. Wir machen es also, um genauere Semantik zu vermitteln, sodass das Modell die Vorhersage richtig machen kann. Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Verhalten des Modells zu verstehen. Um unsere Arbeit abzuschließen: Zunächst ist unser Modell ziemlich effizient und wir können interpretierbare Lösungsmethoden bereitstellen, und wir können ein wenig vorheriges Wissen als Einschränkung einbeziehen, was die Leistung verbessern kann. Das letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch auf andere Aufgaben, die mehrträgliches Denken beinhalten. Wir haben aber auch bestimmte Einschränkungen. Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein. Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung bei verschiedenen Zeitstufen unbalanciert ist, daher ist es auch ziemlich schwierig, eine Beam-Suche-Strategie anzuwenden. Das ist also das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich bin von der Maastricht University. Ich werde meine gemeinsame Arbeit mit Jerry vorstellen, die sich mit einer neuen Datensammlung für die Erfassung von gesetzlichen Artikeln befasst. Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen, aber die Mehrheit der Bürger hat wenig bis kein Knowledge über ihre Rechte und grundlegenden Rechtsprozesse. Daher werden viele gefährdeten Bürger, die sich die kostspielige Unterstützung eines Rechtsexperten nicht leisten können, ungeschützt oder schlimmer gesagt, ausgenutzt. Unsere Arbeit zielt darauf ab, die Grenze zwischen Menschen und dem Gesetz zu schließen, indem er ein effektives Retrievalsystem für Statutartikel entwickelt. Ein solches System könnte eine freie professionelle Rechtshilfegemeinschaft für unqualifizierte Menschen bieten. Bevor wir uns auf den Hauptbegriff dieser Arbeit konzentrieren, sollten wir uns zunächst mit dem Problem der Statutartikelretrieval befassen. Bei einer einfachen Frage auf einem Rechtsmaterial, wie zum Beispiel was ich riskieren kann, wenn ich professionelle Privatsphäre verletze, ist ein Modell erforderlich, um alle relevanten Statutartikel aus einem großen Bereich der der Gesetzgebung. Diese Information Retrieval Task kommt mit seiner eigenen Setz von Challenges. Erstens geht es mit zwei Arten von Linguage, der normalen natürlichen Sprache für die Fragen und der komplexen legalen Sprache für die Statuten zu tun. Diese Differenz in Languageverteilungen macht es für ein System schwieriger, relevante Kandidaten zu retrieveren, da es indirekt eine inhärente Interpretationssysteme erfordert, die eine natürliche Frage zu einer rechtlichen Frage, die die Terminologie der Statuten entspricht, translatiert. Besides, statutory Law ist nicht ein Stack von Independent Artikeln, die als eine vollständige Source von Informationen auf der Own behandelt werden können, wie neue Rezepte, zum Beispiel. Instead, es ist eine Struktur, eine Sammlung von legalen Provisionen, die eine ganze Bedeutung nur in der allgemeinen Kontext haben, das ist zusammen mit der supplementären Information aus den neighbouring Artikeln, den Feldern und Subfields, die sie belong zu, und ihrer Platz in der Struktur der Laub. Lastly, statutory Artikel sind ein kleiner Paragraph. was in den meisten Retrievalwerken die typische Retrieval-Einheit ist. Hier sind es lange Dokumente, die bis zu sechstausend Wörter schreiben können. Die recenten Entwicklungen in NLP haben enorme Interesse in vielen Rechtsakten wie Legal Judgment Prediction oder automatisierten Kontaktkontraktreview gespielt, aber die Statutory Article Retrieval hat sich aufgrund der Lack von groß und hochwertigen Labeldatensätzen in der Lage geblieben. In dieser Arbeit präsentieren wir eine neue French Native Citizen Centric Datenset zu studieren, ob ein Retrievalmodell die Effizienz und Reliabilität eines Legal Experts für die Task der Statutory Article Retrieval angeht. Unser Belgisch Statutory Article Retrieval Datsatsatz besteht aus mehr als 1.100 legalen Fragen, die von Belgischen Bürgern gestellt werden. Diese Fragen umfassen eine wide Reihe von Themen von Familie, Housing, Money, bis hin zu Work und Sozialversicherung. Each of them ist von erfahrenen Juristen mit Referenzen zu relevanten Artikel aus einem Corpus von mehr als 22.600 legal Artikeln aus Belgischen Codes of Law. Lassen Sie uns nun über die Art und Weise sprechen, wie wir diese Daten setzen. Erst, wir starten mit der Compilierung eines Large Corpus von legal Artikeln. Wir betrachteten 32 öffentlich verfügbare Belgischen Codes und extrahierten alle Artikel sowie die correspondenden Section Headings. Dann gingen wir mit Referenzen zu relevanten Statuten zusammen. To tun so, wir partnerten mit der Belgischen Law Firma. jedes Jahr um viertausend Emails von Belgischen Bürgern, die um Rat und persönliche Rechtsfragen bitten. Wir hatten die Glück, Zugang zu ihren Websites zu bekommen, wo ihr Team erfahrener Juristen belgische am häufigsten rechtlichen Fragen behandelt. Wir sammelten Tausende von Fragen, die mit Kategorien, Subkategorien und Rechtsreferenzen zu relevanten Statuten angepasst wurden. Lastlich durchgingen wir die Rechtsreferenzen und filterten die Fragen, die nicht Artikel in einem der Codes of Law we considered. Die remaining Referenzen wurden matched und zu den corresponding Artikel IDs von O Corpus. Wir eventuell endeten mit einem Jahrhundert und acht Fragen, die sich sorgfältig mit den IDs der relevanten Artikel aus unserem Large Corpus von twenty two thousand six hundred thirty three Statutory Articles labelten. In addition, jeder Frage kommt mit einer Mainkategorie und einer Konkatenation von Subkategorien. Jeder Artikel enthält eine Konkatenation der nachfolgenden Überschriften in der Struktur des Gesetzes. Diese zusätzlichen Informationen werden in der aktuellen Arbeit nicht verwendet, aber könnten für zukünftige Forschungen zur Rechtsinformationserfassung oder zur Klassifizierung von Rechtstexten interessant sein. Schauen wir uns einige Merkmale unserer Datensätze an. Die Frage ist zwischen fünf und vierundvierzig Wörter lang mit einem Median von vierzig Wörtern. Die Artikel sind viel länger mit einem Median von siebzig sieben Wörtern, wobei einhundertvierundvierzig davon mehr als tausend Wörter betragen. Die Länge eines von fünftausend siebenhundert und neunzig Wörtern. Wie bereits erwähnt, umfassen die Frage eine breite Palette von Themen, wobei etwa achtzig Prozent davon entweder Familie, Wohnung, Geld oder Justiz betreffen, während die restlichen fünfzehn Prozent entweder Sozialversicherung, Ausländer oder Arbeit betreffen. Die Artikel sind auch sehr vielfältig, da sie aus dreißig zwei verschiedenen belgischen Gesetzen stammen, die eine große Anzahl von illegalen Themen abdecken. Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Gesetze gesammelt wurden. Von den 22.633 Artikeln werden nur 1.612 als relevant für mindestens eine Frage in den Datensätzen angegeben, und etwa 80 % dieser zitierten Artikel stammen entweder aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafgesetz. Inzwischen werden 18 von 32 Gesetzen weniger als fünf Artikel als relevant für mindestens eine Frage angege, die durch die Tatsache verursacht wird, dass diese Code weniger auf individuelle und ihre Anliegen fokussiert. Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünfundzwanzig Prozent von ihnen sind mehr als fünfmal citiert. Mit unseren Data sets benchmarken wir verschiedene Retrievalapproaches, einschließlich Lexical und Densarchitektur. Given eine query in einem Artikel, eine Lexicalmodelle assigniert eine Score zu den queryartikelpaaren. Durch die Berechnung der Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfrage-Terme. Wir experimentieren mit den Standard-TFIDF- und BM25-Rankingsfunktionen. Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten. Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die die semantische Beziehung zwischen Abfragen und Artikeln erfassen kann. Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert. und berechnen einen relevanten Punkt zwischen einem Artikelpaar der Abfrage anhand der Ähnlichkeit ihrer Eingebettungen. Diese Eingebettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Eingebettungsmodells. Zunächst untersuchen wir die Effektivität siamesischer B-Encoder in einer Zero-Shot-Evaluierungs-Einrichtung, was bedeutet, dass vorgebildete Word-Eingebettungsmodelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden. Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und Fastastex und kontextabhängige Embeddingmodelle, nämlich Roberta und speziell Kamembert, ein französisches Roberta-Modell. Darüber hinaus trainieren wir unsere eigenen Kamembert basierenden Biencoders auf allen Datenmengen. Beachten Sie, dass wir für das Training mit den beiden Arten der Biencoder Architektur experimentieren. Siamese, das ein einzigartiges Wort-Embeddingmodell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraum mappiert. Und Tutor, das zwei unabhängige Wort-Embeddingmodelle verwendet. Wir haben zwei Independent Word Embedding Models, die den Query und Artikel separat in verschiedene Embeddingsphasen codieren. Wir experimentieren mit Mean, Max und CLS Pooling sowie Dot Product und Cosine für die Computing-Similaritäten. Hier sind die Ergebnisse unserer Baseline auf dem Testset, mit den Lexikonmethoden oben, den Siamese BE Encoders evaluiert in einem Zero Shot Setup in der Mitte, und den Fein Tun BE Encoders unten. Overall, die Fein Tun BE Encoders übertragen alle anderen Baselines. seine Siamese-Variante auf RECOLAT 100, aber ähnlich auf den anderen Metriken abschneidet. Obwohl BM 25 den trainierten Biancoder erheblich unterlegen hat, deutet seine Leistung darauf hin, dass es immer noch eine starke Grundlage für Domain-spezifische Rückholung ist. Bei der Zero Shot Evaluation des Siamese Biancoders finden wir, dass die direkte Verwendung der Embeddings eines vortrainierten Kamembert-Modells ohne Optimierung für die Informationsaufnahmeaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt. Der Word-to-Vec-basierte Biancoder übertraf die Fastex- und Vogelbasierten Modelle deutlich, was darauf hindeutet, dass möglicherweise vor-train-Word-Einbettungen für die Aufgabe angemessener sind als Charakter- oder Unterword-Einbettungen, wenn sie von Anfang an verwendet werden. Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Verbesserungsmöglichkeiten im Vergleich zu einem geschickten Experten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann. Lassen Sie uns mit zwei Limitationen von allen Datensätzen beginnen. Erstens ist der Corpus von Artikeln limitiert zu denen, die aus den dreißig zwei betrachteten Belgischen Codes erfasst werden, was nicht den gesamten Belgischen Law abdeckt, da Artikel aus Dekrees, Direktives und Ordinanzen enthalten sind. Durch die Datensatzkonstruktion werden alle Referenzen zu diesen unkollektierten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Fragment der initialen Anzahl relevanter Artikeln enthalten. Dieser Informationlaus impliquiert, dass die Antwort in den remaining relevanten Artikelnkel könnten incomplete sein, obwohl es immer noch vollständig appropriate ist. Second, wir sollten merken, dass nicht alle Rechtsfragen mit Statuten alone beantwortet werden können. For instance, die Frage kann ich meine Tenants evicten, wenn sie zu viel Noise machen, könnte nicht eine detaillierte Antwort in statutory Law enthalten, die eine spezifische Noise Threshold at which Eviction ist. Insted sollten die Landlage wahrscheinlich mehr auf Fallslaw und Präceden ähnlich wie der aktuelle Situation finden. Zwei Parteien pro Woche bis 2 Uhr morgens. Daher sind einige Fragen besser als andere für die Aufgabe der gesetzlichen Artikelerfassung geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen. Wir hoffen, dass unsere Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle der gesetzlichen Artikelerfassung weckt, die den Zugang zur Justiz für alle verbessern können. Sie können sich unsere Arbeit Datensätze und Code unter den folgenden Links ansehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir sind froh, unsere Arbeit auf VALS, einem Taskindependenten Benchmark für das Testen von Vision und Language Models mit spezifischen linguistiken Phänomenen zu präsentieren. Warum haben wir uns die Trouble in der Setzung dieses Benchmarks gemacht? Nun, während der letzten Jahre haben wir eine explosion von Transformer basierten Vision und Language Models, die auf große Mengen von Image Textpaaren geprägt sind. Each dieser Modelle pusht State of the Art auf Vision und Language Tasks, wie z. B. visuelle Fragen Sinnesrechnung, Bildretrieval, Phrase-Grundung. Wir haben also eine Nachricht, die Akuragen auf diesen spezifischen Benchmarks steigern, aber wissen wir, was die Modelle tatsächlich gelernt haben? Was hat ein Vision und Language Transformer verstanden, als er eine High Score für dieses Bild und diesen Satz zugewiesen hat und eine Low Score für dieses Bild? Fokusieren Vision und Language Models auf das Richtige oder konzentrieren sie sich auf Biasen? wie gezeigt durch vorherige Arbeit. Um mehr Licht auf diesen Aspekt zu senden, propellieren wir eine mehr task agnostic direction und einführen WALS, das die Sensitivität von Vision und Language Models zu spezifischen linguistiken Phenomenen, die sowohl die linguistic als auch die visuelle Modalitäten beeinflussen. Wir targen Existenz, Pluralität, Zählung, Spatialrelationen, Aktionen und Entity Coreference. Aber wie testen wir, ob die Vision und Language Models diese Phenomena erfasst haben? Foiling, eine Methode, die vorher für Vision und Language Models, nur für Nanphrasen von Ravi Shakar und Kollaborators und auf Counting von Asin previous worked. Foiling basically means, dass wir den Caption of an Image und einen Foil produzieren, indem wir den Caption so verändern, dass er nicht die Image anymore beschreibt. Und wir machen diese Phrasealterations, indem wir uns auf sechs spezifische Pieces wie Existenz, Pluralität, Counting, Spatialrelations, Actions, und Entity Coreference. Jede Piece kann aus einem oder mehreren Instrumenten bestehen, in dem Fall, dass wir mehr als eine interessante Möglichkeit gefunden haben, FOIL instanzen zu erstellen. Zum Beispiel haben wir in der Fall der Aktionspiece zwei Instrumente, einen in dem das Action verb mit einer anderen Action geändert wird und einen in dem Actants gewechselt werden. Zählen und Coreferenz sind auch Pieces, die mehr als eine Instrumenten haben. Und wir erstellen diese FOILs, indem wir unserstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererweit validierten Sätze sind. Dies ist nicht einfach zu tun, weil eine Foiled Caption weniger wahrscheinlich ist als die ursprüngliche Caption. Zum Beispiel, though it's not impossible, ist es statistisch weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann, und Largevision und Language Models könnten dies erkennen. Daher müssen wir, um valid Foils zu erhalten, Action unternehmen. Erstens, wir machen uns auf Strong Language Models zu propellieren. Zweitens, wir verwenden Natural Language Inference oder NLI, um Foils zu filtern, die noch beschreibiben das Bild immer noch, da wir bei der Konstruktion von FOILs sicherstellen müssen, dass sie das Bild nicht beschreiben. Um dies automatisch zu testen, wenden wir eine natürliche Sprachinferenz mit der folgenden Begründung an. Wir betrachten ein Bild als die Premise und seine Beschriftung als die damit verbundene Hypothese. Darüber hinaus betrachten wir die Beschriftung als die Premise und die FOIL als ihre Hypothese. Wenn ein NLI-Modell die FOIL zu widersprechen oder neutral zu den Beschriftungen zu sein, nehmen wir dies als Indikator für eine gültige FOIL. Wenn wir die Foil zu beentalten, kann es nicht eine gute Foil sein, da es durch Transitivität eine truthliche Beschreibung der Image geben wird und wir diese Foils ausfiltern. Aber dieser Prozess ist nicht perfekt. Es ist nur ein Indikator für valide Foils, daher als eine dritte Möglichkeit für die generierung von valid Foils, wir verwenden Humananannotators, um die Daten zu validieren, die in Valse verwendet werden. Also, nach Filtering und Human Evaluation, wir haben so viele Testinstanzen wie in dieser Tabelle. Note, dass Valse nicht trainierend Daten liefert. Aber nur Testdaten, da es sich nur um einen Benchmark für Null-Shot-Tests handelt. Es ist darauf ausgelegt, die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vor-Training-Aktivität zu nutzen. Die Feinabstimmung würde es Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen. Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen einschlagen. Und wie wir sagten, sind wir daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vor-Training-Aktivität haben. Wir experimentieren mit fünf Vision- und Sprachmodellen auf WALS, nämlich mit CLIP, Wilbert, Wilbert Kelvin I und Visual Bert. Zwei unserer wichtigsten Evaluierungsmetriken sind die Accuracy der Modelle in der Klassifizierung von Image Sentenzenpaaren in Untertitel und Foils. Perhaps für dieses Video mehr relevant, wir werden unsere permissive Metrik, die Paarwise Accuracy, die messen, ob die Image Sentenz alignment score für die korrekte Image Textpaar als für ihre Foilpaar ist. Für mehr Metriken und Ergebnisse auf themen, doch checken Sie unsere Papier. Die Ergebnisse mit Paarwise Accuracy sind hier und sie sind konsistent mit den Ergebnissen, die wir von den anderen Metriken bekommen haben. Es ist, dass die besten Zero Shot Performance durch Wilbert zwölf in one, gefolgt von Wilbert, Alex Mert, Clip, und schließlich Visual Bird. Es ist notabel, wie Instrumente centered on individuelle Objekte wie Existenz und Nounphrases fast solviert werden, wobei Wilbert zwölf in one, highlighting, dass Models ableistisch genannte Objekte und ihre Präsenz in Images identifizieren können. Allerdings können none der remaining Pieces in unseren adversarialen Foiling-Settings reliably solviert werden. Instrumenten, dass Vision und Language Models Trouble distinguisieren, referenzieren zu single versus multiple Objekten oder in einem Image. Die Relation Piece zeigt, dass sie Schwierigkeiten haben, eine named spatiale Relation zwischen Objekten in einem Image zu klassifizieren. Sie haben auch Trouble, Aktionen zu distinguieren und ihre Partizipanten zu identifizieren, selbst wenn sie durch Plausibility bias sind, wie wir in der Aktionspiece sehen. Aus der Referenzpiece finden wir, dass das Tracing multiple Referenzen zu dem gleichen Objekt in einem Image durch Pronouns auch für Vision und Language Models. Als eine Sanity Check und weil es ein interessantes Experiment ist, benchmarken wir auch zwei Textonlegermodelle GPT one und GPT two, um zu assessieren, ob Valse solvable durch diese Unimodalmodelle ist, indem wir die Perplexität der korrekt und der foiled Caption, keine Image hier, und die Entry mit der lowest Perplexität. Wenn die Perplexität höher für die Foil ist, dann nehmen wir dies als eine Indikation, dass die foiled Caption möglicherweise von Plausibility bias oder anderen linguistiken Biasen leidet. Und es ist interessant zu sehen, dass in einigen Fällen Die Textmodelle nur GPT haben die Plausibilität der Welt besser erfasst als die Vision und Language Models. Zusammenfassend ist VALSE ein Benchmark, das die Lensen von Linguistikkonstrukten verwendet, um die Community zu helfen, Vision und Language Models zu verbessern, indem sie ihre visuellen Grounding-Fähigkeiten hart testen. Unsere Experimente zeigen, dass Vision und Language Models namensgelegene Objekte in ihrer Präsenz in Bildern gut identifizieren, wie gezeigt durch das Existenzstück, aber es schwerwiegt, ihre Interdependence und Relationships in visuellen Szenen zu genehmigen, wenn sie gezwungen sind, linguistic Indikatoren zu respektieren. Wir möchten die Community wirklich ermutigen, Valse zur Messung des Fortschritts hin zur Sprachbasis mit Vision- und Sprachmodellen zu verwenden. Und noch mehr, Valse könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von Valse getesteten Aspekte hilft. Wenn Sie interessiert sind, sollten Sie sich die Valse-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamisara von der University of Tokio. Ich werde eine Papier entitelt RNSAM, ein großes Dasein für automatische Restnoturation bei der Commit Dog Summization. Ich werde in dieser Ordnung erklären. Erst, ich werde die automatische Restnoturation, die wir in dieser Research arbeiten, einführen. ReleaseNode ist ein technischer Dokument, das die Changes mit jedem Release von einem Softwareprodukt zusammenfasst. Das Image zeigt die ReleaseNode für Version zwei. sechs. vier der GBUJS Library. Diese Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consumierend zu erstellen. Daher wird es sehr nützlich sein, automatisch hochqualitäre Release Nodes zu generieren. Ich werde auf zwei frühere Researchers auf automatische Release Node Generation eingehen. Der erste ist ein System namens Arena, das in twenty fourteen erstellt wurde. Es ergreift eine Rule basierende Approach, zum Beispiel, indem es die Change Extractor verwendet, um Code differenzen zu extrahieren. Bibliotheksänderungen und Dokumentenänderungen von den differenzierten Releases und schließlich kombinieren. Die meisten erkennbaren Funktionen dieses Systems sind die Issue Extractor in der oberen rechten Ecke, die mit Jira, dem Issue Toco System, verknüpft und nur für Projekte verwendet werden kann. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden. Die zweite ist Griff, die Entry angeboten wurde in twenty twenty. Sie ist auf dem Internet und kann durch PIPSTEMENSSER Dieses System hat ein einfaches Lernbasis für Textklassifikation und erhält eine von fünf Rabellen, die Funktionen oder Bugfixen für jedes Input Commit-Message enthalten. Das Bild ist eine Sample-Usage, die eine korrekte oder Bugfixen-Rabelle enthält. Die gerade erstellten Rabellen sind ziemlich klein, etwa fünftausend, und werden in den Experimenten beschriebenen darüber gezeigt. Die Leistung des Textklassifikationsmodells ist nicht hoch. Ich präsentiere zwei related Researchers, aber es gibt Probleme mit begrenztem Erwerb und geringen Daten. und Scar State Resources. Unser Papier löst diese beiden Probleme und automatisch generiert High Quality Releasing Notes. Für das limitierte Applicability Programm, wir propagieren eine High Quality Classifier Summarization Methode, die nur Committee Message als Input verwendet. Diese Methode kann für alle English Repositories verwendet werden. Für das zweite Problem der Scar State Resources, wir bauen RL und SAM DSET konsistent mit etwa achtzig zwei Tausend Pieces von Daten, die von öffentlichen GitHub API. Next, ich beschreibe unser Desert. Hier ist ein Beispiel für Daten. Die linke Seite ist ein Commit Message und die rechte Seite ist die RISE Nodes. Die RISE Nodes sind Raveled als Implement, Bug fixes, etc. Wir haben eine Task setup, die die Commit Messages als Input und die Raveled RISE Nodes aufwendet. Dies kann als eine Summarization Task bezeichnet werden. Wir haben vier Raveled Features, Implement, Bug fixes, Duplications, Removables und Breaking Changes. Diese wurden basierend auf PBR research und anderen Faktoren. Die RISE Noten auf der bottom right und extrahiert von den RISE Noten auf der bottom left. At diesem Zeitpunkt ist es notwendig, die vier Rabels zu detektieren, die in der Passage sind, aber die Rabels sind nicht immer konsistent mit jeder Repository. Zum Beispiel, die Improvements Rabels inklusive Improvements, Enhancements, Optimisations und so weiter. Wir haben eine Vokabularliste oder Studie Rabels für jeden dieser Notation. variations. Verwenden Sie es, um die Restknoten zu erkennen und den Text der Restknoten zu korrigieren. Als nächstes kommt eine Kommittemessage. Kommittemessagen sind nicht zu jeder Rest. Wie in der image below, wenn die aktuelle Rest Persönlich 2.5219 ist, müssen wir die vorherige Rest Persönlich 2.5218 identifizieren und einen Tiff erhalten. Dies ist ein bisschen tedious und es ist nicht genug, nur eine Rest der Restknoten zu erhalten. Und wir haben die Vorhand nach. Wir haben eine heuristic Matching Blue erstellt, um die vorherigen und nächsten Persönlichkeiten zu erhalten. Dasset Analysis In der End, 7.200 Repositories und 82.000 PSO wurden korrektiv. Außerdem ist die average Anzahl von ReleaseNode Tokens 63, was für eine Summarisation Task ziemlich hoch ist. Außerdem ist die Anzahl von Unique Tokens ziemlich groß, also 8.830.000. Dies ist auf die große Anzahl von Unique Kosten und Methoden zurück namens in der Repository. Next, ich werde explain die proposierte Methode. Das Crosswise Extractive and Abstractive Summarization Model besteht aus zwei neuronalen Modules, einem Classifier, der Bot oder Code Bot und einem Generator, der Bot verwendet. Erstens, GAS verwendet einen Classifier, um jedes Committee Message in fünf Risnode Classes, Features, Improvements, Bugfixes, Duplications, Plus, und andere. Die Committee Messages klassifiziert als andere oder diskutiert. Dann GAS wendet einen Generator zu den vier Rabelschnitteln unabhängig und generiert RISE NOTE für jeden Kurs. In diesem Zusammenhang sind die direkten Korrespondenzen zwischen Commit Messages und RISE NOTE nicht bekannt. Daher, um den Kurs zu trainieren, wir zwar Rabelschnitteln zu jedem Input Commit Message verwenden, indem wir die ersten zehn Charaktere für jedes Commit Message verwenden. Wir modellieren den Kurs abstruktiven Summarisierungsansatz durch zwei verschiedene Methoden. Das erste Modell, das wir als GAS Single Sync konsist von einer Sync zwei Sync Network und generiert eine Sync Long RISE Node Tagist, geben eine Konkurrenz von Input Committee Messages. Die Output Tagist kann in Crosswise Segment basierend auf speziellen Cross Specific Endpoint Symbols unterteilt werden. Die zweite Methode, Methode, die wir CSMUCH, besteht aus vier verschiedenen Sync zwei Sync Networks, jeder von denen zu einer der RISE Node Classes entspricht. Okay, lassen Sie mich das Experiment erklären. Fünf Methoden wurden GS, GS Single, GS Marge, Russelling und previous studied Griff. Regarding Abortion, in einigen Fällen, diese Noten sind in multiple Sentenzen. Da es difficil ist, die Nummer von Sentenzen zu erkennen, sind sie kombiniert mit Spaces und treaten als ein langer Satz. Der Blue ist penalisiert, wenn das System einen kurzen Satz erfährt. Diese Penalty resultiert in einem loweren Blue Value in den Experimenten der Results describiert. Finally, wir auch die Spezifität erkennen, weil Rouge und Brew nicht erkennen können, wenn die Rouge Nodes leer sind. Eine hohe Spezifität bedeutet, dass die Modellkorrektie auspackt ist, in denen die Rouge Nodes leer sind. Hier sind die Ergebnisse. Da der Daseit Emailadresse, Hashbarrieren, etc. enthält, haben wir auch den Green Daseit erkannt, der sie ausschließt. GAS und GAS erreichten Rouge Error Scores mehr als zehn Punkte höher als die Baselines. Auf dem grünen Testset stieg die Score-Gap zwischen der vorgeschlagenen Methode und der Basis auf mehr als zwanzig Punkte. Diese Ergebnisse zeigen, dass GAS und GAS signifikant effektiv sind. GAS erreichte eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Klassifierers und eines Generators effektiv ist und das Training des Klassifierers mit Pseudoberseiten. Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, da der Klassifier sich auf das Sekten relevanter Kommittemechanismen für jede Klasse konzentrieren kann. Xia ist viel zu höheren Ruder als Xia single, suggesting, dass es auch effektiv ist, unterschiedliche perspektive Summarisationsmodelle für jedes Nodecraft zu entwickeln. Hier sind Erronnas. Xia's Methods tend to output shorter Sentenzen als humanen Referenz Sentenzen. In der Figur auf der rechten Referenz Sentenzen hat drei oder vier Sentenzen, während Xia nur eins hat. Der Grund für diese Modellrücktanz ist, dass in den Trainingdaten nur 33 Prozent der Sentenzen sind in der Features Rabel und 40 Prozent in der Improvements Rabel. Für die More CS Methods können nicht akurat mit Noten ohne zusätzliche Informationen generiert werden. Das Top Exempel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommittemessage und die Komplettesentence kann nicht generiert werden, ohne dass es sich auf die correspondente Periodrequest oder Issue bezieht. Das Beispiel below zeigt, dass die zwei Kommittemessagen in der Input related und sollten kombiniert werden. Aber es versucht dies zu tun. Schließlich eine Konklusion. Wir haben eine neue DSET für automatische Rezensionsschnittgenerierung erstellt. Wir haben auch die Aufgabe erstellt, Kommentarn zu enthalten und sie so zu summarisieren, dass sie für alle Projekte in Englisch anwendbar ist. Unser Experiment zeigt, dass die vorgeschlagene Methode weniger Noisy Rezensionsschnittgenerierung bei höherer Abdeckung als die Basisrate erzeugt. Bitte schauen Sie sich unsere DSET auf GitHub an. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 0, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle. Heute werde ich unsere Forschungsarbeit Lernen zu reisen deduktiv, Methodenproblemlösung als komplexe Rasen-Extraktion vorstellen."}
{"dataset_id": "acl_6060", "sample_id": 1, "src_lang": "en", "tgt_lang": "de", "output": "Ich bin Alan von Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD."}
{"dataset_id": "acl_6060", "sample_id": 2, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst möchte ich über unsere Motivation für das Denken sprechen."}
{"dataset_id": "acl_6060", "sample_id": 3, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir Beispiele, bei denen mehrstufiges Denken hilfreich ist."}
{"dataset_id": "acl_6060", "sample_id": 4, "src_lang": "en", "tgt_lang": "de", "output": "Diese Zahl stammt aus dem POWN-Papier, in dem sie Anweisungen zur Lösung des Methodenproblems in einem Fluch-Learning-Szenario ausführen."}
{"dataset_id": "acl_6060", "sample_id": 5, "src_lang": "en", "tgt_lang": "de", "output": "Auf der anderen Seite können wir sehen, dass wir, wenn wir einige Beispiele nur mit Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 6, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir jedoch noch mehr Beschreibungen geben, kann das Modell die Beschreibung vorhersagen und auch hier eine korrekte Vorhersage treffen."}
{"dataset_id": "acl_6060", "sample_id": 7, "src_lang": "en", "tgt_lang": "de", "output": "Es ist also gut, als Ausgabe interpretierbares Mehrstufenrechnungsverfahren zu haben."}
{"dataset_id": "acl_6060", "sample_id": 8, "src_lang": "en", "tgt_lang": "de", "output": "Wir denken auch, dass ein Methodenproblem eine einfache Anwendung zur Bewertung solcher Argumentationsfähigkeiten ist."}
{"dataset_id": "acl_6060", "sample_id": 9, "src_lang": "en", "tgt_lang": "de", "output": "Hier müssen wir also in unserer Problemkonfiguration, angesichts der Fragen, diese Frage lösen und die numerischen Antworten erhalten."}
{"dataset_id": "acl_6060", "sample_id": 10, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Datensätzen wird uns also auch der mathematische Ausdruck gegeben, der zu dieser besonderen Antwort führt."}
{"dataset_id": "acl_6060", "sample_id": 11, "src_lang": "en", "tgt_lang": "de", "output": "Daher gelten auch bestimmte Annahmen wie in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 12, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Genauigkeit der Größen bekannt ist"}
{"dataset_id": "acl_6060", "sample_id": 13, "src_lang": "en", "tgt_lang": "de", "output": "Und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential."}
{"dataset_id": "acl_6060", "sample_id": 14, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können komplizierte Operatoren tatsächlich in diese grundlegenden Operatoren aufgeteilt werden."}
{"dataset_id": "acl_6060", "sample_id": 15, "src_lang": "en", "tgt_lang": "de", "output": "Eine frühere Arbeit im Lösungsproblem der Methode kann also tatsächlich in Sequenz- und Baummodell kategorisiert werden."}
{"dataset_id": "acl_6060", "sample_id": 16, "src_lang": "en", "tgt_lang": "de", "output": "Traditionelle Sequenzmodelle konvertieren den Ausdruck also in eine bestimmte Sequenz für die Generierung."}
{"dataset_id": "acl_6060", "sample_id": 17, "src_lang": "en", "tgt_lang": "de", "output": "Es ist ziemlich einfach umzusetzen und kann auf viele verschiedene komplizierte Probleme verallgemeinert werden."}
{"dataset_id": "acl_6060", "sample_id": 18, "src_lang": "en", "tgt_lang": "de", "output": "Aber der Nachteil ist, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell und es fehlt an Interpretabilität für die Vorhersage."}
{"dataset_id": "acl_6060", "sample_id": 19, "src_lang": "en", "tgt_lang": "de", "output": "Aber eigentlich ist diese Direction noch ziemlich populär, weil der Transformermodell"}
{"dataset_id": "acl_6060", "sample_id": 20, "src_lang": "en", "tgt_lang": "de", "output": "In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen."}
{"dataset_id": "acl_6060", "sample_id": 21, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also die Operatoren weiter, bis wir die Lifts erreichen, die die Größen sind."}
{"dataset_id": "acl_6060", "sample_id": 22, "src_lang": "en", "tgt_lang": "de", "output": "Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt, aber es ist eigentlich ganz entgegengesetzt, weil wir zuerst den Operator generieren und dann am Ende die Größen generieren."}
{"dataset_id": "acl_6060", "sample_id": 23, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens enthält es auch einige wiederholte Berechnungen."}
{"dataset_id": "acl_6060", "sample_id": 24, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns also diesen Ausdruck hier ansehen, wird acht mal drei plus drei tatsächlich zweimal erzeugt. Aber tatsächlich sollten wir die Ergebnisse verwenden"}
{"dataset_id": "acl_6060", "sample_id": 25, "src_lang": "en", "tgt_lang": "de", "output": "In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und in interpretierbaren Methoden lösen."}
{"dataset_id": "acl_6060", "sample_id": 26, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel können wir hier im zweiten Schritt diesen Teiler erhalten, der 27 ist."}
{"dataset_id": "acl_6060", "sample_id": 27, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden."}
{"dataset_id": "acl_6060", "sample_id": 28, "src_lang": "en", "tgt_lang": "de", "output": "Und in diesen Schritten erhalten wir die Teiler."}
{"dataset_id": "acl_6060", "sample_id": 29, "src_lang": "en", "tgt_lang": "de", "output": "Und dann erhalten wir bei diesem dritten Schritt tatsächlich den Quotienten."}
{"dataset_id": "acl_6060", "sample_id": 30, "src_lang": "en", "tgt_lang": "de", "output": "Okay. Und nach diesen drei Schritten können wir die Ergebnisse des zweiten Schritts tatsächlich wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten."}
{"dataset_id": "acl_6060", "sample_id": 31, "src_lang": "en", "tgt_lang": "de", "output": "Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 32, "src_lang": "en", "tgt_lang": "de", "output": "Dadurch wird der Prozess genauer."}
{"dataset_id": "acl_6060", "sample_id": 33, "src_lang": "en", "tgt_lang": "de", "output": "In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als unser Anfangszustand ein."}
{"dataset_id": "acl_6060", "sample_id": 34, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausdruck wird also durch EIJOP dargestellt."}
{"dataset_id": "acl_6060", "sample_id": 35, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen Operatoren von QY bis QJ aus, und dieser Ausdruck ist tatsächlich gerichtet."}
{"dataset_id": "acl_6060", "sample_id": 36, "src_lang": "en", "tgt_lang": "de", "output": "So, wir haben hier auch Subtraction-Wert, um die entgegengesetzte Richtung zu repräsentieren."}
{"dataset_id": "acl_6060", "sample_id": 37, "src_lang": "en", "tgt_lang": "de", "output": "Das ist ziemlich ähnlich wie bei der Strahlungsauffnahme."}
{"dataset_id": "acl_6060", "sample_id": 38, "src_lang": "en", "tgt_lang": "de", "output": "In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diese neuen Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 39, "src_lang": "en", "tgt_lang": "de", "output": "Wir fügen es in den nächsten Zustand hinzu, um eine neue Menge zu werden."}
{"dataset_id": "acl_6060", "sample_id": 40, "src_lang": "en", "tgt_lang": "de", "output": "Diese Folien visualisieren also tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zuständen immer wieder Ausdrücke hinzufügen."}
{"dataset_id": "acl_6060", "sample_id": 41, "src_lang": "en", "tgt_lang": "de", "output": "In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Sprachmodell, das Vögel oder Robetts sein kann, und dann kodieren wir den Satz und erhalten diese Mengenrepräsentationen."}
{"dataset_id": "acl_6060", "sample_id": 42, "src_lang": "en", "tgt_lang": "de", "output": "Sobald wir also die Mengen darstellen, können wir mit der Schlussfolgerung beginnen."}
{"dataset_id": "acl_6060", "sample_id": 43, "src_lang": "en", "tgt_lang": "de", "output": "Hier zeigen wir ein Beispiel für Q1, um die Darstellung für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q4 multipliziert wird."}
{"dataset_id": "acl_6060", "sample_id": 44, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst erhalten wir die Paar-Anweisung, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist. Dann wenden wir ein Fit-Forward-Netzwerk an, das vom Operator parametriert wird."}
{"dataset_id": "acl_6060", "sample_id": 45, "src_lang": "en", "tgt_lang": "de", "output": "Und schließlich erhalten wir die Ausdrucksrepräsentation Q1 geteilt durch Q2."}
{"dataset_id": "acl_6060", "sample_id": 46, "src_lang": "en", "tgt_lang": "de", "output": "Aber in der Praxis könnten wir in der Schlussfolgerung möglicherweise auch den falschen Ausdruck erhalten."}
{"dataset_id": "acl_6060", "sample_id": 47, "src_lang": "en", "tgt_lang": "de", "output": "Hier entspricht also jeder möglichen Ausdruck dreimal so viel wie die Anzahl der Operatoren."}
{"dataset_id": "acl_6060", "sample_id": 48, "src_lang": "en", "tgt_lang": "de", "output": "Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern."}
{"dataset_id": "acl_6060", "sample_id": 49, "src_lang": "en", "tgt_lang": "de", "output": "Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchbereich entfernen."}
{"dataset_id": "acl_6060", "sample_id": 50, "src_lang": "en", "tgt_lang": "de", "output": "Im zweiten Schritt machen wir das Gleiche, aber der einzige Unterschied ist, dass wir noch eine Menge mehr haben."}
{"dataset_id": "acl_6060", "sample_id": 51, "src_lang": "en", "tgt_lang": "de", "output": "Diese Größe stammt aus dem vorherigen berechneten Ausdruck."}
{"dataset_id": "acl_6060", "sample_id": 52, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich können wir diesen letzten Ausdruck Q3 erhalten."}
{"dataset_id": "acl_6060", "sample_id": 53, "src_lang": "en", "tgt_lang": "de", "output": "Wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke von dem vorherigen Schritt unterschiedlich ist."}
{"dataset_id": "acl_6060", "sample_id": 54, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede machen es schwierig, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist."}
{"dataset_id": "acl_6060", "sample_id": 55, "src_lang": "en", "tgt_lang": "de", "output": "Die Trainingsmethode ist ähnlich wie bei der Schulung eines Sequenzmodells, bei dem wir den Verlust bei jedem Zeitschritt optimieren."}
{"dataset_id": "acl_6060", "sample_id": 56, "src_lang": "en", "tgt_lang": "de", "output": "Und hier verwenden wir auch diese Tao, um darzustellen, wann wir diesen Generierungsprozess beenden sollten."}
{"dataset_id": "acl_6060", "sample_id": 57, "src_lang": "en", "tgt_lang": "de", "output": "Und hier ist der Raum von Sequenz zu Sequenz anders, weil der Raum bei jedem Zeitpunkt anders ist, während es im traditionellen Sequenz- zu-Sequenz-Modell die Anzahl des Wortschatzes ist."}
{"dataset_id": "acl_6060", "sample_id": 58, "src_lang": "en", "tgt_lang": "de", "output": "Und es ermöglicht es uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen zu verhängen."}
{"dataset_id": "acl_6060", "sample_id": 59, "src_lang": "en", "tgt_lang": "de", "output": "Wir führen also Experimente mit den häufig verwendeten Method-Problem-Datensätzen durch, MAWPS, Math23K, MathQA und SWAM."}
{"dataset_id": "acl_6060", "sample_id": 60, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen."}
{"dataset_id": "acl_6060", "sample_id": 61, "src_lang": "en", "tgt_lang": "de", "output": "Unsere beste Variante ist also Roberta Dedative Reasoner."}
{"dataset_id": "acl_6060", "sample_id": 62, "src_lang": "en", "tgt_lang": "de", "output": "Und tatsächlich verwenden wir BeamSearch nicht, im Gegensatz zu offensichtlichen Ansätzen mit BeamSearch."}
{"dataset_id": "acl_6060", "sample_id": 63, "src_lang": "en", "tgt_lang": "de", "output": "Okay, die besten Ansätze sind oft ein Baumbasiertes Modell."}
{"dataset_id": "acl_6060", "sample_id": 64, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt kann unser Vernunft also dieses Baumbasierungsmodell deutlich übertreffen."}
{"dataset_id": "acl_6060", "sample_id": 65, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir können sehen, dass die absoluten Zahlen auf MatQuery oder SWAM nicht wirklich hoch sind."}
{"dataset_id": "acl_6060", "sample_id": 66, "src_lang": "en", "tgt_lang": "de", "output": "Wir untersuchen die Ergebnisse weiter."}
{"dataset_id": "acl_6060", "sample_id": 67, "src_lang": "en", "tgt_lang": "de", "output": "Und dieser Datensatz ist eine Herausforderung, weil der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie z. B. irrelevante Informationen und zusätzliche Mengen hinzuzufügen."}
{"dataset_id": "acl_6060", "sample_id": 68, "src_lang": "en", "tgt_lang": "de", "output": "Also, in unserer Vorhersage finden wir, dass einige der intermediären Werte tatsächlich negativ sind."}
{"dataset_id": "acl_6060", "sample_id": 69, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel fragen wir in diesen Fragen, wie viele Äpfel Jake hat."}
{"dataset_id": "acl_6060", "sample_id": 70, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Pitchs und Stephen hat acht Pitchs, was völlig irrelevant ist."}
{"dataset_id": "acl_6060", "sample_id": 71, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt."}
{"dataset_id": "acl_6060", "sample_id": 72, "src_lang": "en", "tgt_lang": "de", "output": "Und wir beobachten diese beiden Ausdrücke."}
{"dataset_id": "acl_6060", "sample_id": 73, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Suchraum tatsächlich einschränken, indem wir diese Ergebnisse als negativ entfernen, damit wir die Antwort richtig machen können."}
{"dataset_id": "acl_6060", "sample_id": 74, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert."}
{"dataset_id": "acl_6060", "sample_id": 75, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel haben wir bei Vögeln sieben Punkte verbessert und bei dem Roberta-Basemodell tatsächlich zwei Punkte verbessert."}
{"dataset_id": "acl_6060", "sample_id": 76, "src_lang": "en", "tgt_lang": "de", "output": "Ein besseres Sprachmodell hat also bessere Sprachverständnisfähigkeiten, sodass die Zahl hier für Roberta höher und für Bert niedriger ist."}
{"dataset_id": "acl_6060", "sample_id": 77, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen auch, die Schwierigkeit hinter diesem BPP zu analysieren."}
{"dataset_id": "acl_6060", "sample_id": 78, "src_lang": "en", "tgt_lang": "de", "output": "Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Information angesehen werden kann."}
{"dataset_id": "acl_6060", "sample_id": 79, "src_lang": "en", "tgt_lang": "de", "output": "Hier sehen wir also, dass wir den Prozentsatz der ungenutzten Mengen haben und der SWAMP-Datensatz den größten Teil enthält."}
{"dataset_id": "acl_6060", "sample_id": 80, "src_lang": "en", "tgt_lang": "de", "output": "Und hier zeigen wir auch die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 81, "src_lang": "en", "tgt_lang": "de", "output": "Für diese Proben ohne ungenutzte Mengen ist die Gesamtleistung tatsächlich höher als die Gesamtleistung."}
{"dataset_id": "acl_6060", "sample_id": 82, "src_lang": "en", "tgt_lang": "de", "output": "Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlimmer ist als die, äh, viel schlimmer als."}
{"dataset_id": "acl_6060", "sample_id": 83, "src_lang": "en", "tgt_lang": "de", "output": "Für MAWPS haben wir nicht wirklich viele Desk-Cases, also ignoriere ich diesen Teil einfach."}
{"dataset_id": "acl_6060", "sample_id": 84, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich möchten wir die Interpretationsfähigkeit durch ein Beispiel für die Zusammenstoßpartizierung zeigen."}
{"dataset_id": "acl_6060", "sample_id": 85, "src_lang": "en", "tgt_lang": "de", "output": "Unser Modell macht also tatsächlich eine falsche Vorhersage im ersten Schritt."}
{"dataset_id": "acl_6060", "sample_id": 86, "src_lang": "en", "tgt_lang": "de", "output": "Wir können diesen Ausdruck also tatsächlich mit dem Satz hier korrelieren, oder?"}
{"dataset_id": "acl_6060", "sample_id": 87, "src_lang": "en", "tgt_lang": "de", "output": "Wir glauben also, dass dieser Satz das Modell in eine falsche Vorhersage führen könnte."}
{"dataset_id": "acl_6060", "sample_id": 88, "src_lang": "en", "tgt_lang": "de", "output": "Wenn man hier also noch 35 plant, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte."}
{"dataset_id": "acl_6060", "sample_id": 89, "src_lang": "en", "tgt_lang": "de", "output": "Wir versuchen also, den Satz so zu ändern, dass er so aussieht wie die Anzahl der Birnenfäden fünfundfünfzig weniger ist als die Apfelbäume."}
{"dataset_id": "acl_6060", "sample_id": 90, "src_lang": "en", "tgt_lang": "de", "output": "Wir stellen es also so, dass es genauere Semantik vermittelt, damit das Modell die Vorhersage richtig machen kann."}
{"dataset_id": "acl_6060", "sample_id": 91, "src_lang": "en", "tgt_lang": "de", "output": "Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Modellverhalten zu verstehen."}
{"dataset_id": "acl_6060", "sample_id": 92, "src_lang": "en", "tgt_lang": "de", "output": "Um unsere Arbeit abzuschließen, ist unser Modell eigentlich ziemlich effizient."}
{"dataset_id": "acl_6060", "sample_id": 93, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können eine interpretierbare Lösungsmethode bereitstellen."}
{"dataset_id": "acl_6060", "sample_id": 94, "src_lang": "en", "tgt_lang": "de", "output": "Und wir können leicht einige vorherige Kenntnisse als Konstrakt einbeziehen, was uns helfen kann, die Leistung zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 95, "src_lang": "en", "tgt_lang": "de", "output": "Und das Letzte ist, dass der zugrunde liegende Mechanismus nicht nur für Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch für andere Aufgaben, die mehrtretende Argumentation beinhalten."}
{"dataset_id": "acl_6060", "sample_id": 96, "src_lang": "en", "tgt_lang": "de", "output": "Aber wir haben auch bestimmte Einschränkungen."}
{"dataset_id": "acl_6060", "sample_id": 97, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein."}
{"dataset_id": "acl_6060", "sample_id": 98, "src_lang": "en", "tgt_lang": "de", "output": "Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung in verschiedenen Zeitzonen unbalanciert ist, daher ist es auch ziemlich schwierig, Beam-Suche anzuwenden."}
{"dataset_id": "acl_6060", "sample_id": 99, "src_lang": "en", "tgt_lang": "de", "output": "Das ist also das Ende des Vortrags und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 100, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich komme von der Maastricht University."}
{"dataset_id": "acl_6060", "sample_id": 101, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde mein Johannes Werk mit Jerry vorstellen, das sich mit einem neuen Datensatz für die Abholung von gesetzlichen Artikeln befasst."}
{"dataset_id": "acl_6060", "sample_id": 102, "src_lang": "en", "tgt_lang": "de", "output": "Rechtsfragen sind ein wesentlicher Bestandteil des Lebens vieler Menschen."}
{"dataset_id": "acl_6060", "sample_id": 103, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Mehrheit der Bürger hat wenig oder kein Wissen über ihre Rechte und grundlegenden Rechtsverfahren."}
{"dataset_id": "acl_6060", "sample_id": 104, "src_lang": "en", "tgt_lang": "de", "output": "Als Ergebnis sind viele vulnerable Bürger, die sich nicht die kostbare Assistance eines Legal Experts erwarten können, unprotegt oder worstens, exploitiert."}
{"dataset_id": "acl_6060", "sample_id": 105, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Arbeit zielt darauf ab, die Lücke zwischen Menschen und dem Gesetz zu schließen, indem wir ein effektives Rückholsystem für gesetzliche Artikel entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 106, "src_lang": "en", "tgt_lang": "de", "output": "Ein solches System könnte für unqualifizierte Menschen einen kostenlosen professionellen Rechtshilfenservice bieten."}
{"dataset_id": "acl_6060", "sample_id": 107, "src_lang": "en", "tgt_lang": "de", "output": "Bevor wir uns mit dem Hauptbeitrag dieser Arbeit befassen, beschreiben wir zunächst das Problem der statutarischen Artikelabholung."}
{"dataset_id": "acl_6060", "sample_id": 108, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ich eine einfache Frage zu einem rechtlichen Thema stelle, wie zum Beispiel: Was mache ich, wenn ich die professionelle Vertraulichkeit verletze?"}
{"dataset_id": "acl_6060", "sample_id": 109, "src_lang": "en", "tgt_lang": "de", "output": "Ein Modell ist erforderlich, um alle relevanten gesetzlichen Artikel aus einem großen Gesetz zu erfassen."}
{"dataset_id": "acl_6060", "sample_id": 110, "src_lang": "en", "tgt_lang": "de", "output": "Diese Aufgabe zur Informationserfassung bringt eine ganze Reihe von Herausforderungen mit sich."}
{"dataset_id": "acl_6060", "sample_id": 111, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst geht es um zwei Sprachtypen."}
{"dataset_id": "acl_6060", "sample_id": 112, "src_lang": "en", "tgt_lang": "de", "output": "für die Fragen eine gängige natürliche Sprache und für die Statuten eine komplexe rechtliche Sprache."}
{"dataset_id": "acl_6060", "sample_id": 113, "src_lang": "en", "tgt_lang": "de", "output": "Diese Unterschiede in den Sprachverteilungen machen es für ein System schwieriger, relevante Kandidaten zu finden, da es indirekt ein inhärentes Interpretationssystem erfordert, das eine natürliche Frage in eine rechtliche Frage übersetzen kann, die mit der Terminologie der Gesetze entspricht."}
{"dataset_id": "acl_6060", "sample_id": 114, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem ist das gesetzliche Recht kein Stapel unabhängiger Artikel, die als vollständige Informationsquelle an sich behandelt werden können, wie zum Beispiel Nachrichten oder Rezepte."}
{"dataset_id": "acl_6060", "sample_id": 115, "src_lang": "en", "tgt_lang": "de", "output": "Insted ist es eine Strukturkollektion von legalen Provisionen, die nur in der allgemeinen Kontext betrachtet sind, zusammen mit den zusätzlichen Informationen aus den neighbouring Artikeln, den Feldern und Subfeldern, zu denen sie gehören, und ihrer Platz in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 116, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, statutory Articles RN small paragraph, was usuell die typische Retrieval Unit in Most Retrieval Works ist."}
{"dataset_id": "acl_6060", "sample_id": 117, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind lange Dokumente, die bis zu sechs Jahre dauern können."}
{"dataset_id": "acl_6060", "sample_id": 118, "src_lang": "en", "tgt_lang": "de", "output": "Die jüngsten Fortschritte im Bereich NLP haben großes Interesse an vielen rechtlichen Aufgaben wie der Vorhersage von Rechtsentscheidungen oder der automatisierten Überprüfung von Vertragsverträgen weckt."}
{"dataset_id": "acl_6060", "sample_id": 119, "src_lang": "en", "tgt_lang": "de", "output": "Die gesetzliche Artikelabholung ist jedoch aufgrund des Mangels an großen und hochwertigen gekennzeichneten Datensätzen größtenteils unberührt geblieben."}
{"dataset_id": "acl_6060", "sample_id": 120, "src_lang": "en", "tgt_lang": "de", "output": "In dieser Arbeit präsentieren wir ein neues französisches, zentrales, zentrales Datenkett, um zu untersuchen, ob ein Rückholmodell die Effizienz und Zuverlässigkeit eines Rechtsexperten für die Aufgabe der Statutorienartikelrückholung nähern kann."}
{"dataset_id": "acl_6060", "sample_id": 121, "src_lang": "en", "tgt_lang": "de", "output": "Our Belgian Statutory Article Retrieval Data Sets consist von mehr als einem Jahrzehnt Liter."}
{"dataset_id": "acl_6060", "sample_id": 122, "src_lang": "en", "tgt_lang": "de", "output": "Diese Fragen umfassen eine breite Palette von Themen, von Familie, Wohnraum, Geld bis hin zu Arbeit und Sozialversicherung."}
{"dataset_id": "acl_6060", "sample_id": 123, "src_lang": "en", "tgt_lang": "de", "output": "Jeder von ihnen hat von erfahrenen Juristen mit Referenzen zu relevanten Artikeln aus einem Corpus von mehr als twenty zwei Tausend sechshundert."}
{"dataset_id": "acl_6060", "sample_id": 124, "src_lang": "en", "tgt_lang": "de", "output": "Belgische Codes of Law. Lassen Sie uns nun über die Erstellung dieser Datsätze sprechen."}
{"dataset_id": "acl_6060", "sample_id": 125, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst haben wir mit der Zusammenstellung eines großen Korpus an rechtlichen Artikeln begonnen."}
{"dataset_id": "acl_6060", "sample_id": 126, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben 32 öffentlich verfügbare Belgische Codes und alle Artikel sowie die entsprechenden Abschnittshebungen entnommen."}
{"dataset_id": "acl_6060", "sample_id": 127, "src_lang": "en", "tgt_lang": "de", "output": "Dann sammelten wir rechtliche Fragen mit Verweisen auf relevante Gesetze."}
{"dataset_id": "acl_6060", "sample_id": 128, "src_lang": "en", "tgt_lang": "de", "output": "Dazu arbeiten wir mit einer belgischen Anwaltskanzlei zusammen, die jedes Jahr etwa viertausend E-Mails von belgischen Bürgern erhält, die um Rat zu einer persönlichen Rechtsfrage bitten."}
{"dataset_id": "acl_6060", "sample_id": 129, "src_lang": "en", "tgt_lang": "de", "output": "Wir waren glücklich, auf ihre Websites zuzugreifen, wo ihr Team von erfahrenen Juristen Belgien's am häufigsten rechtlichen Probleme behandelt."}
{"dataset_id": "acl_6060", "sample_id": 130, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben Tausende von Fragen zusammengestellt, mit Kategorien, Subkategorien und rechtlichen Verweisen auf relevante Statuten."}
{"dataset_id": "acl_6060", "sample_id": 131, "src_lang": "en", "tgt_lang": "de", "output": "Lastly, wir passten die legalen Referenzen und filterten die Fragen aus, die Referenzen nicht Artikel in einem der Codes of Law wirkten."}
{"dataset_id": "acl_6060", "sample_id": 132, "src_lang": "en", "tgt_lang": "de", "output": "Die verbleibenden Verweise wurden in die entsprechenden Artikel-IDs aus O Corpus abgestimmt und umgewandelt."}
{"dataset_id": "acl_6060", "sample_id": 133, "src_lang": "en", "tgt_lang": "de", "output": "Wir endeten schließlich mit 1.108 Fragen, jeder sorgfältig mit den IDs der relevanten Artikel aus dem Buch."}
{"dataset_id": "acl_6060", "sample_id": 134, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich enthält jede Frage eine Hauptkategorie und eine Konkatenation von Unterkategorien."}
{"dataset_id": "acl_6060", "sample_id": 135, "src_lang": "en", "tgt_lang": "de", "output": "Und jeder Artikel kommt mit einer Konkatenation ihrer nachfolgenden Überschriften in der Struktur des Gesetzes."}
{"dataset_id": "acl_6060", "sample_id": 136, "src_lang": "en", "tgt_lang": "de", "output": "Diese zusätzliche Information wird nicht in der Präsentation verwendet, aber sie könnte für zukünftige Research auf Legal Information Retrieval oder Legaltext Classification interessant sein."}
{"dataset_id": "acl_6060", "sample_id": 137, "src_lang": "en", "tgt_lang": "de", "output": "Schauen wir uns einige Merkmale unserer Datensätze an."}
{"dataset_id": "acl_6060", "sample_id": 138, "src_lang": "en", "tgt_lang": "de", "output": "Die Frage ist zwischen fünf und vierundvierzig Wort lang, mit einem Median von vierzig Wort."}
{"dataset_id": "acl_6060", "sample_id": 139, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind viel länger, mit einer medianen Länge von sechzig sieben Wörtern, mit 140 Gramm."}
{"dataset_id": "acl_6060", "sample_id": 140, "src_lang": "en", "tgt_lang": "de", "output": "zwei von ihnen, die eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr als eintausend mehr"}
{"dataset_id": "acl_6060", "sample_id": 141, "src_lang": "en", "tgt_lang": "de", "output": "Wie bereits erwähnt, umfasste die Frage eine Vielzahl von Themen, von denen etwa 85 % entweder über Familie, Wohnraum, Geld oder Gerechtigkeit betraf."}
{"dataset_id": "acl_6060", "sample_id": 142, "src_lang": "en", "tgt_lang": "de", "output": "Während die restlichen fünfzehn Prozent entweder mit der Sozialversicherung, Ausländern oder Arbeit zu tun haben."}
{"dataset_id": "acl_6060", "sample_id": 143, "src_lang": "en", "tgt_lang": "de", "output": "Die Artikel sind auch sehr diverse, da sie aus dreißig zwei verschiedenen Belgischen Codes kommen, die eine große Anzahl von illegalen Themen abdecken."}
{"dataset_id": "acl_6060", "sample_id": 144, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist die Gesamtzahl der Artikel aus jedem dieser belgischen Codes."}
{"dataset_id": "acl_6060", "sample_id": 145, "src_lang": "en", "tgt_lang": "de", "output": "Aus den twenty two thousand six hundred thirty three Artikeln, nur eintausend sechs hundred twelve sind als relevant zu at least einem"}
{"dataset_id": "acl_6060", "sample_id": 146, "src_lang": "en", "tgt_lang": "de", "output": "nur eine Frage in den Daten sätzen. Und etwa achtzig Prozent dieser zitierten Artikel stammen aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafverfolgungsgesetz."}
{"dataset_id": "acl_6060", "sample_id": 147, "src_lang": "en", "tgt_lang": "de", "output": "Inzwischen enthalten achtzehn von dreißig zwei Codes weniger als fünf Artikel, die als relevant für mindestens eine Frage erwähnt werden."}
{"dataset_id": "acl_6060", "sample_id": 148, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann durch die Tatsache erklärt werden, dass diese Codes weniger auf Einzelpersonen und ihre Anliegen fokussieren."}
{"dataset_id": "acl_6060", "sample_id": 149, "src_lang": "en", "tgt_lang": "de", "output": "Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünf Prozent von ihnen sind in der"}
{"dataset_id": "acl_6060", "sample_id": 150, "src_lang": "en", "tgt_lang": "de", "output": "Mit unseren Datensätzen benchmarken wir verschiedene Rückholmethoden, einschließlich lexikalischer und denser Architektur."}
{"dataset_id": "acl_6060", "sample_id": 151, "src_lang": "en", "tgt_lang": "de", "output": "Bei einer Abfrage in einem Artikel weist ein lexikalisches Modell der Abfrageartikelpaar eine Punktzahl zu, indem es die Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfragezeiten berechnet."}
{"dataset_id": "acl_6060", "sample_id": 152, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit den Standard-TFIDF- und BM-25-Rankingfunktionen."}
{"dataset_id": "acl_6060", "sample_id": 153, "src_lang": "en", "tgt_lang": "de", "output": "Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten."}
{"dataset_id": "acl_6060", "sample_id": 154, "src_lang": "en", "tgt_lang": "de", "output": "Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die semantische Beziehungen zwischen Abfragen und Artikeln erfassen kann."}
{"dataset_id": "acl_6060", "sample_id": 155, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert und eine relevante Punktzahl zwischen einem Abfrage-Artikelpaar anhand der Ähnlichkeit ihrer Eingebettungen berechnet."}
{"dataset_id": "acl_6060", "sample_id": 156, "src_lang": "en", "tgt_lang": "de", "output": "Diese Einbettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Einbettungsmodells."}
{"dataset_id": "acl_6060", "sample_id": 157, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst untersuchen wir die Wirksamkeit siamesischer Biancoder in einer Nullschussbewertung, was bedeutet, dass vorgebildete Word-Embedding-Modelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 158, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und FastText, und kontextunabhängigen Einbettungsmodellen, nämlich Roberta und genauer gesagt Camembert, das ein französisches Roberta-Modell ist."}
{"dataset_id": "acl_6060", "sample_id": 159, "src_lang": "en", "tgt_lang": "de", "output": "Zusätzlich trainieren wir unser eigenes Camembert-basiertes Modell. Beyond quoters."}
{"dataset_id": "acl_6060", "sample_id": 160, "src_lang": "en", "tgt_lang": "de", "output": "Beispiele auf allen Datensätzen. Beachten Sie, dass wir für das Training mit den beiden Flavors der Bianco architektur experimentieren."}
{"dataset_id": "acl_6060", "sample_id": 161, "src_lang": "en", "tgt_lang": "de", "output": "Siamese, das ein einzigartiges Word-Embedding-Modell verwendet, das die Query und den Artikel in einem gemeinsamen Densivektorraum mappiert, und Tutor, das zwei unabhängige Word-Embedding-Modelle verwendet, die die Query und den Artikel separat in zwei verschiedene Embedding-Spaces codieren."}
{"dataset_id": "acl_6060", "sample_id": 162, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit dem Pooling von Mittel, Max und CLS sowie mit dem Punktprodukt und dem Kosinus für die Rechengelähnungen."}
{"dataset_id": "acl_6060", "sample_id": 163, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unserer Ausgangslinie auf den Testsätzen."}
{"dataset_id": "acl_6060", "sample_id": 164, "src_lang": "en", "tgt_lang": "de", "output": "Dann mit den lexikalischen Methoden oben, den Siamese-B-Encodern, die in einer Null-Schuss-Einrichtung evaluiert wurden, und den fein abgestimmten B-Encodern unten."}
{"dataset_id": "acl_6060", "sample_id": 165, "src_lang": "en", "tgt_lang": "de", "output": "Insgesamt übertreffen die fein abgestimmten Bianchore alle anderen Basslinien deutlich."}
{"dataset_id": "acl_6060", "sample_id": 166, "src_lang": "en", "tgt_lang": "de", "output": "Das Two Tower Modell verbessert sich gegenüber seiner Siamese-Variante auf Recallat one hundred, aber es funktioniert ähnlich bei den anderen Metriken."}
{"dataset_id": "acl_6060", "sample_id": 167, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl BM twenty five den trainierten Biancode erheblich unterlegen hat, zeigt seine Leistung, dass es immer noch eine starke Grundlage für Domain Specific Retrieval ist."}
{"dataset_id": "acl_6060", "sample_id": 168, "src_lang": "en", "tgt_lang": "de", "output": "Was die Nullschussbewertung des siamesischen Biancoders betrifft, stellen wir fest, dass die direkte Verwendung der Eingebettungen eines vorgebildeten Kamembert-Modells ohne Optimierung für die Informationsabholungsaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt."}
{"dataset_id": "acl_6060", "sample_id": 169, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus haben wir festgestellt, dass der Word-Tuec-basierte Biancoder den Vastex- und Vogelbasierten Modell deutlich übertrifft, was darauf hindeutet, dass möglicherweise vor-train-Word-Level-Embeddings für die Aufgabe besser geeignet sind als Charakter- oder Unterword-Level-Embeddings, wenn sie von vorn verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 170, "src_lang": "en", "tgt_lang": "de", "output": "Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Möglichkeiten für Verbesserungen im Vergleich zu einem geschickten Rechtsexperten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann."}
{"dataset_id": "acl_6060", "sample_id": 171, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns mit zwei Einschränkungen aller Datensätze abschließen."}
{"dataset_id": "acl_6060", "sample_id": 172, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst ist der Artikelkorpus auf die aus den 32 belgischen Gesetzen gezogenen beschränkt, die nicht das gesamte belgische Gesetz abdecken, da Artikel aus Verordnungen, Richtlinien und Verordnungen fehlen."}
{"dataset_id": "acl_6060", "sample_id": 173, "src_lang": "en", "tgt_lang": "de", "output": "Während der Datensatzkonstruktion werden alle Referenzen zu diesen ungesammelten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Bruchteil der ursprünglichen Anzahl relevanten Artikeln erhalten."}
{"dataset_id": "acl_6060", "sample_id": 174, "src_lang": "en", "tgt_lang": "de", "output": "Diese Informationsloss impliziert, dass die Antwort in den verbleibenden relevanten Artikeln unvollständig sein könnte, obwohl sie immer noch vollständig angemessen ist."}
{"dataset_id": "acl_6060", "sample_id": 175, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens sollten wir beachten, dass nicht alle rechtlichen Fragen allein mit Gesetzen beantwortet werden können."}
{"dataset_id": "acl_6060", "sample_id": 176, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel die Frage: Kann ich meine Mieter vertreiben, wenn sie zu viel Lärm machen?"}
{"dataset_id": "acl_6060", "sample_id": 177, "src_lang": "en", "tgt_lang": "de", "output": "Might not have a detaillierte Antwort innerhalb des gesetzlichen Gesetzes, das eine spezifische Noise-Threshold quantifiziert, bei der Räumung zulässig ist."}
{"dataset_id": "acl_6060", "sample_id": 178, "src_lang": "en", "tgt_lang": "de", "output": "Stattdessen sollte der Vermieter wahrscheinlich mehr auf die Rechtsprechung vertrauen und Präzedenzfälle finden, die ähnlich zu ihrer aktuellen Situation sind."}
{"dataset_id": "acl_6060", "sample_id": 179, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel macht der Tenant zwei Parties pro Woche und tut es."}
{"dataset_id": "acl_6060", "sample_id": 180, "src_lang": "en", "tgt_lang": "de", "output": "Daher sind einige Fragen besser als andere für die gesetzliche Artikel-Retrieval-Tasche geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen."}
{"dataset_id": "acl_6060", "sample_id": 181, "src_lang": "en", "tgt_lang": "de", "output": "Wir hoffen, dass all diese Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle zur Berechnung von gesetzlichen Artikeln weckt,"}
{"dataset_id": "acl_6060", "sample_id": 182, "src_lang": "en", "tgt_lang": "de", "output": "Das kann dazu beitragen, den Zugang zur Justiz für alle zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 183, "src_lang": "en", "tgt_lang": "de", "output": "Sie können unsere Papier, Datset und Code unter den folgenden Links sehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 184, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir freuen uns, unsere Arbeit an Vowls vorzustellen, einem unabhängigen Benchmark, der für die Testung von Vision- und Sprachmodellen mit bestimmten sprachlichen Phänomenen gedacht ist."}
{"dataset_id": "acl_6060", "sample_id": 185, "src_lang": "en", "tgt_lang": "de", "output": "Warum haben wir uns die Mühe gemacht, diesen Benchmark festzulegen?"}
{"dataset_id": "acl_6060", "sample_id": 186, "src_lang": "en", "tgt_lang": "de", "output": "In den letzten Jahren haben wir eine Explosion von Transformer-basierten Vision- und Sprachmodellen gesehen, die auf große Mengen an Bild-Textpaaren vorgebildet wurden."}
{"dataset_id": "acl_6060", "sample_id": 187, "src_lang": "en", "tgt_lang": "de", "output": "Jedes dieser Modelle drängt die Moderne in der Vision und Sprachaufgaben wie der Antwort auf visuelle Fragen, der visuellen Sinnesreasoning, der Bildherstellung und der Phrase-Grundung voran."}
{"dataset_id": "acl_6060", "sample_id": 188, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben also eine Nachricht erhalten. Die Genauigkeit dieser für die Aufgabe spezifischen Benchmarks steigt stetig."}
{"dataset_id": "acl_6060", "sample_id": 189, "src_lang": "en", "tgt_lang": "de", "output": "Aber wissen wir, was die Modelle tatsächlich gelernt haben?"}
{"dataset_id": "acl_6060", "sample_id": 190, "src_lang": "en", "tgt_lang": "de", "output": "Was hat ein Vision- und Sprachtransformer verstanden, als er diesem Bild und diesem Satz eine hohe Punktzahl zugewiesen hat, um es zu vereinbaren?"}
{"dataset_id": "acl_6060", "sample_id": 191, "src_lang": "en", "tgt_lang": "de", "output": "Und der niedrige Punkt für diesen."}
{"dataset_id": "acl_6060", "sample_id": 192, "src_lang": "en", "tgt_lang": "de", "output": "Konzentrieren sich Vision- und Sprachmodelle auf das Richtige?"}
{"dataset_id": "acl_6060", "sample_id": 193, "src_lang": "en", "tgt_lang": "de", "output": "Oder konzentrieren sie sich auf Vorurteile, wie durch frühere Arbeiten gezeigt?"}
{"dataset_id": "acl_6060", "sample_id": 194, "src_lang": "en", "tgt_lang": "de", "output": "Um mehr Licht auf diesen Aspekt zu werfen, schlagen wir eine tauschfreundlichere Richtung vor und führen VALS ein, das die Empfindlichkeit von Seh- und Sprachmodellen auf spezifische sprachliche Phänomene testet, die sowohl die sprachlichen als auch die visuellen Modalitäten beeinflussen."}
{"dataset_id": "acl_6060", "sample_id": 195, "src_lang": "en", "tgt_lang": "de", "output": "Wir zielen auf Existenz, Vielfalt, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenzen ab."}
{"dataset_id": "acl_6060", "sample_id": 196, "src_lang": "en", "tgt_lang": "de", "output": "Aber wie testen wir, ob die Vision- und Sprachmodelle dieses Phänomen festgehalten haben?"}
{"dataset_id": "acl_6060", "sample_id": 197, "src_lang": "en", "tgt_lang": "de", "output": "Durch Foiling, eine Methode, die zuvor nur für Vision und Sprachmodelle von Ravi Shakar und seinen Mitarbeitern für Nomenphrasen angewendet wurde, und bei der Zählung von uns in früheren Arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 198, "src_lang": "en", "tgt_lang": "de", "output": "Foiling bedeutet im Grunde, dass wir den Bildunterschrift eines Bildes nehmen und einen Foil erzeugen, indem wir den Unterschrift so verändern, dass er das Bild nicht mehr beschreibt."}
{"dataset_id": "acl_6060", "sample_id": 199, "src_lang": "en", "tgt_lang": "de", "output": "Wir ändern diese Phrase, indem wir uns auf sechs spezifische Teile konzentrieren, wie Existenz, Pluralität, Zählung, räumliche Beziehungen, Aktionen und Entitätsreferenz, wobei jedes Teil aus einem oder mehreren Instrumenten bestehen kann, falls wir mehr als eine interessante Möglichkeit gefunden haben, FOIL-Instanzen zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 200, "src_lang": "en", "tgt_lang": "de", "output": "Beispielsweise haben wir im Fall des Aktionsstücks zwei Instrumente, eines, bei dem das Aktionsverb mit einer anderen Aktion geändert wird, und eines, bei dem die Spielzeuge ausgetauscht werden."}
{"dataset_id": "acl_6060", "sample_id": 201, "src_lang": "en", "tgt_lang": "de", "output": "Zählen und Ko-Referenzen sind auch Stücke, die mehr als ein Instrument haben."}
{"dataset_id": "acl_6060", "sample_id": 202, "src_lang": "en", "tgt_lang": "de", "output": "Und wir schaffen diese Fehler, indem wir sicherstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererseits gültige Sätze sind."}
{"dataset_id": "acl_6060", "sample_id": 203, "src_lang": "en", "tgt_lang": "de", "output": "Das ist nicht einfach, da eine fehlerhafte Beschreibung weniger wahrscheinlich sein kann als die ursprüngliche Beschreibung."}
{"dataset_id": "acl_6060", "sample_id": 204, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel ist es zwar nicht unmöglich, statistisch gesehen ist es weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann Pflanzen schneiden, und große Vision- und Sprachmodelle könnten dies aufgreifen."}
{"dataset_id": "acl_6060", "sample_id": 205, "src_lang": "en", "tgt_lang": "de", "output": "Um gültige Folien zu erhalten, müssen wir daher Maßnahmen ergreifen."}
{"dataset_id": "acl_6060", "sample_id": 206, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst nutzen wir starke Sprachmodelle, um FOILs vorzuschlagen."}
{"dataset_id": "acl_6060", "sample_id": 207, "src_lang": "en", "tgt_lang": "de", "output": "Zweitens verwenden wir die Inferenz durch natürliche Sprache oder kurz NLI, um Folien zu filtern, die das Bild noch beschreiben könnten, da wir bei der Konstruktion von Folien sicherstellen müssen, dass sie das Bild nicht beschreiben."}
{"dataset_id": "acl_6060", "sample_id": 208, "src_lang": "en", "tgt_lang": "de", "output": "Um dies automatisch zu testen, wenden wir eine Schlussfolgerung aus natürlicher Sprache mit der folgenden Begründung an."}
{"dataset_id": "acl_6060", "sample_id": 209, "src_lang": "en", "tgt_lang": "de", "output": "Wir betrachten ein Bild als die Prämisse und seine Beschriftung als die damit verbundene Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 210, "src_lang": "en", "tgt_lang": "de", "output": "In addition, wir betrachten die Kaption als die Premise und die FOIL als ihre Hypothese."}
{"dataset_id": "acl_6060", "sample_id": 211, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI-Modell die FOIL als widersprechend oder neutral gegenüber dem Untertitel vorhersagt, nehmen wir dies als Indikator für eine gültige FOIL."}
{"dataset_id": "acl_6060", "sample_id": 212, "src_lang": "en", "tgt_lang": "de", "output": "Wenn ein NLI vorhersagt, dass die Folie durch den Untertitel enthalten ist, kann es keine gute Folie sein, da sie durch Transitivität eine wahrhaftige Beschreibung des Bildes liefert und wir diese Folien ausfiltern."}
{"dataset_id": "acl_6060", "sample_id": 213, "src_lang": "en", "tgt_lang": "de", "output": "Aber dieses Prozedere ist nicht perfekt. Es ist nur ein Indikator für valide Foil."}
{"dataset_id": "acl_6060", "sample_id": 214, "src_lang": "en", "tgt_lang": "de", "output": "Daher verwenden wir als dritte Maßnahme zur Erstellung gültiger FOILs menschliche Annotatoren, um die in Valse verwendeten Daten zu validieren."}
{"dataset_id": "acl_6060", "sample_id": 215, "src_lang": "en", "tgt_lang": "de", "output": "Nach dem Filtern und der menschlichen Bewertung haben wir also so viele Testfälle wie in dieser Tabelle beschrieben."}
{"dataset_id": "acl_6060", "sample_id": 216, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass VALS keine Trainingsdaten liefert, sondern nur Testdaten."}
{"dataset_id": "acl_6060", "sample_id": 217, "src_lang": "en", "tgt_lang": "de", "output": "Da es sich nur um einen Benchmark für Null-Schuss-Tests handelt, ist er so konzipiert, dass er die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vorausbildung nutzt."}
{"dataset_id": "acl_6060", "sample_id": 218, "src_lang": "en", "tgt_lang": "de", "output": "Die Feinabstimmung würde es den Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen."}
{"dataset_id": "acl_6060", "sample_id": 219, "src_lang": "en", "tgt_lang": "de", "output": "Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen nutzen."}
{"dataset_id": "acl_6060", "sample_id": 220, "src_lang": "en", "tgt_lang": "de", "output": "Und wie gesagt, wir sind daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vorausbildung haben."}
{"dataset_id": "acl_6060", "sample_id": 221, "src_lang": "en", "tgt_lang": "de", "output": "Wir experimentieren mit fünf Vision- und Sprachmodellen auf Vowels, nämlich mit CLIP, AlexMert, Wilbert, Wilbert Kelvin I und VisualBERT."}
{"dataset_id": "acl_6060", "sample_id": 222, "src_lang": "en", "tgt_lang": "de", "output": "Zwei unserer wichtigsten Bewertungsmetriken sind die Genauigkeit der Modelle bei der Klassifizierung von Bilder-Satzpaaren in Untertitel und FOILs."}
{"dataset_id": "acl_6060", "sample_id": 223, "src_lang": "en", "tgt_lang": "de", "output": "Vielleicht ist für dieses Video relevanter, dass wir unsere permissivere Metrik, die Paargenauigkeit, präsentieren, die misst, ob der Ausrichtungswert des Bildesatzes für das korrekte Textpaar des Bildes höher ist als für das fehlerhafte Paar."}
{"dataset_id": "acl_6060", "sample_id": 224, "src_lang": "en", "tgt_lang": "de", "output": "Weitere Metriken und Ergebnisse zu diesen Ergebnissen finden Sie in unserer Arbeit."}
{"dataset_id": "acl_6060", "sample_id": 225, "src_lang": "en", "tgt_lang": "de", "output": "Die Ergebnisse mit Paar-Präzision sind hier gezeigt und entsprechen den Ergebnissen, die wir aus den anderen Metriken erhalten haben. Die beste Leistung bei Nullschüssen wird von Wilbert zwölf in einem, gefolgt von Wilbert, LXMert, Clip und schließlich VisualBird erreicht."}
{"dataset_id": "acl_6060", "sample_id": 226, "src_lang": "en", "tgt_lang": "de", "output": "Es ist bemerkenswert, wie Instrumente, die sich auf einzelne Objekte wie Existenz und Nomenphrasen konzentrieren, von Wilbert Twelve in One fast gelöst werden, wobei er hervorhebt, dass Modelle in der Lage sind, benannte Objekte und ihre Anwesenheit in Bildern zu identifizieren."}
{"dataset_id": "acl_6060", "sample_id": 227, "src_lang": "en", "tgt_lang": "de", "output": "Allerdings kann in unseren Adversarial Foiling-Einstellungen keine der verbleibenden Teile zuverlässig gelöst werden"}
{"dataset_id": "acl_6060", "sample_id": 228, "src_lang": "en", "tgt_lang": "de", "output": "Aus den Pluralitäten und Zählungsinstrumenten sehen wir, dass Seh- und Sprachmodelle Schwierigkeiten haben, Verweise auf einzelne und mehrere Objekte zu unterscheiden oder sie in einem Bild zu zählen."}
{"dataset_id": "acl_6060", "sample_id": 229, "src_lang": "en", "tgt_lang": "de", "output": "Die Beziehung Ps zeigt, dass sie Schwierigkeiten haben, eine benannte räumliche Beziehung zwischen Objekten in einem Bild korrekt zu klassifizieren,"}
{"dataset_id": "acl_6060", "sample_id": 230, "src_lang": "en", "tgt_lang": "de", "output": "Sie haben auch Schwierigkeiten, Aktionen zu unterscheiden und ihre Teilnehmer zu identifizieren, auch wenn sie durch plausibel Vorurteile unterstützt werden, wie wir im Aktionsteil sehen."}
{"dataset_id": "acl_6060", "sample_id": 231, "src_lang": "en", "tgt_lang": "de", "output": "Aus dem Ko-Referenz-Bereich erfahren wir, dass es für Vision- und Sprachmodelle ebenfalls schwierig ist, mehrere Referenzen auf das gleiche Objekt in einem Bild mit Pronomen zu verfolgen."}
{"dataset_id": "acl_6060", "sample_id": 232, "src_lang": "en", "tgt_lang": "de", "output": "Als Verstandskontrolle und weil es ein interessantes Experiment ist, haben wir auch zwei Textmodelle, GPT eins und GPT zwei, benchmarkt, um zu beurteilen, ob Valse durch diese Einmodalmodelle gelöst werden kann, indem wir die Verwirrung der richtigen und der fehlgeschlagenen Beschriftung berechnen und den Eintrag mit der geringsten Verwirrung vorhersagen."}
{"dataset_id": "acl_6060", "sample_id": 233, "src_lang": "en", "tgt_lang": "de", "output": "Wenn die Verwirrung für die FOIL höher ist, nehmen wir dies als Hinweis darauf, dass die FOIL-Beschriftung unter einer plausibilen Voreingenommenheit oder anderen sprachlichen Voreingenommenheiten leidet."}
{"dataset_id": "acl_6060", "sample_id": 234, "src_lang": "en", "tgt_lang": "de", "output": "Und es ist interessant zu sehen, dass in einigen Fällen die Text nur GPT Modelle die Plausibilität der Welt besser erfassen haben als die Vision und Language Modelle."}
{"dataset_id": "acl_6060", "sample_id": 235, "src_lang": "en", "tgt_lang": "de", "output": "Zusammenfassend lässt sich sagen, dass VALS ein Benchmark ist, der die Linse der sprachlichen Konstruktionen nutzt, um der Community bei der Verbesserung von Seh- und Sprachmodellen zu helfen, indem sie ihre visuellen Grundlagefähigkeiten hart testet."}
{"dataset_id": "acl_6060", "sample_id": 236, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass Seh- und Sprachmodelle benannte Objekte und ihre Anwesenheit in Bildern gut identifizieren, wie das Existenzstück zeigt, aber Schwierigkeiten haben, ihre gegenseitige Abhängigkeit und Beziehungen in visuellen Szenen zu begründen, wenn sie gezwungen sind, sprachliche Indikatoren zu respektieren."}
{"dataset_id": "acl_6060", "sample_id": 237, "src_lang": "en", "tgt_lang": "de", "output": "Wir möchten die Community wirklich ermutigen, VALS zur Messung des Fortschritts hin zur Sprachbasis mit Vision und Sprachmodellen zu verwenden."}
{"dataset_id": "acl_6060", "sample_id": 238, "src_lang": "en", "tgt_lang": "de", "output": "Und noch mehr, VALS könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von VALS getesteten Aspekte hilft."}
{"dataset_id": "acl_6060", "sample_id": 239, "src_lang": "en", "tgt_lang": "de", "output": "Wenn Sie interessiert sind, sollten Sie sich die Walls-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 240, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamizura von der Universität Tokio."}
{"dataset_id": "acl_6060", "sample_id": 241, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde eine Papier entitelt RNSAM, ein Large Scale DSET für automatische Risikogrammierung beim Commitologizieren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 242, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde in dieser Reihenfolge erklären"}
{"dataset_id": "acl_6060", "sample_id": 243, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst werde ich die automatische Risikogenerierung vorstellen, an der wir in dieser Forschung arbeiten."}
{"dataset_id": "acl_6060", "sample_id": 244, "src_lang": "en", "tgt_lang": "de", "output": "ReleaseNote ist ein technisches Dokument, das die bei jeder Veröffentlichung eines Softwareprodukts zusammenfasst."}
{"dataset_id": "acl_6060", "sample_id": 245, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild zeigt die Restnoten für Bosch 2.6"}
{"dataset_id": "acl_6060", "sample_id": 246, "src_lang": "en", "tgt_lang": "de", "output": "User Us Library These Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consuming, um manuell zu erstellen."}
{"dataset_id": "acl_6060", "sample_id": 247, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es sehr nützlich, in der Lage zu sein, hochwertige Release-Noten automatisch zu erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 248, "src_lang": "en", "tgt_lang": "de", "output": "Ich werde auf zwei frühere Forschungen zur automatischen Frischknotengenerierung verweisen."}
{"dataset_id": "acl_6060", "sample_id": 249, "src_lang": "en", "tgt_lang": "de", "output": "Das erste System, das Arena erstellt wurde, wurde 2014 erstellt."}
{"dataset_id": "acl_6060", "sample_id": 250, "src_lang": "en", "tgt_lang": "de", "output": "Es erfordert eine ruralbasierte Approach, zum Beispiel, indem man die Change Extractor verwendet, um Code differenzen, Bibliothekänder und Dokumentenänderungen von den differenzen zwischen Releases zu extrahieren, und schließlich kombinieren sie."}
{"dataset_id": "acl_6060", "sample_id": 251, "src_lang": "en", "tgt_lang": "de", "output": "Das bemerkenswerteste Merkmal dieses Systems ist der Ausgaben-Extraktor in der oberen rechten Ecke,"}
{"dataset_id": "acl_6060", "sample_id": 252, "src_lang": "en", "tgt_lang": "de", "output": "Dieses muss mit dem Issues-Ökosystem verbunden sein und kann nur auf Projekte mit Null angewendet werden."}
{"dataset_id": "acl_6060", "sample_id": 253, "src_lang": "en", "tgt_lang": "de", "output": "hier. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 254, "src_lang": "en", "tgt_lang": "de", "output": "Der zweite ist Grief. Dies entweder angesagt in 2014."}
{"dataset_id": "acl_6060", "sample_id": 255, "src_lang": "en", "tgt_lang": "de", "output": "2020. Es ist auf dem Internet verfügbar und kann via PIP gespeichert werden."}
{"dataset_id": "acl_6060", "sample_id": 256, "src_lang": "en", "tgt_lang": "de", "output": "Dieses System verfügt über ein einfaches Textklassifizierungsmodell basierendes auf Lernen und Ausgaben aus fünf Labors, wie z. B. Funktionen oder Fehlerbehebungen, für jede Eingabe-Kommentarnachricht."}
{"dataset_id": "acl_6060", "sample_id": 257, "src_lang": "en", "tgt_lang": "de", "output": "Das Bild ist ein Sample-User, das eine Korrektur für Fehlerkorrekturen erhält."}
{"dataset_id": "acl_6060", "sample_id": 258, "src_lang": "en", "tgt_lang": "de", "output": "Griffiths Trainingdaten sind sehr klein, etwa fünftausend, und werden in den Experimenten beschriebenen unten gezeigt."}
{"dataset_id": "acl_6060", "sample_id": 259, "src_lang": "en", "tgt_lang": "de", "output": "Die Leistung des statistischen Kreuzschaltmodells ist nicht höher."}
{"dataset_id": "acl_6060", "sample_id": 260, "src_lang": "en", "tgt_lang": "de", "output": "Ich präsentiere zwei verwandte Forschungen, aber es gibt Probleme mit begrenzter Anwendbarkeit und knappen Datenressourcen."}
{"dataset_id": "acl_6060", "sample_id": 261, "src_lang": "en", "tgt_lang": "de", "output": "Unser Papier löst diese beiden Probleme und erzeugt automatisch hochwertige Freigabe-Noten."}
{"dataset_id": "acl_6060", "sample_id": 262, "src_lang": "en", "tgt_lang": "de", "output": "Für das begrenzte Anwendungsprogramm schlagen wir eine hochwertige Klassifizierungsmethode mit nur Kommentarmeldungen als Eingabe vor."}
{"dataset_id": "acl_6060", "sample_id": 263, "src_lang": "en", "tgt_lang": "de", "output": "Diese vorgeschlagene Methode kann für alle englischen Repositories verwendet werden."}
{"dataset_id": "acl_6060", "sample_id": 264, "src_lang": "en", "tgt_lang": "de", "output": "Für das zweite Problem der Skarbstaatressourcen haben wir eine RNSAM DSET konsistent mit etwa 82.000 Datenpunkten erstellt, indem wir Daten aus öffentlichen GitHub Repositories mit der GitHub API erstellen."}
{"dataset_id": "acl_6060", "sample_id": 265, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes beschreibe ich unsere Daseinsetzung."}
{"dataset_id": "acl_6060", "sample_id": 266, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Beispiel für Daten."}
{"dataset_id": "acl_6060", "sample_id": 267, "src_lang": "en", "tgt_lang": "de", "output": "Die linke Seite ist die Nachricht des Komitees und die rechte Seite ist die Release-Note."}
{"dataset_id": "acl_6060", "sample_id": 268, "src_lang": "en", "tgt_lang": "de", "output": "Die Riesen sind als Verbesserungen, Verbesserungen, etc. gelobt."}
{"dataset_id": "acl_6060", "sample_id": 269, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Aufgabe eingerichtet, die die Kommentarnachrichten als Eingaben aufnimmt und die Raveled-Please-Notizen ausgibt."}
{"dataset_id": "acl_6060", "sample_id": 270, "src_lang": "en", "tgt_lang": "de", "output": "Dies kann als Zusammenfassungsaufgabe angesehen werden."}
{"dataset_id": "acl_6060", "sample_id": 271, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben vier Rubber, Funktionen, Verbesserungen, Fehlerbehebungen, Deprekationen, Entfernungen und Bremsänderungen vorgedefiniert."}
{"dataset_id": "acl_6060", "sample_id": 272, "src_lang": "en", "tgt_lang": "de", "output": "Diese wurden aufgrund früherer Forschung und anderer Faktoren festgelegt."}
{"dataset_id": "acl_6060", "sample_id": 273, "src_lang": "en", "tgt_lang": "de", "output": "Die Rhythmus-Noten unten rechts werden aus den Rhythmus-Noten unten links abgezogen."}
{"dataset_id": "acl_6060", "sample_id": 274, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Moment müssen die vier Schuttwerke, die im Voraus aufgestellt wurden, entdeckt werden."}
{"dataset_id": "acl_6060", "sample_id": 275, "src_lang": "en", "tgt_lang": "de", "output": "Aber die Lager sind nicht immer mit jeder Freiheit übereinstimmen"}
{"dataset_id": "acl_6060", "sample_id": 276, "src_lang": "en", "tgt_lang": "de", "output": "Zum Beispiel, um Verbesserungen zu treffen, zu erhöhen, Verbesserungen, Verbesserungen, Optimierungen und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 277, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben eine Vokabulärliste mit etwa 30 Numbers für jede dieser Rotationsvariationen erstellt."}
{"dataset_id": "acl_6060", "sample_id": 278, "src_lang": "en", "tgt_lang": "de", "output": "Verwenden Sie es, um die Restnotkrasten zu erkennen und den Text der Restnotkrasten zu korrigieren."}
{"dataset_id": "acl_6060", "sample_id": 279, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes kommt eine Komiteemeldung."}
{"dataset_id": "acl_6060", "sample_id": 280, "src_lang": "en", "tgt_lang": "de", "output": "Die Nachrichten des Komitees sind nicht an jede Stimme gebunden."}
{"dataset_id": "acl_6060", "sample_id": 281, "src_lang": "en", "tgt_lang": "de", "output": "Wie in der image below, wenn die aktuelle Realität Boson zwei Punkt fünf zwei neunzehn, müssen wir die IDECHTEN"}
{"dataset_id": "acl_6060", "sample_id": 282, "src_lang": "en", "tgt_lang": "de", "output": "erfüllt die vorherige Version 2.5218 und erhält einen Tiff. Dies ist ein bisschen mühsam und es reicht nicht aus, nur eine Liste der Releases zu erhalten und sich die Vorher und Nachher anzusehen."}
{"dataset_id": "acl_6060", "sample_id": 283, "src_lang": "en", "tgt_lang": "de", "output": "Er erstellte eine Heuristik, die mit Ihnen übereinstimmt, um die vorherigen und nächsten Schauspielzeiten zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 284, "src_lang": "en", "tgt_lang": "de", "output": "Da sind die Horses."}
{"dataset_id": "acl_6060", "sample_id": 285, "src_lang": "en", "tgt_lang": "de", "output": "In der Hand, siebentausend zwei hundert Repositories"}
{"dataset_id": "acl_6060", "sample_id": 286, "src_lang": "en", "tgt_lang": "de", "output": "Außerdem beträgt die durchschnittliche Anzahl der freigegebenen Token 63, was für eine Zusammenfassungsaufgabe ziemlich hoch ist."}
{"dataset_id": "acl_6060", "sample_id": 287, "src_lang": "en", "tgt_lang": "de", "output": "Auch die Nummer der Unique Tokens ist bei Roger at eight thousand eight hundred thirty thousand."}
{"dataset_id": "acl_6060", "sample_id": 288, "src_lang": "en", "tgt_lang": "de", "output": "aufgrund der großen Anzahl von einzigartigen Kasten und Methoden im Repertory."}
{"dataset_id": "acl_6060", "sample_id": 289, "src_lang": "en", "tgt_lang": "de", "output": "Als nächstes erkläre ich die vorgeschlagene Methode."}
{"dataset_id": "acl_6060", "sample_id": 290, "src_lang": "en", "tgt_lang": "de", "output": "Das Querschnitts-, Extraktions- und Abstruktionsmodell besteht aus zwei neuer Modulen"}
{"dataset_id": "acl_6060", "sample_id": 291, "src_lang": "en", "tgt_lang": "de", "output": "Ein Klassifier mit Bot oder Code Bot und ein Generator mit Bot."}
{"dataset_id": "acl_6060", "sample_id": 292, "src_lang": "en", "tgt_lang": "de", "output": "Zunächst verwendet GEAS einen Klassifizierer, um jede Kommentarnachricht in fünf RESNOT-Klassen zu klassifizieren: Funktionen, Verbesserungen, Fehlerbehebungen, Duplizierungen und andere."}
{"dataset_id": "acl_6060", "sample_id": 293, "src_lang": "en", "tgt_lang": "de", "output": "Die als anderer eingestuften Komitee-Nachrichten werden abgelehnt."}
{"dataset_id": "acl_6060", "sample_id": 294, "src_lang": "en", "tgt_lang": "de", "output": "Dann wendet GAS den Generator unabhängig auf die vier Rudder-Dokumente an und erzeugt für jede Klasse Risikonode."}
{"dataset_id": "acl_6060", "sample_id": 295, "src_lang": "en", "tgt_lang": "de", "output": "Bei dieser Aufgabe sind die direkten Übereinstimmungen zwischen Commit-Nachrichten und Lesemerkungen nicht bekannt."}
{"dataset_id": "acl_6060", "sample_id": 296, "src_lang": "en", "tgt_lang": "de", "output": "Um den Klassifizierer zu trainieren, weisen wir jeder Eingabe-Commit-Nachricht Pseudorabben zu, indem wir die ersten zehn Zeichen jeder Commit-Nachricht verwenden."}
{"dataset_id": "acl_6060", "sample_id": 297, "src_lang": "en", "tgt_lang": "de", "output": "Wir modellieren die Kreuzstreifen-Abstruktiv-Summersätze durch zwei verschiedene Methoden."}
{"dataset_id": "acl_6060", "sample_id": 298, "src_lang": "en", "tgt_lang": "de", "output": "Das erste Modell, das wir GIS Single nennen, besteht aus einem einzigen SEC-Netzwerk und generiert einen einzigen Long-SNode-Text, der eine Kombination von Eingabe-Commit-Nachrichten liefert."}
{"dataset_id": "acl_6060", "sample_id": 299, "src_lang": "en", "tgt_lang": "de", "output": "Der Ausgangstext kann in Kreuzzeichen aufgeteilt werden, basierend auf speziellen Kreuz-Spezifischen Endpunkt-Symbolen."}
{"dataset_id": "acl_6060", "sample_id": 300, "src_lang": "en", "tgt_lang": "de", "output": "Die zweite Methode, die wir GSMarch nennen, besteht aus vier verschiedenen SEC-to-SEC-Netzwerken, von denen jede einer der RES-Knotenklassen entspricht."}
{"dataset_id": "acl_6060", "sample_id": 301, "src_lang": "en", "tgt_lang": "de", "output": "Okay, das macht Spain's Experiment."}
{"dataset_id": "acl_6060", "sample_id": 302, "src_lang": "en", "tgt_lang": "de", "output": "Es wurden fünf Methoden verglichen: CS, CS Single, CS Smart, Russelling und die vorherige Studienbeschreibung."}
{"dataset_id": "acl_6060", "sample_id": 303, "src_lang": "en", "tgt_lang": "de", "output": "Bei der Abrissung sind in einigen Fällen diese Noten in mehreren Sätzen ausgeführt."}
{"dataset_id": "acl_6060", "sample_id": 304, "src_lang": "en", "tgt_lang": "de", "output": "Da es schwierig ist, die Anzahl der Sätze als Null zu berechnen, werden sie mit Leerzeichen kombiniert und als ein langer Satz behandelt."}
{"dataset_id": "acl_6060", "sample_id": 305, "src_lang": "en", "tgt_lang": "de", "output": "Das Büro ist penetrativ, wenn das System einen kurzen Satz ausgibt"}
{"dataset_id": "acl_6060", "sample_id": 306, "src_lang": "en", "tgt_lang": "de", "output": "Diese Strafe führt zu einem geringeren Brauvolumen. In den als nächstes beschriebenen Experimentenergebnissen"}
{"dataset_id": "acl_6060", "sample_id": 307, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich erzeugen wir auch eine Spezifität, da Rouge und Brux nicht erzeugt werden können, wenn die Riesen-Knoten leer sind."}
{"dataset_id": "acl_6060", "sample_id": 308, "src_lang": "en", "tgt_lang": "de", "output": "Eine hohe Spezifität bedeutet, dass die Modellprojekte ausgegeben sind, die in Fällen, in denen die Reasonals empfangen, empfindlich sind."}
{"dataset_id": "acl_6060", "sample_id": 309, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse."}
{"dataset_id": "acl_6060", "sample_id": 310, "src_lang": "en", "tgt_lang": "de", "output": "Da der Daseit Emailadresse, Hashbarriers, etc. enthält, erweitern wir auch den Quint Daseit, der sie ausschließt."}
{"dataset_id": "acl_6060", "sample_id": 311, "src_lang": "en", "tgt_lang": "de", "output": "Sie hat und sie hat Rouge Air-Punkte erreicht, die mehr als zehn Punkte höher waren als die Baselines."}
{"dataset_id": "acl_6060", "sample_id": 312, "src_lang": "en", "tgt_lang": "de", "output": "Insbesondere auf dem Green Test set, der Square Gap zwischen der proposierten Methode und der Basis jumped zu mehr als 20 Punkten."}
{"dataset_id": "acl_6060", "sample_id": 313, "src_lang": "en", "tgt_lang": "de", "output": "Diese Ergebnisse zeigen, dass sie und sie erfolgreich sind."}
{"dataset_id": "acl_6060", "sample_id": 314, "src_lang": "en", "tgt_lang": "de", "output": "GAS hat eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Crossfire und eines Generators auf das Training des Crossfire-Systems mit Pseudobus effektiv ist."}
{"dataset_id": "acl_6060", "sample_id": 315, "src_lang": "en", "tgt_lang": "de", "output": "Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, weil der Klassifizierer sich auf die relevanten Kommittentests für jeden Kurs konzentrieren kann."}
{"dataset_id": "acl_6060", "sample_id": 316, "src_lang": "en", "tgt_lang": "de", "output": "Sie isst in dieser Zeit viel höher als wenn sie ledig ist."}
{"dataset_id": "acl_6060", "sample_id": 317, "src_lang": "en", "tgt_lang": "de", "output": "Dies deutet darauf hin, dass es auch effektiv ist, für jede dieser Notengrasse unabhängig verschiedene Perspektivsummerisierungsmodelle zu entwickeln."}
{"dataset_id": "acl_6060", "sample_id": 318, "src_lang": "en", "tgt_lang": "de", "output": "Hero und Eronasus"}
{"dataset_id": "acl_6060", "sample_id": 319, "src_lang": "en", "tgt_lang": "de", "output": "Xia's Methoden neigen dazu, kürzere Sätze als menschliche Referenz-Sätze zu erhalten."}
{"dataset_id": "acl_6060", "sample_id": 320, "src_lang": "en", "tgt_lang": "de", "output": "In der Figur auf der rechten Referenz hat drei oder vier Sätze, während CS nur eins hat."}
{"dataset_id": "acl_6060", "sample_id": 321, "src_lang": "en", "tgt_lang": "de", "output": "Der Grund für diese Modellzugabe ist, dass in den Trainingsdaten nur 33 % der Sätze im Rabel Merkmale und 40 % im Rabel Verbesserungen vorhanden sind."}
{"dataset_id": "acl_6060", "sample_id": 322, "src_lang": "en", "tgt_lang": "de", "output": "Darüber hinaus können CES Methoden ohne zusätzliche Informationen keine genauen Risikobewertungen erzeugen."}
{"dataset_id": "acl_6060", "sample_id": 323, "src_lang": "en", "tgt_lang": "de", "output": "Das obere Beispiel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommentarmeldung, und die Kommentarfassung kann nicht generiert werden, ohne auf die entsprechende Peru-Request oder -Erstellung hinzugefügt."}
{"dataset_id": "acl_6060", "sample_id": 324, "src_lang": "en", "tgt_lang": "de", "output": "Das untenstehende Beispiel zeigt, dass die beiden Kommentarberichte im Eingaben miteinander verbunden sind und in einen Satz kombiniert werden sollten, aber dies geschieht nicht."}
{"dataset_id": "acl_6060", "sample_id": 325, "src_lang": "en", "tgt_lang": "de", "output": "Schließlich eine Schlussfolgerung."}
{"dataset_id": "acl_6060", "sample_id": 326, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben einen neuen Datensatz für die automatische Personalgenerierung erstellt,"}
{"dataset_id": "acl_6060", "sample_id": 327, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben auch die Aufgabe, Kommentarmeldungen einzugeben und sie zusammenzufassen, sodass sie für alle Projekte auf Englisch anwendbar ist."}
{"dataset_id": "acl_6060", "sample_id": 328, "src_lang": "en", "tgt_lang": "de", "output": "Unsere Experimente zeigen, dass die vorgeschlagene Methode die Bassrate besser laut macht als die Bassrate."}
{"dataset_id": "acl_6060", "sample_id": 329, "src_lang": "en", "tgt_lang": "de", "output": "Bitte schauen Sie sich unsere Dessert-Audit-Tab an."}
{"dataset_id": "acl_6060", "sample_id": 330, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 331, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist ein Safarari,"}
{"dataset_id": "acl_6060", "sample_id": 332, "src_lang": "en", "tgt_lang": "de", "output": "Und ich werde unsere Arbeit über die Anreicherung von Tabellen mit Hilfe von fein abgestimmten Transformatoren präsentieren."}
{"dataset_id": "acl_6060", "sample_id": 333, "src_lang": "en", "tgt_lang": "de", "output": "Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Merkmale der Daten."}
{"dataset_id": "acl_6060", "sample_id": 334, "src_lang": "en", "tgt_lang": "de", "output": "Aber manchmal sind seine Funktionen begrenzt."}
{"dataset_id": "acl_6060", "sample_id": 335, "src_lang": "en", "tgt_lang": "de", "output": "Die Erstellung von Funktionen mit einer anderen Datenquelle kann erhebliche Informationen bieten."}
{"dataset_id": "acl_6060", "sample_id": 336, "src_lang": "en", "tgt_lang": "de", "output": "Unser Forschungsziel ist die automatische Anreicherung von Tabelldaten mit externen Quellen-Freitexten."}
{"dataset_id": "acl_6060", "sample_id": 337, "src_lang": "en", "tgt_lang": "de", "output": "Nehmen wir an, wir haben eine Tabelldatensammlung und eine Wissensbasis."}
{"dataset_id": "acl_6060", "sample_id": 338, "src_lang": "en", "tgt_lang": "de", "output": "Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Funktionen aus dem künstlichen Text der Wissensbasis zu extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 339, "src_lang": "en", "tgt_lang": "de", "output": "Unser Rahmenwerk ist genau dieser automatische Prozess."}
{"dataset_id": "acl_6060", "sample_id": 340, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns ein Beispiel sehen. In einem Datensatz, der in FEST eingeführt wird."}
{"dataset_id": "acl_6060", "sample_id": 341, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist die Datenmenge Universitätsdatenmenge."}
{"dataset_id": "acl_6060", "sample_id": 342, "src_lang": "en", "tgt_lang": "de", "output": "Wenn es darum geht, Universitäten in niedrig eingestufte und hoch eingestufte Universitäten zu unterteilen."}
{"dataset_id": "acl_6060", "sample_id": 343, "src_lang": "en", "tgt_lang": "de", "output": "Als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 344, "src_lang": "en", "tgt_lang": "de", "output": "Die erste Phase des Festes ist die Entitätsverknüpfung."}
{"dataset_id": "acl_6060", "sample_id": 345, "src_lang": "en", "tgt_lang": "de", "output": "Wenn jede Einheit, in diesem Beispiel der Name der Universität, mit einer Einheit innerhalb der Wissensbasis verknüpft ist."}
{"dataset_id": "acl_6060", "sample_id": 346, "src_lang": "en", "tgt_lang": "de", "output": "und der Text der Entitäten der Knowledge-Basis wird extrahiert und in die Daten setzt."}
{"dataset_id": "acl_6060", "sample_id": 347, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel ist der Text der Abstrakt der Wikipedia-Seite."}
{"dataset_id": "acl_6060", "sample_id": 348, "src_lang": "en", "tgt_lang": "de", "output": "Jetzt müssen wir Funktionen aus dem abgerufenen Text generieren oder extrahieren."}
{"dataset_id": "acl_6060", "sample_id": 349, "src_lang": "en", "tgt_lang": "de", "output": "Wir brauchen also eine Funktionsaufnahmephase, die Textanalyse beinhaltet."}
{"dataset_id": "acl_6060", "sample_id": 350, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist die Hauptneuheit dieses Papiers, und ich werde mich in den nächsten Folien tiefer damit befassen."}
{"dataset_id": "acl_6060", "sample_id": 351, "src_lang": "en", "tgt_lang": "de", "output": "Nach der Extraktionsphase der Merkmale gibt es eine Generierungsphase der Merkmale, in der wir die extrahierten Merkmale verwenden, um eine kleine Anzahl neuer Merkmale zu generieren."}
{"dataset_id": "acl_6060", "sample_id": 352, "src_lang": "en", "tgt_lang": "de", "output": "Zuerst generieren Sie Funktionen in der Anzahl der Klassen des ursprünglichen Datensatzes."}
{"dataset_id": "acl_6060", "sample_id": 353, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen"}
{"dataset_id": "acl_6060", "sample_id": 354, "src_lang": "en", "tgt_lang": "de", "output": "Also, erstens zwei neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 355, "src_lang": "en", "tgt_lang": "de", "output": "Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 356, "src_lang": "en", "tgt_lang": "de", "output": "Jede Funktion stellt die Wahrscheinlichkeit für jede Klasse dar."}
{"dataset_id": "acl_6060", "sample_id": 357, "src_lang": "en", "tgt_lang": "de", "output": "Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, die sich auf Transformer basieren lassen, wie Baird, GPT, XLED und so weiter."}
{"dataset_id": "acl_6060", "sample_id": 358, "src_lang": "en", "tgt_lang": "de", "output": "Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können."}
{"dataset_id": "acl_6060", "sample_id": 359, "src_lang": "en", "tgt_lang": "de", "output": "Ein naiver Ansatz wird also eine Zielaufgabe zur Feinabstimmung sein."}
{"dataset_id": "acl_6060", "sample_id": 360, "src_lang": "en", "tgt_lang": "de", "output": "In der Phase der Funktionsauffnahme können wir also ein Parent-Train-Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 361, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel wird das Sprachmodell verfeinert, um Text in Klassen zu klassifizieren, abstrakt in Klassen, niedrig oder hoch."}
{"dataset_id": "acl_6060", "sample_id": 362, "src_lang": "en", "tgt_lang": "de", "output": "Empfangen Sie die Ausgabe des Sprachmodells, die die Wahrscheinlichkeit für jede Klasse ist, und verwenden Sie sie als neue Funktionen."}
{"dataset_id": "acl_6060", "sample_id": 363, "src_lang": "en", "tgt_lang": "de", "output": "Das Problem bei diesem Ansatz ist, dass Datenmengen möglicherweise wenige unterschiedliche Entitätsstapel haben."}
{"dataset_id": "acl_6060", "sample_id": 364, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Experiment enthielten fast die Hälfte der Datensätze weniger als vierhundert Proben, und der kleinste Datensatz enthält fünfunddreißig Proben in seinem Trainings-Satz."}
{"dataset_id": "acl_6060", "sample_id": 365, "src_lang": "en", "tgt_lang": "de", "output": "Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern."}
{"dataset_id": "acl_6060", "sample_id": 366, "src_lang": "en", "tgt_lang": "de", "output": "Wir können jedoch vorherige Kenntnisse über voranalyseierte Datensätze nutzen."}
{"dataset_id": "acl_6060", "sample_id": 367, "src_lang": "en", "tgt_lang": "de", "output": "Da wir FAST auf mehrere Datensätze anwenden, können wir die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir den nth-Datensatz analysieren."}
{"dataset_id": "acl_6060", "sample_id": 368, "src_lang": "en", "tgt_lang": "de", "output": "Was wir sugest, ist die Hälfte der Fine Tuning Phase."}
{"dataset_id": "acl_6060", "sample_id": 369, "src_lang": "en", "tgt_lang": "de", "output": "Eine vorläufige Phase der Fine-Tuning-Multitask."}
{"dataset_id": "acl_6060", "sample_id": 370, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir das Sprachmodell über n minus eins Datensätze finden,"}
{"dataset_id": "acl_6060", "sample_id": 371, "src_lang": "en", "tgt_lang": "de", "output": "Dann führen wir eine weitere Feinabstimmungsphase durch, die eine Feinabstimmung der Zielaufgaben ist, wenn wir das Sprachmodell über den n-Tiel-Datensatz feinabstimmen."}
{"dataset_id": "acl_6060", "sample_id": 372, "src_lang": "en", "tgt_lang": "de", "output": "Der neueste Stand der Multitask-Fine-Tuning, der MTDNN genannt wird."}
{"dataset_id": "acl_6060", "sample_id": 373, "src_lang": "en", "tgt_lang": "de", "output": "In MTDNN hält MTDNN eine Anzahl von Aufgaben im Trainingsatz aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 374, "src_lang": "en", "tgt_lang": "de", "output": "In diesem Beispiel gibt es also vier Aufgaben im Trainings-Set. Also leere DNN und halte vier Kopfhäupter, wie Sie auf dem Bild sehen können."}
{"dataset_id": "acl_6060", "sample_id": 375, "src_lang": "en", "tgt_lang": "de", "output": "Und es samplet eine zufällige Charge aus dem Trainingsset."}
{"dataset_id": "acl_6060", "sample_id": 376, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn der Run-Batch zu einer, zum Beispiel, Sing und Selton-Klassifizierungsaufgabe gehört, führt er einen Vorwärts- und Rückwärtspass durch den ersten Kopf aus."}
{"dataset_id": "acl_6060", "sample_id": 377, "src_lang": "en", "tgt_lang": "de", "output": "Und wenn die zufällige Charge zu einer Paar-Ranking-Tasche gehört, wird sie durch den letzten Kopf weitergegeben und zurückgegeben."}
{"dataset_id": "acl_6060", "sample_id": 378, "src_lang": "en", "tgt_lang": "de", "output": "In unserem Szenario verifiziert eine Datenmenge-Tabelle die Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 379, "src_lang": "en", "tgt_lang": "de", "output": "Es gibt also viele Aufgaben."}
{"dataset_id": "acl_6060", "sample_id": 380, "src_lang": "en", "tgt_lang": "de", "output": "MTDN hält die Anzahl der Klassen-Heads-Ausgaben-Schichten aufrecht."}
{"dataset_id": "acl_6060", "sample_id": 381, "src_lang": "en", "tgt_lang": "de", "output": "Und zusätzlich muss MTDNN eine neue HEADS für einen neuen Datensatz mit einer neuen Aufgabe initialisieren."}
{"dataset_id": "acl_6060", "sample_id": 382, "src_lang": "en", "tgt_lang": "de", "output": "Unser Ansatz, der als Task Reformulation Fine Tuning bezeichnet wird, besteht darin, dass wir in unserem Ansatz Task Reformation Fine Tuning statt mehrere Kopfgruppen zu behalten, jeden Datensatz in ein Satz pro Klassifizierungsproblem umformulieren, das zwei Klassen-Aufgaben ist."}
{"dataset_id": "acl_6060", "sample_id": 383, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also ein Beispiel sehen."}
{"dataset_id": "acl_6060", "sample_id": 384, "src_lang": "en", "tgt_lang": "de", "output": "Hier ist unser Input-Datensatz, der von Entitäten, Funktionen, Text und Klassen besteht."}
{"dataset_id": "acl_6060", "sample_id": 385, "src_lang": "en", "tgt_lang": "de", "output": "Und wir formulieren die Aufgabe von der Klassifizierung des Textes in niedrig und hoch zu der Klassifizierung des Textes, des Abstrakts und der Klasse in wahr oder falsch."}
{"dataset_id": "acl_6060", "sample_id": 386, "src_lang": "en", "tgt_lang": "de", "output": "In anderen Worten, wir haben das Sprachmodell so trainiert, dass es abstrakt und in der Klasse klassifiziert, ob die Abstrakt-Klasse in der Klasse gehört oder nicht."}
{"dataset_id": "acl_6060", "sample_id": 387, "src_lang": "en", "tgt_lang": "de", "output": "Der Etikettvektor besteht in diesem Fall also immer aus zwei Klassen."}
{"dataset_id": "acl_6060", "sample_id": 388, "src_lang": "en", "tgt_lang": "de", "output": "Und das ist der Algorithmus für unseren fertigen oder formulierten Feintuning-Ansatz."}
{"dataset_id": "acl_6060", "sample_id": 389, "src_lang": "en", "tgt_lang": "de", "output": "Lassen Sie uns also das vollständige Framework betrachten."}
{"dataset_id": "acl_6060", "sample_id": 390, "src_lang": "en", "tgt_lang": "de", "output": "und das set fade into fast"}
{"dataset_id": "acl_6060", "sample_id": 391, "src_lang": "en", "tgt_lang": "de", "output": "Und dann eine schnelle Entity-Linking-Phase."}
{"dataset_id": "acl_6060", "sample_id": 392, "src_lang": "en", "tgt_lang": "de", "output": "Es extrahiert den Text aus der Wissensbasis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist."}
{"dataset_id": "acl_6060", "sample_id": 393, "src_lang": "en", "tgt_lang": "de", "output": "Dann wird die Aufgabe in eine Satz-Per-Classifikation-Tasche reformuliert."}
{"dataset_id": "acl_6060", "sample_id": 394, "src_lang": "en", "tgt_lang": "de", "output": "Wenden Sie das Sprachmodell auf die neue Aufgabe an und die Ausgabenwahrscheinlichkeit für jede Klasse."}
{"dataset_id": "acl_6060", "sample_id": 395, "src_lang": "en", "tgt_lang": "de", "output": "Beachten Sie, dass das Sprachmodell bereits über n-1-Datensatz mit einer vorläufigen Multitask-Fine-Tuning verfeinert wurde."}
{"dataset_id": "acl_6060", "sample_id": 396, "src_lang": "en", "tgt_lang": "de", "output": "Dann verwenden wir den Ausgabevektor des Sprachmodells als neu erstelltes Merkmal in der Anzahl der Klassen."}
{"dataset_id": "acl_6060", "sample_id": 397, "src_lang": "en", "tgt_lang": "de", "output": "Um unser Rahmenwerk zu bewerten, verwenden wir eine Datenmenge mit siebzehn Tabellen, die Größe, Merkmale, Balance, Bereich und anfängliche Leistung variieren."}
{"dataset_id": "acl_6060", "sample_id": 398, "src_lang": "en", "tgt_lang": "de", "output": "Und als Wissensbasis verwenden wir Wikipedia."}
{"dataset_id": "acl_6060", "sample_id": 399, "src_lang": "en", "tgt_lang": "de", "output": "Wir haben unser Experiment als Live-Out-Evaluierung gestaltet, bei der wir schnell über sechzehn Datensätze trainieren und sie auf das siebzehnte Datenset anwenden."}
{"dataset_id": "acl_6060", "sample_id": 400, "src_lang": "en", "tgt_lang": "de", "output": "Wir teilen auch jeden Datensatz in vier Fehler auf und wenden eine Falten-Cross-Validation an."}
{"dataset_id": "acl_6060", "sample_id": 401, "src_lang": "en", "tgt_lang": "de", "output": "Dann generieren wir die neuen Funktionen und bewerten sie mit fünf Bewertungs-Klassifikatoren."}
{"dataset_id": "acl_6060", "sample_id": 402, "src_lang": "en", "tgt_lang": "de", "output": "Wir verwenden in unserem Experiment eine BERT-Basis-Architektur."}
{"dataset_id": "acl_6060", "sample_id": 403, "src_lang": "en", "tgt_lang": "de", "output": "Hier sind die Ergebnisse unseres Experiments."}
{"dataset_id": "acl_6060", "sample_id": 404, "src_lang": "en", "tgt_lang": "de", "output": "Sie können sehen, dass wir unser Rahmenwerk mit der Feinabstimmung des Zieldatensatzes, der Feinabstimmung der Zielaufgabe und der vorläufigen Feinabstimmung der MTDNN vergleichen."}
{"dataset_id": "acl_6060", "sample_id": 405, "src_lang": "en", "tgt_lang": "de", "output": "Und unsere Formulierung ist ein Feintuning, das beste Ergebnis, die beste Leistung."}
{"dataset_id": "acl_6060", "sample_id": 406, "src_lang": "en", "tgt_lang": "de", "output": "Während MTDNN eine Verbesserung von 2% gegenüber der Feinabstimmung des Zieldatensatzes erreichte."}
{"dataset_id": "acl_6060", "sample_id": 407, "src_lang": "en", "tgt_lang": "de", "output": "Unser Poach hat eine Verbesserung um sechs Prozent erzielt."}
{"dataset_id": "acl_6060", "sample_id": 408, "src_lang": "en", "tgt_lang": "de", "output": "Wenn wir uns die kleinen Daten ansehen, können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Feinabstimmung bei mehrere Aufgaben auf 1,5 Prozent abnimmt."}
{"dataset_id": "acl_6060", "sample_id": 409, "src_lang": "en", "tgt_lang": "de", "output": "Aber unsere Leistung hat sich im Vergleich zu der Zielaufgabe, die allein mit der Feinabstimmung verbessert wurde, um elf Prozent zu verbessern."}
{"dataset_id": "acl_6060", "sample_id": 410, "src_lang": "en", "tgt_lang": "de", "output": "Für die Zusammenfassung ermöglicht Fast die Bereicherung von Fushot aus 35 Proben in unserem Experiment."}
{"dataset_id": "acl_6060", "sample_id": 411, "src_lang": "en", "tgt_lang": "de", "output": "Es verwendet eine Architektur für alle Aufgaben-Datensätze."}
{"dataset_id": "acl_6060", "sample_id": 412, "src_lang": "en", "tgt_lang": "de", "output": "Und er behält den Kopf des Modells."}
{"dataset_id": "acl_6060", "sample_id": 413, "src_lang": "en", "tgt_lang": "de", "output": "Aber es fügt eine Reformulationsphase hinzu."}
{"dataset_id": "acl_6060", "sample_id": 414, "src_lang": "en", "tgt_lang": "de", "output": "Es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satzpaar-Klassifizierungsproblematik verwenden können."}
{"dataset_id": "acl_6060", "sample_id": 415, "src_lang": "en", "tgt_lang": "de", "output": "Danke."}
{"dataset_id": "acl_6060", "sample_id": 416, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Assa Farari und ich werde unsere Arbeit FUSHOT Tabellendatenanbau mit fein abgestimmten Transformers-Architekturen vorstellen. Datenwissenschaftler analysieren Daten und konzentrieren sich hauptsächlich auf die Manipulation der bestehenden Datenmerkmale, aber manchmal sind diese Merkmale begrenzt. Die Generierung von Merkmalen mit einer anderen Datenquelle kann erhebliche Informationen hinzufügen. Unser Forschungsziel ist die automatische Tabellendatenanbau mit externen Quellen, freiem Text. Nehmen wir an, wir haben eine Tabellendatenmenge und eine Wissensbasis. Wir benötigen einen automatischen Prozess, der die Verknüpfung von Intensität und die Textanalyse beinhaltet, um neue Merkmale aus dem kostenlosen Text der Wissensbasis zu extrahieren. Unser Framework FEST ist genau dieser automatische Prozess. Lassen Sie uns ein Beispiel betrachten. In einem Datensatz, der in FEST eingeführt wird. In diesem Beispiel ist der Datensatz ein Universitätsdatensatz, wenn sein Ziel es ist, Universitäten in niedrig rankende Universitäten und hochrangige Universitäten. Als Wissensbasis verwenden wir Wikipedia. Die erste Phase von FEST ist die Entitätslinkung, bei der jede Entität, in diesem Beispiel der Universitätsname, mit einer Entität innerhalb der Wissensbasis verknüpft wird und der Text der Entitäten der Wissensbasis extrahiert und zum Datensatz hinzugefügt wird. In diesem Beispiel ist der Text der Wikipedia-Seitenabschnitt. Jetzt müssen wir Features aus dem erhaltenen Text generieren oder extrahieren. Wir benötigen also eine Feature-Extraction-Phase, die Textanalyse beinhaltet. Und das ist die Hauptnota dieser Arbeit, und ich werde mich in den nächsten Folien damit befassen. Nach der Feature-Extraction-Phase gibt es eine Feature-Generation-Phase, in der wir die extrahierten Features verwenden, um eine kleine Anzahl von Features zu generieren. Sie eine kleine Anzahl neuer Merkmale. Erstellen Sie zuerst Merkmale in der Anzahl der Klassen des ursprünglichen Datensatzes. In diesem Beispiel hat der ursprüngliche Datensatz zwei Klassen, also erstellen Sie zuerst zwei neue Merkmale. Wenn der Datensatz jedoch fünf Klassen hat, erstellen Sie zuerst fünf neue Merkmale. Jede Merkmale repräsentiert die Wahrscheinlichkeit für jede Klasse. Um den Text zu analysieren, verwenden wir den aktuellen Stand der Technik der Textanalyse, nämlich transformierbare Sprachmodelle wie BERT, GPT, XLERT und so weiter. Es ist jedoch unwahrscheinlich, dass wir ein Sprachmodell mit den Eingabedaten ausbilden können. Daher wäre eine naive Herangehensweise die Feinabstimmung der Zielaufgabe. In der Fase der Extraktion der Funktionen können wir ein pertrainiertes Sprachmodell herunterladen und das Sprachmodell über das Zieldatenset feinabstimmen. In diesem Beispiel können wir das Sprachmodell fe soll Text in Klassen, Abstract in Klassen, Low oder High, in Klassen eingeteilt, die Sprachmodell-Ausgaben erhalten, die für jede Klasse die Wahrscheinlichkeit sind, und als neue Funktionen verwendet werden. Das Problem bei diesem Ansatz ist, dass Daten sätze möglicherweise wenige unterschiedliche Entitäten wie Text enthalten. In unserem Experiment enthalten fast die Hälfte der Daten sätze weniger als 400 Samples und die kleinsten Daten sätze enthalten. Es enthält 35 Proben in seinem Trainings-Set. Daher wäre es ineffektiv, ein Sprachmodell über diesen Datensatz zu verfeinern. Wir können jedoch vorherige Kenntnisse über voranalysierte Datensätze nutzen, da wir FAST über mehrere Datensätze anwenden. Wir können die N-1-Datensätze verwenden, um Informationen über die N-1-Datensätze zu sammeln und diese Informationen zu verwenden, wenn wir die nth Dataset. Was wir vorschlagen, ist eine weitere Fein-Tuning-Phase, eine preliminäre Multitask-Fein-Tuning-Phase, wenn wir das Languagemodell über n-1 Datasets fein-tunen. Und dann führen wir eine weitere Fein-Tuning-Phase aus, die eine Target-Task-Fein-Tuning ist, wenn wir das Languagemodell über das nth-Target-Dataset fein-tunen. Der Stand der Welt in der Multitask-Fein-Tuning-Phase. Fine-Tuning-Anwendung namens MTDNN. In MTDNN, MTDNN, mainten Sie eine Hälfte der Taschen im Trainingssatz. In diesem Beispiel gibt es vier Taschen im Trainingssatz. MTDNN mainten Sie vier Hälfte, wie Sie sehen können, im Bild. Es sampelt eine Random-Batch aus dem Trainingssatz. Und wenn die Random-Batch zu einem Zum Beispiel Singenselten's Classification-Tasks, es führt Vor- und Rückwärtspfade durch den ersten Kopf aus. Und wenn der Random-Batch zu Paar-Wise-Ranking-Task gehört, führt es Vor- und Rückwärtspfade durch den letzten Kopf aus. In unserem Szenario verringen Tableau-Datensätze die Anzahl der Klassen. Es gibt also viele Aufgaben. MTDNN-Mainten. DNN hält eine Reihe von Klassen-Heads-Ausgaben-Lagen aufrecht und zusätzlich muss MTDNN neue Heads für einen neuen Datensatz mit einer neuen Aufgabe initialisieren. Unser Ansatz, der als Task-Reformulation-Fine-Tuning bezeichnet wird, ist, dass wir in unserem Ansatz Task-Reformulation-Fine-Tuning, anstatt mehrere Heads aufrechtzuerhalten, jedes Datensatz in ein Satz pro Klassifizierungsproblem, das zwei Klassen-Taschen. Also, sehen wir ein Beispiel. Hier ist unser Input-Datensatz, der entweder von Entitäten, Funktionen, Text und Klassen besteht. Und wir reformulieren die Tasche von der Klassifizierung der Text in Low und High, um die Text, den Abstrakt und die Klasse in True oder False zu klassifizieren. Oder in anderen Worten, wir trainieren das Languagemodell, um eine Abstrakt- und Klassenklasse zu klassifizieren, ob die Abstrakt- und Klassenklasse zur Klasse gehören oder nicht. Der Etikettvektor bleibt in diesem Fall immer mit zwei Klassen bestehen. Und das ist der Algorithmus für unsere Find-Orientierung. find reformulated fine-tuning approach. Also, sehen wir uns den vollständigen Framework an. Ein Datensatz wird in FAST eingeführt und dann FAST execute in die Linkingphase. Es extrahiert den Text aus der Knowledge-Basis, die in diesem Beispiel das Abstract der Wikipedia-Seite ist. Dann wird die Task reformuliert in Satz-Per-Classification-Tasks, das Sprachmodell auf die neue Task und die Ausgaben-Likelihood für jede Klasse. Beachten Sie, dass das Language-Modell bereits über n-1-Datensätze mit einer vorläufigen Multitask-Fine-Tuning abgestimmt ist. Dann verwenden wir den Ausgabenvektor des Language-Modells als neu generierten Funktion in der Anzahl der Klassen. Um unser Framework zu evaluieren, verwenden wir eine 17. Wir haben eine siebzehn-Tabellklassifizierungsdatensätze, die die Größe, die Merkmale, den Bereich und die anfängliche Leistung in Einklang bringt. Und als Wissensbasis verwenden wir Wikipedia. Wir haben unser Experiment als eine Live-Out-Evaluierung entworfen, bei der wir schnell über sechzehn Datensätze trainieren und sie auf die siebzehnte Datensätze anwenden. Wir haben auch jede Datensätze in vier Daten aufgeteilt. Wir erstellen Fehler und wenden eine Fork-Fehler-Kreuzvalidierung an. Dann generieren wir die neue Funktion und bewerten sie mit fünf Bewertungs-Klassifikatoren. In unserem Experiment verwenden wir eine auf Bild-Basis basierte Architektur. Hier sind die Ergebnisse unseres Experiments. Sie sehen, dass wir unser Framework mit der Feinabstimmung des Zieldatensatzes vergleichen, der Feinabstimmung der Zielaufgabe. und MTDNN preliminäre Feintuning und unsere reformulierte Feintuning erreichten den besten Ergebnis, die besten Leistungen, während MTDNN 2% Verbesserung über die Target-Datenset-Fine-Tuning erreichte. Unser Produkt erreichte 6% Verbesserung. Wenn wir uns die kleinen Daten ansehen, Aus dem Datensatz können wir sehen, dass die Leistung von MTDNN abnimmt und die Verbesserung der vorläufigen Phase der Fine-Tuning für mehrere Aufgaben auf 1,5 Prozent abnimmt, aber unsere Leistung steigt auf 11 Prozent im Vergleich zur alleinigen Fine-Tuning für die Zielaufgabe. Für die Zusammenfassung ermöglicht FAST die Bereicherung von Flux-Schüssen aus 35 Proben in unserem Experiment. verwendet eine Architektur für alle Aufgaben-Datensätze und behält den Kopf des Modells bei. Aber es fügt eine Formulierungsphase hinzu, es erweitert den Train-Satz und benötigt einen Zielwert mit semantischer Bedeutung, damit wir ihn in das Sprachmodell einfügen und in der Satz-Par-Klassifizierungsproblematik verwenden können. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 417, "src_lang": "en", "tgt_lang": "de", "output": "Hallo alle zusammen. Heute werde ich unser Forschungswerk Lernen, deduktiv zu denken, Methodenproblemlösung als komplexe Rationsauffnahme vorstellen. Ich bin Alan vom Biden's AI Lab und dies ist eine gemeinsame Arbeit mit Thierry von der University of Texas in Austin und Wayloo von SUDD. Zunächst möchte ich über unsere Motivation für das Denken sprechen. Hier zeigen wir Beispiele, in denen mehrträgliches Denken hilfreich ist. Diese Zahl stammt aus der POWN-Artikel, in der sie die Anregung zur Lösung des Methodenproblems in einem Future-Learning-Szenario durchführen. Auf der Netto-Pan-Seite können wir sehen, dass wir, wenn wir einige Beispiele mit nur Fragen und Antworten geben, möglicherweise nicht in der Lage sind, die richtigen Antworten zu erhalten. Wenn wir jedoch eine weitere Beschreibung geben, kann das Modell die Beschreibung vorhersagen und auch eine korrekte Vorhersage treffen. Es ist also gut, als Ausgabe interpretierbare Mehrstufige Beschreibung zu haben. Wir denken auch, dass das Methodenproblem eine einfache Anwendung ist, um solche Beschreibungsfähigkeiten zu bewerten. Hier in unserer Problemkonfiguration müssen wir diese Frage aufgrund der Fragen lösen und die numerischen Antworten erhalten. In unseren Datensätzen erhalten wir also auch den mathematischen Ausdruck, der auch zu dieser bestimmten Antwort führt. Daher gelten bestimmte Annahmen wie in früheren Arbeiten. Wir gehen davon aus, dass die Präzision von Größen bekannt ist, und wir betrachten nur grundlegende Operatoren wie Addition, Subtraktion, Multiplikation, Division und Exponential. Darüber hinaus können komplizierte Operatoren tatsächlich ent in diese grundlegenden Operatoren aufgeteilt werden. Frühere Arbeiten im Lösungsproblem der Methode können also tatsächlich in Sequenz-zu-Sequenz- und Sequenz-zu-Baummodell kategorisiert werden. Traditionelle Sequenz-zu-Sequenz-Modelle konvertieren den Ausdruck in eine spezifische Sequenz für die Generierung, und es ist ziemlich einfach zu implementieren, und es kann auf viele verschiedene komplizierte Probleme verallgemeinert werden. Aber die Nachteile sind, dass die Leistung im Allgemeinen nicht besser ist als das Strukturmodell, und es fehlt an Interpretabilität für die die Vorhersage. Aber eigentlich ist diese Richtung aufgrund des Transformator-Modells immer noch ziemlich beliebt. In Baumbasierten Modellen strukturieren wir diese Ausdrücke tatsächlich in Baumform und folgen einer Vorordnungstraversal in Baumgenerationen. Hier generieren wir also die Operatoren, bis wir die Blätter erreichen, die die Größen sind. Das Gute ist, dass es uns tatsächlich diese binäre Baumstruktur gibt. Aber eigentlich ist es ziemlich kontraintuitiv. Denn wir generieren zuerst den Operator und dann am Ende die Größen. Und das Zweite ist, dass er auch einige wiederholte Berechnungen enthält. Wenn wir uns also diesen Ausdruck a mal drei plus drei ansehen, wird er tatsächlich zweimal generiert. Aber tatsächlich sollten wir die Ergebnisse wiederverwenden. In unserem vorgeschlagenen Ansatz möchten wir diese Probleme also Schritt für Schritt und interpretierbar lösen. Zum Beispiel können wir hier im zweiten Schritt die Daten erhalten., die 27 sind. Und wir können auch auf die ursprünglichen Fragen zurückgreifen, um den relevanten Inhalt zu finden. Und in diesen Schritten erhalten wir die Teiler. Und dann erhalten wir in diesem dritten Schritt tatsächlich den Quotienten. Und nach diesen drei Schritten können wir tatsächlich die Ergebnisse des zweiten Schritts wiederverwenden und dann die Ergebnisse des vierten Schritts erhalten. Und dann können wir schließlich die Dividenden erhalten. Hier generieren wir also tatsächlich den gesamten Ausdruck direkt, anstatt einzelne Operatoren oder Größen zu generieren. Dies macht den Prozess genauer. In unserem deduktiven System beginnen wir also zunächst mit einer Reihe von Größen, die in den Fragen dargestellt werden, und fügen auch einige Konstanten als Anfangszustände ein. Der Ausdruck wird also durch EIJOP dargestellt, bei dem wir Operatoren von Qi bis Qj ausführen, und dieser Ausdruck ist tatsächlich gelenkt. Wir haben hier auch eine Subtraktion umgekehrt, um die entgegengesetzte Richtung darzustellen. Das ist ziemlich ähnlich wie eine Relationsentfernung. In einem formellen deduktiven System wenden wir den Operator zwischen dem Qi- und Qj-Paar an, und dann erhalten wir diesen neuen Ausdruck. Wir fügen ihn den nächsten Zuständen hinzu, um eine neue Größe zu erhalten. Diese Folien visualisieren tatsächlich die Entwicklung der Zustände, bei denen wir den aktuellen Zustand weiterhin Ausdrücke hinzufügen. In unseren Modellimplementierungen verwenden wir zunächst ein vorgebildetes Netzwerkmodell, das Vögel oder Roberto sein kann, und dann codieren wir den Satz und erhalten diese Mengenrepräsentationen. Sobald wir die Mengenrepräsentationen erhalten, können wir mit der Schlussfolgerung beginnen. Hier zeigen wir ein Beispiel für Q1, um die Repräsentation für Q1 zu erhalten, die durch Q2 geteilt und dann durch Q3 multipliziert wird. Zuerst erhalten wir die Paarrepräsentation, die im Grunde nur die Konkatenation zwischen Q1 und Q2 ist, und dann wenden wir ein Fit-Forward-Netzwerk an, das ist. Dies wird durch den Operator parametriert. Und schließlich erhalten wir die Ausdrucksdarstellung Q1 geteilt durch Q2. Aber in der Praxis könnten wir im Inferenzstadium auch den falschen Ausdruck erhalten. Hier sind alle möglichen Ausdrücke gleich dreimal so viele Operatoren. Das Schöne daran ist, dass wir leicht Einschränkungen hinzufügen können, um diesen Suchraum zu steuern. Wenn dieser Ausdruck beispielsweise nicht erlaubt ist, können wir diesen Ausdruck einfach in unserem Suchraum entfernen. Im zweiten Schritt machen wir also das Gleiche, aber der einzige Unterschied ist eine weitere Größe. Diese Größe stammt also aus dem vorher berechneten Ausdruck. Schließlich können wir diesen endgültigen Ausdruck Q drei mal Q vier erhalten. Und wir können auch sehen, dass die Anzahl aller möglichen Ausdrücke vom vorherigen Schritt unterschiedlich ist. Solche Unterschiede machen es schwierig, ihn anzuwenden. Es ist schwer, Beam-Suche anzuwenden, da die Wahrscheinlichkeitsverteilung zwischen diesen beiden Schritten unbalanciert ist. Der Trainingsverfahren ist ähnlich wie bei der Schulung eines Sequenz-zu-Sequenz-Modells, bei dem wir den Verlust bei jedem Zeitschritt optimieren, und hier verwenden wir auch diese Zeichen, um darzustellen, wann wir diesen Generierungsprozess beenden sollten. Und hier ist der Raum von Sequenz zu Sequenz anders, da der Raum bei jedem Zeitschritt unterschiedlich ist, während es im traditionellen Sequenz-zu-Sequenz-Modell die Anzahl des Wortschatzes ist. Es ermöglicht uns auch, bestimmte Einschränkungen aus vorherigen Kenntnissen aufzustellen. Wir führen also Experimente mit den häufig verwendeten Methodenproblemdatensätzen durch, MAWPS, Math twenty three K, MathQA und SWAM. Hier zeigen wir kurz die Ergebnisse im Vergleich zu den vorherigen besten Ansätzen. Unsere am besten funktionierende Variante ist Roberta Deductive Reasoner. Tatsächlich verwenden wir nicht BeamSearch, im Gegensatz zu den vorherigen Ansätzen mitze sind oft ein Baumbasiertes Modell. Insgesamt kann unser Argumentationsmodell dieses Baumbasierten Modells deutlich übertreffen, aber wir können sehen, dass die absoluten Zahlen bei MathQA oder SWAM nicht wirklich hoch sind. Wir untersuchen die Ergebnisse bei SWAM weiter, und dieser Datensatz ist eine Herausforderung, da der Autor versucht, manuell etwas hinzuzufügen, um das NLP-Modell zu verwirren, wie zum Beispiel das Hininzufügung von irrelevanten Informationen und zusätzlichen Mengen. In unserer Vorhersage stellen wir fest, dass einige der Zwischenwerte tatsächlich negativ sind. In diesen Fragen fragen wir zum Beispiel, wie viele Äpfel Jake hat, aber wir haben einige zusätzliche Informationen, wie siebzehn weniger Töne und Stephen hat acht Töne, was völlig irrelevant ist. Unser Modell macht also eine solche Vorhersage, die negative Werte erzeugt. Und wir beobachten, dass diese beiden Ausdrücke tatsächlich ähnliche Zahlen haben. Wir haben tatsächlich ähnliche Punktzahlen. Wir können also diesen Suchraum einschränken, indem wir diese negativen Ergebnisse entfernen, damit wir die Antwort richtig machen können. Wir stellen also fest, dass eine solche Einschränkung für einige Modelle tatsächlich ziemlich viel verbessert. Zum Beispiel verbessern wir für Vögel sieben Punkte und für das Roberta-basierte Modell zwei Punkte. Ein besseres Sprachmodell hat also eine bessere Sprachverständnisfähigkeit, sodass die Zahl hier. Hier ist es höher für Roberta und niedriger für Vögel. Und wir versuchen auch, die Schwierigkeit hinter all diesen Daten zu analysieren. Wir gehen davon aus, dass die Anzahl der ungenutzten Mengen hier als irrelevante Informationen angesehen werden kann. Hier können wir also sehen, dass wir den Prozentsatz der Proben mit ungenutzten Mengen haben und der SWAMP-Datenmenge den größten Teil hat. Und hier zeigen wir auch die Gesamtleistung für diese Proben ohne ungenutzte Mengen. Die Gesamtleistung ist also tatsächlich höher als die. Und die Leistung ist tatsächlich höher als die Gesamtleistung. Aber bei diesen Proben, bei denen die ungenutzte Menge tatsächlich viel schlechter ist als die Gesamtleistung. Für MAWPS haben wir nicht wirklich viele Datenfälle, also ignoriere ich diesen Teil einfach. Schließlich möchten wir die Interpretbarkeit durch ein Beispiel für das Zusammenbruch zeigen. Hier macht unser Modell also tatsächlich eine falsche Vorhersage im ersten Schritt. Wir können diesen Ausdruck tatsächlich mit dem Satz hier korrelieren. Wir denken, dass dieser Satz das Modell mit einer falschen Vorhersage irreführt. Wenn wir hier also weitere 35 Pflanzen pflanzen, glaubt das Modell, dass es sich um eine Addition von Operatoren handeln sollte. Wir versuchen, den Satz so zu ändern, dass die Anzahl der Birnen 35 weniger als die Apfelbäume ist. Wir machen es also, um genauere Semantik zu vermitteln, sodass das Modell die Vorhersage richtig machen kann. Diese Studie zeigt, wie die interpretierbaren Vorhersagen uns helfen, das Verhalten des Modells zu verstehen. Um unsere Arbeit abzuschließen: Zunächst ist unser Modell ziemlich effizient und wir können interpretierbare Lösungsmethoden bereitstellen, und wir können ein wenig vorheriges Wissen als Einschränkung einbeziehen, was die Leistung verbessern kann. Das letzte ist, dass der zugrunde liegende Mechanismus nicht nur auf Netzwerkproblemlösungsaufgaben anwendet wird, sondern auch auf andere Aufgaben, die mehrträgliches Denken beinhalten. Wir haben aber auch bestimmte Einschränkungen. Wenn wir eine große Anzahl von Operatoren oder Konstanten haben, könnte der Speicherverbrauch ziemlich hoch sein. Und das Zweite ist, wie erwähnt, dass die Wahrscheinlichkeitsverteilung bei verschiedenen Zeitstufen unbalanciert ist, daher ist es auch ziemlich schwierig, eine Beam-Suche-Strategie anzuwenden. Das ist also das Ende des Vortrags, und Fragen sind willkommen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 418, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Antoine und ich bin von der Maastricht University. Ich werde meine gemeinsame Arbeit mit Jerry vorstellen, die sich mit einer neuen Datensammlung für die Erfassung von gesetzlichen Artikeln befasst. Rechtsfragen sind ein integraler Bestandteil des Lebens vieler Menschen, aber die Mehrheit der Bürger hat wenig bis kein Knowledge über ihre Rechte und grundlegenden Rechtsprozesse. Daher werden viele gefährdeten Bürger, die sich die kostspielige Unterstützung eines Rechtsexperten nicht leisten können, ungeschützt oder schlimmer gesagt, ausgenutzt. Unsere Arbeit zielt darauf ab, die Grenze zwischen Menschen und dem Gesetz zu schließen, indem er ein effektives Retrievalsystem für Statutartikel entwickelt. Ein solches System könnte eine freie professionelle Rechtshilfegemeinschaft für unqualifizierte Menschen bieten. Bevor wir uns auf den Hauptbegriff dieser Arbeit konzentrieren, sollten wir uns zunächst mit dem Problem der Statutartikelretrieval befassen. Bei einer einfachen Frage auf einem Rechtsmaterial, wie zum Beispiel was ich riskieren kann, wenn ich professionelle Privatsphäre verletze, ist ein Modell erforderlich, um alle relevanten Statutartikel aus einem großen Bereich der der Gesetzgebung. Diese Information Retrieval Task kommt mit seiner eigenen Setz von Challenges. Erstens geht es mit zwei Arten von Linguage, der normalen natürlichen Sprache für die Fragen und der komplexen legalen Sprache für die Statuten zu tun. Diese Differenz in Languageverteilungen macht es für ein System schwieriger, relevante Kandidaten zu retrieveren, da es indirekt eine inhärente Interpretationssysteme erfordert, die eine natürliche Frage zu einer rechtlichen Frage, die die Terminologie der Statuten entspricht, translatiert. Besides, statutory Law ist nicht ein Stack von Independent Artikeln, die als eine vollständige Source von Informationen auf der Own behandelt werden können, wie neue Rezepte, zum Beispiel. Instead, es ist eine Struktur, eine Sammlung von legalen Provisionen, die eine ganze Bedeutung nur in der allgemeinen Kontext haben, das ist zusammen mit der supplementären Information aus den neighbouring Artikeln, den Feldern und Subfields, die sie belong zu, und ihrer Platz in der Struktur der Laub. Lastly, statutory Artikel sind ein kleiner Paragraph. was in den meisten Retrievalwerken die typische Retrieval-Einheit ist. Hier sind es lange Dokumente, die bis zu sechstausend Wörter schreiben können. Die recenten Entwicklungen in NLP haben enorme Interesse in vielen Rechtsakten wie Legal Judgment Prediction oder automatisierten Kontaktkontraktreview gespielt, aber die Statutory Article Retrieval hat sich aufgrund der Lack von groß und hochwertigen Labeldatensätzen in der Lage geblieben. In dieser Arbeit präsentieren wir eine neue French Native Citizen Centric Datenset zu studieren, ob ein Retrievalmodell die Effizienz und Reliabilität eines Legal Experts für die Task der Statutory Article Retrieval angeht. Unser Belgisch Statutory Article Retrieval Datsatsatz besteht aus mehr als 1.100 legalen Fragen, die von Belgischen Bürgern gestellt werden. Diese Fragen umfassen eine wide Reihe von Themen von Familie, Housing, Money, bis hin zu Work und Sozialversicherung. Each of them ist von erfahrenen Juristen mit Referenzen zu relevanten Artikel aus einem Corpus von mehr als 22.600 legal Artikeln aus Belgischen Codes of Law. Lassen Sie uns nun über die Art und Weise sprechen, wie wir diese Daten setzen. Erst, wir starten mit der Compilierung eines Large Corpus von legal Artikeln. Wir betrachteten 32 öffentlich verfügbare Belgischen Codes und extrahierten alle Artikel sowie die correspondenden Section Headings. Dann gingen wir mit Referenzen zu relevanten Statuten zusammen. To tun so, wir partnerten mit der Belgischen Law Firma. jedes Jahr um viertausend Emails von Belgischen Bürgern, die um Rat und persönliche Rechtsfragen bitten. Wir hatten die Glück, Zugang zu ihren Websites zu bekommen, wo ihr Team erfahrener Juristen belgische am häufigsten rechtlichen Fragen behandelt. Wir sammelten Tausende von Fragen, die mit Kategorien, Subkategorien und Rechtsreferenzen zu relevanten Statuten angepasst wurden. Lastlich durchgingen wir die Rechtsreferenzen und filterten die Fragen, die nicht Artikel in einem der Codes of Law we considered. Die remaining Referenzen wurden matched und zu den corresponding Artikel IDs von O Corpus. Wir eventuell endeten mit einem Jahrhundert und acht Fragen, die sich sorgfältig mit den IDs der relevanten Artikel aus unserem Large Corpus von twenty two thousand six hundred thirty three Statutory Articles labelten. In addition, jeder Frage kommt mit einer Mainkategorie und einer Konkatenation von Subkategorien. Jeder Artikel enthält eine Konkatenation der nachfolgenden Überschriften in der Struktur des Gesetzes. Diese zusätzlichen Informationen werden in der aktuellen Arbeit nicht verwendet, aber könnten für zukünftige Forschungen zur Rechtsinformationserfassung oder zur Klassifizierung von Rechtstexten interessant sein. Schauen wir uns einige Merkmale unserer Datensätze an. Die Frage ist zwischen fünf und vierundvierzig Wörter lang mit einem Median von vierzig Wörtern. Die Artikel sind viel länger mit einem Median von siebzig sieben Wörtern, wobei einhundertvierundvierzig davon mehr als tausend Wörter betragen. Die Länge eines von fünftausend siebenhundert und neunzig Wörtern. Wie bereits erwähnt, umfassen die Frage eine breite Palette von Themen, wobei etwa achtzig Prozent davon entweder Familie, Wohnung, Geld oder Justiz betreffen, während die restlichen fünfzehn Prozent entweder Sozialversicherung, Ausländer oder Arbeit betreffen. Die Artikel sind auch sehr vielfältig, da sie aus dreißig zwei verschiedenen belgischen Gesetzen stammen, die eine große Anzahl von illegalen Themen abdecken. Hier ist die Gesamtzahl der Artikel, die aus jedem dieser belgischen Gesetze gesammelt wurden. Von den 22.633 Artikeln werden nur 1.612 als relevant für mindestens eine Frage in den Datensätzen angegeben, und etwa 80 % dieser zitierten Artikel stammen entweder aus dem Zivilgesetz, dem Justizgesetz, dem Strafverfolgungsgesetz oder dem Strafgesetz. Inzwischen werden 18 von 32 Gesetzen weniger als fünf Artikel als relevant für mindestens eine Frage angege, die durch die Tatsache verursacht wird, dass diese Code weniger auf individuelle und ihre Anliegen fokussiert. Overall, die medianen Zitation für diese citierten Artikel ist zwei, und weniger als fünfundzwanzig Prozent von ihnen sind mehr als fünfmal citiert. Mit unseren Data sets benchmarken wir verschiedene Retrievalapproaches, einschließlich Lexical und Densarchitektur. Given eine query in einem Artikel, eine Lexicalmodelle assigniert eine Score zu den queryartikelpaaren. Durch die Berechnung der Summe der Gewichte jedes dieser Terme in diesem Artikel über die Abfrage-Terme. Wir experimentieren mit den Standard-TFIDF- und BM25-Rankingsfunktionen. Das Hauptproblem bei diesen Ansätzen ist, dass sie nur Artikel abrufen können, die im Abfrage vorhandenen Schlüsselwörter enthalten. Um diese Einschränkung zu überwinden, experimentieren wir mit einer neuronalen Architektur, die die semantische Beziehung zwischen Abfragen und Artikeln erfassen kann. Wir verwenden ein B-Coder-Modell, das Abfragen und Artikel in dichte Vektorrepräsentationen kartiert. und berechnen einen relevanten Punkt zwischen einem Artikelpaar der Abfrage anhand der Ähnlichkeit ihrer Eingebettungen. Diese Eingebettungen sind typischerweise das Ergebnis einer Pooling-Operation auf dem Ausgang eines Word-Eingebettungsmodells. Zunächst untersuchen wir die Effektivität siamesischer B-Encoder in einer Zero-Shot-Evaluierungs-Einrichtung, was bedeutet, dass vorgebildete Word-Eingebettungsmodelle ohne zusätzliche Feinabstimmung aus der Box angewendet werden. Wir experimentieren mit kontextunabhängigen Text-Encodern, nämlich Word2Vec und Fastastex und kontextabhängige Embeddingmodelle, nämlich Roberta und speziell Kamembert, ein französisches Roberta-Modell. Darüber hinaus trainieren wir unsere eigenen Kamembert basierenden Biencoders auf allen Datenmengen. Beachten Sie, dass wir für das Training mit den beiden Arten der Biencoder Architektur experimentieren. Siamese, das ein einzigartiges Wort-Embeddingmodell verwendet, das die Abfrage und den Artikel in einem gemeinsamen dichten Vektorraum mappiert. Und Tutor, das zwei unabhängige Wort-Embeddingmodelle verwendet. Wir haben zwei Independent Word Embedding Models, die den Query und Artikel separat in verschiedene Embeddingsphasen codieren. Wir experimentieren mit Mean, Max und CLS Pooling sowie Dot Product und Cosine für die Computing-Similaritäten. Hier sind die Ergebnisse unserer Baseline auf dem Testset, mit den Lexikonmethoden oben, den Siamese BE Encoders evaluiert in einem Zero Shot Setup in der Mitte, und den Fein Tun BE Encoders unten. Overall, die Fein Tun BE Encoders übertragen alle anderen Baselines. seine Siamese-Variante auf RECOLAT 100, aber ähnlich auf den anderen Metriken abschneidet. Obwohl BM 25 den trainierten Biancoder erheblich unterlegen hat, deutet seine Leistung darauf hin, dass es immer noch eine starke Grundlage für Domain-spezifische Rückholung ist. Bei der Zero Shot Evaluation des Siamese Biancoders finden wir, dass die direkte Verwendung der Embeddings eines vortrainierten Kamembert-Modells ohne Optimierung für die Informationsaufnahmeaufgabe schlechte Ergebnisse liefert, was mit früheren Erkenntnissen übereinstimmt. Der Word-to-Vec-basierte Biancoder übertraf die Fastex- und Vogelbasierten Modelle deutlich, was darauf hindeutet, dass möglicherweise vor-train-Word-Einbettungen für die Aufgabe angemessener sind als Charakter- oder Unterword-Einbettungen, wenn sie von Anfang an verwendet werden. Obwohl sie vielversprechend sind, deuten diese Ergebnisse auf reichliche Verbesserungsmöglichkeiten im Vergleich zu einem geschickten Experten hin, der schließlich alle relevanten Artikel zu jeder Frage abrufen und somit perfekte Punktzahlen erzielen kann. Lassen Sie uns mit zwei Limitationen von allen Datensätzen beginnen. Erstens ist der Corpus von Artikeln limitiert zu denen, die aus den dreißig zwei betrachteten Belgischen Codes erfasst werden, was nicht den gesamten Belgischen Law abdeckt, da Artikel aus Dekrees, Direktives und Ordinanzen enthalten sind. Durch die Datensatzkonstruktion werden alle Referenzen zu diesen unkollektierten Artikeln ignoriert, was dazu führt, dass einige Fragen nur einen Fragment der initialen Anzahl relevanter Artikeln enthalten. Dieser Informationlaus impliquiert, dass die Antwort in den remaining relevanten Artikelnkel könnten incomplete sein, obwohl es immer noch vollständig appropriate ist. Second, wir sollten merken, dass nicht alle Rechtsfragen mit Statuten alone beantwortet werden können. For instance, die Frage kann ich meine Tenants evicten, wenn sie zu viel Noise machen, könnte nicht eine detaillierte Antwort in statutory Law enthalten, die eine spezifische Noise Threshold at which Eviction ist. Insted sollten die Landlage wahrscheinlich mehr auf Fallslaw und Präceden ähnlich wie der aktuelle Situation finden. Zwei Parteien pro Woche bis 2 Uhr morgens. Daher sind einige Fragen besser als andere für die Aufgabe der gesetzlichen Artikelerfassung geeignet, und der Bereich der weniger geeigneten Fragen bleibt noch zu bestimmen. Wir hoffen, dass unsere Arbeit das Interesse an der Entwicklung praktischer und zuverlässiger Modelle der gesetzlichen Artikelerfassung weckt, die den Zugang zur Justiz für alle verbessern können. Sie können sich unsere Arbeit Datensätze und Code unter den folgenden Links ansehen. Vielen Dank."}
{"dataset_id": "acl_6060", "sample_id": 419, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, wir sind froh, unsere Arbeit auf VALS, einem Taskindependenten Benchmark für das Testen von Vision und Language Models mit spezifischen linguistiken Phänomenen zu präsentieren. Warum haben wir uns die Trouble in der Setzung dieses Benchmarks gemacht? Nun, während der letzten Jahre haben wir eine explosion von Transformer basierten Vision und Language Models, die auf große Mengen von Image Textpaaren geprägt sind. Each dieser Modelle pusht State of the Art auf Vision und Language Tasks, wie z. B. visuelle Fragen Sinnesrechnung, Bildretrieval, Phrase-Grundung. Wir haben also eine Nachricht, die Akuragen auf diesen spezifischen Benchmarks steigern, aber wissen wir, was die Modelle tatsächlich gelernt haben? Was hat ein Vision und Language Transformer verstanden, als er eine High Score für dieses Bild und diesen Satz zugewiesen hat und eine Low Score für dieses Bild? Fokusieren Vision und Language Models auf das Richtige oder konzentrieren sie sich auf Biasen? wie gezeigt durch vorherige Arbeit. Um mehr Licht auf diesen Aspekt zu senden, propellieren wir eine mehr task agnostic direction und einführen WALS, das die Sensitivität von Vision und Language Models zu spezifischen linguistiken Phenomenen, die sowohl die linguistic als auch die visuelle Modalitäten beeinflussen. Wir targen Existenz, Pluralität, Zählung, Spatialrelationen, Aktionen und Entity Coreference. Aber wie testen wir, ob die Vision und Language Models diese Phenomena erfasst haben? Foiling, eine Methode, die vorher für Vision und Language Models, nur für Nanphrasen von Ravi Shakar und Kollaborators und auf Counting von Asin previous worked. Foiling basically means, dass wir den Caption of an Image und einen Foil produzieren, indem wir den Caption so verändern, dass er nicht die Image anymore beschreibt. Und wir machen diese Phrasealterations, indem wir uns auf sechs spezifische Pieces wie Existenz, Pluralität, Counting, Spatialrelations, Actions, und Entity Coreference. Jede Piece kann aus einem oder mehreren Instrumenten bestehen, in dem Fall, dass wir mehr als eine interessante Möglichkeit gefunden haben, FOIL instanzen zu erstellen. Zum Beispiel haben wir in der Fall der Aktionspiece zwei Instrumente, einen in dem das Action verb mit einer anderen Action geändert wird und einen in dem Actants gewechselt werden. Zählen und Coreferenz sind auch Pieces, die mehr als eine Instrumenten haben. Und wir erstellen diese FOILs, indem wir unserstellen, dass sie das Bild nicht beschreiben, dass sie grammatikalische und andererweit validierten Sätze sind. Dies ist nicht einfach zu tun, weil eine Foiled Caption weniger wahrscheinlich ist als die ursprüngliche Caption. Zum Beispiel, though it's not impossible, ist es statistisch weniger wahrscheinlich, dass Pflanzen einen Mann schneiden als ein Mann, und Largevision und Language Models könnten dies erkennen. Daher müssen wir, um valid Foils zu erhalten, Action unternehmen. Erstens, wir machen uns auf Strong Language Models zu propellieren. Zweitens, wir verwenden Natural Language Inference oder NLI, um Foils zu filtern, die noch beschreibiben das Bild immer noch, da wir bei der Konstruktion von FOILs sicherstellen müssen, dass sie das Bild nicht beschreiben. Um dies automatisch zu testen, wenden wir eine natürliche Sprachinferenz mit der folgenden Begründung an. Wir betrachten ein Bild als die Premise und seine Beschriftung als die damit verbundene Hypothese. Darüber hinaus betrachten wir die Beschriftung als die Premise und die FOIL als ihre Hypothese. Wenn ein NLI-Modell die FOIL zu widersprechen oder neutral zu den Beschriftungen zu sein, nehmen wir dies als Indikator für eine gültige FOIL. Wenn wir die Foil zu beentalten, kann es nicht eine gute Foil sein, da es durch Transitivität eine truthliche Beschreibung der Image geben wird und wir diese Foils ausfiltern. Aber dieser Prozess ist nicht perfekt. Es ist nur ein Indikator für valide Foils, daher als eine dritte Möglichkeit für die generierung von valid Foils, wir verwenden Humananannotators, um die Daten zu validieren, die in Valse verwendet werden. Also, nach Filtering und Human Evaluation, wir haben so viele Testinstanzen wie in dieser Tabelle. Note, dass Valse nicht trainierend Daten liefert. Aber nur Testdaten, da es sich nur um einen Benchmark für Null-Shot-Tests handelt. Es ist darauf ausgelegt, die bestehenden Fähigkeiten von Vision- und Sprachmodellen nach der Vor-Training-Aktivität zu nutzen. Die Feinabstimmung würde es Modellen nur ermöglichen, Artefakte oder statistische Voreingenommenheiten in den Daten auszunutzen. Und wir alle wissen, dass diese Modelle gerne betrügen und Abkürzungen einschlagen. Und wie wir sagten, sind wir daran interessiert, zu bewerten, welche Fähigkeiten die Vision- und Sprachmodelle nach der Vor-Training-Aktivität haben. Wir experimentieren mit fünf Vision- und Sprachmodellen auf WALS, nämlich mit CLIP, Wilbert, Wilbert Kelvin I und Visual Bert. Zwei unserer wichtigsten Evaluierungsmetriken sind die Accuracy der Modelle in der Klassifizierung von Image Sentenzenpaaren in Untertitel und Foils. Perhaps für dieses Video mehr relevant, wir werden unsere permissive Metrik, die Paarwise Accuracy, die messen, ob die Image Sentenz alignment score für die korrekte Image Textpaar als für ihre Foilpaar ist. Für mehr Metriken und Ergebnisse auf themen, doch checken Sie unsere Papier. Die Ergebnisse mit Paarwise Accuracy sind hier und sie sind konsistent mit den Ergebnissen, die wir von den anderen Metriken bekommen haben. Es ist, dass die besten Zero Shot Performance durch Wilbert zwölf in one, gefolgt von Wilbert, Alex Mert, Clip, und schließlich Visual Bird. Es ist notabel, wie Instrumente centered on individuelle Objekte wie Existenz und Nounphrases fast solviert werden, wobei Wilbert zwölf in one, highlighting, dass Models ableistisch genannte Objekte und ihre Präsenz in Images identifizieren können. Allerdings können none der remaining Pieces in unseren adversarialen Foiling-Settings reliably solviert werden. Instrumenten, dass Vision und Language Models Trouble distinguisieren, referenzieren zu single versus multiple Objekten oder in einem Image. Die Relation Piece zeigt, dass sie Schwierigkeiten haben, eine named spatiale Relation zwischen Objekten in einem Image zu klassifizieren. Sie haben auch Trouble, Aktionen zu distinguieren und ihre Partizipanten zu identifizieren, selbst wenn sie durch Plausibility bias sind, wie wir in der Aktionspiece sehen. Aus der Referenzpiece finden wir, dass das Tracing multiple Referenzen zu dem gleichen Objekt in einem Image durch Pronouns auch für Vision und Language Models. Als eine Sanity Check und weil es ein interessantes Experiment ist, benchmarken wir auch zwei Textonlegermodelle GPT one und GPT two, um zu assessieren, ob Valse solvable durch diese Unimodalmodelle ist, indem wir die Perplexität der korrekt und der foiled Caption, keine Image hier, und die Entry mit der lowest Perplexität. Wenn die Perplexität höher für die Foil ist, dann nehmen wir dies als eine Indikation, dass die foiled Caption möglicherweise von Plausibility bias oder anderen linguistiken Biasen leidet. Und es ist interessant zu sehen, dass in einigen Fällen Die Textmodelle nur GPT haben die Plausibilität der Welt besser erfasst als die Vision und Language Models. Zusammenfassend ist VALSE ein Benchmark, das die Lensen von Linguistikkonstrukten verwendet, um die Community zu helfen, Vision und Language Models zu verbessern, indem sie ihre visuellen Grounding-Fähigkeiten hart testen. Unsere Experimente zeigen, dass Vision und Language Models namensgelegene Objekte in ihrer Präsenz in Bildern gut identifizieren, wie gezeigt durch das Existenzstück, aber es schwerwiegt, ihre Interdependence und Relationships in visuellen Szenen zu genehmigen, wenn sie gezwungen sind, linguistic Indikatoren zu respektieren. Wir möchten die Community wirklich ermutigen, Valse zur Messung des Fortschritts hin zur Sprachbasis mit Vision- und Sprachmodellen zu verwenden. Und noch mehr, Valse könnte als indirekte Bewertung von Datensätzen verwendet werden, da Modelle vor und nach dem Training oder der Feinabstimmung bewertet werden könnten, um zu sehen, ob ein Datensatz Modelle bei der Verbesserung eines der von Valse getesteten Aspekte hilft. Wenn Sie interessiert sind, sollten Sie sich die Valse-Daten auf GitHub ansehen und wenn Sie Fragen haben, zögern Sie nicht, uns zu kontaktieren."}
{"dataset_id": "acl_6060", "sample_id": 420, "src_lang": "en", "tgt_lang": "de", "output": "Hallo, mein Name ist Kamisara von der University of Tokio. Ich werde eine Papier entitelt RNSAM, ein großes Dasein für automatische Restnoturation bei der Commit Dog Summization. Ich werde in dieser Ordnung erklären. Erst, ich werde die automatische Restnoturation, die wir in dieser Research arbeiten, einführen. ReleaseNode ist ein technischer Dokument, das die Changes mit jedem Release von einem Softwareprodukt zusammenfasst. Das Image zeigt die ReleaseNode für Version zwei. sechs. vier der GBUJS Library. Diese Nodes spielen eine wichtige Rolle in Open Source Development, aber sie sind Zeit consumierend zu erstellen. Daher wird es sehr nützlich sein, automatisch hochqualitäre Release Nodes zu generieren. Ich werde auf zwei frühere Researchers auf automatische Release Node Generation eingehen. Der erste ist ein System namens Arena, das in twenty fourteen erstellt wurde. Es ergreift eine Rule basierende Approach, zum Beispiel, indem es die Change Extractor verwendet, um Code differenzen zu extrahieren. Bibliotheksänderungen und Dokumentenänderungen von den differenzierten Releases und schließlich kombinieren. Die meisten erkennbaren Funktionen dieses Systems sind die Issue Extractor in der oberen rechten Ecke, die mit Jira, dem Issue Toco System, verknüpft und nur für Projekte verwendet werden kann. In anderen Worten, es kann nicht für viele Projekte auf GitHub verwendet werden. Die zweite ist Griff, die Entry angeboten wurde in twenty twenty. Sie ist auf dem Internet und kann durch PIPSTEMENSSER Dieses System hat ein einfaches Lernbasis für Textklassifikation und erhält eine von fünf Rabellen, die Funktionen oder Bugfixen für jedes Input Commit-Message enthalten. Das Bild ist eine Sample-Usage, die eine korrekte oder Bugfixen-Rabelle enthält. Die gerade erstellten Rabellen sind ziemlich klein, etwa fünftausend, und werden in den Experimenten beschriebenen darüber gezeigt. Die Leistung des Textklassifikationsmodells ist nicht hoch. Ich präsentiere zwei related Researchers, aber es gibt Probleme mit begrenztem Erwerb und geringen Daten. und Scar State Resources. Unser Papier löst diese beiden Probleme und automatisch generiert High Quality Releasing Notes. Für das limitierte Applicability Programm, wir propagieren eine High Quality Classifier Summarization Methode, die nur Committee Message als Input verwendet. Diese Methode kann für alle English Repositories verwendet werden. Für das zweite Problem der Scar State Resources, wir bauen RL und SAM DSET konsistent mit etwa achtzig zwei Tausend Pieces von Daten, die von öffentlichen GitHub API. Next, ich beschreibe unser Desert. Hier ist ein Beispiel für Daten. Die linke Seite ist ein Commit Message und die rechte Seite ist die RISE Nodes. Die RISE Nodes sind Raveled als Implement, Bug fixes, etc. Wir haben eine Task setup, die die Commit Messages als Input und die Raveled RISE Nodes aufwendet. Dies kann als eine Summarization Task bezeichnet werden. Wir haben vier Raveled Features, Implement, Bug fixes, Duplications, Removables und Breaking Changes. Diese wurden basierend auf PBR research und anderen Faktoren. Die RISE Noten auf der bottom right und extrahiert von den RISE Noten auf der bottom left. At diesem Zeitpunkt ist es notwendig, die vier Rabels zu detektieren, die in der Passage sind, aber die Rabels sind nicht immer konsistent mit jeder Repository. Zum Beispiel, die Improvements Rabels inklusive Improvements, Enhancements, Optimisations und so weiter. Wir haben eine Vokabularliste oder Studie Rabels für jeden dieser Notation. variations. Verwenden Sie es, um die Restknoten zu erkennen und den Text der Restknoten zu korrigieren. Als nächstes kommt eine Kommittemessage. Kommittemessagen sind nicht zu jeder Rest. Wie in der image below, wenn die aktuelle Rest Persönlich 2.5219 ist, müssen wir die vorherige Rest Persönlich 2.5218 identifizieren und einen Tiff erhalten. Dies ist ein bisschen tedious und es ist nicht genug, nur eine Rest der Restknoten zu erhalten. Und wir haben die Vorhand nach. Wir haben eine heuristic Matching Blue erstellt, um die vorherigen und nächsten Persönlichkeiten zu erhalten. Dasset Analysis In der End, 7.200 Repositories und 82.000 PSO wurden korrektiv. Außerdem ist die average Anzahl von ReleaseNode Tokens 63, was für eine Summarisation Task ziemlich hoch ist. Außerdem ist die Anzahl von Unique Tokens ziemlich groß, also 8.830.000. Dies ist auf die große Anzahl von Unique Kosten und Methoden zurück namens in der Repository. Next, ich werde explain die proposierte Methode. Das Crosswise Extractive and Abstractive Summarization Model besteht aus zwei neuronalen Modules, einem Classifier, der Bot oder Code Bot und einem Generator, der Bot verwendet. Erstens, GAS verwendet einen Classifier, um jedes Committee Message in fünf Risnode Classes, Features, Improvements, Bugfixes, Duplications, Plus, und andere. Die Committee Messages klassifiziert als andere oder diskutiert. Dann GAS wendet einen Generator zu den vier Rabelschnitteln unabhängig und generiert RISE NOTE für jeden Kurs. In diesem Zusammenhang sind die direkten Korrespondenzen zwischen Commit Messages und RISE NOTE nicht bekannt. Daher, um den Kurs zu trainieren, wir zwar Rabelschnitteln zu jedem Input Commit Message verwenden, indem wir die ersten zehn Charaktere für jedes Commit Message verwenden. Wir modellieren den Kurs abstruktiven Summarisierungsansatz durch zwei verschiedene Methoden. Das erste Modell, das wir als GAS Single Sync konsist von einer Sync zwei Sync Network und generiert eine Sync Long RISE Node Tagist, geben eine Konkurrenz von Input Committee Messages. Die Output Tagist kann in Crosswise Segment basierend auf speziellen Cross Specific Endpoint Symbols unterteilt werden. Die zweite Methode, Methode, die wir CSMUCH, besteht aus vier verschiedenen Sync zwei Sync Networks, jeder von denen zu einer der RISE Node Classes entspricht. Okay, lassen Sie mich das Experiment erklären. Fünf Methoden wurden GS, GS Single, GS Marge, Russelling und previous studied Griff. Regarding Abortion, in einigen Fällen, diese Noten sind in multiple Sentenzen. Da es difficil ist, die Nummer von Sentenzen zu erkennen, sind sie kombiniert mit Spaces und treaten als ein langer Satz. Der Blue ist penalisiert, wenn das System einen kurzen Satz erfährt. Diese Penalty resultiert in einem loweren Blue Value in den Experimenten der Results describiert. Finally, wir auch die Spezifität erkennen, weil Rouge und Brew nicht erkennen können, wenn die Rouge Nodes leer sind. Eine hohe Spezifität bedeutet, dass die Modellkorrektie auspackt ist, in denen die Rouge Nodes leer sind. Hier sind die Ergebnisse. Da der Daseit Emailadresse, Hashbarrieren, etc. enthält, haben wir auch den Green Daseit erkannt, der sie ausschließt. GAS und GAS erreichten Rouge Error Scores mehr als zehn Punkte höher als die Baselines. Auf dem grünen Testset stieg die Score-Gap zwischen der vorgeschlagenen Methode und der Basis auf mehr als zwanzig Punkte. Diese Ergebnisse zeigen, dass GAS und GAS signifikant effektiv sind. GAS erreichte eine bessere Rouge als GAS, was darauf hindeutet, dass das Kombinieren eines Klassifierers und eines Generators effektiv ist und das Training des Klassifierers mit Pseudoberseiten. Die hohe Abdeckung von GAS kann wahrscheinlich erreicht werden, da der Klassifier sich auf das Sekten relevanter Kommittemechanismen für jede Klasse konzentrieren kann. Xia ist viel zu höheren Ruder als Xia single, suggesting, dass es auch effektiv ist, unterschiedliche perspektive Summarisationsmodelle für jedes Nodecraft zu entwickeln. Hier sind Erronnas. Xia's Methods tend to output shorter Sentenzen als humanen Referenz Sentenzen. In der Figur auf der rechten Referenz Sentenzen hat drei oder vier Sentenzen, während Xia nur eins hat. Der Grund für diese Modellrücktanz ist, dass in den Trainingdaten nur 33 Prozent der Sentenzen sind in der Features Rabel und 40 Prozent in der Improvements Rabel. Für die More CS Methods können nicht akurat mit Noten ohne zusätzliche Informationen generiert werden. Das Top Exempel auf der rechten Seite ist ein Beispiel für eine sehr messige Kommittemessage und die Komplettesentence kann nicht generiert werden, ohne dass es sich auf die correspondente Periodrequest oder Issue bezieht. Das Beispiel below zeigt, dass die zwei Kommittemessagen in der Input related und sollten kombiniert werden. Aber es versucht dies zu tun. Schließlich eine Konklusion. Wir haben eine neue DSET für automatische Rezensionsschnittgenerierung erstellt. Wir haben auch die Aufgabe erstellt, Kommentarn zu enthalten und sie so zu summarisieren, dass sie für alle Projekte in Englisch anwendbar ist. Unser Experiment zeigt, dass die vorgeschlagene Methode weniger Noisy Rezensionsschnittgenerierung bei höherer Abdeckung als die Basisrate erzeugt. Bitte schauen Sie sich unsere DSET auf GitHub an. Vielen Dank."}
